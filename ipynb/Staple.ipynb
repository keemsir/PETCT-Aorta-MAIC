{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import special\n",
    "import os\n",
    "import copy\n",
    "import nibabel as nib\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "# Utils ..\n",
    "def subdirs(folder: str, join: bool = True, prefix: str = None, suffix: str = None, sort: bool = True) -> List[str]:\n",
    "    if join:\n",
    "        l = os.path.join\n",
    "    else:\n",
    "        l = lambda x, y: y\n",
    "    res = [l(folder, i) for i in os.listdir(folder) if os.path.isdir(os.path.join(folder, i))\n",
    "           and (prefix is None or i.startswith(prefix))\n",
    "           and (suffix is None or i.endswith(suffix))]\n",
    "    if sort:\n",
    "        res.sort()\n",
    "    return res\n",
    "\n",
    "def subfiles(folder: str, join: bool = True, prefix: str = None, suffix: str = None, sort: bool = True) -> List[str]:\n",
    "    if join:\n",
    "        l = os.path.join\n",
    "    else:\n",
    "        l = lambda x, y: y\n",
    "    res = [l(folder, i) for i in os.listdir(folder) if os.path.isfile(os.path.join(folder, i))\n",
    "           and (prefix is None or i.startswith(prefix))\n",
    "           and (suffix is None or i.endswith(suffix))]\n",
    "    if sort:\n",
    "        res.sort()\n",
    "    return res\n",
    "\n",
    "def maybe_mkdir_p(directory: str) -> None:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "\n",
    "def find3d_ind(bigMask_):\n",
    "    indV = np.argwhere(bigMask_ == True)\n",
    "    indVx = indV[:, 0]\n",
    "    indVy = indV[:, 1]\n",
    "    indVz = indV[:, 2]\n",
    "\n",
    "    xMin = np.min(indVx)\n",
    "    xMax = np.max(indVx)\n",
    "    yMin = np.min(indVy)\n",
    "    yMax = np.max(indVy)\n",
    "    zMin = np.min(indVz)\n",
    "    zMax = np.max(indVz)\n",
    "    return xMin, xMax, yMin, yMax, zMin, zMax\n",
    "\n",
    "\n",
    "def staple_wjcheon(D, iterlim, p, q):\n",
    "    # ---- inputs:\n",
    "    # *D: a matrix of N(voxels) x R(binary decisions by experts)\n",
    "    # *p: intial sensitivity\n",
    "    # *q: intial specificity\n",
    "    # *iterlim: iteration limit\n",
    "    # ---- outputs:\n",
    "    # *p: final sensitivity estimate\n",
    "    # *q: final specificity estimate\n",
    "    # *W: estimated belief in true segmentation\n",
    "    [N, R] = np.shape(D)\n",
    "    Tol = 1e-5\n",
    "    iter = 0\n",
    "    gamma = np.sum(np.sum(D, axis=0) / (R * N))\n",
    "    W = np.zeros((N, 1), dtype=np.single)\n",
    "    S0 = np.sum(W)\n",
    "\n",
    "    stapleV = []\n",
    "    sen = []\n",
    "    spec = []\n",
    "    Sall = []\n",
    "    while (True):\n",
    "        iter = iter + 1\n",
    "        Sall.append(S0)\n",
    "\n",
    "        ind1 = np.equal(D, 1)\n",
    "        ind0 = np.equal(D, 0)\n",
    "        ind1_not = np.logical_not(ind1)\n",
    "        ind0_not = np.logical_not(ind0)\n",
    "\n",
    "        p = np.repeat(p, N, axis=0)\n",
    "        p1 = copy.deepcopy(p)\n",
    "        p0 = copy.deepcopy(1 - p1)\n",
    "\n",
    "        p1[ind1_not] = 1\n",
    "        p0[ind0_not] = 1\n",
    "        a = gamma * np.multiply(np.prod(p1, axis=1), np.prod(p0, axis=1))\n",
    "        del p1, p0\n",
    "\n",
    "        q = np.repeat(q, N, axis=0)\n",
    "        q0 = copy.deepcopy(q)\n",
    "        q1 = copy.deepcopy(1 - q0)\n",
    "        q1[ind1_not] = 1\n",
    "        q0[ind0_not] = 1\n",
    "        del ind1, ind0, ind1_not, ind0_not\n",
    "        b = (1 - gamma) * np.multiply(np.prod(q0, axis=1), np.prod(q1, axis=1))\n",
    "        del q1, q0\n",
    "\n",
    "        W = np.divide(a, a + b)\n",
    "        W = np.reshape(W, (1, len(W)))\n",
    "\n",
    "        del a, b, p, q\n",
    "\n",
    "        p = np.divide(np.matmul(W, D), np.sum(W))\n",
    "        q = np.divide(np.matmul(1 - W, 1 - D), np.sum(1 - W))\n",
    "        # Check convergence\n",
    "        S = np.sum(W)\n",
    "        if np.abs(S - S0) < Tol:\n",
    "            print(\"STAPLE converged in {} iterations\".format(iter))\n",
    "            break\n",
    "        else:\n",
    "            S0 = S\n",
    "\n",
    "        # Check iteration limit\n",
    "        if (iter > iterlim):\n",
    "            print(\"STAPLE: Number of iterations exceeded without convergence (convergence tolerance = %e)\".format(Tol))\n",
    "            break\n",
    "\n",
    "    return W, p, q, Sall\n",
    "\n",
    "\n",
    "def getUniformScanXYZVals_standardalone(rtstStruct):\n",
    "    sizeArray = np.shape(rtstStruct)\n",
    "    sizeDim1 = sizeArray[0] - 1  # sizeArray[0] - 1\n",
    "    sizeDim2 = sizeArray[1] - 1  # sizeArray[1] - 1\n",
    "\n",
    "    xOffset = 0\n",
    "    yOffset = 0\n",
    "    firstZValue = 0\n",
    "    grid2Units = 4.6875  # 0.9765625\n",
    "    grid1Units = 4.6875  # 0.9765625\n",
    "    sliceThickness = 3.27001953\n",
    "\n",
    "    # xVals = xOffset - (sizeDim2*grid2Units)/2 : grid2Units :\n",
    "    xSt = xOffset - (sizeDim2 * grid2Units) / 2\n",
    "    xEnd = xOffset + (sizeDim2 * grid2Units) / 2 + grid2Units\n",
    "    xVals = np.arange(xSt, xEnd, grid2Units)\n",
    "\n",
    "    ySt = yOffset - (sizeDim1 * grid1Units) / 2\n",
    "    yEnd = yOffset + (sizeDim1 * grid1Units) / 2 + grid2Units\n",
    "    yVals = np.arange(ySt, yEnd, grid1Units)\n",
    "    yVals = np.flip(yVals)\n",
    "\n",
    "    nZSlices = sizeArray[2];\n",
    "    zSt = firstZValue\n",
    "    zEnd = sliceThickness * (nZSlices - 1) + firstZValue + sliceThickness\n",
    "    zVals = np.arange(zSt, zEnd, sliceThickness)\n",
    "\n",
    "    return xVals, yVals, zVals\n",
    "\n",
    "\n",
    "def kappa_stats(D, ncat):\n",
    "    [N, M] = np.shape(D)\n",
    "    lk = len(ncat)\n",
    "    x = []\n",
    "    for iterVal in range(0, lk):\n",
    "        x.append(np.sum(np.equal(D, ncat[iterVal]), axis=1))\n",
    "    x = np.transpose(x)\n",
    "\n",
    "    p = np.divide(np.sum(x, axis=0), (N * M)) # Default : axis=0\n",
    "    eps = np.finfo(float).eps\n",
    "    k_a = np.sum(np.multiply(x, M - x), axis=0) # Default : axis=0\n",
    "    k_b = (N * M * (M - 1)) * np.multiply(p, (1 - p)) + eps\n",
    "    k = 1 - np.divide(k_a, k_b)\n",
    "    sek = np.sqrt(2 / (N * M * (M - 1)))\n",
    "    pk = drxlr_get_p_gaussian(np.divide(k, sek)) / 2\n",
    "    kappa_a = N * M * M - np.sum(np.sum(np.multiply(x, x)))\n",
    "    kappa_b = N * M * (M - 1) * np.sum(np.multiply(p, (1 - p))) + eps\n",
    "    kappa = 1 - (kappa_a / kappa_b)\n",
    "    sekappa_a = np.sum(np.multiply(p, (1 - p)) * np.sqrt(N * M * (M - 1)) + eps)\n",
    "    sekappa_b = np.power(np.sqrt(np.sum(np.multiply(p, (1 - p)))), 2) - np.sum(\n",
    "        np.multiply(np.multiply(p, 1 - p), (1 - 2 * p)))\n",
    "    sekappa = np.sqrt(2) / sekappa_a * sekappa_b\n",
    "    z = kappa / sekappa\n",
    "    pval = drxlr_get_p_gaussian(z) / 2\n",
    "\n",
    "    return kappa, pval, k, pk\n",
    "\n",
    "\n",
    "def drxlr_get_p_gaussian(x):\n",
    "    p = special.erfc(np.abs(x) / np.sqrt(2))\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "def calConsensus_standardalone(rtstStructs):\n",
    "    keysDictionary = list(rtstStructs.keys())\n",
    "    bigMask = rtstStructs.get(keysDictionary[0])\n",
    "    dictionaryLength = len(rtstStructs)\n",
    "    for iter1 in range(0, dictionaryLength):\n",
    "        bigMask = np.logical_or(bigMask, rtstStructs.get(keysDictionary[iter1]))\n",
    "\n",
    "    iMin, iMax, jMin, jMax, kMin, kMax = find3d_ind(bigMask);\n",
    "\n",
    "    averageMask3M = np.zeros((iMax - iMin + 1, jMax - jMin + 1, kMax - kMin + 1), dtype=np.single)\n",
    "    rateMat = []\n",
    "    for iter1 in range(0, dictionaryLength):\n",
    "        mask3M = rtstStructs.get(keysDictionary[iter1])\n",
    "        mask3M_ROI = np.asanyarray(mask3M[iMin:iMax + 1, jMin: jMax + 1, kMin: kMax + 1])\n",
    "        averageMask3M = averageMask3M + mask3M_ROI\n",
    "        mask3M_ROI_flat = mask3M_ROI.flatten()\n",
    "        rateMat.append(mask3M_ROI_flat)\n",
    "    averageMask3M = averageMask3M / dictionaryLength\n",
    "    rateMat = np.transpose(rateMat)\n",
    "    scanNum = 1\n",
    "    iterlim = 100\n",
    "    senstart = 0.9999 * np.ones((1, dictionaryLength))\n",
    "    specstart = 0.9999 * np.ones((1, dictionaryLength))\n",
    "    [stapleV, sen, spec, Sall] = staple_wjcheon(rateMat, iterlim, np.single(senstart), np.single(specstart))\n",
    "\n",
    "    mean_sen = np.mean(sen)\n",
    "    std_sen = np.std(sen, ddof=1)\n",
    "    mean_spec = np.mean(spec)\n",
    "    std_spec = np.std(spec, ddof=1)\n",
    "\n",
    "    [xUnifV, yUnifV, zUnifV] = getUniformScanXYZVals_standardalone(mask3M)\n",
    "    vol = (xUnifV[2] - xUnifV[1]) * (yUnifV[1] - yUnifV[2]) * (zUnifV[2] - zUnifV[1])\n",
    "    vol = vol * 0.001\n",
    "\n",
    "    numBins = 20\n",
    "    obsAgree = np.linspace(0.001, 1, numBins)\n",
    "    rater_prob = np.mean(rateMat, axis=0)\n",
    "    chance_prob = np.sqrt(np.multiply(rater_prob, (1 - rater_prob)))\n",
    "    chance_prob = np.reshape(chance_prob, (1, np.shape(chance_prob)[0]))\n",
    "    chance_prob_mat = np.repeat(chance_prob, np.shape(rateMat)[0], axis=0)\n",
    "    reliabilityV = np.mean(np.divide((rateMat - chance_prob_mat), (1 - chance_prob_mat)), axis=1)\n",
    "    del rater_prob, chance_prob, chance_prob_mat\n",
    "\n",
    "    volV = []\n",
    "    volStapleV = []\n",
    "    volKappaV = []\n",
    "    for iter10 in range(0, len(obsAgree)):\n",
    "        updatedValue = np.sum((averageMask3M.flatten() >= obsAgree[iter10]) * vol)\n",
    "        volV.append(updatedValue)\n",
    "        updatedValue2 = np.sum((stapleV.flatten() >= obsAgree[iter10]) * vol)\n",
    "        volStapleV.append(updatedValue2)\n",
    "        updatedValue3 = np.sum((reliabilityV.flatten() >= obsAgree[iter10]) * vol)\n",
    "        volKappaV.append(updatedValue3)\n",
    "\n",
    "    # calculate overall kappa\n",
    "    [kappa, pval, k, pk] = kappa_stats(rateMat, [0, 1])\n",
    "    min_vol = np.min(np.sum(rateMat, axis=0)) * vol\n",
    "    max_vol = np.max(np.sum(rateMat, axis=0)) * vol\n",
    "    mean_vol = np.mean(np.sum(rateMat, axis=0)) * vol\n",
    "    sd_vol = np.std(np.sum(rateMat, axis=0), ddof=1) * vol\n",
    "\n",
    "    print('-------------------------------------------')\n",
    "    print('Overall kappa: {0:1.8f}'.format(kappa))\n",
    "    print('p-value: {0:1.8f}'.format(pval))\n",
    "    print('Mean Sensitivity: {0:1.8f}'.format(mean_sen))\n",
    "    print('Std. Sensitivity: {0:1.8f}'.format(std_sen))\n",
    "    print('Mean Specificity: {0:1.8f}'.format(mean_spec))\n",
    "    print('Std. Specificity: {0:1.8f}'.format(std_spec))\n",
    "    print('Min. volume: {0:1.8f}'.format(min_vol))\n",
    "    print('Max. volume: {0:1.8f}'.format(max_vol))\n",
    "    print('Mean volume: {0:1.8f}'.format(mean_vol))\n",
    "    print('Std. volume: {0:1.8f}'.format(sd_vol))\n",
    "    print('Intersection volume: {0:1.8f}'.format(volV[-1]))\n",
    "    print('Union volume: {0:1.8f}'.format(volV[1]))\n",
    "    print('-------------------------------------------')\n",
    "    \n",
    "    len_x, len_y, len_z = np.shape(averageMask3M)\n",
    "    stapleV_reshape = np.reshape(stapleV, (len_x, len_y, len_z))\n",
    "    staple3M = np.zeros_like(bigMask, dtype=np.single)\n",
    "    staple3M[iMin:iMax + 1, jMin: jMax + 1, kMin: kMax + 1] = stapleV_reshape\n",
    "    #\n",
    "    reliabilityV_reshape = np.reshape(reliabilityV, (len_x, len_y, len_z))\n",
    "    reliability3M = np.zeros_like(bigMask, dtype=np.single)\n",
    "    reliability3M[iMin:iMax + 1, jMin: jMax + 1, kMin: kMax + 1] = reliabilityV_reshape\n",
    "    #\n",
    "    apparent3M = np.zeros_like(bigMask, dtype=np.single)\n",
    "    apparent3M[iMin:iMax + 1, jMin: jMax + 1, kMin: kMax + 1] = averageMask3M\n",
    "\n",
    "    return apparent3M, staple3M, reliability3M\n",
    "\n",
    "\n",
    "##### Parameter #####\n",
    "\n",
    "folderlist_temp = ['21-11-19_18:39:14-models', '21-11-20_14:40:14-models', '21-11-21_20:01:25-models', '21-11-22_13:15:33-models', '21-11-23_09:00:50-models']\n",
    "\n",
    "# mainPath = './models/result/'\n",
    "savePath = './models/staple/'\n",
    "\n",
    "mainPath = './{}/result/'.format(folderlist_temp[0])\n",
    "\n",
    "result_list = subfiles(mainPath, join=False, suffix='.nii.gz')\n",
    "\n",
    "\n",
    "\n",
    "targetWeight = 0.99\n",
    "\n",
    "maybe_mkdir_p(savePath)\n",
    "\n",
    "\n",
    "# folderList = subdirs(mainPath, join = False) # os.listdir(mainPath)\n",
    "\n",
    "\n",
    "print(\"STAPLE process is starting...\")\n",
    "\n",
    "\n",
    "\n",
    "for iterPatient in result_list: # PatientKey\n",
    "\n",
    "    dataPerPatient_aorta = {} # Model ë³„ Stack\n",
    "\n",
    "    for ModelList in folderlist_temp:\n",
    "\n",
    "        patientStack_aorta = np.array(nib.load(os.path.join('./{}/result/'.format(ModelList), iterPatient)).dataobj)\n",
    "\n",
    "        dataPerPatient_aorta[ModelList] = patientStack_aorta\n",
    "        \n",
    "        del patientStack_aorta\n",
    "\n",
    "    # STAPLE\n",
    "    [apparent3M_label2, staple3M_label2, reliability3M_label2] = calConsensus_standardalone(dataPerPatient_aorta)\n",
    "    mask2 = np.uint8((staple3M_label2 >= targetWeight))\n",
    "    \n",
    "    print(iterPatient)\n",
    "    print(np.sum(mask2))\n",
    "    \n",
    "    print(np.unique(staple3M_label2))\n",
    "    print(np.sum(staple3M_label2))\n",
    "    print(staple3M_label2.shape)\n",
    "    print(type(staple3M_label2))\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    plt.hist(staple3M_label2.flatten(), bins=40)\n",
    "    plt.axis([0, 1, 0, 500])\n",
    "    plt.show()\n",
    "    \n",
    "#     plt.hist(staple3M_label2.flatten(), bins=40)\n",
    "#     plt.axis([0.9, 1, 0, 2000])\n",
    "#     plt.show()\n",
    "    \n",
    "    print(np.unique(mask2))\n",
    "    print(mask2.shape)\n",
    "    print(type(mask2))\n",
    "    \n",
    "    print('==========================================================')\n",
    "    \n",
    "    nii_stp = nib.Nifti1Image(mask2, affine=np.eye(4))\n",
    "    nib.save(nii_stp, os.path.join(savePath, iterPatient))\n",
    "    \n",
    "    del apparent3M_label2, staple3M_label2, reliability3M_label2\n",
    "\n",
    "\n",
    "print(\"STAPLE process is done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/mnt/NM/dataset/'\n",
    "size_dic = {}\n",
    "\n",
    "def hdf2nifti_size(hdf_folder: str):\n",
    "    # hdf_folder : [train_dir, test_dir] hdf5 file path\n",
    "    # save_folder : [imagesTr, imagesTs] Save Folder path\n",
    "\n",
    "    hdf5_files = os.listdir(hdf_folder)\n",
    "\n",
    "\n",
    "    for hdf5_file in hdf5_files:\n",
    "\n",
    "        hdf5_path = os.path.join(hdf_folder, hdf5_file)\n",
    "\n",
    "        # image\n",
    "        f_i = h5py.File(hdf5_path, 'r')\n",
    "        ctarr = np.asarray(f_i['CT'])\n",
    "        petarr = np.asarray(f_i['PET'])\n",
    "        sizearr = np.asarray(f_i['Size'])\n",
    "        f_i.close()\n",
    "        \n",
    "        size_dic[hdf5_file[:17]] = sizearr # new\n",
    "\n",
    "        print('{} = sizearr : {}, ctarr : {}, petarr : {}'.format(hdf5_file, sizearr, ctarr.shape, petarr.shape))\n",
    "\n",
    "\n",
    "    print('Image Patient : {}'.format(len(os.listdir(hdf_folder))))\n",
    "\n",
    "\n",
    "hdf2nifti_size(input_dir)\n",
    "\n",
    "\n",
    "\n",
    "def get_suv_params(ptarr, roi):\n",
    "    roi = np.asarray(roi>0, dtype=np.float)\n",
    "    suvmax = np.max(ptarr*roi)\n",
    "    suvmean = np.sum(ptarr*roi)/np.sum(roi)\n",
    "    return suvmax, suvmean\n",
    "\n",
    "def get_vol_params(ptzoom, roi):\n",
    "    roi = np.asarray(roi>0, dtype=np.float)\n",
    "    return np.prod(ptzoom) * np.sum(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PN_list = subfiles('./models/staple/', join=False, suffix='.nii.gz')\n",
    "\n",
    "for pn_l in PN_list:\n",
    "    _, ext = os.path.splitext(pn_l)\n",
    "    if ext == '.gz':\n",
    "        \n",
    "        pn = pn_l[:-7]\n",
    "        PATIENT_NUM = pn\n",
    "        \n",
    "        ptarr = np.array(nib.load('./21-11-16_14:39:41-models/temp/convert_data/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data/Task555_PETCT/imagesTs/{}_0001.nii.gz'.format(pn)).dataobj)\n",
    "        ctarr = np.array(nib.load('./21-11-16_14:39:41-models/temp/convert_data/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data/Task555_PETCT/imagesTs/{}_0000.nii.gz'.format(pn)).dataobj)\n",
    "        pred_arr = np.array(nib.load('./models/staple/{}.nii.gz'.format(pn)).dataobj)\n",
    "\n",
    "        \n",
    "        # size = ([4.07283, 4.07283, 3.])\n",
    "        # size = ([4.6875, 4.6875, 3.27001953])\n",
    "        size = size_dic[PATIENT_NUM]\n",
    "        \n",
    "        #Calculate Mean SUV and Max SUV\n",
    "\n",
    "        suvmax, suvmean = get_suv_params(ptarr, pred_arr)\n",
    "\n",
    "        #Calculate Volume\n",
    "\n",
    "        aorvol = get_vol_params(size, pred_arr)\n",
    "        \n",
    "        PATIENT_NUM = pn\n",
    "\n",
    "        data = {'case' : [PATIENT_NUM], 'PD_Aorta_volume' : [aorvol], 'PD_SUVmean' : [suvmean]}\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # .to_csv \n",
    "        if not os.path.exists('submission.csv'):\n",
    "            df.to_csv('submission.csv', index=False, mode='w')\n",
    "        else:\n",
    "            df.to_csv('submission.csv', index=False, mode='a', header=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
