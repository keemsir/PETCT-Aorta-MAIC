{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from typing import List\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_mkdir_p(directory: str) -> None:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "input_dir = '/mnt/NM/dataset/'\n",
    "\n",
    "try:\n",
    "    import nnunet\n",
    "except:\n",
    "    respository_dir = os.path.join(base_dir, 'models/module')\n",
    "    os.chdir(respository_dir)\n",
    "    ! pip install -e .\n",
    "    os.chdir(base_dir)\n",
    "\n",
    "# from scipy import special\n",
    "# import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils ..\n",
    "def subdirs(folder: str, join: bool = True, prefix: str = None, suffix: str = None, sort: bool = True) -> List[str]:\n",
    "    if join:\n",
    "        l = os.path.join\n",
    "    else:\n",
    "        l = lambda x, y: y\n",
    "    res = [l(folder, i) for i in os.listdir(folder) if os.path.isdir(os.path.join(folder, i))\n",
    "           and (prefix is None or i.startswith(prefix))\n",
    "           and (suffix is None or i.endswith(suffix))]\n",
    "    if sort:\n",
    "        res.sort()\n",
    "    return res\n",
    "\n",
    "\n",
    "def subfiles(folder: str, join: bool = True, prefix: str = None, suffix: str = None, sort: bool = True) -> List[str]:\n",
    "    if join:\n",
    "        l = os.path.join\n",
    "    else:\n",
    "        l = lambda x, y: y\n",
    "    res = [l(folder, i) for i in os.listdir(folder) if os.path.isfile(os.path.join(folder, i))\n",
    "           and (prefix is None or i.startswith(prefix))\n",
    "           and (suffix is None or i.endswith(suffix))]\n",
    "    if sort:\n",
    "        res.sort()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder : \n",
    "\n",
    "! nnUNet_ensemble -f ./21-11-18_16:29:27-models/result/ ./21-11-18_17:01:56-models/result/ -o ./models/result/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_dic = {}\n",
    "\n",
    "def hdf2nifti_size(hdf_folder: str):\n",
    "    # hdf_folder : [train_dir, test_dir] hdf5 file path\n",
    "    # save_folder : [imagesTr, imagesTs] Save Folder path\n",
    "\n",
    "    hdf5_files = os.listdir(hdf_folder)\n",
    "    hdf5_files.sort()\n",
    "\n",
    "\n",
    "    for hdf5_file in hdf5_files:\n",
    "\n",
    "        hdf5_path = os.path.join(hdf_folder, hdf5_file)\n",
    "\n",
    "        # image\n",
    "        f_i = h5py.File(hdf5_path, 'r')\n",
    "        ctarr = np.asarray(f_i['CT'])\n",
    "        petarr = np.asarray(f_i['PET'])\n",
    "        sizearr = np.asarray(f_i['Size'])\n",
    "        f_i.close()\n",
    "        \n",
    "        size_dic[hdf5_file[:17]] = sizearr # new\n",
    "\n",
    "        print('{} = sizearr : {}, ctarr : {}, petarr : {}'.format(hdf5_file, sizearr, ctarr.shape, petarr.shape))\n",
    "\n",
    "\n",
    "    print('Image Patient : {}'.format(len(os.listdir(hdf_folder))))\n",
    "\n",
    "\n",
    "def get_suv_params(ptarr, roi):\n",
    "    roi = np.asarray(roi>0, dtype=np.float)\n",
    "    suvmax = np.max(ptarr*roi)\n",
    "    suvmean = np.sum(ptarr*roi)/np.sum(roi)\n",
    "    return suvmax, suvmean\n",
    "\n",
    "def get_vol_params(ptzoom, roi):\n",
    "    roi = np.asarray(roi>0, dtype=np.float)\n",
    "    return np.prod(ptzoom) * np.sum(roi)\n",
    "\n",
    "hdf2nifti_size(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PN_list = subfiles('./models/result/', join=False, suffix='.nii.gz')\n",
    "\n",
    "for pn_l in PN_list:\n",
    "    _, ext = os.path.splitext(pn_l)\n",
    "    if ext == '.gz':\n",
    "        \n",
    "        pn = pn_l[:-7]\n",
    "\n",
    "        ptarr = np.array(nib.load('./21-11-16_14:39:41-models/temp/convert_data/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data/Task555_PETCT/imagesTs/{}_0001.nii.gz'.format(pn)).dataobj)\n",
    "        ctarr = np.array(nib.load('./21-11-16_14:39:41-models/temp/convert_data/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data/Task555_PETCT/imagesTs/{}_0000.nii.gz'.format(pn)).dataobj)\n",
    "        pred_arr = np.array(nib.load('./models/result/{}.nii.gz'.format(pn)).dataobj)\n",
    "        \n",
    "        \n",
    "        size = size_dic[pn]\n",
    "        \n",
    "        #Calculate Mean SUV and Max SUV\n",
    "\n",
    "        suvmax, suvmean = get_suv_params(ptarr, pred_arr)\n",
    "\n",
    "        #Calculate Volume\n",
    "\n",
    "        aorvol = get_vol_params(size, pred_arr)\n",
    "        \n",
    "        data = {'case' : [pn], 'PD_Aorta_volume' : [aorvol], 'PD_SUVmean' : [suvmean]}\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # .to_csv \n",
    "        if not os.path.exists('submission.csv'):\n",
    "            df.to_csv('submission.csv', index=False, mode='w')\n",
    "        else:\n",
    "            df.to_csv('submission.csv', index=False, mode='a', header=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
