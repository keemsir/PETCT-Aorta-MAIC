{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n! mkdir -p /root/.pip\\n\\n\\n%%writefile /root/.pip/pip.conf\\n[global]\\nindex-url=http://ftp.daumkakao.com/pypi/simple\\ntrusted-host=ftp.daumkakao.com\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "! mkdir -p /root/.pip\n",
    "\n",
    "\n",
    "%%writefile /root/.pip/pip.conf\n",
    "[global]\n",
    "index-url=http://ftp.daumkakao.com/pypi/simple\n",
    "trusted-host=ftp.daumkakao.com\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://ftp.daumkakao.com/pypi/simple\n",
      "Obtaining file:///tf/backup/nnUNet\n",
      "Requirement already satisfied: torch>=1.6.0a in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (1.9.1+cu111)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (4.62.3)\n",
      "Collecting dicom2nifti\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/26/f1/22e4cb6704a5204b9ed731e74fac180b3659c0a1af65f6e2b149013bda21/dicom2nifti-2.3.0.tar.gz (33 kB)\n",
      "Requirement already satisfied: scikit-image>=0.14 in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (0.18.3)\n",
      "Collecting medpy\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/3b/70/c1fd5dd60242eee81774696ea7ba4caafac2bad8f028bba94b1af83777d7/MedPy-0.4.0.tar.gz (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 26.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (1.7.1)\n",
      "Collecting batchgenerators>=0.23\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/02/6e/3353824a6d782dfad850f026c3020509b69abf21c5a503b1f76e63b8f48f/batchgenerators-0.23.tar.gz (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 101.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (1.19.5)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (0.0)\n",
      "Collecting SimpleITK\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/94/82/3d9993548359b031bdba679cab7562cdd7380e829924e6c6ce90237de700/SimpleITK-2.1.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 48.4 MB 39.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (1.3.4)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from nnunet==1.7.0) (2.22.0)\n",
      "Collecting nibabel\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/42/bf/ba089fec67237f6439c345b8977ca6dde67402ada6592bf84c2c78d557ff/nibabel-3.2.1-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 44.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tifffile in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (2021.11.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6.0a->nnunet==1.7.0) (3.7.4.3)\n",
      "Collecting pydicom>=1.3.0\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/53/9a/98df4fb41e7905b587be2ee9ce38bab8a092990bd174f46fd915a23ec0ea/pydicom-2.2.2-py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 46.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.6.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (8.3.2)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.10.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (3.4.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from batchgenerators>=0.23->nnunet==1.7.0) (1.0.1)\n",
      "Collecting future\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 46.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting unittest2\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/72/20/7f0f433060a962200b7272b8c12ba90ef5b903e218174301d0abfd523813/unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 123.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl in /usr/local/lib/python3.8/dist-packages (from batchgenerators>=0.23->nnunet==1.7.0) (3.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->nnunet==1.7.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->nnunet==1.7.0) (2021.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.8/dist-packages (from nibabel->nnunet==1.7.0) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14->nnunet==1.7.0) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14->nnunet==1.7.0) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14->nnunet==1.7.0) (1.3.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->batchgenerators>=0.23->nnunet==1.7.0) (1.1.0)\n",
      "Collecting argparse\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: six>=1.4 in /usr/local/lib/python3.8/dist-packages (from unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.15.0)\n",
      "Collecting traceback2\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/17/0a/6ac05a3723017a967193456a2efa0aa9ac4b51456891af1e2353bb9de21e/traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting linecache2\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/c7/a3/c5da2a44c85bfbb6eebcfc1dde24933f8704441b98fdde6528f4831757a6/linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: dicom2nifti, medpy, batchgenerators, future\n",
      "  Building wheel for dicom2nifti (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dicom2nifti: filename=dicom2nifti-2.3.0-py3-none-any.whl size=42932 sha256=388e702ee551b9b77c31814fa1bed13d1e2e3fe68c40c04bd429352c6c276c8a\n",
      "  Stored in directory: /root/.cache/pip/wheels/6c/63/4b/bfdb925ebf1c6ee721258d7f8a69951cd76e6d178bb0d0395b\n",
      "  Building wheel for medpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for medpy: filename=MedPy-0.4.0-py3-none-any.whl size=214963 sha256=c0b022cfa89d02fc363f53660a1b18231e4efef04cf097bf5d25919c4faa7073\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/90/13/5b5a86494a571d07e6549b9910a7bdc9728aa15b4778dfddff\n",
      "  Building wheel for batchgenerators (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for batchgenerators: filename=batchgenerators-0.23-py3-none-any.whl size=84780 sha256=a3a51fc2815c1d3eebd05bba168e02b9effcfdecc52806085d1f78e546674c15\n",
      "  Stored in directory: /root/.cache/pip/wheels/c1/2c/4d/038dd472e137fe2b32c595bd96a6cc346543b9c7141432e8be\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=abc4ecc833ad255477d16c54f0d308b71df79f764a3d6deb5f4e70c09acec300\n",
      "  Stored in directory: /root/.cache/pip/wheels/18/06/47/bf4a03c24ff334fa02e8b45095b422a432b7c6bf9d72a40a99\n",
      "Successfully built dicom2nifti medpy batchgenerators future\n",
      "Installing collected packages: nibabel, pydicom, dicom2nifti, SimpleITK, medpy, future, argparse, linecache2, traceback2, unittest2, batchgenerators, nnunet\n",
      "  Running setup.py develop for nnunet\n",
      "Successfully installed SimpleITK-2.1.1 argparse-1.4.0 batchgenerators-0.23 dicom2nifti-2.3.0 future-0.18.2 linecache2-1.0.0 medpy-0.4.0 nibabel-3.2.1 nnunet pydicom-2.2.2 traceback2-1.4.0 unittest2-1.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def maybe_mkdir_p(directory: str) -> None:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "maic_dir = '/tf/backup/'\n",
    "base_dir = os.path.join(maic_dir, 'working')\n",
    "input_dir = '/mnt/dataset/'\n",
    "temp_dir = '/tf/temp/'\n",
    "\n",
    "maybe_mkdir_p(base_dir)\n",
    "maybe_mkdir_p(temp_dir)\n",
    "\n",
    "# ! git clone https://github.com/keemsir/nnUNet.git\n",
    "\n",
    "respository_dir = os.path.join(maic_dir, 'nnUNet')\n",
    "os.chdir(respository_dir)\n",
    "\n",
    "! pip install -e .\n",
    "\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installed\n",
    "import shutil\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "from scipy import special\n",
    "import copy\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "# must install\n",
    "import pydicom\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Completed!\n"
     ]
    }
   ],
   "source": [
    "task_name = 'Task55_PETCT'\n",
    "convert_name = 'Task555_PETCT'\n",
    "\n",
    "main_dir = os.path.join(base_dir, 'nnUNet/nnunet')\n",
    "mainT_dir = os.path.join(temp_dir, 'nnUNet/nnunet')\n",
    "\n",
    "rawbase_dir = os.path.join(mainT_dir, 'nnUNet_raw_data_base/')\n",
    "\n",
    "pp_dir = os.path.join(mainT_dir, 'preprocessed')\n",
    "tasks_dir = os.path.join(mainT_dir, 'Tasks')\n",
    "task_dir = os.path.join(tasks_dir, task_name)\n",
    "\n",
    "model_dir = os.path.join(main_dir, 'nnUNet_trained_models')\n",
    "Prediction_dir = os.path.join(main_dir, 'nnUNet_Prediction_Results')\n",
    "result_dir = os.path.join(Prediction_dir, convert_name)\n",
    "\n",
    "staple_dir = os.path.join(Prediction_dir, 'staple')\n",
    "\n",
    "# 1. Data preprocessing\n",
    "maybe_mkdir_p(tasks_dir)\n",
    "maybe_mkdir_p(temp_dir)\n",
    "\n",
    "# 2. Directory\n",
    "maybe_mkdir_p(main_dir)\n",
    "maybe_mkdir_p(model_dir)\n",
    "maybe_mkdir_p(pp_dir)\n",
    "\n",
    "# 3. Directory\n",
    "maybe_mkdir_p(result_dir)\n",
    "maybe_mkdir_p(staple_dir)\n",
    "\n",
    "\n",
    "#Environment Setting\n",
    "os.environ['nnUNet_raw_data_base'] = rawbase_dir #os.path.join(mainT_dir, 'nnUNet_raw_data_base')\n",
    "os.environ['nnUNet_preprocessed'] = pp_dir #os.path.join(mainT_dir, 'preprocessed')\n",
    "os.environ['RESULTS_FOLDER'] = model_dir #os.path.join(main_dir, 'nnUNet_trained_models')\n",
    "\n",
    "\n",
    "print('Setting Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating \"Task55_PETCT\" Image & Label ..\n",
      "23090580_20131226.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090618_20161212.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090628_20150204.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090643_20121227.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090644_20131216.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090636_20121018.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090585_20130213.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090572_20130226.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090603_20141212.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090601_20130225.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090569_20120607.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090599_20140701.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090597_20130227.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090627_20160608.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090559_20150812.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090614_20120402.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090557_20130717.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090634_20150409.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090581_20130626.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090626_20160119.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090568_20121018.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090623_20120406.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090615_20140403.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090640_20140711.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090613_20130208.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090641_20160510.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090609_20120510.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090560_20160114.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090563_20151216.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090596_20150112.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090632_20130807.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090598_20130103.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090584_20120523.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090633_20120403.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090607_20120420.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090594_20160706.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090622_20150105.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090583_20160308.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090637_20140401.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090620_20130617.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090645_20141212.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090621_20130409.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090562_20140206.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090582_20150401.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090566_20141114.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090571_20120517.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090642_20130409.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090595_20121015.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090586_20120627.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090604_20140303.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090561_20120330.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090610_20151210.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090639_20150522.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090608_20120718.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090588_20131025.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090578_20120613.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090593_20120625.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090564_20130312.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090631_20130128.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090616_20140331.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090606_20120619.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090638_20131126.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090629_20120830.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090592_20130218.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090625_20160111.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090589_20140219.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090617_20140211.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090590_20121212.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090619_20121210.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090611_20150212.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090612_20121213.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090646_20120718.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090600_20121108.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090579_20141215.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090630_20130213.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090558_20120330.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090591_20140124.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090567_20160819.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090635_20140710.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "23090587_20150908.hdf5  :  [4.6875     4.6875     3.27001953]\n",
      "\"Task55_PETCT\" Image & Label Completed !!\n",
      "Image Patient : 80\n"
     ]
    }
   ],
   "source": [
    "def hdf2nifti(hdf_folder: str, save_folder: str):\n",
    "    # hdf_folder : [train_dir, test_dir] hdf5 file path\n",
    "    # save_folder : [imagesTr, imagesTs] Save Folder path\n",
    "    maybe_mkdir_p(os.path.join(save_folder, 'imagesTr'))\n",
    "    maybe_mkdir_p(os.path.join(save_folder, 'labelsTr'))\n",
    "    print('Creating \"{}\" Image & Label ..'.format(os.path.basename(os.path.normpath(save_folder))))\n",
    "    hdf5_files = os.listdir(hdf_folder)\n",
    "\n",
    "\n",
    "    for hdf5_file in hdf5_files:\n",
    "\n",
    "\n",
    "        hdf5_path = os.path.join(hdf_folder, hdf5_file)\n",
    "\n",
    "        # image\n",
    "        f_i = h5py.File(hdf5_path, 'r')\n",
    "        ctarr = np.asarray(f_i['CT'])\n",
    "        petarr = np.asarray(f_i['PET'])\n",
    "        labels = np.asarray(f_i['Aorta'])\n",
    "        sizearr = np.asarray(f_i['Size'])\n",
    "        f_i.close()\n",
    "\n",
    "        SLICE_SIZE_X, SLICE_SIZE_Y, SLICE_COUNT = ctarr.shape\n",
    "        images = np.empty([SLICE_SIZE_X, SLICE_SIZE_Y, SLICE_COUNT, 0], dtype=np.single)\n",
    "\n",
    "        image_ct = np.expand_dims(ctarr, axis=3)\n",
    "        images = np.append(images, image_ct, axis=3)\n",
    "        image_pet = np.expand_dims(petarr, axis=3)\n",
    "        images = np.append(images, image_pet, axis=3)\n",
    "\n",
    "\n",
    "        hdf5_file_NAME = hdf5_file\n",
    "\n",
    "        niim = nib.Nifti1Image(images, affine=np.eye(4))\n",
    "        nib.save(niim, os.path.join(save_folder, 'imagesTr/{}.nii.gz'.format(hdf5_file[:17])))\n",
    "\n",
    "        nila = nib.Nifti1Image(labels, affine=np.eye(4))\n",
    "        nib.save(nila, os.path.join(save_folder, 'labelsTr/{}.nii.gz'.format(hdf5_file[:17])))\n",
    "        print(hdf5_file, ' : ', sizearr)\n",
    "\n",
    "\n",
    "    print('\"{}\" Image & Label Completed !!'.format(os.path.basename(os.path.normpath(save_folder))))\n",
    "    print('Image Patient : {}'.format(len(os.listdir(input_dir))))\n",
    "\n",
    "hdf2nifti(input_dir, task_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json created!\n"
     ]
    }
   ],
   "source": [
    "def json_mk(save_dir: str):\n",
    "    # Path\n",
    "    imagesTr = os.path.join(save_dir, 'imagesTr')\n",
    "    imagesTs = os.path.join(save_dir, 'imagesTs')\n",
    "    maybe_mkdir_p(imagesTr)\n",
    "    maybe_mkdir_p(imagesTs)\n",
    "\n",
    "    overwrite_json_file = True\n",
    "    json_file_exist = False\n",
    "\n",
    "    if os.path.exists(os.path.join(save_dir, 'dataset.json')):\n",
    "        print('dataset.json already exist!')\n",
    "        json_file_exist = True\n",
    "\n",
    "    if json_file_exist == False or overwrite_json_file:\n",
    "\n",
    "        json_dict = OrderedDict()\n",
    "        json_dict['name'] = \"PETCT\"\n",
    "        json_dict['description'] = \"Medical Image AI Challenge 2021\"\n",
    "        json_dict['tensorImageSize'] = \"4D\"\n",
    "        json_dict['reference'] = \"https://maic.or.kr/competitions/\"\n",
    "        json_dict['licence'] = \"SNUH\"\n",
    "        json_dict['release'] = \"18/10/2021\"\n",
    "\n",
    "        json_dict['modality'] = {\n",
    "            \"0\": \"CT\",\n",
    "            \"1\": \"PET\"\n",
    "        }\n",
    "        json_dict['labels'] = {\n",
    "            \"0\": \"background\",\n",
    "            \"1\": \"Aorta\"\n",
    "        }\n",
    "\n",
    "        train_ids = sorted(os.listdir(imagesTr))\n",
    "        test_ids = sorted(os.listdir(imagesTs))\n",
    "        json_dict['numTraining'] = len(train_ids)\n",
    "        json_dict['numTest'] = len(test_ids)\n",
    "\n",
    "        json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "        json_dict['test'] = [\"./imagesTs/%s\" % i for i in test_ids] #(i[:i.find(\"_0000\")])\n",
    "\n",
    "        with open(os.path.join(save_dir, \"dataset.json\"), 'w') as f:\n",
    "            json.dump(json_dict, f, indent=4, sort_keys=False)\n",
    "\n",
    "        if os.path.exists(os.path.join(save_dir, 'dataset.json')):\n",
    "            if json_file_exist == False:\n",
    "                print('dataset.json created!')\n",
    "            else:\n",
    "                print('dataset.json overwritten!')\n",
    "json_mk(task_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-2. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imagesTr', 'labelsTr', 'imagesTs', 'dataset.json']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/tf/temp/nnUNet/nnunet/Tasks/Task55_PETCT/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "23090557_20130717\n",
      "23090560_20160114\n",
      "23090563_20151216\n",
      "23090567_20160819\n",
      "23090571_20120517\n",
      "23090579_20141215\n",
      "23090582_20150401\n",
      "23090585_20130213\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090558_20120330\n",
      "23090572_20130226\n",
      "23090561_20120330\n",
      "23090568_20121018\n",
      "23090580_20131226\n",
      "23090583_20160308\n",
      "23090564_20130312\n",
      "23090586_20120627\n",
      "before crop: (2, 263, 128, 128) after crop: (2, 263, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090559_20150812\n",
      "23090562_20140206\n",
      "23090578_20120613\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090566_20141114\n",
      "23090587_20150908\n",
      "23090581_20130626\n",
      "23090569_20120607\n",
      "23090584_20120523\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090588_20131025\n",
      "23090591_20140124\n",
      "23090594_20160706\n",
      "23090597_20130227\n",
      "23090600_20121108\n",
      "23090604_20140303\n",
      "23090608_20120718\n",
      "23090611_20150212\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090592_20130218\n",
      "23090589_20140219\n",
      "23090598_20130103\n",
      "23090595_20121015\n",
      "23090606_20120619\n",
      "23090601_20130225\n",
      "23090609_20120510\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090612_20121213\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090593_20120625\n",
      "23090590_20121212\n",
      "23090607_20120420\n",
      "23090596_20150112\n",
      "23090599_20140701\n",
      "23090603_20141212\n",
      "23090613_20130208\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090610_20151210\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090614_20120402\n",
      "23090617_20140211\n",
      "23090620_20130617\n",
      "23090623_20120406\n",
      "23090627_20160608\n",
      "23090630_20130213\n",
      "23090633_20120403\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090636_20121018\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090625_20160111\n",
      "23090615_20140403\n",
      "23090618_20161212\n",
      "23090621_20130409\n",
      "23090628_20150204\n",
      "23090631_20130128\n",
      "23090634_20150409\n",
      "23090637_20140401\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090622_20150105\n",
      "23090626_20160119\n",
      "23090616_20140331\n",
      "23090619_20121210\n",
      "23090629_20120830\n",
      "23090638_20131126\n",
      "23090635_20140710\n",
      "23090632_20130807\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090639_20150522\n",
      "23090642_20130409\n",
      "23090645_20141212\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090640_20140711\n",
      "23090643_20121227\n",
      "23090646_20120718\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090641_20160510\n",
      "23090644_20131216\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Task556_PETCT\n",
      "number of threads:  (8, 8) \n",
      "\n",
      "not using nonzero mask for normalization\n",
      "Are we using the nonzero mask for normalizaion? OrderedDict([(0, False), (1, False)])\n",
      "the median shape of the dataset is  [299. 128. 128.]\n",
      "the max shape in the dataset is  [335. 128. 128.]\n",
      "the min shape in the dataset is  [263. 128. 128.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [299. 128. 128.]\n",
      "generating configuration for 3d_fullres\n",
      "{0: {'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}}\n",
      "transpose forward [0, 1, 2]\n",
      "transpose backward [0, 1, 2]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /tf/temp/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_cropped_data/Task556_PETCT\n",
      "output_folder: /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1523\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090557_20130717.npz\n",
      "1 1576\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090571_20120517.npz\n",
      "1 2130\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090567_20160819.npz\n",
      "1 3800\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090560_20160114.npz\n",
      "1 2148\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090563_20151216.npz\n",
      "1 3219\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090585_20130213.npz\n",
      "1 2186\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090579_20141215.npz\n",
      "1 2179\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090582_20150401.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 263, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 263, 128, 128)} \n",
      "\n",
      "1 1998\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090558_20120330.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2276\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090572_20130226.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2259\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090561_20120330.npz\n",
      "1 2405\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090568_20121018.npz\n",
      "1 1764\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090564_20130312.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1980\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090586_20120627.npz\n",
      "1 2223\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090583_20160308.npz\n",
      "1 1977\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090580_20131226.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3121\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090559_20150812.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2047\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090562_20140206.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2753\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090578_20120613.npz\n",
      "1 2088\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090566_20141114.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2658\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090587_20150908.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2170\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090569_20120607.npz\n",
      "1 2928\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090584_20120523.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1188\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090581_20130626.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2343\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090588_20131025.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2175\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090591_20140124.npz\n",
      "1 2660\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090597_20130227.npz\n",
      "1 3501\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090594_20160706.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1603\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090604_20140303.npz\n",
      "1 2381\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090600_20121108.npz\n",
      "1 2943\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090608_20120718.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2569\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090611_20150212.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2579\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090589_20140219.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2846\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090592_20130218.npz\n",
      "1 1630\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090598_20130103.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1422\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090595_20121015.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2286\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090606_20120619.npz\n",
      "1 1385\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090601_20130225.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1909\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090609_20120510.npz\n",
      "1 1721\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090612_20121213.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1803\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090599_20140701.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 3163\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090590_20121212.npz\n",
      "1 2888\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090593_20120625.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2867\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090596_20150112.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1770\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090607_20120420.npz\n",
      "1 2984\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090603_20141212.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1447\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090613_20130208.npz\n",
      "1 3219\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090610_20151210.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3220\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090614_20120402.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2589\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090617_20140211.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2773\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090623_20120406.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1998\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090620_20130617.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2354\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090627_20160608.npz\n",
      "1 1982\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090630_20130213.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2765\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090633_20120403.npz\n",
      "1 1903\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090636_20121018.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3091\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090615_20140403.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1863\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090625_20160111.npz\n",
      "1 2934\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090618_20161212.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 3187\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090621_20130409.npz\n",
      "1 2933\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090628_20150204.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2146\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090631_20130128.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1531\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090637_20140401.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1586\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090634_20150409.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 3021\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090616_20140331.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1799\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090622_20150105.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3654\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090626_20160119.npz\n",
      "1 1009\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090619_20121210.npz\n",
      "1 2314\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090629_20120830.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2730\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090638_20131126.npz\n",
      "1 1693\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090632_20130807.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2319\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090635_20140710.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1259\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090642_20130409.npz\n",
      "1 2119\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090639_20150522.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1918\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090645_20141212.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 4845\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090643_20121227.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2258\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090646_20120718.npz\n",
      "1 1909\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090640_20140711.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1377\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090641_20160510.npz\n",
      "1 1635\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_stage0/23090644_20131216.npz\n",
      "not using nonzero mask for normalization\n",
      "Are we using the nonzero maks for normalizaion? OrderedDict([(0, False), (1, False)])\n",
      "the median shape of the dataset is  [299. 128. 128.]\n",
      "the max shape in the dataset is  [335. 128. 128.]\n",
      "the min shape in the dataset is  [263. 128. 128.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [299. 128. 128.]\n",
      "[{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /tf/temp/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_cropped_data/Task556_PETCT\n",
      "output_folder: /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "normalization...\n",
      "normalization...\n",
      "normalization...\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "1 1576\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090571_20120517.npz\n",
      "1 1523\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090557_20130717.npz\n",
      "1 3800\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090560_20160114.npz\n",
      "1 2179\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090582_20150401.npz\n",
      "1 2186\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090579_20141215.npz\n",
      "1 2130\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090567_20160819.npz\n",
      "1 3219\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090585_20130213.npz\n",
      "1 2148\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090563_20151216.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 263, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 263, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 1998\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090558_20120330.npz\n",
      "1 2276\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090572_20130226.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 2223\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090583_20160308.npz\n",
      "normalization done\n",
      "normalization done\n",
      "1 1980\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090586_20120627.npz\n",
      "1 2259\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090561_20120330.npz\n",
      "normalization done\n",
      "1 2405\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090568_20121018.npz\n",
      "1 1764\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090564_20130312.npz\n",
      "1 1977\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090580_20131226.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 3121\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090559_20150812.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 2753\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090578_20120613.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2047\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090562_20140206.npz\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 2658\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090587_20150908.npz\n",
      "normalization done\n",
      "1 2928\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090584_20120523.npz\n",
      "normalization done\n",
      "1 2088\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090566_20141114.npz\n",
      "normalization done\n",
      "1 2170\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090569_20120607.npz\n",
      "1 1188\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090581_20130626.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 2175\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090591_20140124.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 2343\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090588_20131025.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 3501\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090594_20160706.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 2660\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090597_20130227.npz\n",
      "normalization done\n",
      "normalization done\n",
      "1 1603\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090604_20140303.npz\n",
      "normalization done\n",
      "normalization done\n",
      "1 2381\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090600_20121108.npz\n",
      "1 2943\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090608_20120718.npz\n",
      "1 2569\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090611_20150212.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2846\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090592_20130218.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1630\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090598_20130103.npz\n",
      "1 2286\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090606_20120619.npz\n",
      "normalization done\n",
      "normalization done\n",
      "1 2579\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090589_20140219.npz\n",
      "1 1422\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090595_20121015.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "1 1721\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090612_20121213.npz\n",
      "1 1385\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090601_20130225.npz\n",
      "1 1909\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090609_20120510.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 2888\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090593_20120625.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 1803\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090599_20140701.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 1770\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090607_20120420.npz\n",
      "1 2867\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090596_20150112.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 1447\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090613_20130208.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization done\n",
      "normalization...\n",
      "1 2984\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090603_20141212.npz\n",
      "1 3163\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090590_20121212.npz\n",
      "normalization done\n",
      "1 3219\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090610_20151210.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 3220\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090614_20120402.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization...\n",
      "1 2589\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090617_20140211.npz\n",
      "normalization done\n",
      "normalization done\n",
      "1 2773\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090623_20120406.npz\n",
      "1 1998\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090620_20130617.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 2354\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090627_20160608.npz\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 1982\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090630_20130213.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 1903\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090636_20121018.npz\n",
      "1 2765\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090633_20120403.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 3091\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090615_20140403.npz\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1863\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090625_20160111.npz\n",
      "1 2934\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090618_20161212.npz\n",
      "normalization done\n",
      "1 3187\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090621_20130409.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 2933\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090628_20150204.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "normalization done\n",
      "\n",
      "normalization...\n",
      "1 1531\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090637_20140401.npz\n",
      "normalization done\n",
      "normalization done\n",
      "1 1586\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090634_20150409.npz\n",
      "1 2146\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090631_20130128.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 3021\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090616_20140331.npz\n",
      "normalization done\n",
      "1 1799\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090622_20150105.npz\n",
      "normalization done\n",
      "1 3654\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090626_20160119.npz\n",
      "1 1009\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090619_20121210.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 2314\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090629_20120830.npz\n",
      "normalization done\n",
      "normalization done\n",
      "1 2319\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090635_20140710.npz\n",
      "1 2730\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090638_20131126.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1693\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090632_20130807.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 2119\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090639_20150522.npz\n",
      "1 1259\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090642_20130409.npz\n",
      "normalization done\n",
      "1 1918\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090645_20141212.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 4845\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090643_20121227.npz\n",
      "1 2258\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090646_20120718.npz\n",
      "normalization done\n",
      "1 1909\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090640_20140711.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1377\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090641_20160510.npz\n",
      "normalization done\n",
      "1 1635\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task556_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090644_20131216.npz\n"
     ]
    }
   ],
   "source": [
    "# os.chdir(mainT_dir)\n",
    "!nnUNet_convert_decathlon_task -i /tf/temp/nnUNet/nnunet/Tasks/Task55_PETCT -output_task_id 556 # -i : task_dir\n",
    "!nnUNet_plan_and_preprocess -t 556 # --verify_dataset_integrity\n",
    "# os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "23090557_20130717\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090558_20120330\n",
      "before crop: (2, 263, 128, 128) after crop: (2, 263, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090559_20150812\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090560_20160114\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090561_20120330\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090562_20140206\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090563_20151216\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090564_20130312\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090566_20141114\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090567_20160819\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090568_20121018\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090569_20120607\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090571_20120517\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090572_20130226\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090578_20120613\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090579_20141215\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090580_20131226\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090581_20130626\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090582_20150401\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090583_20160308\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090584_20120523\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090585_20130213\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090586_20120627\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090587_20150908\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090588_20131025\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090589_20140219\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090590_20121212\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090591_20140124\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090592_20130218\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090593_20120625\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090594_20160706\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090595_20121015\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090596_20150112\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090597_20130227\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090598_20130103\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090599_20140701\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090600_20121108\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090601_20130225\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090603_20141212\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090604_20140303\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090606_20120619\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090607_20120420\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090608_20120718\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090609_20120510\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090610_20151210\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090611_20150212\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090612_20121213\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090613_20130208\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090614_20120402\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090615_20140403\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090616_20140331\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090617_20140211\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090618_20161212\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090619_20121210\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090620_20130617\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090621_20130409\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090622_20150105\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090623_20120406\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090625_20160111\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090626_20160119\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090627_20160608\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090628_20150204\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090629_20120830\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090630_20130213\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090631_20130128\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090632_20130807\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090633_20120403\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090634_20150409\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090635_20140710\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090636_20121018\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090637_20140401\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090638_20131126\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090639_20150522\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090640_20140711\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090641_20160510\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090642_20130409\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090643_20121227\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090644_20131216\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090645_20141212\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090646_20120718\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Task557_PETCT\n",
      "number of threads:  (1, 1) \n",
      "\n",
      "not using nonzero mask for normalization\n",
      "Are we using the nonzero mask for normalizaion? OrderedDict([(0, False), (1, False)])\n",
      "the median shape of the dataset is  [299. 128. 128.]\n",
      "the max shape in the dataset is  [335. 128. 128.]\n",
      "the min shape in the dataset is  [263. 128. 128.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [299. 128. 128.]\n",
      "generating configuration for 3d_fullres\n",
      "{0: {'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}}\n",
      "transpose forward [0, 1, 2]\n",
      "transpose backward [0, 1, 2]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /tf/temp/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_cropped_data/Task557_PETCT\n",
      "output_folder: /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1523\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090557_20130717.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 263, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 263, 128, 128)} \n",
      "\n",
      "1 1998\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090558_20120330.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3121\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090559_20150812.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3800\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090560_20160114.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2259\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090561_20120330.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2047\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090562_20140206.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2148\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090563_20151216.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1764\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090564_20130312.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2088\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090566_20141114.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2130\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090567_20160819.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2405\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090568_20121018.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2170\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090569_20120607.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1576\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090571_20120517.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2276\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090572_20130226.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2753\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090578_20120613.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2186\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090579_20141215.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1977\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090580_20131226.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1188\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090581_20130626.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2179\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090582_20150401.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2223\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090583_20160308.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2928\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090584_20120523.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3219\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090585_20130213.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1980\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090586_20120627.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2658\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090587_20150908.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2343\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090588_20131025.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2579\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090589_20140219.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3163\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090590_20121212.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2175\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090591_20140124.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2846\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090592_20130218.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2888\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090593_20120625.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3501\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090594_20160706.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1422\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090595_20121015.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2867\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090596_20150112.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2660\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090597_20130227.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1630\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090598_20130103.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1803\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090599_20140701.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2381\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090600_20121108.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1385\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090601_20130225.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2984\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090603_20141212.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1603\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090604_20140303.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2286\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090606_20120619.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1770\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090607_20120420.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2943\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090608_20120718.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1909\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090609_20120510.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3219\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090610_20151210.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2569\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090611_20150212.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1721\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090612_20121213.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1447\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090613_20130208.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3220\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090614_20120402.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3091\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090615_20140403.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3021\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090616_20140331.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2589\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090617_20140211.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2934\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090618_20161212.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1009\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090619_20121210.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1998\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090620_20130617.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 3187\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090621_20130409.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1799\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090622_20150105.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2773\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090623_20120406.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1863\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090625_20160111.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3654\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090626_20160119.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2354\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090627_20160608.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2933\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090628_20150204.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2314\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090629_20120830.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1982\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090630_20130213.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2146\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090631_20130128.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1693\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090632_20130807.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2765\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090633_20120403.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1586\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090634_20150409.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2319\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090635_20140710.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1903\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090636_20121018.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1531\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090637_20140401.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2730\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090638_20131126.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2119\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090639_20150522.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1909\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090640_20140711.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1377\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090641_20160510.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1259\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090642_20130409.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 4845\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090643_20121227.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1635\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090644_20131216.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1918\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090645_20141212.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2258\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_stage0/23090646_20120718.npz\n",
      "not using nonzero mask for normalization\n",
      "Are we using the nonzero maks for normalizaion? OrderedDict([(0, False), (1, False)])\n",
      "the median shape of the dataset is  [299. 128. 128.]\n",
      "the max shape in the dataset is  [335. 128. 128.]\n",
      "the min shape in the dataset is  [263. 128. 128.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [299. 128. 128.]\n",
      "[{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /tf/temp/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_cropped_data/Task557_PETCT\n",
      "output_folder: /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1523\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090557_20130717.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 263, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 263, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1998\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090558_20120330.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 3121\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090559_20150812.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 3800\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090560_20160114.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2259\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090561_20120330.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2047\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090562_20140206.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2148\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090563_20151216.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1764\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090564_20130312.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2088\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090566_20141114.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2130\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090567_20160819.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2405\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090568_20121018.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2170\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090569_20120607.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1576\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090571_20120517.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2276\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090572_20130226.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2753\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090578_20120613.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2186\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090579_20141215.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1977\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090580_20131226.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1188\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090581_20130626.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2179\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090582_20150401.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2223\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090583_20160308.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2928\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090584_20120523.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 3219\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090585_20130213.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1980\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090586_20120627.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2658\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090587_20150908.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2343\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090588_20131025.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2579\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090589_20140219.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 3163\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090590_20121212.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2175\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090591_20140124.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2846\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090592_20130218.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2888\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090593_20120625.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 3501\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090594_20160706.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1422\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090595_20121015.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2867\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090596_20150112.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2660\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090597_20130227.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1630\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090598_20130103.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1803\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090599_20140701.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2381\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090600_20121108.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1385\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090601_20130225.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2984\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090603_20141212.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1603\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090604_20140303.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2286\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090606_20120619.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1770\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090607_20120420.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2943\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090608_20120718.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1909\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090609_20120510.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 3219\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090610_20151210.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2569\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090611_20150212.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1721\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090612_20121213.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1447\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090613_20130208.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 3220\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090614_20120402.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 3091\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090615_20140403.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 3021\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090616_20140331.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2589\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090617_20140211.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2934\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090618_20161212.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1009\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090619_20121210.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1998\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090620_20130617.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 3187\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090621_20130409.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1799\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090622_20150105.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2773\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090623_20120406.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1863\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090625_20160111.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 3654\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090626_20160119.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2354\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090627_20160608.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2933\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090628_20150204.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2314\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090629_20120830.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1982\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090630_20130213.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2146\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090631_20130128.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1693\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090632_20130807.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2765\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090633_20120403.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1586\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090634_20150409.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2319\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090635_20140710.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1903\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090636_20121018.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1531\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090637_20140401.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2730\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090638_20131126.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2119\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090639_20150522.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1909\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090640_20140711.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1377\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090641_20160510.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1259\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090642_20130409.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 4845\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090643_20121227.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1635\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090644_20131216.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1918\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090645_20141212.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2258\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task557_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090646_20120718.npz\n"
     ]
    }
   ],
   "source": [
    "# 556 -tf 4\n",
    "!nnUNet_convert_decathlon_task -i /tf/temp/nnUNet/nnunet/Tasks/Task55_PETCT -output_task_id 557 # -i : task_dir\n",
    "!nnUNet_plan_and_preprocess -t 557 -tf 1 -tl 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-27 16:15:17.554927: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-27 16:15:46.888453: Unable to plot network architecture:\n",
      "2021-10-27 16:15:46.996411: No module named 'hiddenlayer'\n",
      "2021-10-27 16:15:47.096315: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-27 16:15:47.180416: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-27 16:15:47.433523: \n",
      "\n",
      "2021-10-27 16:15:47.500475: \n",
      "epoch:  0\n",
      "2021-10-27 16:18:59.718543: train loss : -0.2210\n",
      "2021-10-27 16:19:13.865317: validation loss: -0.6623\n",
      "2021-10-27 16:19:13.869488: Average global foreground Dice: [0.6989]\n",
      "2021-10-27 16:19:13.875212: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:19:14.290968: lr: 0.00991\n",
      "2021-10-27 16:19:14.324789: This epoch took 206.756409 s\n",
      "\n",
      "2021-10-27 16:19:14.331478: \n",
      "epoch:  1\n",
      "2021-10-27 16:22:26.081245: train loss : -0.6986\n",
      "2021-10-27 16:22:40.195020: validation loss: -0.7923\n",
      "2021-10-27 16:22:40.199469: Average global foreground Dice: [0.8137]\n",
      "2021-10-27 16:22:40.206626: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:22:40.716233: lr: 0.00982\n",
      "2021-10-27 16:22:40.813947: saving checkpoint...\n",
      "2021-10-27 16:22:41.789972: done, saving took 1.04 seconds\n",
      "2021-10-27 16:22:42.018425: This epoch took 207.678639 s\n",
      "\n",
      "2021-10-27 16:22:42.040115: \n",
      "epoch:  2\n",
      "2021-10-27 16:25:49.402736: train loss : -0.7691\n",
      "2021-10-27 16:26:03.426464: validation loss: -0.8225\n",
      "2021-10-27 16:26:03.430629: Average global foreground Dice: [0.8376]\n",
      "2021-10-27 16:26:03.437733: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:26:03.993473: lr: 0.00973\n",
      "2021-10-27 16:26:04.050973: saving checkpoint...\n",
      "2021-10-27 16:26:05.266915: done, saving took 1.24 seconds\n",
      "2021-10-27 16:26:05.667787: This epoch took 203.621566 s\n",
      "\n",
      "2021-10-27 16:26:05.686312: \n",
      "epoch:  3\n",
      "2021-10-27 16:29:17.119637: train loss : -0.7936\n",
      "2021-10-27 16:29:31.347813: validation loss: -0.8237\n",
      "2021-10-27 16:29:31.352603: Average global foreground Dice: [0.8371]\n",
      "2021-10-27 16:29:31.358892: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:29:31.914852: lr: 0.009639\n",
      "2021-10-27 16:29:31.952582: saving checkpoint...\n",
      "2021-10-27 16:29:33.100416: done, saving took 1.17 seconds\n",
      "2021-10-27 16:29:33.536399: This epoch took 207.844127 s\n",
      "\n",
      "2021-10-27 16:29:33.545092: \n",
      "epoch:  4\n",
      "2021-10-27 16:32:40.637586: train loss : -0.8058\n",
      "2021-10-27 16:32:54.676850: validation loss: -0.8346\n",
      "2021-10-27 16:32:54.681857: Average global foreground Dice: [0.8465]\n",
      "2021-10-27 16:32:54.689617: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:32:55.202167: lr: 0.009549\n",
      "2021-10-27 16:32:55.268535: saving checkpoint...\n",
      "2021-10-27 16:32:56.365358: done, saving took 1.13 seconds\n",
      "2021-10-27 16:32:56.859082: This epoch took 203.307810 s\n",
      "\n",
      "2021-10-27 16:32:56.873139: \n",
      "epoch:  5\n",
      "2021-10-27 16:36:07.219622: train loss : -0.8164\n",
      "2021-10-27 16:36:21.428898: validation loss: -0.8439\n",
      "2021-10-27 16:36:21.432943: Average global foreground Dice: [0.8531]\n",
      "2021-10-27 16:36:21.439554: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:36:21.945920: lr: 0.009458\n",
      "2021-10-27 16:36:22.013656: saving checkpoint...\n",
      "2021-10-27 16:36:23.335724: done, saving took 1.36 seconds\n",
      "2021-10-27 16:36:23.600338: This epoch took 206.720120 s\n",
      "\n",
      "2021-10-27 16:36:23.619381: \n",
      "epoch:  6\n",
      "2021-10-27 16:39:33.962859: train loss : -0.8223\n",
      "2021-10-27 16:39:48.168229: validation loss: -0.8499\n",
      "2021-10-27 16:39:48.172292: Average global foreground Dice: [0.8601]\n",
      "2021-10-27 16:39:48.179092: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:39:48.670321: lr: 0.009368\n",
      "2021-10-27 16:39:48.717124: saving checkpoint...\n",
      "2021-10-27 16:39:49.922694: done, saving took 1.22 seconds\n",
      "2021-10-27 16:39:50.259526: This epoch took 206.633933 s\n",
      "\n",
      "2021-10-27 16:39:50.281845: \n",
      "epoch:  7\n",
      "2021-10-27 16:43:00.683633: train loss : -0.8278\n",
      "2021-10-27 16:43:14.904088: validation loss: -0.8525\n",
      "2021-10-27 16:43:14.908590: Average global foreground Dice: [0.8616]\n",
      "2021-10-27 16:43:14.914384: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:43:15.466205: lr: 0.009277\n",
      "2021-10-27 16:43:15.516546: saving checkpoint...\n",
      "2021-10-27 16:43:16.601164: done, saving took 1.10 seconds\n",
      "2021-10-27 16:43:17.324125: This epoch took 207.035653 s\n",
      "\n",
      "2021-10-27 16:43:17.341800: \n",
      "epoch:  8\n",
      "2021-10-27 16:46:29.139361: train loss : -0.8330\n",
      "2021-10-27 16:46:43.344243: validation loss: -0.8549\n",
      "2021-10-27 16:46:43.348664: Average global foreground Dice: [0.8632]\n",
      "2021-10-27 16:46:43.356322: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:46:43.890189: lr: 0.009186\n",
      "2021-10-27 16:46:43.958172: saving checkpoint...\n",
      "2021-10-27 16:46:45.078849: done, saving took 1.16 seconds\n",
      "2021-10-27 16:46:45.430456: This epoch took 208.082009 s\n",
      "\n",
      "2021-10-27 16:46:45.450783: \n",
      "epoch:  9\n",
      "2021-10-27 16:49:56.594596: train loss : -0.8338\n",
      "2021-10-27 16:50:10.816225: validation loss: -0.8592\n",
      "2021-10-27 16:50:10.820862: Average global foreground Dice: [0.8679]\n",
      "2021-10-27 16:50:10.827181: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:50:11.329562: lr: 0.009095\n",
      "2021-10-27 16:50:11.388503: saving checkpoint...\n",
      "2021-10-27 16:50:12.543743: done, saving took 1.18 seconds\n",
      "2021-10-27 16:50:12.991771: This epoch took 207.534300 s\n",
      "\n",
      "2021-10-27 16:50:13.011533: \n",
      "epoch:  10\n",
      "2021-10-27 16:53:24.052798: train loss : -0.8393\n",
      "2021-10-27 16:53:38.278238: validation loss: -0.8622\n",
      "2021-10-27 16:53:38.282418: Average global foreground Dice: [0.8702]\n",
      "2021-10-27 16:53:38.289221: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:53:38.861925: lr: 0.009004\n",
      "2021-10-27 16:53:38.914918: saving checkpoint...\n",
      "2021-10-27 16:53:40.158682: done, saving took 1.27 seconds\n",
      "2021-10-27 16:53:40.529228: This epoch took 207.510832 s\n",
      "\n",
      "2021-10-27 16:53:40.549043: \n",
      "epoch:  11\n",
      "2021-10-27 16:56:51.992955: train loss : -0.8421\n",
      "2021-10-27 16:57:06.237341: validation loss: -0.8658\n",
      "2021-10-27 16:57:06.241754: Average global foreground Dice: [0.8725]\n",
      "2021-10-27 16:57:06.248301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:57:06.745189: lr: 0.008913\n",
      "2021-10-27 16:57:06.802613: saving checkpoint...\n",
      "2021-10-27 16:57:07.909294: done, saving took 1.13 seconds\n",
      "2021-10-27 16:57:08.315907: This epoch took 207.760675 s\n",
      "\n",
      "2021-10-27 16:57:08.334923: \n",
      "epoch:  12\n",
      "2021-10-27 17:00:19.878735: train loss : -0.8436\n",
      "2021-10-27 17:00:34.112004: validation loss: -0.8659\n",
      "2021-10-27 17:00:34.116223: Average global foreground Dice: [0.873]\n",
      "2021-10-27 17:00:34.122811: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:00:34.745908: lr: 0.008822\n",
      "2021-10-27 17:00:34.800883: saving checkpoint...\n",
      "2021-10-27 17:00:35.876860: done, saving took 1.10 seconds\n",
      "2021-10-27 17:00:36.182032: This epoch took 207.840477 s\n",
      "\n",
      "2021-10-27 17:00:36.199789: \n",
      "epoch:  13\n",
      "2021-10-27 17:03:47.900950: train loss : -0.8470\n",
      "2021-10-27 17:04:02.136399: validation loss: -0.8681\n",
      "2021-10-27 17:04:02.140368: Average global foreground Dice: [0.8749]\n",
      "2021-10-27 17:04:02.146461: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:04:02.642723: lr: 0.008731\n",
      "2021-10-27 17:04:02.692363: saving checkpoint...\n",
      "2021-10-27 17:04:03.799992: done, saving took 1.13 seconds\n",
      "2021-10-27 17:04:04.042984: This epoch took 207.836482 s\n",
      "\n",
      "2021-10-27 17:04:04.061878: \n",
      "epoch:  14\n",
      "2021-10-27 17:07:15.883038: train loss : -0.8489\n",
      "2021-10-27 17:07:30.092684: validation loss: -0.8702\n",
      "2021-10-27 17:07:30.096931: Average global foreground Dice: [0.876]\n",
      "2021-10-27 17:07:30.103577: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:07:30.620436: lr: 0.008639\n",
      "2021-10-27 17:07:30.670778: saving checkpoint...\n",
      "2021-10-27 17:07:31.744756: done, saving took 1.09 seconds\n",
      "2021-10-27 17:07:32.188677: This epoch took 208.118920 s\n",
      "\n",
      "2021-10-27 17:07:32.206728: \n",
      "epoch:  15\n",
      "2021-10-27 17:10:43.528100: train loss : -0.8501\n",
      "2021-10-27 17:10:57.746241: validation loss: -0.8714\n",
      "2021-10-27 17:10:57.750674: Average global foreground Dice: [0.8778]\n",
      "2021-10-27 17:10:57.757516: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:10:58.267996: lr: 0.008548\n",
      "2021-10-27 17:10:58.320610: saving checkpoint...\n",
      "2021-10-27 17:10:59.454544: done, saving took 1.16 seconds\n",
      "2021-10-27 17:10:59.751400: This epoch took 207.538210 s\n",
      "\n",
      "2021-10-27 17:10:59.771410: \n",
      "epoch:  16\n",
      "2021-10-27 17:14:12.248561: train loss : -0.8525\n",
      "2021-10-27 17:14:26.456915: validation loss: -0.8768\n",
      "2021-10-27 17:14:26.461422: Average global foreground Dice: [0.8837]\n",
      "2021-10-27 17:14:26.467772: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:14:26.974939: lr: 0.008456\n",
      "2021-10-27 17:14:27.030425: saving checkpoint...\n",
      "2021-10-27 17:14:28.122860: done, saving took 1.11 seconds\n",
      "2021-10-27 17:14:28.513036: This epoch took 208.735487 s\n",
      "\n",
      "2021-10-27 17:14:28.531475: \n",
      "epoch:  17\n",
      "2021-10-27 17:17:41.022295: train loss : -0.8538\n",
      "2021-10-27 17:17:55.225448: validation loss: -0.8756\n",
      "2021-10-27 17:17:55.229394: Average global foreground Dice: [0.8796]\n",
      "2021-10-27 17:17:55.235512: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:17:55.751291: lr: 0.008364\n",
      "2021-10-27 17:17:55.788638: saving checkpoint...\n",
      "2021-10-27 17:17:56.872582: done, saving took 1.10 seconds\n",
      "2021-10-27 17:17:57.135095: This epoch took 208.596153 s\n",
      "\n",
      "2021-10-27 17:17:57.143217: \n",
      "epoch:  18\n",
      "2021-10-27 17:21:09.620421: train loss : -0.8564\n",
      "2021-10-27 17:21:23.855744: validation loss: -0.8798\n",
      "2021-10-27 17:21:23.860033: Average global foreground Dice: [0.886]\n",
      "2021-10-27 17:21:23.866910: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:21:24.378822: lr: 0.008272\n",
      "2021-10-27 17:21:24.416566: saving checkpoint...\n",
      "2021-10-27 17:21:25.514822: done, saving took 1.12 seconds\n",
      "2021-10-27 17:21:26.108468: This epoch took 208.957060 s\n",
      "\n",
      "2021-10-27 17:21:26.116536: \n",
      "epoch:  19\n",
      "2021-10-27 17:24:38.613017: train loss : -0.8581\n",
      "2021-10-27 17:24:52.819587: validation loss: -0.8806\n",
      "2021-10-27 17:24:52.824164: Average global foreground Dice: [0.8861]\n",
      "2021-10-27 17:24:52.831293: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:24:53.333785: lr: 0.008181\n",
      "2021-10-27 17:24:53.374055: saving checkpoint...\n",
      "2021-10-27 17:24:54.463508: done, saving took 1.11 seconds\n",
      "2021-10-27 17:24:54.913401: This epoch took 208.791076 s\n",
      "\n",
      "2021-10-27 17:24:54.923956: \n",
      "epoch:  20\n",
      "2021-10-27 17:28:07.361281: train loss : -0.8594\n",
      "2021-10-27 17:28:21.570464: validation loss: -0.8845\n",
      "2021-10-27 17:28:21.574740: Average global foreground Dice: [0.8893]\n",
      "2021-10-27 17:28:21.582563: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:28:22.124996: lr: 0.008088\n",
      "2021-10-27 17:28:22.162406: saving checkpoint...\n",
      "2021-10-27 17:28:23.244981: done, saving took 1.10 seconds\n",
      "2021-10-27 17:28:23.610828: This epoch took 208.679771 s\n",
      "\n",
      "2021-10-27 17:28:23.618555: \n",
      "epoch:  21\n",
      "2021-10-27 17:31:36.052924: train loss : -0.8613\n",
      "2021-10-27 17:31:50.264493: validation loss: -0.8844\n",
      "2021-10-27 17:31:50.268931: Average global foreground Dice: [0.8881]\n",
      "2021-10-27 17:31:50.275697: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:31:50.883229: lr: 0.007996\n",
      "2021-10-27 17:31:50.921509: saving checkpoint...\n",
      "2021-10-27 17:31:52.003817: done, saving took 1.10 seconds\n",
      "2021-10-27 17:31:52.359109: This epoch took 208.733335 s\n",
      "\n",
      "2021-10-27 17:31:52.367161: \n",
      "epoch:  22\n",
      "2021-10-27 17:35:04.841682: train loss : -0.8618\n",
      "2021-10-27 17:35:19.053703: validation loss: -0.8864\n",
      "2021-10-27 17:35:19.057836: Average global foreground Dice: [0.8905]\n",
      "2021-10-27 17:35:19.063690: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:35:19.579424: lr: 0.007904\n",
      "2021-10-27 17:35:19.620622: saving checkpoint...\n",
      "2021-10-27 17:35:20.759770: done, saving took 1.16 seconds\n",
      "2021-10-27 17:35:21.295731: This epoch took 208.921829 s\n",
      "\n",
      "2021-10-27 17:35:21.304954: \n",
      "epoch:  23\n",
      "2021-10-27 17:38:33.417630: train loss : -0.8627\n",
      "2021-10-27 17:38:47.645205: validation loss: -0.8861\n",
      "2021-10-27 17:38:47.649923: Average global foreground Dice: [0.8907]\n",
      "2021-10-27 17:38:47.656332: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:38:48.159803: lr: 0.007811\n",
      "2021-10-27 17:38:48.196627: saving checkpoint...\n",
      "2021-10-27 17:38:49.289126: done, saving took 1.11 seconds\n",
      "2021-10-27 17:38:49.585298: This epoch took 208.273760 s\n",
      "\n",
      "2021-10-27 17:38:49.593639: \n",
      "epoch:  24\n",
      "2021-10-27 17:42:02.324453: train loss : -0.8633\n",
      "2021-10-27 17:42:16.552246: validation loss: -0.8878\n",
      "2021-10-27 17:42:16.556428: Average global foreground Dice: [0.8919]\n",
      "2021-10-27 17:42:16.563163: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:42:17.062274: lr: 0.007719\n",
      "2021-10-27 17:42:17.111444: saving checkpoint...\n",
      "2021-10-27 17:42:18.252469: done, saving took 1.17 seconds\n",
      "2021-10-27 17:42:18.549101: This epoch took 208.947923 s\n",
      "\n",
      "2021-10-27 17:42:18.558415: \n",
      "epoch:  25\n",
      "2021-10-27 17:45:31.293353: train loss : -0.8646\n",
      "2021-10-27 17:45:45.536252: validation loss: -0.8894\n",
      "2021-10-27 17:45:45.540864: Average global foreground Dice: [0.8924]\n",
      "2021-10-27 17:45:45.548082: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:45:46.073924: lr: 0.007626\n",
      "2021-10-27 17:45:46.112747: saving checkpoint...\n",
      "2021-10-27 17:45:47.201913: done, saving took 1.11 seconds\n",
      "2021-10-27 17:45:47.711458: This epoch took 209.145721 s\n",
      "\n",
      "2021-10-27 17:45:47.719983: \n",
      "epoch:  26\n",
      "2021-10-27 17:49:00.506113: train loss : -0.8654\n",
      "2021-10-27 17:49:14.730387: validation loss: -0.8881\n",
      "2021-10-27 17:49:14.734563: Average global foreground Dice: [0.892]\n",
      "2021-10-27 17:49:14.741678: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:49:15.296919: lr: 0.007533\n",
      "2021-10-27 17:49:15.333424: saving checkpoint...\n",
      "2021-10-27 17:49:16.457399: done, saving took 1.14 seconds\n",
      "2021-10-27 17:49:16.898577: This epoch took 209.171539 s\n",
      "\n",
      "2021-10-27 17:49:16.906759: \n",
      "epoch:  27\n",
      "2021-10-27 17:52:29.759110: train loss : -0.8672\n",
      "2021-10-27 17:52:43.966842: validation loss: -0.8923\n",
      "2021-10-27 17:52:43.971301: Average global foreground Dice: [0.8957]\n",
      "2021-10-27 17:52:43.977158: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:52:44.514082: lr: 0.00744\n",
      "2021-10-27 17:52:44.552968: saving checkpoint...\n",
      "2021-10-27 17:52:45.732203: done, saving took 1.20 seconds\n",
      "2021-10-27 17:52:46.166207: This epoch took 209.253330 s\n",
      "\n",
      "2021-10-27 17:52:46.174451: \n",
      "epoch:  28\n",
      "2021-10-27 17:55:59.100895: train loss : -0.8689\n",
      "2021-10-27 17:56:13.309849: validation loss: -0.8934\n",
      "2021-10-27 17:56:13.314962: Average global foreground Dice: [0.8964]\n",
      "2021-10-27 17:56:13.321711: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:56:13.816742: lr: 0.007347\n",
      "2021-10-27 17:56:13.855166: saving checkpoint...\n",
      "2021-10-27 17:56:14.939538: done, saving took 1.10 seconds\n",
      "2021-10-27 17:56:15.494885: This epoch took 209.313562 s\n",
      "\n",
      "2021-10-27 17:56:15.503253: \n",
      "epoch:  29\n",
      "2021-10-27 17:59:28.381236: train loss : -0.8701\n",
      "2021-10-27 17:59:42.599836: validation loss: -0.8949\n",
      "2021-10-27 17:59:42.604089: Average global foreground Dice: [0.8985]\n",
      "2021-10-27 17:59:42.613005: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:59:43.160082: lr: 0.007254\n",
      "2021-10-27 17:59:43.197030: saving checkpoint...\n",
      "2021-10-27 17:59:44.285800: done, saving took 1.11 seconds\n",
      "2021-10-27 17:59:44.504813: This epoch took 208.991896 s\n",
      "\n",
      "2021-10-27 17:59:44.513197: \n",
      "epoch:  30\n",
      "2021-10-27 18:02:57.393340: train loss : -0.8701\n",
      "2021-10-27 18:03:11.602970: validation loss: -0.8945\n",
      "2021-10-27 18:03:11.607172: Average global foreground Dice: [0.8979]\n",
      "2021-10-27 18:03:11.613240: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:03:12.181896: lr: 0.007161\n",
      "2021-10-27 18:03:12.220428: saving checkpoint...\n",
      "2021-10-27 18:03:13.383526: done, saving took 1.18 seconds\n",
      "2021-10-27 18:03:13.879991: This epoch took 209.360189 s\n",
      "\n",
      "2021-10-27 18:03:13.888570: \n",
      "epoch:  31\n",
      "2021-10-27 18:06:26.627889: train loss : -0.8706\n",
      "2021-10-27 18:06:40.843950: validation loss: -0.8942\n",
      "2021-10-27 18:06:40.848250: Average global foreground Dice: [0.8971]\n",
      "2021-10-27 18:06:40.855362: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:06:41.351729: lr: 0.007067\n",
      "2021-10-27 18:06:41.392221: saving checkpoint...\n",
      "2021-10-27 18:06:42.476691: done, saving took 1.10 seconds\n",
      "2021-10-27 18:06:42.946102: This epoch took 209.050401 s\n",
      "\n",
      "2021-10-27 18:06:42.953912: \n",
      "epoch:  32\n",
      "2021-10-27 18:09:55.916393: train loss : -0.8729\n",
      "2021-10-27 18:10:10.132735: validation loss: -0.9004\n",
      "2021-10-27 18:10:10.136760: Average global foreground Dice: [0.9026]\n",
      "2021-10-27 18:10:10.143046: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:10:10.661268: lr: 0.006974\n",
      "2021-10-27 18:10:10.710543: saving checkpoint...\n",
      "2021-10-27 18:10:11.770903: done, saving took 1.08 seconds\n",
      "2021-10-27 18:10:12.288792: This epoch took 209.321669 s\n",
      "\n",
      "2021-10-27 18:10:12.306394: \n",
      "epoch:  33\n",
      "2021-10-27 18:13:25.415457: train loss : -0.8752\n",
      "2021-10-27 18:13:39.631616: validation loss: -0.8955\n",
      "2021-10-27 18:13:39.635985: Average global foreground Dice: [0.8974]\n",
      "2021-10-27 18:13:39.643288: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:13:40.224740: lr: 0.00688\n",
      "2021-10-27 18:13:40.271913: saving checkpoint...\n",
      "2021-10-27 18:13:41.453340: done, saving took 1.20 seconds\n",
      "2021-10-27 18:13:42.022172: This epoch took 209.708516 s\n",
      "\n",
      "2021-10-27 18:13:42.041297: \n",
      "epoch:  34\n",
      "2021-10-27 18:16:55.281148: train loss : -0.8749\n",
      "2021-10-27 18:17:09.510006: validation loss: -0.8993\n",
      "2021-10-27 18:17:09.514738: Average global foreground Dice: [0.9015]\n",
      "2021-10-27 18:17:09.520659: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:17:10.058416: lr: 0.006786\n",
      "2021-10-27 18:17:10.109918: saving checkpoint...\n",
      "2021-10-27 18:17:11.230133: done, saving took 1.14 seconds\n",
      "2021-10-27 18:17:11.738451: This epoch took 209.689980 s\n",
      "\n",
      "2021-10-27 18:17:11.757760: \n",
      "epoch:  35\n",
      "2021-10-27 18:20:25.081292: train loss : -0.8739\n",
      "2021-10-27 18:20:39.327822: validation loss: -0.8997\n",
      "2021-10-27 18:20:39.336111: Average global foreground Dice: [0.9019]\n",
      "2021-10-27 18:20:39.342218: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:20:39.839740: lr: 0.006692\n",
      "2021-10-27 18:20:39.883673: saving checkpoint...\n",
      "2021-10-27 18:20:41.011133: done, saving took 1.15 seconds\n",
      "2021-10-27 18:20:41.537440: This epoch took 209.769815 s\n",
      "\n",
      "2021-10-27 18:20:41.549886: \n",
      "epoch:  36\n",
      "2021-10-27 18:23:54.773245: train loss : -0.8765\n",
      "2021-10-27 18:24:09.003823: validation loss: -0.9023\n",
      "2021-10-27 18:24:09.007932: Average global foreground Dice: [0.9034]\n",
      "2021-10-27 18:24:09.014719: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:24:09.579808: lr: 0.006598\n",
      "2021-10-27 18:24:09.629672: saving checkpoint...\n",
      "2021-10-27 18:24:10.719901: done, saving took 1.11 seconds\n",
      "2021-10-27 18:24:11.162323: This epoch took 209.605477 s\n",
      "\n",
      "2021-10-27 18:24:11.178553: \n",
      "epoch:  37\n",
      "2021-10-27 18:27:24.297173: train loss : -0.8759\n",
      "2021-10-27 18:27:38.516657: validation loss: -0.9004\n",
      "2021-10-27 18:27:38.521299: Average global foreground Dice: [0.9026]\n",
      "2021-10-27 18:27:38.528165: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:27:39.068530: lr: 0.006504\n",
      "2021-10-27 18:27:39.115374: saving checkpoint...\n",
      "2021-10-27 18:27:40.201446: done, saving took 1.10 seconds\n",
      "2021-10-27 18:27:40.477253: This epoch took 209.290530 s\n",
      "\n",
      "2021-10-27 18:27:40.495629: \n",
      "epoch:  38\n",
      "2021-10-27 18:30:53.690677: train loss : -0.8772\n",
      "2021-10-27 18:31:07.903650: validation loss: -0.9033\n",
      "2021-10-27 18:31:07.907789: Average global foreground Dice: [0.9053]\n",
      "2021-10-27 18:31:07.914478: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:31:08.396436: lr: 0.006409\n",
      "2021-10-27 18:31:08.449460: saving checkpoint...\n",
      "2021-10-27 18:31:09.536963: done, saving took 1.11 seconds\n",
      "2021-10-27 18:31:10.005163: This epoch took 209.502626 s\n",
      "\n",
      "2021-10-27 18:31:10.022940: \n",
      "epoch:  39\n",
      "2021-10-27 18:34:23.134222: train loss : -0.8781\n",
      "2021-10-27 18:34:37.347618: validation loss: -0.9046\n",
      "2021-10-27 18:34:37.352507: Average global foreground Dice: [0.9059]\n",
      "2021-10-27 18:34:37.359176: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:34:37.892069: lr: 0.006314\n",
      "2021-10-27 18:34:37.942531: saving checkpoint...\n",
      "2021-10-27 18:34:39.045789: done, saving took 1.12 seconds\n",
      "2021-10-27 18:34:39.452251: This epoch took 209.422542 s\n",
      "\n",
      "2021-10-27 18:34:39.469736: \n",
      "epoch:  40\n",
      "2021-10-27 18:37:53.147609: train loss : -0.8793\n",
      "2021-10-27 18:38:07.369455: validation loss: -0.9037\n",
      "2021-10-27 18:38:07.373936: Average global foreground Dice: [0.904]\n",
      "2021-10-27 18:38:07.381395: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:38:07.874585: lr: 0.00622\n",
      "2021-10-27 18:38:07.923303: saving checkpoint...\n",
      "2021-10-27 18:38:09.006621: done, saving took 1.10 seconds\n",
      "2021-10-27 18:38:09.443952: This epoch took 209.967504 s\n",
      "\n",
      "2021-10-27 18:38:09.463562: \n",
      "epoch:  41\n",
      "2021-10-27 18:41:23.285274: train loss : -0.8806\n",
      "2021-10-27 18:41:37.499027: validation loss: -0.9021\n",
      "2021-10-27 18:41:37.503599: Average global foreground Dice: [0.9036]\n",
      "2021-10-27 18:41:37.509929: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:41:37.991693: lr: 0.006125\n",
      "2021-10-27 18:41:38.039450: saving checkpoint...\n",
      "2021-10-27 18:41:39.121900: done, saving took 1.10 seconds\n",
      "2021-10-27 18:41:39.510254: This epoch took 210.040017 s\n",
      "\n",
      "2021-10-27 18:41:39.527032: \n",
      "epoch:  42\n",
      "2021-10-27 18:44:53.345369: train loss : -0.8806\n",
      "2021-10-27 18:45:07.560451: validation loss: -0.9021\n",
      "2021-10-27 18:45:07.565123: Average global foreground Dice: [0.9035]\n",
      "2021-10-27 18:45:07.571889: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:45:08.117473: lr: 0.00603\n",
      "2021-10-27 18:45:08.172475: saving checkpoint...\n",
      "2021-10-27 18:45:09.286355: done, saving took 1.13 seconds\n",
      "2021-10-27 18:45:09.740690: This epoch took 210.206446 s\n",
      "\n",
      "2021-10-27 18:45:09.758028: \n",
      "epoch:  43\n",
      "2021-10-27 18:48:23.568766: train loss : -0.8824\n",
      "2021-10-27 18:48:37.791871: validation loss: -0.9069\n",
      "2021-10-27 18:48:37.796122: Average global foreground Dice: [0.9077]\n",
      "2021-10-27 18:48:37.802655: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:48:38.306463: lr: 0.005934\n",
      "2021-10-27 18:48:38.352660: saving checkpoint...\n",
      "2021-10-27 18:48:39.468688: done, saving took 1.14 seconds\n",
      "2021-10-27 18:48:39.933730: This epoch took 210.169208 s\n",
      "\n",
      "2021-10-27 18:48:39.952298: \n",
      "epoch:  44\n",
      "2021-10-27 18:51:53.849514: train loss : -0.8812\n",
      "2021-10-27 18:52:08.077659: validation loss: -0.9085\n",
      "2021-10-27 18:52:08.083382: Average global foreground Dice: [0.9103]\n",
      "2021-10-27 18:52:08.089809: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:52:08.584181: lr: 0.005839\n",
      "2021-10-27 18:52:08.630008: saving checkpoint...\n",
      "2021-10-27 18:52:09.726172: done, saving took 1.12 seconds\n",
      "2021-10-27 18:52:10.168128: This epoch took 210.209103 s\n",
      "\n",
      "2021-10-27 18:52:10.186176: \n",
      "epoch:  45\n",
      "2021-10-27 18:55:23.964481: train loss : -0.8824\n",
      "2021-10-27 18:55:38.217515: validation loss: -0.9085\n",
      "2021-10-27 18:55:38.222154: Average global foreground Dice: [0.9092]\n",
      "2021-10-27 18:55:38.229241: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:55:38.724879: lr: 0.005743\n",
      "2021-10-27 18:55:38.772058: saving checkpoint...\n",
      "2021-10-27 18:55:39.930874: done, saving took 1.18 seconds\n",
      "2021-10-27 18:55:40.313049: This epoch took 210.120921 s\n",
      "\n",
      "2021-10-27 18:55:40.334138: \n",
      "epoch:  46\n",
      "2021-10-27 18:58:53.999112: train loss : -0.8837\n",
      "2021-10-27 18:59:08.228720: validation loss: -0.9093\n",
      "2021-10-27 18:59:08.233006: Average global foreground Dice: [0.9103]\n",
      "2021-10-27 18:59:08.240121: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:59:08.789995: lr: 0.005647\n",
      "2021-10-27 18:59:08.845074: saving checkpoint...\n",
      "2021-10-27 18:59:09.946259: done, saving took 1.12 seconds\n",
      "2021-10-27 18:59:10.231436: This epoch took 209.890431 s\n",
      "\n",
      "2021-10-27 18:59:10.249202: \n",
      "epoch:  47\n",
      "2021-10-27 19:02:24.073480: train loss : -0.8836\n",
      "2021-10-27 19:02:38.293362: validation loss: -0.9106\n",
      "2021-10-27 19:02:38.297653: Average global foreground Dice: [0.9112]\n",
      "2021-10-27 19:02:38.303978: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:02:38.832428: lr: 0.005551\n",
      "2021-10-27 19:02:38.887215: saving checkpoint...\n",
      "2021-10-27 19:02:40.019033: done, saving took 1.15 seconds\n",
      "2021-10-27 19:02:40.540802: This epoch took 210.284503 s\n",
      "\n",
      "2021-10-27 19:02:40.561311: \n",
      "epoch:  48\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-27 19:05:54.003040: train loss : -0.8830\n",
      "2021-10-27 19:06:08.226439: validation loss: -0.9111\n",
      "2021-10-27 19:06:08.230642: Average global foreground Dice: [0.9116]\n",
      "2021-10-27 19:06:08.237617: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:06:08.816145: lr: 0.005455\n",
      "2021-10-27 19:06:08.868201: saving checkpoint...\n",
      "2021-10-27 19:06:10.074313: done, saving took 1.22 seconds\n",
      "2021-10-27 19:06:10.406582: This epoch took 209.838289 s\n",
      "\n",
      "2021-10-27 19:06:10.425955: \n",
      "epoch:  49\n",
      "2021-10-27 19:09:23.657384: train loss : -0.8843\n",
      "2021-10-27 19:09:37.865330: validation loss: -0.9113\n",
      "2021-10-27 19:09:37.870036: Average global foreground Dice: [0.9119]\n",
      "2021-10-27 19:09:37.876658: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:09:38.405019: lr: 0.005359\n",
      "2021-10-27 19:09:38.435755: saving scheduled checkpoint file...\n",
      "2021-10-27 19:09:38.461917: saving checkpoint...\n",
      "2021-10-27 19:09:39.409618: done, saving took 0.97 seconds\n",
      "2021-10-27 19:09:39.945523: done\n",
      "2021-10-27 19:09:39.986156: saving checkpoint...\n",
      "2021-10-27 19:09:41.103102: done, saving took 1.14 seconds\n",
      "2021-10-27 19:09:41.667199: This epoch took 211.234864 s\n",
      "\n",
      "2021-10-27 19:09:41.684789: \n",
      "epoch:  50\n",
      "2021-10-27 19:12:55.030789: train loss : -0.8847\n",
      "2021-10-27 19:13:09.244159: validation loss: -0.9129\n",
      "2021-10-27 19:13:09.248719: Average global foreground Dice: [0.9137]\n",
      "2021-10-27 19:13:09.255521: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:13:09.795948: lr: 0.005262\n",
      "2021-10-27 19:13:09.838286: saving checkpoint...\n",
      "2021-10-27 19:13:10.957539: done, saving took 1.14 seconds\n",
      "2021-10-27 19:13:11.391642: This epoch took 209.699962 s\n",
      "\n",
      "2021-10-27 19:13:11.405061: \n",
      "epoch:  51\n",
      "2021-10-27 19:16:24.703082: train loss : -0.8858\n",
      "2021-10-27 19:16:38.913828: validation loss: -0.9134\n",
      "2021-10-27 19:16:38.917996: Average global foreground Dice: [0.9134]\n",
      "2021-10-27 19:16:38.924697: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:16:39.467023: lr: 0.005166\n",
      "2021-10-27 19:16:39.517044: saving checkpoint...\n",
      "2021-10-27 19:16:40.584957: done, saving took 1.09 seconds\n",
      "2021-10-27 19:16:41.164922: This epoch took 209.752770 s\n",
      "\n",
      "2021-10-27 19:16:41.184223: \n",
      "epoch:  52\n",
      "2021-10-27 19:19:54.374327: train loss : -0.8857\n",
      "2021-10-27 19:20:08.583690: validation loss: -0.9123\n",
      "2021-10-27 19:20:08.588850: Average global foreground Dice: [0.9131]\n",
      "2021-10-27 19:20:08.596879: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:20:09.112903: lr: 0.005069\n",
      "2021-10-27 19:20:09.163153: saving checkpoint...\n",
      "2021-10-27 19:20:10.252950: done, saving took 1.11 seconds\n",
      "2021-10-27 19:20:10.526856: This epoch took 209.335903 s\n",
      "\n",
      "2021-10-27 19:20:10.546122: \n",
      "epoch:  53\n",
      "2021-10-27 19:23:23.773113: train loss : -0.8871\n",
      "2021-10-27 19:23:37.983027: validation loss: -0.9129\n",
      "2021-10-27 19:23:37.989635: Average global foreground Dice: [0.9134]\n",
      "2021-10-27 19:23:37.996375: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:23:38.484683: lr: 0.004971\n",
      "2021-10-27 19:23:38.535633: saving checkpoint...\n",
      "2021-10-27 19:23:39.625043: done, saving took 1.11 seconds\n",
      "2021-10-27 19:23:39.880332: This epoch took 209.326435 s\n",
      "\n",
      "2021-10-27 19:23:39.900689: \n",
      "epoch:  54\n",
      "2021-10-27 19:26:52.967294: train loss : -0.8879\n",
      "2021-10-27 19:27:07.209468: validation loss: -0.9158\n",
      "2021-10-27 19:27:07.213817: Average global foreground Dice: [0.9156]\n",
      "2021-10-27 19:27:07.222145: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:27:07.749857: lr: 0.004874\n",
      "2021-10-27 19:27:07.795798: saving checkpoint...\n",
      "2021-10-27 19:27:08.926045: done, saving took 1.15 seconds\n",
      "2021-10-27 19:27:09.242221: This epoch took 209.334017 s\n",
      "\n",
      "2021-10-27 19:27:09.260999: \n",
      "epoch:  55\n",
      "2021-10-27 19:30:22.423413: train loss : -0.8886\n",
      "2021-10-27 19:30:36.666178: validation loss: -0.9135\n",
      "2021-10-27 19:30:36.670454: Average global foreground Dice: [0.9141]\n",
      "2021-10-27 19:30:36.677383: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:30:37.207479: lr: 0.004776\n",
      "2021-10-27 19:30:37.255629: saving checkpoint...\n",
      "2021-10-27 19:30:38.345457: done, saving took 1.11 seconds\n",
      "2021-10-27 19:30:38.974070: This epoch took 209.705697 s\n",
      "\n",
      "2021-10-27 19:30:38.993410: \n",
      "epoch:  56\n",
      "2021-10-27 19:33:52.663529: train loss : -0.8894\n",
      "2021-10-27 19:34:06.905928: validation loss: -0.9143\n",
      "2021-10-27 19:34:06.910747: Average global foreground Dice: [0.9148]\n",
      "2021-10-27 19:34:06.917081: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:34:07.404546: lr: 0.004679\n",
      "2021-10-27 19:34:07.450116: saving checkpoint...\n",
      "2021-10-27 19:34:08.587927: done, saving took 1.16 seconds\n",
      "2021-10-27 19:34:09.074216: This epoch took 210.073930 s\n",
      "\n",
      "2021-10-27 19:34:09.094282: \n",
      "epoch:  57\n",
      "2021-10-27 19:37:22.901973: train loss : -0.8886\n",
      "2021-10-27 19:37:37.111795: validation loss: -0.9159\n",
      "2021-10-27 19:37:37.116528: Average global foreground Dice: [0.9165]\n",
      "2021-10-27 19:37:37.124284: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:37:37.714602: lr: 0.004581\n",
      "2021-10-27 19:37:37.765320: saving checkpoint...\n",
      "2021-10-27 19:37:38.875245: done, saving took 1.13 seconds\n",
      "2021-10-27 19:37:39.314889: This epoch took 210.213801 s\n",
      "\n",
      "2021-10-27 19:37:39.334868: \n",
      "epoch:  58\n",
      "2021-10-27 19:40:53.318713: train loss : -0.8898\n",
      "2021-10-27 19:41:07.532108: validation loss: -0.9168\n",
      "2021-10-27 19:41:07.536461: Average global foreground Dice: [0.917]\n",
      "2021-10-27 19:41:07.543389: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:41:08.042904: lr: 0.004482\n",
      "2021-10-27 19:41:08.094285: saving checkpoint...\n",
      "2021-10-27 19:41:09.186874: done, saving took 1.11 seconds\n",
      "2021-10-27 19:41:09.774178: This epoch took 210.432549 s\n",
      "\n",
      "2021-10-27 19:41:09.792928: \n",
      "epoch:  59\n",
      "2021-10-27 19:44:23.489713: train loss : -0.8902\n",
      "2021-10-27 19:44:37.704231: validation loss: -0.9129\n",
      "2021-10-27 19:44:37.709921: Average global foreground Dice: [0.913]\n",
      "2021-10-27 19:44:37.716452: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:44:38.211161: lr: 0.004384\n",
      "2021-10-27 19:44:38.251070: saving checkpoint...\n",
      "2021-10-27 19:44:39.337494: done, saving took 1.11 seconds\n",
      "2021-10-27 19:44:39.749732: This epoch took 209.949464 s\n",
      "\n",
      "2021-10-27 19:44:39.757981: \n",
      "epoch:  60\n",
      "2021-10-27 19:47:53.535278: train loss : -0.8913\n",
      "2021-10-27 19:48:07.759081: validation loss: -0.9164\n",
      "2021-10-27 19:48:07.763155: Average global foreground Dice: [0.9164]\n",
      "2021-10-27 19:48:07.769557: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:48:08.251485: lr: 0.004285\n",
      "2021-10-27 19:48:08.293824: saving checkpoint...\n",
      "2021-10-27 19:48:09.381947: done, saving took 1.11 seconds\n",
      "2021-10-27 19:48:09.852822: This epoch took 210.088605 s\n",
      "\n",
      "2021-10-27 19:48:09.861013: \n",
      "epoch:  61\n",
      "2021-10-27 19:51:23.790404: train loss : -0.8908\n",
      "2021-10-27 19:51:38.014508: validation loss: -0.9183\n",
      "2021-10-27 19:51:38.020443: Average global foreground Dice: [0.9179]\n",
      "2021-10-27 19:51:38.027904: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:51:38.514375: lr: 0.004186\n",
      "2021-10-27 19:51:38.554790: saving checkpoint...\n",
      "2021-10-27 19:51:39.651123: done, saving took 1.12 seconds\n",
      "2021-10-27 19:51:40.104480: This epoch took 210.236465 s\n",
      "\n",
      "2021-10-27 19:51:40.113657: \n",
      "epoch:  62\n",
      "2021-10-27 19:54:54.129905: train loss : -0.8919\n",
      "2021-10-27 19:55:08.347906: validation loss: -0.9191\n",
      "2021-10-27 19:55:08.352703: Average global foreground Dice: [0.9188]\n",
      "2021-10-27 19:55:08.360081: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:55:08.898398: lr: 0.004087\n",
      "2021-10-27 19:55:08.937012: saving checkpoint...\n",
      "2021-10-27 19:55:10.028582: done, saving took 1.11 seconds\n",
      "2021-10-27 19:55:10.322850: This epoch took 210.201872 s\n",
      "\n",
      "2021-10-27 19:55:10.331222: \n",
      "epoch:  63\n",
      "2021-10-27 19:58:24.244332: train loss : -0.8925\n",
      "2021-10-27 19:58:38.476549: validation loss: -0.9175\n",
      "2021-10-27 19:58:38.480878: Average global foreground Dice: [0.917]\n",
      "2021-10-27 19:58:38.488853: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:58:39.019267: lr: 0.003987\n",
      "2021-10-27 19:58:39.059770: saving checkpoint...\n",
      "2021-10-27 19:58:40.156377: done, saving took 1.12 seconds\n",
      "2021-10-27 19:58:40.578212: This epoch took 210.239975 s\n",
      "\n",
      "2021-10-27 19:58:40.586604: \n",
      "epoch:  64\n",
      "2021-10-27 20:01:54.344904: train loss : -0.8917\n",
      "2021-10-27 20:02:08.595672: validation loss: -0.9200\n",
      "2021-10-27 20:02:08.602630: Average global foreground Dice: [0.9192]\n",
      "2021-10-27 20:02:08.609382: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:02:09.142107: lr: 0.003887\n",
      "2021-10-27 20:02:09.180128: saving checkpoint...\n",
      "2021-10-27 20:02:10.296857: done, saving took 1.14 seconds\n",
      "2021-10-27 20:02:10.724901: This epoch took 210.131480 s\n",
      "\n",
      "2021-10-27 20:02:10.734387: \n",
      "epoch:  65\n",
      "2021-10-27 20:05:24.081175: train loss : -0.8938\n",
      "2021-10-27 20:05:38.308932: validation loss: -0.9217\n",
      "2021-10-27 20:05:38.313105: Average global foreground Dice: [0.9214]\n",
      "2021-10-27 20:05:38.319721: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:05:38.851503: lr: 0.003787\n",
      "2021-10-27 20:05:38.891527: saving checkpoint...\n",
      "2021-10-27 20:05:40.052271: done, saving took 1.18 seconds\n",
      "2021-10-27 20:05:40.542876: This epoch took 209.801040 s\n",
      "\n",
      "2021-10-27 20:05:40.550988: \n",
      "epoch:  66\n",
      "2021-10-27 20:08:53.911151: train loss : -0.8951\n",
      "2021-10-27 20:09:08.132201: validation loss: -0.9228\n",
      "2021-10-27 20:09:08.136538: Average global foreground Dice: [0.9219]\n",
      "2021-10-27 20:09:08.143013: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:09:08.654717: lr: 0.003687\n",
      "2021-10-27 20:09:08.695593: saving checkpoint...\n",
      "2021-10-27 20:09:09.782169: done, saving took 1.11 seconds\n",
      "2021-10-27 20:09:10.228943: This epoch took 209.671707 s\n",
      "\n",
      "2021-10-27 20:09:10.236654: \n",
      "epoch:  67\n",
      "2021-10-27 20:12:23.696460: train loss : -0.8948\n",
      "2021-10-27 20:12:37.917202: validation loss: -0.9222\n",
      "2021-10-27 20:12:37.922053: Average global foreground Dice: [0.9214]\n",
      "2021-10-27 20:12:37.929561: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:12:38.422100: lr: 0.003586\n",
      "2021-10-27 20:12:38.463353: saving checkpoint...\n",
      "2021-10-27 20:12:39.561992: done, saving took 1.12 seconds\n",
      "2021-10-27 20:12:39.953203: This epoch took 209.709893 s\n",
      "\n",
      "2021-10-27 20:12:39.961633: \n",
      "epoch:  68\n",
      "2021-10-27 20:15:53.221067: train loss : -0.8954\n",
      "2021-10-27 20:16:07.429568: validation loss: -0.9239\n",
      "2021-10-27 20:16:07.433751: Average global foreground Dice: [0.9232]\n",
      "2021-10-27 20:16:07.440206: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:16:07.969167: lr: 0.003485\n",
      "2021-10-27 20:16:08.030812: saving checkpoint...\n",
      "2021-10-27 20:16:09.153811: done, saving took 1.14 seconds\n",
      "2021-10-27 20:16:09.420716: This epoch took 209.452179 s\n",
      "\n",
      "2021-10-27 20:16:09.428357: \n",
      "epoch:  69\n",
      "2021-10-27 20:19:22.376887: train loss : -0.8964\n",
      "2021-10-27 20:19:36.589476: validation loss: -0.9234\n",
      "2021-10-27 20:19:36.593596: Average global foreground Dice: [0.9231]\n",
      "2021-10-27 20:19:36.599974: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:19:37.098011: lr: 0.003384\n",
      "2021-10-27 20:19:37.137971: saving checkpoint...\n",
      "2021-10-27 20:19:38.213141: done, saving took 1.09 seconds\n",
      "2021-10-27 20:19:38.626835: This epoch took 209.191838 s\n",
      "\n",
      "2021-10-27 20:19:38.634830: \n",
      "epoch:  70\n",
      "2021-10-27 20:22:51.480104: train loss : -0.8964\n",
      "2021-10-27 20:23:05.695925: validation loss: -0.9247\n",
      "2021-10-27 20:23:05.700474: Average global foreground Dice: [0.924]\n",
      "2021-10-27 20:23:05.706839: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:23:06.196258: lr: 0.003282\n",
      "2021-10-27 20:23:06.235288: saving checkpoint...\n",
      "2021-10-27 20:23:07.337533: done, saving took 1.12 seconds\n",
      "2021-10-27 20:23:07.988722: This epoch took 209.344851 s\n",
      "\n",
      "2021-10-27 20:23:07.996735: \n",
      "epoch:  71\n",
      "2021-10-27 20:26:20.829101: train loss : -0.8971\n",
      "2021-10-27 20:26:35.038158: validation loss: -0.9260\n",
      "2021-10-27 20:26:35.042964: Average global foreground Dice: [0.9245]\n",
      "2021-10-27 20:26:35.049708: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:26:35.602245: lr: 0.00318\n",
      "2021-10-27 20:26:35.640149: saving checkpoint...\n",
      "2021-10-27 20:26:36.760428: done, saving took 1.14 seconds\n",
      "2021-10-27 20:26:37.079408: This epoch took 209.076185 s\n",
      "\n",
      "2021-10-27 20:26:37.087748: \n",
      "epoch:  72\n",
      "2021-10-27 20:29:50.019905: train loss : -0.8978\n",
      "2021-10-27 20:30:04.241614: validation loss: -0.9260\n",
      "2021-10-27 20:30:04.245916: Average global foreground Dice: [0.9249]\n",
      "2021-10-27 20:30:04.251995: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:30:04.759520: lr: 0.003078\n",
      "2021-10-27 20:30:04.797996: saving checkpoint...\n",
      "2021-10-27 20:30:05.895194: done, saving took 1.12 seconds\n",
      "2021-10-27 20:30:06.314644: This epoch took 209.220294 s\n",
      "\n",
      "2021-10-27 20:30:06.323040: \n",
      "epoch:  73\n",
      "2021-10-27 20:33:19.259122: train loss : -0.8978\n",
      "2021-10-27 20:33:33.481588: validation loss: -0.9254\n",
      "2021-10-27 20:33:33.486125: Average global foreground Dice: [0.9246]\n",
      "2021-10-27 20:33:33.492896: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:33:33.983122: lr: 0.002975\n",
      "2021-10-27 20:33:34.033557: saving checkpoint...\n",
      "2021-10-27 20:33:35.121497: done, saving took 1.11 seconds\n",
      "2021-10-27 20:33:35.527054: This epoch took 209.197583 s\n",
      "\n",
      "2021-10-27 20:33:35.546369: \n",
      "epoch:  74\n",
      "2021-10-27 20:36:48.403444: train loss : -0.8992\n",
      "2021-10-27 20:37:02.639039: validation loss: -0.9262\n",
      "2021-10-27 20:37:02.643097: Average global foreground Dice: [0.9255]\n",
      "2021-10-27 20:37:02.650785: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:37:03.137144: lr: 0.002872\n",
      "2021-10-27 20:37:03.190368: saving checkpoint...\n",
      "2021-10-27 20:37:04.382689: done, saving took 1.21 seconds\n",
      "2021-10-27 20:37:04.805258: This epoch took 209.251645 s\n",
      "\n",
      "2021-10-27 20:37:04.826111: \n",
      "epoch:  75\n",
      "2021-10-27 20:40:17.672020: train loss : -0.8993\n",
      "2021-10-27 20:40:31.915754: validation loss: -0.9271\n",
      "2021-10-27 20:40:31.920605: Average global foreground Dice: [0.9259]\n",
      "2021-10-27 20:40:31.931567: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:40:32.462604: lr: 0.002768\n",
      "2021-10-27 20:40:32.513423: saving checkpoint...\n",
      "2021-10-27 20:40:33.613173: done, saving took 1.12 seconds\n",
      "2021-10-27 20:40:33.950976: This epoch took 209.118092 s\n",
      "\n",
      "2021-10-27 20:40:33.970650: \n",
      "epoch:  76\n",
      "2021-10-27 20:43:46.931294: train loss : -0.9000\n",
      "2021-10-27 20:44:01.159491: validation loss: -0.9276\n",
      "2021-10-27 20:44:01.164469: Average global foreground Dice: [0.9262]\n",
      "2021-10-27 20:44:01.171446: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:44:01.669525: lr: 0.002664\n",
      "2021-10-27 20:44:01.720809: saving checkpoint...\n",
      "2021-10-27 20:44:02.804666: done, saving took 1.10 seconds\n",
      "2021-10-27 20:44:03.205812: This epoch took 209.228037 s\n",
      "\n",
      "2021-10-27 20:44:03.224814: \n",
      "epoch:  77\n",
      "2021-10-27 20:47:16.488878: train loss : -0.8999\n",
      "2021-10-27 20:47:30.698685: validation loss: -0.9290\n",
      "2021-10-27 20:47:30.704420: Average global foreground Dice: [0.9278]\n",
      "2021-10-27 20:47:30.711139: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:47:31.204801: lr: 0.00256\n",
      "2021-10-27 20:47:31.260777: saving checkpoint...\n",
      "2021-10-27 20:47:32.444647: done, saving took 1.21 seconds\n",
      "2021-10-27 20:47:32.858278: This epoch took 209.626297 s\n",
      "\n",
      "2021-10-27 20:47:32.877568: \n",
      "epoch:  78\n",
      "2021-10-27 20:50:46.329304: train loss : -0.9007\n",
      "2021-10-27 20:51:00.547373: validation loss: -0.9268\n",
      "2021-10-27 20:51:00.551728: Average global foreground Dice: [0.9245]\n",
      "2021-10-27 20:51:00.559014: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:51:01.092634: lr: 0.002455\n",
      "2021-10-27 20:51:01.142945: saving checkpoint...\n",
      "2021-10-27 20:51:02.235200: done, saving took 1.11 seconds\n",
      "2021-10-27 20:51:02.497506: This epoch took 209.614185 s\n",
      "\n",
      "2021-10-27 20:51:02.516364: \n",
      "epoch:  79\n",
      "2021-10-27 20:54:15.770254: train loss : -0.9016\n",
      "2021-10-27 20:54:29.979403: validation loss: -0.9310\n",
      "2021-10-27 20:54:29.983731: Average global foreground Dice: [0.9293]\n",
      "2021-10-27 20:54:29.990735: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:54:30.501043: lr: 0.002349\n",
      "2021-10-27 20:54:30.546625: saving checkpoint...\n",
      "2021-10-27 20:54:31.608206: done, saving took 1.08 seconds\n",
      "2021-10-27 20:54:31.828865: This epoch took 209.304489 s\n",
      "\n",
      "2021-10-27 20:54:31.842247: \n",
      "epoch:  80\n",
      "2021-10-27 20:57:45.270379: train loss : -0.9018\n",
      "2021-10-27 20:57:59.485231: validation loss: -0.9299\n",
      "2021-10-27 20:57:59.489508: Average global foreground Dice: [0.9286]\n",
      "2021-10-27 20:57:59.496691: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:58:00.053982: lr: 0.002243\n",
      "2021-10-27 20:58:00.106218: saving checkpoint...\n",
      "2021-10-27 20:58:01.207440: done, saving took 1.12 seconds\n",
      "2021-10-27 20:58:01.630846: This epoch took 209.781206 s\n",
      "\n",
      "2021-10-27 20:58:01.649563: \n",
      "epoch:  81\n",
      "2021-10-27 21:01:14.950641: train loss : -0.9026\n",
      "2021-10-27 21:01:29.170892: validation loss: -0.9306\n",
      "2021-10-27 21:01:29.177411: Average global foreground Dice: [0.9297]\n",
      "2021-10-27 21:01:29.184938: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:01:29.674535: lr: 0.002137\n",
      "2021-10-27 21:01:29.721301: saving checkpoint...\n",
      "2021-10-27 21:01:30.841138: done, saving took 1.14 seconds\n",
      "2021-10-27 21:01:31.439124: This epoch took 209.783458 s\n",
      "\n",
      "2021-10-27 21:01:31.459046: \n",
      "epoch:  82\n",
      "2021-10-27 21:04:44.688455: train loss : -0.9037\n",
      "2021-10-27 21:04:58.907620: validation loss: -0.9325\n",
      "2021-10-27 21:04:58.911829: Average global foreground Dice: [0.9309]\n",
      "2021-10-27 21:04:58.918344: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:04:59.428277: lr: 0.00203\n",
      "2021-10-27 21:04:59.477633: saving checkpoint...\n",
      "2021-10-27 21:05:00.543790: done, saving took 1.09 seconds\n",
      "2021-10-27 21:05:00.755704: This epoch took 209.289634 s\n",
      "\n",
      "2021-10-27 21:05:00.771210: \n",
      "epoch:  83\n",
      "2021-10-27 21:08:14.189635: train loss : -0.9040\n",
      "2021-10-27 21:08:28.407394: validation loss: -0.9329\n",
      "2021-10-27 21:08:28.412035: Average global foreground Dice: [0.9318]\n",
      "2021-10-27 21:08:28.417964: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:08:28.974440: lr: 0.001922\n",
      "2021-10-27 21:08:29.025777: saving checkpoint...\n",
      "2021-10-27 21:08:30.124595: done, saving took 1.12 seconds\n",
      "2021-10-27 21:08:30.397497: This epoch took 209.619283 s\n",
      "\n",
      "2021-10-27 21:08:30.416051: \n",
      "epoch:  84\n",
      "2021-10-27 21:11:43.802112: train loss : -0.9038\n",
      "2021-10-27 21:11:58.025545: validation loss: -0.9332\n",
      "2021-10-27 21:11:58.030287: Average global foreground Dice: [0.9316]\n",
      "2021-10-27 21:11:58.036797: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:11:58.556268: lr: 0.001813\n",
      "2021-10-27 21:11:58.605919: saving checkpoint...\n",
      "2021-10-27 21:11:59.706355: done, saving took 1.12 seconds\n",
      "2021-10-27 21:11:59.942307: This epoch took 209.519464 s\n",
      "\n",
      "2021-10-27 21:11:59.960284: \n",
      "epoch:  85\n",
      "2021-10-27 21:15:14.043883: train loss : -0.9048\n",
      "2021-10-27 21:15:28.275241: validation loss: -0.9332\n",
      "2021-10-27 21:15:28.279448: Average global foreground Dice: [0.9313]\n",
      "2021-10-27 21:15:28.286027: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:15:28.846346: lr: 0.001704\n",
      "2021-10-27 21:15:28.900374: saving checkpoint...\n",
      "2021-10-27 21:15:29.995219: done, saving took 1.12 seconds\n",
      "2021-10-27 21:15:30.266608: This epoch took 210.299585 s\n",
      "\n",
      "2021-10-27 21:15:30.284843: \n",
      "epoch:  86\n",
      "2021-10-27 21:18:44.196057: train loss : -0.9053\n",
      "2021-10-27 21:18:58.434228: validation loss: -0.9348\n",
      "2021-10-27 21:18:58.438670: Average global foreground Dice: [0.9329]\n",
      "2021-10-27 21:18:58.445390: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:18:58.927255: lr: 0.001594\n",
      "2021-10-27 21:18:58.974977: saving checkpoint...\n",
      "2021-10-27 21:19:00.066794: done, saving took 1.11 seconds\n",
      "2021-10-27 21:19:00.602233: This epoch took 210.310823 s\n",
      "\n",
      "2021-10-27 21:19:00.620105: \n",
      "epoch:  87\n",
      "2021-10-27 21:22:14.739652: train loss : -0.9056\n",
      "2021-10-27 21:22:28.960334: validation loss: -0.9351\n",
      "2021-10-27 21:22:28.964882: Average global foreground Dice: [0.9324]\n",
      "2021-10-27 21:22:28.971247: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:22:29.451562: lr: 0.001483\n",
      "2021-10-27 21:22:29.499696: saving checkpoint...\n",
      "2021-10-27 21:22:30.604387: done, saving took 1.12 seconds\n",
      "2021-10-27 21:22:30.887698: This epoch took 210.261526 s\n",
      "\n",
      "2021-10-27 21:22:30.905945: \n",
      "epoch:  88\n",
      "2021-10-27 21:25:44.831125: train loss : -0.9052\n",
      "2021-10-27 21:25:59.036747: validation loss: -0.9348\n",
      "2021-10-27 21:25:59.040957: Average global foreground Dice: [0.933]\n",
      "2021-10-27 21:25:59.048035: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:25:59.534214: lr: 0.001372\n",
      "2021-10-27 21:25:59.585217: saving checkpoint...\n",
      "2021-10-27 21:26:00.701123: done, saving took 1.13 seconds\n",
      "2021-10-27 21:26:01.145140: This epoch took 210.232304 s\n",
      "\n",
      "2021-10-27 21:26:01.163864: \n",
      "epoch:  89\n",
      "2021-10-27 21:29:15.229650: train loss : -0.9068\n",
      "2021-10-27 21:29:29.448395: validation loss: -0.9354\n",
      "2021-10-27 21:29:29.454415: Average global foreground Dice: [0.9332]\n",
      "2021-10-27 21:29:29.461432: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:29:29.986075: lr: 0.001259\n",
      "2021-10-27 21:29:30.034969: saving checkpoint...\n",
      "2021-10-27 21:29:31.101214: done, saving took 1.09 seconds\n",
      "2021-10-27 21:29:31.539693: This epoch took 210.369396 s\n",
      "\n",
      "2021-10-27 21:29:31.559355: \n",
      "epoch:  90\n",
      "2021-10-27 21:32:45.692551: train loss : -0.9073\n",
      "2021-10-27 21:32:59.919585: validation loss: -0.9370\n",
      "2021-10-27 21:32:59.923735: Average global foreground Dice: [0.9347]\n",
      "2021-10-27 21:32:59.929613: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:33:00.421001: lr: 0.001145\n",
      "2021-10-27 21:33:00.472834: saving checkpoint...\n",
      "2021-10-27 21:33:01.544254: done, saving took 1.09 seconds\n",
      "2021-10-27 21:33:01.999954: This epoch took 210.433331 s\n",
      "\n",
      "2021-10-27 21:33:02.019347: \n",
      "epoch:  91\n",
      "2021-10-27 21:36:16.209172: train loss : -0.9081\n",
      "2021-10-27 21:36:30.414753: validation loss: -0.9378\n",
      "2021-10-27 21:36:30.418961: Average global foreground Dice: [0.9354]\n",
      "2021-10-27 21:36:30.425363: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:36:30.907677: lr: 0.00103\n",
      "2021-10-27 21:36:30.962582: saving checkpoint...\n",
      "2021-10-27 21:36:32.115925: done, saving took 1.17 seconds\n",
      "2021-10-27 21:36:32.502489: This epoch took 210.476507 s\n",
      "\n",
      "2021-10-27 21:36:32.519588: \n",
      "epoch:  92\n",
      "2021-10-27 21:39:46.734115: train loss : -0.9072\n",
      "2021-10-27 21:40:00.961530: validation loss: -0.9385\n",
      "2021-10-27 21:40:00.965844: Average global foreground Dice: [0.9365]\n",
      "2021-10-27 21:40:00.972866: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:40:01.458180: lr: 0.000913\n",
      "2021-10-27 21:40:01.505439: saving checkpoint...\n",
      "2021-10-27 21:40:02.596578: done, saving took 1.11 seconds\n",
      "2021-10-27 21:40:02.920891: This epoch took 210.394666 s\n",
      "\n",
      "2021-10-27 21:40:02.933887: \n",
      "epoch:  93\n",
      "2021-10-27 21:43:17.256623: train loss : -0.9085\n",
      "2021-10-27 21:43:31.477609: validation loss: -0.9397\n",
      "2021-10-27 21:43:31.482184: Average global foreground Dice: [0.9374]\n",
      "2021-10-27 21:43:31.489246: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:43:31.996620: lr: 0.000795\n",
      "2021-10-27 21:43:32.053448: saving checkpoint...\n",
      "2021-10-27 21:43:33.147370: done, saving took 1.11 seconds\n",
      "2021-10-27 21:43:33.592073: This epoch took 210.651240 s\n",
      "\n",
      "2021-10-27 21:43:33.611052: \n",
      "epoch:  94\n",
      "2021-10-27 21:46:47.689788: train loss : -0.9081\n",
      "2021-10-27 21:47:01.931321: validation loss: -0.9392\n",
      "2021-10-27 21:47:01.935587: Average global foreground Dice: [0.9373]\n",
      "2021-10-27 21:47:01.943267: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:47:02.540334: lr: 0.000675\n",
      "2021-10-27 21:47:02.599293: saving checkpoint...\n",
      "2021-10-27 21:47:03.678540: done, saving took 1.10 seconds\n",
      "2021-10-27 21:47:04.103273: This epoch took 210.485805 s\n",
      "\n",
      "2021-10-27 21:47:04.120881: \n",
      "epoch:  95\n",
      "2021-10-27 21:50:18.211537: train loss : -0.9090\n",
      "2021-10-27 21:50:32.449051: validation loss: -0.9396\n",
      "2021-10-27 21:50:32.455130: Average global foreground Dice: [0.9372]\n",
      "2021-10-27 21:50:32.461590: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:50:32.944235: lr: 0.000552\n",
      "2021-10-27 21:50:33.001392: saving checkpoint...\n",
      "2021-10-27 21:50:34.083019: done, saving took 1.10 seconds\n",
      "2021-10-27 21:50:34.576202: This epoch took 210.448514 s\n",
      "\n",
      "2021-10-27 21:50:34.598963: \n",
      "epoch:  96\n",
      "2021-10-27 21:53:48.723944: train loss : -0.9097\n",
      "2021-10-27 21:54:02.950562: validation loss: -0.9429\n",
      "2021-10-27 21:54:02.954893: Average global foreground Dice: [0.9399]\n",
      "2021-10-27 21:54:02.961798: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:54:03.450382: lr: 0.000426\n",
      "2021-10-27 21:54:03.505901: saving checkpoint...\n",
      "2021-10-27 21:54:04.584997: done, saving took 1.10 seconds\n",
      "2021-10-27 21:54:04.994034: This epoch took 210.388111 s\n",
      "\n",
      "2021-10-27 21:54:05.016133: \n",
      "epoch:  97\n",
      "2021-10-27 21:57:19.159474: train loss : -0.9108\n",
      "2021-10-27 21:57:33.368762: validation loss: -0.9408\n",
      "2021-10-27 21:57:33.373151: Average global foreground Dice: [0.9386]\n",
      "2021-10-27 21:57:33.380163: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:57:33.878674: lr: 0.000296\n",
      "2021-10-27 21:57:33.929405: saving checkpoint...\n",
      "2021-10-27 21:57:35.033006: done, saving took 1.12 seconds\n",
      "2021-10-27 21:57:35.443416: This epoch took 210.420974 s\n",
      "\n",
      "2021-10-27 21:57:35.465357: \n",
      "epoch:  98\n",
      "2021-10-27 22:00:49.499074: train loss : -0.9108\n",
      "2021-10-27 22:01:03.703976: validation loss: -0.9417\n",
      "2021-10-27 22:01:03.708362: Average global foreground Dice: [0.9402]\n",
      "2021-10-27 22:01:03.719799: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 22:01:04.252295: lr: 0.000158\n",
      "2021-10-27 22:01:04.299187: saving checkpoint...\n",
      "2021-10-27 22:01:05.427521: done, saving took 1.15 seconds\n",
      "2021-10-27 22:01:05.997954: This epoch took 210.522279 s\n",
      "\n",
      "2021-10-27 22:01:06.016545: \n",
      "epoch:  99\n",
      "2021-10-27 22:04:19.501552: train loss : -0.9108\n",
      "2021-10-27 22:04:33.718564: validation loss: -0.9415\n",
      "2021-10-27 22:04:33.724377: Average global foreground Dice: [0.9394]\n",
      "2021-10-27 22:04:33.736524: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 22:04:34.235325: lr: 0.0\n",
      "2021-10-27 22:04:34.256986: saving scheduled checkpoint file...\n",
      "2021-10-27 22:04:34.286717: saving checkpoint...\n",
      "2021-10-27 22:04:35.404941: done, saving took 1.14 seconds\n",
      "2021-10-27 22:04:36.081759: done\n",
      "2021-10-27 22:04:36.109581: saving checkpoint...\n",
      "2021-10-27 22:04:37.213675: done, saving took 1.12 seconds\n",
      "2021-10-27 22:04:37.762863: This epoch took 211.733864 s\n",
      "\n",
      "2021-10-27 22:04:37.790235: saving checkpoint...\n",
      "2021-10-27 22:04:38.730713: done, saving took 0.96 seconds\n",
      "23090557_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090558_20120 (3, 263, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090559_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090560_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090562_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090563_20151 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090564_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090566_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090567_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090568_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090569_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090571_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090584_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090589_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090590_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090592_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090593_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090596_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090597_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090599_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090600_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090603_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090604_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090607_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090608_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090609_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090614_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090615_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090616_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090617_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090619_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090620_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090621_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090627_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090628_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090629_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090631_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090634_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090635_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090636_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090637_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090640_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090644_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090646_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-27 22:14:07.310181: finished prediction\n",
      "2021-10-27 22:14:07.315912: evaluation of raw predictions\n",
      "2021-10-27 22:14:13.081033: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.9544701828710818\n",
      "after:  0.9544701828710818\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train 2d nnUNetTrainerV2 555 all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-27 05:36:45.754326: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-27 05:37:00.594287: Unable to plot network architecture:\n",
      "2021-10-27 05:37:00.680377: No module named 'hiddenlayer'\n",
      "2021-10-27 05:37:00.764416: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-27 05:37:00.888404: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-27 05:37:01.048429: \n",
      "\n",
      "2021-10-27 05:37:01.132366: \n",
      "epoch:  0\n",
      "2021-10-27 05:42:56.337986: train loss : -0.1084\n",
      "2021-10-27 05:43:19.246696: validation loss: -0.4531\n",
      "2021-10-27 05:43:19.656855: Average global foreground Dice: [0.5549]\n",
      "2021-10-27 05:43:19.735797: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 05:43:20.492887: lr: 0.00991\n",
      "2021-10-27 05:43:20.511991: This epoch took 379.317797 s\n",
      "\n",
      "2021-10-27 05:43:20.519050: \n",
      "epoch:  1\n",
      "2021-10-27 05:48:34.736089: train loss : -0.5763\n",
      "2021-10-27 05:48:57.258855: validation loss: -0.6947\n",
      "2021-10-27 05:48:57.636249: Average global foreground Dice: [0.7405]\n",
      "2021-10-27 05:48:57.653465: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 05:48:58.269662: lr: 0.00982\n",
      "2021-10-27 05:48:58.367762: saving checkpoint...\n",
      "2021-10-27 05:49:00.300601: done, saving took 2.01 seconds\n",
      "2021-10-27 05:49:00.898111: This epoch took 340.372163 s\n",
      "\n",
      "2021-10-27 05:49:00.906590: \n",
      "epoch:  2\n",
      "2021-10-27 05:54:10.472372: train loss : -0.6588\n",
      "2021-10-27 05:54:29.506801: validation loss: -0.7093\n",
      "2021-10-27 05:54:29.512614: Average global foreground Dice: [0.7458]\n",
      "2021-10-27 05:54:29.519367: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 05:54:30.022358: lr: 0.00973\n",
      "2021-10-27 05:54:30.122938: saving checkpoint...\n",
      "2021-10-27 05:54:31.979202: done, saving took 1.94 seconds\n",
      "2021-10-27 05:54:32.377752: This epoch took 331.463497 s\n",
      "\n",
      "2021-10-27 05:54:32.386107: \n",
      "epoch:  3\n",
      "2021-10-27 05:59:41.609478: train loss : -0.6952\n",
      "2021-10-27 06:00:00.365910: validation loss: -0.7450\n",
      "2021-10-27 06:00:00.370566: Average global foreground Dice: [0.785]\n",
      "2021-10-27 06:00:00.377347: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:00:00.912946: lr: 0.009639\n",
      "2021-10-27 06:00:00.998966: saving checkpoint...\n",
      "2021-10-27 06:00:02.739374: done, saving took 1.81 seconds\n",
      "2021-10-27 06:00:03.150345: This epoch took 330.757618 s\n",
      "\n",
      "2021-10-27 06:00:03.158510: \n",
      "epoch:  4\n",
      "2021-10-27 06:05:10.471361: train loss : -0.7361\n",
      "2021-10-27 06:05:29.548562: validation loss: -0.7779\n",
      "2021-10-27 06:05:29.552832: Average global foreground Dice: [0.8133]\n",
      "2021-10-27 06:05:29.559305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:05:30.050826: lr: 0.009549\n",
      "2021-10-27 06:05:30.109914: saving checkpoint...\n",
      "2021-10-27 06:05:31.919902: done, saving took 1.85 seconds\n",
      "2021-10-27 06:05:32.396935: This epoch took 329.231300 s\n",
      "\n",
      "2021-10-27 06:05:32.406394: \n",
      "epoch:  5\n",
      "2021-10-27 06:10:49.058462: train loss : -0.7494\n",
      "2021-10-27 06:11:09.338736: validation loss: -0.7669\n",
      "2021-10-27 06:11:09.342862: Average global foreground Dice: [0.798]\n",
      "2021-10-27 06:11:09.349957: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:11:09.854059: lr: 0.009458\n",
      "2021-10-27 06:11:09.939370: saving checkpoint...\n",
      "2021-10-27 06:11:11.733479: done, saving took 1.85 seconds\n",
      "2021-10-27 06:11:12.519548: This epoch took 340.106175 s\n",
      "\n",
      "2021-10-27 06:11:12.537691: \n",
      "epoch:  6\n",
      "2021-10-27 06:16:21.297568: train loss : -0.7552\n",
      "2021-10-27 06:16:40.766828: validation loss: -0.7856\n",
      "2021-10-27 06:16:40.771118: Average global foreground Dice: [0.8162]\n",
      "2021-10-27 06:16:40.777596: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:16:41.298534: lr: 0.009368\n",
      "2021-10-27 06:16:41.394979: saving checkpoint...\n",
      "2021-10-27 06:16:43.217364: done, saving took 1.89 seconds\n",
      "2021-10-27 06:16:44.065569: This epoch took 331.522061 s\n",
      "\n",
      "2021-10-27 06:16:44.085018: \n",
      "epoch:  7\n",
      "2021-10-27 06:21:59.655666: train loss : -0.7667\n",
      "2021-10-27 06:22:22.121924: validation loss: -0.7889\n",
      "2021-10-27 06:22:22.126039: Average global foreground Dice: [0.8256]\n",
      "2021-10-27 06:22:22.132284: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:22:22.676008: lr: 0.009277\n",
      "2021-10-27 06:22:22.756664: saving checkpoint...\n",
      "2021-10-27 06:22:24.541749: done, saving took 1.85 seconds\n",
      "2021-10-27 06:22:25.235333: This epoch took 341.141758 s\n",
      "\n",
      "2021-10-27 06:22:25.243758: \n",
      "epoch:  8\n",
      "2021-10-27 06:27:38.212064: train loss : -0.7828\n",
      "2021-10-27 06:27:58.232234: validation loss: -0.8125\n",
      "2021-10-27 06:27:58.236296: Average global foreground Dice: [0.8376]\n",
      "2021-10-27 06:27:58.243344: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:27:58.753826: lr: 0.009186\n",
      "2021-10-27 06:27:58.848660: saving checkpoint...\n",
      "2021-10-27 06:28:00.669415: done, saving took 1.88 seconds\n",
      "2021-10-27 06:28:01.266723: This epoch took 336.015583 s\n",
      "\n",
      "2021-10-27 06:28:01.287906: \n",
      "epoch:  9\n",
      "2021-10-27 06:33:18.220029: train loss : -0.7898\n",
      "2021-10-27 06:33:37.289514: validation loss: -0.8148\n",
      "2021-10-27 06:33:37.294728: Average global foreground Dice: [0.8349]\n",
      "2021-10-27 06:33:37.301049: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:33:37.795578: lr: 0.009095\n",
      "2021-10-27 06:33:37.893389: saving checkpoint...\n",
      "2021-10-27 06:33:39.762477: done, saving took 1.93 seconds\n",
      "2021-10-27 06:33:40.367029: This epoch took 339.072011 s\n",
      "\n",
      "2021-10-27 06:33:40.386094: \n",
      "epoch:  10\n",
      "2021-10-27 06:38:53.524237: train loss : -0.7933\n",
      "2021-10-27 06:39:12.187485: validation loss: -0.8239\n",
      "2021-10-27 06:39:12.192142: Average global foreground Dice: [0.845]\n",
      "2021-10-27 06:39:12.199265: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:39:12.685277: lr: 0.009004\n",
      "2021-10-27 06:39:12.730635: saving checkpoint...\n",
      "2021-10-27 06:39:14.423584: done, saving took 1.72 seconds\n",
      "2021-10-27 06:39:14.716424: This epoch took 334.323305 s\n",
      "\n",
      "2021-10-27 06:39:14.724909: \n",
      "epoch:  11\n",
      "2021-10-27 06:44:28.122439: train loss : -0.7944\n",
      "2021-10-27 06:44:46.786031: validation loss: -0.8233\n",
      "2021-10-27 06:44:46.792301: Average global foreground Dice: [0.8461]\n",
      "2021-10-27 06:44:46.799551: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:44:47.286655: lr: 0.008913\n",
      "2021-10-27 06:44:47.343975: saving checkpoint...\n",
      "2021-10-27 06:44:49.186247: done, saving took 1.87 seconds\n",
      "2021-10-27 06:44:50.013637: This epoch took 335.281991 s\n",
      "\n",
      "2021-10-27 06:44:50.024031: \n",
      "epoch:  12\n",
      "2021-10-27 06:50:09.884418: train loss : -0.7952\n",
      "2021-10-27 06:50:32.548254: validation loss: -0.8161\n",
      "2021-10-27 06:50:32.776911: Average global foreground Dice: [0.8336]\n",
      "2021-10-27 06:50:32.892607: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:50:34.265349: lr: 0.008822\n",
      "2021-10-27 06:50:34.790616: saving checkpoint...\n",
      "2021-10-27 06:50:36.791297: done, saving took 2.06 seconds\n",
      "2021-10-27 06:50:37.211121: This epoch took 347.180167 s\n",
      "\n",
      "2021-10-27 06:50:37.221430: \n",
      "epoch:  13\n",
      "2021-10-27 06:55:50.987137: train loss : -0.7990\n",
      "2021-10-27 06:56:09.693555: validation loss: -0.8286\n",
      "2021-10-27 06:56:09.697793: Average global foreground Dice: [0.8489]\n",
      "2021-10-27 06:56:09.703762: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:56:10.197740: lr: 0.008731\n",
      "2021-10-27 06:56:10.253930: saving checkpoint...\n",
      "2021-10-27 06:56:12.037356: done, saving took 1.81 seconds\n",
      "2021-10-27 06:56:12.640672: This epoch took 335.412399 s\n",
      "\n",
      "2021-10-27 06:56:12.650077: \n",
      "epoch:  14\n",
      "2021-10-27 07:01:23.809832: train loss : -0.8040\n",
      "2021-10-27 07:01:42.484494: validation loss: -0.8271\n",
      "2021-10-27 07:01:42.488945: Average global foreground Dice: [0.8545]\n",
      "2021-10-27 07:01:42.494767: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:01:43.029150: lr: 0.008639\n",
      "2021-10-27 07:01:43.085283: saving checkpoint...\n",
      "2021-10-27 07:01:44.872595: done, saving took 1.82 seconds\n",
      "2021-10-27 07:01:45.140937: This epoch took 332.483765 s\n",
      "\n",
      "2021-10-27 07:01:45.154666: \n",
      "epoch:  15\n",
      "2021-10-27 07:07:01.236776: train loss : -0.8089\n",
      "2021-10-27 07:07:22.686962: validation loss: -0.8125\n",
      "2021-10-27 07:07:22.691325: Average global foreground Dice: [0.8274]\n",
      "2021-10-27 07:07:22.698020: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:07:23.186690: lr: 0.008548\n",
      "2021-10-27 07:07:23.270579: saving checkpoint...\n",
      "2021-10-27 07:07:25.151231: done, saving took 1.94 seconds\n",
      "2021-10-27 07:07:25.782058: This epoch took 340.619288 s\n",
      "\n",
      "2021-10-27 07:07:25.799818: \n",
      "epoch:  16\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-27 07:12:36.207913: train loss : -0.8148\n",
      "2021-10-27 07:12:54.956311: validation loss: -0.8363\n",
      "2021-10-27 07:12:54.960962: Average global foreground Dice: [0.8549]\n",
      "2021-10-27 07:12:54.967874: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:12:55.478076: lr: 0.008456\n",
      "2021-10-27 07:12:55.581270: saving checkpoint...\n",
      "2021-10-27 07:12:57.413083: done, saving took 1.91 seconds\n",
      "2021-10-27 07:12:57.796482: This epoch took 331.990578 s\n",
      "\n",
      "2021-10-27 07:12:57.816657: \n",
      "epoch:  17\n",
      "2021-10-27 07:18:08.443479: train loss : -0.8171\n",
      "2021-10-27 07:18:28.238153: validation loss: -0.8339\n",
      "2021-10-27 07:18:28.242250: Average global foreground Dice: [0.8505]\n",
      "2021-10-27 07:18:28.249011: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:18:28.752438: lr: 0.008364\n",
      "2021-10-27 07:18:28.821295: saving checkpoint...\n",
      "2021-10-27 07:18:30.647820: done, saving took 1.88 seconds\n",
      "2021-10-27 07:18:31.278517: This epoch took 333.455236 s\n",
      "\n",
      "2021-10-27 07:18:31.286401: \n",
      "epoch:  18\n",
      "2021-10-27 07:23:41.603876: train loss : -0.8192\n",
      "2021-10-27 07:24:01.005017: validation loss: -0.8390\n",
      "2021-10-27 07:24:01.009310: Average global foreground Dice: [0.8573]\n",
      "2021-10-27 07:24:01.016337: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:24:01.503953: lr: 0.008272\n",
      "2021-10-27 07:24:01.581358: saving checkpoint...\n",
      "2021-10-27 07:24:03.380301: done, saving took 1.86 seconds\n",
      "2021-10-27 07:24:03.984866: This epoch took 332.691288 s\n",
      "\n",
      "2021-10-27 07:24:03.993599: \n",
      "epoch:  19\n",
      "2021-10-27 07:29:16.769640: train loss : -0.8223\n",
      "2021-10-27 07:29:37.365802: validation loss: -0.8304\n",
      "2021-10-27 07:29:37.371743: Average global foreground Dice: [0.8503]\n",
      "2021-10-27 07:29:37.378189: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:29:37.884919: lr: 0.008181\n",
      "2021-10-27 07:29:37.963552: saving checkpoint...\n",
      "2021-10-27 07:29:39.794301: done, saving took 1.89 seconds\n",
      "2021-10-27 07:29:40.392755: This epoch took 336.392340 s\n",
      "\n",
      "2021-10-27 07:29:40.400845: \n",
      "epoch:  20\n",
      "2021-10-27 07:34:50.300021: train loss : -0.8227\n",
      "2021-10-27 07:35:11.219905: validation loss: -0.8346\n",
      "2021-10-27 07:35:11.225841: Average global foreground Dice: [0.8485]\n",
      "2021-10-27 07:35:11.233207: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:35:11.753283: lr: 0.008088\n",
      "2021-10-27 07:35:11.845299: saving checkpoint...\n",
      "2021-10-27 07:35:13.685198: done, saving took 1.91 seconds\n",
      "2021-10-27 07:35:14.369558: This epoch took 333.961206 s\n",
      "\n",
      "2021-10-27 07:35:14.379288: \n",
      "epoch:  21\n",
      "2021-10-27 07:40:29.399157: train loss : -0.8257\n",
      "2021-10-27 07:40:51.906086: validation loss: -0.8422\n",
      "2021-10-27 07:40:51.911365: Average global foreground Dice: [0.8582]\n",
      "2021-10-27 07:40:51.918160: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:40:52.475408: lr: 0.007996\n",
      "2021-10-27 07:40:52.566410: saving checkpoint...\n",
      "2021-10-27 07:40:54.436013: done, saving took 1.94 seconds\n",
      "2021-10-27 07:40:55.029176: This epoch took 340.643695 s\n",
      "\n",
      "2021-10-27 07:40:55.037449: \n",
      "epoch:  22\n",
      "2021-10-27 07:46:03.899553: train loss : -0.8265\n",
      "2021-10-27 07:46:22.974674: validation loss: -0.8393\n",
      "2021-10-27 07:46:22.979055: Average global foreground Dice: [0.8573]\n",
      "2021-10-27 07:46:22.985926: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:46:23.473557: lr: 0.007904\n",
      "2021-10-27 07:46:23.524432: saving checkpoint...\n",
      "2021-10-27 07:46:25.340564: done, saving took 1.84 seconds\n",
      "2021-10-27 07:46:25.732403: This epoch took 330.688140 s\n",
      "\n",
      "2021-10-27 07:46:25.741086: \n",
      "epoch:  23\n",
      "2021-10-27 07:51:35.034164: train loss : -0.8239\n",
      "2021-10-27 07:51:54.700251: validation loss: -0.8347\n",
      "2021-10-27 07:51:54.704540: Average global foreground Dice: [0.8517]\n",
      "2021-10-27 07:51:54.710415: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:51:55.197334: lr: 0.007811\n",
      "2021-10-27 07:51:55.247006: saving checkpoint...\n",
      "2021-10-27 07:51:57.061264: done, saving took 1.84 seconds\n",
      "2021-10-27 07:51:57.657955: This epoch took 331.909948 s\n",
      "\n",
      "2021-10-27 07:51:57.665954: \n",
      "epoch:  24\n",
      "2021-10-27 07:57:11.873959: train loss : -0.8198\n",
      "2021-10-27 07:57:32.651845: validation loss: -0.8557\n",
      "2021-10-27 07:57:32.655974: Average global foreground Dice: [0.8665]\n",
      "2021-10-27 07:57:32.661975: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:57:33.188350: lr: 0.007719\n",
      "2021-10-27 07:57:33.236439: saving checkpoint...\n",
      "2021-10-27 07:57:35.060813: done, saving took 1.85 seconds\n",
      "2021-10-27 07:57:35.713517: This epoch took 338.040356 s\n",
      "\n",
      "2021-10-27 07:57:35.722692: \n",
      "epoch:  25\n",
      "2021-10-27 08:02:51.361112: train loss : -0.8272\n",
      "2021-10-27 08:03:12.595388: validation loss: -0.8370\n",
      "2021-10-27 08:03:12.636132: Average global foreground Dice: [0.855]\n",
      "2021-10-27 08:03:12.648819: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:03:13.519324: lr: 0.007626\n",
      "2021-10-27 08:03:13.568756: saving checkpoint...\n",
      "2021-10-27 08:03:15.387704: done, saving took 1.85 seconds\n",
      "2021-10-27 08:03:16.048801: This epoch took 340.319428 s\n",
      "\n",
      "2021-10-27 08:03:16.057024: \n",
      "epoch:  26\n",
      "2021-10-27 08:08:28.777412: train loss : -0.8319\n",
      "2021-10-27 08:08:48.083474: validation loss: -0.8459\n",
      "2021-10-27 08:08:48.088450: Average global foreground Dice: [0.8598]\n",
      "2021-10-27 08:08:48.094799: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:08:48.586686: lr: 0.007533\n",
      "2021-10-27 08:08:48.675295: saving checkpoint...\n",
      "2021-10-27 08:08:50.515305: done, saving took 1.90 seconds\n",
      "2021-10-27 08:08:51.017343: This epoch took 334.953342 s\n",
      "\n",
      "2021-10-27 08:08:51.036642: \n",
      "epoch:  27\n",
      "2021-10-27 08:14:08.445664: train loss : -0.8317\n",
      "2021-10-27 08:14:30.127451: validation loss: -0.8412\n",
      "2021-10-27 08:14:30.133045: Average global foreground Dice: [0.8605]\n",
      "2021-10-27 08:14:30.139405: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:14:30.682478: lr: 0.00744\n",
      "2021-10-27 08:14:30.770151: saving checkpoint...\n",
      "2021-10-27 08:14:32.598030: done, saving took 1.89 seconds\n",
      "2021-10-27 08:14:33.208548: This epoch took 342.164896 s\n",
      "\n",
      "2021-10-27 08:14:33.222252: \n",
      "epoch:  28\n",
      "2021-10-27 08:19:46.846218: train loss : -0.8308\n",
      "2021-10-27 08:20:05.534777: validation loss: -0.8448\n",
      "2021-10-27 08:20:05.538927: Average global foreground Dice: [0.8616]\n",
      "2021-10-27 08:20:05.545895: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:20:06.055259: lr: 0.007347\n",
      "2021-10-27 08:20:06.162602: saving checkpoint...\n",
      "2021-10-27 08:20:07.974128: done, saving took 1.89 seconds\n",
      "2021-10-27 08:20:08.652125: This epoch took 335.422223 s\n",
      "\n",
      "2021-10-27 08:20:08.671939: \n",
      "epoch:  29\n",
      "2021-10-27 08:25:21.900605: train loss : -0.8317\n",
      "2021-10-27 08:25:40.830975: validation loss: -0.8436\n",
      "2021-10-27 08:25:40.835417: Average global foreground Dice: [0.862]\n",
      "2021-10-27 08:25:40.842186: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:25:41.339769: lr: 0.007254\n",
      "2021-10-27 08:25:41.447596: saving checkpoint...\n",
      "2021-10-27 08:25:43.250961: done, saving took 1.88 seconds\n",
      "2021-10-27 08:25:43.865656: This epoch took 335.187732 s\n",
      "\n",
      "2021-10-27 08:25:43.883135: \n",
      "epoch:  30\n",
      "2021-10-27 08:30:57.820599: train loss : -0.8309\n",
      "2021-10-27 08:31:16.937678: validation loss: -0.8454\n",
      "2021-10-27 08:31:16.941836: Average global foreground Dice: [0.8598]\n",
      "2021-10-27 08:31:16.948016: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:31:17.462581: lr: 0.007161\n",
      "2021-10-27 08:31:17.566257: saving checkpoint...\n",
      "2021-10-27 08:31:19.405896: done, saving took 1.92 seconds\n",
      "2021-10-27 08:31:20.001666: This epoch took 336.112279 s\n",
      "\n",
      "2021-10-27 08:31:20.021153: \n",
      "epoch:  31\n",
      "2021-10-27 08:36:33.400209: train loss : -0.8264\n",
      "2021-10-27 08:36:54.288383: validation loss: -0.8529\n",
      "2021-10-27 08:36:54.292802: Average global foreground Dice: [0.8649]\n",
      "2021-10-27 08:36:54.299042: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:36:54.818409: lr: 0.007067\n",
      "2021-10-27 08:36:54.926564: saving checkpoint...\n",
      "2021-10-27 08:36:56.754896: done, saving took 1.90 seconds\n",
      "2021-10-27 08:36:57.349473: This epoch took 337.321694 s\n",
      "\n",
      "2021-10-27 08:36:57.367673: \n",
      "epoch:  32\n",
      "2021-10-27 08:42:08.376979: train loss : -0.8315\n",
      "2021-10-27 08:42:27.841266: validation loss: -0.8439\n",
      "2021-10-27 08:42:27.845251: Average global foreground Dice: [0.8597]\n",
      "2021-10-27 08:42:27.851515: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:42:28.368438: lr: 0.006974\n",
      "2021-10-27 08:42:28.471261: saving checkpoint...\n",
      "2021-10-27 08:42:30.290474: done, saving took 1.89 seconds\n",
      "2021-10-27 08:42:30.876517: This epoch took 333.502313 s\n",
      "\n",
      "2021-10-27 08:42:30.894356: \n",
      "epoch:  33\n",
      "2021-10-27 08:47:44.190153: train loss : -0.8308\n",
      "2021-10-27 08:48:03.179371: validation loss: -0.8557\n",
      "2021-10-27 08:48:03.183546: Average global foreground Dice: [0.872]\n",
      "2021-10-27 08:48:03.190126: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:48:03.690746: lr: 0.00688\n",
      "2021-10-27 08:48:03.793864: saving checkpoint...\n",
      "2021-10-27 08:48:05.652019: done, saving took 1.93 seconds\n",
      "2021-10-27 08:48:06.090887: This epoch took 335.189950 s\n",
      "\n",
      "2021-10-27 08:48:06.110717: \n",
      "epoch:  34\n",
      "2021-10-27 08:53:22.723152: train loss : -0.8362\n",
      "2021-10-27 08:53:41.399960: validation loss: -0.8503\n",
      "2021-10-27 08:53:41.405482: Average global foreground Dice: [0.8654]\n",
      "2021-10-27 08:53:41.411476: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:53:41.918862: lr: 0.006786\n",
      "2021-10-27 08:53:42.022581: saving checkpoint...\n",
      "2021-10-27 08:53:43.870504: done, saving took 1.92 seconds\n",
      "2021-10-27 08:53:44.163703: This epoch took 338.046275 s\n",
      "\n",
      "2021-10-27 08:53:44.181862: \n",
      "epoch:  35\n",
      "2021-10-27 08:58:56.906454: train loss : -0.8389\n",
      "2021-10-27 08:59:15.825960: validation loss: -0.8505\n",
      "2021-10-27 08:59:15.830220: Average global foreground Dice: [0.8693]\n",
      "2021-10-27 08:59:15.835989: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:59:16.347006: lr: 0.006692\n",
      "2021-10-27 08:59:16.452041: saving checkpoint...\n",
      "2021-10-27 08:59:18.326398: done, saving took 1.95 seconds\n",
      "2021-10-27 08:59:18.814306: This epoch took 334.625644 s\n",
      "\n",
      "2021-10-27 08:59:18.831297: \n",
      "epoch:  36\n",
      "2021-10-27 09:04:34.454200: train loss : -0.8353\n",
      "2021-10-27 09:04:54.948409: validation loss: -0.8458\n",
      "2021-10-27 09:04:54.952317: Average global foreground Dice: [0.8614]\n",
      "2021-10-27 09:04:54.958803: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:04:55.473415: lr: 0.006598\n",
      "2021-10-27 09:04:55.580785: saving checkpoint...\n",
      "2021-10-27 09:04:57.417821: done, saving took 1.91 seconds\n",
      "2021-10-27 09:04:58.008489: This epoch took 339.170347 s\n",
      "\n",
      "2021-10-27 09:04:58.029280: \n",
      "epoch:  37\n",
      "2021-10-27 09:10:18.239484: train loss : -0.8365\n",
      "2021-10-27 09:10:37.874238: validation loss: -0.8493\n",
      "2021-10-27 09:10:37.878478: Average global foreground Dice: [0.8668]\n",
      "2021-10-27 09:10:37.884964: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:10:38.397209: lr: 0.006504\n",
      "2021-10-27 09:10:38.503180: saving checkpoint...\n",
      "2021-10-27 09:10:40.275735: done, saving took 1.85 seconds\n",
      "2021-10-27 09:10:41.039956: This epoch took 343.004281 s\n",
      "\n",
      "2021-10-27 09:10:41.056958: \n",
      "epoch:  38\n",
      "2021-10-27 09:15:54.400546: train loss : -0.8401\n",
      "2021-10-27 09:16:13.758532: validation loss: -0.8556\n",
      "2021-10-27 09:16:13.762788: Average global foreground Dice: [0.8676]\n",
      "2021-10-27 09:16:13.770293: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:16:14.294311: lr: 0.006409\n",
      "2021-10-27 09:16:14.399675: saving checkpoint...\n",
      "2021-10-27 09:16:16.210426: done, saving took 1.89 seconds\n",
      "2021-10-27 09:16:16.863796: This epoch took 335.799948 s\n",
      "\n",
      "2021-10-27 09:16:16.881286: \n",
      "epoch:  39\n",
      "2021-10-27 09:21:35.847135: train loss : -0.8423\n",
      "2021-10-27 09:21:55.515813: validation loss: -0.8486\n",
      "2021-10-27 09:21:55.519841: Average global foreground Dice: [0.8649]\n",
      "2021-10-27 09:21:55.526444: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:21:56.073610: lr: 0.006314\n",
      "2021-10-27 09:21:56.133123: saving checkpoint...\n",
      "2021-10-27 09:21:57.924997: done, saving took 1.82 seconds\n",
      "2021-10-27 09:21:58.515623: This epoch took 341.627457 s\n",
      "\n",
      "2021-10-27 09:21:58.534461: \n",
      "epoch:  40\n",
      "2021-10-27 09:27:16.188045: train loss : -0.8395\n",
      "2021-10-27 09:27:36.453600: validation loss: -0.8526\n",
      "2021-10-27 09:27:36.457867: Average global foreground Dice: [0.8692]\n",
      "2021-10-27 09:27:36.463723: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:27:36.985073: lr: 0.00622\n",
      "2021-10-27 09:27:37.044210: saving checkpoint...\n",
      "2021-10-27 09:27:38.873144: done, saving took 1.86 seconds\n",
      "2021-10-27 09:27:40.101649: This epoch took 341.560426 s\n",
      "\n",
      "2021-10-27 09:27:40.118693: \n",
      "epoch:  41\n",
      "2021-10-27 09:32:55.478247: train loss : -0.8406\n",
      "2021-10-27 09:33:14.376339: validation loss: -0.8554\n",
      "2021-10-27 09:33:14.380378: Average global foreground Dice: [0.8709]\n",
      "2021-10-27 09:33:14.387162: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:33:14.875946: lr: 0.006125\n",
      "2021-10-27 09:33:14.937412: saving checkpoint...\n",
      "2021-10-27 09:33:16.744038: done, saving took 1.84 seconds\n",
      "2021-10-27 09:33:17.836694: This epoch took 337.711675 s\n",
      "\n",
      "2021-10-27 09:33:17.856574: \n",
      "epoch:  42\n",
      "2021-10-27 09:38:33.856787: train loss : -0.8397\n",
      "2021-10-27 09:38:54.555132: validation loss: -0.8461\n",
      "2021-10-27 09:38:54.560517: Average global foreground Dice: [0.8628]\n",
      "2021-10-27 09:38:54.566768: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:38:55.055655: lr: 0.00603\n",
      "2021-10-27 09:38:55.131332: saving checkpoint...\n",
      "2021-10-27 09:38:56.970124: done, saving took 1.89 seconds\n",
      "2021-10-27 09:38:57.802033: This epoch took 339.937121 s\n",
      "\n",
      "2021-10-27 09:38:57.810286: \n",
      "epoch:  43\n",
      "2021-10-27 09:44:16.618143: train loss : -0.8401\n",
      "2021-10-27 09:44:35.681386: validation loss: -0.8586\n",
      "2021-10-27 09:44:35.685620: Average global foreground Dice: [0.8693]\n",
      "2021-10-27 09:44:35.694182: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:44:36.178469: lr: 0.005934\n",
      "2021-10-27 09:44:36.253067: saving checkpoint...\n",
      "2021-10-27 09:44:38.081283: done, saving took 1.88 seconds\n",
      "2021-10-27 09:44:38.935454: This epoch took 341.118671 s\n",
      "\n",
      "2021-10-27 09:44:38.946573: \n",
      "epoch:  44\n",
      "2021-10-27 09:49:59.362663: train loss : -0.8366\n",
      "2021-10-27 09:50:21.833496: validation loss: -0.8642\n",
      "2021-10-27 09:50:22.169322: Average global foreground Dice: [0.8763]\n",
      "2021-10-27 09:50:22.332078: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:50:23.352062: lr: 0.005839\n",
      "2021-10-27 09:50:23.461989: saving checkpoint...\n",
      "2021-10-27 09:50:25.347451: done, saving took 1.94 seconds\n",
      "2021-10-27 09:50:26.399102: This epoch took 347.445382 s\n",
      "\n",
      "2021-10-27 09:50:26.407545: \n",
      "epoch:  45\n",
      "2021-10-27 09:55:42.006908: train loss : -0.8418\n",
      "2021-10-27 09:56:03.371500: validation loss: -0.8586\n",
      "2021-10-27 09:56:03.375653: Average global foreground Dice: [0.8705]\n",
      "2021-10-27 09:56:03.382355: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:56:03.886043: lr: 0.005743\n",
      "2021-10-27 09:56:03.937177: saving checkpoint...\n",
      "2021-10-27 09:56:05.828916: done, saving took 1.92 seconds\n",
      "2021-10-27 09:56:06.555861: This epoch took 340.142043 s\n",
      "\n",
      "2021-10-27 09:56:06.563987: \n",
      "epoch:  46\n",
      "2021-10-27 10:01:21.242340: train loss : -0.8410\n",
      "2021-10-27 10:01:40.812607: validation loss: -0.8565\n",
      "2021-10-27 10:01:40.816647: Average global foreground Dice: [0.8711]\n",
      "2021-10-27 10:01:40.823283: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:01:41.343675: lr: 0.005647\n",
      "2021-10-27 10:01:41.431736: saving checkpoint...\n",
      "2021-10-27 10:01:43.243643: done, saving took 1.84 seconds\n",
      "2021-10-27 10:01:44.168144: This epoch took 337.596297 s\n",
      "\n",
      "2021-10-27 10:01:44.176883: \n",
      "epoch:  47\n",
      "2021-10-27 10:06:58.675125: train loss : -0.8426\n",
      "2021-10-27 10:07:17.700844: validation loss: -0.8583\n",
      "2021-10-27 10:07:17.704784: Average global foreground Dice: [0.8715]\n",
      "2021-10-27 10:07:17.711589: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:07:18.211276: lr: 0.005551\n",
      "2021-10-27 10:07:18.260628: saving checkpoint...\n",
      "2021-10-27 10:07:20.046446: done, saving took 1.81 seconds\n",
      "2021-10-27 10:07:20.651901: This epoch took 336.468649 s\n",
      "\n",
      "2021-10-27 10:07:20.670126: \n",
      "epoch:  48\n",
      "2021-10-27 10:12:37.575590: train loss : -0.8417\n",
      "2021-10-27 10:12:57.308330: validation loss: -0.8542\n",
      "2021-10-27 10:12:57.312532: Average global foreground Dice: [0.8678]\n",
      "2021-10-27 10:12:57.318847: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:12:57.814358: lr: 0.005455\n",
      "2021-10-27 10:12:57.886767: saving checkpoint...\n",
      "2021-10-27 10:12:59.704076: done, saving took 1.85 seconds\n",
      "2021-10-27 10:13:01.290091: This epoch took 340.612979 s\n",
      "\n",
      "2021-10-27 10:13:01.298798: \n",
      "epoch:  49\n",
      "2021-10-27 10:18:15.784439: train loss : -0.8392\n",
      "2021-10-27 10:18:35.763544: validation loss: -0.8551\n",
      "2021-10-27 10:18:35.767477: Average global foreground Dice: [0.8723]\n",
      "2021-10-27 10:18:35.774469: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:18:36.274002: lr: 0.005359\n",
      "2021-10-27 10:18:36.296129: saving scheduled checkpoint file...\n",
      "2021-10-27 10:18:36.331500: saving checkpoint...\n",
      "2021-10-27 10:18:37.865548: done, saving took 1.56 seconds\n",
      "2021-10-27 10:18:38.747238: done\n",
      "2021-10-27 10:18:38.784700: saving checkpoint...\n",
      "2021-10-27 10:18:40.571849: done, saving took 1.82 seconds\n",
      "2021-10-27 10:18:41.576798: This epoch took 340.271051 s\n",
      "\n",
      "2021-10-27 10:18:41.585110: \n",
      "epoch:  50\n",
      "2021-10-27 10:23:57.736776: train loss : -0.8435\n",
      "2021-10-27 10:24:16.865106: validation loss: -0.8596\n",
      "2021-10-27 10:24:16.869249: Average global foreground Dice: [0.8737]\n",
      "2021-10-27 10:24:16.875302: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:24:17.362334: lr: 0.005262\n",
      "2021-10-27 10:24:17.410342: saving checkpoint...\n",
      "2021-10-27 10:24:19.192627: done, saving took 1.81 seconds\n",
      "2021-10-27 10:24:19.736643: This epoch took 338.145428 s\n",
      "\n",
      "2021-10-27 10:24:19.744684: \n",
      "epoch:  51\n",
      "2021-10-27 10:29:35.400601: train loss : -0.8451\n",
      "2021-10-27 10:29:56.722901: validation loss: -0.8519\n",
      "2021-10-27 10:29:56.726954: Average global foreground Dice: [0.8666]\n",
      "2021-10-27 10:29:56.733445: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:29:57.220289: lr: 0.005166\n",
      "2021-10-27 10:29:57.272928: saving checkpoint...\n",
      "2021-10-27 10:29:59.094363: done, saving took 1.85 seconds\n",
      "2021-10-27 10:29:59.799447: This epoch took 340.047708 s\n",
      "\n",
      "2021-10-27 10:29:59.807208: \n",
      "epoch:  52\n",
      "2021-10-27 10:35:12.137227: train loss : -0.8394\n",
      "2021-10-27 10:35:32.324435: validation loss: -0.8607\n",
      "2021-10-27 10:35:32.328475: Average global foreground Dice: [0.875]\n",
      "2021-10-27 10:35:32.334682: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:35:32.824584: lr: 0.005069\n",
      "2021-10-27 10:35:32.921238: saving checkpoint...\n",
      "2021-10-27 10:35:34.748378: done, saving took 1.89 seconds\n",
      "2021-10-27 10:35:35.424128: This epoch took 335.610118 s\n",
      "\n",
      "2021-10-27 10:35:35.445065: \n",
      "epoch:  53\n",
      "2021-10-27 10:40:55.006237: train loss : -0.8446\n",
      "2021-10-27 10:41:14.603211: validation loss: -0.8663\n",
      "2021-10-27 10:41:14.607493: Average global foreground Dice: [0.8786]\n",
      "2021-10-27 10:41:14.613998: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:41:15.151183: lr: 0.004971\n",
      "2021-10-27 10:41:15.255430: saving checkpoint...\n",
      "2021-10-27 10:41:17.051549: done, saving took 1.87 seconds\n",
      "2021-10-27 10:41:17.696322: This epoch took 342.244483 s\n",
      "\n",
      "2021-10-27 10:41:17.714064: \n",
      "epoch:  54\n",
      "2021-10-27 10:46:36.708224: train loss : -0.8465\n",
      "2021-10-27 10:46:58.016701: validation loss: -0.8630\n",
      "2021-10-27 10:46:58.020716: Average global foreground Dice: [0.8752]\n",
      "2021-10-27 10:46:58.027166: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:46:58.533263: lr: 0.004874\n",
      "2021-10-27 10:46:58.643459: saving checkpoint...\n",
      "2021-10-27 10:47:00.428953: done, saving took 1.86 seconds\n",
      "2021-10-27 10:47:01.179836: This epoch took 343.458914 s\n",
      "\n",
      "2021-10-27 10:47:01.197492: \n",
      "epoch:  55\n",
      "2021-10-27 10:52:11.688329: train loss : -0.8486\n",
      "2021-10-27 10:52:30.616707: validation loss: -0.8637\n",
      "2021-10-27 10:52:30.620711: Average global foreground Dice: [0.8761]\n",
      "2021-10-27 10:52:30.627906: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:52:31.145968: lr: 0.004776\n",
      "2021-10-27 10:52:31.248901: saving checkpoint...\n",
      "2021-10-27 10:52:33.025600: done, saving took 1.85 seconds\n",
      "2021-10-27 10:52:33.984212: This epoch took 332.780323 s\n",
      "\n",
      "2021-10-27 10:52:34.001855: \n",
      "epoch:  56\n",
      "2021-10-27 10:57:45.084346: train loss : -0.8498\n",
      "2021-10-27 10:58:04.003546: validation loss: -0.8642\n",
      "2021-10-27 10:58:04.007637: Average global foreground Dice: [0.879]\n",
      "2021-10-27 10:58:04.014064: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:58:04.537251: lr: 0.004679\n",
      "2021-10-27 10:58:04.646013: saving checkpoint...\n",
      "2021-10-27 10:58:06.455575: done, saving took 1.88 seconds\n",
      "2021-10-27 10:58:07.097543: This epoch took 333.089400 s\n",
      "\n",
      "2021-10-27 10:58:07.113977: \n",
      "epoch:  57\n",
      "2021-10-27 11:03:23.271069: train loss : -0.8520\n",
      "2021-10-27 11:03:43.366331: validation loss: -0.8629\n",
      "2021-10-27 11:03:43.370458: Average global foreground Dice: [0.8747]\n",
      "2021-10-27 11:03:43.376849: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:03:43.900257: lr: 0.004581\n",
      "2021-10-27 11:03:44.002676: saving checkpoint...\n",
      "2021-10-27 11:03:45.889653: done, saving took 1.96 seconds\n",
      "2021-10-27 11:03:46.535783: This epoch took 339.415341 s\n",
      "\n",
      "2021-10-27 11:03:46.555264: \n",
      "epoch:  58\n",
      "2021-10-27 11:08:58.915848: train loss : -0.8456\n",
      "2021-10-27 11:09:18.097389: validation loss: -0.8597\n",
      "2021-10-27 11:09:18.101349: Average global foreground Dice: [0.8738]\n",
      "2021-10-27 11:09:18.108310: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:09:18.616735: lr: 0.004482\n",
      "2021-10-27 11:09:18.721861: saving checkpoint...\n",
      "2021-10-27 11:09:20.569794: done, saving took 1.92 seconds\n",
      "2021-10-27 11:09:21.185719: This epoch took 334.623189 s\n",
      "\n",
      "2021-10-27 11:09:21.203407: \n",
      "epoch:  59\n",
      "2021-10-27 11:14:38.850753: train loss : -0.8394\n",
      "2021-10-27 11:14:59.612266: validation loss: -0.8630\n",
      "2021-10-27 11:14:59.616345: Average global foreground Dice: [0.8748]\n",
      "2021-10-27 11:14:59.623535: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:15:00.133288: lr: 0.004384\n",
      "2021-10-27 11:15:00.231461: saving checkpoint...\n",
      "2021-10-27 11:15:02.043624: done, saving took 1.88 seconds\n",
      "2021-10-27 11:15:02.641912: This epoch took 341.431850 s\n",
      "\n",
      "2021-10-27 11:15:02.662317: \n",
      "epoch:  60\n",
      "2021-10-27 11:20:18.192627: train loss : -0.8507\n",
      "2021-10-27 11:20:37.392681: validation loss: -0.8636\n",
      "2021-10-27 11:20:37.396857: Average global foreground Dice: [0.8753]\n",
      "2021-10-27 11:20:37.402840: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:20:37.914947: lr: 0.004285\n",
      "2021-10-27 11:20:37.996358: saving checkpoint...\n",
      "2021-10-27 11:20:39.801872: done, saving took 1.86 seconds\n",
      "2021-10-27 11:20:40.527262: This epoch took 337.858588 s\n",
      "\n",
      "2021-10-27 11:20:40.546200: \n",
      "epoch:  61\n",
      "2021-10-27 11:25:52.234976: train loss : -0.8538\n",
      "2021-10-27 11:26:11.196808: validation loss: -0.8568\n",
      "2021-10-27 11:26:11.200964: Average global foreground Dice: [0.8709]\n",
      "2021-10-27 11:26:11.206595: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:26:11.723978: lr: 0.004186\n",
      "2021-10-27 11:26:11.753769: This epoch took 331.199540 s\n",
      "\n",
      "2021-10-27 11:26:11.760295: \n",
      "epoch:  62\n",
      "2021-10-27 11:31:27.557966: train loss : -0.8514\n",
      "2021-10-27 11:31:51.042056: validation loss: -0.8612\n",
      "2021-10-27 11:31:51.148701: Average global foreground Dice: [0.8713]\n",
      "2021-10-27 11:31:51.155424: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:31:52.089945: lr: 0.004087\n",
      "2021-10-27 11:31:52.119209: This epoch took 340.352648 s\n",
      "\n",
      "2021-10-27 11:31:52.125203: \n",
      "epoch:  63\n",
      "2021-10-27 11:37:07.011630: train loss : -0.8480\n",
      "2021-10-27 11:37:25.908466: validation loss: -0.8684\n",
      "2021-10-27 11:37:25.913870: Average global foreground Dice: [0.8809]\n",
      "2021-10-27 11:37:25.921167: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:37:26.425206: lr: 0.003987\n",
      "2021-10-27 11:37:26.513384: saving checkpoint...\n",
      "2021-10-27 11:37:28.326210: done, saving took 1.87 seconds\n",
      "2021-10-27 11:37:28.941237: This epoch took 336.810110 s\n",
      "\n",
      "2021-10-27 11:37:28.958987: \n",
      "epoch:  64\n",
      "2021-10-27 11:42:48.670689: train loss : -0.8504\n",
      "2021-10-27 11:43:10.207015: validation loss: -0.8611\n",
      "2021-10-27 11:43:10.211115: Average global foreground Dice: [0.8733]\n",
      "2021-10-27 11:43:10.217436: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:43:10.781179: lr: 0.003887\n",
      "2021-10-27 11:43:10.841158: saving checkpoint...\n",
      "2021-10-27 11:43:12.632288: done, saving took 1.82 seconds\n",
      "2021-10-27 11:43:13.226784: This epoch took 344.261916 s\n",
      "\n",
      "2021-10-27 11:43:13.245499: \n",
      "epoch:  65\n",
      "2021-10-27 11:48:27.202197: train loss : -0.8508\n",
      "2021-10-27 11:48:47.446159: validation loss: -0.8677\n",
      "2021-10-27 11:48:47.450511: Average global foreground Dice: [0.8774]\n",
      "2021-10-27 11:48:47.456847: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:48:47.948381: lr: 0.003787\n",
      "2021-10-27 11:48:48.005176: saving checkpoint...\n",
      "2021-10-27 11:48:49.815933: done, saving took 1.84 seconds\n",
      "2021-10-27 11:48:50.504112: This epoch took 337.251177 s\n",
      "\n",
      "2021-10-27 11:48:50.522283: \n",
      "epoch:  66\n",
      "2021-10-27 11:54:03.555506: train loss : -0.8562\n",
      "2021-10-27 11:54:22.258310: validation loss: -0.8702\n",
      "2021-10-27 11:54:22.262454: Average global foreground Dice: [0.8829]\n",
      "2021-10-27 11:54:22.268714: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:54:22.760472: lr: 0.003687\n",
      "2021-10-27 11:54:22.819736: saving checkpoint...\n",
      "2021-10-27 11:54:24.596887: done, saving took 1.81 seconds\n",
      "2021-10-27 11:54:25.232934: This epoch took 334.704103 s\n",
      "\n",
      "2021-10-27 11:54:25.249432: \n",
      "epoch:  67\n",
      "2021-10-27 11:59:42.157796: train loss : -0.8541\n",
      "2021-10-27 12:00:02.854938: validation loss: -0.8631\n",
      "2021-10-27 12:00:02.861270: Average global foreground Dice: [0.8757]\n",
      "2021-10-27 12:00:02.870945: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:00:03.371450: lr: 0.003586\n",
      "2021-10-27 12:00:03.431118: saving checkpoint...\n",
      "2021-10-27 12:00:05.202545: done, saving took 1.80 seconds\n",
      "2021-10-27 12:00:05.837624: This epoch took 340.580344 s\n",
      "\n",
      "2021-10-27 12:00:05.855203: \n",
      "epoch:  68\n",
      "2021-10-27 12:05:24.565482: train loss : -0.8487\n",
      "2021-10-27 12:05:44.529098: validation loss: -0.8683\n",
      "2021-10-27 12:05:44.533028: Average global foreground Dice: [0.8801]\n",
      "2021-10-27 12:05:44.538918: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:05:45.037280: lr: 0.003485\n",
      "2021-10-27 12:05:45.096524: saving checkpoint...\n",
      "2021-10-27 12:05:46.892235: done, saving took 1.82 seconds\n",
      "2021-10-27 12:05:47.523133: This epoch took 341.661388 s\n",
      "\n",
      "2021-10-27 12:05:47.540433: \n",
      "epoch:  69\n",
      "2021-10-27 12:11:03.057410: train loss : -0.8538\n",
      "2021-10-27 12:11:23.696167: validation loss: -0.8691\n",
      "2021-10-27 12:11:23.700324: Average global foreground Dice: [0.8804]\n",
      "2021-10-27 12:11:23.706676: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:11:24.220681: lr: 0.003384\n",
      "2021-10-27 12:11:24.309613: saving checkpoint...\n",
      "2021-10-27 12:11:26.155128: done, saving took 1.91 seconds\n",
      "2021-10-27 12:11:26.897264: This epoch took 339.350504 s\n",
      "\n",
      "2021-10-27 12:11:26.914481: \n",
      "epoch:  70\n",
      "2021-10-27 12:16:43.645449: train loss : -0.8538\n",
      "2021-10-27 12:17:03.670887: validation loss: -0.8704\n",
      "2021-10-27 12:17:03.676153: Average global foreground Dice: [0.8806]\n",
      "2021-10-27 12:17:03.681938: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:17:04.252237: lr: 0.003282\n",
      "2021-10-27 12:17:04.314000: saving checkpoint...\n",
      "2021-10-27 12:17:06.122631: done, saving took 1.84 seconds\n",
      "2021-10-27 12:17:06.763932: This epoch took 339.842589 s\n",
      "\n",
      "2021-10-27 12:17:06.782110: \n",
      "epoch:  71\n",
      "2021-10-27 12:22:22.170742: train loss : -0.8540\n",
      "2021-10-27 12:22:42.626244: validation loss: -0.8631\n",
      "2021-10-27 12:22:42.630238: Average global foreground Dice: [0.8781]\n",
      "2021-10-27 12:22:42.636979: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:22:43.142190: lr: 0.00318\n",
      "2021-10-27 12:22:43.192255: saving checkpoint...\n",
      "2021-10-27 12:22:45.027963: done, saving took 1.86 seconds\n",
      "2021-10-27 12:22:45.679294: This epoch took 338.891024 s\n",
      "\n",
      "2021-10-27 12:22:45.687963: \n",
      "epoch:  72\n",
      "2021-10-27 12:28:01.945551: train loss : -0.8545\n",
      "2021-10-27 12:28:21.584784: validation loss: -0.8683\n",
      "2021-10-27 12:28:21.589278: Average global foreground Dice: [0.8823]\n",
      "2021-10-27 12:28:21.595505: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:28:22.093279: lr: 0.003078\n",
      "2021-10-27 12:28:22.142061: saving checkpoint...\n",
      "2021-10-27 12:28:23.908866: done, saving took 1.80 seconds\n",
      "2021-10-27 12:28:24.510803: This epoch took 338.816025 s\n",
      "\n",
      "2021-10-27 12:28:24.518760: \n",
      "epoch:  73\n",
      "2021-10-27 12:33:37.588612: train loss : -0.8574\n",
      "2021-10-27 12:33:56.867777: validation loss: -0.8723\n",
      "2021-10-27 12:33:56.872149: Average global foreground Dice: [0.8845]\n",
      "2021-10-27 12:33:56.877821: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:33:57.383963: lr: 0.002975\n",
      "2021-10-27 12:33:57.433038: saving checkpoint...\n",
      "2021-10-27 12:33:59.212573: done, saving took 1.81 seconds\n",
      "2021-10-27 12:33:59.743454: This epoch took 335.218347 s\n",
      "\n",
      "2021-10-27 12:33:59.752434: \n",
      "epoch:  74\n",
      "2021-10-27 12:39:11.540598: train loss : -0.8568\n",
      "2021-10-27 12:39:30.190633: validation loss: -0.8713\n",
      "2021-10-27 12:39:30.194885: Average global foreground Dice: [0.8838]\n",
      "2021-10-27 12:39:30.201631: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:39:30.694888: lr: 0.002872\n",
      "2021-10-27 12:39:30.748963: saving checkpoint...\n",
      "2021-10-27 12:39:32.531494: done, saving took 1.81 seconds\n",
      "2021-10-27 12:39:32.757906: This epoch took 332.999312 s\n",
      "\n",
      "2021-10-27 12:39:32.766116: \n",
      "epoch:  75\n",
      "2021-10-27 12:44:45.755841: train loss : -0.8576\n",
      "2021-10-27 12:45:04.724397: validation loss: -0.8686\n",
      "2021-10-27 12:45:04.728333: Average global foreground Dice: [0.8813]\n",
      "2021-10-27 12:45:04.734457: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:45:05.243610: lr: 0.002768\n",
      "2021-10-27 12:45:05.333264: saving checkpoint...\n",
      "2021-10-27 12:45:07.161466: done, saving took 1.89 seconds\n",
      "2021-10-27 12:45:07.546731: This epoch took 334.774636 s\n",
      "\n",
      "2021-10-27 12:45:07.554703: \n",
      "epoch:  76\n",
      "2021-10-27 12:50:23.750068: train loss : -0.8564\n",
      "2021-10-27 12:50:43.216377: validation loss: -0.8755\n",
      "2021-10-27 12:50:43.220494: Average global foreground Dice: [0.8855]\n",
      "2021-10-27 12:50:43.225855: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:50:43.820287: lr: 0.002664\n",
      "2021-10-27 12:50:43.867823: saving checkpoint...\n",
      "2021-10-27 12:50:45.671129: done, saving took 1.83 seconds\n",
      "2021-10-27 12:50:46.267259: This epoch took 338.706201 s\n",
      "\n",
      "2021-10-27 12:50:46.275101: \n",
      "epoch:  77\n",
      "2021-10-27 12:56:01.783557: train loss : -0.8562\n",
      "2021-10-27 12:56:21.501432: validation loss: -0.8742\n",
      "2021-10-27 12:56:21.505505: Average global foreground Dice: [0.8858]\n",
      "2021-10-27 12:56:21.512621: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:56:22.016219: lr: 0.00256\n",
      "2021-10-27 12:56:22.068063: saving checkpoint...\n",
      "2021-10-27 12:56:23.869725: done, saving took 1.83 seconds\n",
      "2021-10-27 12:56:24.456137: This epoch took 338.174575 s\n",
      "\n",
      "2021-10-27 12:56:24.464145: \n",
      "epoch:  78\n",
      "2021-10-27 13:01:36.057728: train loss : -0.8594\n",
      "2021-10-27 13:01:57.203727: validation loss: -0.8703\n",
      "2021-10-27 13:01:57.207708: Average global foreground Dice: [0.8795]\n",
      "2021-10-27 13:01:57.213690: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:01:57.734782: lr: 0.002455\n",
      "2021-10-27 13:01:57.757955: This epoch took 333.287396 s\n",
      "\n",
      "2021-10-27 13:01:57.764135: \n",
      "epoch:  79\n",
      "2021-10-27 13:07:08.686100: train loss : -0.8602\n",
      "2021-10-27 13:07:27.360962: validation loss: -0.8764\n",
      "2021-10-27 13:07:27.365032: Average global foreground Dice: [0.8902]\n",
      "2021-10-27 13:07:27.371476: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:07:27.877257: lr: 0.002349\n",
      "2021-10-27 13:07:27.941766: saving checkpoint...\n",
      "2021-10-27 13:07:29.732624: done, saving took 1.82 seconds\n",
      "2021-10-27 13:07:29.999948: This epoch took 332.228988 s\n",
      "\n",
      "2021-10-27 13:07:30.008737: \n",
      "epoch:  80\n",
      "2021-10-27 13:12:43.658887: train loss : -0.8614\n",
      "2021-10-27 13:13:02.349518: validation loss: -0.8735\n",
      "2021-10-27 13:13:02.354912: Average global foreground Dice: [0.8852]\n",
      "2021-10-27 13:13:02.360782: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:13:02.863518: lr: 0.002243\n",
      "2021-10-27 13:13:02.923543: saving checkpoint...\n",
      "2021-10-27 13:13:04.697313: done, saving took 1.80 seconds\n",
      "2021-10-27 13:13:04.970594: This epoch took 334.955056 s\n",
      "\n",
      "2021-10-27 13:13:04.988238: \n",
      "epoch:  81\n",
      "2021-10-27 13:18:16.310612: train loss : -0.8632\n",
      "2021-10-27 13:18:35.361326: validation loss: -0.8632\n",
      "2021-10-27 13:18:35.365278: Average global foreground Dice: [0.875]\n",
      "2021-10-27 13:18:35.371450: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:18:35.865892: lr: 0.002137\n",
      "2021-10-27 13:18:35.900213: This epoch took 330.905383 s\n",
      "\n",
      "2021-10-27 13:18:35.906332: \n",
      "epoch:  82\n",
      "2021-10-27 13:23:54.874989: train loss : -0.8605\n",
      "2021-10-27 13:24:13.583668: validation loss: -0.8740\n",
      "2021-10-27 13:24:13.587970: Average global foreground Dice: [0.8872]\n",
      "2021-10-27 13:24:13.595030: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:24:14.091373: lr: 0.00203\n",
      "2021-10-27 13:24:14.156817: saving checkpoint...\n",
      "2021-10-27 13:24:16.029772: done, saving took 1.91 seconds\n",
      "2021-10-27 13:24:16.624587: This epoch took 340.712164 s\n",
      "\n",
      "2021-10-27 13:24:16.641407: \n",
      "epoch:  83\n",
      "2021-10-27 13:29:30.581821: train loss : -0.8617\n",
      "2021-10-27 13:29:49.317184: validation loss: -0.8743\n",
      "2021-10-27 13:29:49.321404: Average global foreground Dice: [0.8863]\n",
      "2021-10-27 13:29:49.327234: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:29:49.819613: lr: 0.001922\n",
      "2021-10-27 13:29:49.882658: saving checkpoint...\n",
      "2021-10-27 13:29:51.664496: done, saving took 1.81 seconds\n",
      "2021-10-27 13:29:52.297091: This epoch took 335.648651 s\n",
      "\n",
      "2021-10-27 13:29:52.313680: \n",
      "epoch:  84\n",
      "2021-10-27 13:35:08.645694: train loss : -0.8609\n",
      "2021-10-27 13:35:28.996273: validation loss: -0.8756\n",
      "2021-10-27 13:35:29.000255: Average global foreground Dice: [0.8879]\n",
      "2021-10-27 13:35:29.006764: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:35:29.496705: lr: 0.001813\n",
      "2021-10-27 13:35:29.558200: saving checkpoint...\n",
      "2021-10-27 13:35:31.365227: done, saving took 1.84 seconds\n",
      "2021-10-27 13:35:32.068063: This epoch took 339.748055 s\n",
      "\n",
      "2021-10-27 13:35:32.086602: \n",
      "epoch:  85\n",
      "2021-10-27 13:40:44.242605: train loss : -0.8619\n",
      "2021-10-27 13:41:04.068329: validation loss: -0.8791\n",
      "2021-10-27 13:41:04.073794: Average global foreground Dice: [0.8904]\n",
      "2021-10-27 13:41:04.079887: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:41:04.581499: lr: 0.001704\n",
      "2021-10-27 13:41:04.642407: saving checkpoint...\n",
      "2021-10-27 13:41:06.465482: done, saving took 1.85 seconds\n",
      "2021-10-27 13:41:07.080846: This epoch took 334.987244 s\n",
      "\n",
      "2021-10-27 13:41:07.097704: \n",
      "epoch:  86\n",
      "2021-10-27 13:46:19.090565: train loss : -0.8609\n",
      "2021-10-27 13:46:37.827404: validation loss: -0.8751\n",
      "2021-10-27 13:46:37.831453: Average global foreground Dice: [0.8851]\n",
      "2021-10-27 13:46:37.837800: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:46:38.335802: lr: 0.001594\n",
      "2021-10-27 13:46:38.432265: saving checkpoint...\n",
      "2021-10-27 13:46:40.237931: done, saving took 1.86 seconds\n",
      "2021-10-27 13:46:40.852673: This epoch took 333.748409 s\n",
      "\n",
      "2021-10-27 13:46:40.869420: \n",
      "epoch:  87\n",
      "2021-10-27 13:51:58.652572: train loss : -0.8624\n",
      "2021-10-27 13:52:19.985733: validation loss: -0.8732\n",
      "2021-10-27 13:52:20.349074: Average global foreground Dice: [0.8875]\n",
      "2021-10-27 13:52:20.555278: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:52:21.499212: lr: 0.001483\n",
      "2021-10-27 13:52:21.613147: saving checkpoint...\n",
      "2021-10-27 13:52:23.546669: done, saving took 2.01 seconds\n",
      "2021-10-27 13:52:24.192923: This epoch took 343.317061 s\n",
      "\n",
      "2021-10-27 13:52:24.209433: \n",
      "epoch:  88\n",
      "2021-10-27 13:57:41.732277: train loss : -0.8616\n",
      "2021-10-27 13:58:02.602819: validation loss: -0.8777\n",
      "2021-10-27 13:58:02.607138: Average global foreground Dice: [0.8905]\n",
      "2021-10-27 13:58:02.614340: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:58:03.140560: lr: 0.001372\n",
      "2021-10-27 13:58:03.245350: saving checkpoint...\n",
      "2021-10-27 13:58:05.124903: done, saving took 1.95 seconds\n",
      "2021-10-27 13:58:05.700750: This epoch took 341.484436 s\n",
      "\n",
      "2021-10-27 13:58:05.718751: \n",
      "epoch:  89\n",
      "2021-10-27 14:03:18.176409: train loss : -0.8620\n",
      "2021-10-27 14:03:37.700831: validation loss: -0.8815\n",
      "2021-10-27 14:03:37.705068: Average global foreground Dice: [0.8919]\n",
      "2021-10-27 14:03:37.711113: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:03:38.225982: lr: 0.001259\n",
      "2021-10-27 14:03:38.336688: saving checkpoint...\n",
      "2021-10-27 14:03:40.164346: done, saving took 1.90 seconds\n",
      "2021-10-27 14:03:41.016505: This epoch took 335.290967 s\n",
      "\n",
      "2021-10-27 14:03:41.035963: \n",
      "epoch:  90\n",
      "2021-10-27 14:08:52.249756: train loss : -0.8653\n",
      "2021-10-27 14:09:13.614411: validation loss: -0.8812\n",
      "2021-10-27 14:09:13.618294: Average global foreground Dice: [0.8897]\n",
      "2021-10-27 14:09:13.624521: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:09:14.133039: lr: 0.001145\n",
      "2021-10-27 14:09:14.254064: saving checkpoint...\n",
      "2021-10-27 14:09:16.093049: done, saving took 1.90 seconds\n",
      "2021-10-27 14:09:16.844113: This epoch took 335.801644 s\n",
      "\n",
      "2021-10-27 14:09:16.862835: \n",
      "epoch:  91\n",
      "2021-10-27 14:14:29.073007: train loss : -0.8642\n",
      "2021-10-27 14:14:47.938326: validation loss: -0.8793\n",
      "2021-10-27 14:14:47.942386: Average global foreground Dice: [0.8922]\n",
      "2021-10-27 14:14:47.976056: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:14:48.481653: lr: 0.00103\n",
      "2021-10-27 14:14:48.583026: saving checkpoint...\n",
      "2021-10-27 14:14:50.443642: done, saving took 1.92 seconds\n",
      "2021-10-27 14:14:51.357242: This epoch took 334.487264 s\n",
      "\n",
      "2021-10-27 14:14:51.378350: \n",
      "epoch:  92\n",
      "2021-10-27 14:20:05.506632: train loss : -0.8660\n",
      "2021-10-27 14:20:26.070569: validation loss: -0.8811\n",
      "2021-10-27 14:20:26.074580: Average global foreground Dice: [0.8938]\n",
      "2021-10-27 14:20:26.081363: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:20:26.583857: lr: 0.000913\n",
      "2021-10-27 14:20:26.673201: saving checkpoint...\n",
      "2021-10-27 14:20:28.515493: done, saving took 1.90 seconds\n",
      "2021-10-27 14:20:29.397102: This epoch took 338.011880 s\n",
      "\n",
      "2021-10-27 14:20:29.415392: \n",
      "epoch:  93\n",
      "2021-10-27 14:25:41.560245: train loss : -0.8649\n",
      "2021-10-27 14:26:01.539243: validation loss: -0.8791\n",
      "2021-10-27 14:26:01.543417: Average global foreground Dice: [0.893]\n",
      "2021-10-27 14:26:01.550516: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:26:02.043810: lr: 0.000795\n",
      "2021-10-27 14:26:02.110137: saving checkpoint...\n",
      "2021-10-27 14:26:03.957816: done, saving took 1.88 seconds\n",
      "2021-10-27 14:26:04.650072: This epoch took 335.227920 s\n",
      "\n",
      "2021-10-27 14:26:04.669096: \n",
      "epoch:  94\n",
      "2021-10-27 14:31:24.676731: train loss : -0.8671\n",
      "2021-10-27 14:31:44.173751: validation loss: -0.8787\n",
      "2021-10-27 14:31:44.177874: Average global foreground Dice: [0.8883]\n",
      "2021-10-27 14:31:44.184414: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:31:44.693813: lr: 0.000675\n",
      "2021-10-27 14:31:44.760379: saving checkpoint...\n",
      "2021-10-27 14:31:46.668366: done, saving took 1.94 seconds\n",
      "2021-10-27 14:31:47.374394: This epoch took 342.698364 s\n",
      "\n",
      "2021-10-27 14:31:47.393735: \n",
      "epoch:  95\n",
      "2021-10-27 14:37:02.372414: train loss : -0.8666\n",
      "2021-10-27 14:37:22.570345: validation loss: -0.8764\n",
      "2021-10-27 14:37:22.577744: Average global foreground Dice: [0.8895]\n",
      "2021-10-27 14:37:22.587365: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:37:23.085510: lr: 0.000552\n",
      "2021-10-27 14:37:23.198147: saving checkpoint...\n",
      "2021-10-27 14:37:25.043677: done, saving took 1.92 seconds\n",
      "2021-10-27 14:37:25.717177: This epoch took 338.316833 s\n",
      "\n",
      "2021-10-27 14:37:25.736930: \n",
      "epoch:  96\n",
      "2021-10-27 14:42:41.746002: train loss : -0.8658\n",
      "2021-10-27 14:43:02.274456: validation loss: -0.8824\n",
      "2021-10-27 14:43:02.278812: Average global foreground Dice: [0.893]\n",
      "2021-10-27 14:43:02.285393: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:43:02.801658: lr: 0.000426\n",
      "2021-10-27 14:43:02.894938: saving checkpoint...\n",
      "2021-10-27 14:43:04.760830: done, saving took 1.94 seconds\n",
      "2021-10-27 14:43:05.407601: This epoch took 339.663821 s\n",
      "\n",
      "2021-10-27 14:43:05.415432: \n",
      "epoch:  97\n",
      "2021-10-27 14:48:27.766203: train loss : -0.8642\n",
      "2021-10-27 14:48:48.991311: validation loss: -0.8798\n",
      "2021-10-27 14:48:49.013809: Average global foreground Dice: [0.8912]\n",
      "2021-10-27 14:48:49.022711: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:48:49.593659: lr: 0.000296\n",
      "2021-10-27 14:48:49.687172: saving checkpoint...\n",
      "2021-10-27 14:48:52.412832: done, saving took 2.78 seconds\n",
      "2021-10-27 14:48:53.080795: This epoch took 347.658721 s\n",
      "\n",
      "2021-10-27 14:48:53.089255: \n",
      "epoch:  98\n",
      "2021-10-27 14:54:06.714407: train loss : -0.8654\n",
      "2021-10-27 14:54:25.596044: validation loss: -0.8822\n",
      "2021-10-27 14:54:25.600147: Average global foreground Dice: [0.8906]\n",
      "2021-10-27 14:54:25.608914: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:54:26.114146: lr: 0.000158\n",
      "2021-10-27 14:54:26.200789: saving checkpoint...\n",
      "2021-10-27 14:54:28.042169: done, saving took 1.90 seconds\n",
      "2021-10-27 14:54:28.676009: This epoch took 335.576707 s\n",
      "\n",
      "2021-10-27 14:54:28.685182: \n",
      "epoch:  99\n",
      "2021-10-27 14:59:48.362208: train loss : -0.8679\n",
      "2021-10-27 15:00:08.883269: validation loss: -0.8766\n",
      "2021-10-27 15:00:08.888633: Average global foreground Dice: [0.8892]\n",
      "2021-10-27 15:00:08.897219: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 15:00:09.413488: lr: 0.0\n",
      "2021-10-27 15:00:09.457190: saving scheduled checkpoint file...\n",
      "2021-10-27 15:00:09.543148: saving checkpoint...\n",
      "2021-10-27 15:00:11.348438: done, saving took 1.87 seconds\n",
      "2021-10-27 15:00:12.005667: done\n",
      "2021-10-27 15:00:12.042743: saving checkpoint...\n",
      "2021-10-27 15:00:13.834539: done, saving took 1.82 seconds\n",
      "2021-10-27 15:00:14.481227: This epoch took 345.786126 s\n",
      "\n",
      "2021-10-27 15:00:14.518106: saving checkpoint...\n",
      "2021-10-27 15:00:16.030301: done, saving took 1.54 seconds\n",
      "23090557_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090558_20120 (3, 263, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 263, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 7], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090559_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090560_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090562_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090563_20151 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090564_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090566_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090567_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090568_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090569_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090571_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090584_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090589_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090590_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090592_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090593_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090596_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090597_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090599_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090600_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090603_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090604_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090607_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090608_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090609_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090614_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090615_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090616_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090617_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090619_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090620_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090621_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090627_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090628_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090629_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090631_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090634_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090635_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090636_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090637_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090640_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090644_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090646_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-27 15:17:38.215724: finished prediction\n",
      "2021-10-27 15:17:38.223844: evaluation of raw predictions\n",
      "2021-10-27 15:17:43.813130: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8937433343947685\n",
      "after:  0.8937433343947685\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_Dice.nnUNetTrainerV2_Loss_Dice'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-28 01:53:51.095200: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-28 01:54:02.344412: Unable to plot network architecture:\n",
      "2021-10-28 01:54:02.451298: No module named 'hiddenlayer'\n",
      "2021-10-28 01:54:02.504593: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-28 01:54:02.572459: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-28 01:54:02.749940: \n",
      "\n",
      "2021-10-28 01:54:02.948434: \n",
      "epoch:  0\n",
      "2021-10-28 01:57:11.151170: train loss : -0.0051\n",
      "2021-10-28 01:57:25.051175: validation loss: -0.0081\n",
      "2021-10-28 01:57:25.055552: Average global foreground Dice: [0.0114]\n",
      "2021-10-28 01:57:25.062294: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 01:57:25.586056: lr: 0.00991\n",
      "2021-10-28 01:57:25.612901: This epoch took 202.460560 s\n",
      "\n",
      "2021-10-28 01:57:25.619299: \n",
      "epoch:  1\n",
      "2021-10-28 02:00:38.093419: train loss : -0.1116\n",
      "2021-10-28 02:00:52.148162: validation loss: -0.5402\n",
      "2021-10-28 02:00:52.152371: Average global foreground Dice: [0.688]\n",
      "2021-10-28 02:00:52.158278: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 02:00:52.652710: lr: 0.00982\n",
      "2021-10-28 02:00:52.720771: saving checkpoint...\n",
      "2021-10-28 02:00:53.661904: done, saving took 0.98 seconds\n",
      "2021-10-28 02:00:54.079526: This epoch took 208.454072 s\n",
      "\n",
      "2021-10-28 02:00:54.097410: \n",
      "epoch:  2\n",
      "2021-10-28 02:04:03.180589: train loss : -0.5923\n",
      "2021-10-28 02:04:17.268249: validation loss: -0.7599\n",
      "2021-10-28 02:04:17.275498: Average global foreground Dice: [0.8041]\n",
      "2021-10-28 02:04:17.278843: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 02:04:17.852598: lr: 0.00973\n",
      "2021-10-28 02:04:17.923850: saving checkpoint...\n",
      "2021-10-28 02:04:18.941175: done, saving took 1.06 seconds\n",
      "2021-10-28 02:04:19.131834: This epoch took 205.027268 s\n",
      "\n",
      "2021-10-28 02:04:19.146086: \n",
      "epoch:  3\n",
      "2021-10-28 02:07:26.712565: train loss : -0.7649\n",
      "2021-10-28 02:07:40.816766: validation loss: -0.8205\n",
      "2021-10-28 02:07:40.821002: Average global foreground Dice: [0.8339]\n",
      "2021-10-28 02:07:40.827735: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 02:07:41.392129: lr: 0.009639\n",
      "2021-10-28 02:07:41.456141: saving checkpoint...\n",
      "2021-10-28 02:07:42.497646: done, saving took 1.08 seconds\n",
      "2021-10-28 02:07:43.334258: This epoch took 204.181805 s\n",
      "\n",
      "2021-10-28 02:07:43.342650: \n",
      "epoch:  4\n",
      "2021-10-28 02:10:50.365819: train loss : -0.7963\n",
      "2021-10-28 02:11:04.506486: validation loss: -0.8313\n",
      "2021-10-28 02:11:04.510818: Average global foreground Dice: [0.8426]\n",
      "2021-10-28 02:11:04.516732: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 02:11:05.055273: lr: 0.009549\n",
      "2021-10-28 02:11:05.117977: saving checkpoint...\n",
      "2021-10-28 02:11:06.127008: done, saving took 1.05 seconds\n",
      "2021-10-28 02:11:07.408028: This epoch took 204.057305 s\n",
      "\n",
      "2021-10-28 02:11:07.420728: \n",
      "epoch:  5\n",
      "2021-10-28 02:14:14.547313: train loss : -0.8093\n",
      "2021-10-28 02:14:28.674917: validation loss: -0.8402\n",
      "2021-10-28 02:14:28.680661: Average global foreground Dice: [0.8498]\n",
      "2021-10-28 02:14:28.686058: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 02:14:29.203979: lr: 0.009458\n",
      "2021-10-28 02:14:29.240843: saving checkpoint...\n",
      "2021-10-28 02:14:30.250666: done, saving took 1.03 seconds\n",
      "2021-10-28 02:14:30.486506: This epoch took 203.059918 s\n",
      "\n",
      "2021-10-28 02:14:30.495426: \n",
      "epoch:  6\n",
      "2021-10-28 02:17:37.895125: train loss : -0.8183\n",
      "2021-10-28 02:17:52.020162: validation loss: -0.8446\n",
      "2021-10-28 02:17:52.026300: Average global foreground Dice: [0.8507]\n",
      "2021-10-28 02:17:52.032807: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 02:17:52.564784: lr: 0.009368\n",
      "2021-10-28 02:17:52.609653: saving checkpoint...\n",
      "2021-10-28 02:17:53.649197: done, saving took 1.06 seconds\n",
      "2021-10-28 02:17:54.130304: This epoch took 203.628834 s\n",
      "\n",
      "2021-10-28 02:17:54.139364: \n",
      "epoch:  7\n",
      "2021-10-28 02:21:01.566922: train loss : -0.8261\n",
      "2021-10-28 02:21:15.681142: validation loss: -0.8519\n",
      "2021-10-28 02:21:15.685938: Average global foreground Dice: [0.859]\n",
      "2021-10-28 02:21:15.691650: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 02:21:16.173803: lr: 0.009277\n",
      "2021-10-28 02:21:16.213941: saving checkpoint...\n",
      "2021-10-28 02:21:17.193859: done, saving took 1.00 seconds\n",
      "2021-10-28 02:21:17.697203: This epoch took 203.551579 s\n",
      "\n",
      "2021-10-28 02:21:17.710835: \n",
      "epoch:  8\n",
      "2021-10-28 02:24:25.504672: train loss : -0.8302\n",
      "2021-10-28 02:24:39.652592: validation loss: -0.8528\n",
      "2021-10-28 02:24:39.656761: Average global foreground Dice: [0.858]\n",
      "2021-10-28 02:24:39.663043: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 02:24:40.185414: lr: 0.009186\n",
      "2021-10-28 02:24:40.226901: saving checkpoint...\n",
      "2021-10-28 02:24:41.248835: done, saving took 1.04 seconds\n",
      "2021-10-28 02:24:41.438743: This epoch took 203.721314 s\n",
      "\n",
      "2021-10-28 02:24:41.447374: \n",
      "epoch:  9\n",
      "2021-10-28 02:27:49.290734: train loss : -0.8340\n",
      "2021-10-28 02:28:03.422332: validation loss: -0.8554\n",
      "2021-10-28 02:28:03.428167: Average global foreground Dice: [0.8592]\n",
      "2021-10-28 02:28:03.434751: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 02:28:03.951530: lr: 0.009095\n",
      "2021-10-28 02:28:03.991823: saving checkpoint...\n",
      "2021-10-28 02:28:04.998223: done, saving took 1.03 seconds\n",
      "2021-10-28 02:28:05.401592: This epoch took 203.943933 s\n",
      "\n",
      "2021-10-28 02:28:05.409822: \n",
      "epoch:  10\n",
      "2021-10-28 02:31:13.177174: train loss : -0.8379\n",
      "2021-10-28 02:31:27.304268: validation loss: -0.8581\n",
      "2021-10-28 02:31:27.308756: Average global foreground Dice: [0.8638]\n",
      "2021-10-28 02:31:27.315504: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 02:31:27.840605: lr: 0.009004\n",
      "2021-10-28 02:31:27.873996: saving checkpoint...\n",
      "2021-10-28 02:31:28.891931: done, saving took 1.04 seconds\n",
      "2021-10-28 02:31:29.307656: This epoch took 203.891190 s\n",
      "\n",
      "2021-10-28 02:31:29.315861: \n",
      "epoch:  11\n",
      "2021-10-28 02:34:37.212977: train loss : -0.8392\n",
      "2021-10-28 02:34:51.349464: validation loss: -0.8624\n",
      "2021-10-28 02:34:51.354009: Average global foreground Dice: [0.8657]\n",
      "2021-10-28 02:34:51.360479: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 02:34:51.872293: lr: 0.008913\n",
      "2021-10-28 02:34:51.903299: saving checkpoint...\n",
      "2021-10-28 02:34:52.910677: done, saving took 1.03 seconds\n",
      "2021-10-28 02:34:53.291179: This epoch took 203.969486 s\n",
      "\n",
      "2021-10-28 02:34:53.298839: \n",
      "epoch:  12\n",
      "2021-10-28 02:38:01.207739: train loss : -0.8423\n",
      "2021-10-28 02:38:15.337143: validation loss: -0.8658\n",
      "2021-10-28 02:38:15.341432: Average global foreground Dice: [0.8698]\n",
      "2021-10-28 02:38:15.347646: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 02:38:15.831503: lr: 0.008822\n",
      "2021-10-28 02:38:15.867373: saving checkpoint...\n",
      "2021-10-28 02:38:16.855652: done, saving took 1.01 seconds\n",
      "2021-10-28 02:38:17.229144: This epoch took 203.923553 s\n",
      "\n",
      "2021-10-28 02:38:17.239134: \n",
      "epoch:  13\n",
      "2021-10-28 02:41:25.343075: train loss : -0.8452\n",
      "2021-10-28 02:41:39.482183: validation loss: -0.8688\n",
      "2021-10-28 02:41:39.486252: Average global foreground Dice: [0.8733]\n",
      "2021-10-28 02:41:39.492095: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 02:41:39.978689: lr: 0.008731\n",
      "2021-10-28 02:41:40.013370: saving checkpoint...\n",
      "2021-10-28 02:41:41.017781: done, saving took 1.02 seconds\n",
      "2021-10-28 02:41:41.411412: This epoch took 204.164362 s\n",
      "\n",
      "2021-10-28 02:41:41.419548: \n",
      "epoch:  14\n",
      "2021-10-28 02:44:49.301932: train loss : -0.8475\n",
      "2021-10-28 02:45:03.401466: validation loss: -0.8692\n",
      "2021-10-28 02:45:03.405556: Average global foreground Dice: [0.8722]\n",
      "2021-10-28 02:45:03.412392: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 02:45:03.896700: lr: 0.008639\n",
      "2021-10-28 02:45:03.934847: saving checkpoint...\n",
      "2021-10-28 02:45:04.949571: done, saving took 1.03 seconds\n",
      "2021-10-28 02:45:05.175830: This epoch took 203.749605 s\n",
      "\n",
      "2021-10-28 02:45:05.183982: \n",
      "epoch:  15\n",
      "2021-10-28 02:48:13.094011: train loss : -0.8493\n",
      "2021-10-28 02:48:27.220503: validation loss: -0.8739\n",
      "2021-10-28 02:48:27.224444: Average global foreground Dice: [0.8764]\n",
      "2021-10-28 02:48:27.230702: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 02:48:27.780154: lr: 0.008548\n",
      "2021-10-28 02:48:27.814839: saving checkpoint...\n",
      "2021-10-28 02:48:28.824383: done, saving took 1.03 seconds\n",
      "2021-10-28 02:48:29.192345: This epoch took 204.002210 s\n",
      "\n",
      "2021-10-28 02:48:29.200562: \n",
      "epoch:  16\n",
      "2021-10-28 02:51:37.820147: train loss : -0.8508\n",
      "2021-10-28 02:51:51.940688: validation loss: -0.8718\n",
      "2021-10-28 02:51:51.948177: Average global foreground Dice: [0.8758]\n",
      "2021-10-28 02:51:51.981562: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 02:51:52.473706: lr: 0.008456\n",
      "2021-10-28 02:51:52.508446: saving checkpoint...\n",
      "2021-10-28 02:51:53.549277: done, saving took 1.06 seconds\n",
      "2021-10-28 02:51:53.745046: This epoch took 204.536918 s\n",
      "\n",
      "2021-10-28 02:51:53.753451: \n",
      "epoch:  17\n",
      "2021-10-28 02:55:02.230450: train loss : -0.8536\n",
      "2021-10-28 02:55:16.327312: validation loss: -0.8749\n",
      "2021-10-28 02:55:16.331620: Average global foreground Dice: [0.8765]\n",
      "2021-10-28 02:55:16.339500: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 02:55:16.840689: lr: 0.008364\n",
      "2021-10-28 02:55:16.872786: saving checkpoint...\n",
      "2021-10-28 02:55:17.891049: done, saving took 1.04 seconds\n",
      "2021-10-28 02:55:18.123328: This epoch took 204.362823 s\n",
      "\n",
      "2021-10-28 02:55:18.131673: \n",
      "epoch:  18\n",
      "2021-10-28 02:58:26.942355: train loss : -0.8546\n",
      "2021-10-28 02:58:41.060342: validation loss: -0.8755\n",
      "2021-10-28 02:58:41.064548: Average global foreground Dice: [0.8781]\n",
      "2021-10-28 02:58:41.070752: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 02:58:41.604151: lr: 0.008272\n",
      "2021-10-28 02:58:41.639250: saving checkpoint...\n",
      "2021-10-28 02:58:42.655050: done, saving took 1.03 seconds\n",
      "2021-10-28 02:58:42.850226: This epoch took 204.711864 s\n",
      "\n",
      "2021-10-28 02:58:42.858912: \n",
      "epoch:  19\n",
      "2021-10-28 03:01:51.458230: train loss : -0.8553\n",
      "2021-10-28 03:02:05.596364: validation loss: -0.8768\n",
      "2021-10-28 03:02:05.602166: Average global foreground Dice: [0.8797]\n",
      "2021-10-28 03:02:05.608229: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 03:02:06.106125: lr: 0.008181\n",
      "2021-10-28 03:02:06.139220: saving checkpoint...\n",
      "2021-10-28 03:02:07.161231: done, saving took 1.04 seconds\n",
      "2021-10-28 03:02:07.579186: This epoch took 204.713573 s\n",
      "\n",
      "2021-10-28 03:02:07.587406: \n",
      "epoch:  20\n",
      "2021-10-28 03:05:16.004925: train loss : -0.8567\n",
      "2021-10-28 03:05:30.145134: validation loss: -0.8743\n",
      "2021-10-28 03:05:30.149393: Average global foreground Dice: [0.8761]\n",
      "2021-10-28 03:05:30.155411: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 03:05:30.652821: lr: 0.008088\n",
      "2021-10-28 03:05:30.684834: saving checkpoint...\n",
      "2021-10-28 03:05:31.694446: done, saving took 1.03 seconds\n",
      "2021-10-28 03:05:32.091538: This epoch took 204.498049 s\n",
      "\n",
      "2021-10-28 03:05:32.099435: \n",
      "epoch:  21\n",
      "2021-10-28 03:08:40.954500: train loss : -0.8578\n",
      "2021-10-28 03:08:55.079182: validation loss: -0.8795\n",
      "2021-10-28 03:08:55.085356: Average global foreground Dice: [0.8809]\n",
      "2021-10-28 03:08:55.092449: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 03:08:55.642813: lr: 0.007996\n",
      "2021-10-28 03:08:55.678398: saving checkpoint...\n",
      "2021-10-28 03:08:56.991017: done, saving took 1.33 seconds\n",
      "2021-10-28 03:08:57.380008: This epoch took 205.274315 s\n",
      "\n",
      "2021-10-28 03:08:57.388121: \n",
      "epoch:  22\n",
      "2021-10-28 03:12:06.007769: train loss : -0.8592\n",
      "2021-10-28 03:12:20.133856: validation loss: -0.8835\n",
      "2021-10-28 03:12:20.139532: Average global foreground Dice: [0.8861]\n",
      "2021-10-28 03:12:20.146053: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 03:12:20.621596: lr: 0.007904\n",
      "2021-10-28 03:12:20.655776: saving checkpoint...\n",
      "2021-10-28 03:12:21.666838: done, saving took 1.03 seconds\n",
      "2021-10-28 03:12:22.085186: This epoch took 204.689665 s\n",
      "\n",
      "2021-10-28 03:12:22.093843: \n",
      "epoch:  23\n",
      "2021-10-28 03:15:30.767284: train loss : -0.8609\n",
      "2021-10-28 03:15:44.861041: validation loss: -0.8832\n",
      "2021-10-28 03:15:44.866009: Average global foreground Dice: [0.8861]\n",
      "2021-10-28 03:15:44.872457: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 03:15:45.376034: lr: 0.007811\n",
      "2021-10-28 03:15:45.412921: saving checkpoint...\n",
      "2021-10-28 03:15:46.416935: done, saving took 1.02 seconds\n",
      "2021-10-28 03:15:46.794725: This epoch took 204.694800 s\n",
      "\n",
      "2021-10-28 03:15:46.803119: \n",
      "epoch:  24\n",
      "2021-10-28 03:18:56.335450: train loss : -0.8633\n",
      "2021-10-28 03:19:10.439591: validation loss: -0.8817\n",
      "2021-10-28 03:19:10.444032: Average global foreground Dice: [0.8853]\n",
      "2021-10-28 03:19:10.451241: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 03:19:10.936557: lr: 0.007719\n",
      "2021-10-28 03:19:10.986302: saving checkpoint...\n",
      "2021-10-28 03:19:12.005836: done, saving took 1.05 seconds\n",
      "2021-10-28 03:19:12.230786: This epoch took 205.421199 s\n",
      "\n",
      "2021-10-28 03:19:12.239204: \n",
      "epoch:  25\n",
      "2021-10-28 03:22:21.932859: train loss : -0.8623\n",
      "2021-10-28 03:22:36.085073: validation loss: -0.8853\n",
      "2021-10-28 03:22:36.089655: Average global foreground Dice: [0.8879]\n",
      "2021-10-28 03:22:36.096359: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 03:22:36.589663: lr: 0.007626\n",
      "2021-10-28 03:22:36.631760: saving checkpoint...\n",
      "2021-10-28 03:22:37.638975: done, saving took 1.03 seconds\n",
      "2021-10-28 03:22:38.015274: This epoch took 205.769546 s\n",
      "\n",
      "2021-10-28 03:22:38.023189: \n",
      "epoch:  26\n",
      "2021-10-28 03:25:47.585279: train loss : -0.8652\n",
      "2021-10-28 03:26:01.700415: validation loss: -0.8851\n",
      "2021-10-28 03:26:01.705386: Average global foreground Dice: [0.8868]\n",
      "2021-10-28 03:26:01.712049: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 03:26:02.212712: lr: 0.007533\n",
      "2021-10-28 03:26:02.245422: saving checkpoint...\n",
      "2021-10-28 03:26:03.246693: done, saving took 1.02 seconds\n",
      "2021-10-28 03:26:03.632657: This epoch took 205.602914 s\n",
      "\n",
      "2021-10-28 03:26:03.640722: \n",
      "epoch:  27\n",
      "2021-10-28 03:29:13.389367: train loss : -0.8656\n",
      "2021-10-28 03:29:27.517968: validation loss: -0.8881\n",
      "2021-10-28 03:29:27.526123: Average global foreground Dice: [0.8887]\n",
      "2021-10-28 03:29:27.531805: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 03:29:28.008610: lr: 0.00744\n",
      "2021-10-28 03:29:28.043317: saving checkpoint...\n",
      "2021-10-28 03:29:29.064756: done, saving took 1.04 seconds\n",
      "2021-10-28 03:29:29.512876: This epoch took 205.865598 s\n",
      "\n",
      "2021-10-28 03:29:29.520854: \n",
      "epoch:  28\n",
      "2021-10-28 03:32:39.381726: train loss : -0.8659\n",
      "2021-10-28 03:32:53.503889: validation loss: -0.8881\n",
      "2021-10-28 03:32:53.508203: Average global foreground Dice: [0.8881]\n",
      "2021-10-28 03:32:53.515611: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 03:32:54.066781: lr: 0.007347\n",
      "2021-10-28 03:32:54.102577: saving checkpoint...\n",
      "2021-10-28 03:32:55.063615: done, saving took 0.98 seconds\n",
      "2021-10-28 03:32:55.502748: This epoch took 205.974670 s\n",
      "\n",
      "2021-10-28 03:32:55.511061: \n",
      "epoch:  29\n",
      "2021-10-28 03:36:05.310215: train loss : -0.8689\n",
      "2021-10-28 03:36:19.458068: validation loss: -0.8952\n",
      "2021-10-28 03:36:19.462208: Average global foreground Dice: [0.8953]\n",
      "2021-10-28 03:36:19.467987: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 03:36:19.993173: lr: 0.007254\n",
      "2021-10-28 03:36:20.028625: saving checkpoint...\n",
      "2021-10-28 03:36:21.030426: done, saving took 1.02 seconds\n",
      "2021-10-28 03:36:21.448588: This epoch took 205.930929 s\n",
      "\n",
      "2021-10-28 03:36:21.456315: \n",
      "epoch:  30\n",
      "2021-10-28 03:39:31.541988: train loss : -0.8681\n",
      "2021-10-28 03:39:45.663523: validation loss: -0.8922\n",
      "2021-10-28 03:39:45.667693: Average global foreground Dice: [0.8923]\n",
      "2021-10-28 03:39:45.674441: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 03:39:46.205307: lr: 0.007161\n",
      "2021-10-28 03:39:46.244258: saving checkpoint...\n",
      "2021-10-28 03:39:47.259366: done, saving took 1.03 seconds\n",
      "2021-10-28 03:39:47.632281: This epoch took 206.169878 s\n",
      "\n",
      "2021-10-28 03:39:47.640391: \n",
      "epoch:  31\n",
      "2021-10-28 03:42:57.713494: train loss : -0.8692\n",
      "2021-10-28 03:43:11.811698: validation loss: -0.8911\n",
      "2021-10-28 03:43:11.816221: Average global foreground Dice: [0.8914]\n",
      "2021-10-28 03:43:11.822418: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 03:43:12.302335: lr: 0.007067\n",
      "2021-10-28 03:43:12.335219: saving checkpoint...\n",
      "2021-10-28 03:43:13.337672: done, saving took 1.02 seconds\n",
      "2021-10-28 03:43:13.730551: This epoch took 206.083208 s\n",
      "\n",
      "2021-10-28 03:43:13.738688: \n",
      "epoch:  32\n",
      "2021-10-28 03:46:24.264450: train loss : -0.8712\n",
      "2021-10-28 03:46:38.381245: validation loss: -0.8946\n",
      "2021-10-28 03:46:38.385505: Average global foreground Dice: [0.8957]\n",
      "2021-10-28 03:46:38.392629: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 03:46:38.912818: lr: 0.006974\n",
      "2021-10-28 03:46:38.944413: saving checkpoint...\n",
      "2021-10-28 03:46:39.951318: done, saving took 1.03 seconds\n",
      "2021-10-28 03:46:40.157158: This epoch took 206.411613 s\n",
      "\n",
      "2021-10-28 03:46:40.167476: \n",
      "epoch:  33\n",
      "2021-10-28 03:49:50.876689: train loss : -0.8712\n",
      "2021-10-28 03:50:05.022527: validation loss: -0.8925\n",
      "2021-10-28 03:50:05.026963: Average global foreground Dice: [0.8935]\n",
      "2021-10-28 03:50:05.033340: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 03:50:05.556444: lr: 0.00688\n",
      "2021-10-28 03:50:05.602957: saving checkpoint...\n",
      "2021-10-28 03:50:08.320909: done, saving took 2.74 seconds\n",
      "2021-10-28 03:50:08.759707: This epoch took 208.585512 s\n",
      "\n",
      "2021-10-28 03:50:08.779377: \n",
      "epoch:  34\n",
      "2021-10-28 03:53:19.339913: train loss : -0.8718\n",
      "2021-10-28 03:53:33.462611: validation loss: -0.8958\n",
      "2021-10-28 03:53:33.466753: Average global foreground Dice: [0.8964]\n",
      "2021-10-28 03:53:33.473339: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 03:53:34.031791: lr: 0.006786\n",
      "2021-10-28 03:53:34.081330: saving checkpoint...\n",
      "2021-10-28 03:53:35.322756: done, saving took 1.26 seconds\n",
      "2021-10-28 03:53:35.734167: This epoch took 206.947463 s\n",
      "\n",
      "2021-10-28 03:53:35.750248: \n",
      "epoch:  35\n",
      "2021-10-28 03:56:46.480740: train loss : -0.8726\n",
      "2021-10-28 03:57:00.620692: validation loss: -0.8975\n",
      "2021-10-28 03:57:00.625253: Average global foreground Dice: [0.8977]\n",
      "2021-10-28 03:57:00.632114: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 03:57:01.159477: lr: 0.006692\n",
      "2021-10-28 03:57:01.211655: saving checkpoint...\n",
      "2021-10-28 03:57:02.310128: done, saving took 1.12 seconds\n",
      "2021-10-28 03:57:02.521328: This epoch took 206.764957 s\n",
      "\n",
      "2021-10-28 03:57:02.540459: \n",
      "epoch:  36\n",
      "2021-10-28 04:00:13.345756: train loss : -0.8747\n",
      "2021-10-28 04:00:27.476907: validation loss: -0.8983\n",
      "2021-10-28 04:00:27.481078: Average global foreground Dice: [0.8985]\n",
      "2021-10-28 04:00:27.488101: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 04:00:28.002751: lr: 0.006598\n",
      "2021-10-28 04:00:28.049317: saving checkpoint...\n",
      "2021-10-28 04:00:29.141727: done, saving took 1.11 seconds\n",
      "2021-10-28 04:00:29.396055: This epoch took 206.848920 s\n",
      "\n",
      "2021-10-28 04:00:29.414593: \n",
      "epoch:  37\n",
      "2021-10-28 04:03:40.164264: train loss : -0.8744\n",
      "2021-10-28 04:03:54.279877: validation loss: -0.8959\n",
      "2021-10-28 04:03:54.284379: Average global foreground Dice: [0.8958]\n",
      "2021-10-28 04:03:54.290130: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 04:03:54.791667: lr: 0.006504\n",
      "2021-10-28 04:03:54.841772: saving checkpoint...\n",
      "2021-10-28 04:03:55.923331: done, saving took 1.10 seconds\n",
      "2021-10-28 04:03:56.359705: This epoch took 206.938196 s\n",
      "\n",
      "2021-10-28 04:03:56.377894: \n",
      "epoch:  38\n",
      "2021-10-28 04:07:07.285983: train loss : -0.8745\n",
      "2021-10-28 04:07:21.409446: validation loss: -0.8971\n",
      "2021-10-28 04:07:21.413627: Average global foreground Dice: [0.8968]\n",
      "2021-10-28 04:07:21.419366: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 04:07:21.904586: lr: 0.006409\n",
      "2021-10-28 04:07:21.952222: saving checkpoint...\n",
      "2021-10-28 04:07:23.334585: done, saving took 1.40 seconds\n",
      "2021-10-28 04:07:23.701934: This epoch took 207.317230 s\n",
      "\n",
      "2021-10-28 04:07:23.722369: \n",
      "epoch:  39\n",
      "2021-10-28 04:10:34.606233: train loss : -0.8757\n",
      "2021-10-28 04:10:48.752723: validation loss: -0.8955\n",
      "2021-10-28 04:10:48.756891: Average global foreground Dice: [0.8954]\n",
      "2021-10-28 04:10:48.763329: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 04:10:49.291321: lr: 0.006314\n",
      "2021-10-28 04:10:49.344993: saving checkpoint...\n",
      "2021-10-28 04:10:50.607297: done, saving took 1.28 seconds\n",
      "2021-10-28 04:10:50.876836: This epoch took 207.147854 s\n",
      "\n",
      "2021-10-28 04:10:50.894599: \n",
      "epoch:  40\n",
      "2021-10-28 04:14:02.491638: train loss : -0.8764\n",
      "2021-10-28 04:14:16.615708: validation loss: -0.8970\n",
      "2021-10-28 04:14:16.621602: Average global foreground Dice: [0.8968]\n",
      "2021-10-28 04:14:16.628594: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 04:14:17.117257: lr: 0.00622\n",
      "2021-10-28 04:14:17.165942: saving checkpoint...\n",
      "2021-10-28 04:14:18.281127: done, saving took 1.13 seconds\n",
      "2021-10-28 04:14:18.536854: This epoch took 207.634962 s\n",
      "\n",
      "2021-10-28 04:14:18.555782: \n",
      "epoch:  41\n",
      "2021-10-28 04:17:30.326196: train loss : -0.8781\n",
      "2021-10-28 04:17:44.433721: validation loss: -0.8988\n",
      "2021-10-28 04:17:44.438210: Average global foreground Dice: [0.8986]\n",
      "2021-10-28 04:17:44.444733: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 04:17:44.982662: lr: 0.006125\n",
      "2021-10-28 04:17:45.031456: saving checkpoint...\n",
      "2021-10-28 04:17:46.107725: done, saving took 1.09 seconds\n",
      "2021-10-28 04:17:46.325480: This epoch took 207.763600 s\n",
      "\n",
      "2021-10-28 04:17:46.344329: \n",
      "epoch:  42\n",
      "2021-10-28 04:20:57.920995: train loss : -0.8788\n",
      "2021-10-28 04:21:12.019789: validation loss: -0.9025\n",
      "2021-10-28 04:21:12.024038: Average global foreground Dice: [0.9025]\n",
      "2021-10-28 04:21:12.029609: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 04:21:12.545379: lr: 0.00603\n",
      "2021-10-28 04:21:12.599550: saving checkpoint...\n",
      "2021-10-28 04:21:13.701498: done, saving took 1.12 seconds\n",
      "2021-10-28 04:21:14.111194: This epoch took 207.760016 s\n",
      "\n",
      "2021-10-28 04:21:14.129091: \n",
      "epoch:  43\n",
      "2021-10-28 04:24:25.890703: train loss : -0.8785\n",
      "2021-10-28 04:24:40.025923: validation loss: -0.8979\n",
      "2021-10-28 04:24:40.029961: Average global foreground Dice: [0.8975]\n",
      "2021-10-28 04:24:40.036733: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 04:24:40.552512: lr: 0.005934\n",
      "2021-10-28 04:24:40.600937: saving checkpoint...\n",
      "2021-10-28 04:24:41.717185: done, saving took 1.14 seconds\n",
      "2021-10-28 04:24:42.099913: This epoch took 207.963686 s\n",
      "\n",
      "2021-10-28 04:24:42.117209: \n",
      "epoch:  44\n",
      "2021-10-28 04:27:54.101246: train loss : -0.8781\n",
      "2021-10-28 04:28:08.219493: validation loss: -0.9003\n",
      "2021-10-28 04:28:08.223694: Average global foreground Dice: [0.8995]\n",
      "2021-10-28 04:28:08.230223: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 04:28:08.712905: lr: 0.005839\n",
      "2021-10-28 04:28:08.757966: saving checkpoint...\n",
      "2021-10-28 04:28:09.841277: done, saving took 1.10 seconds\n",
      "2021-10-28 04:28:10.241466: This epoch took 208.117594 s\n",
      "\n",
      "2021-10-28 04:28:10.254304: \n",
      "epoch:  45\n",
      "2021-10-28 04:31:22.133478: train loss : -0.8787\n",
      "2021-10-28 04:31:36.280237: validation loss: -0.9067\n",
      "2021-10-28 04:31:36.284436: Average global foreground Dice: [0.9058]\n",
      "2021-10-28 04:31:36.292369: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 04:31:36.781402: lr: 0.005743\n",
      "2021-10-28 04:31:36.826101: saving checkpoint...\n",
      "2021-10-28 04:31:37.958361: done, saving took 1.15 seconds\n",
      "2021-10-28 04:31:38.344178: This epoch took 208.083170 s\n",
      "\n",
      "2021-10-28 04:31:38.364628: \n",
      "epoch:  46\n",
      "2021-10-28 04:34:50.255540: train loss : -0.8813\n",
      "2021-10-28 04:35:04.391293: validation loss: -0.9035\n",
      "2021-10-28 04:35:04.398842: Average global foreground Dice: [0.9026]\n",
      "2021-10-28 04:35:04.404932: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 04:35:04.887416: lr: 0.005647\n",
      "2021-10-28 04:35:04.940852: saving checkpoint...\n",
      "2021-10-28 04:35:06.050322: done, saving took 1.13 seconds\n",
      "2021-10-28 04:35:06.458761: This epoch took 208.087293 s\n",
      "\n",
      "2021-10-28 04:35:06.476670: \n",
      "epoch:  47\n",
      "2021-10-28 04:38:18.174090: train loss : -0.8814\n",
      "2021-10-28 04:38:32.261011: validation loss: -0.9064\n",
      "2021-10-28 04:38:32.265384: Average global foreground Dice: [0.905]\n",
      "2021-10-28 04:38:32.272281: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 04:38:32.802201: lr: 0.005551\n",
      "2021-10-28 04:38:32.854644: saving checkpoint...\n",
      "2021-10-28 04:38:33.950648: done, saving took 1.11 seconds\n",
      "2021-10-28 04:38:34.199952: This epoch took 207.716354 s\n",
      "\n",
      "2021-10-28 04:38:34.218298: \n",
      "epoch:  48\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-28 04:41:45.988881: train loss : -0.8817\n",
      "2021-10-28 04:42:00.098412: validation loss: -0.9062\n",
      "2021-10-28 04:42:00.104099: Average global foreground Dice: [0.9058]\n",
      "2021-10-28 04:42:00.110971: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 04:42:00.631536: lr: 0.005455\n",
      "2021-10-28 04:42:00.677632: saving checkpoint...\n",
      "2021-10-28 04:42:01.753735: done, saving took 1.09 seconds\n",
      "2021-10-28 04:42:02.172531: This epoch took 207.942331 s\n",
      "\n",
      "2021-10-28 04:42:02.193131: \n",
      "epoch:  49\n",
      "2021-10-28 04:45:14.143371: train loss : -0.8827\n",
      "2021-10-28 04:45:28.283940: validation loss: -0.9043\n",
      "2021-10-28 04:45:28.288148: Average global foreground Dice: [0.9032]\n",
      "2021-10-28 04:45:28.294816: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 04:45:28.818981: lr: 0.005359\n",
      "2021-10-28 04:45:28.850810: saving scheduled checkpoint file...\n",
      "2021-10-28 04:45:28.876318: saving checkpoint...\n",
      "2021-10-28 04:45:29.824946: done, saving took 0.97 seconds\n",
      "2021-10-28 04:45:30.229076: done\n",
      "2021-10-28 04:45:30.264965: saving checkpoint...\n",
      "2021-10-28 04:45:31.337354: done, saving took 1.09 seconds\n",
      "2021-10-28 04:45:31.734087: This epoch took 209.534351 s\n",
      "\n",
      "2021-10-28 04:45:31.752290: \n",
      "epoch:  50\n",
      "2021-10-28 04:48:43.727817: train loss : -0.8826\n",
      "2021-10-28 04:48:57.887854: validation loss: -0.9058\n",
      "2021-10-28 04:48:57.892024: Average global foreground Dice: [0.9057]\n",
      "2021-10-28 04:48:57.897862: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 04:48:58.522171: lr: 0.005262\n",
      "2021-10-28 04:48:58.568173: saving checkpoint...\n",
      "2021-10-28 04:48:59.637999: done, saving took 1.09 seconds\n",
      "2021-10-28 04:48:59.886478: This epoch took 208.126955 s\n",
      "\n",
      "2021-10-28 04:48:59.905425: \n",
      "epoch:  51\n",
      "2021-10-28 04:52:12.202973: train loss : -0.8835\n",
      "2021-10-28 04:52:26.385930: validation loss: -0.9071\n",
      "2021-10-28 04:52:26.391561: Average global foreground Dice: [0.9056]\n",
      "2021-10-28 04:52:26.397317: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 04:52:26.915188: lr: 0.005166\n",
      "2021-10-28 04:52:26.964918: saving checkpoint...\n",
      "2021-10-28 04:52:28.043468: done, saving took 1.10 seconds\n",
      "2021-10-28 04:52:28.317368: This epoch took 208.405130 s\n",
      "\n",
      "2021-10-28 04:52:28.330095: \n",
      "epoch:  52\n",
      "2021-10-28 04:55:40.410853: train loss : -0.8840\n",
      "2021-10-28 04:55:54.568366: validation loss: -0.9106\n",
      "2021-10-28 04:55:54.573556: Average global foreground Dice: [0.9087]\n",
      "2021-10-28 04:55:54.580409: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 04:55:55.124587: lr: 0.005069\n",
      "2021-10-28 04:55:55.170055: saving checkpoint...\n",
      "2021-10-28 04:55:56.276000: done, saving took 1.12 seconds\n",
      "2021-10-28 04:55:56.608251: This epoch took 208.270959 s\n",
      "\n",
      "2021-10-28 04:55:56.628753: \n",
      "epoch:  53\n",
      "2021-10-28 04:59:08.830809: train loss : -0.8851\n",
      "2021-10-28 04:59:22.985916: validation loss: -0.9102\n",
      "2021-10-28 04:59:22.990451: Average global foreground Dice: [0.9079]\n",
      "2021-10-28 04:59:22.996061: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 04:59:23.553070: lr: 0.004971\n",
      "2021-10-28 04:59:23.605140: saving checkpoint...\n",
      "2021-10-28 04:59:24.683155: done, saving took 1.10 seconds\n",
      "2021-10-28 04:59:25.186872: This epoch took 208.551821 s\n",
      "\n",
      "2021-10-28 04:59:25.203390: \n",
      "epoch:  54\n",
      "2021-10-28 05:02:37.190995: train loss : -0.8857\n",
      "2021-10-28 05:02:51.322020: validation loss: -0.9119\n",
      "2021-10-28 05:02:51.326183: Average global foreground Dice: [0.9096]\n",
      "2021-10-28 05:02:51.332893: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 05:02:51.855367: lr: 0.004874\n",
      "2021-10-28 05:02:51.907703: saving checkpoint...\n",
      "2021-10-28 05:02:53.004264: done, saving took 1.12 seconds\n",
      "2021-10-28 05:02:53.184683: This epoch took 207.974918 s\n",
      "\n",
      "2021-10-28 05:02:53.202802: \n",
      "epoch:  55\n",
      "2021-10-28 05:06:05.175179: train loss : -0.8865\n",
      "2021-10-28 05:06:19.292292: validation loss: -0.9111\n",
      "2021-10-28 05:06:19.296438: Average global foreground Dice: [0.9089]\n",
      "2021-10-28 05:06:19.303383: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 05:06:19.839580: lr: 0.004776\n",
      "2021-10-28 05:06:19.884395: saving checkpoint...\n",
      "2021-10-28 05:06:21.008950: done, saving took 1.14 seconds\n",
      "2021-10-28 05:06:21.204063: This epoch took 207.994632 s\n",
      "\n",
      "2021-10-28 05:06:21.217657: \n",
      "epoch:  56\n",
      "2021-10-28 05:09:33.474594: train loss : -0.8868\n",
      "2021-10-28 05:09:47.609441: validation loss: -0.9123\n",
      "2021-10-28 05:09:47.613911: Average global foreground Dice: [0.9103]\n",
      "2021-10-28 05:09:47.620021: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 05:09:48.149597: lr: 0.004679\n",
      "2021-10-28 05:09:48.196581: saving checkpoint...\n",
      "2021-10-28 05:09:49.307229: done, saving took 1.13 seconds\n",
      "2021-10-28 05:09:49.548837: This epoch took 208.324532 s\n",
      "\n",
      "2021-10-28 05:09:49.568419: \n",
      "epoch:  57\n",
      "2021-10-28 05:13:01.593168: train loss : -0.8886\n",
      "2021-10-28 05:13:15.698534: validation loss: -0.9129\n",
      "2021-10-28 05:13:15.702706: Average global foreground Dice: [0.9116]\n",
      "2021-10-28 05:13:15.709301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 05:13:16.232280: lr: 0.004581\n",
      "2021-10-28 05:13:16.277536: saving checkpoint...\n",
      "2021-10-28 05:13:17.357775: done, saving took 1.10 seconds\n",
      "2021-10-28 05:13:17.779962: This epoch took 208.205023 s\n",
      "\n",
      "2021-10-28 05:13:17.798246: \n",
      "epoch:  58\n",
      "2021-10-28 05:16:29.955504: train loss : -0.8880\n",
      "2021-10-28 05:16:44.083169: validation loss: -0.9121\n",
      "2021-10-28 05:16:44.087478: Average global foreground Dice: [0.911]\n",
      "2021-10-28 05:16:44.094774: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 05:16:44.576049: lr: 0.004482\n",
      "2021-10-28 05:16:44.618034: saving checkpoint...\n",
      "2021-10-28 05:16:45.733221: done, saving took 1.13 seconds\n",
      "2021-10-28 05:16:46.119613: This epoch took 208.314628 s\n",
      "\n",
      "2021-10-28 05:16:46.132356: \n",
      "epoch:  59\n",
      "2021-10-28 05:19:57.638982: train loss : -0.8877\n",
      "2021-10-28 05:20:11.786075: validation loss: -0.9125\n",
      "2021-10-28 05:20:11.790237: Average global foreground Dice: [0.9103]\n",
      "2021-10-28 05:20:11.796511: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 05:20:12.322246: lr: 0.004384\n",
      "2021-10-28 05:20:12.370214: saving checkpoint...\n",
      "2021-10-28 05:20:13.691999: done, saving took 1.34 seconds\n",
      "2021-10-28 05:20:13.937429: This epoch took 207.798240 s\n",
      "\n",
      "2021-10-28 05:20:13.959497: \n",
      "epoch:  60\n",
      "2021-10-28 05:23:25.111797: train loss : -0.8888\n",
      "2021-10-28 05:23:39.193535: validation loss: -0.9130\n",
      "2021-10-28 05:23:39.197725: Average global foreground Dice: [0.9102]\n",
      "2021-10-28 05:23:39.204784: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 05:23:39.727373: lr: 0.004285\n",
      "2021-10-28 05:23:39.776761: saving checkpoint...\n",
      "2021-10-28 05:23:40.884912: done, saving took 1.13 seconds\n",
      "2021-10-28 05:23:41.299993: This epoch took 207.333580 s\n",
      "\n",
      "2021-10-28 05:23:41.319211: \n",
      "epoch:  61\n",
      "2021-10-28 05:26:52.578357: train loss : -0.8887\n",
      "2021-10-28 05:27:06.717845: validation loss: -0.9141\n",
      "2021-10-28 05:27:06.721948: Average global foreground Dice: [0.9117]\n",
      "2021-10-28 05:27:06.728836: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 05:27:07.210956: lr: 0.004186\n",
      "2021-10-28 05:27:07.259801: saving checkpoint...\n",
      "2021-10-28 05:27:08.359501: done, saving took 1.12 seconds\n",
      "2021-10-28 05:27:08.797663: This epoch took 207.470317 s\n",
      "\n",
      "2021-10-28 05:27:08.815013: \n",
      "epoch:  62\n",
      "2021-10-28 05:30:19.981985: train loss : -0.8900\n",
      "2021-10-28 05:30:34.109234: validation loss: -0.9169\n",
      "2021-10-28 05:30:34.113964: Average global foreground Dice: [0.9155]\n",
      "2021-10-28 05:30:34.120829: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 05:30:34.601031: lr: 0.004087\n",
      "2021-10-28 05:30:34.651951: saving checkpoint...\n",
      "2021-10-28 05:30:35.717467: done, saving took 1.08 seconds\n",
      "2021-10-28 05:30:36.479528: This epoch took 207.658263 s\n",
      "\n",
      "2021-10-28 05:30:36.498405: \n",
      "epoch:  63\n",
      "2021-10-28 05:33:47.793056: train loss : -0.8904\n",
      "2021-10-28 05:34:01.906341: validation loss: -0.9165\n",
      "2021-10-28 05:34:01.909113: Average global foreground Dice: [0.9148]\n",
      "2021-10-28 05:34:01.915080: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 05:34:02.464089: lr: 0.003987\n",
      "2021-10-28 05:34:02.512979: saving checkpoint...\n",
      "2021-10-28 05:34:03.603373: done, saving took 1.11 seconds\n",
      "2021-10-28 05:34:03.890374: This epoch took 207.384994 s\n",
      "\n",
      "2021-10-28 05:34:03.908235: \n",
      "epoch:  64\n",
      "2021-10-28 05:37:15.018075: train loss : -0.8911\n",
      "2021-10-28 05:37:29.147845: validation loss: -0.9198\n",
      "2021-10-28 05:37:29.152294: Average global foreground Dice: [0.9168]\n",
      "2021-10-28 05:37:29.158100: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 05:37:29.677470: lr: 0.003887\n",
      "2021-10-28 05:37:29.721787: saving checkpoint...\n",
      "2021-10-28 05:37:30.808589: done, saving took 1.11 seconds\n",
      "2021-10-28 05:37:31.261329: This epoch took 207.345674 s\n",
      "\n",
      "2021-10-28 05:37:31.278612: \n",
      "epoch:  65\n",
      "2021-10-28 05:40:42.706469: train loss : -0.8926\n",
      "2021-10-28 05:40:56.826849: validation loss: -0.9180\n",
      "2021-10-28 05:40:56.831106: Average global foreground Dice: [0.9153]\n",
      "2021-10-28 05:40:56.837303: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 05:40:57.339553: lr: 0.003787\n",
      "2021-10-28 05:40:57.392398: saving checkpoint...\n",
      "2021-10-28 05:40:58.454545: done, saving took 1.08 seconds\n",
      "2021-10-28 05:40:59.202494: This epoch took 207.917396 s\n",
      "\n",
      "2021-10-28 05:40:59.221090: \n",
      "epoch:  66\n",
      "2021-10-28 05:44:10.605453: train loss : -0.8922\n",
      "2021-10-28 05:44:24.725070: validation loss: -0.9198\n",
      "2021-10-28 05:44:24.729429: Average global foreground Dice: [0.9176]\n",
      "2021-10-28 05:44:24.736081: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 05:44:25.222070: lr: 0.003687\n",
      "2021-10-28 05:44:25.271486: saving checkpoint...\n",
      "2021-10-28 05:44:26.382359: done, saving took 1.13 seconds\n",
      "2021-10-28 05:44:26.839243: This epoch took 207.611262 s\n",
      "\n",
      "2021-10-28 05:44:26.861432: \n",
      "epoch:  67\n",
      "2021-10-28 05:47:38.829703: train loss : -0.8932\n",
      "2021-10-28 05:47:52.959930: validation loss: -0.9189\n",
      "2021-10-28 05:47:52.964233: Average global foreground Dice: [0.9168]\n",
      "2021-10-28 05:47:52.972810: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 05:47:53.491919: lr: 0.003586\n",
      "2021-10-28 05:47:53.539533: saving checkpoint...\n",
      "2021-10-28 05:47:54.649745: done, saving took 1.13 seconds\n",
      "2021-10-28 05:47:54.883654: This epoch took 208.015565 s\n",
      "\n",
      "2021-10-28 05:47:54.903603: \n",
      "epoch:  68\n",
      "2021-10-28 05:51:07.012566: train loss : -0.8933\n",
      "2021-10-28 05:51:21.179303: validation loss: -0.9200\n",
      "2021-10-28 05:51:21.183820: Average global foreground Dice: [0.917]\n",
      "2021-10-28 05:51:21.190460: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 05:51:21.705234: lr: 0.003485\n",
      "2021-10-28 05:51:21.756474: saving checkpoint...\n",
      "2021-10-28 05:51:22.869715: done, saving took 1.13 seconds\n",
      "2021-10-28 05:51:23.129826: This epoch took 208.219278 s\n",
      "\n",
      "2021-10-28 05:51:23.147939: \n",
      "epoch:  69\n",
      "2021-10-28 05:54:35.347388: train loss : -0.8942\n",
      "2021-10-28 05:54:49.471944: validation loss: -0.9210\n",
      "2021-10-28 05:54:49.476369: Average global foreground Dice: [0.9184]\n",
      "2021-10-28 05:54:49.483226: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 05:54:49.966480: lr: 0.003384\n",
      "2021-10-28 05:54:50.019012: saving checkpoint...\n",
      "2021-10-28 05:54:51.080249: done, saving took 1.08 seconds\n",
      "2021-10-28 05:54:51.756209: This epoch took 208.601276 s\n",
      "\n",
      "2021-10-28 05:54:51.774262: \n",
      "epoch:  70\n",
      "2021-10-28 05:58:04.162452: train loss : -0.8955\n",
      "2021-10-28 05:58:18.291913: validation loss: -0.9211\n",
      "2021-10-28 05:58:18.296451: Average global foreground Dice: [0.9183]\n",
      "2021-10-28 05:58:18.303112: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 05:58:18.812349: lr: 0.003282\n",
      "2021-10-28 05:58:18.861513: saving checkpoint...\n",
      "2021-10-28 05:58:19.930512: done, saving took 1.09 seconds\n",
      "2021-10-28 05:58:20.215160: This epoch took 208.433781 s\n",
      "\n",
      "2021-10-28 05:58:20.232409: \n",
      "epoch:  71\n",
      "2021-10-28 06:01:32.289103: train loss : -0.8946\n",
      "2021-10-28 06:01:46.432025: validation loss: -0.9191\n",
      "2021-10-28 06:01:46.436905: Average global foreground Dice: [0.9163]\n",
      "2021-10-28 06:01:46.443851: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 06:01:46.942469: lr: 0.00318\n",
      "2021-10-28 06:01:46.990933: saving checkpoint...\n",
      "2021-10-28 06:01:48.140429: done, saving took 1.17 seconds\n",
      "2021-10-28 06:01:48.562529: This epoch took 208.323155 s\n",
      "\n",
      "2021-10-28 06:01:48.579596: \n",
      "epoch:  72\n",
      "2021-10-28 06:05:00.766274: train loss : -0.8940\n",
      "2021-10-28 06:05:14.896210: validation loss: -0.9217\n",
      "2021-10-28 06:05:14.900545: Average global foreground Dice: [0.9196]\n",
      "2021-10-28 06:05:14.906605: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 06:05:15.405690: lr: 0.003078\n",
      "2021-10-28 06:05:15.451896: saving checkpoint...\n",
      "2021-10-28 06:05:16.522363: done, saving took 1.09 seconds\n",
      "2021-10-28 06:05:16.938658: This epoch took 208.352277 s\n",
      "\n",
      "2021-10-28 06:05:16.954461: \n",
      "epoch:  73\n",
      "2021-10-28 06:08:28.832758: train loss : -0.8957\n",
      "2021-10-28 06:08:42.942113: validation loss: -0.9237\n",
      "2021-10-28 06:08:42.946395: Average global foreground Dice: [0.9209]\n",
      "2021-10-28 06:08:42.952614: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 06:08:43.445219: lr: 0.002975\n",
      "2021-10-28 06:08:43.494676: saving checkpoint...\n",
      "2021-10-28 06:08:44.576389: done, saving took 1.10 seconds\n",
      "2021-10-28 06:08:44.970170: This epoch took 208.008702 s\n",
      "\n",
      "2021-10-28 06:08:44.989075: \n",
      "epoch:  74\n",
      "2021-10-28 06:11:57.297496: train loss : -0.8967\n",
      "2021-10-28 06:12:11.431547: validation loss: -0.9229\n",
      "2021-10-28 06:12:11.435698: Average global foreground Dice: [0.9206]\n",
      "2021-10-28 06:12:11.442702: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 06:12:11.922343: lr: 0.002872\n",
      "2021-10-28 06:12:11.970992: saving checkpoint...\n",
      "2021-10-28 06:12:13.321891: done, saving took 1.37 seconds\n",
      "2021-10-28 06:12:13.608653: This epoch took 208.612656 s\n",
      "\n",
      "2021-10-28 06:12:13.626932: \n",
      "epoch:  75\n",
      "2021-10-28 06:15:26.080619: train loss : -0.8968\n",
      "2021-10-28 06:15:40.204079: validation loss: -0.9234\n",
      "2021-10-28 06:15:40.208462: Average global foreground Dice: [0.9204]\n",
      "2021-10-28 06:15:40.215251: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 06:15:40.710097: lr: 0.002768\n",
      "2021-10-28 06:15:40.761662: saving checkpoint...\n",
      "2021-10-28 06:15:41.851130: done, saving took 1.11 seconds\n",
      "2021-10-28 06:15:42.229835: This epoch took 208.596149 s\n",
      "\n",
      "2021-10-28 06:15:42.246758: \n",
      "epoch:  76\n",
      "2021-10-28 06:18:54.435142: train loss : -0.8978\n",
      "2021-10-28 06:19:08.557490: validation loss: -0.9248\n",
      "2021-10-28 06:19:08.561808: Average global foreground Dice: [0.9221]\n",
      "2021-10-28 06:19:08.569487: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 06:19:09.118704: lr: 0.002664\n",
      "2021-10-28 06:19:09.168430: saving checkpoint...\n",
      "2021-10-28 06:19:10.261511: done, saving took 1.11 seconds\n",
      "2021-10-28 06:19:10.660807: This epoch took 208.406162 s\n",
      "\n",
      "2021-10-28 06:19:10.678015: \n",
      "epoch:  77\n",
      "2021-10-28 06:22:22.712548: train loss : -0.8986\n",
      "2021-10-28 06:22:36.818484: validation loss: -0.9263\n",
      "2021-10-28 06:22:36.822534: Average global foreground Dice: [0.9236]\n",
      "2021-10-28 06:22:36.829098: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 06:22:37.354084: lr: 0.00256\n",
      "2021-10-28 06:22:37.401369: saving checkpoint...\n",
      "2021-10-28 06:22:38.696783: done, saving took 1.31 seconds\n",
      "2021-10-28 06:22:39.181637: This epoch took 208.496910 s\n",
      "\n",
      "2021-10-28 06:22:39.200383: \n",
      "epoch:  78\n",
      "2021-10-28 06:25:51.422173: train loss : -0.8981\n",
      "2021-10-28 06:26:05.532237: validation loss: -0.9265\n",
      "2021-10-28 06:26:05.536557: Average global foreground Dice: [0.9231]\n",
      "2021-10-28 06:26:05.543674: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 06:26:06.067262: lr: 0.002455\n",
      "2021-10-28 06:26:06.113788: saving checkpoint...\n",
      "2021-10-28 06:26:07.212357: done, saving took 1.12 seconds\n",
      "2021-10-28 06:26:07.443107: This epoch took 208.235845 s\n",
      "\n",
      "2021-10-28 06:26:07.461551: \n",
      "epoch:  79\n",
      "2021-10-28 06:29:19.721037: train loss : -0.8999\n",
      "2021-10-28 06:29:33.856174: validation loss: -0.9266\n",
      "2021-10-28 06:29:33.860740: Average global foreground Dice: [0.9231]\n",
      "2021-10-28 06:29:33.867321: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 06:29:34.377766: lr: 0.002349\n",
      "2021-10-28 06:29:34.425800: saving checkpoint...\n",
      "2021-10-28 06:29:35.694896: done, saving took 1.29 seconds\n",
      "2021-10-28 06:29:36.098889: This epoch took 208.630903 s\n",
      "\n",
      "2021-10-28 06:29:36.120680: \n",
      "epoch:  80\n",
      "2021-10-28 06:32:48.589466: train loss : -0.9000\n",
      "2021-10-28 06:33:02.733197: validation loss: -0.9280\n",
      "2021-10-28 06:33:02.737763: Average global foreground Dice: [0.9245]\n",
      "2021-10-28 06:33:02.743913: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 06:33:03.246292: lr: 0.002243\n",
      "2021-10-28 06:33:03.297713: saving checkpoint...\n",
      "2021-10-28 06:33:04.444367: done, saving took 1.17 seconds\n",
      "2021-10-28 06:33:04.693186: This epoch took 208.565454 s\n",
      "\n",
      "2021-10-28 06:33:04.709754: \n",
      "epoch:  81\n",
      "2021-10-28 06:36:16.958960: train loss : -0.9002\n",
      "2021-10-28 06:36:31.067071: validation loss: -0.9285\n",
      "2021-10-28 06:36:31.071559: Average global foreground Dice: [0.925]\n",
      "2021-10-28 06:36:31.078234: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 06:36:31.585660: lr: 0.002137\n",
      "2021-10-28 06:36:31.636593: saving checkpoint...\n",
      "2021-10-28 06:36:32.909143: done, saving took 1.29 seconds\n",
      "2021-10-28 06:36:33.131448: This epoch took 208.414583 s\n",
      "\n",
      "2021-10-28 06:36:33.150301: \n",
      "epoch:  82\n",
      "2021-10-28 06:39:45.466241: train loss : -0.9003\n",
      "2021-10-28 06:39:59.601636: validation loss: -0.9288\n",
      "2021-10-28 06:39:59.605978: Average global foreground Dice: [0.9261]\n",
      "2021-10-28 06:39:59.612406: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 06:40:00.124150: lr: 0.00203\n",
      "2021-10-28 06:40:00.170628: saving checkpoint...\n",
      "2021-10-28 06:40:01.259557: done, saving took 1.11 seconds\n",
      "2021-10-28 06:40:01.527273: This epoch took 208.370430 s\n",
      "\n",
      "2021-10-28 06:40:01.544562: \n",
      "epoch:  83\n",
      "2021-10-28 06:43:13.946383: train loss : -0.9017\n",
      "2021-10-28 06:43:28.067057: validation loss: -0.9279\n",
      "2021-10-28 06:43:28.072011: Average global foreground Dice: [0.9245]\n",
      "2021-10-28 06:43:28.078568: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 06:43:28.570260: lr: 0.001922\n",
      "2021-10-28 06:43:28.618751: saving checkpoint...\n",
      "2021-10-28 06:43:29.913305: done, saving took 1.31 seconds\n",
      "2021-10-28 06:43:30.119676: This epoch took 208.567586 s\n",
      "\n",
      "2021-10-28 06:43:30.137797: \n",
      "epoch:  84\n",
      "2021-10-28 06:46:42.626287: train loss : -0.9018\n",
      "2021-10-28 06:46:56.743022: validation loss: -0.9303\n",
      "2021-10-28 06:46:56.748828: Average global foreground Dice: [0.9268]\n",
      "2021-10-28 06:46:56.755232: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 06:46:57.231946: lr: 0.001813\n",
      "2021-10-28 06:46:57.281729: saving checkpoint...\n",
      "2021-10-28 06:46:58.374535: done, saving took 1.11 seconds\n",
      "2021-10-28 06:46:58.545649: This epoch took 208.400774 s\n",
      "\n",
      "2021-10-28 06:46:58.563291: \n",
      "epoch:  85\n",
      "2021-10-28 06:50:10.974869: train loss : -0.9014\n",
      "2021-10-28 06:50:25.107873: validation loss: -0.9291\n",
      "2021-10-28 06:50:25.112101: Average global foreground Dice: [0.9255]\n",
      "2021-10-28 06:50:25.118291: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 06:50:25.595246: lr: 0.001704\n",
      "2021-10-28 06:50:25.649056: saving checkpoint...\n",
      "2021-10-28 06:50:26.770931: done, saving took 1.14 seconds\n",
      "2021-10-28 06:50:27.021718: This epoch took 208.451731 s\n",
      "\n",
      "2021-10-28 06:50:27.042145: \n",
      "epoch:  86\n",
      "2021-10-28 06:53:39.317517: train loss : -0.9038\n",
      "2021-10-28 06:53:53.460998: validation loss: -0.9308\n",
      "2021-10-28 06:53:53.465382: Average global foreground Dice: [0.9274]\n",
      "2021-10-28 06:53:53.472012: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 06:53:53.962568: lr: 0.001594\n",
      "2021-10-28 06:53:54.011278: saving checkpoint...\n",
      "2021-10-28 06:53:55.112207: done, saving took 1.12 seconds\n",
      "2021-10-28 06:53:55.356402: This epoch took 208.307435 s\n",
      "\n",
      "2021-10-28 06:53:55.375757: \n",
      "epoch:  87\n",
      "2021-10-28 06:57:07.670333: train loss : -0.9030\n",
      "2021-10-28 06:57:21.799236: validation loss: -0.9312\n",
      "2021-10-28 06:57:21.803406: Average global foreground Dice: [0.9276]\n",
      "2021-10-28 06:57:21.809590: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 06:57:22.307461: lr: 0.001483\n",
      "2021-10-28 06:57:22.356040: saving checkpoint...\n",
      "2021-10-28 06:57:23.434613: done, saving took 1.10 seconds\n",
      "2021-10-28 06:57:23.831246: This epoch took 208.448947 s\n",
      "\n",
      "2021-10-28 06:57:23.844702: \n",
      "epoch:  88\n",
      "2021-10-28 07:00:36.143865: train loss : -0.9045\n",
      "2021-10-28 07:00:50.308116: validation loss: -0.9304\n",
      "2021-10-28 07:00:50.312386: Average global foreground Dice: [0.9272]\n",
      "2021-10-28 07:00:50.319271: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 07:00:50.848702: lr: 0.001372\n",
      "2021-10-28 07:00:50.896180: saving checkpoint...\n",
      "2021-10-28 07:00:51.971476: done, saving took 1.09 seconds\n",
      "2021-10-28 07:00:52.185169: This epoch took 208.334205 s\n",
      "\n",
      "2021-10-28 07:00:52.204513: \n",
      "epoch:  89\n",
      "2021-10-28 07:04:04.490769: train loss : -0.9047\n",
      "2021-10-28 07:04:18.627341: validation loss: -0.9318\n",
      "2021-10-28 07:04:18.631624: Average global foreground Dice: [0.9281]\n",
      "2021-10-28 07:04:18.638273: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 07:04:19.165093: lr: 0.001259\n",
      "2021-10-28 07:04:19.211270: saving checkpoint...\n",
      "2021-10-28 07:04:20.298113: done, saving took 1.11 seconds\n",
      "2021-10-28 07:04:20.736340: This epoch took 208.524962 s\n",
      "\n",
      "2021-10-28 07:04:20.757238: \n",
      "epoch:  90\n",
      "2021-10-28 07:07:32.278985: train loss : -0.9052\n",
      "2021-10-28 07:07:46.429273: validation loss: -0.9329\n",
      "2021-10-28 07:07:46.433619: Average global foreground Dice: [0.9295]\n",
      "2021-10-28 07:07:46.441164: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 07:07:46.928423: lr: 0.001145\n",
      "2021-10-28 07:07:46.976453: saving checkpoint...\n",
      "2021-10-28 07:07:48.079229: done, saving took 1.12 seconds\n",
      "2021-10-28 07:07:48.482968: This epoch took 207.718408 s\n",
      "\n",
      "2021-10-28 07:07:48.499886: \n",
      "epoch:  91\n",
      "2021-10-28 07:11:00.357893: train loss : -0.9045\n",
      "2021-10-28 07:11:14.543006: validation loss: -0.9329\n",
      "2021-10-28 07:11:14.547183: Average global foreground Dice: [0.9294]\n",
      "2021-10-28 07:11:14.553422: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 07:11:15.083508: lr: 0.00103\n",
      "2021-10-28 07:11:15.131176: saving checkpoint...\n",
      "2021-10-28 07:11:16.239671: done, saving took 1.13 seconds\n",
      "2021-10-28 07:11:16.718701: This epoch took 208.212141 s\n",
      "\n",
      "2021-10-28 07:11:16.735796: \n",
      "epoch:  92\n",
      "2021-10-28 07:14:28.220609: train loss : -0.9058\n",
      "2021-10-28 07:14:42.366365: validation loss: -0.9334\n",
      "2021-10-28 07:14:42.370482: Average global foreground Dice: [0.9296]\n",
      "2021-10-28 07:14:42.376848: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 07:14:42.877808: lr: 0.000913\n",
      "2021-10-28 07:14:42.927771: saving checkpoint...\n",
      "2021-10-28 07:14:44.020636: done, saving took 1.11 seconds\n",
      "2021-10-28 07:14:44.402483: This epoch took 207.658929 s\n",
      "\n",
      "2021-10-28 07:14:44.423520: \n",
      "epoch:  93\n",
      "2021-10-28 07:17:55.961215: train loss : -0.9074\n",
      "2021-10-28 07:18:10.093237: validation loss: -0.9344\n",
      "2021-10-28 07:18:10.098950: Average global foreground Dice: [0.9314]\n",
      "2021-10-28 07:18:10.106303: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 07:18:10.605567: lr: 0.000795\n",
      "2021-10-28 07:18:10.647299: saving checkpoint...\n",
      "2021-10-28 07:18:11.730155: done, saving took 1.10 seconds\n",
      "2021-10-28 07:18:12.128959: This epoch took 207.698755 s\n",
      "\n",
      "2021-10-28 07:18:12.146993: \n",
      "epoch:  94\n",
      "2021-10-28 07:21:23.810433: train loss : -0.9071\n",
      "2021-10-28 07:21:37.956168: validation loss: -0.9363\n",
      "2021-10-28 07:21:37.960436: Average global foreground Dice: [0.9321]\n",
      "2021-10-28 07:21:37.967840: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 07:21:38.477041: lr: 0.000675\n",
      "2021-10-28 07:21:38.529994: saving checkpoint...\n",
      "2021-10-28 07:21:39.702294: done, saving took 1.19 seconds\n",
      "2021-10-28 07:21:40.181587: This epoch took 208.028149 s\n",
      "\n",
      "2021-10-28 07:21:40.202953: \n",
      "epoch:  95\n",
      "2021-10-28 07:24:51.936493: train loss : -0.9073\n",
      "2021-10-28 07:25:06.044055: validation loss: -0.9371\n",
      "2021-10-28 07:25:06.048637: Average global foreground Dice: [0.9329]\n",
      "2021-10-28 07:25:06.054702: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 07:25:06.599057: lr: 0.000552\n",
      "2021-10-28 07:25:06.645632: saving checkpoint...\n",
      "2021-10-28 07:25:07.737140: done, saving took 1.11 seconds\n",
      "2021-10-28 07:25:08.038316: This epoch took 207.828654 s\n",
      "\n",
      "2021-10-28 07:25:08.058664: \n",
      "epoch:  96\n",
      "2021-10-28 07:28:19.889434: train loss : -0.9086\n",
      "2021-10-28 07:28:34.035355: validation loss: -0.9386\n",
      "2021-10-28 07:28:34.040845: Average global foreground Dice: [0.9345]\n",
      "2021-10-28 07:28:34.047347: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 07:28:34.573386: lr: 0.000426\n",
      "2021-10-28 07:28:34.622405: saving checkpoint...\n",
      "2021-10-28 07:28:35.717648: done, saving took 1.11 seconds\n",
      "2021-10-28 07:28:35.963838: This epoch took 207.898392 s\n",
      "\n",
      "2021-10-28 07:28:35.982967: \n",
      "epoch:  97\n",
      "2021-10-28 07:31:48.036081: train loss : -0.9078\n",
      "2021-10-28 07:32:02.172086: validation loss: -0.9374\n",
      "2021-10-28 07:32:02.176790: Average global foreground Dice: [0.9334]\n",
      "2021-10-28 07:32:02.183167: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 07:32:02.723885: lr: 0.000296\n",
      "2021-10-28 07:32:02.779864: saving checkpoint...\n",
      "2021-10-28 07:32:03.880236: done, saving took 1.12 seconds\n",
      "2021-10-28 07:32:04.324732: This epoch took 208.335291 s\n",
      "\n",
      "2021-10-28 07:32:04.344813: \n",
      "epoch:  98\n",
      "2021-10-28 07:35:16.834627: train loss : -0.9084\n",
      "2021-10-28 07:35:30.982717: validation loss: -0.9376\n",
      "2021-10-28 07:35:30.986996: Average global foreground Dice: [0.9334]\n",
      "2021-10-28 07:35:30.995965: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 07:35:31.543705: lr: 0.000158\n",
      "2021-10-28 07:35:31.594587: saving checkpoint...\n",
      "2021-10-28 07:35:32.685935: done, saving took 1.11 seconds\n",
      "2021-10-28 07:35:33.172453: This epoch took 208.817017 s\n",
      "\n",
      "2021-10-28 07:35:33.192502: \n",
      "epoch:  99\n",
      "2021-10-28 07:38:45.456363: train loss : -0.9085\n",
      "2021-10-28 07:38:59.569806: validation loss: -0.9377\n",
      "2021-10-28 07:38:59.574053: Average global foreground Dice: [0.934]\n",
      "2021-10-28 07:38:59.583800: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 07:39:00.090815: lr: 0.0\n",
      "2021-10-28 07:39:00.107172: saving scheduled checkpoint file...\n",
      "2021-10-28 07:39:00.136214: saving checkpoint...\n",
      "2021-10-28 07:39:01.313540: done, saving took 1.20 seconds\n",
      "2021-10-28 07:39:01.631870: done\n",
      "2021-10-28 07:39:01.660364: saving checkpoint...\n",
      "2021-10-28 07:39:02.771941: done, saving took 1.13 seconds\n",
      "2021-10-28 07:39:03.146889: This epoch took 209.944170 s\n",
      "\n",
      "2021-10-28 07:39:03.174448: saving checkpoint...\n",
      "2021-10-28 07:39:04.125981: done, saving took 0.97 seconds\n",
      "23090557_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090558_20120 (3, 263, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090559_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090560_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090562_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090563_20151 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090564_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090566_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090567_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090568_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090569_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090571_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090584_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090589_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090590_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090592_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090593_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090596_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090597_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090599_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090600_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090603_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090604_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090607_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090608_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090609_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090614_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090615_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090616_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090617_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090619_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090620_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090621_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090627_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090628_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090629_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090631_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090634_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090635_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090636_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090637_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090640_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090644_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090646_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-28 07:48:49.959934: finished prediction\n",
      "2021-10-28 07:48:49.972018: evaluation of raw predictions\n",
      "2021-10-28 07:48:56.103411: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.9484908874058698\n",
      "after:  0.9484908874058698\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_Dice 555 all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-28 10:36:06.654625: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-28 10:36:16.460406: Unable to plot network architecture:\n",
      "2021-10-28 10:36:16.548432: No module named 'hiddenlayer'\n",
      "2021-10-28 10:36:16.680338: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-28 10:36:16.852402: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-28 10:36:17.042218: \n",
      "\n",
      "2021-10-28 10:36:17.132025: \n",
      "epoch:  0\n",
      "2021-10-28 10:39:27.467797: train loss : -0.2596\n",
      "2021-10-28 10:39:41.503281: validation loss: -0.6471\n",
      "2021-10-28 10:39:41.507400: Average global foreground Dice: [0.7185]\n",
      "2021-10-28 10:39:41.514312: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 10:39:42.005787: lr: 0.00991\n",
      "2021-10-28 10:39:42.022491: This epoch took 204.826072 s\n",
      "\n",
      "2021-10-28 10:39:42.030085: \n",
      "epoch:  1\n",
      "2021-10-28 10:42:52.500503: train loss : -0.6824\n",
      "2021-10-28 10:43:06.605818: validation loss: -0.7714\n",
      "2021-10-28 10:43:06.610530: Average global foreground Dice: [0.8138]\n",
      "2021-10-28 10:43:06.616941: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 10:43:07.173168: lr: 0.00982\n",
      "2021-10-28 10:43:07.231468: saving checkpoint...\n",
      "2021-10-28 10:43:08.184710: done, saving took 0.99 seconds\n",
      "2021-10-28 10:43:08.604921: This epoch took 206.568987 s\n",
      "\n",
      "2021-10-28 10:43:08.613598: \n",
      "epoch:  2\n",
      "2021-10-28 10:46:14.279984: train loss : -0.7752\n",
      "2021-10-28 10:46:28.277574: validation loss: -0.8200\n",
      "2021-10-28 10:46:28.283195: Average global foreground Dice: [0.8356]\n",
      "2021-10-28 10:46:28.290206: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 10:46:28.806422: lr: 0.00973\n",
      "2021-10-28 10:46:28.853106: saving checkpoint...\n",
      "2021-10-28 10:46:29.955473: done, saving took 1.13 seconds\n",
      "2021-10-28 10:46:30.140846: This epoch took 201.520979 s\n",
      "\n",
      "2021-10-28 10:46:30.149128: \n",
      "epoch:  3\n",
      "2021-10-28 10:49:36.651232: train loss : -0.7983\n",
      "2021-10-28 10:49:50.661174: validation loss: -0.8312\n",
      "2021-10-28 10:49:50.665932: Average global foreground Dice: [0.845]\n",
      "2021-10-28 10:49:50.673529: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 10:49:51.164089: lr: 0.009639\n",
      "2021-10-28 10:49:51.211068: saving checkpoint...\n",
      "2021-10-28 10:49:52.198602: done, saving took 1.02 seconds\n",
      "2021-10-28 10:49:52.605723: This epoch took 202.449930 s\n",
      "\n",
      "2021-10-28 10:49:52.617089: \n",
      "epoch:  4\n",
      "2021-10-28 10:53:00.797145: train loss : -0.8118\n",
      "2021-10-28 10:53:15.011037: validation loss: -0.8393\n",
      "2021-10-28 10:53:15.015242: Average global foreground Dice: [0.8515]\n",
      "2021-10-28 10:53:15.021703: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 10:53:15.534327: lr: 0.009549\n",
      "2021-10-28 10:53:15.582829: saving checkpoint...\n",
      "2021-10-28 10:53:16.608975: done, saving took 1.06 seconds\n",
      "2021-10-28 10:53:16.993865: This epoch took 204.371172 s\n",
      "\n",
      "2021-10-28 10:53:17.001935: \n",
      "epoch:  5\n",
      "2021-10-28 10:56:25.869629: train loss : -0.8187\n",
      "2021-10-28 10:56:40.085749: validation loss: -0.8406\n",
      "2021-10-28 10:56:40.090532: Average global foreground Dice: [0.8521]\n",
      "2021-10-28 10:56:40.097457: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 10:56:40.635052: lr: 0.009458\n",
      "2021-10-28 10:56:40.675523: saving checkpoint...\n",
      "2021-10-28 10:56:41.701860: done, saving took 1.05 seconds\n",
      "2021-10-28 10:56:42.107143: This epoch took 205.099322 s\n",
      "\n",
      "2021-10-28 10:56:42.115829: \n",
      "epoch:  6\n",
      "2021-10-28 10:59:50.821181: train loss : -0.8265\n",
      "2021-10-28 11:00:05.042128: validation loss: -0.8511\n",
      "2021-10-28 11:00:05.046352: Average global foreground Dice: [0.8613]\n",
      "2021-10-28 11:00:05.052040: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 11:00:05.576226: lr: 0.009368\n",
      "2021-10-28 11:00:05.612597: saving checkpoint...\n",
      "2021-10-28 11:00:06.655130: done, saving took 1.06 seconds\n",
      "2021-10-28 11:00:07.101256: This epoch took 204.978217 s\n",
      "\n",
      "2021-10-28 11:00:07.110417: \n",
      "epoch:  7\n",
      "2021-10-28 11:03:15.683348: train loss : -0.8308\n",
      "2021-10-28 11:03:29.895197: validation loss: -0.8556\n",
      "2021-10-28 11:03:29.900275: Average global foreground Dice: [0.8654]\n",
      "2021-10-28 11:03:29.906115: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 11:03:30.434488: lr: 0.009277\n",
      "2021-10-28 11:03:30.470476: saving checkpoint...\n",
      "2021-10-28 11:03:31.456028: done, saving took 1.00 seconds\n",
      "2021-10-28 11:03:31.846556: This epoch took 204.730237 s\n",
      "\n",
      "2021-10-28 11:03:31.854797: \n",
      "epoch:  8\n",
      "2021-10-28 11:06:41.075108: train loss : -0.8371\n",
      "2021-10-28 11:06:55.291246: validation loss: -0.8596\n",
      "2021-10-28 11:06:55.295801: Average global foreground Dice: [0.8689]\n",
      "2021-10-28 11:06:55.302992: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 11:06:55.832552: lr: 0.009186\n",
      "2021-10-28 11:06:55.869618: saving checkpoint...\n",
      "2021-10-28 11:06:56.869637: done, saving took 1.02 seconds\n",
      "2021-10-28 11:06:57.256282: This epoch took 205.393758 s\n",
      "\n",
      "2021-10-28 11:06:57.264115: \n",
      "epoch:  9\n",
      "2021-10-28 11:10:06.478731: train loss : -0.8372\n",
      "2021-10-28 11:10:20.678182: validation loss: -0.8676\n",
      "2021-10-28 11:10:20.682661: Average global foreground Dice: [0.8757]\n",
      "2021-10-28 11:10:20.689481: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 11:10:21.214613: lr: 0.009095\n",
      "2021-10-28 11:10:21.249119: saving checkpoint...\n",
      "2021-10-28 11:10:22.290113: done, saving took 1.06 seconds\n",
      "2021-10-28 11:10:22.479914: This epoch took 205.209749 s\n",
      "\n",
      "2021-10-28 11:10:22.490248: \n",
      "epoch:  10\n",
      "2021-10-28 11:13:31.549070: train loss : -0.8425\n",
      "2021-10-28 11:13:45.771821: validation loss: -0.8668\n",
      "2021-10-28 11:13:45.776432: Average global foreground Dice: [0.8737]\n",
      "2021-10-28 11:13:45.782958: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 11:13:46.275806: lr: 0.009004\n",
      "2021-10-28 11:13:46.312508: saving checkpoint...\n",
      "2021-10-28 11:13:47.333268: done, saving took 1.04 seconds\n",
      "2021-10-28 11:13:47.716465: This epoch took 205.219457 s\n",
      "\n",
      "2021-10-28 11:13:47.725339: \n",
      "epoch:  11\n",
      "2021-10-28 11:16:56.851238: train loss : -0.8463\n",
      "2021-10-28 11:17:11.066835: validation loss: -0.8707\n",
      "2021-10-28 11:17:11.071162: Average global foreground Dice: [0.8762]\n",
      "2021-10-28 11:17:11.078082: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 11:17:11.572371: lr: 0.008913\n",
      "2021-10-28 11:17:11.607162: saving checkpoint...\n",
      "2021-10-28 11:17:12.629374: done, saving took 1.04 seconds\n",
      "2021-10-28 11:17:13.047784: This epoch took 205.316110 s\n",
      "\n",
      "2021-10-28 11:17:13.056269: \n",
      "epoch:  12\n",
      "2021-10-28 11:20:22.481796: train loss : -0.8462\n",
      "2021-10-28 11:20:36.698656: validation loss: -0.8716\n",
      "2021-10-28 11:20:36.703222: Average global foreground Dice: [0.8791]\n",
      "2021-10-28 11:20:36.709725: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 11:20:37.202727: lr: 0.008822\n",
      "2021-10-28 11:20:37.238899: saving checkpoint...\n",
      "2021-10-28 11:20:38.273846: done, saving took 1.05 seconds\n",
      "2021-10-28 11:20:38.470921: This epoch took 205.408285 s\n",
      "\n",
      "2021-10-28 11:20:38.478604: \n",
      "epoch:  13\n",
      "2021-10-28 11:23:47.679317: train loss : -0.8503\n",
      "2021-10-28 11:24:01.906249: validation loss: -0.8683\n",
      "2021-10-28 11:24:01.911088: Average global foreground Dice: [0.8761]\n",
      "2021-10-28 11:24:01.917856: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 11:24:02.419206: lr: 0.008731\n",
      "2021-10-28 11:24:02.454388: saving checkpoint...\n",
      "2021-10-28 11:24:03.463791: done, saving took 1.03 seconds\n",
      "2021-10-28 11:24:03.719668: This epoch took 205.235068 s\n",
      "\n",
      "2021-10-28 11:24:03.736311: \n",
      "epoch:  14\n",
      "2021-10-28 11:27:13.306961: train loss : -0.8511\n",
      "2021-10-28 11:27:27.535949: validation loss: -0.8762\n",
      "2021-10-28 11:27:27.540549: Average global foreground Dice: [0.8818]\n",
      "2021-10-28 11:27:27.548078: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 11:27:28.119347: lr: 0.008639\n",
      "2021-10-28 11:27:28.155143: saving checkpoint...\n",
      "2021-10-28 11:27:29.222692: done, saving took 1.09 seconds\n",
      "2021-10-28 11:27:29.597070: This epoch took 205.853361 s\n",
      "\n",
      "2021-10-28 11:27:29.606841: \n",
      "epoch:  15\n",
      "2021-10-28 11:30:38.819185: train loss : -0.8533\n",
      "2021-10-28 11:30:53.052808: validation loss: -0.8763\n",
      "2021-10-28 11:30:53.057631: Average global foreground Dice: [0.8819]\n",
      "2021-10-28 11:30:53.064096: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 11:30:53.600636: lr: 0.008548\n",
      "2021-10-28 11:30:53.644567: saving checkpoint...\n",
      "2021-10-28 11:30:54.689827: done, saving took 1.07 seconds\n",
      "2021-10-28 11:30:55.014612: This epoch took 205.400549 s\n",
      "\n",
      "2021-10-28 11:30:55.022742: \n",
      "epoch:  16\n",
      "2021-10-28 11:34:05.538135: train loss : -0.8548\n",
      "2021-10-28 11:34:19.786561: validation loss: -0.8790\n",
      "2021-10-28 11:34:19.792614: Average global foreground Dice: [0.8849]\n",
      "2021-10-28 11:34:19.800483: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 11:34:20.287539: lr: 0.008456\n",
      "2021-10-28 11:34:20.322416: saving checkpoint...\n",
      "2021-10-28 11:34:21.348081: done, saving took 1.04 seconds\n",
      "2021-10-28 11:34:21.727529: This epoch took 206.698574 s\n",
      "\n",
      "2021-10-28 11:34:21.735221: \n",
      "epoch:  17\n",
      "2021-10-28 11:37:31.980091: train loss : -0.8563\n",
      "2021-10-28 11:37:46.220147: validation loss: -0.8813\n",
      "2021-10-28 11:37:46.225127: Average global foreground Dice: [0.8871]\n",
      "2021-10-28 11:37:46.232794: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 11:37:46.756359: lr: 0.008364\n",
      "2021-10-28 11:37:46.793556: saving checkpoint...\n",
      "2021-10-28 11:37:47.859227: done, saving took 1.08 seconds\n",
      "2021-10-28 11:37:48.241513: This epoch took 206.500607 s\n",
      "\n",
      "2021-10-28 11:37:48.250005: \n",
      "epoch:  18\n",
      "2021-10-28 11:40:58.908112: train loss : -0.8586\n",
      "2021-10-28 11:41:13.133296: validation loss: -0.8811\n",
      "2021-10-28 11:41:13.141307: Average global foreground Dice: [0.8868]\n",
      "2021-10-28 11:41:13.148758: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 11:41:13.668129: lr: 0.008272\n",
      "2021-10-28 11:41:13.710837: saving checkpoint...\n",
      "2021-10-28 11:41:14.759323: done, saving took 1.07 seconds\n",
      "2021-10-28 11:41:15.177557: This epoch took 206.920981 s\n",
      "\n",
      "2021-10-28 11:41:15.186210: \n",
      "epoch:  19\n",
      "2021-10-28 11:44:25.422435: train loss : -0.8601\n",
      "2021-10-28 11:44:39.638779: validation loss: -0.8863\n",
      "2021-10-28 11:44:39.643161: Average global foreground Dice: [0.8907]\n",
      "2021-10-28 11:44:39.650474: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 11:44:40.151434: lr: 0.008181\n",
      "2021-10-28 11:44:40.187872: saving checkpoint...\n",
      "2021-10-28 11:44:41.201018: done, saving took 1.03 seconds\n",
      "2021-10-28 11:44:41.632374: This epoch took 206.439182 s\n",
      "\n",
      "2021-10-28 11:44:41.640754: \n",
      "epoch:  20\n",
      "2021-10-28 11:47:52.365746: train loss : -0.8625\n",
      "2021-10-28 11:48:06.571875: validation loss: -0.8832\n",
      "2021-10-28 11:48:06.576876: Average global foreground Dice: [0.8874]\n",
      "2021-10-28 11:48:06.584929: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 11:48:07.105694: lr: 0.008088\n",
      "2021-10-28 11:48:07.142633: saving checkpoint...\n",
      "2021-10-28 11:48:08.225252: done, saving took 1.10 seconds\n",
      "2021-10-28 11:48:08.624662: This epoch took 206.975455 s\n",
      "\n",
      "2021-10-28 11:48:08.632534: \n",
      "epoch:  21\n",
      "2021-10-28 11:51:19.176478: train loss : -0.8628\n",
      "2021-10-28 11:51:33.382100: validation loss: -0.8877\n",
      "2021-10-28 11:51:33.388734: Average global foreground Dice: [0.8914]\n",
      "2021-10-28 11:51:33.395457: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 11:51:33.928891: lr: 0.007996\n",
      "2021-10-28 11:51:33.972795: saving checkpoint...\n",
      "2021-10-28 11:51:35.015300: done, saving took 1.07 seconds\n",
      "2021-10-28 11:51:35.395420: This epoch took 206.754472 s\n",
      "\n",
      "2021-10-28 11:51:35.403987: \n",
      "epoch:  22\n",
      "2021-10-28 11:54:46.051545: train loss : -0.8647\n",
      "2021-10-28 11:55:00.267467: validation loss: -0.8873\n",
      "2021-10-28 11:55:00.271503: Average global foreground Dice: [0.8911]\n",
      "2021-10-28 11:55:00.278223: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 11:55:00.766723: lr: 0.007904\n",
      "2021-10-28 11:55:00.801889: saving checkpoint...\n",
      "2021-10-28 11:55:01.810764: done, saving took 1.03 seconds\n",
      "2021-10-28 11:55:02.184712: This epoch took 206.773842 s\n",
      "\n",
      "2021-10-28 11:55:02.195453: \n",
      "epoch:  23\n",
      "2021-10-28 11:58:12.951684: train loss : -0.8653\n",
      "2021-10-28 11:58:27.159018: validation loss: -0.8911\n",
      "2021-10-28 11:58:27.166083: Average global foreground Dice: [0.895]\n",
      "2021-10-28 11:58:27.173605: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 11:58:27.709232: lr: 0.007811\n",
      "2021-10-28 11:58:27.744514: saving checkpoint...\n",
      "2021-10-28 11:58:28.832636: done, saving took 1.11 seconds\n",
      "2021-10-28 11:58:29.093833: This epoch took 206.891854 s\n",
      "\n",
      "2021-10-28 11:58:29.102168: \n",
      "epoch:  24\n",
      "2021-10-28 12:01:40.928701: train loss : -0.8666\n",
      "2021-10-28 12:01:55.140401: validation loss: -0.8936\n",
      "2021-10-28 12:01:55.144392: Average global foreground Dice: [0.8967]\n",
      "2021-10-28 12:01:55.150801: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 12:01:55.676250: lr: 0.007719\n",
      "2021-10-28 12:01:55.726426: saving checkpoint...\n",
      "2021-10-28 12:01:56.753240: done, saving took 1.06 seconds\n",
      "2021-10-28 12:01:57.189731: This epoch took 208.080430 s\n",
      "\n",
      "2021-10-28 12:01:57.197989: \n",
      "epoch:  25\n",
      "2021-10-28 12:05:08.836952: train loss : -0.8675\n",
      "2021-10-28 12:05:23.115888: validation loss: -0.8905\n",
      "2021-10-28 12:05:23.120270: Average global foreground Dice: [0.8932]\n",
      "2021-10-28 12:05:23.128182: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 12:05:23.632115: lr: 0.007626\n",
      "2021-10-28 12:05:23.674695: saving checkpoint...\n",
      "2021-10-28 12:05:24.780624: done, saving took 1.14 seconds\n",
      "2021-10-28 12:05:25.203542: This epoch took 207.998355 s\n",
      "\n",
      "2021-10-28 12:05:25.211699: \n",
      "epoch:  26\n",
      "2021-10-28 12:08:36.919878: train loss : -0.8697\n",
      "2021-10-28 12:08:51.135085: validation loss: -0.8931\n",
      "2021-10-28 12:08:51.140093: Average global foreground Dice: [0.8963]\n",
      "2021-10-28 12:08:51.147406: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 12:08:51.668381: lr: 0.007533\n",
      "2021-10-28 12:08:51.710935: saving checkpoint...\n",
      "2021-10-28 12:08:52.722682: done, saving took 1.04 seconds\n",
      "2021-10-28 12:08:52.970246: This epoch took 207.751077 s\n",
      "\n",
      "2021-10-28 12:08:52.978573: \n",
      "epoch:  27\n",
      "2021-10-28 12:12:04.585348: train loss : -0.8689\n",
      "2021-10-28 12:12:18.797413: validation loss: -0.8925\n",
      "2021-10-28 12:12:18.801968: Average global foreground Dice: [0.8946]\n",
      "2021-10-28 12:12:18.810398: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 12:12:19.301157: lr: 0.00744\n",
      "2021-10-28 12:12:19.336110: saving checkpoint...\n",
      "2021-10-28 12:12:20.364472: done, saving took 1.05 seconds\n",
      "2021-10-28 12:12:20.661699: This epoch took 207.676210 s\n",
      "\n",
      "2021-10-28 12:12:20.669993: \n",
      "epoch:  28\n",
      "2021-10-28 12:15:32.238159: train loss : -0.8705\n",
      "2021-10-28 12:15:46.450774: validation loss: -0.8953\n",
      "2021-10-28 12:15:46.455681: Average global foreground Dice: [0.8975]\n",
      "2021-10-28 12:15:46.462327: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 12:15:47.016224: lr: 0.007347\n",
      "2021-10-28 12:15:47.054356: saving checkpoint...\n",
      "2021-10-28 12:15:48.050085: done, saving took 1.01 seconds\n",
      "2021-10-28 12:15:48.455162: This epoch took 207.778760 s\n",
      "\n",
      "2021-10-28 12:15:48.462931: \n",
      "epoch:  29\n",
      "2021-10-28 12:19:00.375741: train loss : -0.8712\n",
      "2021-10-28 12:19:14.602138: validation loss: -0.8965\n",
      "2021-10-28 12:19:14.606655: Average global foreground Dice: [0.9004]\n",
      "2021-10-28 12:19:14.613981: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 12:19:15.141219: lr: 0.007254\n",
      "2021-10-28 12:19:15.177784: saving checkpoint...\n",
      "2021-10-28 12:19:16.171824: done, saving took 1.01 seconds\n",
      "2021-10-28 12:19:16.556559: This epoch took 208.086843 s\n",
      "\n",
      "2021-10-28 12:19:16.564466: \n",
      "epoch:  30\n",
      "2021-10-28 12:22:28.491709: train loss : -0.8717\n",
      "2021-10-28 12:22:42.726493: validation loss: -0.8962\n",
      "2021-10-28 12:22:42.731299: Average global foreground Dice: [0.8987]\n",
      "2021-10-28 12:22:42.740048: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 12:22:43.233848: lr: 0.007161\n",
      "2021-10-28 12:22:43.270652: saving checkpoint...\n",
      "2021-10-28 12:22:44.278889: done, saving took 1.03 seconds\n",
      "2021-10-28 12:22:44.694703: This epoch took 208.122665 s\n",
      "\n",
      "2021-10-28 12:22:44.702473: \n",
      "epoch:  31\n",
      "2021-10-28 12:25:56.398636: train loss : -0.8745\n",
      "2021-10-28 12:26:10.639947: validation loss: -0.8985\n",
      "2021-10-28 12:26:10.644848: Average global foreground Dice: [0.9011]\n",
      "2021-10-28 12:26:10.651357: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 12:26:11.152865: lr: 0.007067\n",
      "2021-10-28 12:26:11.191107: saving checkpoint...\n",
      "2021-10-28 12:26:12.168608: done, saving took 1.00 seconds\n",
      "2021-10-28 12:26:12.535372: This epoch took 207.826369 s\n",
      "\n",
      "2021-10-28 12:26:12.543758: \n",
      "epoch:  32\n",
      "2021-10-28 12:29:25.080446: train loss : -0.8746\n",
      "2021-10-28 12:29:39.302748: validation loss: -0.8992\n",
      "2021-10-28 12:29:39.307930: Average global foreground Dice: [0.9019]\n",
      "2021-10-28 12:29:39.315217: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 12:29:39.827015: lr: 0.006974\n",
      "2021-10-28 12:29:39.876172: saving checkpoint...\n",
      "2021-10-28 12:29:40.897318: done, saving took 1.05 seconds\n",
      "2021-10-28 12:29:41.284550: This epoch took 208.734088 s\n",
      "\n",
      "2021-10-28 12:29:41.292831: \n",
      "epoch:  33\n",
      "2021-10-28 12:32:53.647401: train loss : -0.8750\n",
      "2021-10-28 12:33:07.869045: validation loss: -0.8989\n",
      "2021-10-28 12:33:07.873525: Average global foreground Dice: [0.9012]\n",
      "2021-10-28 12:33:07.880927: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 12:33:08.416623: lr: 0.00688\n",
      "2021-10-28 12:33:08.451063: saving checkpoint...\n",
      "2021-10-28 12:33:09.491422: done, saving took 1.06 seconds\n",
      "2021-10-28 12:33:09.877799: This epoch took 208.577667 s\n",
      "\n",
      "2021-10-28 12:33:09.886342: \n",
      "epoch:  34\n",
      "2021-10-28 12:36:22.590074: train loss : -0.8767\n",
      "2021-10-28 12:36:36.782301: validation loss: -0.8999\n",
      "2021-10-28 12:36:36.787902: Average global foreground Dice: [0.9017]\n",
      "2021-10-28 12:36:36.794824: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 12:36:37.286398: lr: 0.006786\n",
      "2021-10-28 12:36:37.322798: saving checkpoint...\n",
      "2021-10-28 12:36:38.362431: done, saving took 1.06 seconds\n",
      "2021-10-28 12:36:38.640296: This epoch took 208.746810 s\n",
      "\n",
      "2021-10-28 12:36:38.648683: \n",
      "epoch:  35\n",
      "2021-10-28 12:39:51.297125: train loss : -0.8774\n",
      "2021-10-28 12:40:05.513768: validation loss: -0.9032\n",
      "2021-10-28 12:40:05.518044: Average global foreground Dice: [0.9052]\n",
      "2021-10-28 12:40:05.524552: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 12:40:06.015481: lr: 0.006692\n",
      "2021-10-28 12:40:06.051502: saving checkpoint...\n",
      "2021-10-28 12:40:07.100275: done, saving took 1.07 seconds\n",
      "2021-10-28 12:40:07.491105: This epoch took 208.835077 s\n",
      "\n",
      "2021-10-28 12:40:07.499550: \n",
      "epoch:  36\n",
      "2021-10-28 12:43:20.243677: train loss : -0.8770\n",
      "2021-10-28 12:43:34.449753: validation loss: -0.9041\n",
      "2021-10-28 12:43:34.454022: Average global foreground Dice: [0.9052]\n",
      "2021-10-28 12:43:34.460528: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 12:43:35.020869: lr: 0.006598\n",
      "2021-10-28 12:43:35.063449: saving checkpoint...\n",
      "2021-10-28 12:43:36.091237: done, saving took 1.05 seconds\n",
      "2021-10-28 12:43:36.448781: This epoch took 208.942507 s\n",
      "\n",
      "2021-10-28 12:43:36.457746: \n",
      "epoch:  37\n",
      "2021-10-28 12:46:49.219677: train loss : -0.8776\n",
      "2021-10-28 12:47:03.429217: validation loss: -0.9015\n",
      "2021-10-28 12:47:03.433816: Average global foreground Dice: [0.9024]\n",
      "2021-10-28 12:47:03.440262: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 12:47:03.984608: lr: 0.006504\n",
      "2021-10-28 12:47:04.025646: saving checkpoint...\n",
      "2021-10-28 12:47:05.025903: done, saving took 1.03 seconds\n",
      "2021-10-28 12:47:05.195730: This epoch took 208.731276 s\n",
      "\n",
      "2021-10-28 12:47:05.203939: \n",
      "epoch:  38\n",
      "2021-10-28 12:50:18.050752: train loss : -0.8782\n",
      "2021-10-28 12:50:32.287443: validation loss: -0.9050\n",
      "2021-10-28 12:50:32.292332: Average global foreground Dice: [0.9061]\n",
      "2021-10-28 12:50:32.300768: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 12:50:32.803272: lr: 0.006409\n",
      "2021-10-28 12:50:32.843526: saving checkpoint...\n",
      "2021-10-28 12:50:33.979462: done, saving took 1.16 seconds\n",
      "2021-10-28 12:50:34.420027: This epoch took 209.209206 s\n",
      "\n",
      "2021-10-28 12:50:34.428860: \n",
      "epoch:  39\n",
      "2021-10-28 12:53:47.057044: train loss : -0.8789\n",
      "2021-10-28 12:54:01.265657: validation loss: -0.9044\n",
      "2021-10-28 12:54:01.270348: Average global foreground Dice: [0.9067]\n",
      "2021-10-28 12:54:01.278303: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 12:54:01.775927: lr: 0.006314\n",
      "2021-10-28 12:54:01.825542: saving checkpoint...\n",
      "2021-10-28 12:54:02.833725: done, saving took 1.04 seconds\n",
      "2021-10-28 12:54:03.235741: This epoch took 208.799377 s\n",
      "\n",
      "2021-10-28 12:54:03.244181: \n",
      "epoch:  40\n",
      "2021-10-28 12:57:15.984676: train loss : -0.8797\n",
      "2021-10-28 12:57:30.195783: validation loss: -0.9056\n",
      "2021-10-28 12:57:30.200633: Average global foreground Dice: [0.9057]\n",
      "2021-10-28 12:57:30.208355: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 12:57:30.725476: lr: 0.00622\n",
      "2021-10-28 12:57:30.774807: saving checkpoint...\n",
      "2021-10-28 12:57:31.791093: done, saving took 1.05 seconds\n",
      "2021-10-28 12:57:32.177624: This epoch took 208.926119 s\n",
      "\n",
      "2021-10-28 12:57:32.185692: \n",
      "epoch:  41\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-28 13:00:44.791861: train loss : -0.8809\n",
      "2021-10-28 13:00:59.010289: validation loss: -0.9071\n",
      "2021-10-28 13:00:59.014766: Average global foreground Dice: [0.9084]\n",
      "2021-10-28 13:00:59.022260: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 13:00:59.519018: lr: 0.006125\n",
      "2021-10-28 13:00:59.565437: saving checkpoint...\n",
      "2021-10-28 13:01:00.571880: done, saving took 1.04 seconds\n",
      "2021-10-28 13:01:01.023774: This epoch took 208.830882 s\n",
      "\n",
      "2021-10-28 13:01:01.032017: \n",
      "epoch:  42\n",
      "2021-10-28 13:04:13.800021: train loss : -0.8815\n",
      "2021-10-28 13:04:28.031100: validation loss: -0.9087\n",
      "2021-10-28 13:04:28.035739: Average global foreground Dice: [0.91]\n",
      "2021-10-28 13:04:28.043050: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 13:04:28.586387: lr: 0.00603\n",
      "2021-10-28 13:04:28.623890: saving checkpoint...\n",
      "2021-10-28 13:04:29.653636: done, saving took 1.05 seconds\n",
      "2021-10-28 13:04:30.080181: This epoch took 209.041963 s\n",
      "\n",
      "2021-10-28 13:04:30.091518: \n",
      "epoch:  43\n",
      "2021-10-28 13:07:42.763367: train loss : -0.8826\n",
      "2021-10-28 13:07:57.002563: validation loss: -0.9068\n",
      "2021-10-28 13:07:57.006856: Average global foreground Dice: [0.9087]\n",
      "2021-10-28 13:07:57.013067: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 13:07:57.512077: lr: 0.005934\n",
      "2021-10-28 13:07:57.547349: saving checkpoint...\n",
      "2021-10-28 13:07:58.727378: done, saving took 1.20 seconds\n",
      "2021-10-28 13:07:58.983957: This epoch took 208.884175 s\n",
      "\n",
      "2021-10-28 13:07:58.992426: \n",
      "epoch:  44\n",
      "2021-10-28 13:11:11.762040: train loss : -0.8832\n",
      "2021-10-28 13:11:25.999951: validation loss: -0.9096\n",
      "2021-10-28 13:11:26.004409: Average global foreground Dice: [0.911]\n",
      "2021-10-28 13:11:26.010573: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 13:11:26.514097: lr: 0.005839\n",
      "2021-10-28 13:11:26.551061: saving checkpoint...\n",
      "2021-10-28 13:11:27.624505: done, saving took 1.09 seconds\n",
      "2021-10-28 13:11:27.999438: This epoch took 208.999993 s\n",
      "\n",
      "2021-10-28 13:11:28.007933: \n",
      "epoch:  45\n",
      "2021-10-28 13:14:40.820135: train loss : -0.8847\n",
      "2021-10-28 13:14:55.041722: validation loss: -0.9096\n",
      "2021-10-28 13:14:55.046465: Average global foreground Dice: [0.9108]\n",
      "2021-10-28 13:14:55.053317: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 13:14:55.547927: lr: 0.005743\n",
      "2021-10-28 13:14:55.592393: saving checkpoint...\n",
      "2021-10-28 13:14:56.643142: done, saving took 1.08 seconds\n",
      "2021-10-28 13:14:56.915405: This epoch took 208.900574 s\n",
      "\n",
      "2021-10-28 13:14:56.923328: \n",
      "epoch:  46\n",
      "2021-10-28 13:18:09.681342: train loss : -0.8843\n",
      "2021-10-28 13:18:23.910402: validation loss: -0.9114\n",
      "2021-10-28 13:18:23.915161: Average global foreground Dice: [0.9122]\n",
      "2021-10-28 13:18:23.921438: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 13:18:24.430114: lr: 0.005647\n",
      "2021-10-28 13:18:24.479822: saving checkpoint...\n",
      "2021-10-28 13:18:25.496905: done, saving took 1.05 seconds\n",
      "2021-10-28 13:18:25.755847: This epoch took 208.825383 s\n",
      "\n",
      "2021-10-28 13:18:25.764970: \n",
      "epoch:  47\n",
      "2021-10-28 13:21:38.496865: train loss : -0.8848\n",
      "2021-10-28 13:21:52.705225: validation loss: -0.9120\n",
      "2021-10-28 13:21:52.709444: Average global foreground Dice: [0.9133]\n",
      "2021-10-28 13:21:52.716751: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 13:21:53.266703: lr: 0.005551\n",
      "2021-10-28 13:21:53.318358: saving checkpoint...\n",
      "2021-10-28 13:21:54.392815: done, saving took 1.11 seconds\n",
      "2021-10-28 13:21:54.636374: This epoch took 208.861528 s\n",
      "\n",
      "2021-10-28 13:21:54.645594: \n",
      "epoch:  48\n",
      "2021-10-28 13:25:07.364571: train loss : -0.8857\n",
      "2021-10-28 13:25:21.576022: validation loss: -0.9108\n",
      "2021-10-28 13:25:21.581308: Average global foreground Dice: [0.9116]\n",
      "2021-10-28 13:25:21.588820: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 13:25:22.114618: lr: 0.005455\n",
      "2021-10-28 13:25:22.155515: saving checkpoint...\n",
      "2021-10-28 13:25:23.139609: done, saving took 1.00 seconds\n",
      "2021-10-28 13:25:23.513277: This epoch took 208.860077 s\n",
      "\n",
      "2021-10-28 13:25:23.521375: \n",
      "epoch:  49\n",
      "2021-10-28 13:28:36.352638: train loss : -0.8851\n",
      "2021-10-28 13:28:50.569062: validation loss: -0.9135\n",
      "2021-10-28 13:28:50.573819: Average global foreground Dice: [0.9147]\n",
      "2021-10-28 13:28:50.580691: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 13:28:51.108161: lr: 0.005359\n",
      "2021-10-28 13:28:51.128955: saving scheduled checkpoint file...\n",
      "2021-10-28 13:28:51.155230: saving checkpoint...\n",
      "2021-10-28 13:28:52.273748: done, saving took 1.14 seconds\n",
      "2021-10-28 13:28:52.480390: done\n",
      "2021-10-28 13:28:52.508720: saving checkpoint...\n",
      "2021-10-28 13:28:53.503144: done, saving took 1.01 seconds\n",
      "2021-10-28 13:28:53.882464: This epoch took 210.354250 s\n",
      "\n",
      "2021-10-28 13:28:53.890793: \n",
      "epoch:  50\n",
      "2021-10-28 13:32:06.645224: train loss : -0.8873\n",
      "2021-10-28 13:32:20.856606: validation loss: -0.9129\n",
      "2021-10-28 13:32:20.861025: Average global foreground Dice: [0.9134]\n",
      "2021-10-28 13:32:20.867945: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 13:32:21.446090: lr: 0.005262\n",
      "2021-10-28 13:32:21.495507: saving checkpoint...\n",
      "2021-10-28 13:32:22.570023: done, saving took 1.10 seconds\n",
      "2021-10-28 13:32:23.185496: This epoch took 209.287975 s\n",
      "\n",
      "2021-10-28 13:32:23.194198: \n",
      "epoch:  51\n",
      "2021-10-28 13:35:35.958861: train loss : -0.8874\n",
      "2021-10-28 13:35:50.172952: validation loss: -0.9161\n",
      "2021-10-28 13:35:50.177672: Average global foreground Dice: [0.9153]\n",
      "2021-10-28 13:35:50.184466: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 13:35:50.741179: lr: 0.005166\n",
      "2021-10-28 13:35:50.787427: saving checkpoint...\n",
      "2021-10-28 13:35:51.789816: done, saving took 1.03 seconds\n",
      "2021-10-28 13:35:52.183790: This epoch took 208.976966 s\n",
      "\n",
      "2021-10-28 13:35:52.192091: \n",
      "epoch:  52\n",
      "2021-10-28 13:39:04.817087: train loss : -0.8876\n",
      "2021-10-28 13:39:19.033197: validation loss: -0.9140\n",
      "2021-10-28 13:39:19.037768: Average global foreground Dice: [0.9144]\n",
      "2021-10-28 13:39:19.045294: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 13:39:19.541028: lr: 0.005069\n",
      "2021-10-28 13:39:19.582755: saving checkpoint...\n",
      "2021-10-28 13:39:20.591944: done, saving took 1.03 seconds\n",
      "2021-10-28 13:39:21.027645: This epoch took 208.827963 s\n",
      "\n",
      "2021-10-28 13:39:21.036306: \n",
      "epoch:  53\n",
      "2021-10-28 13:42:33.682066: train loss : -0.8890\n",
      "2021-10-28 13:42:47.905161: validation loss: -0.9163\n",
      "2021-10-28 13:42:47.909747: Average global foreground Dice: [0.9165]\n",
      "2021-10-28 13:42:47.916583: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 13:42:48.418710: lr: 0.004971\n",
      "2021-10-28 13:42:48.451670: saving checkpoint...\n",
      "2021-10-28 13:42:49.465712: done, saving took 1.03 seconds\n",
      "2021-10-28 13:42:49.834697: This epoch took 208.791732 s\n",
      "\n",
      "2021-10-28 13:42:49.842752: \n",
      "epoch:  54\n",
      "2021-10-28 13:46:02.388018: train loss : -0.8894\n",
      "2021-10-28 13:46:16.625078: validation loss: -0.9149\n",
      "2021-10-28 13:46:16.630523: Average global foreground Dice: [0.9152]\n",
      "2021-10-28 13:46:16.637926: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 13:46:17.168914: lr: 0.004874\n",
      "2021-10-28 13:46:17.213808: saving checkpoint...\n",
      "2021-10-28 13:46:18.225988: done, saving took 1.04 seconds\n",
      "2021-10-28 13:46:18.484266: This epoch took 208.634567 s\n",
      "\n",
      "2021-10-28 13:46:18.493341: \n",
      "epoch:  55\n",
      "2021-10-28 13:49:31.195938: train loss : -0.8902\n",
      "2021-10-28 13:49:45.435077: validation loss: -0.9175\n",
      "2021-10-28 13:49:45.440140: Average global foreground Dice: [0.9179]\n",
      "2021-10-28 13:49:45.447736: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 13:49:45.954741: lr: 0.004776\n",
      "2021-10-28 13:49:45.994550: saving checkpoint...\n",
      "2021-10-28 13:49:47.026403: done, saving took 1.06 seconds\n",
      "2021-10-28 13:49:47.258530: This epoch took 208.758011 s\n",
      "\n",
      "2021-10-28 13:49:47.266537: \n",
      "epoch:  56\n",
      "2021-10-28 13:53:00.012258: train loss : -0.8900\n",
      "2021-10-28 13:53:14.238827: validation loss: -0.9183\n",
      "2021-10-28 13:53:14.243379: Average global foreground Dice: [0.9188]\n",
      "2021-10-28 13:53:14.249966: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 13:53:14.775395: lr: 0.004679\n",
      "2021-10-28 13:53:14.821947: saving checkpoint...\n",
      "2021-10-28 13:53:15.831222: done, saving took 1.03 seconds\n",
      "2021-10-28 13:53:16.255418: This epoch took 208.982275 s\n",
      "\n",
      "2021-10-28 13:53:16.264026: \n",
      "epoch:  57\n",
      "2021-10-28 13:56:28.880394: train loss : -0.8899\n",
      "2021-10-28 13:56:43.094452: validation loss: -0.9154\n",
      "2021-10-28 13:56:43.099524: Average global foreground Dice: [0.9152]\n",
      "2021-10-28 13:56:43.106761: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 13:56:43.647386: lr: 0.004581\n",
      "2021-10-28 13:56:43.690466: saving checkpoint...\n",
      "2021-10-28 13:56:44.711370: done, saving took 1.05 seconds\n",
      "2021-10-28 13:56:45.090969: This epoch took 208.820664 s\n",
      "\n",
      "2021-10-28 13:56:45.099455: \n",
      "epoch:  58\n",
      "2021-10-28 13:59:57.703026: train loss : -0.8915\n",
      "2021-10-28 14:00:11.910934: validation loss: -0.9210\n",
      "2021-10-28 14:00:11.915699: Average global foreground Dice: [0.9206]\n",
      "2021-10-28 14:00:11.923030: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 14:00:12.445350: lr: 0.004482\n",
      "2021-10-28 14:00:12.491786: saving checkpoint...\n",
      "2021-10-28 14:00:13.480584: done, saving took 1.01 seconds\n",
      "2021-10-28 14:00:13.866702: This epoch took 208.761090 s\n",
      "\n",
      "2021-10-28 14:00:13.875078: \n",
      "epoch:  59\n",
      "2021-10-28 14:03:26.680233: train loss : -0.8923\n",
      "2021-10-28 14:03:40.885992: validation loss: -0.9191\n",
      "2021-10-28 14:03:40.891253: Average global foreground Dice: [0.9184]\n",
      "2021-10-28 14:03:40.897239: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 14:03:41.402475: lr: 0.004384\n",
      "2021-10-28 14:03:41.451325: saving checkpoint...\n",
      "2021-10-28 14:03:42.483720: done, saving took 1.06 seconds\n",
      "2021-10-28 14:03:42.918818: This epoch took 209.037259 s\n",
      "\n",
      "2021-10-28 14:03:42.926852: \n",
      "epoch:  60\n",
      "2021-10-28 14:06:55.744492: train loss : -0.8924\n",
      "2021-10-28 14:07:09.962073: validation loss: -0.9192\n",
      "2021-10-28 14:07:09.967509: Average global foreground Dice: [0.9191]\n",
      "2021-10-28 14:07:09.974024: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 14:07:10.496346: lr: 0.004285\n",
      "2021-10-28 14:07:10.543838: saving checkpoint...\n",
      "2021-10-28 14:07:11.546577: done, saving took 1.03 seconds\n",
      "2021-10-28 14:07:11.970480: This epoch took 209.036336 s\n",
      "\n",
      "2021-10-28 14:07:11.979560: \n",
      "epoch:  61\n",
      "2021-10-28 14:10:24.834819: train loss : -0.8930\n",
      "2021-10-28 14:10:39.040298: validation loss: -0.9222\n",
      "2021-10-28 14:10:39.046872: Average global foreground Dice: [0.9223]\n",
      "2021-10-28 14:10:39.052901: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 14:10:39.597824: lr: 0.004186\n",
      "2021-10-28 14:10:39.648263: saving checkpoint...\n",
      "2021-10-28 14:10:40.657617: done, saving took 1.04 seconds\n",
      "2021-10-28 14:10:40.863930: This epoch took 208.877153 s\n",
      "\n",
      "2021-10-28 14:10:40.871975: \n",
      "epoch:  62\n",
      "2021-10-28 14:13:53.730850: train loss : -0.8933\n",
      "2021-10-28 14:14:07.942768: validation loss: -0.9197\n",
      "2021-10-28 14:14:07.947493: Average global foreground Dice: [0.9201]\n",
      "2021-10-28 14:14:07.954974: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 14:14:08.454201: lr: 0.004087\n",
      "2021-10-28 14:14:08.498984: saving checkpoint...\n",
      "2021-10-28 14:14:09.512990: done, saving took 1.05 seconds\n",
      "2021-10-28 14:14:09.886232: This epoch took 209.007607 s\n",
      "\n",
      "2021-10-28 14:14:09.894850: \n",
      "epoch:  63\n",
      "2021-10-28 14:17:22.717263: train loss : -0.8946\n",
      "2021-10-28 14:17:36.947425: validation loss: -0.9231\n",
      "2021-10-28 14:17:36.952180: Average global foreground Dice: [0.923]\n",
      "2021-10-28 14:17:36.959773: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 14:17:37.498897: lr: 0.003987\n",
      "2021-10-28 14:17:37.551464: saving checkpoint...\n",
      "2021-10-28 14:17:38.551248: done, saving took 1.03 seconds\n",
      "2021-10-28 14:17:39.090715: This epoch took 209.188504 s\n",
      "\n",
      "2021-10-28 14:17:39.099620: \n",
      "epoch:  64\n",
      "2021-10-28 14:20:51.896686: train loss : -0.8950\n",
      "2021-10-28 14:21:06.112294: validation loss: -0.9216\n",
      "2021-10-28 14:21:06.116961: Average global foreground Dice: [0.9206]\n",
      "2021-10-28 14:21:06.124178: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 14:21:06.676320: lr: 0.003887\n",
      "2021-10-28 14:21:06.723100: saving checkpoint...\n",
      "2021-10-28 14:21:07.754447: done, saving took 1.06 seconds\n",
      "2021-10-28 14:21:09.252543: This epoch took 210.146091 s\n",
      "\n",
      "2021-10-28 14:21:09.261564: \n",
      "epoch:  65\n",
      "2021-10-28 14:24:21.991758: train loss : -0.8959\n",
      "2021-10-28 14:24:36.231416: validation loss: -0.9236\n",
      "2021-10-28 14:24:36.235734: Average global foreground Dice: [0.923]\n",
      "2021-10-28 14:24:36.242227: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 14:24:36.761636: lr: 0.003787\n",
      "2021-10-28 14:24:36.809847: saving checkpoint...\n",
      "2021-10-28 14:24:37.864345: done, saving took 1.08 seconds\n",
      "2021-10-28 14:24:38.122933: This epoch took 208.854028 s\n",
      "\n",
      "2021-10-28 14:24:38.131173: \n",
      "epoch:  66\n",
      "2021-10-28 14:27:50.691767: train loss : -0.8960\n",
      "2021-10-28 14:28:04.933738: validation loss: -0.9228\n",
      "2021-10-28 14:28:04.938359: Average global foreground Dice: [0.9221]\n",
      "2021-10-28 14:28:04.946275: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 14:28:05.466221: lr: 0.003687\n",
      "2021-10-28 14:28:05.503071: saving checkpoint...\n",
      "2021-10-28 14:28:06.497904: done, saving took 1.01 seconds\n",
      "2021-10-28 14:28:06.891760: This epoch took 208.753224 s\n",
      "\n",
      "2021-10-28 14:28:06.900443: \n",
      "epoch:  67\n",
      "2021-10-28 14:31:19.395269: train loss : -0.8957\n",
      "2021-10-28 14:31:33.628712: validation loss: -0.9253\n",
      "2021-10-28 14:31:33.633126: Average global foreground Dice: [0.9244]\n",
      "2021-10-28 14:31:33.640114: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 14:31:34.122289: lr: 0.003586\n",
      "2021-10-28 14:31:34.154488: saving checkpoint...\n",
      "2021-10-28 14:31:35.179436: done, saving took 1.04 seconds\n",
      "2021-10-28 14:31:35.587424: This epoch took 208.680112 s\n",
      "\n",
      "2021-10-28 14:31:35.596136: \n",
      "epoch:  68\n",
      "2021-10-28 14:34:48.236866: train loss : -0.8973\n",
      "2021-10-28 14:35:02.459135: validation loss: -0.9249\n",
      "2021-10-28 14:35:02.463387: Average global foreground Dice: [0.9248]\n",
      "2021-10-28 14:35:02.470720: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 14:35:03.004150: lr: 0.003485\n",
      "2021-10-28 14:35:03.040857: saving checkpoint...\n",
      "2021-10-28 14:35:04.092312: done, saving took 1.07 seconds\n",
      "2021-10-28 14:35:04.502129: This epoch took 208.897877 s\n",
      "\n",
      "2021-10-28 14:35:04.510040: \n",
      "epoch:  69\n",
      "2021-10-28 14:38:17.254081: train loss : -0.8980\n",
      "2021-10-28 14:38:31.458951: validation loss: -0.9261\n",
      "2021-10-28 14:38:31.465261: Average global foreground Dice: [0.9249]\n",
      "2021-10-28 14:38:31.472567: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 14:38:32.016111: lr: 0.003384\n",
      "2021-10-28 14:38:32.095011: saving checkpoint...\n",
      "2021-10-28 14:38:33.116732: done, saving took 1.05 seconds\n",
      "2021-10-28 14:38:33.524356: This epoch took 209.008428 s\n",
      "\n",
      "2021-10-28 14:38:33.532620: \n",
      "epoch:  70\n",
      "2021-10-28 14:41:46.185101: train loss : -0.8972\n",
      "2021-10-28 14:42:00.388373: validation loss: -0.9247\n",
      "2021-10-28 14:42:00.393623: Average global foreground Dice: [0.9229]\n",
      "2021-10-28 14:42:00.401304: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 14:42:00.945978: lr: 0.003282\n",
      "2021-10-28 14:42:00.992633: saving checkpoint...\n",
      "2021-10-28 14:42:02.035939: done, saving took 1.07 seconds\n",
      "2021-10-28 14:42:02.457075: This epoch took 208.917669 s\n",
      "\n",
      "2021-10-28 14:42:02.465458: \n",
      "epoch:  71\n",
      "2021-10-28 14:45:14.998883: train loss : -0.8978\n",
      "2021-10-28 14:45:29.211338: validation loss: -0.9271\n",
      "2021-10-28 14:45:29.215647: Average global foreground Dice: [0.9263]\n",
      "2021-10-28 14:45:29.222905: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 14:45:29.728858: lr: 0.00318\n",
      "2021-10-28 14:45:29.779261: saving checkpoint...\n",
      "2021-10-28 14:45:30.826042: done, saving took 1.08 seconds\n",
      "2021-10-28 14:45:31.151694: This epoch took 208.678593 s\n",
      "\n",
      "2021-10-28 14:45:31.160469: \n",
      "epoch:  72\n",
      "2021-10-28 14:48:43.686072: train loss : -0.8987\n",
      "2021-10-28 14:48:57.891749: validation loss: -0.9284\n",
      "2021-10-28 14:48:57.896641: Average global foreground Dice: [0.9271]\n",
      "2021-10-28 14:48:57.903016: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 14:48:58.389088: lr: 0.003078\n",
      "2021-10-28 14:48:58.426539: saving checkpoint...\n",
      "2021-10-28 14:48:59.431376: done, saving took 1.02 seconds\n",
      "2021-10-28 14:48:59.803805: This epoch took 208.635371 s\n",
      "\n",
      "2021-10-28 14:48:59.814633: \n",
      "epoch:  73\n",
      "2021-10-28 14:52:12.465928: train loss : -0.8998\n",
      "2021-10-28 14:52:26.679961: validation loss: -0.9260\n",
      "2021-10-28 14:52:26.684437: Average global foreground Dice: [0.9251]\n",
      "2021-10-28 14:52:26.691628: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 14:52:27.216983: lr: 0.002975\n",
      "2021-10-28 14:52:27.254694: saving checkpoint...\n",
      "2021-10-28 14:52:28.259275: done, saving took 1.02 seconds\n",
      "2021-10-28 14:52:28.557156: This epoch took 208.736548 s\n",
      "\n",
      "2021-10-28 14:52:28.566279: \n",
      "epoch:  74\n",
      "2021-10-28 14:55:41.401453: train loss : -0.8999\n",
      "2021-10-28 14:55:55.611548: validation loss: -0.9305\n",
      "2021-10-28 14:55:55.616473: Average global foreground Dice: [0.929]\n",
      "2021-10-28 14:55:55.623753: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 14:55:56.100736: lr: 0.002872\n",
      "2021-10-28 14:55:56.139075: saving checkpoint...\n",
      "2021-10-28 14:55:57.244148: done, saving took 1.12 seconds\n",
      "2021-10-28 14:55:57.507950: This epoch took 208.934315 s\n",
      "\n",
      "2021-10-28 14:55:57.516704: \n",
      "epoch:  75\n",
      "2021-10-28 14:59:10.257203: train loss : -0.9005\n",
      "2021-10-28 14:59:24.471281: validation loss: -0.9293\n",
      "2021-10-28 14:59:24.476067: Average global foreground Dice: [0.9276]\n",
      "2021-10-28 14:59:24.483287: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 14:59:25.020930: lr: 0.002768\n",
      "2021-10-28 14:59:25.056966: saving checkpoint...\n",
      "2021-10-28 14:59:26.058286: done, saving took 1.02 seconds\n",
      "2021-10-28 14:59:26.489195: This epoch took 208.965446 s\n",
      "\n",
      "2021-10-28 14:59:26.497569: \n",
      "epoch:  76\n",
      "2021-10-28 15:02:39.023609: train loss : -0.9004\n",
      "2021-10-28 15:02:53.254632: validation loss: -0.9272\n",
      "2021-10-28 15:02:53.258904: Average global foreground Dice: [0.9262]\n",
      "2021-10-28 15:02:53.265469: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 15:02:53.800392: lr: 0.002664\n",
      "2021-10-28 15:02:53.835186: saving checkpoint...\n",
      "2021-10-28 15:02:54.859983: done, saving took 1.04 seconds\n",
      "2021-10-28 15:02:55.321605: This epoch took 208.810157 s\n",
      "\n",
      "2021-10-28 15:02:55.333280: \n",
      "epoch:  77\n",
      "2021-10-28 15:06:07.932480: train loss : -0.9011\n",
      "2021-10-28 15:06:22.163176: validation loss: -0.9312\n",
      "2021-10-28 15:06:22.169291: Average global foreground Dice: [0.9299]\n",
      "2021-10-28 15:06:22.177516: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 15:06:22.712472: lr: 0.00256\n",
      "2021-10-28 15:06:22.756472: saving checkpoint...\n",
      "2021-10-28 15:06:23.811890: done, saving took 1.08 seconds\n",
      "2021-10-28 15:06:24.070472: This epoch took 208.728820 s\n",
      "\n",
      "2021-10-28 15:06:24.079339: \n",
      "epoch:  78\n",
      "2021-10-28 15:09:36.737965: train loss : -0.9017\n",
      "2021-10-28 15:09:50.977815: validation loss: -0.9320\n",
      "2021-10-28 15:09:50.982681: Average global foreground Dice: [0.9298]\n",
      "2021-10-28 15:09:50.989640: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 15:09:51.512366: lr: 0.002455\n",
      "2021-10-28 15:09:51.551588: saving checkpoint...\n",
      "2021-10-28 15:09:52.541286: done, saving took 1.01 seconds\n",
      "2021-10-28 15:09:53.274990: This epoch took 209.188129 s\n",
      "\n",
      "2021-10-28 15:09:53.284718: \n",
      "epoch:  79\n",
      "2021-10-28 15:13:05.616101: train loss : -0.9019\n",
      "2021-10-28 15:13:19.840630: validation loss: -0.9310\n",
      "2021-10-28 15:13:19.845557: Average global foreground Dice: [0.93]\n",
      "2021-10-28 15:13:19.853106: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 15:13:20.336493: lr: 0.002349\n",
      "2021-10-28 15:13:20.379196: saving checkpoint...\n",
      "2021-10-28 15:13:21.394114: done, saving took 1.03 seconds\n",
      "2021-10-28 15:13:21.842297: This epoch took 208.551020 s\n",
      "\n",
      "2021-10-28 15:13:21.851067: \n",
      "epoch:  80\n",
      "2021-10-28 15:16:34.381101: train loss : -0.9028\n",
      "2021-10-28 15:16:48.598322: validation loss: -0.9313\n",
      "2021-10-28 15:16:48.603109: Average global foreground Dice: [0.93]\n",
      "2021-10-28 15:16:48.610355: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 15:16:49.114359: lr: 0.002243\n",
      "2021-10-28 15:16:49.151685: saving checkpoint...\n",
      "2021-10-28 15:16:50.222453: done, saving took 1.09 seconds\n",
      "2021-10-28 15:16:50.654106: This epoch took 208.795123 s\n",
      "\n",
      "2021-10-28 15:16:50.663724: \n",
      "epoch:  81\n",
      "2021-10-28 15:20:03.182088: train loss : -0.9038\n",
      "2021-10-28 15:20:17.396677: validation loss: -0.9335\n",
      "2021-10-28 15:20:17.402403: Average global foreground Dice: [0.9312]\n",
      "2021-10-28 15:20:17.409553: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 15:20:17.917278: lr: 0.002137\n",
      "2021-10-28 15:20:17.955405: saving checkpoint...\n",
      "2021-10-28 15:20:18.989637: done, saving took 1.05 seconds\n",
      "2021-10-28 15:20:19.429922: This epoch took 208.758855 s\n",
      "\n",
      "2021-10-28 15:20:19.440301: \n",
      "epoch:  82\n",
      "2021-10-28 15:23:32.033266: train loss : -0.9025\n",
      "2021-10-28 15:23:46.244749: validation loss: -0.9330\n",
      "2021-10-28 15:23:46.249171: Average global foreground Dice: [0.9312]\n",
      "2021-10-28 15:23:46.256676: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 15:23:46.765115: lr: 0.00203\n",
      "2021-10-28 15:23:46.799288: saving checkpoint...\n",
      "2021-10-28 15:23:47.806037: done, saving took 1.03 seconds\n",
      "2021-10-28 15:23:48.356815: This epoch took 208.906116 s\n",
      "\n",
      "2021-10-28 15:23:48.365756: \n",
      "epoch:  83\n",
      "2021-10-28 15:27:00.977938: train loss : -0.9037\n",
      "2021-10-28 15:27:15.187562: validation loss: -0.9329\n",
      "2021-10-28 15:27:15.192230: Average global foreground Dice: [0.9317]\n",
      "2021-10-28 15:27:15.200073: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 15:27:15.682089: lr: 0.001922\n",
      "2021-10-28 15:27:15.721596: saving checkpoint...\n",
      "2021-10-28 15:27:16.824918: done, saving took 1.12 seconds\n",
      "2021-10-28 15:27:17.223840: This epoch took 208.850548 s\n",
      "\n",
      "2021-10-28 15:27:17.233878: \n",
      "epoch:  84\n",
      "2021-10-28 15:30:29.980513: train loss : -0.9057\n",
      "2021-10-28 15:30:44.194541: validation loss: -0.9342\n",
      "2021-10-28 15:30:44.199383: Average global foreground Dice: [0.9329]\n",
      "2021-10-28 15:30:44.206085: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 15:30:44.697864: lr: 0.001813\n",
      "2021-10-28 15:30:44.745963: saving checkpoint...\n",
      "2021-10-28 15:30:45.833886: done, saving took 1.12 seconds\n",
      "2021-10-28 15:30:46.206170: This epoch took 208.964853 s\n",
      "\n",
      "2021-10-28 15:30:46.214707: \n",
      "epoch:  85\n",
      "2021-10-28 15:33:58.976149: train loss : -0.9048\n",
      "2021-10-28 15:34:13.189048: validation loss: -0.9348\n",
      "2021-10-28 15:34:13.193944: Average global foreground Dice: [0.9327]\n",
      "2021-10-28 15:34:13.201268: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 15:34:13.722022: lr: 0.001704\n",
      "2021-10-28 15:34:13.766098: saving checkpoint...\n",
      "2021-10-28 15:34:14.791488: done, saving took 1.06 seconds\n",
      "2021-10-28 15:34:15.155034: This epoch took 208.932923 s\n",
      "\n",
      "2021-10-28 15:34:15.163295: \n",
      "epoch:  86\n",
      "2021-10-28 15:37:27.730857: train loss : -0.9065\n",
      "2021-10-28 15:37:41.943214: validation loss: -0.9346\n",
      "2021-10-28 15:37:41.949120: Average global foreground Dice: [0.9326]\n",
      "2021-10-28 15:37:41.956363: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 15:37:42.452460: lr: 0.001594\n",
      "2021-10-28 15:37:42.498653: saving checkpoint...\n",
      "2021-10-28 15:37:43.553787: done, saving took 1.09 seconds\n",
      "2021-10-28 15:37:44.153780: This epoch took 208.983529 s\n",
      "\n",
      "2021-10-28 15:37:44.162317: \n",
      "epoch:  87\n",
      "2021-10-28 15:40:56.679757: train loss : -0.9070\n",
      "2021-10-28 15:41:10.901582: validation loss: -0.9361\n",
      "2021-10-28 15:41:10.906118: Average global foreground Dice: [0.9342]\n",
      "2021-10-28 15:41:10.912874: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 15:41:11.399302: lr: 0.001483\n",
      "2021-10-28 15:41:11.447684: saving checkpoint...\n",
      "2021-10-28 15:41:12.485724: done, saving took 1.07 seconds\n",
      "2021-10-28 15:41:12.894412: This epoch took 208.725197 s\n",
      "\n",
      "2021-10-28 15:41:12.902596: \n",
      "epoch:  88\n",
      "2021-10-28 15:44:25.464736: train loss : -0.9067\n",
      "2021-10-28 15:44:39.696818: validation loss: -0.9373\n",
      "2021-10-28 15:44:39.701774: Average global foreground Dice: [0.9357]\n",
      "2021-10-28 15:44:39.708301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 15:44:40.232362: lr: 0.001372\n",
      "2021-10-28 15:44:40.281763: saving checkpoint...\n",
      "2021-10-28 15:44:41.438189: done, saving took 1.19 seconds\n",
      "2021-10-28 15:44:41.860345: This epoch took 208.947832 s\n",
      "\n",
      "2021-10-28 15:44:41.869571: \n",
      "epoch:  89\n",
      "2021-10-28 15:47:54.351265: train loss : -0.9074\n",
      "2021-10-28 15:48:08.588549: validation loss: -0.9381\n",
      "2021-10-28 15:48:08.594077: Average global foreground Dice: [0.9354]\n",
      "2021-10-28 15:48:08.602293: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 15:48:09.132768: lr: 0.001259\n",
      "2021-10-28 15:48:09.179996: saving checkpoint...\n",
      "2021-10-28 15:48:10.202702: done, saving took 1.06 seconds\n",
      "2021-10-28 15:48:10.738657: This epoch took 208.862051 s\n",
      "\n",
      "2021-10-28 15:48:10.747668: \n",
      "epoch:  90\n",
      "2021-10-28 15:51:23.258218: train loss : -0.9089\n",
      "2021-10-28 15:51:37.485089: validation loss: -0.9386\n",
      "2021-10-28 15:51:37.491439: Average global foreground Dice: [0.9368]\n",
      "2021-10-28 15:51:37.497483: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 15:51:38.026071: lr: 0.001145\n",
      "2021-10-28 15:51:38.074111: saving checkpoint...\n",
      "2021-10-28 15:51:39.112528: done, saving took 1.07 seconds\n",
      "2021-10-28 15:51:39.499044: This epoch took 208.744831 s\n",
      "\n",
      "2021-10-28 15:51:39.507278: \n",
      "epoch:  91\n",
      "2021-10-28 15:54:52.135949: train loss : -0.9089\n",
      "2021-10-28 15:55:06.352453: validation loss: -0.9379\n",
      "2021-10-28 15:55:06.357090: Average global foreground Dice: [0.9361]\n",
      "2021-10-28 15:55:06.364432: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 15:55:06.893294: lr: 0.00103\n",
      "2021-10-28 15:55:06.940600: saving checkpoint...\n",
      "2021-10-28 15:55:07.939981: done, saving took 1.03 seconds\n",
      "2021-10-28 15:55:08.334415: This epoch took 208.820001 s\n",
      "\n",
      "2021-10-28 15:55:08.345307: \n",
      "epoch:  92\n",
      "2021-10-28 15:58:20.967376: train loss : -0.9096\n",
      "2021-10-28 15:58:35.178778: validation loss: -0.9405\n",
      "2021-10-28 15:58:35.185962: Average global foreground Dice: [0.9381]\n",
      "2021-10-28 15:58:35.194044: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 15:58:35.689354: lr: 0.000913\n",
      "2021-10-28 15:58:35.738261: saving checkpoint...\n",
      "2021-10-28 15:58:36.807522: done, saving took 1.10 seconds\n",
      "2021-10-28 15:58:37.179644: This epoch took 208.827145 s\n",
      "\n",
      "2021-10-28 15:58:37.188370: \n",
      "epoch:  93\n",
      "2021-10-28 16:01:49.895728: train loss : -0.9096\n",
      "2021-10-28 16:02:04.106983: validation loss: -0.9387\n",
      "2021-10-28 16:02:04.111785: Average global foreground Dice: [0.9362]\n",
      "2021-10-28 16:02:04.119314: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 16:02:04.646004: lr: 0.000795\n",
      "2021-10-28 16:02:04.683747: saving checkpoint...\n",
      "2021-10-28 16:02:05.715351: done, saving took 1.05 seconds\n",
      "2021-10-28 16:02:06.102627: This epoch took 208.907525 s\n",
      "\n",
      "2021-10-28 16:02:06.113399: \n",
      "epoch:  94\n",
      "2021-10-28 16:05:18.974211: train loss : -0.9101\n",
      "2021-10-28 16:05:33.189767: validation loss: -0.9404\n",
      "2021-10-28 16:05:33.196547: Average global foreground Dice: [0.9388]\n",
      "2021-10-28 16:05:33.203753: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 16:05:33.725219: lr: 0.000675\n",
      "2021-10-28 16:05:33.757914: saving checkpoint...\n",
      "2021-10-28 16:05:34.777429: done, saving took 1.04 seconds\n",
      "2021-10-28 16:05:35.335003: This epoch took 209.214557 s\n",
      "\n",
      "2021-10-28 16:05:35.343345: \n",
      "epoch:  95\n",
      "2021-10-28 16:08:48.181065: train loss : -0.9094\n",
      "2021-10-28 16:09:02.396297: validation loss: -0.9408\n",
      "2021-10-28 16:09:02.400429: Average global foreground Dice: [0.9384]\n",
      "2021-10-28 16:09:02.407146: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 16:09:02.924997: lr: 0.000552\n",
      "2021-10-28 16:09:02.959657: saving checkpoint...\n",
      "2021-10-28 16:09:04.020826: done, saving took 1.08 seconds\n",
      "2021-10-28 16:09:04.785192: This epoch took 209.433932 s\n",
      "\n",
      "2021-10-28 16:09:04.795467: \n",
      "epoch:  96\n",
      "2021-10-28 16:12:17.578549: train loss : -0.9113\n",
      "2021-10-28 16:12:31.788163: validation loss: -0.9412\n",
      "2021-10-28 16:12:31.793054: Average global foreground Dice: [0.9387]\n",
      "2021-10-28 16:12:31.800696: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 16:12:32.292389: lr: 0.000426\n",
      "2021-10-28 16:12:32.335966: saving checkpoint...\n",
      "2021-10-28 16:12:33.363268: done, saving took 1.05 seconds\n",
      "2021-10-28 16:12:33.693194: This epoch took 208.890170 s\n",
      "\n",
      "2021-10-28 16:12:33.702187: \n",
      "epoch:  97\n",
      "2021-10-28 16:15:46.342587: train loss : -0.9119\n",
      "2021-10-28 16:16:00.555208: validation loss: -0.9429\n",
      "2021-10-28 16:16:00.560002: Average global foreground Dice: [0.9403]\n",
      "2021-10-28 16:16:00.567846: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 16:16:01.112090: lr: 0.000296\n",
      "2021-10-28 16:16:01.157172: saving checkpoint...\n",
      "2021-10-28 16:16:02.202558: done, saving took 1.07 seconds\n",
      "2021-10-28 16:16:02.711601: This epoch took 209.001963 s\n",
      "\n",
      "2021-10-28 16:16:02.721170: \n",
      "epoch:  98\n",
      "2021-10-28 16:19:15.201427: train loss : -0.9104\n",
      "2021-10-28 16:19:29.423903: validation loss: -0.9407\n",
      "2021-10-28 16:19:29.428656: Average global foreground Dice: [0.9387]\n",
      "2021-10-28 16:19:29.439046: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 16:19:29.989140: lr: 0.000158\n",
      "2021-10-28 16:19:30.039738: saving checkpoint...\n",
      "2021-10-28 16:19:31.154629: done, saving took 1.14 seconds\n",
      "2021-10-28 16:19:31.872626: This epoch took 209.140599 s\n",
      "\n",
      "2021-10-28 16:19:31.880466: \n",
      "epoch:  99\n",
      "2021-10-28 16:22:44.555253: train loss : -0.9116\n",
      "2021-10-28 16:22:58.779069: validation loss: -0.9426\n",
      "2021-10-28 16:22:58.783739: Average global foreground Dice: [0.9404]\n",
      "2021-10-28 16:22:58.792657: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 16:22:59.300477: lr: 0.0\n",
      "2021-10-28 16:22:59.329766: saving scheduled checkpoint file...\n",
      "2021-10-28 16:22:59.359071: saving checkpoint...\n",
      "2021-10-28 16:23:00.478998: done, saving took 1.14 seconds\n",
      "2021-10-28 16:23:00.878047: done\n",
      "2021-10-28 16:23:00.906677: saving checkpoint...\n",
      "2021-10-28 16:23:01.941309: done, saving took 1.05 seconds\n",
      "2021-10-28 16:23:02.379063: This epoch took 210.487885 s\n",
      "\n",
      "2021-10-28 16:23:02.406212: saving checkpoint...\n",
      "2021-10-28 16:23:03.332567: done, saving took 0.95 seconds\n",
      "23090557_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090558_20120 (3, 263, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090559_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090560_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090562_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090563_20151 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090564_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090566_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090567_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090568_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090569_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090571_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090584_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090589_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090590_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090592_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090593_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090596_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090597_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090599_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090600_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090603_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090604_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090607_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090608_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090609_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090614_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090615_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090616_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090617_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090619_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090620_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090621_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090627_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090628_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090629_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090631_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090634_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090635_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090636_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090637_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090640_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090644_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090646_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-28 16:32:22.105578: finished prediction\n",
      "2021-10-28 16:32:22.111493: evaluation of raw predictions\n",
      "2021-10-28 16:32:28.512501: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.9553244485714515\n",
      "after:  0.9553244485714515\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_CEGDL 555 all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-10-29 07:41:45.691577: Creating new 5-fold cross-validation split...\n",
      "2021-10-29 07:41:45.710309: Desired fold for training: 0\n",
      "2021-10-29 07:41:45.714455: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-29 07:41:54.350784: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-29 07:42:02.364164: Unable to plot network architecture:\n",
      "2021-10-29 07:42:02.366336: No module named 'hiddenlayer'\n",
      "2021-10-29 07:42:02.372029: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-29 07:42:02.439317: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-29 07:42:02.450731: \n",
      "\n",
      "2021-10-29 07:42:02.455902: \n",
      "epoch:  0\n",
      "2021-10-29 07:45:03.310955: train loss : -0.2613\n",
      "2021-10-29 07:45:15.997457: validation loss: -0.6347\n",
      "2021-10-29 07:45:16.000547: Average global foreground Dice: [0.726]\n",
      "2021-10-29 07:45:16.004649: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 07:45:16.425461: lr: 0.00991\n",
      "2021-10-29 07:45:16.439684: This epoch took 193.979554 s\n",
      "\n",
      "2021-10-29 07:45:16.444568: \n",
      "epoch:  1\n",
      "2021-10-29 07:48:08.996344: train loss : -0.6610\n",
      "2021-10-29 07:48:21.954867: validation loss: -0.7313\n",
      "2021-10-29 07:48:21.957413: Average global foreground Dice: [0.802]\n",
      "2021-10-29 07:48:21.961977: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 07:48:22.441152: lr: 0.00982\n",
      "2021-10-29 07:48:22.475872: saving checkpoint...\n",
      "2021-10-29 07:48:23.280077: done, saving took 0.82 seconds\n",
      "2021-10-29 07:48:23.696256: This epoch took 187.247645 s\n",
      "\n",
      "2021-10-29 07:48:23.702680: \n",
      "epoch:  2\n",
      "2021-10-29 07:51:17.865959: train loss : -0.7587\n",
      "2021-10-29 07:51:30.867140: validation loss: -0.8019\n",
      "2021-10-29 07:51:30.869618: Average global foreground Dice: [0.8257]\n",
      "2021-10-29 07:51:30.873631: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 07:51:31.347352: lr: 0.00973\n",
      "2021-10-29 07:51:31.398471: saving checkpoint...\n",
      "2021-10-29 07:51:32.037620: done, saving took 0.67 seconds\n",
      "2021-10-29 07:51:32.453394: This epoch took 188.745373 s\n",
      "\n",
      "2021-10-29 07:51:32.460826: \n",
      "epoch:  3\n",
      "2021-10-29 07:54:26.967631: train loss : -0.7894\n",
      "2021-10-29 07:54:39.994846: validation loss: -0.8147\n",
      "2021-10-29 07:54:39.997176: Average global foreground Dice: [0.8395]\n",
      "2021-10-29 07:54:40.001053: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 07:54:40.467089: lr: 0.009639\n",
      "2021-10-29 07:54:40.521729: saving checkpoint...\n",
      "2021-10-29 07:54:41.174495: done, saving took 0.69 seconds\n",
      "2021-10-29 07:54:41.554642: This epoch took 189.087266 s\n",
      "\n",
      "2021-10-29 07:54:41.562145: \n",
      "epoch:  4\n",
      "2021-10-29 07:57:35.968906: train loss : -0.8051\n",
      "2021-10-29 07:57:48.976492: validation loss: -0.8215\n",
      "2021-10-29 07:57:48.979236: Average global foreground Dice: [0.8395]\n",
      "2021-10-29 07:57:48.983209: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 07:57:49.455001: lr: 0.009549\n",
      "2021-10-29 07:57:49.501229: saving checkpoint...\n",
      "2021-10-29 07:57:50.143694: done, saving took 0.67 seconds\n",
      "2021-10-29 07:57:50.538620: This epoch took 188.970801 s\n",
      "\n",
      "2021-10-29 07:57:50.545619: \n",
      "epoch:  5\n",
      "2021-10-29 08:00:44.667864: train loss : -0.8143\n",
      "2021-10-29 08:00:57.667520: validation loss: -0.8296\n",
      "2021-10-29 08:00:57.670455: Average global foreground Dice: [0.8447]\n",
      "2021-10-29 08:00:57.675659: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:00:58.142286: lr: 0.009458\n",
      "2021-10-29 08:00:58.178002: saving checkpoint...\n",
      "2021-10-29 08:00:58.825410: done, saving took 0.67 seconds\n",
      "2021-10-29 08:00:59.211370: This epoch took 188.659881 s\n",
      "\n",
      "2021-10-29 08:00:59.217531: \n",
      "epoch:  6\n",
      "2021-10-29 08:03:53.398823: train loss : -0.8206\n",
      "2021-10-29 08:04:06.426629: validation loss: -0.8250\n",
      "2021-10-29 08:04:06.429321: Average global foreground Dice: [0.8401]\n",
      "2021-10-29 08:04:06.433224: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:04:06.905508: lr: 0.009368\n",
      "2021-10-29 08:04:06.942630: saving checkpoint...\n",
      "2021-10-29 08:04:07.669771: done, saving took 0.75 seconds\n",
      "2021-10-29 08:04:08.066405: This epoch took 188.842692 s\n",
      "\n",
      "2021-10-29 08:04:08.072896: \n",
      "epoch:  7\n",
      "2021-10-29 08:07:02.359312: train loss : -0.8277\n",
      "2021-10-29 08:07:15.359334: validation loss: -0.8337\n",
      "2021-10-29 08:07:15.361985: Average global foreground Dice: [0.8485]\n",
      "2021-10-29 08:07:15.367180: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:07:15.843472: lr: 0.009277\n",
      "2021-10-29 08:07:15.880464: saving checkpoint...\n",
      "2021-10-29 08:07:16.607441: done, saving took 0.75 seconds\n",
      "2021-10-29 08:07:16.999704: This epoch took 188.922330 s\n",
      "\n",
      "2021-10-29 08:07:17.007239: \n",
      "epoch:  8\n",
      "2021-10-29 08:10:11.521673: train loss : -0.8324\n",
      "2021-10-29 08:10:24.539049: validation loss: -0.8276\n",
      "2021-10-29 08:10:24.552202: Average global foreground Dice: [0.8403]\n",
      "2021-10-29 08:10:24.556579: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:10:25.043398: lr: 0.009186\n",
      "2021-10-29 08:10:25.075667: saving checkpoint...\n",
      "2021-10-29 08:10:25.716643: done, saving took 0.66 seconds\n",
      "2021-10-29 08:10:26.136609: This epoch took 189.123253 s\n",
      "\n",
      "2021-10-29 08:10:26.143609: \n",
      "epoch:  9\n",
      "2021-10-29 08:13:20.894236: train loss : -0.8355\n",
      "2021-10-29 08:13:33.927471: validation loss: -0.8231\n",
      "2021-10-29 08:13:33.930594: Average global foreground Dice: [0.8388]\n",
      "2021-10-29 08:13:33.934813: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:13:34.407944: lr: 0.009095\n",
      "2021-10-29 08:13:34.442386: saving checkpoint...\n",
      "2021-10-29 08:13:35.110331: done, saving took 0.69 seconds\n",
      "2021-10-29 08:13:35.493769: This epoch took 189.344290 s\n",
      "\n",
      "2021-10-29 08:13:35.500553: \n",
      "epoch:  10\n",
      "2021-10-29 08:16:30.315989: train loss : -0.8402\n",
      "2021-10-29 08:16:43.321263: validation loss: -0.8331\n",
      "2021-10-29 08:16:43.323804: Average global foreground Dice: [0.8475]\n",
      "2021-10-29 08:16:43.328726: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:16:43.801797: lr: 0.009004\n",
      "2021-10-29 08:16:43.835677: saving checkpoint...\n",
      "2021-10-29 08:16:44.486937: done, saving took 0.67 seconds\n",
      "2021-10-29 08:16:44.895349: This epoch took 189.389984 s\n",
      "\n",
      "2021-10-29 08:16:44.903828: \n",
      "epoch:  11\n",
      "2021-10-29 08:19:39.451842: train loss : -0.8437\n",
      "2021-10-29 08:19:52.468217: validation loss: -0.8322\n",
      "2021-10-29 08:19:52.471369: Average global foreground Dice: [0.8454]\n",
      "2021-10-29 08:19:52.477101: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:19:52.946983: lr: 0.008913\n",
      "2021-10-29 08:19:52.984668: saving checkpoint...\n",
      "2021-10-29 08:19:53.637826: done, saving took 0.67 seconds\n",
      "2021-10-29 08:19:54.080092: This epoch took 189.171514 s\n",
      "\n",
      "2021-10-29 08:19:54.087391: \n",
      "epoch:  12\n",
      "2021-10-29 08:22:48.969226: train loss : -0.8457\n",
      "2021-10-29 08:23:02.002472: validation loss: -0.8335\n",
      "2021-10-29 08:23:02.005191: Average global foreground Dice: [0.8509]\n",
      "2021-10-29 08:23:02.009781: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:23:02.540200: lr: 0.008822\n",
      "2021-10-29 08:23:02.575650: saving checkpoint...\n",
      "2021-10-29 08:23:03.221977: done, saving took 0.66 seconds\n",
      "2021-10-29 08:23:03.589741: This epoch took 189.496854 s\n",
      "\n",
      "2021-10-29 08:23:03.597942: \n",
      "epoch:  13\n",
      "2021-10-29 08:25:58.326803: train loss : -0.8477\n",
      "2021-10-29 08:26:11.334799: validation loss: -0.8361\n",
      "2021-10-29 08:26:11.338368: Average global foreground Dice: [0.8466]\n",
      "2021-10-29 08:26:11.344186: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:26:11.812543: lr: 0.008731\n",
      "2021-10-29 08:26:11.847820: saving checkpoint...\n",
      "2021-10-29 08:26:12.492489: done, saving took 0.66 seconds\n",
      "2021-10-29 08:26:12.873016: This epoch took 189.268219 s\n",
      "\n",
      "2021-10-29 08:26:12.880977: \n",
      "epoch:  14\n",
      "2021-10-29 08:29:07.665716: train loss : -0.8482\n",
      "2021-10-29 08:29:20.686688: validation loss: -0.8412\n",
      "2021-10-29 08:29:20.689432: Average global foreground Dice: [0.8528]\n",
      "2021-10-29 08:29:20.694182: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:29:21.213123: lr: 0.008639\n",
      "2021-10-29 08:29:21.244185: saving checkpoint...\n",
      "2021-10-29 08:29:21.903596: done, saving took 0.68 seconds\n",
      "2021-10-29 08:29:22.288911: This epoch took 189.403374 s\n",
      "\n",
      "2021-10-29 08:29:22.295650: \n",
      "epoch:  15\n",
      "2021-10-29 08:32:17.173160: train loss : -0.8526\n",
      "2021-10-29 08:32:30.240077: validation loss: -0.8409\n",
      "2021-10-29 08:32:30.242730: Average global foreground Dice: [0.8562]\n",
      "2021-10-29 08:32:30.247670: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:32:30.725614: lr: 0.008548\n",
      "2021-10-29 08:32:30.760392: saving checkpoint...\n",
      "2021-10-29 08:32:31.430238: done, saving took 0.69 seconds\n",
      "2021-10-29 08:32:31.818434: This epoch took 189.517392 s\n",
      "\n",
      "2021-10-29 08:32:31.824779: \n",
      "epoch:  16\n",
      "2021-10-29 08:35:26.768674: train loss : -0.8548\n",
      "2021-10-29 08:35:39.784123: validation loss: -0.8309\n",
      "2021-10-29 08:35:39.786583: Average global foreground Dice: [0.8448]\n",
      "2021-10-29 08:35:39.792556: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:35:40.273067: lr: 0.008456\n",
      "2021-10-29 08:35:40.304398: saving checkpoint...\n",
      "2021-10-29 08:35:40.969651: done, saving took 0.68 seconds\n",
      "2021-10-29 08:35:41.336410: This epoch took 189.505019 s\n",
      "\n",
      "2021-10-29 08:35:41.343660: \n",
      "epoch:  17\n",
      "2021-10-29 08:38:36.085547: train loss : -0.8561\n",
      "2021-10-29 08:38:49.097477: validation loss: -0.8328\n",
      "2021-10-29 08:38:49.101440: Average global foreground Dice: [0.8477]\n",
      "2021-10-29 08:38:49.107465: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:38:49.647221: lr: 0.008364\n",
      "2021-10-29 08:38:49.681056: saving checkpoint...\n",
      "2021-10-29 08:38:50.332918: done, saving took 0.67 seconds\n",
      "2021-10-29 08:38:50.709582: This epoch took 189.360939 s\n",
      "\n",
      "2021-10-29 08:38:50.715950: \n",
      "epoch:  18\n",
      "2021-10-29 08:41:45.534595: train loss : -0.8582\n",
      "2021-10-29 08:41:58.533555: validation loss: -0.8245\n",
      "2021-10-29 08:41:58.536069: Average global foreground Dice: [0.839]\n",
      "2021-10-29 08:41:58.540474: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:41:59.025210: lr: 0.008272\n",
      "2021-10-29 08:41:59.057355: saving checkpoint...\n",
      "2021-10-29 08:41:59.712430: done, saving took 0.67 seconds\n",
      "2021-10-29 08:42:00.097628: This epoch took 189.376497 s\n",
      "\n",
      "2021-10-29 08:42:00.104088: \n",
      "epoch:  19\n",
      "2021-10-29 08:44:54.820635: train loss : -0.8616\n",
      "2021-10-29 08:45:07.827410: validation loss: -0.8382\n",
      "2021-10-29 08:45:07.830090: Average global foreground Dice: [0.8516]\n",
      "2021-10-29 08:45:07.834584: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:45:08.314499: lr: 0.008181\n",
      "2021-10-29 08:45:08.350799: saving checkpoint...\n",
      "2021-10-29 08:45:09.013007: done, saving took 0.68 seconds\n",
      "2021-10-29 08:45:09.405800: This epoch took 189.296455 s\n",
      "\n",
      "2021-10-29 08:45:09.412000: \n",
      "epoch:  20\n",
      "2021-10-29 08:48:04.195283: train loss : -0.8619\n",
      "2021-10-29 08:48:17.209655: validation loss: -0.8443\n",
      "2021-10-29 08:48:17.213272: Average global foreground Dice: [0.8552]\n",
      "2021-10-29 08:48:17.218990: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:48:17.696598: lr: 0.008088\n",
      "2021-10-29 08:48:17.732373: saving checkpoint...\n",
      "2021-10-29 08:48:18.387161: done, saving took 0.67 seconds\n",
      "2021-10-29 08:48:18.787867: This epoch took 189.371726 s\n",
      "\n",
      "2021-10-29 08:48:18.797876: \n",
      "epoch:  21\n",
      "2021-10-29 08:51:13.667714: train loss : -0.8630\n",
      "2021-10-29 08:51:26.726249: validation loss: -0.8357\n",
      "2021-10-29 08:51:26.728852: Average global foreground Dice: [0.8488]\n",
      "2021-10-29 08:51:26.733344: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:51:27.205221: lr: 0.007996\n",
      "2021-10-29 08:51:27.240929: saving checkpoint...\n",
      "2021-10-29 08:51:27.905475: done, saving took 0.68 seconds\n",
      "2021-10-29 08:51:28.279020: This epoch took 189.475396 s\n",
      "\n",
      "2021-10-29 08:51:28.285840: \n",
      "epoch:  22\n",
      "2021-10-29 08:54:23.213737: train loss : -0.8654\n",
      "2021-10-29 08:54:36.229915: validation loss: -0.8386\n",
      "2021-10-29 08:54:36.232646: Average global foreground Dice: [0.8524]\n",
      "2021-10-29 08:54:36.237797: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:54:36.710477: lr: 0.007904\n",
      "2021-10-29 08:54:36.744626: saving checkpoint...\n",
      "2021-10-29 08:54:37.450237: done, saving took 0.72 seconds\n",
      "2021-10-29 08:54:37.821399: This epoch took 189.530226 s\n",
      "\n",
      "2021-10-29 08:54:37.831174: \n",
      "epoch:  23\n",
      "2021-10-29 08:57:32.913464: train loss : -0.8654\n",
      "2021-10-29 08:57:45.931045: validation loss: -0.8333\n",
      "2021-10-29 08:57:45.935382: Average global foreground Dice: [0.8467]\n",
      "2021-10-29 08:57:45.940658: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 08:57:46.416717: lr: 0.007811\n",
      "2021-10-29 08:57:46.453085: saving checkpoint...\n",
      "2021-10-29 08:57:47.105273: done, saving took 0.67 seconds\n",
      "2021-10-29 08:57:47.485567: This epoch took 189.648825 s\n",
      "\n",
      "2021-10-29 08:57:47.491741: \n",
      "epoch:  24\n",
      "2021-10-29 09:00:43.153121: train loss : -0.8657\n",
      "2021-10-29 09:00:56.204047: validation loss: -0.8393\n",
      "2021-10-29 09:00:56.207064: Average global foreground Dice: [0.852]\n",
      "2021-10-29 09:00:56.212030: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:00:56.682364: lr: 0.007719\n",
      "2021-10-29 09:00:56.714263: saving checkpoint...\n",
      "2021-10-29 09:00:57.359880: done, saving took 0.66 seconds\n",
      "2021-10-29 09:00:57.749616: This epoch took 190.252050 s\n",
      "\n",
      "2021-10-29 09:00:57.755823: \n",
      "epoch:  25\n",
      "2021-10-29 09:03:53.280286: train loss : -0.8677\n",
      "2021-10-29 09:04:06.306254: validation loss: -0.8401\n",
      "2021-10-29 09:04:06.308922: Average global foreground Dice: [0.8532]\n",
      "2021-10-29 09:04:06.313918: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:04:06.785623: lr: 0.007626\n",
      "2021-10-29 09:04:06.820497: saving checkpoint...\n",
      "2021-10-29 09:04:07.480699: done, saving took 0.68 seconds\n",
      "2021-10-29 09:04:07.872130: This epoch took 190.110043 s\n",
      "\n",
      "2021-10-29 09:04:07.879012: \n",
      "epoch:  26\n",
      "2021-10-29 09:07:03.304103: train loss : -0.8694\n",
      "2021-10-29 09:07:16.329617: validation loss: -0.8382\n",
      "2021-10-29 09:07:16.332693: Average global foreground Dice: [0.8524]\n",
      "2021-10-29 09:07:16.338845: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:07:16.814411: lr: 0.007533\n",
      "2021-10-29 09:07:16.851003: saving checkpoint...\n",
      "2021-10-29 09:07:17.511126: done, saving took 0.68 seconds\n",
      "2021-10-29 09:07:17.881050: This epoch took 189.995789 s\n",
      "\n",
      "2021-10-29 09:07:17.888257: \n",
      "epoch:  27\n",
      "2021-10-29 09:10:13.388862: train loss : -0.8714\n",
      "2021-10-29 09:10:26.401016: validation loss: -0.8362\n",
      "2021-10-29 09:10:26.404200: Average global foreground Dice: [0.8502]\n",
      "2021-10-29 09:10:26.410176: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:10:26.890186: lr: 0.00744\n",
      "2021-10-29 09:10:26.920677: saving checkpoint...\n",
      "2021-10-29 09:10:27.588309: done, saving took 0.69 seconds\n",
      "2021-10-29 09:10:28.073438: This epoch took 190.179681 s\n",
      "\n",
      "2021-10-29 09:10:28.080562: \n",
      "epoch:  28\n",
      "2021-10-29 09:13:23.345642: train loss : -0.8709\n",
      "2021-10-29 09:13:36.359156: validation loss: -0.8359\n",
      "2021-10-29 09:13:36.361959: Average global foreground Dice: [0.8484]\n",
      "2021-10-29 09:13:36.366719: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:13:36.910455: lr: 0.007347\n",
      "2021-10-29 09:13:36.946320: saving checkpoint...\n",
      "2021-10-29 09:13:37.594342: done, saving took 0.67 seconds\n",
      "2021-10-29 09:13:37.986615: This epoch took 189.899835 s\n",
      "\n",
      "2021-10-29 09:13:37.992878: \n",
      "epoch:  29\n",
      "2021-10-29 09:16:33.233391: train loss : -0.8722\n",
      "2021-10-29 09:16:46.239347: validation loss: -0.8303\n",
      "2021-10-29 09:16:46.243210: Average global foreground Dice: [0.8434]\n",
      "2021-10-29 09:16:46.248086: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:16:46.724597: lr: 0.007254\n",
      "2021-10-29 09:16:46.760099: saving checkpoint...\n",
      "2021-10-29 09:16:47.407341: done, saving took 0.67 seconds\n",
      "2021-10-29 09:16:47.777136: This epoch took 189.779003 s\n",
      "\n",
      "2021-10-29 09:16:47.783987: \n",
      "epoch:  30\n",
      "2021-10-29 09:19:42.786098: train loss : -0.8734\n",
      "2021-10-29 09:19:55.795619: validation loss: -0.8313\n",
      "2021-10-29 09:19:55.799524: Average global foreground Dice: [0.844]\n",
      "2021-10-29 09:19:55.803974: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:19:56.281897: lr: 0.007161\n",
      "2021-10-29 09:19:56.314178: saving checkpoint...\n",
      "2021-10-29 09:19:56.960865: done, saving took 0.67 seconds\n",
      "2021-10-29 09:19:57.324751: This epoch took 189.534678 s\n",
      "\n",
      "2021-10-29 09:19:57.332324: \n",
      "epoch:  31\n",
      "2021-10-29 09:22:52.701037: train loss : -0.8742\n",
      "2021-10-29 09:23:05.731225: validation loss: -0.8306\n",
      "2021-10-29 09:23:05.734365: Average global foreground Dice: [0.844]\n",
      "2021-10-29 09:23:05.739463: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:23:06.213742: lr: 0.007067\n",
      "2021-10-29 09:23:06.246534: saving checkpoint...\n",
      "2021-10-29 09:23:06.903477: done, saving took 0.68 seconds\n",
      "2021-10-29 09:23:07.316697: This epoch took 189.978702 s\n",
      "\n",
      "2021-10-29 09:23:07.324358: \n",
      "epoch:  32\n",
      "2021-10-29 09:26:02.950074: train loss : -0.8758\n",
      "2021-10-29 09:26:15.981136: validation loss: -0.8289\n",
      "2021-10-29 09:26:15.983592: Average global foreground Dice: [0.8426]\n",
      "2021-10-29 09:26:15.988984: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:26:16.468498: lr: 0.006974\n",
      "2021-10-29 09:26:16.486451: This epoch took 189.155073 s\n",
      "\n",
      "2021-10-29 09:26:16.492415: \n",
      "epoch:  33\n",
      "2021-10-29 09:29:12.513746: train loss : -0.8769\n",
      "2021-10-29 09:29:25.545775: validation loss: -0.8355\n",
      "2021-10-29 09:29:25.549469: Average global foreground Dice: [0.8472]\n",
      "2021-10-29 09:29:25.553918: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:29:26.091660: lr: 0.00688\n",
      "2021-10-29 09:29:26.124164: saving checkpoint...\n",
      "2021-10-29 09:29:26.769110: done, saving took 0.66 seconds\n",
      "2021-10-29 09:29:27.183558: This epoch took 190.685884 s\n",
      "\n",
      "2021-10-29 09:29:27.190507: \n",
      "epoch:  34\n",
      "2021-10-29 09:32:22.341228: train loss : -0.8763\n",
      "2021-10-29 09:32:35.308391: validation loss: -0.8389\n",
      "2021-10-29 09:32:35.311057: Average global foreground Dice: [0.8508]\n",
      "2021-10-29 09:32:35.316515: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:32:35.797846: lr: 0.006786\n",
      "2021-10-29 09:32:35.835148: saving checkpoint...\n",
      "2021-10-29 09:32:36.486435: done, saving took 0.67 seconds\n",
      "2021-10-29 09:32:36.857718: This epoch took 189.662100 s\n",
      "\n",
      "2021-10-29 09:32:36.864308: \n",
      "epoch:  35\n",
      "2021-10-29 09:35:31.844728: train loss : -0.8778\n",
      "2021-10-29 09:35:44.809612: validation loss: -0.8341\n",
      "2021-10-29 09:35:44.812618: Average global foreground Dice: [0.8466]\n",
      "2021-10-29 09:35:44.817679: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:35:45.298743: lr: 0.006692\n",
      "2021-10-29 09:35:45.333855: saving checkpoint...\n",
      "2021-10-29 09:35:45.973815: done, saving took 0.66 seconds\n",
      "2021-10-29 09:35:46.393153: This epoch took 189.522482 s\n",
      "\n",
      "2021-10-29 09:35:46.399656: \n",
      "epoch:  36\n",
      "2021-10-29 09:38:41.340297: train loss : -0.8796\n",
      "2021-10-29 09:38:54.322926: validation loss: -0.8216\n",
      "2021-10-29 09:38:54.326662: Average global foreground Dice: [0.8343]\n",
      "2021-10-29 09:38:54.332151: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:38:54.816238: lr: 0.006598\n",
      "2021-10-29 09:38:54.835041: This epoch took 188.430100 s\n",
      "\n",
      "2021-10-29 09:38:54.840289: \n",
      "epoch:  37\n",
      "2021-10-29 09:41:49.592454: train loss : -0.8796\n",
      "2021-10-29 09:42:02.537855: validation loss: -0.8371\n",
      "2021-10-29 09:42:02.540690: Average global foreground Dice: [0.8493]\n",
      "2021-10-29 09:42:02.546411: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:42:03.029346: lr: 0.006504\n",
      "2021-10-29 09:42:03.047312: This epoch took 188.202773 s\n",
      "\n",
      "2021-10-29 09:42:03.052500: \n",
      "epoch:  38\n",
      "2021-10-29 09:44:57.981426: train loss : -0.8819\n",
      "2021-10-29 09:45:10.966842: validation loss: -0.8308\n",
      "2021-10-29 09:45:10.969857: Average global foreground Dice: [0.8428]\n",
      "2021-10-29 09:45:10.975181: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:45:11.525984: lr: 0.006409\n",
      "2021-10-29 09:45:11.539450: This epoch took 188.481826 s\n",
      "\n",
      "2021-10-29 09:45:11.544797: \n",
      "epoch:  39\n",
      "2021-10-29 09:48:06.555632: train loss : -0.8811\n",
      "2021-10-29 09:48:19.526259: validation loss: -0.8333\n",
      "2021-10-29 09:48:19.528907: Average global foreground Dice: [0.8456]\n",
      "2021-10-29 09:48:19.534476: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:48:20.014224: lr: 0.006314\n",
      "2021-10-29 09:48:20.029207: This epoch took 188.478723 s\n",
      "\n",
      "2021-10-29 09:48:20.034739: \n",
      "epoch:  40\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-29 09:51:14.809887: train loss : -0.8818\n",
      "2021-10-29 09:51:27.784673: validation loss: -0.8277\n",
      "2021-10-29 09:51:27.787766: Average global foreground Dice: [0.8414]\n",
      "2021-10-29 09:51:27.792329: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:51:28.274154: lr: 0.00622\n",
      "2021-10-29 09:51:28.290380: This epoch took 188.250773 s\n",
      "\n",
      "2021-10-29 09:51:28.295764: \n",
      "epoch:  41\n",
      "2021-10-29 09:54:23.018889: train loss : -0.8831\n",
      "2021-10-29 09:54:35.996083: validation loss: -0.8378\n",
      "2021-10-29 09:54:35.999323: Average global foreground Dice: [0.8496]\n",
      "2021-10-29 09:54:36.004658: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:54:36.481922: lr: 0.006125\n",
      "2021-10-29 09:54:36.529397: saving checkpoint...\n",
      "2021-10-29 09:54:37.200332: done, saving took 0.70 seconds\n",
      "2021-10-29 09:54:37.570264: This epoch took 189.268194 s\n",
      "\n",
      "2021-10-29 09:54:37.577577: \n",
      "epoch:  42\n",
      "2021-10-29 09:57:32.187780: train loss : -0.8846\n",
      "2021-10-29 09:57:45.164910: validation loss: -0.8286\n",
      "2021-10-29 09:57:45.168460: Average global foreground Dice: [0.8416]\n",
      "2021-10-29 09:57:45.173688: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 09:57:45.649979: lr: 0.00603\n",
      "2021-10-29 09:57:45.665444: This epoch took 188.082253 s\n",
      "\n",
      "2021-10-29 09:57:45.670570: \n",
      "epoch:  43\n",
      "2021-10-29 10:00:40.343993: train loss : -0.8846\n",
      "2021-10-29 10:00:53.293957: validation loss: -0.8255\n",
      "2021-10-29 10:00:53.296530: Average global foreground Dice: [0.8407]\n",
      "2021-10-29 10:00:53.302754: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:00:53.846611: lr: 0.005934\n",
      "2021-10-29 10:00:53.866397: This epoch took 188.190543 s\n",
      "\n",
      "2021-10-29 10:00:53.873718: \n",
      "epoch:  44\n",
      "2021-10-29 10:03:48.765905: train loss : -0.8851\n",
      "2021-10-29 10:04:01.725747: validation loss: -0.8391\n",
      "2021-10-29 10:04:01.728684: Average global foreground Dice: [0.8529]\n",
      "2021-10-29 10:04:01.734272: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:04:02.213252: lr: 0.005839\n",
      "2021-10-29 10:04:02.245106: saving checkpoint...\n",
      "2021-10-29 10:04:02.894036: done, saving took 0.67 seconds\n",
      "2021-10-29 10:04:03.264068: This epoch took 189.384579 s\n",
      "\n",
      "2021-10-29 10:04:03.270934: \n",
      "epoch:  45\n",
      "2021-10-29 10:06:57.965139: train loss : -0.8860\n",
      "2021-10-29 10:07:10.934934: validation loss: -0.8259\n",
      "2021-10-29 10:07:10.938985: Average global foreground Dice: [0.8409]\n",
      "2021-10-29 10:07:10.943092: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:07:11.419952: lr: 0.005743\n",
      "2021-10-29 10:07:11.435803: This epoch took 188.158418 s\n",
      "\n",
      "2021-10-29 10:07:11.441631: \n",
      "epoch:  46\n",
      "2021-10-29 10:10:06.004698: train loss : -0.8869\n",
      "2021-10-29 10:10:18.957454: validation loss: -0.8318\n",
      "2021-10-29 10:10:18.959680: Average global foreground Dice: [0.8445]\n",
      "2021-10-29 10:10:18.965461: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:10:19.441546: lr: 0.005647\n",
      "2021-10-29 10:10:19.456161: This epoch took 188.009115 s\n",
      "\n",
      "2021-10-29 10:10:19.461360: \n",
      "epoch:  47\n",
      "2021-10-29 10:13:13.863119: train loss : -0.8874\n",
      "2021-10-29 10:13:26.803379: validation loss: -0.8309\n",
      "2021-10-29 10:13:26.806758: Average global foreground Dice: [0.8436]\n",
      "2021-10-29 10:13:26.811895: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:13:27.297150: lr: 0.005551\n",
      "2021-10-29 10:13:27.311866: This epoch took 187.845115 s\n",
      "\n",
      "2021-10-29 10:13:27.317139: \n",
      "epoch:  48\n",
      "2021-10-29 10:16:21.792788: train loss : -0.8886\n",
      "2021-10-29 10:16:34.741899: validation loss: -0.8345\n",
      "2021-10-29 10:16:34.744711: Average global foreground Dice: [0.8452]\n",
      "2021-10-29 10:16:34.750252: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:16:35.234325: lr: 0.005455\n",
      "2021-10-29 10:16:35.250299: This epoch took 187.928072 s\n",
      "\n",
      "2021-10-29 10:16:35.255212: \n",
      "epoch:  49\n",
      "2021-10-29 10:19:29.488543: train loss : -0.8899\n",
      "2021-10-29 10:19:42.407060: validation loss: -0.8297\n",
      "2021-10-29 10:19:42.410578: Average global foreground Dice: [0.8413]\n",
      "2021-10-29 10:19:42.416142: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:19:42.903160: lr: 0.005359\n",
      "2021-10-29 10:19:42.916335: saving scheduled checkpoint file...\n",
      "2021-10-29 10:19:42.944226: saving checkpoint...\n",
      "2021-10-29 10:19:43.648451: done, saving took 0.72 seconds\n",
      "2021-10-29 10:19:44.045942: done\n",
      "2021-10-29 10:19:44.054002: This epoch took 188.793494 s\n",
      "\n",
      "2021-10-29 10:19:44.059457: \n",
      "epoch:  50\n",
      "2021-10-29 10:22:38.311701: train loss : -0.8894\n",
      "2021-10-29 10:22:51.246638: validation loss: -0.8359\n",
      "2021-10-29 10:22:51.249825: Average global foreground Dice: [0.8471]\n",
      "2021-10-29 10:22:51.255113: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:22:51.737846: lr: 0.005262\n",
      "2021-10-29 10:22:51.751065: This epoch took 187.685906 s\n",
      "\n",
      "2021-10-29 10:22:51.756705: \n",
      "epoch:  51\n",
      "2021-10-29 10:25:46.494676: train loss : -0.8893\n",
      "2021-10-29 10:25:59.459426: validation loss: -0.8326\n",
      "2021-10-29 10:25:59.463572: Average global foreground Dice: [0.8453]\n",
      "2021-10-29 10:25:59.468951: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:25:59.953515: lr: 0.005166\n",
      "2021-10-29 10:25:59.971828: This epoch took 188.209643 s\n",
      "\n",
      "2021-10-29 10:25:59.976579: \n",
      "epoch:  52\n",
      "2021-10-29 10:28:54.537047: train loss : -0.8901\n",
      "2021-10-29 10:29:07.467793: validation loss: -0.8307\n",
      "2021-10-29 10:29:07.471563: Average global foreground Dice: [0.8424]\n",
      "2021-10-29 10:29:07.476126: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:29:07.955124: lr: 0.005069\n",
      "2021-10-29 10:29:07.972895: This epoch took 187.991875 s\n",
      "\n",
      "2021-10-29 10:29:07.979885: \n",
      "epoch:  53\n",
      "2021-10-29 10:32:02.358093: train loss : -0.8907\n",
      "2021-10-29 10:32:15.318189: validation loss: -0.8285\n",
      "2021-10-29 10:32:15.320794: Average global foreground Dice: [0.8419]\n",
      "2021-10-29 10:32:15.326447: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:32:15.807245: lr: 0.004971\n",
      "2021-10-29 10:32:15.824759: This epoch took 187.839422 s\n",
      "\n",
      "2021-10-29 10:32:15.829591: \n",
      "epoch:  54\n",
      "2021-10-29 10:35:10.326464: train loss : -0.8929\n",
      "2021-10-29 10:35:23.255934: validation loss: -0.8302\n",
      "2021-10-29 10:35:23.258806: Average global foreground Dice: [0.8433]\n",
      "2021-10-29 10:35:23.264127: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:35:23.808990: lr: 0.004874\n",
      "2021-10-29 10:35:23.827347: This epoch took 187.993539 s\n",
      "\n",
      "2021-10-29 10:35:23.832271: \n",
      "epoch:  55\n",
      "2021-10-29 10:38:18.248874: train loss : -0.8931\n",
      "2021-10-29 10:38:31.162410: validation loss: -0.8329\n",
      "2021-10-29 10:38:31.165016: Average global foreground Dice: [0.8455]\n",
      "2021-10-29 10:38:31.170125: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:38:31.650388: lr: 0.004776\n",
      "2021-10-29 10:38:31.668126: This epoch took 187.830455 s\n",
      "\n",
      "2021-10-29 10:38:31.673487: \n",
      "epoch:  56\n",
      "2021-10-29 10:41:26.042686: train loss : -0.8927\n",
      "2021-10-29 10:41:38.980332: validation loss: -0.8299\n",
      "2021-10-29 10:41:38.983097: Average global foreground Dice: [0.8425]\n",
      "2021-10-29 10:41:38.989179: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:41:39.466519: lr: 0.004679\n",
      "2021-10-29 10:41:39.484068: This epoch took 187.805063 s\n",
      "\n",
      "2021-10-29 10:41:39.489423: \n",
      "epoch:  57\n",
      "2021-10-29 10:44:33.849616: train loss : -0.8925\n",
      "2021-10-29 10:44:46.780693: validation loss: -0.8288\n",
      "2021-10-29 10:44:46.783217: Average global foreground Dice: [0.841]\n",
      "2021-10-29 10:44:46.787833: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:44:47.266195: lr: 0.004581\n",
      "2021-10-29 10:44:47.282238: This epoch took 187.787382 s\n",
      "\n",
      "2021-10-29 10:44:47.287914: \n",
      "epoch:  58\n",
      "2021-10-29 10:47:41.454824: train loss : -0.8930\n",
      "2021-10-29 10:47:54.371376: validation loss: -0.8289\n",
      "2021-10-29 10:47:54.374635: Average global foreground Dice: [0.8419]\n",
      "2021-10-29 10:47:54.379757: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:47:54.864049: lr: 0.004482\n",
      "2021-10-29 10:47:54.882103: This epoch took 187.589247 s\n",
      "\n",
      "2021-10-29 10:47:54.887668: \n",
      "epoch:  59\n",
      "2021-10-29 10:50:48.870107: train loss : -0.8947\n",
      "2021-10-29 10:51:01.808412: validation loss: -0.8299\n",
      "2021-10-29 10:51:01.811655: Average global foreground Dice: [0.8427]\n",
      "2021-10-29 10:51:01.817011: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:51:02.298129: lr: 0.004384\n",
      "2021-10-29 10:51:02.318158: This epoch took 187.425223 s\n",
      "\n",
      "2021-10-29 10:51:02.323154: \n",
      "epoch:  60\n",
      "2021-10-29 10:53:56.316487: train loss : -0.8959\n",
      "2021-10-29 10:54:09.200883: validation loss: -0.8251\n",
      "2021-10-29 10:54:09.203332: Average global foreground Dice: [0.8381]\n",
      "2021-10-29 10:54:09.207707: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:54:09.689533: lr: 0.004285\n",
      "2021-10-29 10:54:09.708931: This epoch took 187.380594 s\n",
      "\n",
      "2021-10-29 10:54:09.714334: \n",
      "epoch:  61\n",
      "2021-10-29 10:57:03.759767: train loss : -0.8955\n",
      "2021-10-29 10:57:16.673371: validation loss: -0.8252\n",
      "2021-10-29 10:57:16.677180: Average global foreground Dice: [0.8363]\n",
      "2021-10-29 10:57:16.682192: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 10:57:17.162107: lr: 0.004186\n",
      "2021-10-29 10:57:17.177586: This epoch took 187.458195 s\n",
      "\n",
      "2021-10-29 10:57:17.182569: \n",
      "epoch:  62\n",
      "2021-10-29 11:00:11.354395: train loss : -0.8968\n",
      "2021-10-29 11:00:24.261183: validation loss: -0.8255\n",
      "2021-10-29 11:00:24.265327: Average global foreground Dice: [0.8368]\n",
      "2021-10-29 11:00:24.271764: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:00:24.760567: lr: 0.004087\n",
      "2021-10-29 11:00:24.778815: This epoch took 187.591121 s\n",
      "\n",
      "2021-10-29 11:00:24.784829: \n",
      "epoch:  63\n",
      "2021-10-29 11:03:18.961081: train loss : -0.8982\n",
      "2021-10-29 11:03:31.867619: validation loss: -0.8249\n",
      "2021-10-29 11:03:31.871058: Average global foreground Dice: [0.8376]\n",
      "2021-10-29 11:03:31.875264: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:03:32.357906: lr: 0.003987\n",
      "2021-10-29 11:03:32.379193: This epoch took 187.589226 s\n",
      "\n",
      "2021-10-29 11:03:32.384555: \n",
      "epoch:  64\n",
      "2021-10-29 11:06:26.291894: train loss : -0.8968\n",
      "2021-10-29 11:06:39.182335: validation loss: -0.8284\n",
      "2021-10-29 11:06:39.185353: Average global foreground Dice: [0.8404]\n",
      "2021-10-29 11:06:39.189699: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:06:39.672371: lr: 0.003887\n",
      "2021-10-29 11:06:39.694124: This epoch took 187.302310 s\n",
      "\n",
      "2021-10-29 11:06:39.699902: \n",
      "epoch:  65\n",
      "2021-10-29 11:09:33.486075: train loss : -0.8973\n",
      "2021-10-29 11:09:46.361943: validation loss: -0.8278\n",
      "2021-10-29 11:09:46.364520: Average global foreground Dice: [0.8416]\n",
      "2021-10-29 11:09:46.369376: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:09:46.857754: lr: 0.003787\n",
      "2021-10-29 11:09:46.882080: This epoch took 187.177651 s\n",
      "\n",
      "2021-10-29 11:09:46.887839: \n",
      "epoch:  66\n",
      "2021-10-29 11:12:40.739372: train loss : -0.8983\n",
      "2021-10-29 11:12:53.635257: validation loss: -0.8278\n",
      "2021-10-29 11:12:53.638050: Average global foreground Dice: [0.8395]\n",
      "2021-10-29 11:12:53.642960: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:12:54.130042: lr: 0.003687\n",
      "2021-10-29 11:12:54.146791: This epoch took 187.253582 s\n",
      "\n",
      "2021-10-29 11:12:54.153099: \n",
      "epoch:  67\n",
      "2021-10-29 11:15:48.057484: train loss : -0.8990\n",
      "2021-10-29 11:16:00.938377: validation loss: -0.8329\n",
      "2021-10-29 11:16:00.940981: Average global foreground Dice: [0.8467]\n",
      "2021-10-29 11:16:00.947194: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:16:01.429738: lr: 0.003586\n",
      "2021-10-29 11:16:01.448476: This epoch took 187.291476 s\n",
      "\n",
      "2021-10-29 11:16:01.454465: \n",
      "epoch:  68\n",
      "2021-10-29 11:18:55.065848: train loss : -0.8995\n",
      "2021-10-29 11:19:07.953466: validation loss: -0.8236\n",
      "2021-10-29 11:19:07.956623: Average global foreground Dice: [0.8364]\n",
      "2021-10-29 11:19:07.960663: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:19:08.443861: lr: 0.003485\n",
      "2021-10-29 11:19:08.460768: This epoch took 187.001589 s\n",
      "\n",
      "2021-10-29 11:19:08.466497: \n",
      "epoch:  69\n",
      "2021-10-29 11:22:01.092707: train loss : -0.8996\n",
      "2021-10-29 11:22:13.924742: validation loss: -0.8295\n",
      "2021-10-29 11:22:13.927552: Average global foreground Dice: [0.8403]\n",
      "2021-10-29 11:22:13.932223: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:22:14.412870: lr: 0.003384\n",
      "2021-10-29 11:22:14.430851: This epoch took 185.959027 s\n",
      "\n",
      "2021-10-29 11:22:14.435764: \n",
      "epoch:  70\n",
      "2021-10-29 11:25:06.781712: train loss : -0.9000\n",
      "2021-10-29 11:25:19.633718: validation loss: -0.8318\n",
      "2021-10-29 11:25:19.636902: Average global foreground Dice: [0.8437]\n",
      "2021-10-29 11:25:19.641427: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:25:20.185851: lr: 0.003282\n",
      "2021-10-29 11:25:20.201972: This epoch took 185.760602 s\n",
      "\n",
      "2021-10-29 11:25:20.206768: \n",
      "epoch:  71\n",
      "2021-10-29 11:28:12.559947: train loss : -0.9004\n",
      "2021-10-29 11:28:25.379933: validation loss: -0.8275\n",
      "2021-10-29 11:28:25.382294: Average global foreground Dice: [0.8408]\n",
      "2021-10-29 11:28:25.386825: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:28:25.912085: lr: 0.00318\n",
      "2021-10-29 11:28:25.935062: This epoch took 185.723084 s\n",
      "\n",
      "2021-10-29 11:28:25.940769: \n",
      "epoch:  72\n",
      "2021-10-29 11:31:18.337443: train loss : -0.9012\n",
      "2021-10-29 11:31:31.141259: validation loss: -0.8308\n",
      "2021-10-29 11:31:31.147728: Average global foreground Dice: [0.8431]\n",
      "2021-10-29 11:31:31.152476: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:31:31.635520: lr: 0.003078\n",
      "2021-10-29 11:31:31.652509: This epoch took 185.706236 s\n",
      "\n",
      "2021-10-29 11:31:31.658062: \n",
      "epoch:  73\n",
      "2021-10-29 11:34:23.974467: train loss : -0.9020\n",
      "2021-10-29 11:34:36.803165: validation loss: -0.8277\n",
      "2021-10-29 11:34:36.806681: Average global foreground Dice: [0.8388]\n",
      "2021-10-29 11:34:36.811654: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:34:37.290904: lr: 0.002975\n",
      "2021-10-29 11:34:37.308213: This epoch took 185.645217 s\n",
      "\n",
      "2021-10-29 11:34:37.313523: \n",
      "epoch:  74\n",
      "2021-10-29 11:37:29.641781: train loss : -0.9025\n",
      "2021-10-29 11:37:42.450273: validation loss: -0.8298\n",
      "2021-10-29 11:37:42.453803: Average global foreground Dice: [0.8429]\n",
      "2021-10-29 11:37:42.458636: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:37:42.939876: lr: 0.002872\n",
      "2021-10-29 11:37:42.957445: This epoch took 185.639812 s\n",
      "\n",
      "2021-10-29 11:37:42.963536: \n",
      "epoch:  75\n",
      "2021-10-29 11:40:35.339850: train loss : -0.9036\n",
      "2021-10-29 11:40:48.153866: validation loss: -0.8233\n",
      "2021-10-29 11:40:48.156399: Average global foreground Dice: [0.8358]\n",
      "2021-10-29 11:40:48.162077: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:40:48.645953: lr: 0.002768\n",
      "2021-10-29 11:40:48.665883: This epoch took 185.697235 s\n",
      "\n",
      "2021-10-29 11:40:48.671804: \n",
      "epoch:  76\n",
      "2021-10-29 11:43:41.008195: train loss : -0.9040\n",
      "2021-10-29 11:43:53.810286: validation loss: -0.8238\n",
      "2021-10-29 11:43:53.813793: Average global foreground Dice: [0.8371]\n",
      "2021-10-29 11:43:53.818306: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:43:54.301930: lr: 0.002664\n",
      "2021-10-29 11:43:54.322157: This epoch took 185.644928 s\n",
      "\n",
      "2021-10-29 11:43:54.327361: \n",
      "epoch:  77\n",
      "2021-10-29 11:46:46.626158: train loss : -0.9040\n",
      "2021-10-29 11:46:59.440706: validation loss: -0.8269\n",
      "2021-10-29 11:46:59.443486: Average global foreground Dice: [0.8387]\n",
      "2021-10-29 11:46:59.447988: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:46:59.936208: lr: 0.00256\n",
      "2021-10-29 11:46:59.960201: This epoch took 185.627281 s\n",
      "\n",
      "2021-10-29 11:46:59.966436: \n",
      "epoch:  78\n",
      "2021-10-29 11:49:52.400403: train loss : -0.9046\n",
      "2021-10-29 11:50:05.193968: validation loss: -0.8262\n",
      "2021-10-29 11:50:05.196641: Average global foreground Dice: [0.8385]\n",
      "2021-10-29 11:50:05.201404: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:50:05.688392: lr: 0.002455\n",
      "2021-10-29 11:50:05.706403: This epoch took 185.735006 s\n",
      "\n",
      "2021-10-29 11:50:05.711557: \n",
      "epoch:  79\n",
      "2021-10-29 11:52:58.073135: train loss : -0.9053\n",
      "2021-10-29 11:53:10.885364: validation loss: -0.8257\n",
      "2021-10-29 11:53:10.889313: Average global foreground Dice: [0.8395]\n",
      "2021-10-29 11:53:10.894409: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:53:11.377371: lr: 0.002349\n",
      "2021-10-29 11:53:11.394647: This epoch took 185.677750 s\n",
      "\n",
      "2021-10-29 11:53:11.399775: \n",
      "epoch:  80\n",
      "2021-10-29 11:56:03.752609: train loss : -0.9060\n",
      "2021-10-29 11:56:16.579283: validation loss: -0.8282\n",
      "2021-10-29 11:56:16.583563: Average global foreground Dice: [0.8405]\n",
      "2021-10-29 11:56:16.589298: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:56:17.079684: lr: 0.002243\n",
      "2021-10-29 11:56:17.096724: This epoch took 185.689821 s\n",
      "\n",
      "2021-10-29 11:56:17.101809: \n",
      "epoch:  81\n",
      "2021-10-29 11:59:09.428646: train loss : -0.9068\n",
      "2021-10-29 11:59:22.224659: validation loss: -0.8255\n",
      "2021-10-29 11:59:22.228859: Average global foreground Dice: [0.8388]\n",
      "2021-10-29 11:59:22.232716: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 11:59:22.783266: lr: 0.002137\n",
      "2021-10-29 11:59:22.801008: This epoch took 185.693908 s\n",
      "\n",
      "2021-10-29 11:59:22.806463: \n",
      "epoch:  82\n",
      "2021-10-29 12:02:15.170841: train loss : -0.9062\n",
      "2021-10-29 12:02:27.962751: validation loss: -0.8251\n",
      "2021-10-29 12:02:27.966204: Average global foreground Dice: [0.8371]\n",
      "2021-10-29 12:02:27.971425: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 12:02:28.447567: lr: 0.00203\n",
      "2021-10-29 12:02:28.463354: This epoch took 185.650720 s\n",
      "\n",
      "2021-10-29 12:02:28.468552: \n",
      "epoch:  83\n",
      "2021-10-29 12:05:20.840189: train loss : -0.9078\n",
      "2021-10-29 12:05:33.635026: validation loss: -0.8292\n",
      "2021-10-29 12:05:33.638214: Average global foreground Dice: [0.841]\n",
      "2021-10-29 12:05:33.643326: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 12:05:34.120039: lr: 0.001922\n",
      "2021-10-29 12:05:34.135536: This epoch took 185.662411 s\n",
      "\n",
      "2021-10-29 12:05:34.140090: \n",
      "epoch:  84\n",
      "2021-10-29 12:08:26.448776: train loss : -0.9081\n",
      "2021-10-29 12:08:39.256524: validation loss: -0.8258\n",
      "2021-10-29 12:08:39.259834: Average global foreground Dice: [0.8382]\n",
      "2021-10-29 12:08:39.265282: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 12:08:39.743400: lr: 0.001813\n",
      "2021-10-29 12:08:39.759934: This epoch took 185.614611 s\n",
      "\n",
      "2021-10-29 12:08:39.765660: \n",
      "epoch:  85\n",
      "2021-10-29 12:11:32.105235: train loss : -0.9077\n",
      "2021-10-29 12:11:44.876380: validation loss: -0.8267\n",
      "2021-10-29 12:11:44.879199: Average global foreground Dice: [0.8403]\n",
      "2021-10-29 12:11:44.885086: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 12:11:45.360062: lr: 0.001704\n",
      "2021-10-29 12:11:45.377257: This epoch took 185.605808 s\n",
      "\n",
      "2021-10-29 12:11:45.382712: \n",
      "epoch:  86\n",
      "2021-10-29 12:14:37.750679: train loss : -0.9100\n",
      "2021-10-29 12:14:50.582340: validation loss: -0.8246\n",
      "2021-10-29 12:14:50.585396: Average global foreground Dice: [0.8365]\n",
      "2021-10-29 12:14:50.590027: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 12:14:51.066163: lr: 0.001594\n",
      "2021-10-29 12:14:51.083345: This epoch took 185.696626 s\n",
      "\n",
      "2021-10-29 12:14:51.087507: \n",
      "epoch:  87\n",
      "2021-10-29 12:17:43.442138: train loss : -0.9097\n",
      "2021-10-29 12:17:56.250254: validation loss: -0.8256\n",
      "2021-10-29 12:17:56.253123: Average global foreground Dice: [0.8386]\n",
      "2021-10-29 12:17:56.258328: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 12:17:56.734352: lr: 0.001483\n",
      "2021-10-29 12:17:56.748405: This epoch took 185.655434 s\n",
      "\n",
      "2021-10-29 12:17:56.753275: \n",
      "epoch:  88\n",
      "2021-10-29 12:20:49.120597: train loss : -0.9096\n",
      "2021-10-29 12:21:01.917693: validation loss: -0.8209\n",
      "2021-10-29 12:21:01.920717: Average global foreground Dice: [0.834]\n",
      "2021-10-29 12:21:01.925625: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 12:21:02.402797: lr: 0.001372\n",
      "2021-10-29 12:21:02.420989: This epoch took 185.661608 s\n",
      "\n",
      "2021-10-29 12:21:02.425954: \n",
      "epoch:  89\n",
      "2021-10-29 12:23:54.733264: train loss : -0.9102\n",
      "2021-10-29 12:24:07.570573: validation loss: -0.8261\n",
      "2021-10-29 12:24:07.573443: Average global foreground Dice: [0.8398]\n",
      "2021-10-29 12:24:07.578850: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 12:24:08.055713: lr: 0.001259\n",
      "2021-10-29 12:24:08.071987: This epoch took 185.641096 s\n",
      "\n",
      "2021-10-29 12:24:08.076975: \n",
      "epoch:  90\n",
      "2021-10-29 12:27:00.435277: train loss : -0.9106\n",
      "2021-10-29 12:27:13.238463: validation loss: -0.8265\n",
      "2021-10-29 12:27:13.241853: Average global foreground Dice: [0.8403]\n",
      "2021-10-29 12:27:13.247034: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 12:27:13.726524: lr: 0.001145\n",
      "2021-10-29 12:27:13.744517: This epoch took 185.661013 s\n",
      "\n",
      "2021-10-29 12:27:13.749174: \n",
      "epoch:  91\n",
      "2021-10-29 12:30:06.143075: train loss : -0.9119\n",
      "2021-10-29 12:30:18.954402: validation loss: -0.8271\n",
      "2021-10-29 12:30:18.957239: Average global foreground Dice: [0.8384]\n",
      "2021-10-29 12:30:18.963207: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 12:30:19.443389: lr: 0.00103\n",
      "2021-10-29 12:30:19.463462: This epoch took 185.708064 s\n",
      "\n",
      "2021-10-29 12:30:19.468768: \n",
      "epoch:  92\n",
      "2021-10-29 12:33:11.775685: train loss : -0.9116\n",
      "2021-10-29 12:33:24.570272: validation loss: -0.8223\n",
      "2021-10-29 12:33:24.572880: Average global foreground Dice: [0.8358]\n",
      "2021-10-29 12:33:24.577971: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 12:33:25.120193: lr: 0.000913\n",
      "2021-10-29 12:33:25.140030: This epoch took 185.666098 s\n",
      "\n",
      "2021-10-29 12:33:25.146696: \n",
      "epoch:  93\n",
      "2021-10-29 12:36:17.449286: train loss : -0.9125\n",
      "2021-10-29 12:36:30.207869: validation loss: -0.8229\n",
      "2021-10-29 12:36:30.211270: Average global foreground Dice: [0.8349]\n",
      "2021-10-29 12:36:30.215677: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 12:36:30.694528: lr: 0.000795\n",
      "2021-10-29 12:36:30.710302: This epoch took 185.556593 s\n",
      "\n",
      "2021-10-29 12:36:30.714362: \n",
      "epoch:  94\n",
      "2021-10-29 12:39:23.101425: train loss : -0.9141\n",
      "2021-10-29 12:39:35.897118: validation loss: -0.8250\n",
      "2021-10-29 12:39:35.900905: Average global foreground Dice: [0.8389]\n",
      "2021-10-29 12:39:35.905795: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 12:39:36.385059: lr: 0.000675\n",
      "2021-10-29 12:39:36.401017: This epoch took 185.681447 s\n",
      "\n",
      "2021-10-29 12:39:36.406459: \n",
      "epoch:  95\n",
      "2021-10-29 12:42:28.749561: train loss : -0.9139\n",
      "2021-10-29 12:42:41.532567: validation loss: -0.8271\n",
      "2021-10-29 12:42:41.535270: Average global foreground Dice: [0.8396]\n",
      "2021-10-29 12:42:41.540017: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 12:42:42.017816: lr: 0.000552\n",
      "2021-10-29 12:42:42.035606: This epoch took 185.624079 s\n",
      "\n",
      "2021-10-29 12:42:42.040883: \n",
      "epoch:  96\n",
      "2021-10-29 12:45:34.384446: train loss : -0.9147\n",
      "2021-10-29 12:45:47.143734: validation loss: -0.8261\n",
      "2021-10-29 12:45:47.146108: Average global foreground Dice: [0.839]\n",
      "2021-10-29 12:45:47.151231: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 12:45:47.635171: lr: 0.000426\n",
      "2021-10-29 12:45:47.654565: This epoch took 185.608570 s\n",
      "\n",
      "2021-10-29 12:45:47.659323: \n",
      "epoch:  97\n",
      "2021-10-29 12:48:40.021556: train loss : -0.9149\n",
      "2021-10-29 12:48:52.813193: validation loss: -0.8270\n",
      "2021-10-29 12:48:52.815841: Average global foreground Dice: [0.8386]\n",
      "2021-10-29 12:48:52.820577: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 12:48:53.301003: lr: 0.000296\n",
      "2021-10-29 12:48:53.317101: This epoch took 185.652390 s\n",
      "\n",
      "2021-10-29 12:48:53.322719: \n",
      "epoch:  98\n",
      "2021-10-29 12:51:45.670996: train loss : -0.9142\n",
      "2021-10-29 12:51:58.457648: validation loss: -0.8247\n",
      "2021-10-29 12:51:58.460278: Average global foreground Dice: [0.8363]\n",
      "2021-10-29 12:51:58.464872: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 12:51:58.941973: lr: 0.000158\n",
      "2021-10-29 12:51:58.958945: This epoch took 185.628907 s\n",
      "\n",
      "2021-10-29 12:51:58.964313: \n",
      "epoch:  99\n",
      "2021-10-29 12:54:51.314424: train loss : -0.9154\n",
      "2021-10-29 12:55:04.095062: validation loss: -0.8259\n",
      "2021-10-29 12:55:04.097629: Average global foreground Dice: [0.8378]\n",
      "2021-10-29 12:55:04.102675: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 12:55:04.581507: lr: 0.0\n",
      "2021-10-29 12:55:04.601376: saving scheduled checkpoint file...\n",
      "2021-10-29 12:55:04.625491: saving checkpoint...\n",
      "2021-10-29 12:55:05.340990: done, saving took 0.73 seconds\n",
      "2021-10-29 12:55:05.766603: done\n",
      "2021-10-29 12:55:05.773452: This epoch took 186.804045 s\n",
      "\n",
      "2021-10-29 12:55:05.798696: saving checkpoint...\n",
      "2021-10-29 12:55:06.366732: done, saving took 0.59 seconds\n",
      "23090559_20150812 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120330 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090563_20151216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130226 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090584_20120523 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090589_20140219 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090592_20130218 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090614_20120402 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090620_20130617 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090627_20160608 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090628_20150204 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090635_20140710 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090640_20140711 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121227 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-29 12:57:02.851665: finished prediction\n",
      "2021-10-29 12:57:02.856488: evaluation of raw predictions\n",
      "2021-10-29 12:57:04.159078: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8324956369901785\n",
      "after:  0.8325149131744742\n",
      "Removing all but the largest foreground region improved results!\n",
      "for_which_classes [1]\n",
      "min_valid_object_sizes None\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[[1]]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-10-29 12:57:13.239320: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-10-29 12:57:13.254708: The split file contains 5 splits.\n",
      "2021-10-29 12:57:13.260669: Desired fold for training: 1\n",
      "2021-10-29 12:57:13.265920: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-29 12:57:17.346983: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-29 12:57:25.145709: Unable to plot network architecture:\n",
      "2021-10-29 12:57:25.147655: No module named 'hiddenlayer'\n",
      "2021-10-29 12:57:25.153403: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-29 12:57:25.242964: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-29 12:57:25.250782: \n",
      "\n",
      "2021-10-29 12:57:25.255965: \n",
      "epoch:  0\n",
      "2021-10-29 13:00:32.169554: train loss : -0.2457\n",
      "2021-10-29 13:00:44.893387: validation loss: -0.6472\n",
      "2021-10-29 13:00:44.896360: Average global foreground Dice: [0.6826]\n",
      "2021-10-29 13:00:44.901977: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:00:45.334553: lr: 0.00991\n",
      "2021-10-29 13:00:45.348924: This epoch took 200.087963 s\n",
      "\n",
      "2021-10-29 13:00:45.354040: \n",
      "epoch:  1\n",
      "2021-10-29 13:03:37.485135: train loss : -0.6972\n",
      "2021-10-29 13:03:50.246950: validation loss: -0.7678\n",
      "2021-10-29 13:03:50.251353: Average global foreground Dice: [0.7923]\n",
      "2021-10-29 13:03:50.259879: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:03:50.742585: lr: 0.00982\n",
      "2021-10-29 13:03:50.814058: saving checkpoint...\n",
      "2021-10-29 13:03:51.467340: done, saving took 0.70 seconds\n",
      "2021-10-29 13:03:51.847990: This epoch took 186.489195 s\n",
      "\n",
      "2021-10-29 13:03:51.858753: \n",
      "epoch:  2\n",
      "2021-10-29 13:06:44.174311: train loss : -0.7716\n",
      "2021-10-29 13:06:56.965781: validation loss: -0.8016\n",
      "2021-10-29 13:06:56.970217: Average global foreground Dice: [0.8171]\n",
      "2021-10-29 13:06:56.976168: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:06:57.476811: lr: 0.00973\n",
      "2021-10-29 13:06:57.530834: saving checkpoint...\n",
      "2021-10-29 13:06:58.192197: done, saving took 0.70 seconds\n",
      "2021-10-29 13:06:58.574349: This epoch took 186.707595 s\n",
      "\n",
      "2021-10-29 13:06:58.582512: \n",
      "epoch:  3\n",
      "2021-10-29 13:09:50.150286: train loss : -0.7980\n",
      "2021-10-29 13:10:02.895350: validation loss: -0.7955\n",
      "2021-10-29 13:10:02.899316: Average global foreground Dice: [0.8148]\n",
      "2021-10-29 13:10:02.905081: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:10:03.388583: lr: 0.009639\n",
      "2021-10-29 13:10:03.439072: saving checkpoint...\n",
      "2021-10-29 13:10:04.096311: done, saving took 0.69 seconds\n",
      "2021-10-29 13:10:04.482237: This epoch took 185.892520 s\n",
      "\n",
      "2021-10-29 13:10:04.490425: \n",
      "epoch:  4\n",
      "2021-10-29 13:12:56.062386: train loss : -0.8137\n",
      "2021-10-29 13:13:08.819169: validation loss: -0.8124\n",
      "2021-10-29 13:13:08.826630: Average global foreground Dice: [0.8252]\n",
      "2021-10-29 13:13:08.832644: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:13:09.312805: lr: 0.009549\n",
      "2021-10-29 13:13:09.346698: saving checkpoint...\n",
      "2021-10-29 13:13:09.992703: done, saving took 0.66 seconds\n",
      "2021-10-29 13:13:10.377933: This epoch took 185.880653 s\n",
      "\n",
      "2021-10-29 13:13:10.386595: \n",
      "epoch:  5\n",
      "2021-10-29 13:16:02.396228: train loss : -0.8206\n",
      "2021-10-29 13:16:15.167650: validation loss: -0.8109\n",
      "2021-10-29 13:16:15.171329: Average global foreground Dice: [0.8255]\n",
      "2021-10-29 13:16:15.178322: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:16:15.653750: lr: 0.009458\n",
      "2021-10-29 13:16:15.689332: saving checkpoint...\n",
      "2021-10-29 13:16:16.353167: done, saving took 0.68 seconds\n",
      "2021-10-29 13:16:16.849451: This epoch took 186.457460 s\n",
      "\n",
      "2021-10-29 13:16:16.859109: \n",
      "epoch:  6\n",
      "2021-10-29 13:19:08.369741: train loss : -0.8282\n",
      "2021-10-29 13:19:21.131455: validation loss: -0.8186\n",
      "2021-10-29 13:19:21.135606: Average global foreground Dice: [0.8302]\n",
      "2021-10-29 13:19:21.141937: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:19:21.631027: lr: 0.009368\n",
      "2021-10-29 13:19:21.668340: saving checkpoint...\n",
      "2021-10-29 13:19:22.329380: done, saving took 0.68 seconds\n",
      "2021-10-29 13:19:22.709138: This epoch took 185.842343 s\n",
      "\n",
      "2021-10-29 13:19:22.718680: \n",
      "epoch:  7\n",
      "2021-10-29 13:22:14.644933: train loss : -0.8330\n",
      "2021-10-29 13:22:27.439629: validation loss: -0.8200\n",
      "2021-10-29 13:22:27.443617: Average global foreground Dice: [0.8329]\n",
      "2021-10-29 13:22:27.450032: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:22:27.992462: lr: 0.009277\n",
      "2021-10-29 13:22:28.027667: saving checkpoint...\n",
      "2021-10-29 13:22:28.676888: done, saving took 0.67 seconds\n",
      "2021-10-29 13:22:29.068622: This epoch took 186.342407 s\n",
      "\n",
      "2021-10-29 13:22:29.078036: \n",
      "epoch:  8\n",
      "2021-10-29 13:25:21.295967: train loss : -0.8382\n",
      "2021-10-29 13:25:34.073782: validation loss: -0.8164\n",
      "2021-10-29 13:25:34.077904: Average global foreground Dice: [0.8288]\n",
      "2021-10-29 13:25:34.085058: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:25:34.571974: lr: 0.009186\n",
      "2021-10-29 13:25:34.604225: saving checkpoint...\n",
      "2021-10-29 13:25:35.269474: done, saving took 0.68 seconds\n",
      "2021-10-29 13:25:35.654019: This epoch took 186.568774 s\n",
      "\n",
      "2021-10-29 13:25:35.662597: \n",
      "epoch:  9\n",
      "2021-10-29 13:28:27.755969: train loss : -0.8425\n",
      "2021-10-29 13:28:40.548299: validation loss: -0.8235\n",
      "2021-10-29 13:28:40.554231: Average global foreground Dice: [0.8354]\n",
      "2021-10-29 13:28:40.561470: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:28:41.039797: lr: 0.009095\n",
      "2021-10-29 13:28:41.084728: saving checkpoint...\n",
      "2021-10-29 13:28:41.741021: done, saving took 0.67 seconds\n",
      "2021-10-29 13:28:42.137565: This epoch took 186.467647 s\n",
      "\n",
      "2021-10-29 13:28:42.147365: \n",
      "epoch:  10\n",
      "2021-10-29 13:31:34.396872: train loss : -0.8467\n",
      "2021-10-29 13:31:47.220101: validation loss: -0.8214\n",
      "2021-10-29 13:31:47.223836: Average global foreground Dice: [0.8332]\n",
      "2021-10-29 13:31:47.230183: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:31:47.708701: lr: 0.009004\n",
      "2021-10-29 13:31:47.745516: saving checkpoint...\n",
      "2021-10-29 13:31:48.403280: done, saving took 0.68 seconds\n",
      "2021-10-29 13:31:48.776168: This epoch took 186.620190 s\n",
      "\n",
      "2021-10-29 13:31:48.784901: \n",
      "epoch:  11\n",
      "2021-10-29 13:34:41.147245: train loss : -0.8479\n",
      "2021-10-29 13:34:53.964518: validation loss: -0.8288\n",
      "2021-10-29 13:34:53.969033: Average global foreground Dice: [0.8401]\n",
      "2021-10-29 13:34:53.976012: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:34:54.452400: lr: 0.008913\n",
      "2021-10-29 13:34:54.487839: saving checkpoint...\n",
      "2021-10-29 13:34:55.157072: done, saving took 0.69 seconds\n",
      "2021-10-29 13:34:55.581183: This epoch took 186.787796 s\n",
      "\n",
      "2021-10-29 13:34:55.589891: \n",
      "epoch:  12\n",
      "2021-10-29 13:37:48.085018: train loss : -0.8505\n",
      "2021-10-29 13:38:00.965230: validation loss: -0.8302\n",
      "2021-10-29 13:38:00.969607: Average global foreground Dice: [0.8408]\n",
      "2021-10-29 13:38:00.976791: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:38:01.498235: lr: 0.008822\n",
      "2021-10-29 13:38:01.534885: saving checkpoint...\n",
      "2021-10-29 13:38:02.247627: done, saving took 0.73 seconds\n",
      "2021-10-29 13:38:02.634889: This epoch took 187.036632 s\n",
      "\n",
      "2021-10-29 13:38:02.646254: \n",
      "epoch:  13\n",
      "2021-10-29 13:40:54.990139: train loss : -0.8531\n",
      "2021-10-29 13:41:07.887312: validation loss: -0.8244\n",
      "2021-10-29 13:41:07.891256: Average global foreground Dice: [0.835]\n",
      "2021-10-29 13:41:07.898838: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:41:08.380311: lr: 0.008731\n",
      "2021-10-29 13:41:08.417303: saving checkpoint...\n",
      "2021-10-29 13:41:09.081416: done, saving took 0.68 seconds\n",
      "2021-10-29 13:41:09.493721: This epoch took 186.839944 s\n",
      "\n",
      "2021-10-29 13:41:09.501986: \n",
      "epoch:  14\n",
      "2021-10-29 13:44:01.830725: train loss : -0.8544\n",
      "2021-10-29 13:44:14.707395: validation loss: -0.8243\n",
      "2021-10-29 13:44:14.711446: Average global foreground Dice: [0.8362]\n",
      "2021-10-29 13:44:14.719180: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:44:15.209571: lr: 0.008639\n",
      "2021-10-29 13:44:15.245964: saving checkpoint...\n",
      "2021-10-29 13:44:15.910267: done, saving took 0.68 seconds\n",
      "2021-10-29 13:44:16.332359: This epoch took 186.821007 s\n",
      "\n",
      "2021-10-29 13:44:16.341373: \n",
      "epoch:  15\n",
      "2021-10-29 13:47:08.685404: train loss : -0.8578\n",
      "2021-10-29 13:47:21.534559: validation loss: -0.8184\n",
      "2021-10-29 13:47:21.538821: Average global foreground Dice: [0.8302]\n",
      "2021-10-29 13:47:21.546466: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:47:22.029953: lr: 0.008548\n",
      "2021-10-29 13:47:22.065809: saving checkpoint...\n",
      "2021-10-29 13:47:22.745554: done, saving took 0.70 seconds\n",
      "2021-10-29 13:47:23.192198: This epoch took 186.843310 s\n",
      "\n",
      "2021-10-29 13:47:23.201486: \n",
      "epoch:  16\n",
      "2021-10-29 13:50:15.587215: train loss : -0.8569\n",
      "2021-10-29 13:50:28.449652: validation loss: -0.8250\n",
      "2021-10-29 13:50:28.453526: Average global foreground Dice: [0.8369]\n",
      "2021-10-29 13:50:28.460717: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:50:28.952855: lr: 0.008456\n",
      "2021-10-29 13:50:29.001364: saving checkpoint...\n",
      "2021-10-29 13:50:29.671530: done, saving took 0.70 seconds\n",
      "2021-10-29 13:50:30.004885: This epoch took 186.795817 s\n",
      "\n",
      "2021-10-29 13:50:30.013660: \n",
      "epoch:  17\n",
      "2021-10-29 13:53:22.370439: train loss : -0.8604\n",
      "2021-10-29 13:53:35.249219: validation loss: -0.8247\n",
      "2021-10-29 13:53:35.253772: Average global foreground Dice: [0.8363]\n",
      "2021-10-29 13:53:35.260714: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:53:35.752293: lr: 0.008364\n",
      "2021-10-29 13:53:35.798639: saving checkpoint...\n",
      "2021-10-29 13:53:36.511661: done, saving took 0.74 seconds\n",
      "2021-10-29 13:53:36.973552: This epoch took 186.951363 s\n",
      "\n",
      "2021-10-29 13:53:36.982813: \n",
      "epoch:  18\n",
      "2021-10-29 13:56:29.323489: train loss : -0.8607\n",
      "2021-10-29 13:56:42.173592: validation loss: -0.8332\n",
      "2021-10-29 13:56:42.177470: Average global foreground Dice: [0.8433]\n",
      "2021-10-29 13:56:42.185145: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:56:42.669159: lr: 0.008272\n",
      "2021-10-29 13:56:42.705718: saving checkpoint...\n",
      "2021-10-29 13:56:43.368741: done, saving took 0.68 seconds\n",
      "2021-10-29 13:56:43.764719: This epoch took 186.773695 s\n",
      "\n",
      "2021-10-29 13:56:43.773602: \n",
      "epoch:  19\n",
      "2021-10-29 13:59:36.092491: train loss : -0.8643\n",
      "2021-10-29 13:59:48.934560: validation loss: -0.8295\n",
      "2021-10-29 13:59:48.938555: Average global foreground Dice: [0.8372]\n",
      "2021-10-29 13:59:48.945550: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 13:59:49.428300: lr: 0.008181\n",
      "2021-10-29 13:59:49.463527: saving checkpoint...\n",
      "2021-10-29 13:59:50.136826: done, saving took 0.69 seconds\n",
      "2021-10-29 13:59:50.534740: This epoch took 186.754097 s\n",
      "\n",
      "2021-10-29 13:59:50.543023: \n",
      "epoch:  20\n",
      "2021-10-29 14:02:42.892332: train loss : -0.8660\n",
      "2021-10-29 14:02:55.750166: validation loss: -0.8331\n",
      "2021-10-29 14:02:55.753914: Average global foreground Dice: [0.843]\n",
      "2021-10-29 14:02:55.762258: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:02:56.246979: lr: 0.008088\n",
      "2021-10-29 14:02:56.281786: saving checkpoint...\n",
      "2021-10-29 14:02:56.949507: done, saving took 0.69 seconds\n",
      "2021-10-29 14:02:57.336348: This epoch took 186.785702 s\n",
      "\n",
      "2021-10-29 14:02:57.345530: \n",
      "epoch:  21\n",
      "2021-10-29 14:05:49.703843: train loss : -0.8668\n",
      "2021-10-29 14:06:02.566735: validation loss: -0.8327\n",
      "2021-10-29 14:06:02.570443: Average global foreground Dice: [0.8444]\n",
      "2021-10-29 14:06:02.577797: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:06:03.057123: lr: 0.007996\n",
      "2021-10-29 14:06:03.092911: saving checkpoint...\n",
      "2021-10-29 14:06:03.748133: done, saving took 0.67 seconds\n",
      "2021-10-29 14:06:04.154305: This epoch took 186.801125 s\n",
      "\n",
      "2021-10-29 14:06:04.164845: \n",
      "epoch:  22\n",
      "2021-10-29 14:08:56.490742: train loss : -0.8675\n",
      "2021-10-29 14:09:09.382272: validation loss: -0.8249\n",
      "2021-10-29 14:09:09.389269: Average global foreground Dice: [0.8353]\n",
      "2021-10-29 14:09:09.396746: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:09:09.876704: lr: 0.007904\n",
      "2021-10-29 14:09:09.910645: saving checkpoint...\n",
      "2021-10-29 14:09:10.631991: done, saving took 0.74 seconds\n",
      "2021-10-29 14:09:11.025835: This epoch took 186.851963 s\n",
      "\n",
      "2021-10-29 14:09:11.035016: \n",
      "epoch:  23\n",
      "2021-10-29 14:12:03.369029: train loss : -0.8691\n",
      "2021-10-29 14:12:16.248173: validation loss: -0.8311\n",
      "2021-10-29 14:12:16.252265: Average global foreground Dice: [0.8402]\n",
      "2021-10-29 14:12:16.259580: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:12:16.738084: lr: 0.007811\n",
      "2021-10-29 14:12:16.774857: saving checkpoint...\n",
      "2021-10-29 14:12:17.438825: done, saving took 0.68 seconds\n",
      "2021-10-29 14:12:17.895875: This epoch took 186.853803 s\n",
      "\n",
      "2021-10-29 14:12:17.904882: \n",
      "epoch:  24\n",
      "2021-10-29 14:15:10.537275: train loss : -0.8704\n",
      "2021-10-29 14:15:23.471493: validation loss: -0.8256\n",
      "2021-10-29 14:15:23.475765: Average global foreground Dice: [0.8369]\n",
      "2021-10-29 14:15:23.482604: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:15:24.007486: lr: 0.007719\n",
      "2021-10-29 14:15:24.042146: saving checkpoint...\n",
      "2021-10-29 14:15:24.708265: done, saving took 0.68 seconds\n",
      "2021-10-29 14:15:25.132281: This epoch took 187.220458 s\n",
      "\n",
      "2021-10-29 14:15:25.141598: \n",
      "epoch:  25\n",
      "2021-10-29 14:18:18.020840: train loss : -0.8712\n",
      "2021-10-29 14:18:30.905899: validation loss: -0.8327\n",
      "2021-10-29 14:18:30.910160: Average global foreground Dice: [0.842]\n",
      "2021-10-29 14:18:30.917072: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:18:31.397977: lr: 0.007626\n",
      "2021-10-29 14:18:31.433061: saving checkpoint...\n",
      "2021-10-29 14:18:32.097322: done, saving took 0.68 seconds\n",
      "2021-10-29 14:18:32.499884: This epoch took 187.350678 s\n",
      "\n",
      "2021-10-29 14:18:32.508890: \n",
      "epoch:  26\n",
      "2021-10-29 14:21:25.304547: train loss : -0.8737\n",
      "2021-10-29 14:21:38.195197: validation loss: -0.8304\n",
      "2021-10-29 14:21:38.199142: Average global foreground Dice: [0.8396]\n",
      "2021-10-29 14:21:38.207036: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:21:38.693756: lr: 0.007533\n",
      "2021-10-29 14:21:38.741035: saving checkpoint...\n",
      "2021-10-29 14:21:39.407620: done, saving took 0.70 seconds\n",
      "2021-10-29 14:21:39.812898: This epoch took 187.296169 s\n",
      "\n",
      "2021-10-29 14:21:39.821964: \n",
      "epoch:  27\n",
      "2021-10-29 14:24:32.926800: train loss : -0.8747\n",
      "2021-10-29 14:24:45.830095: validation loss: -0.8254\n",
      "2021-10-29 14:24:45.833860: Average global foreground Dice: [0.8362]\n",
      "2021-10-29 14:24:45.840256: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:24:46.368903: lr: 0.00744\n",
      "2021-10-29 14:24:46.405400: saving checkpoint...\n",
      "2021-10-29 14:24:47.070475: done, saving took 0.68 seconds\n",
      "2021-10-29 14:24:47.454008: This epoch took 187.625296 s\n",
      "\n",
      "2021-10-29 14:24:47.462595: \n",
      "epoch:  28\n",
      "2021-10-29 14:27:40.775061: train loss : -0.8758\n",
      "2021-10-29 14:27:53.718309: validation loss: -0.8283\n",
      "2021-10-29 14:27:53.723100: Average global foreground Dice: [0.8402]\n",
      "2021-10-29 14:27:53.730001: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:27:54.279151: lr: 0.007347\n",
      "2021-10-29 14:27:54.315605: saving checkpoint...\n",
      "2021-10-29 14:27:54.982334: done, saving took 0.69 seconds\n",
      "2021-10-29 14:27:55.382323: This epoch took 187.912284 s\n",
      "\n",
      "2021-10-29 14:27:55.390926: \n",
      "epoch:  29\n",
      "2021-10-29 14:30:49.000688: train loss : -0.8757\n",
      "2021-10-29 14:31:01.958365: validation loss: -0.8258\n",
      "2021-10-29 14:31:01.963664: Average global foreground Dice: [0.8375]\n",
      "2021-10-29 14:31:01.971887: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:31:02.455837: lr: 0.007254\n",
      "2021-10-29 14:31:02.492829: saving checkpoint...\n",
      "2021-10-29 14:31:03.159367: done, saving took 0.69 seconds\n",
      "2021-10-29 14:31:03.557331: This epoch took 188.158969 s\n",
      "\n",
      "2021-10-29 14:31:03.566211: \n",
      "epoch:  30\n",
      "2021-10-29 14:33:57.729985: train loss : -0.8767\n",
      "2021-10-29 14:34:10.670083: validation loss: -0.8277\n",
      "2021-10-29 14:34:10.674119: Average global foreground Dice: [0.8375]\n",
      "2021-10-29 14:34:10.681270: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:34:11.165630: lr: 0.007161\n",
      "2021-10-29 14:34:11.202247: saving checkpoint...\n",
      "2021-10-29 14:34:11.869081: done, saving took 0.69 seconds\n",
      "2021-10-29 14:34:12.265506: This epoch took 188.691965 s\n",
      "\n",
      "2021-10-29 14:34:12.273576: \n",
      "epoch:  31\n",
      "2021-10-29 14:37:06.303206: train loss : -0.8771\n",
      "2021-10-29 14:37:19.263566: validation loss: -0.8292\n",
      "2021-10-29 14:37:19.267675: Average global foreground Dice: [0.8391]\n",
      "2021-10-29 14:37:19.278317: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:37:19.763482: lr: 0.007067\n",
      "2021-10-29 14:37:19.801004: saving checkpoint...\n",
      "2021-10-29 14:37:20.460091: done, saving took 0.68 seconds\n",
      "2021-10-29 14:37:20.847182: This epoch took 188.565761 s\n",
      "\n",
      "2021-10-29 14:37:20.860100: \n",
      "epoch:  32\n",
      "2021-10-29 14:40:15.246621: train loss : -0.8780\n",
      "2021-10-29 14:40:28.208545: validation loss: -0.8297\n",
      "2021-10-29 14:40:28.212514: Average global foreground Dice: [0.8396]\n",
      "2021-10-29 14:40:28.219136: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:40:28.706147: lr: 0.006974\n",
      "2021-10-29 14:40:28.740151: saving checkpoint...\n",
      "2021-10-29 14:40:29.410349: done, saving took 0.69 seconds\n",
      "2021-10-29 14:40:29.790490: This epoch took 188.922092 s\n",
      "\n",
      "2021-10-29 14:40:29.798528: \n",
      "epoch:  33\n",
      "2021-10-29 14:43:24.465946: train loss : -0.8800\n",
      "2021-10-29 14:43:37.438282: validation loss: -0.8328\n",
      "2021-10-29 14:43:37.442541: Average global foreground Dice: [0.8418]\n",
      "2021-10-29 14:43:37.449102: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:43:38.003318: lr: 0.00688\n",
      "2021-10-29 14:43:38.040451: saving checkpoint...\n",
      "2021-10-29 14:43:38.706399: done, saving took 0.68 seconds\n",
      "2021-10-29 14:43:39.223250: This epoch took 189.417523 s\n",
      "\n",
      "2021-10-29 14:43:39.232098: \n",
      "epoch:  34\n",
      "2021-10-29 14:46:33.812549: train loss : -0.8812\n",
      "2021-10-29 14:46:46.807435: validation loss: -0.8260\n",
      "2021-10-29 14:46:46.810813: Average global foreground Dice: [0.8368]\n",
      "2021-10-29 14:46:46.817261: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:46:47.304953: lr: 0.006786\n",
      "2021-10-29 14:46:47.340772: saving checkpoint...\n",
      "2021-10-29 14:46:48.013648: done, saving took 0.69 seconds\n",
      "2021-10-29 14:46:48.494581: This epoch took 189.255065 s\n",
      "\n",
      "2021-10-29 14:46:48.502400: \n",
      "epoch:  35\n",
      "2021-10-29 14:49:42.942017: train loss : -0.8816\n",
      "2021-10-29 14:49:55.925162: validation loss: -0.8306\n",
      "2021-10-29 14:49:55.929044: Average global foreground Dice: [0.8396]\n",
      "2021-10-29 14:49:55.935143: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:49:56.422269: lr: 0.006692\n",
      "2021-10-29 14:49:56.466366: saving checkpoint...\n",
      "2021-10-29 14:49:57.140154: done, saving took 0.70 seconds\n",
      "2021-10-29 14:49:57.537480: This epoch took 189.027101 s\n",
      "\n",
      "2021-10-29 14:49:57.546469: \n",
      "epoch:  36\n",
      "2021-10-29 14:52:52.401136: train loss : -0.8830\n",
      "2021-10-29 14:53:05.400698: validation loss: -0.8279\n",
      "2021-10-29 14:53:05.405696: Average global foreground Dice: [0.8384]\n",
      "2021-10-29 14:53:05.413661: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:53:05.905523: lr: 0.006598\n",
      "2021-10-29 14:53:05.940681: saving checkpoint...\n",
      "2021-10-29 14:53:06.619039: done, saving took 0.70 seconds\n",
      "2021-10-29 14:53:07.044424: This epoch took 189.490187 s\n",
      "\n",
      "2021-10-29 14:53:07.053231: \n",
      "epoch:  37\n",
      "2021-10-29 14:56:01.821699: train loss : -0.8828\n",
      "2021-10-29 14:56:14.762386: validation loss: -0.8300\n",
      "2021-10-29 14:56:14.767328: Average global foreground Dice: [0.8393]\n",
      "2021-10-29 14:56:14.775943: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:56:15.261664: lr: 0.006504\n",
      "2021-10-29 14:56:15.298383: saving checkpoint...\n",
      "2021-10-29 14:56:15.965188: done, saving took 0.69 seconds\n",
      "2021-10-29 14:56:16.376630: This epoch took 189.315546 s\n",
      "\n",
      "2021-10-29 14:56:16.385780: \n",
      "epoch:  38\n",
      "2021-10-29 14:59:11.052968: train loss : -0.8826\n",
      "2021-10-29 14:59:24.030738: validation loss: -0.8311\n",
      "2021-10-29 14:59:24.035172: Average global foreground Dice: [0.8415]\n",
      "2021-10-29 14:59:24.042093: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 14:59:24.595466: lr: 0.006409\n",
      "2021-10-29 14:59:24.631768: saving checkpoint...\n",
      "2021-10-29 14:59:25.302250: done, saving took 0.69 seconds\n",
      "2021-10-29 14:59:25.689014: This epoch took 189.286101 s\n",
      "\n",
      "2021-10-29 14:59:25.697665: \n",
      "epoch:  39\n",
      "2021-10-29 15:02:20.680614: train loss : -0.8852\n",
      "2021-10-29 15:02:33.679227: validation loss: -0.8344\n",
      "2021-10-29 15:02:33.683101: Average global foreground Dice: [0.8442]\n",
      "2021-10-29 15:02:33.690520: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:02:34.178283: lr: 0.006314\n",
      "2021-10-29 15:02:34.215412: saving checkpoint...\n",
      "2021-10-29 15:02:34.886400: done, saving took 0.69 seconds\n",
      "2021-10-29 15:02:35.270203: This epoch took 189.564562 s\n",
      "\n",
      "2021-10-29 15:02:35.280297: \n",
      "epoch:  40\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-29 15:05:30.580886: train loss : -0.8854\n",
      "2021-10-29 15:05:43.611467: validation loss: -0.8267\n",
      "2021-10-29 15:05:43.615545: Average global foreground Dice: [0.8391]\n",
      "2021-10-29 15:05:43.623377: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:05:44.108195: lr: 0.00622\n",
      "2021-10-29 15:05:44.142073: saving checkpoint...\n",
      "2021-10-29 15:05:44.812923: done, saving took 0.69 seconds\n",
      "2021-10-29 15:05:45.325599: This epoch took 190.036861 s\n",
      "\n",
      "2021-10-29 15:05:45.335476: \n",
      "epoch:  41\n",
      "2021-10-29 15:08:40.631106: train loss : -0.8859\n",
      "2021-10-29 15:08:53.640634: validation loss: -0.8324\n",
      "2021-10-29 15:08:53.644961: Average global foreground Dice: [0.8423]\n",
      "2021-10-29 15:08:53.652000: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:08:54.128039: lr: 0.006125\n",
      "2021-10-29 15:08:54.163416: saving checkpoint...\n",
      "2021-10-29 15:08:54.832395: done, saving took 0.69 seconds\n",
      "2021-10-29 15:08:55.242458: This epoch took 189.900068 s\n",
      "\n",
      "2021-10-29 15:08:55.251149: \n",
      "epoch:  42\n",
      "2021-10-29 15:11:50.525387: train loss : -0.8864\n",
      "2021-10-29 15:12:03.515683: validation loss: -0.8315\n",
      "2021-10-29 15:12:03.519584: Average global foreground Dice: [0.8398]\n",
      "2021-10-29 15:12:03.527029: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:12:04.004226: lr: 0.00603\n",
      "2021-10-29 15:12:04.040242: saving checkpoint...\n",
      "2021-10-29 15:12:04.702087: done, saving took 0.68 seconds\n",
      "2021-10-29 15:12:05.145585: This epoch took 189.886418 s\n",
      "\n",
      "2021-10-29 15:12:05.154428: \n",
      "epoch:  43\n",
      "2021-10-29 15:15:00.971376: train loss : -0.8873\n",
      "2021-10-29 15:15:13.965306: validation loss: -0.8294\n",
      "2021-10-29 15:15:13.969029: Average global foreground Dice: [0.8375]\n",
      "2021-10-29 15:15:13.976037: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:15:14.515190: lr: 0.005934\n",
      "2021-10-29 15:15:14.533715: This epoch took 189.371107 s\n",
      "\n",
      "2021-10-29 15:15:14.541449: \n",
      "epoch:  44\n",
      "2021-10-29 15:18:10.923291: train loss : -0.8876\n",
      "2021-10-29 15:18:23.982239: validation loss: -0.8321\n",
      "2021-10-29 15:18:23.986244: Average global foreground Dice: [0.8422]\n",
      "2021-10-29 15:18:23.993502: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:18:24.474707: lr: 0.005839\n",
      "2021-10-29 15:18:24.509771: saving checkpoint...\n",
      "2021-10-29 15:18:25.260960: done, saving took 0.77 seconds\n",
      "2021-10-29 15:18:25.705872: This epoch took 191.156475 s\n",
      "\n",
      "2021-10-29 15:18:25.716998: \n",
      "epoch:  45\n",
      "2021-10-29 15:21:21.753523: train loss : -0.8902\n",
      "2021-10-29 15:21:34.810752: validation loss: -0.8305\n",
      "2021-10-29 15:21:34.813102: Average global foreground Dice: [0.8399]\n",
      "2021-10-29 15:21:34.820102: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:21:35.299791: lr: 0.005743\n",
      "2021-10-29 15:21:35.338135: saving checkpoint...\n",
      "2021-10-29 15:21:36.086271: done, saving took 0.77 seconds\n",
      "2021-10-29 15:21:36.794346: This epoch took 191.068940 s\n",
      "\n",
      "2021-10-29 15:21:36.803123: \n",
      "epoch:  46\n",
      "2021-10-29 15:24:32.506702: train loss : -0.8900\n",
      "2021-10-29 15:24:45.549863: validation loss: -0.8325\n",
      "2021-10-29 15:24:45.553455: Average global foreground Dice: [0.843]\n",
      "2021-10-29 15:24:45.559696: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:24:46.040505: lr: 0.005647\n",
      "2021-10-29 15:24:46.084103: saving checkpoint...\n",
      "2021-10-29 15:24:46.838324: done, saving took 0.78 seconds\n",
      "2021-10-29 15:24:47.263708: This epoch took 190.453228 s\n",
      "\n",
      "2021-10-29 15:24:47.272240: \n",
      "epoch:  47\n",
      "2021-10-29 15:27:42.942904: train loss : -0.8902\n",
      "2021-10-29 15:27:55.993544: validation loss: -0.8293\n",
      "2021-10-29 15:27:55.997288: Average global foreground Dice: [0.8391]\n",
      "2021-10-29 15:27:56.004525: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:27:56.495735: lr: 0.005551\n",
      "2021-10-29 15:27:56.542635: saving checkpoint...\n",
      "2021-10-29 15:27:57.293319: done, saving took 0.78 seconds\n",
      "2021-10-29 15:27:57.742605: This epoch took 190.462184 s\n",
      "\n",
      "2021-10-29 15:27:57.751554: \n",
      "epoch:  48\n",
      "2021-10-29 15:30:53.508307: train loss : -0.8900\n",
      "2021-10-29 15:31:06.575241: validation loss: -0.8297\n",
      "2021-10-29 15:31:06.578902: Average global foreground Dice: [0.8378]\n",
      "2021-10-29 15:31:06.587172: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:31:07.149336: lr: 0.005455\n",
      "2021-10-29 15:31:07.169343: This epoch took 189.408926 s\n",
      "\n",
      "2021-10-29 15:31:07.176894: \n",
      "epoch:  49\n",
      "2021-10-29 15:34:02.916505: train loss : -0.8927\n",
      "2021-10-29 15:34:15.984945: validation loss: -0.8280\n",
      "2021-10-29 15:34:15.988888: Average global foreground Dice: [0.8379]\n",
      "2021-10-29 15:34:15.996507: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:34:16.478321: lr: 0.005359\n",
      "2021-10-29 15:34:16.500493: saving scheduled checkpoint file...\n",
      "2021-10-29 15:34:16.530758: saving checkpoint...\n",
      "2021-10-29 15:34:17.132632: done, saving took 0.63 seconds\n",
      "2021-10-29 15:34:17.549655: done\n",
      "2021-10-29 15:34:17.557786: This epoch took 190.374325 s\n",
      "\n",
      "2021-10-29 15:34:17.565076: \n",
      "epoch:  50\n",
      "2021-10-29 15:37:13.369366: train loss : -0.8920\n",
      "2021-10-29 15:37:26.434781: validation loss: -0.8307\n",
      "2021-10-29 15:37:26.438883: Average global foreground Dice: [0.8408]\n",
      "2021-10-29 15:37:26.446270: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:37:26.931114: lr: 0.005262\n",
      "2021-10-29 15:37:26.968567: saving checkpoint...\n",
      "2021-10-29 15:37:27.730490: done, saving took 0.78 seconds\n",
      "2021-10-29 15:37:28.140096: This epoch took 190.568025 s\n",
      "\n",
      "2021-10-29 15:37:28.149423: \n",
      "epoch:  51\n",
      "2021-10-29 15:40:23.779868: train loss : -0.8924\n",
      "2021-10-29 15:40:36.807076: validation loss: -0.8268\n",
      "2021-10-29 15:40:36.811399: Average global foreground Dice: [0.8366]\n",
      "2021-10-29 15:40:36.819110: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:40:37.310724: lr: 0.005166\n",
      "2021-10-29 15:40:37.327558: This epoch took 189.170600 s\n",
      "\n",
      "2021-10-29 15:40:37.334847: \n",
      "epoch:  52\n",
      "2021-10-29 15:43:33.196842: train loss : -0.8941\n",
      "2021-10-29 15:43:46.253967: validation loss: -0.8336\n",
      "2021-10-29 15:43:46.258441: Average global foreground Dice: [0.843]\n",
      "2021-10-29 15:43:46.266177: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:43:46.758787: lr: 0.005069\n",
      "2021-10-29 15:43:46.806890: saving checkpoint...\n",
      "2021-10-29 15:43:47.476791: done, saving took 0.70 seconds\n",
      "2021-10-29 15:43:47.880987: This epoch took 190.538991 s\n",
      "\n",
      "2021-10-29 15:43:47.889073: \n",
      "epoch:  53\n",
      "2021-10-29 15:46:43.544983: train loss : -0.8936\n",
      "2021-10-29 15:46:56.574322: validation loss: -0.8270\n",
      "2021-10-29 15:46:56.578597: Average global foreground Dice: [0.8383]\n",
      "2021-10-29 15:46:56.586430: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:46:57.078256: lr: 0.004971\n",
      "2021-10-29 15:46:57.092989: This epoch took 189.196814 s\n",
      "\n",
      "2021-10-29 15:46:57.099820: \n",
      "epoch:  54\n",
      "2021-10-29 15:49:52.772851: train loss : -0.8939\n",
      "2021-10-29 15:50:05.803793: validation loss: -0.8318\n",
      "2021-10-29 15:50:05.808084: Average global foreground Dice: [0.8401]\n",
      "2021-10-29 15:50:05.815815: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:50:06.301656: lr: 0.004874\n",
      "2021-10-29 15:50:06.339150: saving checkpoint...\n",
      "2021-10-29 15:50:06.995908: done, saving took 0.68 seconds\n",
      "2021-10-29 15:50:07.411714: This epoch took 190.305277 s\n",
      "\n",
      "2021-10-29 15:50:07.420510: \n",
      "epoch:  55\n",
      "2021-10-29 15:53:03.476660: train loss : -0.8954\n",
      "2021-10-29 15:53:16.509933: validation loss: -0.8309\n",
      "2021-10-29 15:53:16.513546: Average global foreground Dice: [0.8404]\n",
      "2021-10-29 15:53:16.519685: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:53:17.005541: lr: 0.004776\n",
      "2021-10-29 15:53:17.043025: saving checkpoint...\n",
      "2021-10-29 15:53:17.715998: done, saving took 0.69 seconds\n",
      "2021-10-29 15:53:18.124332: This epoch took 190.697839 s\n",
      "\n",
      "2021-10-29 15:53:18.132598: \n",
      "epoch:  56\n",
      "2021-10-29 15:56:14.121495: train loss : -0.8955\n",
      "2021-10-29 15:56:27.188422: validation loss: -0.8266\n",
      "2021-10-29 15:56:27.192283: Average global foreground Dice: [0.8364]\n",
      "2021-10-29 15:56:27.199356: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:56:27.690743: lr: 0.004679\n",
      "2021-10-29 15:56:27.703230: This epoch took 189.563525 s\n",
      "\n",
      "2021-10-29 15:56:27.709796: \n",
      "epoch:  57\n",
      "2021-10-29 15:59:23.830796: train loss : -0.8954\n",
      "2021-10-29 15:59:36.852320: validation loss: -0.8315\n",
      "2021-10-29 15:59:36.856461: Average global foreground Dice: [0.8405]\n",
      "2021-10-29 15:59:36.863744: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 15:59:37.347401: lr: 0.004581\n",
      "2021-10-29 15:59:37.363864: This epoch took 189.648036 s\n",
      "\n",
      "2021-10-29 15:59:37.370701: \n",
      "epoch:  58\n",
      "2021-10-29 16:02:33.544006: train loss : -0.8967\n",
      "2021-10-29 16:02:46.571821: validation loss: -0.8314\n",
      "2021-10-29 16:02:46.576074: Average global foreground Dice: [0.8402]\n",
      "2021-10-29 16:02:46.583483: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:02:47.069828: lr: 0.004482\n",
      "2021-10-29 16:02:47.084728: This epoch took 189.707028 s\n",
      "\n",
      "2021-10-29 16:02:47.091286: \n",
      "epoch:  59\n",
      "2021-10-29 16:05:43.090417: train loss : -0.8972\n",
      "2021-10-29 16:05:56.097938: validation loss: -0.8269\n",
      "2021-10-29 16:05:56.101869: Average global foreground Dice: [0.8383]\n",
      "2021-10-29 16:05:56.109071: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:05:56.657614: lr: 0.004384\n",
      "2021-10-29 16:05:56.673808: This epoch took 189.575960 s\n",
      "\n",
      "2021-10-29 16:05:56.680747: \n",
      "epoch:  60\n",
      "2021-10-29 16:08:52.978323: train loss : -0.8975\n",
      "2021-10-29 16:09:06.015906: validation loss: -0.8285\n",
      "2021-10-29 16:09:06.020705: Average global foreground Dice: [0.8386]\n",
      "2021-10-29 16:09:06.026939: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:09:06.556651: lr: 0.004285\n",
      "2021-10-29 16:09:06.570650: This epoch took 189.881766 s\n",
      "\n",
      "2021-10-29 16:09:06.577021: \n",
      "epoch:  61\n",
      "2021-10-29 16:12:02.771168: train loss : -0.8976\n",
      "2021-10-29 16:12:15.832416: validation loss: -0.8257\n",
      "2021-10-29 16:12:15.836158: Average global foreground Dice: [0.8357]\n",
      "2021-10-29 16:12:15.843178: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:12:16.375673: lr: 0.004186\n",
      "2021-10-29 16:12:16.392785: This epoch took 189.808625 s\n",
      "\n",
      "2021-10-29 16:12:16.401180: \n",
      "epoch:  62\n",
      "2021-10-29 16:15:12.528971: train loss : -0.8992\n",
      "2021-10-29 16:15:25.571731: validation loss: -0.8296\n",
      "2021-10-29 16:15:25.576034: Average global foreground Dice: [0.8395]\n",
      "2021-10-29 16:15:25.583995: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:15:26.071330: lr: 0.004087\n",
      "2021-10-29 16:15:26.087343: This epoch took 189.677280 s\n",
      "\n",
      "2021-10-29 16:15:26.094895: \n",
      "epoch:  63\n",
      "2021-10-29 16:18:22.630244: train loss : -0.9002\n",
      "2021-10-29 16:18:35.685303: validation loss: -0.8311\n",
      "2021-10-29 16:18:35.690558: Average global foreground Dice: [0.8387]\n",
      "2021-10-29 16:18:35.698004: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:18:36.187625: lr: 0.003987\n",
      "2021-10-29 16:18:36.200637: This epoch took 190.098574 s\n",
      "\n",
      "2021-10-29 16:18:36.207554: \n",
      "epoch:  64\n",
      "2021-10-29 16:21:32.363855: train loss : -0.9010\n",
      "2021-10-29 16:21:45.390325: validation loss: -0.8313\n",
      "2021-10-29 16:21:45.394486: Average global foreground Dice: [0.8417]\n",
      "2021-10-29 16:21:45.401623: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:21:45.884595: lr: 0.003887\n",
      "2021-10-29 16:21:45.901146: This epoch took 189.687381 s\n",
      "\n",
      "2021-10-29 16:21:45.909355: \n",
      "epoch:  65\n",
      "2021-10-29 16:24:41.836616: train loss : -0.9008\n",
      "2021-10-29 16:24:54.862638: validation loss: -0.8271\n",
      "2021-10-29 16:24:54.866776: Average global foreground Dice: [0.8369]\n",
      "2021-10-29 16:24:54.872971: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:24:55.359819: lr: 0.003787\n",
      "2021-10-29 16:24:55.372499: This epoch took 189.455745 s\n",
      "\n",
      "2021-10-29 16:24:55.379473: \n",
      "epoch:  66\n",
      "2021-10-29 16:27:51.496842: train loss : -0.9010\n",
      "2021-10-29 16:28:04.542224: validation loss: -0.8311\n",
      "2021-10-29 16:28:04.546685: Average global foreground Dice: [0.8404]\n",
      "2021-10-29 16:28:04.554593: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:28:05.040958: lr: 0.003687\n",
      "2021-10-29 16:28:05.058120: This epoch took 189.671984 s\n",
      "\n",
      "2021-10-29 16:28:05.064836: \n",
      "epoch:  67\n",
      "2021-10-29 16:31:00.980869: train loss : -0.9009\n",
      "2021-10-29 16:31:14.008433: validation loss: -0.8313\n",
      "2021-10-29 16:31:14.012445: Average global foreground Dice: [0.8408]\n",
      "2021-10-29 16:31:14.019183: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:31:14.510386: lr: 0.003586\n",
      "2021-10-29 16:31:14.529125: This epoch took 189.456955 s\n",
      "\n",
      "2021-10-29 16:31:14.536715: \n",
      "epoch:  68\n",
      "2021-10-29 16:34:10.447993: train loss : -0.9022\n",
      "2021-10-29 16:34:23.466610: validation loss: -0.8348\n",
      "2021-10-29 16:34:23.470993: Average global foreground Dice: [0.8428]\n",
      "2021-10-29 16:34:23.478320: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:34:23.973825: lr: 0.003485\n",
      "2021-10-29 16:34:24.020574: saving checkpoint...\n",
      "2021-10-29 16:34:24.929657: done, saving took 0.94 seconds\n",
      "2021-10-29 16:34:25.339671: This epoch took 190.794748 s\n",
      "\n",
      "2021-10-29 16:34:25.348058: \n",
      "epoch:  69\n",
      "2021-10-29 16:37:21.340061: train loss : -0.9026\n",
      "2021-10-29 16:37:34.362265: validation loss: -0.8253\n",
      "2021-10-29 16:37:34.367469: Average global foreground Dice: [0.8353]\n",
      "2021-10-29 16:37:34.374280: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:37:34.872044: lr: 0.003384\n",
      "2021-10-29 16:37:34.891014: This epoch took 189.535452 s\n",
      "\n",
      "2021-10-29 16:37:34.898150: \n",
      "epoch:  70\n",
      "2021-10-29 16:40:30.971740: train loss : -0.9024\n",
      "2021-10-29 16:40:44.041044: validation loss: -0.8314\n",
      "2021-10-29 16:40:44.045120: Average global foreground Dice: [0.8396]\n",
      "2021-10-29 16:40:44.052662: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:40:44.620212: lr: 0.003282\n",
      "2021-10-29 16:40:44.641941: This epoch took 189.737325 s\n",
      "\n",
      "2021-10-29 16:40:44.649148: \n",
      "epoch:  71\n",
      "2021-10-29 16:43:40.843685: train loss : -0.9026\n",
      "2021-10-29 16:43:53.915688: validation loss: -0.8333\n",
      "2021-10-29 16:43:53.919744: Average global foreground Dice: [0.8411]\n",
      "2021-10-29 16:43:53.926474: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:43:54.416935: lr: 0.00318\n",
      "2021-10-29 16:43:54.440800: This epoch took 189.784084 s\n",
      "\n",
      "2021-10-29 16:43:54.447872: \n",
      "epoch:  72\n",
      "2021-10-29 16:46:50.615351: train loss : -0.9036\n",
      "2021-10-29 16:47:03.672406: validation loss: -0.8287\n",
      "2021-10-29 16:47:03.676262: Average global foreground Dice: [0.8372]\n",
      "2021-10-29 16:47:03.682554: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:47:04.177657: lr: 0.003078\n",
      "2021-10-29 16:47:04.194049: This epoch took 189.738631 s\n",
      "\n",
      "2021-10-29 16:47:04.200664: \n",
      "epoch:  73\n",
      "2021-10-29 16:50:00.937602: train loss : -0.9056\n",
      "2021-10-29 16:50:13.979595: validation loss: -0.8285\n",
      "2021-10-29 16:50:13.983819: Average global foreground Dice: [0.8371]\n",
      "2021-10-29 16:50:13.991193: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:50:14.499712: lr: 0.002975\n",
      "2021-10-29 16:50:14.519164: This epoch took 190.311986 s\n",
      "\n",
      "2021-10-29 16:50:14.526225: \n",
      "epoch:  74\n",
      "2021-10-29 16:53:06.991778: train loss : -0.9051\n",
      "2021-10-29 16:53:19.183508: validation loss: -0.8229\n",
      "2021-10-29 16:53:19.186859: Average global foreground Dice: [0.8331]\n",
      "2021-10-29 16:53:19.193316: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:53:19.689923: lr: 0.002872\n",
      "2021-10-29 16:53:19.708991: This epoch took 185.172873 s\n",
      "\n",
      "2021-10-29 16:53:19.716573: \n",
      "epoch:  75\n",
      "2021-10-29 16:56:03.342540: train loss : -0.9058\n",
      "2021-10-29 16:56:15.663243: validation loss: -0.8281\n",
      "2021-10-29 16:56:15.667407: Average global foreground Dice: [0.8375]\n",
      "2021-10-29 16:56:15.678221: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:56:16.224032: lr: 0.002768\n",
      "2021-10-29 16:56:16.244507: This epoch took 176.520532 s\n",
      "\n",
      "2021-10-29 16:56:16.251888: \n",
      "epoch:  76\n",
      "2021-10-29 16:59:09.038960: train loss : -0.9056\n",
      "2021-10-29 16:59:22.148741: validation loss: -0.8281\n",
      "2021-10-29 16:59:22.152467: Average global foreground Dice: [0.8368]\n",
      "2021-10-29 16:59:22.158156: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 16:59:22.690977: lr: 0.002664\n",
      "2021-10-29 16:59:22.713904: This epoch took 186.454372 s\n",
      "\n",
      "2021-10-29 16:59:22.721760: \n",
      "epoch:  77\n",
      "2021-10-29 17:02:19.164828: train loss : -0.9073\n",
      "2021-10-29 17:02:32.176789: validation loss: -0.8261\n",
      "2021-10-29 17:02:32.181320: Average global foreground Dice: [0.8354]\n",
      "2021-10-29 17:02:32.188622: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:02:32.680894: lr: 0.00256\n",
      "2021-10-29 17:02:32.699699: This epoch took 189.969093 s\n",
      "\n",
      "2021-10-29 17:02:32.707169: \n",
      "epoch:  78\n",
      "2021-10-29 17:05:28.265914: train loss : -0.9079\n",
      "2021-10-29 17:05:41.316025: validation loss: -0.8261\n",
      "2021-10-29 17:05:41.320006: Average global foreground Dice: [0.8359]\n",
      "2021-10-29 17:05:41.326468: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:05:41.816900: lr: 0.002455\n",
      "2021-10-29 17:05:41.836844: This epoch took 189.122555 s\n",
      "\n",
      "2021-10-29 17:05:41.843838: \n",
      "epoch:  79\n",
      "2021-10-29 17:08:37.826425: train loss : -0.9088\n",
      "2021-10-29 17:08:50.835303: validation loss: -0.8278\n",
      "2021-10-29 17:08:50.839074: Average global foreground Dice: [0.838]\n",
      "2021-10-29 17:08:50.846660: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:08:51.334004: lr: 0.002349\n",
      "2021-10-29 17:08:51.357211: This epoch took 189.506552 s\n",
      "\n",
      "2021-10-29 17:08:51.364032: \n",
      "epoch:  80\n",
      "2021-10-29 17:11:46.723669: train loss : -0.9080\n",
      "2021-10-29 17:11:59.716473: validation loss: -0.8283\n",
      "2021-10-29 17:11:59.720178: Average global foreground Dice: [0.8369]\n",
      "2021-10-29 17:11:59.727107: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:12:00.219195: lr: 0.002243\n",
      "2021-10-29 17:12:00.239194: This epoch took 188.869175 s\n",
      "\n",
      "2021-10-29 17:12:00.246229: \n",
      "epoch:  81\n",
      "2021-10-29 17:14:55.885495: train loss : -0.9086\n",
      "2021-10-29 17:15:08.890146: validation loss: -0.8302\n",
      "2021-10-29 17:15:08.893954: Average global foreground Dice: [0.8382]\n",
      "2021-10-29 17:15:08.901122: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:15:09.388030: lr: 0.002137\n",
      "2021-10-29 17:15:09.408131: This epoch took 189.154629 s\n",
      "\n",
      "2021-10-29 17:15:09.415438: \n",
      "epoch:  82\n",
      "2021-10-29 17:18:05.322900: train loss : -0.9087\n",
      "2021-10-29 17:18:18.327718: validation loss: -0.8300\n",
      "2021-10-29 17:18:18.331482: Average global foreground Dice: [0.8395]\n",
      "2021-10-29 17:18:18.338152: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:18:18.825024: lr: 0.00203\n",
      "2021-10-29 17:18:18.846157: This epoch took 189.423672 s\n",
      "\n",
      "2021-10-29 17:18:18.852918: \n",
      "epoch:  83\n",
      "2021-10-29 17:21:14.289617: train loss : -0.9093\n",
      "2021-10-29 17:21:27.270977: validation loss: -0.8254\n",
      "2021-10-29 17:21:27.274778: Average global foreground Dice: [0.834]\n",
      "2021-10-29 17:21:27.281698: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:21:27.765320: lr: 0.001922\n",
      "2021-10-29 17:21:27.783987: This epoch took 188.923332 s\n",
      "\n",
      "2021-10-29 17:21:27.790880: \n",
      "epoch:  84\n",
      "2021-10-29 17:24:23.406638: train loss : -0.9104\n",
      "2021-10-29 17:24:36.446080: validation loss: -0.8277\n",
      "2021-10-29 17:24:36.449821: Average global foreground Dice: [0.8363]\n",
      "2021-10-29 17:24:36.458771: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:24:36.947004: lr: 0.001813\n",
      "2021-10-29 17:24:36.966905: This epoch took 189.168509 s\n",
      "\n",
      "2021-10-29 17:24:36.973347: \n",
      "epoch:  85\n",
      "2021-10-29 17:27:32.737650: train loss : -0.9105\n",
      "2021-10-29 17:27:45.731277: validation loss: -0.8257\n",
      "2021-10-29 17:27:45.735154: Average global foreground Dice: [0.8346]\n",
      "2021-10-29 17:27:45.742319: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:27:46.276096: lr: 0.001704\n",
      "2021-10-29 17:27:46.297995: This epoch took 189.317070 s\n",
      "\n",
      "2021-10-29 17:27:46.305379: \n",
      "epoch:  86\n",
      "2021-10-29 17:30:41.781425: train loss : -0.9114\n",
      "2021-10-29 17:30:54.786574: validation loss: -0.8284\n",
      "2021-10-29 17:30:54.790497: Average global foreground Dice: [0.8372]\n",
      "2021-10-29 17:30:54.797561: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:30:55.281770: lr: 0.001594\n",
      "2021-10-29 17:30:55.299986: This epoch took 188.986140 s\n",
      "\n",
      "2021-10-29 17:30:55.306213: \n",
      "epoch:  87\n",
      "2021-10-29 17:33:51.335763: train loss : -0.9123\n",
      "2021-10-29 17:34:04.363381: validation loss: -0.8290\n",
      "2021-10-29 17:34:04.366928: Average global foreground Dice: [0.8378]\n",
      "2021-10-29 17:34:04.373160: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:34:04.856289: lr: 0.001483\n",
      "2021-10-29 17:34:04.876924: This epoch took 189.563071 s\n",
      "\n",
      "2021-10-29 17:34:04.883752: \n",
      "epoch:  88\n",
      "2021-10-29 17:37:00.430167: train loss : -0.9116\n",
      "2021-10-29 17:37:13.422720: validation loss: -0.8254\n",
      "2021-10-29 17:37:13.426558: Average global foreground Dice: [0.8338]\n",
      "2021-10-29 17:37:13.433399: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:37:13.919420: lr: 0.001372\n",
      "2021-10-29 17:37:13.940604: This epoch took 189.048564 s\n",
      "\n",
      "2021-10-29 17:37:13.947719: \n",
      "epoch:  89\n",
      "2021-10-29 17:40:09.401491: train loss : -0.9118\n",
      "2021-10-29 17:40:22.395353: validation loss: -0.8305\n",
      "2021-10-29 17:40:22.399233: Average global foreground Dice: [0.8396]\n",
      "2021-10-29 17:40:22.405904: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:40:22.895656: lr: 0.001259\n",
      "2021-10-29 17:40:22.915875: This epoch took 188.961623 s\n",
      "\n",
      "2021-10-29 17:40:22.923137: \n",
      "epoch:  90\n",
      "2021-10-29 17:43:18.823803: train loss : -0.9134\n",
      "2021-10-29 17:43:31.814884: validation loss: -0.8262\n",
      "2021-10-29 17:43:31.818597: Average global foreground Dice: [0.8359]\n",
      "2021-10-29 17:43:31.825216: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:43:32.315444: lr: 0.001145\n",
      "2021-10-29 17:43:32.336063: This epoch took 189.405909 s\n",
      "\n",
      "2021-10-29 17:43:32.343110: \n",
      "epoch:  91\n",
      "2021-10-29 17:46:28.065649: train loss : -0.9137\n",
      "2021-10-29 17:46:41.067269: validation loss: -0.8301\n",
      "2021-10-29 17:46:41.071150: Average global foreground Dice: [0.8386]\n",
      "2021-10-29 17:46:41.078578: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:46:41.632391: lr: 0.00103\n",
      "2021-10-29 17:46:41.655013: This epoch took 189.304892 s\n",
      "\n",
      "2021-10-29 17:46:41.662242: \n",
      "epoch:  92\n",
      "2021-10-29 17:49:37.423763: train loss : -0.9138\n",
      "2021-10-29 17:49:50.454985: validation loss: -0.8293\n",
      "2021-10-29 17:49:50.458583: Average global foreground Dice: [0.8387]\n",
      "2021-10-29 17:49:50.465808: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:49:50.952267: lr: 0.000913\n",
      "2021-10-29 17:49:50.970217: This epoch took 189.301044 s\n",
      "\n",
      "2021-10-29 17:49:50.977350: \n",
      "epoch:  93\n",
      "2021-10-29 17:52:46.988833: train loss : -0.9149\n",
      "2021-10-29 17:52:59.985848: validation loss: -0.8329\n",
      "2021-10-29 17:52:59.990000: Average global foreground Dice: [0.8409]\n",
      "2021-10-29 17:52:59.997148: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:53:00.486192: lr: 0.000795\n",
      "2021-10-29 17:53:00.506477: This epoch took 189.522725 s\n",
      "\n",
      "2021-10-29 17:53:00.513480: \n",
      "epoch:  94\n",
      "2021-10-29 17:55:56.024748: train loss : -0.9145\n",
      "2021-10-29 17:56:09.012427: validation loss: -0.8253\n",
      "2021-10-29 17:56:09.016396: Average global foreground Dice: [0.8342]\n",
      "2021-10-29 17:56:09.023592: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:56:09.514973: lr: 0.000675\n",
      "2021-10-29 17:56:09.535848: This epoch took 189.014166 s\n",
      "\n",
      "2021-10-29 17:56:09.542770: \n",
      "epoch:  95\n",
      "2021-10-29 17:59:05.313120: train loss : -0.9162\n",
      "2021-10-29 17:59:18.382298: validation loss: -0.8305\n",
      "2021-10-29 17:59:18.385930: Average global foreground Dice: [0.839]\n",
      "2021-10-29 17:59:18.392601: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 17:59:18.882587: lr: 0.000552\n",
      "2021-10-29 17:59:18.906113: This epoch took 189.355599 s\n",
      "\n",
      "2021-10-29 17:59:18.913536: \n",
      "epoch:  96\n",
      "2021-10-29 18:02:14.573716: train loss : -0.9170\n",
      "2021-10-29 18:02:27.581055: validation loss: -0.8290\n",
      "2021-10-29 18:02:27.584646: Average global foreground Dice: [0.837]\n",
      "2021-10-29 18:02:27.591107: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 18:02:28.120203: lr: 0.000426\n",
      "2021-10-29 18:02:28.141721: This epoch took 189.220166 s\n",
      "\n",
      "2021-10-29 18:02:28.149304: \n",
      "epoch:  97\n",
      "2021-10-29 18:05:23.533519: train loss : -0.9171\n",
      "2021-10-29 18:05:36.534272: validation loss: -0.8299\n",
      "2021-10-29 18:05:36.539479: Average global foreground Dice: [0.8373]\n",
      "2021-10-29 18:05:36.545998: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 18:05:37.029514: lr: 0.000296\n",
      "2021-10-29 18:05:37.053542: This epoch took 188.896928 s\n",
      "\n",
      "2021-10-29 18:05:37.060757: \n",
      "epoch:  98\n",
      "2021-10-29 18:08:32.904646: train loss : -0.9169\n",
      "2021-10-29 18:08:45.938517: validation loss: -0.8261\n",
      "2021-10-29 18:08:45.943969: Average global foreground Dice: [0.8362]\n",
      "2021-10-29 18:08:45.950950: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 18:08:46.438057: lr: 0.000158\n",
      "2021-10-29 18:08:46.457618: This epoch took 189.388936 s\n",
      "\n",
      "2021-10-29 18:08:46.464372: \n",
      "epoch:  99\n",
      "2021-10-29 18:11:42.147521: train loss : -0.9170\n",
      "2021-10-29 18:11:55.165605: validation loss: -0.8276\n",
      "2021-10-29 18:11:55.169670: Average global foreground Dice: [0.8362]\n",
      "2021-10-29 18:11:55.176857: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 18:11:55.670949: lr: 0.0\n",
      "2021-10-29 18:11:55.698068: saving scheduled checkpoint file...\n",
      "2021-10-29 18:11:55.734995: saving checkpoint...\n",
      "2021-10-29 18:11:56.498720: done, saving took 0.79 seconds\n",
      "2021-10-29 18:11:56.944157: done\n",
      "2021-10-29 18:11:56.952995: This epoch took 190.482474 s\n",
      "\n",
      "2021-10-29 18:11:56.978009: saving checkpoint...\n",
      "2021-10-29 18:11:57.565197: done, saving took 0.61 seconds\n",
      "23090567_20160819 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150401 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130213 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120627 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090590_20121212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160706 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090599_20140701 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130225 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090604_20140303 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090615_20140403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090617_20140211 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120406 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160111 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130213 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090631_20130128 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090634_20150409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-29 18:13:53.652566: finished prediction\n",
      "2021-10-29 18:13:53.659339: evaluation of raw predictions\n",
      "2021-10-29 18:13:55.555137: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8343248918836725\n",
      "after:  0.8343392059570649\n",
      "Removing all but the largest foreground region improved results!\n",
      "for_which_classes [1]\n",
      "min_valid_object_sizes None\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[[1]]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-10-29 18:14:07.923001: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-10-29 18:14:07.945166: The split file contains 5 splits.\n",
      "2021-10-29 18:14:07.951904: Desired fold for training: 2\n",
      "2021-10-29 18:14:07.959122: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-29 18:14:12.034336: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-29 18:14:19.360002: Unable to plot network architecture:\n",
      "2021-10-29 18:14:19.363224: No module named 'hiddenlayer'\n",
      "2021-10-29 18:14:19.440032: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-29 18:14:19.447839: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-29 18:14:19.456372: \n",
      "\n",
      "2021-10-29 18:14:19.462443: \n",
      "epoch:  0\n",
      "2021-10-29 18:17:32.325534: train loss : -0.2083\n",
      "2021-10-29 18:17:45.662601: validation loss: -0.6139\n",
      "2021-10-29 18:17:45.667466: Average global foreground Dice: [0.6978]\n",
      "2021-10-29 18:17:45.674458: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 18:17:46.100300: lr: 0.00991\n",
      "2021-10-29 18:17:46.120485: This epoch took 206.580851 s\n",
      "\n",
      "2021-10-29 18:17:46.126878: \n",
      "epoch:  1\n",
      "2021-10-29 18:20:42.801674: train loss : -0.6878\n",
      "2021-10-29 18:20:56.148609: validation loss: -0.7548\n",
      "2021-10-29 18:20:56.154375: Average global foreground Dice: [0.7807]\n",
      "2021-10-29 18:20:56.157673: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 18:20:56.641901: lr: 0.00982\n",
      "2021-10-29 18:20:56.699575: saving checkpoint...\n",
      "2021-10-29 18:20:57.359628: done, saving took 0.70 seconds\n",
      "2021-10-29 18:20:57.776167: This epoch took 191.642972 s\n",
      "\n",
      "2021-10-29 18:20:57.787161: \n",
      "epoch:  2\n",
      "2021-10-29 18:23:53.794737: train loss : -0.7709\n",
      "2021-10-29 18:24:07.141549: validation loss: -0.7888\n",
      "2021-10-29 18:24:07.145629: Average global foreground Dice: [0.8091]\n",
      "2021-10-29 18:24:07.152819: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 18:24:07.641265: lr: 0.00973\n",
      "2021-10-29 18:24:07.704146: saving checkpoint...\n",
      "2021-10-29 18:24:08.443887: done, saving took 0.78 seconds\n",
      "2021-10-29 18:24:08.854706: This epoch took 191.059842 s\n",
      "\n",
      "2021-10-29 18:24:08.863371: \n",
      "epoch:  3\n",
      "2021-10-29 18:27:04.665084: train loss : -0.7965\n",
      "2021-10-29 18:27:17.983360: validation loss: -0.8081\n",
      "2021-10-29 18:27:17.987628: Average global foreground Dice: [0.827]\n",
      "2021-10-29 18:27:17.994543: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 18:27:18.479560: lr: 0.009639\n",
      "2021-10-29 18:27:18.517466: saving checkpoint...\n",
      "2021-10-29 18:27:19.255291: done, saving took 0.76 seconds\n",
      "2021-10-29 18:27:19.668078: This epoch took 190.797194 s\n",
      "\n",
      "2021-10-29 18:27:19.676150: \n",
      "epoch:  4\n",
      "2021-10-29 18:30:15.613672: train loss : -0.8102\n",
      "2021-10-29 18:30:28.951210: validation loss: -0.8084\n",
      "2021-10-29 18:30:28.955534: Average global foreground Dice: [0.8262]\n",
      "2021-10-29 18:30:28.962095: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 18:30:29.458879: lr: 0.009549\n",
      "2021-10-29 18:30:29.517565: saving checkpoint...\n",
      "2021-10-29 18:30:30.253994: done, saving took 0.78 seconds\n",
      "2021-10-29 18:30:30.645395: This epoch took 190.962106 s\n",
      "\n",
      "2021-10-29 18:30:30.654028: \n",
      "epoch:  5\n",
      "2021-10-29 18:33:26.201355: train loss : -0.8198\n",
      "2021-10-29 18:33:39.497178: validation loss: -0.8120\n",
      "2021-10-29 18:33:39.500811: Average global foreground Dice: [0.8275]\n",
      "2021-10-29 18:33:39.507125: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 18:33:39.985079: lr: 0.009458\n",
      "2021-10-29 18:33:40.024016: saving checkpoint...\n",
      "2021-10-29 18:33:40.749458: done, saving took 0.74 seconds\n",
      "2021-10-29 18:33:41.165113: This epoch took 190.502738 s\n",
      "\n",
      "2021-10-29 18:33:41.173953: \n",
      "epoch:  6\n",
      "2021-10-29 18:36:37.033736: train loss : -0.8284\n",
      "2021-10-29 18:36:50.391231: validation loss: -0.8131\n",
      "2021-10-29 18:36:50.395203: Average global foreground Dice: [0.828]\n",
      "2021-10-29 18:36:50.400744: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 18:36:50.887723: lr: 0.009368\n",
      "2021-10-29 18:36:50.929281: saving checkpoint...\n",
      "2021-10-29 18:36:51.724132: done, saving took 0.82 seconds\n",
      "2021-10-29 18:36:52.129655: This epoch took 190.948822 s\n",
      "\n",
      "2021-10-29 18:36:52.137721: \n",
      "epoch:  7\n",
      "2021-10-29 18:39:48.012492: train loss : -0.8314\n",
      "2021-10-29 18:40:01.358930: validation loss: -0.8186\n",
      "2021-10-29 18:40:01.363017: Average global foreground Dice: [0.8332]\n",
      "2021-10-29 18:40:01.374412: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 18:40:01.857403: lr: 0.009277\n",
      "2021-10-29 18:40:01.895810: saving checkpoint...\n",
      "2021-10-29 18:40:02.635840: done, saving took 0.76 seconds\n",
      "2021-10-29 18:40:03.042593: This epoch took 190.897536 s\n",
      "\n",
      "2021-10-29 18:40:03.051570: \n",
      "epoch:  8\n",
      "2021-10-29 18:42:58.969345: train loss : -0.8379\n",
      "2021-10-29 18:43:12.318410: validation loss: -0.8219\n",
      "2021-10-29 18:43:12.322504: Average global foreground Dice: [0.8349]\n",
      "2021-10-29 18:43:12.328700: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 18:43:12.823295: lr: 0.009186\n",
      "2021-10-29 18:43:12.863758: saving checkpoint...\n",
      "2021-10-29 18:43:13.604354: done, saving took 0.76 seconds\n",
      "2021-10-29 18:43:14.032393: This epoch took 190.973634 s\n",
      "\n",
      "2021-10-29 18:43:14.041542: \n",
      "epoch:  9\n",
      "2021-10-29 18:46:11.203229: train loss : -0.8423\n",
      "2021-10-29 18:46:24.605549: validation loss: -0.8191\n",
      "2021-10-29 18:46:24.634495: Average global foreground Dice: [0.8335]\n",
      "2021-10-29 18:46:24.641707: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 18:46:25.143611: lr: 0.009095\n",
      "2021-10-29 18:46:25.181438: saving checkpoint...\n",
      "2021-10-29 18:46:25.905490: done, saving took 0.74 seconds\n",
      "2021-10-29 18:46:26.288201: This epoch took 192.239992 s\n",
      "\n",
      "2021-10-29 18:46:26.295953: \n",
      "epoch:  10\n",
      "2021-10-29 18:49:23.498101: train loss : -0.8465\n",
      "2021-10-29 18:49:36.920901: validation loss: -0.8195\n",
      "2021-10-29 18:49:36.924650: Average global foreground Dice: [0.8298]\n",
      "2021-10-29 18:49:36.930681: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 18:49:37.411144: lr: 0.009004\n",
      "2021-10-29 18:49:37.448299: saving checkpoint...\n",
      "2021-10-29 18:49:38.188283: done, saving took 0.76 seconds\n",
      "2021-10-29 18:49:38.567506: This epoch took 192.264471 s\n",
      "\n",
      "2021-10-29 18:49:38.576215: \n",
      "epoch:  11\n",
      "2021-10-29 18:52:35.863619: train loss : -0.8472\n",
      "2021-10-29 18:52:49.273661: validation loss: -0.8263\n",
      "2021-10-29 18:52:49.277284: Average global foreground Dice: [0.8373]\n",
      "2021-10-29 18:52:49.284234: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 18:52:49.762092: lr: 0.008913\n",
      "2021-10-29 18:52:49.795875: saving checkpoint...\n",
      "2021-10-29 18:52:50.555459: done, saving took 0.78 seconds\n",
      "2021-10-29 18:52:50.983424: This epoch took 192.399932 s\n",
      "\n",
      "2021-10-29 18:52:50.992013: \n",
      "epoch:  12\n",
      "2021-10-29 18:55:48.269932: train loss : -0.8494\n",
      "2021-10-29 18:56:01.703857: validation loss: -0.8270\n",
      "2021-10-29 18:56:01.707850: Average global foreground Dice: [0.8391]\n",
      "2021-10-29 18:56:01.715290: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 18:56:02.260710: lr: 0.008822\n",
      "2021-10-29 18:56:02.300332: saving checkpoint...\n",
      "2021-10-29 18:56:03.041171: done, saving took 0.76 seconds\n",
      "2021-10-29 18:56:03.475183: This epoch took 192.475794 s\n",
      "\n",
      "2021-10-29 18:56:03.483339: \n",
      "epoch:  13\n",
      "2021-10-29 18:59:00.772724: train loss : -0.8528\n",
      "2021-10-29 18:59:14.202626: validation loss: -0.8248\n",
      "2021-10-29 18:59:14.206345: Average global foreground Dice: [0.8376]\n",
      "2021-10-29 18:59:14.213257: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 18:59:14.695103: lr: 0.008731\n",
      "2021-10-29 18:59:14.730967: saving checkpoint...\n",
      "2021-10-29 18:59:15.472563: done, saving took 0.76 seconds\n",
      "2021-10-29 18:59:15.894374: This epoch took 192.402888 s\n",
      "\n",
      "2021-10-29 18:59:15.902843: \n",
      "epoch:  14\n",
      "2021-10-29 19:02:13.260965: train loss : -0.8568\n",
      "2021-10-29 19:02:26.695283: validation loss: -0.8174\n",
      "2021-10-29 19:02:26.699163: Average global foreground Dice: [0.8309]\n",
      "2021-10-29 19:02:26.705507: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 19:02:27.189545: lr: 0.008639\n",
      "2021-10-29 19:02:27.229010: saving checkpoint...\n",
      "2021-10-29 19:02:27.977658: done, saving took 0.77 seconds\n",
      "2021-10-29 19:02:28.435145: This epoch took 192.525197 s\n",
      "\n",
      "2021-10-29 19:02:28.443392: \n",
      "epoch:  15\n",
      "2021-10-29 19:05:25.788981: train loss : -0.8572\n",
      "2021-10-29 19:05:39.219340: validation loss: -0.8227\n",
      "2021-10-29 19:05:39.223403: Average global foreground Dice: [0.8364]\n",
      "2021-10-29 19:05:39.230266: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 19:05:39.715713: lr: 0.008548\n",
      "2021-10-29 19:05:39.756744: saving checkpoint...\n",
      "2021-10-29 19:05:40.494473: done, saving took 0.76 seconds\n",
      "2021-10-29 19:05:40.901697: This epoch took 192.448379 s\n",
      "\n",
      "2021-10-29 19:05:40.910926: \n",
      "epoch:  16\n",
      "2021-10-29 19:08:38.288038: train loss : -0.8596\n",
      "2021-10-29 19:08:51.721383: validation loss: -0.8210\n",
      "2021-10-29 19:08:51.725683: Average global foreground Dice: [0.8355]\n",
      "2021-10-29 19:08:51.732565: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 19:08:52.227805: lr: 0.008456\n",
      "2021-10-29 19:08:52.269717: saving checkpoint...\n",
      "2021-10-29 19:08:53.009642: done, saving took 0.76 seconds\n",
      "2021-10-29 19:08:53.406528: This epoch took 192.487799 s\n",
      "\n",
      "2021-10-29 19:08:53.415082: \n",
      "epoch:  17\n",
      "2021-10-29 19:11:50.779214: train loss : -0.8601\n",
      "2021-10-29 19:12:04.190867: validation loss: -0.8255\n",
      "2021-10-29 19:12:04.195237: Average global foreground Dice: [0.8366]\n",
      "2021-10-29 19:12:04.202031: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 19:12:04.686477: lr: 0.008364\n",
      "2021-10-29 19:12:04.730034: saving checkpoint...\n",
      "2021-10-29 19:12:05.539632: done, saving took 0.83 seconds\n",
      "2021-10-29 19:12:05.971904: This epoch took 192.549395 s\n",
      "\n",
      "2021-10-29 19:12:05.980466: \n",
      "epoch:  18\n",
      "2021-10-29 19:15:03.362841: train loss : -0.8625\n",
      "2021-10-29 19:15:16.810654: validation loss: -0.8241\n",
      "2021-10-29 19:15:16.814984: Average global foreground Dice: [0.8349]\n",
      "2021-10-29 19:15:16.822120: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 19:15:17.309972: lr: 0.008272\n",
      "2021-10-29 19:15:17.347667: saving checkpoint...\n",
      "2021-10-29 19:15:18.096683: done, saving took 0.77 seconds\n",
      "2021-10-29 19:15:18.498020: This epoch took 192.511027 s\n",
      "\n",
      "2021-10-29 19:15:18.506606: \n",
      "epoch:  19\n",
      "2021-10-29 19:18:15.895947: train loss : -0.8640\n",
      "2021-10-29 19:18:29.306071: validation loss: -0.8297\n",
      "2021-10-29 19:18:29.310074: Average global foreground Dice: [0.8415]\n",
      "2021-10-29 19:18:29.317371: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 19:18:29.801710: lr: 0.008181\n",
      "2021-10-29 19:18:29.847476: saving checkpoint...\n",
      "2021-10-29 19:18:30.585306: done, saving took 0.76 seconds\n",
      "2021-10-29 19:18:31.003054: This epoch took 192.488088 s\n",
      "\n",
      "2021-10-29 19:18:31.012210: \n",
      "epoch:  20\n",
      "2021-10-29 19:21:28.406296: train loss : -0.8658\n",
      "2021-10-29 19:21:41.826022: validation loss: -0.8295\n",
      "2021-10-29 19:21:41.829817: Average global foreground Dice: [0.8404]\n",
      "2021-10-29 19:21:41.836577: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 19:21:42.320543: lr: 0.008088\n",
      "2021-10-29 19:21:42.359200: saving checkpoint...\n",
      "2021-10-29 19:21:43.112141: done, saving took 0.77 seconds\n",
      "2021-10-29 19:21:43.515622: This epoch took 192.495944 s\n",
      "\n",
      "2021-10-29 19:21:43.523939: \n",
      "epoch:  21\n",
      "2021-10-29 19:24:40.934294: train loss : -0.8681\n",
      "2021-10-29 19:24:54.376970: validation loss: -0.8227\n",
      "2021-10-29 19:24:54.382770: Average global foreground Dice: [0.8349]\n",
      "2021-10-29 19:24:54.389816: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 19:24:54.920877: lr: 0.007996\n",
      "2021-10-29 19:24:54.959865: saving checkpoint...\n",
      "2021-10-29 19:24:55.708425: done, saving took 0.77 seconds\n",
      "2021-10-29 19:24:56.114748: This epoch took 192.584141 s\n",
      "\n",
      "2021-10-29 19:24:56.123686: \n",
      "epoch:  22\n",
      "2021-10-29 19:27:53.510782: train loss : -0.8679\n",
      "2021-10-29 19:28:06.948481: validation loss: -0.8252\n",
      "2021-10-29 19:28:06.952220: Average global foreground Dice: [0.837]\n",
      "2021-10-29 19:28:06.958824: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 19:28:07.485021: lr: 0.007904\n",
      "2021-10-29 19:28:07.527261: saving checkpoint...\n",
      "2021-10-29 19:28:08.196632: done, saving took 0.69 seconds\n",
      "2021-10-29 19:28:08.596953: This epoch took 192.465834 s\n",
      "\n",
      "2021-10-29 19:28:08.605641: \n",
      "epoch:  23\n",
      "2021-10-29 19:31:05.980982: train loss : -0.8683\n",
      "2021-10-29 19:31:19.426279: validation loss: -0.8295\n",
      "2021-10-29 19:31:19.430118: Average global foreground Dice: [0.8411]\n",
      "2021-10-29 19:31:19.437477: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 19:31:19.987949: lr: 0.007811\n",
      "2021-10-29 19:31:20.032265: saving checkpoint...\n",
      "2021-10-29 19:31:20.784454: done, saving took 0.77 seconds\n",
      "2021-10-29 19:31:21.186116: This epoch took 192.573642 s\n",
      "\n",
      "2021-10-29 19:31:21.194906: \n",
      "epoch:  24\n",
      "2021-10-29 19:34:18.612726: train loss : -0.8716\n",
      "2021-10-29 19:34:32.039024: validation loss: -0.8285\n",
      "2021-10-29 19:34:32.042936: Average global foreground Dice: [0.8388]\n",
      "2021-10-29 19:34:32.050553: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 19:34:32.538382: lr: 0.007719\n",
      "2021-10-29 19:34:32.578674: saving checkpoint...\n",
      "2021-10-29 19:34:33.322226: done, saving took 0.76 seconds\n",
      "2021-10-29 19:34:33.722046: This epoch took 192.519653 s\n",
      "\n",
      "2021-10-29 19:34:33.730678: \n",
      "epoch:  25\n",
      "2021-10-29 19:37:31.217050: train loss : -0.8715\n",
      "2021-10-29 19:37:44.657338: validation loss: -0.8238\n",
      "2021-10-29 19:37:44.661763: Average global foreground Dice: [0.8343]\n",
      "2021-10-29 19:37:44.668630: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 19:37:45.152250: lr: 0.007626\n",
      "2021-10-29 19:37:45.188485: saving checkpoint...\n",
      "2021-10-29 19:37:45.937826: done, saving took 0.77 seconds\n",
      "2021-10-29 19:37:46.353274: This epoch took 192.614943 s\n",
      "\n",
      "2021-10-29 19:37:46.364685: \n",
      "epoch:  26\n",
      "2021-10-29 19:40:43.793518: train loss : -0.8728\n",
      "2021-10-29 19:40:57.256448: validation loss: -0.8251\n",
      "2021-10-29 19:40:57.261751: Average global foreground Dice: [0.8361]\n",
      "2021-10-29 19:40:57.269962: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 19:40:57.752096: lr: 0.007533\n",
      "2021-10-29 19:40:57.788089: saving checkpoint...\n",
      "2021-10-29 19:40:58.456591: done, saving took 0.69 seconds\n",
      "2021-10-29 19:40:58.862952: This epoch took 192.490792 s\n",
      "\n",
      "2021-10-29 19:40:58.872840: \n",
      "epoch:  27\n",
      "2021-10-29 19:43:56.352336: train loss : -0.8736\n",
      "2021-10-29 19:44:09.769706: validation loss: -0.8270\n",
      "2021-10-29 19:44:09.773325: Average global foreground Dice: [0.839]\n",
      "2021-10-29 19:44:09.780519: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 19:44:10.264605: lr: 0.00744\n",
      "2021-10-29 19:44:10.305168: saving checkpoint...\n",
      "2021-10-29 19:44:11.050077: done, saving took 0.76 seconds\n",
      "2021-10-29 19:44:11.500879: This epoch took 192.620876 s\n",
      "\n",
      "2021-10-29 19:44:11.510563: \n",
      "epoch:  28\n",
      "2021-10-29 19:47:08.993485: train loss : -0.8748\n",
      "2021-10-29 19:47:22.430780: validation loss: -0.8222\n",
      "2021-10-29 19:47:22.434704: Average global foreground Dice: [0.8328]\n",
      "2021-10-29 19:47:22.441876: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 19:47:23.037455: lr: 0.007347\n",
      "2021-10-29 19:47:23.077336: saving checkpoint...\n",
      "2021-10-29 19:47:23.828430: done, saving took 0.77 seconds\n",
      "2021-10-29 19:47:24.251292: This epoch took 192.732971 s\n",
      "\n",
      "2021-10-29 19:47:24.260034: \n",
      "epoch:  29\n",
      "2021-10-29 19:50:21.705209: train loss : -0.8769\n",
      "2021-10-29 19:50:35.133734: validation loss: -0.8217\n",
      "2021-10-29 19:50:35.136991: Average global foreground Dice: [0.8328]\n",
      "2021-10-29 19:50:35.143528: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 19:50:35.628873: lr: 0.007254\n",
      "2021-10-29 19:50:35.667276: saving checkpoint...\n",
      "2021-10-29 19:50:36.416478: done, saving took 0.77 seconds\n",
      "2021-10-29 19:50:36.811044: This epoch took 192.543886 s\n",
      "\n",
      "2021-10-29 19:50:36.819877: \n",
      "epoch:  30\n",
      "2021-10-29 19:53:34.264858: train loss : -0.8766\n",
      "2021-10-29 19:53:47.692634: validation loss: -0.8238\n",
      "2021-10-29 19:53:47.697002: Average global foreground Dice: [0.8348]\n",
      "2021-10-29 19:53:47.704432: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 19:53:48.188714: lr: 0.007161\n",
      "2021-10-29 19:53:48.222448: saving checkpoint...\n",
      "2021-10-29 19:53:48.964777: done, saving took 0.76 seconds\n",
      "2021-10-29 19:53:49.425574: This epoch took 192.598662 s\n",
      "\n",
      "2021-10-29 19:53:49.433996: \n",
      "epoch:  31\n",
      "2021-10-29 19:56:46.870098: train loss : -0.8771\n",
      "2021-10-29 19:57:00.324904: validation loss: -0.8295\n",
      "2021-10-29 19:57:00.329305: Average global foreground Dice: [0.8404]\n",
      "2021-10-29 19:57:00.336316: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 19:57:00.820792: lr: 0.007067\n",
      "2021-10-29 19:57:00.863333: saving checkpoint...\n",
      "2021-10-29 19:57:01.528617: done, saving took 0.68 seconds\n",
      "2021-10-29 19:57:01.972397: This epoch took 192.530697 s\n",
      "\n",
      "2021-10-29 19:57:01.982149: \n",
      "epoch:  32\n",
      "2021-10-29 19:59:59.636721: train loss : -0.8776\n",
      "2021-10-29 20:00:13.094287: validation loss: -0.8221\n",
      "2021-10-29 20:00:13.097988: Average global foreground Dice: [0.833]\n",
      "2021-10-29 20:00:13.104829: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:00:13.593108: lr: 0.006974\n",
      "2021-10-29 20:00:13.629533: saving checkpoint...\n",
      "2021-10-29 20:00:14.373107: done, saving took 0.76 seconds\n",
      "2021-10-29 20:00:14.784719: This epoch took 192.795369 s\n",
      "\n",
      "2021-10-29 20:00:14.793153: \n",
      "epoch:  33\n",
      "2021-10-29 20:03:12.508187: train loss : -0.8788\n",
      "2021-10-29 20:03:25.956316: validation loss: -0.8279\n",
      "2021-10-29 20:03:25.960176: Average global foreground Dice: [0.8387]\n",
      "2021-10-29 20:03:25.967160: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:03:26.516891: lr: 0.00688\n",
      "2021-10-29 20:03:26.558872: saving checkpoint...\n",
      "2021-10-29 20:03:27.297638: done, saving took 0.76 seconds\n",
      "2021-10-29 20:03:27.746944: This epoch took 192.946831 s\n",
      "\n",
      "2021-10-29 20:03:27.755042: \n",
      "epoch:  34\n",
      "2021-10-29 20:06:25.338611: train loss : -0.8804\n",
      "2021-10-29 20:06:38.818330: validation loss: -0.8231\n",
      "2021-10-29 20:06:38.822573: Average global foreground Dice: [0.8335]\n",
      "2021-10-29 20:06:38.832961: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:06:39.334142: lr: 0.006786\n",
      "2021-10-29 20:06:39.371900: saving checkpoint...\n",
      "2021-10-29 20:06:40.137820: done, saving took 0.78 seconds\n",
      "2021-10-29 20:06:40.562475: This epoch took 192.799892 s\n",
      "\n",
      "2021-10-29 20:06:40.572448: \n",
      "epoch:  35\n",
      "2021-10-29 20:09:38.223778: train loss : -0.8812\n",
      "2021-10-29 20:09:51.649412: validation loss: -0.8297\n",
      "2021-10-29 20:09:51.653173: Average global foreground Dice: [0.84]\n",
      "2021-10-29 20:09:51.659384: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:09:52.144113: lr: 0.006692\n",
      "2021-10-29 20:09:52.184337: saving checkpoint...\n",
      "2021-10-29 20:09:52.928482: done, saving took 0.76 seconds\n",
      "2021-10-29 20:09:53.351407: This epoch took 192.769873 s\n",
      "\n",
      "2021-10-29 20:09:53.360707: \n",
      "epoch:  36\n",
      "2021-10-29 20:12:51.071265: train loss : -0.8830\n",
      "2021-10-29 20:13:04.493848: validation loss: -0.8242\n",
      "2021-10-29 20:13:04.498003: Average global foreground Dice: [0.8362]\n",
      "2021-10-29 20:13:04.505825: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:13:04.992446: lr: 0.006598\n",
      "2021-10-29 20:13:05.031457: saving checkpoint...\n",
      "2021-10-29 20:13:05.702666: done, saving took 0.69 seconds\n",
      "2021-10-29 20:13:06.129504: This epoch took 192.760701 s\n",
      "\n",
      "2021-10-29 20:13:06.139192: \n",
      "epoch:  37\n",
      "2021-10-29 20:16:03.796194: train loss : -0.8846\n",
      "2021-10-29 20:16:17.237889: validation loss: -0.8256\n",
      "2021-10-29 20:16:17.241514: Average global foreground Dice: [0.8345]\n",
      "2021-10-29 20:16:17.248781: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:16:17.737227: lr: 0.006504\n",
      "2021-10-29 20:16:17.781028: saving checkpoint...\n",
      "2021-10-29 20:16:18.536161: done, saving took 0.77 seconds\n",
      "2021-10-29 20:16:18.947650: This epoch took 192.800778 s\n",
      "\n",
      "2021-10-29 20:16:18.956277: \n",
      "epoch:  38\n",
      "2021-10-29 20:19:16.585717: train loss : -0.8851\n",
      "2021-10-29 20:19:30.020894: validation loss: -0.8262\n",
      "2021-10-29 20:19:30.024429: Average global foreground Dice: [0.8373]\n",
      "2021-10-29 20:19:30.030930: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:19:30.574896: lr: 0.006409\n",
      "2021-10-29 20:19:30.616124: saving checkpoint...\n",
      "2021-10-29 20:19:31.366597: done, saving took 0.77 seconds\n",
      "2021-10-29 20:19:31.769499: This epoch took 192.805589 s\n",
      "\n",
      "2021-10-29 20:19:31.778530: \n",
      "epoch:  39\n",
      "2021-10-29 20:22:29.466860: train loss : -0.8844\n",
      "2021-10-29 20:22:42.955875: validation loss: -0.8248\n",
      "2021-10-29 20:22:42.960083: Average global foreground Dice: [0.8351]\n",
      "2021-10-29 20:22:42.967709: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:22:43.459996: lr: 0.006314\n",
      "2021-10-29 20:22:43.499765: saving checkpoint...\n",
      "2021-10-29 20:22:44.252205: done, saving took 0.77 seconds\n",
      "2021-10-29 20:22:44.673445: This epoch took 192.887285 s\n",
      "\n",
      "2021-10-29 20:22:44.682471: \n",
      "epoch:  40\n",
      "2021-10-29 20:25:42.787399: train loss : -0.8853\n",
      "2021-10-29 20:25:56.228176: validation loss: -0.8226\n",
      "2021-10-29 20:25:56.231989: Average global foreground Dice: [0.8339]\n",
      "2021-10-29 20:25:56.239174: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:25:56.723271: lr: 0.00622\n",
      "2021-10-29 20:25:56.759751: saving checkpoint...\n",
      "2021-10-29 20:25:57.502374: done, saving took 0.76 seconds\n",
      "2021-10-29 20:25:57.967442: This epoch took 193.277260 s\n",
      "\n",
      "2021-10-29 20:25:57.975665: \n",
      "epoch:  41\n",
      "2021-10-29 20:28:56.074190: train loss : -0.8852\n",
      "2021-10-29 20:29:09.522295: validation loss: -0.8215\n",
      "2021-10-29 20:29:09.527440: Average global foreground Dice: [0.8324]\n",
      "2021-10-29 20:29:09.534219: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:29:10.011028: lr: 0.006125\n",
      "2021-10-29 20:29:10.031708: This epoch took 192.048113 s\n",
      "\n",
      "2021-10-29 20:29:10.039090: \n",
      "epoch:  42\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-29 20:32:07.774739: train loss : -0.8863\n",
      "2021-10-29 20:32:21.231858: validation loss: -0.8232\n",
      "2021-10-29 20:32:21.235795: Average global foreground Dice: [0.8343]\n",
      "2021-10-29 20:32:21.242346: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:32:21.724559: lr: 0.00603\n",
      "2021-10-29 20:32:21.749031: This epoch took 191.703049 s\n",
      "\n",
      "2021-10-29 20:32:21.758434: \n",
      "epoch:  43\n",
      "2021-10-29 20:35:19.409071: train loss : -0.8880\n",
      "2021-10-29 20:35:32.869415: validation loss: -0.8223\n",
      "2021-10-29 20:35:32.873367: Average global foreground Dice: [0.8329]\n",
      "2021-10-29 20:35:32.881874: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:35:33.433061: lr: 0.005934\n",
      "2021-10-29 20:35:33.452735: This epoch took 191.685844 s\n",
      "\n",
      "2021-10-29 20:35:33.460299: \n",
      "epoch:  44\n",
      "2021-10-29 20:38:31.153633: train loss : -0.8883\n",
      "2021-10-29 20:38:44.594492: validation loss: -0.8281\n",
      "2021-10-29 20:38:44.599067: Average global foreground Dice: [0.8393]\n",
      "2021-10-29 20:38:44.605919: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:38:45.086068: lr: 0.005839\n",
      "2021-10-29 20:38:45.125786: saving checkpoint...\n",
      "2021-10-29 20:38:45.884678: done, saving took 0.78 seconds\n",
      "2021-10-29 20:38:46.278235: This epoch took 192.809881 s\n",
      "\n",
      "2021-10-29 20:38:46.287284: \n",
      "epoch:  45\n",
      "2021-10-29 20:41:44.058986: train loss : -0.8893\n",
      "2021-10-29 20:41:57.502178: validation loss: -0.8286\n",
      "2021-10-29 20:41:57.506020: Average global foreground Dice: [0.8386]\n",
      "2021-10-29 20:41:57.511746: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:41:57.994000: lr: 0.005743\n",
      "2021-10-29 20:41:58.031971: saving checkpoint...\n",
      "2021-10-29 20:41:58.785117: done, saving took 0.77 seconds\n",
      "2021-10-29 20:41:59.183545: This epoch took 192.888501 s\n",
      "\n",
      "2021-10-29 20:41:59.191553: \n",
      "epoch:  46\n",
      "2021-10-29 20:44:56.934066: train loss : -0.8904\n",
      "2021-10-29 20:45:10.380377: validation loss: -0.8201\n",
      "2021-10-29 20:45:10.384918: Average global foreground Dice: [0.8326]\n",
      "2021-10-29 20:45:10.391898: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:45:10.873766: lr: 0.005647\n",
      "2021-10-29 20:45:10.895194: This epoch took 191.696016 s\n",
      "\n",
      "2021-10-29 20:45:10.901326: \n",
      "epoch:  47\n",
      "2021-10-29 20:48:08.694293: train loss : -0.8898\n",
      "2021-10-29 20:48:22.145249: validation loss: -0.8262\n",
      "2021-10-29 20:48:22.149285: Average global foreground Dice: [0.837]\n",
      "2021-10-29 20:48:22.156505: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:48:22.639985: lr: 0.005551\n",
      "2021-10-29 20:48:22.680634: saving checkpoint...\n",
      "2021-10-29 20:48:23.433263: done, saving took 0.77 seconds\n",
      "2021-10-29 20:48:23.908345: This epoch took 193.000413 s\n",
      "\n",
      "2021-10-29 20:48:23.916761: \n",
      "epoch:  48\n",
      "2021-10-29 20:51:21.576190: train loss : -0.8904\n",
      "2021-10-29 20:51:34.990582: validation loss: -0.8251\n",
      "2021-10-29 20:51:34.994548: Average global foreground Dice: [0.8362]\n",
      "2021-10-29 20:51:35.000940: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:51:35.549721: lr: 0.005455\n",
      "2021-10-29 20:51:35.590921: saving checkpoint...\n",
      "2021-10-29 20:51:36.317116: done, saving took 0.74 seconds\n",
      "2021-10-29 20:51:36.733418: This epoch took 192.808400 s\n",
      "\n",
      "2021-10-29 20:51:36.741665: \n",
      "epoch:  49\n",
      "2021-10-29 20:54:34.398867: train loss : -0.8911\n",
      "2021-10-29 20:54:47.881905: validation loss: -0.8268\n",
      "2021-10-29 20:54:47.886094: Average global foreground Dice: [0.8373]\n",
      "2021-10-29 20:54:47.893978: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:54:48.383618: lr: 0.005359\n",
      "2021-10-29 20:54:48.402711: saving scheduled checkpoint file...\n",
      "2021-10-29 20:54:48.428705: saving checkpoint...\n",
      "2021-10-29 20:54:49.023259: done, saving took 0.61 seconds\n",
      "2021-10-29 20:54:49.456155: done\n",
      "2021-10-29 20:54:49.484099: saving checkpoint...\n",
      "2021-10-29 20:54:50.235298: done, saving took 0.77 seconds\n",
      "2021-10-29 20:54:50.679052: This epoch took 193.931570 s\n",
      "\n",
      "2021-10-29 20:54:50.687508: \n",
      "epoch:  50\n",
      "2021-10-29 20:57:48.436585: train loss : -0.8910\n",
      "2021-10-29 20:58:01.866884: validation loss: -0.8256\n",
      "2021-10-29 20:58:01.870882: Average global foreground Dice: [0.8364]\n",
      "2021-10-29 20:58:01.877970: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 20:58:02.362077: lr: 0.005262\n",
      "2021-10-29 20:58:02.400484: saving checkpoint...\n",
      "2021-10-29 20:58:03.066629: done, saving took 0.68 seconds\n",
      "2021-10-29 20:58:03.506248: This epoch took 192.810845 s\n",
      "\n",
      "2021-10-29 20:58:03.514414: \n",
      "epoch:  51\n",
      "2021-10-29 21:01:01.360610: train loss : -0.8928\n",
      "2021-10-29 21:01:14.810568: validation loss: -0.8244\n",
      "2021-10-29 21:01:14.814313: Average global foreground Dice: [0.8348]\n",
      "2021-10-29 21:01:14.819933: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:01:15.302009: lr: 0.005166\n",
      "2021-10-29 21:01:15.322516: This epoch took 191.800065 s\n",
      "\n",
      "2021-10-29 21:01:15.329332: \n",
      "epoch:  52\n",
      "2021-10-29 21:04:13.146807: train loss : -0.8928\n",
      "2021-10-29 21:04:26.587786: validation loss: -0.8251\n",
      "2021-10-29 21:04:26.591735: Average global foreground Dice: [0.8348]\n",
      "2021-10-29 21:04:26.599156: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:04:27.080577: lr: 0.005069\n",
      "2021-10-29 21:04:27.101402: This epoch took 191.764118 s\n",
      "\n",
      "2021-10-29 21:04:27.108519: \n",
      "epoch:  53\n",
      "2021-10-29 21:07:24.719944: train loss : -0.8934\n",
      "2021-10-29 21:07:38.160289: validation loss: -0.8227\n",
      "2021-10-29 21:07:38.163983: Average global foreground Dice: [0.8336]\n",
      "2021-10-29 21:07:38.170982: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:07:38.773172: lr: 0.004971\n",
      "2021-10-29 21:07:38.798701: This epoch took 191.683646 s\n",
      "\n",
      "2021-10-29 21:07:38.806759: \n",
      "epoch:  54\n",
      "2021-10-29 21:10:36.645179: train loss : -0.8941\n",
      "2021-10-29 21:10:50.093948: validation loss: -0.8223\n",
      "2021-10-29 21:10:50.097813: Average global foreground Dice: [0.8332]\n",
      "2021-10-29 21:10:50.106107: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:10:50.592418: lr: 0.004874\n",
      "2021-10-29 21:10:50.611278: This epoch took 191.796792 s\n",
      "\n",
      "2021-10-29 21:10:50.618642: \n",
      "epoch:  55\n",
      "2021-10-29 21:13:48.468801: train loss : -0.8942\n",
      "2021-10-29 21:14:01.918407: validation loss: -0.8260\n",
      "2021-10-29 21:14:01.922571: Average global foreground Dice: [0.8365]\n",
      "2021-10-29 21:14:01.930627: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:14:02.424519: lr: 0.004776\n",
      "2021-10-29 21:14:02.442549: This epoch took 191.816335 s\n",
      "\n",
      "2021-10-29 21:14:02.449680: \n",
      "epoch:  56\n",
      "2021-10-29 21:17:00.158320: train loss : -0.8954\n",
      "2021-10-29 21:17:13.588210: validation loss: -0.8264\n",
      "2021-10-29 21:17:13.592599: Average global foreground Dice: [0.837]\n",
      "2021-10-29 21:17:13.599344: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:17:14.081646: lr: 0.004679\n",
      "2021-10-29 21:17:14.100778: This epoch took 191.644016 s\n",
      "\n",
      "2021-10-29 21:17:14.106845: \n",
      "epoch:  57\n",
      "2021-10-29 21:20:11.911750: train loss : -0.8958\n",
      "2021-10-29 21:20:25.353925: validation loss: -0.8235\n",
      "2021-10-29 21:20:25.358167: Average global foreground Dice: [0.8344]\n",
      "2021-10-29 21:20:25.364428: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:20:25.845539: lr: 0.004581\n",
      "2021-10-29 21:20:25.864839: This epoch took 191.751174 s\n",
      "\n",
      "2021-10-29 21:20:25.872369: \n",
      "epoch:  58\n",
      "2021-10-29 21:23:23.934440: train loss : -0.8968\n",
      "2021-10-29 21:23:37.379711: validation loss: -0.8242\n",
      "2021-10-29 21:23:37.385308: Average global foreground Dice: [0.8351]\n",
      "2021-10-29 21:23:37.392587: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:23:37.926897: lr: 0.004482\n",
      "2021-10-29 21:23:37.948704: This epoch took 192.070184 s\n",
      "\n",
      "2021-10-29 21:23:37.956608: \n",
      "epoch:  59\n",
      "2021-10-29 21:26:35.705253: train loss : -0.8974\n",
      "2021-10-29 21:26:49.140376: validation loss: -0.8248\n",
      "2021-10-29 21:26:49.143966: Average global foreground Dice: [0.8349]\n",
      "2021-10-29 21:26:49.150589: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:26:49.629320: lr: 0.004384\n",
      "2021-10-29 21:26:49.647559: This epoch took 191.682833 s\n",
      "\n",
      "2021-10-29 21:26:49.654200: \n",
      "epoch:  60\n",
      "2021-10-29 21:29:47.509410: train loss : -0.8969\n",
      "2021-10-29 21:30:00.953579: validation loss: -0.8195\n",
      "2021-10-29 21:30:00.957341: Average global foreground Dice: [0.8306]\n",
      "2021-10-29 21:30:00.964113: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:30:01.447701: lr: 0.004285\n",
      "2021-10-29 21:30:01.466955: This epoch took 191.807056 s\n",
      "\n",
      "2021-10-29 21:30:01.474098: \n",
      "epoch:  61\n",
      "2021-10-29 21:32:59.348185: train loss : -0.8964\n",
      "2021-10-29 21:33:12.797096: validation loss: -0.8252\n",
      "2021-10-29 21:33:12.800978: Average global foreground Dice: [0.835]\n",
      "2021-10-29 21:33:12.807559: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:33:13.290653: lr: 0.004186\n",
      "2021-10-29 21:33:13.309827: This epoch took 191.830314 s\n",
      "\n",
      "2021-10-29 21:33:13.317377: \n",
      "epoch:  62\n",
      "2021-10-29 21:36:10.988137: train loss : -0.8988\n",
      "2021-10-29 21:36:24.443681: validation loss: -0.8243\n",
      "2021-10-29 21:36:24.447675: Average global foreground Dice: [0.8356]\n",
      "2021-10-29 21:36:24.454123: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:36:24.965501: lr: 0.004087\n",
      "2021-10-29 21:36:24.985138: This epoch took 191.661484 s\n",
      "\n",
      "2021-10-29 21:36:24.992832: \n",
      "epoch:  63\n",
      "2021-10-29 21:39:22.741625: train loss : -0.8981\n",
      "2021-10-29 21:39:36.219439: validation loss: -0.8231\n",
      "2021-10-29 21:39:36.222984: Average global foreground Dice: [0.835]\n",
      "2021-10-29 21:39:36.232342: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:39:36.714954: lr: 0.003987\n",
      "2021-10-29 21:39:36.735248: This epoch took 191.734630 s\n",
      "\n",
      "2021-10-29 21:39:36.742850: \n",
      "epoch:  64\n",
      "2021-10-29 21:42:34.461872: train loss : -0.8991\n",
      "2021-10-29 21:42:47.911451: validation loss: -0.8202\n",
      "2021-10-29 21:42:47.915509: Average global foreground Dice: [0.8309]\n",
      "2021-10-29 21:42:47.922457: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:42:48.471891: lr: 0.003887\n",
      "2021-10-29 21:42:48.491493: This epoch took 191.741354 s\n",
      "\n",
      "2021-10-29 21:42:48.502524: \n",
      "epoch:  65\n",
      "2021-10-29 21:45:46.254998: train loss : -0.9014\n",
      "2021-10-29 21:45:59.705265: validation loss: -0.8247\n",
      "2021-10-29 21:45:59.709014: Average global foreground Dice: [0.8351]\n",
      "2021-10-29 21:45:59.715313: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:46:00.199179: lr: 0.003787\n",
      "2021-10-29 21:46:00.217981: This epoch took 191.708036 s\n",
      "\n",
      "2021-10-29 21:46:00.223730: \n",
      "epoch:  66\n",
      "2021-10-29 21:48:57.934747: train loss : -0.8996\n",
      "2021-10-29 21:49:11.371500: validation loss: -0.8209\n",
      "2021-10-29 21:49:11.375238: Average global foreground Dice: [0.8312]\n",
      "2021-10-29 21:49:11.382411: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:49:11.864825: lr: 0.003687\n",
      "2021-10-29 21:49:11.885689: This epoch took 191.654649 s\n",
      "\n",
      "2021-10-29 21:49:11.892633: \n",
      "epoch:  67\n",
      "2021-10-29 21:52:09.699750: train loss : -0.9014\n",
      "2021-10-29 21:52:23.148276: validation loss: -0.8254\n",
      "2021-10-29 21:52:23.152306: Average global foreground Dice: [0.8354]\n",
      "2021-10-29 21:52:23.157965: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:52:23.642250: lr: 0.003586\n",
      "2021-10-29 21:52:23.662163: This epoch took 191.762957 s\n",
      "\n",
      "2021-10-29 21:52:23.669143: \n",
      "epoch:  68\n",
      "2021-10-29 21:55:21.489984: train loss : -0.9017\n",
      "2021-10-29 21:55:34.927974: validation loss: -0.8233\n",
      "2021-10-29 21:55:34.935991: Average global foreground Dice: [0.8351]\n",
      "2021-10-29 21:55:34.943292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:55:35.431797: lr: 0.003485\n",
      "2021-10-29 21:55:35.451219: This epoch took 191.776142 s\n",
      "\n",
      "2021-10-29 21:55:35.456463: \n",
      "epoch:  69\n",
      "2021-10-29 21:58:33.305878: train loss : -0.9023\n",
      "2021-10-29 21:58:46.748083: validation loss: -0.8209\n",
      "2021-10-29 21:58:46.752465: Average global foreground Dice: [0.8314]\n",
      "2021-10-29 21:58:46.758109: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 21:58:47.309100: lr: 0.003384\n",
      "2021-10-29 21:58:47.327481: This epoch took 191.864145 s\n",
      "\n",
      "2021-10-29 21:58:47.335089: \n",
      "epoch:  70\n",
      "2021-10-29 22:01:45.107278: train loss : -0.9026\n",
      "2021-10-29 22:01:58.553351: validation loss: -0.8213\n",
      "2021-10-29 22:01:58.557106: Average global foreground Dice: [0.8327]\n",
      "2021-10-29 22:01:58.565319: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:01:59.050016: lr: 0.003282\n",
      "2021-10-29 22:01:59.072672: This epoch took 191.729371 s\n",
      "\n",
      "2021-10-29 22:01:59.079972: \n",
      "epoch:  71\n",
      "2021-10-29 22:04:56.843382: train loss : -0.9034\n",
      "2021-10-29 22:05:10.277015: validation loss: -0.8239\n",
      "2021-10-29 22:05:10.281298: Average global foreground Dice: [0.8349]\n",
      "2021-10-29 22:05:10.289971: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:05:10.778119: lr: 0.00318\n",
      "2021-10-29 22:05:10.799423: This epoch took 191.712339 s\n",
      "\n",
      "2021-10-29 22:05:10.806362: \n",
      "epoch:  72\n",
      "2021-10-29 22:08:08.647207: train loss : -0.9042\n",
      "2021-10-29 22:08:22.099235: validation loss: -0.8226\n",
      "2021-10-29 22:08:22.103060: Average global foreground Dice: [0.833]\n",
      "2021-10-29 22:08:22.109559: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:08:22.594357: lr: 0.003078\n",
      "2021-10-29 22:08:22.616721: This epoch took 191.803991 s\n",
      "\n",
      "2021-10-29 22:08:22.624274: \n",
      "epoch:  73\n",
      "2021-10-29 22:11:20.556896: train loss : -0.9045\n",
      "2021-10-29 22:11:34.009617: validation loss: -0.8204\n",
      "2021-10-29 22:11:34.013152: Average global foreground Dice: [0.8312]\n",
      "2021-10-29 22:11:34.019216: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:11:34.505753: lr: 0.002975\n",
      "2021-10-29 22:11:34.525612: This epoch took 191.894301 s\n",
      "\n",
      "2021-10-29 22:11:34.532000: \n",
      "epoch:  74\n",
      "2021-10-29 22:14:32.301317: train loss : -0.9045\n",
      "2021-10-29 22:14:45.755447: validation loss: -0.8209\n",
      "2021-10-29 22:14:45.760445: Average global foreground Dice: [0.8319]\n",
      "2021-10-29 22:14:45.767459: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:14:46.318465: lr: 0.002872\n",
      "2021-10-29 22:14:46.340673: This epoch took 191.801413 s\n",
      "\n",
      "2021-10-29 22:14:46.348297: \n",
      "epoch:  75\n",
      "2021-10-29 22:17:44.202970: train loss : -0.9055\n",
      "2021-10-29 22:17:57.628360: validation loss: -0.8214\n",
      "2021-10-29 22:17:57.631985: Average global foreground Dice: [0.8321]\n",
      "2021-10-29 22:17:57.638656: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:17:58.125220: lr: 0.002768\n",
      "2021-10-29 22:17:58.143590: This epoch took 191.785506 s\n",
      "\n",
      "2021-10-29 22:17:58.150661: \n",
      "epoch:  76\n",
      "2021-10-29 22:20:55.918522: train loss : -0.9057\n",
      "2021-10-29 22:21:09.368092: validation loss: -0.8159\n",
      "2021-10-29 22:21:09.372240: Average global foreground Dice: [0.8275]\n",
      "2021-10-29 22:21:09.379392: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:21:09.865420: lr: 0.002664\n",
      "2021-10-29 22:21:09.884868: This epoch took 191.726827 s\n",
      "\n",
      "2021-10-29 22:21:09.891269: \n",
      "epoch:  77\n",
      "2021-10-29 22:24:07.651016: train loss : -0.9067\n",
      "2021-10-29 22:24:21.114253: validation loss: -0.8226\n",
      "2021-10-29 22:24:21.118413: Average global foreground Dice: [0.832]\n",
      "2021-10-29 22:24:21.125227: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:24:21.616210: lr: 0.00256\n",
      "2021-10-29 22:24:21.636856: This epoch took 191.738825 s\n",
      "\n",
      "2021-10-29 22:24:21.643860: \n",
      "epoch:  78\n",
      "2021-10-29 22:27:19.474101: train loss : -0.9065\n",
      "2021-10-29 22:27:32.898515: validation loss: -0.8217\n",
      "2021-10-29 22:27:32.902795: Average global foreground Dice: [0.8314]\n",
      "2021-10-29 22:27:32.909981: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:27:33.398664: lr: 0.002455\n",
      "2021-10-29 22:27:33.420063: This epoch took 191.768971 s\n",
      "\n",
      "2021-10-29 22:27:33.427833: \n",
      "epoch:  79\n",
      "2021-10-29 22:30:31.400880: train loss : -0.9077\n",
      "2021-10-29 22:30:44.845097: validation loss: -0.8244\n",
      "2021-10-29 22:30:44.848708: Average global foreground Dice: [0.8346]\n",
      "2021-10-29 22:30:44.855763: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:30:45.346304: lr: 0.002349\n",
      "2021-10-29 22:30:45.367162: This epoch took 191.931958 s\n",
      "\n",
      "2021-10-29 22:30:45.374153: \n",
      "epoch:  80\n",
      "2021-10-29 22:33:43.098733: train loss : -0.9080\n",
      "2021-10-29 22:33:56.559451: validation loss: -0.8217\n",
      "2021-10-29 22:33:56.563728: Average global foreground Dice: [0.8314]\n",
      "2021-10-29 22:33:56.570692: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:33:57.104881: lr: 0.002243\n",
      "2021-10-29 22:33:57.125715: This epoch took 191.744442 s\n",
      "\n",
      "2021-10-29 22:33:57.133369: \n",
      "epoch:  81\n",
      "2021-10-29 22:36:55.060757: train loss : -0.9089\n",
      "2021-10-29 22:37:08.523439: validation loss: -0.8191\n",
      "2021-10-29 22:37:08.527689: Average global foreground Dice: [0.8307]\n",
      "2021-10-29 22:37:08.534422: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:37:09.019147: lr: 0.002137\n",
      "2021-10-29 22:37:09.037550: This epoch took 191.896896 s\n",
      "\n",
      "2021-10-29 22:37:09.044952: \n",
      "epoch:  82\n",
      "2021-10-29 22:40:06.982554: train loss : -0.9089\n",
      "2021-10-29 22:40:20.437621: validation loss: -0.8234\n",
      "2021-10-29 22:40:20.441574: Average global foreground Dice: [0.8336]\n",
      "2021-10-29 22:40:20.448943: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:40:20.935554: lr: 0.00203\n",
      "2021-10-29 22:40:20.954635: This epoch took 191.903305 s\n",
      "\n",
      "2021-10-29 22:40:20.960952: \n",
      "epoch:  83\n",
      "2021-10-29 22:43:19.117902: train loss : -0.9103\n",
      "2021-10-29 22:43:32.577141: validation loss: -0.8240\n",
      "2021-10-29 22:43:32.581053: Average global foreground Dice: [0.8348]\n",
      "2021-10-29 22:43:32.588720: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:43:33.068579: lr: 0.001922\n",
      "2021-10-29 22:43:33.087024: This epoch took 192.119064 s\n",
      "\n",
      "2021-10-29 22:43:33.094362: \n",
      "epoch:  84\n",
      "2021-10-29 22:46:31.445600: train loss : -0.9095\n",
      "2021-10-29 22:46:44.901178: validation loss: -0.8193\n",
      "2021-10-29 22:46:44.905142: Average global foreground Dice: [0.829]\n",
      "2021-10-29 22:46:44.912436: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:46:45.394385: lr: 0.001813\n",
      "2021-10-29 22:46:45.413851: This epoch took 192.312334 s\n",
      "\n",
      "2021-10-29 22:46:45.421144: \n",
      "epoch:  85\n",
      "2021-10-29 22:49:43.689305: train loss : -0.9100\n",
      "2021-10-29 22:49:57.121628: validation loss: -0.8197\n",
      "2021-10-29 22:49:57.124961: Average global foreground Dice: [0.8291]\n",
      "2021-10-29 22:49:57.132139: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:49:57.693178: lr: 0.001704\n",
      "2021-10-29 22:49:57.712792: This epoch took 192.283780 s\n",
      "\n",
      "2021-10-29 22:49:57.719475: \n",
      "epoch:  86\n",
      "2021-10-29 22:52:55.688598: train loss : -0.9112\n",
      "2021-10-29 22:53:09.148436: validation loss: -0.8209\n",
      "2021-10-29 22:53:09.152498: Average global foreground Dice: [0.8312]\n",
      "2021-10-29 22:53:09.159376: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:53:09.640277: lr: 0.001594\n",
      "2021-10-29 22:53:09.655025: This epoch took 191.927897 s\n",
      "\n",
      "2021-10-29 22:53:09.661501: \n",
      "epoch:  87\n",
      "2021-10-29 22:56:07.636363: train loss : -0.9108\n",
      "2021-10-29 22:56:21.078011: validation loss: -0.8228\n",
      "2021-10-29 22:56:21.083626: Average global foreground Dice: [0.8327]\n",
      "2021-10-29 22:56:21.089757: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:56:21.572277: lr: 0.001483\n",
      "2021-10-29 22:56:21.592978: This epoch took 191.924465 s\n",
      "\n",
      "2021-10-29 22:56:21.599756: \n",
      "epoch:  88\n",
      "2021-10-29 22:59:19.421808: train loss : -0.9126\n",
      "2021-10-29 22:59:32.855854: validation loss: -0.8186\n",
      "2021-10-29 22:59:32.859681: Average global foreground Dice: [0.8284]\n",
      "2021-10-29 22:59:32.865963: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 22:59:33.348481: lr: 0.001372\n",
      "2021-10-29 22:59:33.370445: This epoch took 191.763333 s\n",
      "\n",
      "2021-10-29 22:59:33.378985: \n",
      "epoch:  89\n",
      "2021-10-29 23:02:31.263577: train loss : -0.9122\n",
      "2021-10-29 23:02:44.709353: validation loss: -0.8215\n",
      "2021-10-29 23:02:44.714609: Average global foreground Dice: [0.8305]\n",
      "2021-10-29 23:02:44.722125: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 23:02:45.206308: lr: 0.001259\n",
      "2021-10-29 23:02:45.229772: This epoch took 191.843635 s\n",
      "\n",
      "2021-10-29 23:02:45.237035: \n",
      "epoch:  90\n",
      "2021-10-29 23:05:43.088260: train loss : -0.9124\n",
      "2021-10-29 23:05:56.540207: validation loss: -0.8190\n",
      "2021-10-29 23:05:56.543836: Average global foreground Dice: [0.8285]\n",
      "2021-10-29 23:05:56.550378: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 23:05:57.032342: lr: 0.001145\n",
      "2021-10-29 23:05:57.052581: This epoch took 191.807832 s\n",
      "\n",
      "2021-10-29 23:05:57.060648: \n",
      "epoch:  91\n",
      "2021-10-29 23:08:54.928111: train loss : -0.9134\n",
      "2021-10-29 23:09:08.394026: validation loss: -0.8209\n",
      "2021-10-29 23:09:08.397749: Average global foreground Dice: [0.8303]\n",
      "2021-10-29 23:09:08.404675: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 23:09:08.888548: lr: 0.00103\n",
      "2021-10-29 23:09:08.905402: This epoch took 191.836858 s\n",
      "\n",
      "2021-10-29 23:09:08.912259: \n",
      "epoch:  92\n",
      "2021-10-29 23:12:06.558390: train loss : -0.9141\n",
      "2021-10-29 23:12:20.001236: validation loss: -0.8195\n",
      "2021-10-29 23:12:20.005263: Average global foreground Dice: [0.8299]\n",
      "2021-10-29 23:12:20.012116: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 23:12:20.497176: lr: 0.000913\n",
      "2021-10-29 23:12:20.515955: This epoch took 191.597149 s\n",
      "\n",
      "2021-10-29 23:12:20.521715: \n",
      "epoch:  93\n",
      "2021-10-29 23:15:18.371402: train loss : -0.9143\n",
      "2021-10-29 23:15:31.841585: validation loss: -0.8222\n",
      "2021-10-29 23:15:31.845744: Average global foreground Dice: [0.8322]\n",
      "2021-10-29 23:15:31.853337: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 23:15:32.338672: lr: 0.000795\n",
      "2021-10-29 23:15:32.354017: This epoch took 191.824975 s\n",
      "\n",
      "2021-10-29 23:15:32.361564: \n",
      "epoch:  94\n",
      "2021-10-29 23:18:30.452030: train loss : -0.9144\n",
      "2021-10-29 23:18:43.902315: validation loss: -0.8227\n",
      "2021-10-29 23:18:43.907267: Average global foreground Dice: [0.8327]\n",
      "2021-10-29 23:18:43.914499: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 23:18:44.397594: lr: 0.000675\n",
      "2021-10-29 23:18:44.421659: This epoch took 192.052450 s\n",
      "\n",
      "2021-10-29 23:18:44.428944: \n",
      "epoch:  95\n",
      "2021-10-29 23:21:42.233477: train loss : -0.9146\n",
      "2021-10-29 23:21:55.680682: validation loss: -0.8223\n",
      "2021-10-29 23:21:55.684622: Average global foreground Dice: [0.8336]\n",
      "2021-10-29 23:21:55.690322: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 23:21:56.172336: lr: 0.000552\n",
      "2021-10-29 23:21:56.191222: This epoch took 191.754152 s\n",
      "\n",
      "2021-10-29 23:21:56.198459: \n",
      "epoch:  96\n",
      "2021-10-29 23:24:54.010663: train loss : -0.9154\n",
      "2021-10-29 23:25:07.453672: validation loss: -0.8233\n",
      "2021-10-29 23:25:07.457828: Average global foreground Dice: [0.8343]\n",
      "2021-10-29 23:25:07.464833: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 23:25:08.013289: lr: 0.000426\n",
      "2021-10-29 23:25:08.036204: This epoch took 191.829911 s\n",
      "\n",
      "2021-10-29 23:25:08.044064: \n",
      "epoch:  97\n",
      "2021-10-29 23:28:05.852072: train loss : -0.9160\n",
      "2021-10-29 23:28:19.301360: validation loss: -0.8202\n",
      "2021-10-29 23:28:19.305709: Average global foreground Dice: [0.8307]\n",
      "2021-10-29 23:28:19.312564: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 23:28:19.798774: lr: 0.000296\n",
      "2021-10-29 23:28:19.815073: This epoch took 191.763227 s\n",
      "\n",
      "2021-10-29 23:28:19.822093: \n",
      "epoch:  98\n",
      "2021-10-29 23:31:17.569405: train loss : -0.9164\n",
      "2021-10-29 23:31:30.998317: validation loss: -0.8247\n",
      "2021-10-29 23:31:31.002271: Average global foreground Dice: [0.8347]\n",
      "2021-10-29 23:31:31.009379: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 23:31:31.493818: lr: 0.000158\n",
      "2021-10-29 23:31:31.516170: This epoch took 191.687115 s\n",
      "\n",
      "2021-10-29 23:31:31.522935: \n",
      "epoch:  99\n",
      "2021-10-29 23:34:29.377124: train loss : -0.9165\n",
      "2021-10-29 23:34:42.833663: validation loss: -0.8217\n",
      "2021-10-29 23:34:42.837582: Average global foreground Dice: [0.8317]\n",
      "2021-10-29 23:34:42.843493: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 23:34:43.325357: lr: 0.0\n",
      "2021-10-29 23:34:43.348945: saving scheduled checkpoint file...\n",
      "2021-10-29 23:34:43.373871: saving checkpoint...\n",
      "2021-10-29 23:34:44.130079: done, saving took 0.77 seconds\n",
      "2021-10-29 23:34:44.571038: done\n",
      "2021-10-29 23:34:44.580170: This epoch took 193.050009 s\n",
      "\n",
      "2021-10-29 23:34:44.606974: saving checkpoint...\n",
      "2021-10-29 23:34:45.185842: done, saving took 0.60 seconds\n",
      "23090566_20141114 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090571_20120517 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131226 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160308 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131025 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090596_20150112 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120619 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090608_20120718 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151210 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121213 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090616_20140331 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090619_20121210 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090629_20120830 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090636_20121018 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150522 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-29 23:36:40.560179: finished prediction\n",
      "2021-10-29 23:36:40.568286: evaluation of raw predictions\n",
      "2021-10-29 23:36:42.466337: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8207421877336428\n",
      "after:  0.8207311440912335\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-10-29 23:36:55.128879: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-10-29 23:36:55.150831: The split file contains 5 splits.\n",
      "2021-10-29 23:36:55.157127: Desired fold for training: 3\n",
      "2021-10-29 23:36:55.163905: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-29 23:36:59.253368: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-29 23:37:06.561353: Unable to plot network architecture:\n",
      "2021-10-29 23:37:06.564453: No module named 'hiddenlayer'\n",
      "2021-10-29 23:37:06.570287: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-29 23:37:06.576787: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-29 23:37:06.639250: \n",
      "\n",
      "2021-10-29 23:37:06.646949: \n",
      "epoch:  0\n",
      "2021-10-29 23:40:19.371966: train loss : -0.2797\n",
      "2021-10-29 23:40:32.614482: validation loss: -0.6705\n",
      "2021-10-29 23:40:32.618174: Average global foreground Dice: [0.7284]\n",
      "2021-10-29 23:40:32.624665: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 23:40:33.038768: lr: 0.00991\n",
      "2021-10-29 23:40:33.059298: This epoch took 206.406302 s\n",
      "\n",
      "2021-10-29 23:40:33.065434: \n",
      "epoch:  1\n",
      "2021-10-29 23:43:30.247102: train loss : -0.7099\n",
      "2021-10-29 23:43:43.622064: validation loss: -0.7806\n",
      "2021-10-29 23:43:43.626174: Average global foreground Dice: [0.8028]\n",
      "2021-10-29 23:43:43.632111: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 23:43:44.124781: lr: 0.00982\n",
      "2021-10-29 23:43:44.186959: saving checkpoint...\n",
      "2021-10-29 23:43:44.839509: done, saving took 0.69 seconds\n",
      "2021-10-29 23:43:45.243849: This epoch took 192.171540 s\n",
      "\n",
      "2021-10-29 23:43:45.252157: \n",
      "epoch:  2\n",
      "2021-10-29 23:46:42.276450: train loss : -0.7757\n",
      "2021-10-29 23:46:55.702164: validation loss: -0.8090\n",
      "2021-10-29 23:46:55.706166: Average global foreground Dice: [0.827]\n",
      "2021-10-29 23:46:55.713224: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 23:46:56.199036: lr: 0.00973\n",
      "2021-10-29 23:46:56.257801: saving checkpoint...\n",
      "2021-10-29 23:46:56.912812: done, saving took 0.70 seconds\n",
      "2021-10-29 23:46:57.287188: This epoch took 192.028507 s\n",
      "\n",
      "2021-10-29 23:46:57.296199: \n",
      "epoch:  3\n",
      "2021-10-29 23:49:54.320217: train loss : -0.7991\n",
      "2021-10-29 23:50:07.750469: validation loss: -0.8152\n",
      "2021-10-29 23:50:07.754267: Average global foreground Dice: [0.8305]\n",
      "2021-10-29 23:50:07.760813: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 23:50:08.247543: lr: 0.009639\n",
      "2021-10-29 23:50:08.300845: saving checkpoint...\n",
      "2021-10-29 23:50:09.050434: done, saving took 0.78 seconds\n",
      "2021-10-29 23:50:09.451252: This epoch took 192.148164 s\n",
      "\n",
      "2021-10-29 23:50:09.459803: \n",
      "epoch:  4\n",
      "2021-10-29 23:53:06.327018: train loss : -0.8115\n",
      "2021-10-29 23:53:19.725993: validation loss: -0.8241\n",
      "2021-10-29 23:53:19.729986: Average global foreground Dice: [0.8365]\n",
      "2021-10-29 23:53:19.737401: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 23:53:20.217839: lr: 0.009549\n",
      "2021-10-29 23:53:20.253553: saving checkpoint...\n",
      "2021-10-29 23:53:20.982589: done, saving took 0.75 seconds\n",
      "2021-10-29 23:53:21.391245: This epoch took 191.924308 s\n",
      "\n",
      "2021-10-29 23:53:21.399234: \n",
      "epoch:  5\n",
      "2021-10-29 23:56:18.323439: train loss : -0.8200\n",
      "2021-10-29 23:56:31.744241: validation loss: -0.8351\n",
      "2021-10-29 23:56:31.747960: Average global foreground Dice: [0.8461]\n",
      "2021-10-29 23:56:31.756407: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 23:56:32.228300: lr: 0.009458\n",
      "2021-10-29 23:56:32.277230: saving checkpoint...\n",
      "2021-10-29 23:56:33.015729: done, saving took 0.77 seconds\n",
      "2021-10-29 23:56:33.428770: This epoch took 192.022024 s\n",
      "\n",
      "2021-10-29 23:56:33.446999: \n",
      "epoch:  6\n",
      "2021-10-29 23:59:30.383704: train loss : -0.8262\n",
      "2021-10-29 23:59:43.786540: validation loss: -0.8359\n",
      "2021-10-29 23:59:43.790780: Average global foreground Dice: [0.8462]\n",
      "2021-10-29 23:59:43.797370: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-29 23:59:44.283268: lr: 0.009368\n",
      "2021-10-29 23:59:44.336170: saving checkpoint...\n",
      "2021-10-29 23:59:45.123429: done, saving took 0.82 seconds\n",
      "2021-10-29 23:59:45.545671: This epoch took 192.091763 s\n",
      "\n",
      "2021-10-29 23:59:45.554734: \n",
      "epoch:  7\n",
      "2021-10-30 00:02:42.415969: train loss : -0.8299\n",
      "2021-10-30 00:02:55.800129: validation loss: -0.8354\n",
      "2021-10-30 00:02:55.805703: Average global foreground Dice: [0.8459]\n",
      "2021-10-30 00:02:55.812956: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 00:02:56.296719: lr: 0.009277\n",
      "2021-10-30 00:02:56.329805: saving checkpoint...\n",
      "2021-10-30 00:02:57.048341: done, saving took 0.74 seconds\n",
      "2021-10-30 00:02:57.468033: This epoch took 191.905951 s\n",
      "\n",
      "2021-10-30 00:02:57.477335: \n",
      "epoch:  8\n",
      "2021-10-30 00:05:54.650773: train loss : -0.8352\n",
      "2021-10-30 00:06:08.043499: validation loss: -0.8372\n",
      "2021-10-30 00:06:08.047326: Average global foreground Dice: [0.8476]\n",
      "2021-10-30 00:06:08.054656: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 00:06:08.531849: lr: 0.009186\n",
      "2021-10-30 00:06:08.571342: saving checkpoint...\n",
      "2021-10-30 00:06:09.290398: done, saving took 0.74 seconds\n",
      "2021-10-30 00:06:09.669142: This epoch took 192.184237 s\n",
      "\n",
      "2021-10-30 00:06:09.677358: \n",
      "epoch:  9\n",
      "2021-10-30 00:09:06.954703: train loss : -0.8382\n",
      "2021-10-30 00:09:20.379124: validation loss: -0.8379\n",
      "2021-10-30 00:09:20.382738: Average global foreground Dice: [0.8471]\n",
      "2021-10-30 00:09:20.389333: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 00:09:20.865027: lr: 0.009095\n",
      "2021-10-30 00:09:20.902422: saving checkpoint...\n",
      "2021-10-30 00:09:21.629671: done, saving took 0.75 seconds\n",
      "2021-10-30 00:09:22.074528: This epoch took 192.391479 s\n",
      "\n",
      "2021-10-30 00:09:22.083126: \n",
      "epoch:  10\n",
      "2021-10-30 00:12:19.364870: train loss : -0.8420\n",
      "2021-10-30 00:12:32.806227: validation loss: -0.8374\n",
      "2021-10-30 00:12:32.810724: Average global foreground Dice: [0.8488]\n",
      "2021-10-30 00:12:32.817894: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 00:12:33.284807: lr: 0.009004\n",
      "2021-10-30 00:12:33.321279: saving checkpoint...\n",
      "2021-10-30 00:12:34.063689: done, saving took 0.76 seconds\n",
      "2021-10-30 00:12:34.474797: This epoch took 192.383515 s\n",
      "\n",
      "2021-10-30 00:12:34.484599: \n",
      "epoch:  11\n",
      "2021-10-30 00:15:31.792714: train loss : -0.8451\n",
      "2021-10-30 00:15:45.210598: validation loss: -0.8288\n",
      "2021-10-30 00:15:45.214454: Average global foreground Dice: [0.8408]\n",
      "2021-10-30 00:15:45.223186: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 00:15:45.695442: lr: 0.008913\n",
      "2021-10-30 00:15:45.736831: saving checkpoint...\n",
      "2021-10-30 00:15:46.461643: done, saving took 0.74 seconds\n",
      "2021-10-30 00:15:46.869977: This epoch took 192.376694 s\n",
      "\n",
      "2021-10-30 00:15:46.878027: \n",
      "epoch:  12\n",
      "2021-10-30 00:18:44.057752: train loss : -0.8474\n",
      "2021-10-30 00:18:57.497663: validation loss: -0.8361\n",
      "2021-10-30 00:18:57.501299: Average global foreground Dice: [0.8478]\n",
      "2021-10-30 00:18:57.508042: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 00:18:58.049165: lr: 0.008822\n",
      "2021-10-30 00:18:58.090874: saving checkpoint...\n",
      "2021-10-30 00:18:58.820769: done, saving took 0.75 seconds\n",
      "2021-10-30 00:18:59.219320: This epoch took 192.334527 s\n",
      "\n",
      "2021-10-30 00:18:59.227439: \n",
      "epoch:  13\n",
      "2021-10-30 00:21:56.506071: train loss : -0.8503\n",
      "2021-10-30 00:22:09.933649: validation loss: -0.8332\n",
      "2021-10-30 00:22:09.937357: Average global foreground Dice: [0.8423]\n",
      "2021-10-30 00:22:09.944899: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 00:22:10.418992: lr: 0.008731\n",
      "2021-10-30 00:22:10.457794: saving checkpoint...\n",
      "2021-10-30 00:22:11.204244: done, saving took 0.76 seconds\n",
      "2021-10-30 00:22:11.609600: This epoch took 192.376069 s\n",
      "\n",
      "2021-10-30 00:22:11.618194: \n",
      "epoch:  14\n",
      "2021-10-30 00:25:08.872520: train loss : -0.8516\n",
      "2021-10-30 00:25:22.279889: validation loss: -0.8379\n",
      "2021-10-30 00:25:22.283296: Average global foreground Dice: [0.848]\n",
      "2021-10-30 00:25:22.289966: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 00:25:22.764436: lr: 0.008639\n",
      "2021-10-30 00:25:22.803299: saving checkpoint...\n",
      "2021-10-30 00:25:23.460979: done, saving took 0.68 seconds\n",
      "2021-10-30 00:25:23.852791: This epoch took 192.226092 s\n",
      "\n",
      "2021-10-30 00:25:23.861466: \n",
      "epoch:  15\n",
      "2021-10-30 00:28:21.121612: train loss : -0.8538\n",
      "2021-10-30 00:28:34.511230: validation loss: -0.8329\n",
      "2021-10-30 00:28:34.515518: Average global foreground Dice: [0.8446]\n",
      "2021-10-30 00:28:34.522013: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 00:28:35.001815: lr: 0.008548\n",
      "2021-10-30 00:28:35.040037: saving checkpoint...\n",
      "2021-10-30 00:28:35.771342: done, saving took 0.75 seconds\n",
      "2021-10-30 00:28:36.155968: This epoch took 192.286053 s\n",
      "\n",
      "2021-10-30 00:28:36.164875: \n",
      "epoch:  16\n",
      "2021-10-30 00:31:33.481407: train loss : -0.8571\n",
      "2021-10-30 00:31:46.909559: validation loss: -0.8396\n",
      "2021-10-30 00:31:46.913472: Average global foreground Dice: [0.8488]\n",
      "2021-10-30 00:31:46.921026: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 00:31:47.402699: lr: 0.008456\n",
      "2021-10-30 00:31:47.439434: saving checkpoint...\n",
      "2021-10-30 00:31:48.168198: done, saving took 0.75 seconds\n",
      "2021-10-30 00:31:48.555086: This epoch took 192.383357 s\n",
      "\n",
      "2021-10-30 00:31:48.563030: \n",
      "epoch:  17\n",
      "2021-10-30 00:34:45.906946: train loss : -0.8577\n",
      "2021-10-30 00:34:59.352441: validation loss: -0.8363\n",
      "2021-10-30 00:34:59.355906: Average global foreground Dice: [0.8463]\n",
      "2021-10-30 00:34:59.361573: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 00:34:59.912495: lr: 0.008364\n",
      "2021-10-30 00:34:59.959880: saving checkpoint...\n",
      "2021-10-30 00:35:00.691583: done, saving took 0.76 seconds\n",
      "2021-10-30 00:35:01.111270: This epoch took 192.540916 s\n",
      "\n",
      "2021-10-30 00:35:01.119437: \n",
      "epoch:  18\n",
      "2021-10-30 00:37:58.499955: train loss : -0.8581\n",
      "2021-10-30 00:38:11.933213: validation loss: -0.8351\n",
      "2021-10-30 00:38:11.937287: Average global foreground Dice: [0.8445]\n",
      "2021-10-30 00:38:11.944905: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 00:38:12.426584: lr: 0.008272\n",
      "2021-10-30 00:38:12.465599: saving checkpoint...\n",
      "2021-10-30 00:38:13.202693: done, saving took 0.76 seconds\n",
      "2021-10-30 00:38:13.584759: This epoch took 192.457745 s\n",
      "\n",
      "2021-10-30 00:38:13.593201: \n",
      "epoch:  19\n",
      "2021-10-30 00:41:10.962193: train loss : -0.8609\n",
      "2021-10-30 00:41:24.387167: validation loss: -0.8338\n",
      "2021-10-30 00:41:24.391227: Average global foreground Dice: [0.8429]\n",
      "2021-10-30 00:41:24.398493: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 00:41:24.878682: lr: 0.008181\n",
      "2021-10-30 00:41:24.911757: saving checkpoint...\n",
      "2021-10-30 00:41:25.580637: done, saving took 0.69 seconds\n",
      "2021-10-30 00:41:25.982340: This epoch took 192.381268 s\n",
      "\n",
      "2021-10-30 00:41:25.990518: \n",
      "epoch:  20\n",
      "2021-10-30 00:44:23.334339: train loss : -0.8629\n",
      "2021-10-30 00:44:36.742245: validation loss: -0.8455\n",
      "2021-10-30 00:44:36.746148: Average global foreground Dice: [0.8552]\n",
      "2021-10-30 00:44:36.752781: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 00:44:37.238343: lr: 0.008088\n",
      "2021-10-30 00:44:37.274805: saving checkpoint...\n",
      "2021-10-30 00:44:38.009407: done, saving took 0.75 seconds\n",
      "2021-10-30 00:44:38.393708: This epoch took 192.395606 s\n",
      "\n",
      "2021-10-30 00:44:38.401432: \n",
      "epoch:  21\n",
      "2021-10-30 00:47:35.733632: train loss : -0.8646\n",
      "2021-10-30 00:47:49.145204: validation loss: -0.8395\n",
      "2021-10-30 00:47:49.149436: Average global foreground Dice: [0.8494]\n",
      "2021-10-30 00:47:49.156960: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 00:47:49.634298: lr: 0.007996\n",
      "2021-10-30 00:47:49.673283: saving checkpoint...\n",
      "2021-10-30 00:47:50.402150: done, saving took 0.75 seconds\n",
      "2021-10-30 00:47:50.789747: This epoch took 192.381721 s\n",
      "\n",
      "2021-10-30 00:47:50.798031: \n",
      "epoch:  22\n",
      "2021-10-30 00:50:48.167102: train loss : -0.8641\n",
      "2021-10-30 00:51:01.587605: validation loss: -0.8382\n",
      "2021-10-30 00:51:01.591935: Average global foreground Dice: [0.8495]\n",
      "2021-10-30 00:51:01.598305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 00:51:02.166296: lr: 0.007904\n",
      "2021-10-30 00:51:02.216613: saving checkpoint...\n",
      "2021-10-30 00:51:02.967705: done, saving took 0.78 seconds\n",
      "2021-10-30 00:51:03.348311: This epoch took 192.542942 s\n",
      "\n",
      "2021-10-30 00:51:03.356400: \n",
      "epoch:  23\n",
      "2021-10-30 00:53:53.651892: train loss : -0.8660\n",
      "2021-10-30 00:54:06.102945: validation loss: -0.8382\n",
      "2021-10-30 00:54:06.106532: Average global foreground Dice: [0.8481]\n",
      "2021-10-30 00:54:06.112648: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 00:54:06.589661: lr: 0.007811\n",
      "2021-10-30 00:54:06.624474: saving checkpoint...\n",
      "2021-10-30 00:54:07.292281: done, saving took 0.69 seconds\n",
      "2021-10-30 00:54:08.648966: This epoch took 185.285283 s\n",
      "\n",
      "2021-10-30 00:54:08.658282: \n",
      "epoch:  24\n",
      "2021-10-30 00:56:54.464225: train loss : -0.8687\n",
      "2021-10-30 00:57:07.356940: validation loss: -0.8447\n",
      "2021-10-30 00:57:07.360282: Average global foreground Dice: [0.8541]\n",
      "2021-10-30 00:57:07.366337: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 00:57:07.846763: lr: 0.007719\n",
      "2021-10-30 00:57:07.885702: saving checkpoint...\n",
      "2021-10-30 00:57:08.638065: done, saving took 0.77 seconds\n",
      "2021-10-30 00:57:09.035779: This epoch took 180.369798 s\n",
      "\n",
      "2021-10-30 00:57:09.043739: \n",
      "epoch:  25\n",
      "2021-10-30 01:00:05.135441: train loss : -0.8697\n",
      "2021-10-30 01:00:18.558709: validation loss: -0.8364\n",
      "2021-10-30 01:00:18.562302: Average global foreground Dice: [0.8477]\n",
      "2021-10-30 01:00:18.569462: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:00:19.093949: lr: 0.007626\n",
      "2021-10-30 01:00:19.131142: saving checkpoint...\n",
      "2021-10-30 01:00:19.877929: done, saving took 0.77 seconds\n",
      "2021-10-30 01:00:20.323921: This epoch took 191.273945 s\n",
      "\n",
      "2021-10-30 01:00:20.332469: \n",
      "epoch:  26\n",
      "2021-10-30 01:03:17.760590: train loss : -0.8704\n",
      "2021-10-30 01:03:31.156440: validation loss: -0.8381\n",
      "2021-10-30 01:03:31.160103: Average global foreground Dice: [0.8475]\n",
      "2021-10-30 01:03:31.166775: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:03:31.646512: lr: 0.007533\n",
      "2021-10-30 01:03:31.687809: saving checkpoint...\n",
      "2021-10-30 01:03:32.413644: done, saving took 0.74 seconds\n",
      "2021-10-30 01:03:32.823043: This epoch took 192.484081 s\n",
      "\n",
      "2021-10-30 01:03:32.830735: \n",
      "epoch:  27\n",
      "2021-10-30 01:06:30.287032: train loss : -0.8716\n",
      "2021-10-30 01:06:43.671034: validation loss: -0.8399\n",
      "2021-10-30 01:06:43.675299: Average global foreground Dice: [0.8472]\n",
      "2021-10-30 01:06:43.682211: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:06:44.243798: lr: 0.00744\n",
      "2021-10-30 01:06:44.294235: saving checkpoint...\n",
      "2021-10-30 01:06:44.964607: done, saving took 0.70 seconds\n",
      "2021-10-30 01:06:45.354636: This epoch took 192.516695 s\n",
      "\n",
      "2021-10-30 01:06:45.362953: \n",
      "epoch:  28\n",
      "2021-10-30 01:09:42.762012: train loss : -0.8732\n",
      "2021-10-30 01:09:56.159755: validation loss: -0.8455\n",
      "2021-10-30 01:09:56.164196: Average global foreground Dice: [0.8546]\n",
      "2021-10-30 01:09:56.171067: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:09:56.656879: lr: 0.007347\n",
      "2021-10-30 01:09:56.694105: saving checkpoint...\n",
      "2021-10-30 01:09:57.444149: done, saving took 0.77 seconds\n",
      "2021-10-30 01:09:57.912661: This epoch took 192.542895 s\n",
      "\n",
      "2021-10-30 01:09:57.920134: \n",
      "epoch:  29\n",
      "2021-10-30 01:12:55.243897: train loss : -0.8744\n",
      "2021-10-30 01:13:08.545951: validation loss: -0.8397\n",
      "2021-10-30 01:13:08.549330: Average global foreground Dice: [0.8481]\n",
      "2021-10-30 01:13:08.555437: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:13:09.038949: lr: 0.007254\n",
      "2021-10-30 01:13:09.089555: saving checkpoint...\n",
      "2021-10-30 01:13:09.836946: done, saving took 0.78 seconds\n",
      "2021-10-30 01:13:10.274403: This epoch took 192.347297 s\n",
      "\n",
      "2021-10-30 01:13:10.282708: \n",
      "epoch:  30\n",
      "2021-10-30 01:16:05.823704: train loss : -0.8740\n",
      "2021-10-30 01:16:19.065192: validation loss: -0.8432\n",
      "2021-10-30 01:16:19.068959: Average global foreground Dice: [0.852]\n",
      "2021-10-30 01:16:19.075675: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:16:19.605883: lr: 0.007161\n",
      "2021-10-30 01:16:19.642339: saving checkpoint...\n",
      "2021-10-30 01:16:20.392977: done, saving took 0.77 seconds\n",
      "2021-10-30 01:16:20.778754: This epoch took 190.489418 s\n",
      "\n",
      "2021-10-30 01:16:20.786993: \n",
      "epoch:  31\n",
      "2021-10-30 01:19:16.440889: train loss : -0.8743\n",
      "2021-10-30 01:19:29.663207: validation loss: -0.8392\n",
      "2021-10-30 01:19:29.667164: Average global foreground Dice: [0.8501]\n",
      "2021-10-30 01:19:29.673831: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:19:30.161947: lr: 0.007067\n",
      "2021-10-30 01:19:30.194733: saving checkpoint...\n",
      "2021-10-30 01:19:30.923606: done, saving took 0.75 seconds\n",
      "2021-10-30 01:19:31.358784: This epoch took 190.564764 s\n",
      "\n",
      "2021-10-30 01:19:31.368172: \n",
      "epoch:  32\n",
      "2021-10-30 01:22:27.066052: train loss : -0.8770\n",
      "2021-10-30 01:22:40.270397: validation loss: -0.8432\n",
      "2021-10-30 01:22:40.275468: Average global foreground Dice: [0.8524]\n",
      "2021-10-30 01:22:40.282079: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:22:40.838790: lr: 0.006974\n",
      "2021-10-30 01:22:40.890264: saving checkpoint...\n",
      "2021-10-30 01:22:41.559381: done, saving took 0.70 seconds\n",
      "2021-10-30 01:22:41.944731: This epoch took 190.569664 s\n",
      "\n",
      "2021-10-30 01:22:41.953509: \n",
      "epoch:  33\n",
      "2021-10-30 01:25:37.840787: train loss : -0.8781\n",
      "2021-10-30 01:25:51.148891: validation loss: -0.8432\n",
      "2021-10-30 01:25:51.152932: Average global foreground Dice: [0.8535]\n",
      "2021-10-30 01:25:51.159420: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:25:51.640985: lr: 0.00688\n",
      "2021-10-30 01:25:51.680172: saving checkpoint...\n",
      "2021-10-30 01:25:52.425261: done, saving took 0.76 seconds\n",
      "2021-10-30 01:25:52.829296: This epoch took 190.868821 s\n",
      "\n",
      "2021-10-30 01:25:52.837454: \n",
      "epoch:  34\n",
      "2021-10-30 01:28:49.093495: train loss : -0.8779\n",
      "2021-10-30 01:29:02.360241: validation loss: -0.8423\n",
      "2021-10-30 01:29:02.363824: Average global foreground Dice: [0.8519]\n",
      "2021-10-30 01:29:02.369796: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:29:02.854577: lr: 0.006786\n",
      "2021-10-30 01:29:02.893500: saving checkpoint...\n",
      "2021-10-30 01:29:03.632960: done, saving took 0.76 seconds\n",
      "2021-10-30 01:29:04.050344: This epoch took 191.205725 s\n",
      "\n",
      "2021-10-30 01:29:04.058963: \n",
      "epoch:  35\n",
      "2021-10-30 01:31:59.927327: train loss : -0.8778\n",
      "2021-10-30 01:32:13.139608: validation loss: -0.8388\n",
      "2021-10-30 01:32:13.143290: Average global foreground Dice: [0.8484]\n",
      "2021-10-30 01:32:13.150177: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:32:13.641659: lr: 0.006692\n",
      "2021-10-30 01:32:13.678679: saving checkpoint...\n",
      "2021-10-30 01:32:14.435313: done, saving took 0.78 seconds\n",
      "2021-10-30 01:32:14.873484: This epoch took 190.808295 s\n",
      "\n",
      "2021-10-30 01:32:14.881511: \n",
      "epoch:  36\n",
      "2021-10-30 01:35:10.631520: train loss : -0.8780\n",
      "2021-10-30 01:35:23.844141: validation loss: -0.8446\n",
      "2021-10-30 01:35:23.847756: Average global foreground Dice: [0.8528]\n",
      "2021-10-30 01:35:23.854492: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:35:24.347888: lr: 0.006598\n",
      "2021-10-30 01:35:24.388363: saving checkpoint...\n",
      "2021-10-30 01:35:25.129826: done, saving took 0.76 seconds\n",
      "2021-10-30 01:35:25.525626: This epoch took 190.637549 s\n",
      "\n",
      "2021-10-30 01:35:25.533384: \n",
      "epoch:  37\n",
      "2021-10-30 01:38:21.575496: train loss : -0.8802\n",
      "2021-10-30 01:38:34.801332: validation loss: -0.8371\n",
      "2021-10-30 01:38:34.804987: Average global foreground Dice: [0.8469]\n",
      "2021-10-30 01:38:34.811626: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:38:35.375446: lr: 0.006504\n",
      "2021-10-30 01:38:35.393773: This epoch took 189.853927 s\n",
      "\n",
      "2021-10-30 01:38:35.400120: \n",
      "epoch:  38\n",
      "2021-10-30 01:41:31.338464: train loss : -0.8801\n",
      "2021-10-30 01:41:44.542706: validation loss: -0.8367\n",
      "2021-10-30 01:41:44.546964: Average global foreground Dice: [0.846]\n",
      "2021-10-30 01:41:44.553969: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:41:45.039874: lr: 0.006409\n",
      "2021-10-30 01:41:45.058762: This epoch took 189.651588 s\n",
      "\n",
      "2021-10-30 01:41:45.065276: \n",
      "epoch:  39\n",
      "2021-10-30 01:44:40.962380: train loss : -0.8823\n",
      "2021-10-30 01:44:54.223923: validation loss: -0.8404\n",
      "2021-10-30 01:44:54.227350: Average global foreground Dice: [0.8504]\n",
      "2021-10-30 01:44:54.233455: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:44:54.720976: lr: 0.006314\n",
      "2021-10-30 01:44:54.770162: saving checkpoint...\n",
      "2021-10-30 01:44:55.506099: done, saving took 0.77 seconds\n",
      "2021-10-30 01:44:55.917324: This epoch took 190.845720 s\n",
      "\n",
      "2021-10-30 01:44:55.925565: \n",
      "epoch:  40\n",
      "2021-10-30 01:47:51.914852: train loss : -0.8811\n",
      "2021-10-30 01:48:05.185761: validation loss: -0.8370\n",
      "2021-10-30 01:48:05.189582: Average global foreground Dice: [0.8473]\n",
      "2021-10-30 01:48:05.197366: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:48:05.682092: lr: 0.00622\n",
      "2021-10-30 01:48:05.703155: This epoch took 189.770615 s\n",
      "\n",
      "2021-10-30 01:48:05.710121: \n",
      "epoch:  41\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-30 01:51:01.610264: train loss : -0.8830\n",
      "2021-10-30 01:51:14.845401: validation loss: -0.8405\n",
      "2021-10-30 01:51:14.848945: Average global foreground Dice: [0.849]\n",
      "2021-10-30 01:51:14.855461: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:51:15.381661: lr: 0.006125\n",
      "2021-10-30 01:51:15.420208: saving checkpoint...\n",
      "2021-10-30 01:51:16.155081: done, saving took 0.75 seconds\n",
      "2021-10-30 01:51:16.585603: This epoch took 190.868688 s\n",
      "\n",
      "2021-10-30 01:51:16.594308: \n",
      "epoch:  42\n",
      "2021-10-30 01:54:11.870423: train loss : -0.8834\n",
      "2021-10-30 01:54:25.089858: validation loss: -0.8321\n",
      "2021-10-30 01:54:25.093551: Average global foreground Dice: [0.8419]\n",
      "2021-10-30 01:54:25.099969: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:54:25.583191: lr: 0.00603\n",
      "2021-10-30 01:54:25.603177: This epoch took 189.001775 s\n",
      "\n",
      "2021-10-30 01:54:25.610022: \n",
      "epoch:  43\n",
      "2021-10-30 01:57:20.990491: train loss : -0.8845\n",
      "2021-10-30 01:57:34.210569: validation loss: -0.8395\n",
      "2021-10-30 01:57:34.214613: Average global foreground Dice: [0.8477]\n",
      "2021-10-30 01:57:34.221527: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 01:57:34.706895: lr: 0.005934\n",
      "2021-10-30 01:57:34.725325: This epoch took 189.107985 s\n",
      "\n",
      "2021-10-30 01:57:34.731735: \n",
      "epoch:  44\n",
      "2021-10-30 02:00:30.141402: train loss : -0.8860\n",
      "2021-10-30 02:00:43.346942: validation loss: -0.8325\n",
      "2021-10-30 02:00:43.350767: Average global foreground Dice: [0.8421]\n",
      "2021-10-30 02:00:43.356729: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:00:43.839898: lr: 0.005839\n",
      "2021-10-30 02:00:43.862257: This epoch took 189.123911 s\n",
      "\n",
      "2021-10-30 02:00:43.869710: \n",
      "epoch:  45\n",
      "2021-10-30 02:03:39.291945: train loss : -0.8852\n",
      "2021-10-30 02:03:52.498807: validation loss: -0.8366\n",
      "2021-10-30 02:03:52.502194: Average global foreground Dice: [0.8455]\n",
      "2021-10-30 02:03:52.509421: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:03:52.986028: lr: 0.005743\n",
      "2021-10-30 02:03:53.005424: This epoch took 189.127949 s\n",
      "\n",
      "2021-10-30 02:03:53.012508: \n",
      "epoch:  46\n",
      "2021-10-30 02:06:48.479928: train loss : -0.8866\n",
      "2021-10-30 02:07:01.684901: validation loss: -0.8456\n",
      "2021-10-30 02:07:01.689026: Average global foreground Dice: [0.854]\n",
      "2021-10-30 02:07:01.696172: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:07:02.175833: lr: 0.005647\n",
      "2021-10-30 02:07:02.197762: This epoch took 189.178241 s\n",
      "\n",
      "2021-10-30 02:07:02.204759: \n",
      "epoch:  47\n",
      "2021-10-30 02:09:57.594729: train loss : -0.8868\n",
      "2021-10-30 02:10:10.811655: validation loss: -0.8384\n",
      "2021-10-30 02:10:10.815537: Average global foreground Dice: [0.8479]\n",
      "2021-10-30 02:10:10.821317: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:10:11.304615: lr: 0.005551\n",
      "2021-10-30 02:10:11.323807: This epoch took 189.111937 s\n",
      "\n",
      "2021-10-30 02:10:11.330408: \n",
      "epoch:  48\n",
      "2021-10-30 02:13:06.534237: train loss : -0.8884\n",
      "2021-10-30 02:13:19.729447: validation loss: -0.8404\n",
      "2021-10-30 02:13:19.732697: Average global foreground Dice: [0.8488]\n",
      "2021-10-30 02:13:19.738907: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:13:20.305375: lr: 0.005455\n",
      "2021-10-30 02:13:20.325473: This epoch took 188.987437 s\n",
      "\n",
      "2021-10-30 02:13:20.332736: \n",
      "epoch:  49\n",
      "2021-10-30 02:16:15.854623: train loss : -0.8882\n",
      "2021-10-30 02:16:29.080589: validation loss: -0.8428\n",
      "2021-10-30 02:16:29.084679: Average global foreground Dice: [0.8511]\n",
      "2021-10-30 02:16:29.092018: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:16:29.591580: lr: 0.005359\n",
      "2021-10-30 02:16:29.606489: saving scheduled checkpoint file...\n",
      "2021-10-30 02:16:29.642282: saving checkpoint...\n",
      "2021-10-30 02:16:30.247629: done, saving took 0.63 seconds\n",
      "2021-10-30 02:16:30.661174: done\n",
      "2021-10-30 02:16:30.688818: saving checkpoint...\n",
      "2021-10-30 02:16:31.417335: done, saving took 0.75 seconds\n",
      "2021-10-30 02:16:31.872344: This epoch took 191.532676 s\n",
      "\n",
      "2021-10-30 02:16:31.881302: \n",
      "epoch:  50\n",
      "2021-10-30 02:19:27.130612: train loss : -0.8885\n",
      "2021-10-30 02:19:40.317632: validation loss: -0.8401\n",
      "2021-10-30 02:19:40.321724: Average global foreground Dice: [0.8497]\n",
      "2021-10-30 02:19:40.328717: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:19:40.823367: lr: 0.005262\n",
      "2021-10-30 02:19:40.861711: saving checkpoint...\n",
      "2021-10-30 02:19:41.608772: done, saving took 0.77 seconds\n",
      "2021-10-30 02:19:42.002056: This epoch took 190.114191 s\n",
      "\n",
      "2021-10-30 02:19:42.010219: \n",
      "epoch:  51\n",
      "2021-10-30 02:22:37.201348: train loss : -0.8890\n",
      "2021-10-30 02:22:50.405338: validation loss: -0.8320\n",
      "2021-10-30 02:22:50.411359: Average global foreground Dice: [0.8434]\n",
      "2021-10-30 02:22:50.417859: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:22:50.901501: lr: 0.005166\n",
      "2021-10-30 02:22:50.923735: This epoch took 188.906292 s\n",
      "\n",
      "2021-10-30 02:22:50.931050: \n",
      "epoch:  52\n",
      "2021-10-30 02:25:46.037094: train loss : -0.8907\n",
      "2021-10-30 02:25:59.258098: validation loss: -0.8367\n",
      "2021-10-30 02:25:59.262146: Average global foreground Dice: [0.8447]\n",
      "2021-10-30 02:25:59.269013: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:25:59.765714: lr: 0.005069\n",
      "2021-10-30 02:25:59.785469: This epoch took 188.846604 s\n",
      "\n",
      "2021-10-30 02:25:59.792434: \n",
      "epoch:  53\n",
      "2021-10-30 02:28:54.880367: train loss : -0.8904\n",
      "2021-10-30 02:29:08.089161: validation loss: -0.8402\n",
      "2021-10-30 02:29:08.092988: Average global foreground Dice: [0.8487]\n",
      "2021-10-30 02:29:08.099746: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:29:08.580268: lr: 0.004971\n",
      "2021-10-30 02:29:08.601332: This epoch took 188.802003 s\n",
      "\n",
      "2021-10-30 02:29:08.610961: \n",
      "epoch:  54\n",
      "2021-10-30 02:32:03.817683: train loss : -0.8925\n",
      "2021-10-30 02:32:17.018881: validation loss: -0.8404\n",
      "2021-10-30 02:32:17.023150: Average global foreground Dice: [0.8484]\n",
      "2021-10-30 02:32:17.030575: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:32:17.520192: lr: 0.004874\n",
      "2021-10-30 02:32:17.538504: This epoch took 188.920880 s\n",
      "\n",
      "2021-10-30 02:32:17.544877: \n",
      "epoch:  55\n",
      "2021-10-30 02:35:12.692259: train loss : -0.8927\n",
      "2021-10-30 02:35:25.918098: validation loss: -0.8372\n",
      "2021-10-30 02:35:25.922061: Average global foreground Dice: [0.847]\n",
      "2021-10-30 02:35:25.928964: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:35:26.427375: lr: 0.004776\n",
      "2021-10-30 02:35:26.448867: This epoch took 188.897019 s\n",
      "\n",
      "2021-10-30 02:35:26.456810: \n",
      "epoch:  56\n",
      "2021-10-30 02:38:21.673640: train loss : -0.8934\n",
      "2021-10-30 02:38:34.874989: validation loss: -0.8419\n",
      "2021-10-30 02:38:34.878453: Average global foreground Dice: [0.8501]\n",
      "2021-10-30 02:38:34.885722: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:38:35.386071: lr: 0.004679\n",
      "2021-10-30 02:38:35.405761: This epoch took 188.941970 s\n",
      "\n",
      "2021-10-30 02:38:35.413165: \n",
      "epoch:  57\n",
      "2021-10-30 02:41:30.499517: train loss : -0.8934\n",
      "2021-10-30 02:41:43.711058: validation loss: -0.8401\n",
      "2021-10-30 02:41:43.714471: Average global foreground Dice: [0.8482]\n",
      "2021-10-30 02:41:43.720908: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:41:44.217983: lr: 0.004581\n",
      "2021-10-30 02:41:44.237602: This epoch took 188.816920 s\n",
      "\n",
      "2021-10-30 02:41:44.243952: \n",
      "epoch:  58\n",
      "2021-10-30 02:44:39.540969: train loss : -0.8940\n",
      "2021-10-30 02:44:52.776999: validation loss: -0.8377\n",
      "2021-10-30 02:44:52.781108: Average global foreground Dice: [0.8473]\n",
      "2021-10-30 02:44:52.786670: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:44:53.283631: lr: 0.004482\n",
      "2021-10-30 02:44:53.303625: This epoch took 189.052894 s\n",
      "\n",
      "2021-10-30 02:44:53.310598: \n",
      "epoch:  59\n",
      "2021-10-30 02:47:48.852864: train loss : -0.8950\n",
      "2021-10-30 02:48:02.072180: validation loss: -0.8393\n",
      "2021-10-30 02:48:02.076214: Average global foreground Dice: [0.8476]\n",
      "2021-10-30 02:48:02.082777: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:48:02.646931: lr: 0.004384\n",
      "2021-10-30 02:48:02.665674: This epoch took 189.348039 s\n",
      "\n",
      "2021-10-30 02:48:02.673947: \n",
      "epoch:  60\n",
      "2021-10-30 02:50:57.908419: train loss : -0.8962\n",
      "2021-10-30 02:51:11.086781: validation loss: -0.8389\n",
      "2021-10-30 02:51:11.090698: Average global foreground Dice: [0.8468]\n",
      "2021-10-30 02:51:11.097703: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:51:11.596311: lr: 0.004285\n",
      "2021-10-30 02:51:11.615719: This epoch took 188.934182 s\n",
      "\n",
      "2021-10-30 02:51:11.622572: \n",
      "epoch:  61\n",
      "2021-10-30 02:54:06.851658: train loss : -0.8966\n",
      "2021-10-30 02:54:20.091461: validation loss: -0.8384\n",
      "2021-10-30 02:54:20.095354: Average global foreground Dice: [0.846]\n",
      "2021-10-30 02:54:20.102212: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:54:20.600435: lr: 0.004186\n",
      "2021-10-30 02:54:21.077708: This epoch took 189.448313 s\n",
      "\n",
      "2021-10-30 02:54:21.083526: \n",
      "epoch:  62\n",
      "2021-10-30 02:57:16.616270: train loss : -0.8963\n",
      "2021-10-30 02:57:29.835187: validation loss: -0.8410\n",
      "2021-10-30 02:57:29.839165: Average global foreground Dice: [0.8514]\n",
      "2021-10-30 02:57:29.846125: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 02:57:30.348885: lr: 0.004087\n",
      "2021-10-30 02:57:30.367198: This epoch took 189.277415 s\n",
      "\n",
      "2021-10-30 02:57:30.374669: \n",
      "epoch:  63\n",
      "2021-10-30 03:00:25.728164: train loss : -0.8969\n",
      "2021-10-30 03:00:38.951773: validation loss: -0.8408\n",
      "2021-10-30 03:00:38.955559: Average global foreground Dice: [0.85]\n",
      "2021-10-30 03:00:38.962708: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:00:39.461525: lr: 0.003987\n",
      "2021-10-30 03:00:39.510142: saving checkpoint...\n",
      "2021-10-30 03:00:40.272824: done, saving took 0.79 seconds\n",
      "2021-10-30 03:00:40.835105: This epoch took 190.453455 s\n",
      "\n",
      "2021-10-30 03:00:40.843492: \n",
      "epoch:  64\n",
      "2021-10-30 03:03:35.788108: train loss : -0.8968\n",
      "2021-10-30 03:03:48.981658: validation loss: -0.8400\n",
      "2021-10-30 03:03:48.985741: Average global foreground Dice: [0.8492]\n",
      "2021-10-30 03:03:48.992983: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:03:49.551014: lr: 0.003887\n",
      "2021-10-30 03:03:49.596361: saving checkpoint...\n",
      "2021-10-30 03:03:50.344918: done, saving took 0.77 seconds\n",
      "2021-10-30 03:03:50.746422: This epoch took 189.895938 s\n",
      "\n",
      "2021-10-30 03:03:50.754711: \n",
      "epoch:  65\n",
      "2021-10-30 03:06:45.680411: train loss : -0.8987\n",
      "2021-10-30 03:06:58.854545: validation loss: -0.8427\n",
      "2021-10-30 03:06:58.858312: Average global foreground Dice: [0.85]\n",
      "2021-10-30 03:06:58.865132: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:06:59.352175: lr: 0.003787\n",
      "2021-10-30 03:06:59.398710: saving checkpoint...\n",
      "2021-10-30 03:07:00.140299: done, saving took 0.77 seconds\n",
      "2021-10-30 03:07:00.538162: This epoch took 189.776389 s\n",
      "\n",
      "2021-10-30 03:07:00.546951: \n",
      "epoch:  66\n",
      "2021-10-30 03:09:55.516478: train loss : -0.8980\n",
      "2021-10-30 03:10:08.705956: validation loss: -0.8407\n",
      "2021-10-30 03:10:08.709703: Average global foreground Dice: [0.8498]\n",
      "2021-10-30 03:10:08.715745: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:10:09.199842: lr: 0.003687\n",
      "2021-10-30 03:10:09.246983: saving checkpoint...\n",
      "2021-10-30 03:10:10.007919: done, saving took 0.79 seconds\n",
      "2021-10-30 03:10:10.415257: This epoch took 189.857919 s\n",
      "\n",
      "2021-10-30 03:10:10.423354: \n",
      "epoch:  67\n",
      "2021-10-30 03:13:05.231569: train loss : -0.8991\n",
      "2021-10-30 03:13:18.421031: validation loss: -0.8396\n",
      "2021-10-30 03:13:18.424855: Average global foreground Dice: [0.8482]\n",
      "2021-10-30 03:13:18.430681: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:13:18.929838: lr: 0.003586\n",
      "2021-10-30 03:13:18.947836: This epoch took 188.517028 s\n",
      "\n",
      "2021-10-30 03:13:18.954569: \n",
      "epoch:  68\n",
      "2021-10-30 03:16:13.847999: train loss : -0.8994\n",
      "2021-10-30 03:16:27.046886: validation loss: -0.8376\n",
      "2021-10-30 03:16:27.050790: Average global foreground Dice: [0.8453]\n",
      "2021-10-30 03:16:27.057898: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:16:27.544218: lr: 0.003485\n",
      "2021-10-30 03:16:27.563284: This epoch took 188.602485 s\n",
      "\n",
      "2021-10-30 03:16:27.569996: \n",
      "epoch:  69\n",
      "2021-10-30 03:19:22.481998: train loss : -0.8989\n",
      "2021-10-30 03:19:35.680548: validation loss: -0.8415\n",
      "2021-10-30 03:19:35.686312: Average global foreground Dice: [0.8496]\n",
      "2021-10-30 03:19:35.693474: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:19:36.183247: lr: 0.003384\n",
      "2021-10-30 03:19:36.201656: This epoch took 188.624502 s\n",
      "\n",
      "2021-10-30 03:19:36.208379: \n",
      "epoch:  70\n",
      "2021-10-30 03:22:31.029365: train loss : -0.9015\n",
      "2021-10-30 03:22:44.231953: validation loss: -0.8383\n",
      "2021-10-30 03:22:44.235931: Average global foreground Dice: [0.8469]\n",
      "2021-10-30 03:22:44.242356: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:22:44.732566: lr: 0.003282\n",
      "2021-10-30 03:22:44.746289: This epoch took 188.531392 s\n",
      "\n",
      "2021-10-30 03:22:44.753997: \n",
      "epoch:  71\n",
      "2021-10-30 03:25:39.623660: train loss : -0.9010\n",
      "2021-10-30 03:25:52.834712: validation loss: -0.8386\n",
      "2021-10-30 03:25:52.838669: Average global foreground Dice: [0.8465]\n",
      "2021-10-30 03:25:52.845174: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:25:53.346080: lr: 0.00318\n",
      "2021-10-30 03:25:53.375356: This epoch took 188.614135 s\n",
      "\n",
      "2021-10-30 03:25:53.382784: \n",
      "epoch:  72\n",
      "2021-10-30 03:28:48.447572: train loss : -0.9007\n",
      "2021-10-30 03:29:01.667305: validation loss: -0.8375\n",
      "2021-10-30 03:29:01.671057: Average global foreground Dice: [0.8459]\n",
      "2021-10-30 03:29:01.677998: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:29:02.183678: lr: 0.003078\n",
      "2021-10-30 03:29:02.205409: This epoch took 188.815044 s\n",
      "\n",
      "2021-10-30 03:29:02.212058: \n",
      "epoch:  73\n",
      "2021-10-30 03:31:57.377369: train loss : -0.9017\n",
      "2021-10-30 03:32:10.608163: validation loss: -0.8377\n",
      "2021-10-30 03:32:10.612183: Average global foreground Dice: [0.8454]\n",
      "2021-10-30 03:32:10.619362: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:32:11.123243: lr: 0.002975\n",
      "2021-10-30 03:32:11.142534: This epoch took 188.924131 s\n",
      "\n",
      "2021-10-30 03:32:11.149736: \n",
      "epoch:  74\n",
      "2021-10-30 03:35:06.402605: train loss : -0.9027\n",
      "2021-10-30 03:35:19.592604: validation loss: -0.8386\n",
      "2021-10-30 03:35:19.596483: Average global foreground Dice: [0.8462]\n",
      "2021-10-30 03:35:19.603209: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:35:20.100065: lr: 0.002872\n",
      "2021-10-30 03:35:20.120202: This epoch took 188.964255 s\n",
      "\n",
      "2021-10-30 03:35:20.127149: \n",
      "epoch:  75\n",
      "2021-10-30 03:38:15.783899: train loss : -0.9033\n",
      "2021-10-30 03:38:29.028890: validation loss: -0.8412\n",
      "2021-10-30 03:38:29.032794: Average global foreground Dice: [0.8488]\n",
      "2021-10-30 03:38:29.039351: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:38:29.595972: lr: 0.002768\n",
      "2021-10-30 03:38:29.614417: This epoch took 189.479906 s\n",
      "\n",
      "2021-10-30 03:38:29.621015: \n",
      "epoch:  76\n",
      "2021-10-30 03:41:25.180895: train loss : -0.9030\n",
      "2021-10-30 03:41:38.465508: validation loss: -0.8375\n",
      "2021-10-30 03:41:38.470007: Average global foreground Dice: [0.8468]\n",
      "2021-10-30 03:41:38.476624: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:41:39.006153: lr: 0.002664\n",
      "2021-10-30 03:41:39.024111: This epoch took 189.395894 s\n",
      "\n",
      "2021-10-30 03:41:39.030946: \n",
      "epoch:  77\n",
      "2021-10-30 03:44:34.539920: train loss : -0.9047\n",
      "2021-10-30 03:44:47.766105: validation loss: -0.8412\n",
      "2021-10-30 03:44:47.771399: Average global foreground Dice: [0.8482]\n",
      "2021-10-30 03:44:47.777918: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:44:48.279880: lr: 0.00256\n",
      "2021-10-30 03:44:49.187557: This epoch took 190.149630 s\n",
      "\n",
      "2021-10-30 03:44:49.194803: \n",
      "epoch:  78\n",
      "2021-10-30 03:47:44.657141: train loss : -0.9054\n",
      "2021-10-30 03:47:57.890534: validation loss: -0.8407\n",
      "2021-10-30 03:47:57.894169: Average global foreground Dice: [0.8481]\n",
      "2021-10-30 03:47:57.899737: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:47:58.404252: lr: 0.002455\n",
      "2021-10-30 03:47:58.426039: This epoch took 189.224921 s\n",
      "\n",
      "2021-10-30 03:47:58.433222: \n",
      "epoch:  79\n",
      "2021-10-30 03:50:53.852633: train loss : -0.9050\n",
      "2021-10-30 03:51:07.057973: validation loss: -0.8376\n",
      "2021-10-30 03:51:07.063509: Average global foreground Dice: [0.8464]\n",
      "2021-10-30 03:51:07.070201: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:51:07.571892: lr: 0.002349\n",
      "2021-10-30 03:51:07.598790: This epoch took 189.157722 s\n",
      "\n",
      "2021-10-30 03:51:07.604680: \n",
      "epoch:  80\n",
      "2021-10-30 03:54:02.754009: train loss : -0.9049\n",
      "2021-10-30 03:54:16.009889: validation loss: -0.8404\n",
      "2021-10-30 03:54:16.014390: Average global foreground Dice: [0.8496]\n",
      "2021-10-30 03:54:16.021178: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:54:16.528333: lr: 0.002243\n",
      "2021-10-30 03:54:16.549231: This epoch took 188.938028 s\n",
      "\n",
      "2021-10-30 03:54:16.555981: \n",
      "epoch:  81\n",
      "2021-10-30 03:57:11.688498: train loss : -0.9061\n",
      "2021-10-30 03:57:24.899122: validation loss: -0.8393\n",
      "2021-10-30 03:57:24.903063: Average global foreground Dice: [0.8464]\n",
      "2021-10-30 03:57:24.910467: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 03:57:25.401257: lr: 0.002137\n",
      "2021-10-30 03:57:25.420683: This epoch took 188.857940 s\n",
      "\n",
      "2021-10-30 03:57:25.427721: \n",
      "epoch:  82\n",
      "2021-10-30 04:00:20.463644: train loss : -0.9072\n",
      "2021-10-30 04:00:33.699718: validation loss: -0.8391\n",
      "2021-10-30 04:00:33.703534: Average global foreground Dice: [0.8473]\n",
      "2021-10-30 04:00:33.710555: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:00:34.206582: lr: 0.00203\n",
      "2021-10-30 04:00:34.228223: This epoch took 188.792424 s\n",
      "\n",
      "2021-10-30 04:00:34.235221: \n",
      "epoch:  83\n",
      "2021-10-30 04:03:29.012637: train loss : -0.9075\n",
      "2021-10-30 04:03:42.225705: validation loss: -0.8398\n",
      "2021-10-30 04:03:42.229420: Average global foreground Dice: [0.8479]\n",
      "2021-10-30 04:03:42.236552: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:03:42.730907: lr: 0.001922\n",
      "2021-10-30 04:03:42.748595: This epoch took 188.506399 s\n",
      "\n",
      "2021-10-30 04:03:42.754299: \n",
      "epoch:  84\n",
      "2021-10-30 04:06:37.591875: train loss : -0.9071\n",
      "2021-10-30 04:06:50.786852: validation loss: -0.8343\n",
      "2021-10-30 04:06:50.790377: Average global foreground Dice: [0.8432]\n",
      "2021-10-30 04:06:50.795968: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:06:51.292760: lr: 0.001813\n",
      "2021-10-30 04:06:51.312545: This epoch took 188.551419 s\n",
      "\n",
      "2021-10-30 04:06:51.319350: \n",
      "epoch:  85\n",
      "2021-10-30 04:09:46.253818: train loss : -0.9086\n",
      "2021-10-30 04:09:59.448935: validation loss: -0.8369\n",
      "2021-10-30 04:09:59.452911: Average global foreground Dice: [0.8441]\n",
      "2021-10-30 04:09:59.459276: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:09:59.956117: lr: 0.001704\n",
      "2021-10-30 04:09:59.975119: This epoch took 188.648871 s\n",
      "\n",
      "2021-10-30 04:09:59.981801: \n",
      "epoch:  86\n",
      "2021-10-30 04:12:54.926581: train loss : -0.9094\n",
      "2021-10-30 04:13:08.143329: validation loss: -0.8396\n",
      "2021-10-30 04:13:08.147081: Average global foreground Dice: [0.847]\n",
      "2021-10-30 04:13:08.154279: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:13:08.719210: lr: 0.001594\n",
      "2021-10-30 04:13:08.738149: This epoch took 188.749788 s\n",
      "\n",
      "2021-10-30 04:13:08.745435: \n",
      "epoch:  87\n",
      "2021-10-30 04:16:03.796155: train loss : -0.9097\n",
      "2021-10-30 04:16:17.001750: validation loss: -0.8339\n",
      "2021-10-30 04:16:17.005890: Average global foreground Dice: [0.8424]\n",
      "2021-10-30 04:16:17.012651: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:16:17.508486: lr: 0.001483\n",
      "2021-10-30 04:16:17.527831: This epoch took 188.774743 s\n",
      "\n",
      "2021-10-30 04:16:17.535341: \n",
      "epoch:  88\n",
      "2021-10-30 04:19:12.744742: train loss : -0.9098\n",
      "2021-10-30 04:19:25.929805: validation loss: -0.8332\n",
      "2021-10-30 04:19:25.933756: Average global foreground Dice: [0.8412]\n",
      "2021-10-30 04:19:25.939334: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:19:26.438025: lr: 0.001372\n",
      "2021-10-30 04:19:26.456546: This epoch took 188.914316 s\n",
      "\n",
      "2021-10-30 04:19:26.463103: \n",
      "epoch:  89\n",
      "2021-10-30 04:22:21.390721: train loss : -0.9108\n",
      "2021-10-30 04:22:34.590444: validation loss: -0.8359\n",
      "2021-10-30 04:22:34.593923: Average global foreground Dice: [0.8433]\n",
      "2021-10-30 04:22:34.602190: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:22:35.100001: lr: 0.001259\n",
      "2021-10-30 04:22:35.121444: This epoch took 188.651831 s\n",
      "\n",
      "2021-10-30 04:22:35.127784: \n",
      "epoch:  90\n",
      "2021-10-30 04:25:29.959177: train loss : -0.9119\n",
      "2021-10-30 04:25:43.173599: validation loss: -0.8363\n",
      "2021-10-30 04:25:43.177881: Average global foreground Dice: [0.8444]\n",
      "2021-10-30 04:25:43.185337: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:25:43.684646: lr: 0.001145\n",
      "2021-10-30 04:25:43.706338: This epoch took 188.572038 s\n",
      "\n",
      "2021-10-30 04:25:43.714209: \n",
      "epoch:  91\n",
      "2021-10-30 04:28:38.681915: train loss : -0.9111\n",
      "2021-10-30 04:28:51.885067: validation loss: -0.8405\n",
      "2021-10-30 04:28:51.889486: Average global foreground Dice: [0.848]\n",
      "2021-10-30 04:28:51.896093: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:28:52.391495: lr: 0.00103\n",
      "2021-10-30 04:28:52.409807: This epoch took 188.687917 s\n",
      "\n",
      "2021-10-30 04:28:52.416577: \n",
      "epoch:  92\n",
      "2021-10-30 04:31:47.440516: train loss : -0.9114\n",
      "2021-10-30 04:32:00.641889: validation loss: -0.8368\n",
      "2021-10-30 04:32:00.645826: Average global foreground Dice: [0.844]\n",
      "2021-10-30 04:32:00.652017: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:32:01.131967: lr: 0.000913\n",
      "2021-10-30 04:32:01.148653: This epoch took 188.725277 s\n",
      "\n",
      "2021-10-30 04:32:01.155750: \n",
      "epoch:  93\n",
      "2021-10-30 04:34:55.986032: train loss : -0.9122\n",
      "2021-10-30 04:35:09.173800: validation loss: -0.8416\n",
      "2021-10-30 04:35:09.177590: Average global foreground Dice: [0.8496]\n",
      "2021-10-30 04:35:09.183842: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:35:09.678294: lr: 0.000795\n",
      "2021-10-30 04:35:09.697185: This epoch took 188.534374 s\n",
      "\n",
      "2021-10-30 04:35:09.704053: \n",
      "epoch:  94\n",
      "2021-10-30 04:38:04.597351: train loss : -0.9132\n",
      "2021-10-30 04:38:17.792958: validation loss: -0.8364\n",
      "2021-10-30 04:38:17.796237: Average global foreground Dice: [0.8448]\n",
      "2021-10-30 04:38:17.803013: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:38:18.302000: lr: 0.000675\n",
      "2021-10-30 04:38:18.315462: This epoch took 188.604672 s\n",
      "\n",
      "2021-10-30 04:38:18.321948: \n",
      "epoch:  95\n",
      "2021-10-30 04:41:13.203373: train loss : -0.9122\n",
      "2021-10-30 04:41:26.410298: validation loss: -0.8384\n",
      "2021-10-30 04:41:26.413862: Average global foreground Dice: [0.8455]\n",
      "2021-10-30 04:41:26.420685: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:41:26.910702: lr: 0.000552\n",
      "2021-10-30 04:41:26.927505: This epoch took 188.598646 s\n",
      "\n",
      "2021-10-30 04:41:26.934192: \n",
      "epoch:  96\n",
      "2021-10-30 04:44:21.709061: train loss : -0.9131\n",
      "2021-10-30 04:44:34.881119: validation loss: -0.8392\n",
      "2021-10-30 04:44:34.884977: Average global foreground Dice: [0.8471]\n",
      "2021-10-30 04:44:34.891504: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:44:35.384899: lr: 0.000426\n",
      "2021-10-30 04:44:35.407699: This epoch took 188.466900 s\n",
      "\n",
      "2021-10-30 04:44:35.414485: \n",
      "epoch:  97\n",
      "2021-10-30 04:47:30.260337: train loss : -0.9146\n",
      "2021-10-30 04:47:43.466229: validation loss: -0.8388\n",
      "2021-10-30 04:47:43.470319: Average global foreground Dice: [0.8447]\n",
      "2021-10-30 04:47:43.477005: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:47:44.027082: lr: 0.000296\n",
      "2021-10-30 04:47:44.052261: This epoch took 188.630816 s\n",
      "\n",
      "2021-10-30 04:47:44.059104: \n",
      "epoch:  98\n",
      "2021-10-30 04:50:38.724962: train loss : -0.9141\n",
      "2021-10-30 04:50:51.905164: validation loss: -0.8388\n",
      "2021-10-30 04:50:51.909830: Average global foreground Dice: [0.8465]\n",
      "2021-10-30 04:50:51.917512: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:50:52.421131: lr: 0.000158\n",
      "2021-10-30 04:50:52.442660: This epoch took 188.376908 s\n",
      "\n",
      "2021-10-30 04:50:52.449453: \n",
      "epoch:  99\n",
      "2021-10-30 04:53:47.054162: train loss : -0.9152\n",
      "2021-10-30 04:54:00.245433: validation loss: -0.8370\n",
      "2021-10-30 04:54:00.249422: Average global foreground Dice: [0.8441]\n",
      "2021-10-30 04:54:00.256824: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:54:00.751009: lr: 0.0\n",
      "2021-10-30 04:54:00.770271: saving scheduled checkpoint file...\n",
      "2021-10-30 04:54:00.808238: saving checkpoint...\n",
      "2021-10-30 04:54:01.570286: done, saving took 0.79 seconds\n",
      "2021-10-30 04:54:02.029877: done\n",
      "2021-10-30 04:54:02.037765: This epoch took 189.580761 s\n",
      "\n",
      "2021-10-30 04:54:02.063741: saving checkpoint...\n",
      "2021-10-30 04:54:02.651561: done, saving took 0.61 seconds\n",
      "23090557_20130717 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090560_20160114 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090562_20140206 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141215 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130626 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140124 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121015 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090597_20130227 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130208 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090621_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150105 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130807 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090637_20140401 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131126 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090644_20131216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-30 04:55:56.187011: finished prediction\n",
      "2021-10-30 04:55:56.192985: evaluation of raw predictions\n",
      "2021-10-30 04:55:58.070593: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8337592541827086\n",
      "after:  0.8339209661941205\n",
      "Removing all but the largest foreground region improved results!\n",
      "for_which_classes [1]\n",
      "min_valid_object_sizes None\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[[1]]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-10-30 04:56:10.339552: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-10-30 04:56:10.360693: The split file contains 5 splits.\n",
      "2021-10-30 04:56:10.367465: Desired fold for training: 4\n",
      "2021-10-30 04:56:10.373250: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-30 04:56:14.582972: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-30 04:56:23.842654: Unable to plot network architecture:\n",
      "2021-10-30 04:56:23.846264: No module named 'hiddenlayer'\n",
      "2021-10-30 04:56:23.853529: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-30 04:56:23.861421: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-30 04:56:23.939664: \n",
      "\n",
      "2021-10-30 04:56:23.947464: \n",
      "epoch:  0\n",
      "2021-10-30 04:59:31.756725: train loss : -0.3151\n",
      "2021-10-30 04:59:44.862274: validation loss: -0.6512\n",
      "2021-10-30 04:59:44.869307: Average global foreground Dice: [0.7184]\n",
      "2021-10-30 04:59:44.873147: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 04:59:45.303201: lr: 0.00991\n",
      "2021-10-30 04:59:45.319716: This epoch took 201.366265 s\n",
      "\n",
      "2021-10-30 04:59:45.326153: \n",
      "epoch:  1\n",
      "2021-10-30 05:02:37.764387: train loss : -0.6883\n",
      "2021-10-30 05:02:50.925620: validation loss: -0.7639\n",
      "2021-10-30 05:02:50.929703: Average global foreground Dice: [0.7951]\n",
      "2021-10-30 05:02:50.936633: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:02:51.427905: lr: 0.00982\n",
      "2021-10-30 05:02:51.489039: saving checkpoint...\n",
      "2021-10-30 05:02:52.158609: done, saving took 0.71 seconds\n",
      "2021-10-30 05:02:52.600062: This epoch took 187.268175 s\n",
      "\n",
      "2021-10-30 05:02:52.608029: \n",
      "epoch:  2\n",
      "2021-10-30 05:05:45.124095: train loss : -0.7749\n",
      "2021-10-30 05:05:58.295234: validation loss: -0.7982\n",
      "2021-10-30 05:05:58.298851: Average global foreground Dice: [0.8146]\n",
      "2021-10-30 05:05:58.305246: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:05:58.796285: lr: 0.00973\n",
      "2021-10-30 05:05:58.849129: saving checkpoint...\n",
      "2021-10-30 05:05:59.593681: done, saving took 0.78 seconds\n",
      "2021-10-30 05:05:59.990108: This epoch took 187.375976 s\n",
      "\n",
      "2021-10-30 05:05:59.998153: \n",
      "epoch:  3\n",
      "2021-10-30 05:08:52.440202: train loss : -0.7969\n",
      "2021-10-30 05:09:05.631548: validation loss: -0.8085\n",
      "2021-10-30 05:09:05.635548: Average global foreground Dice: [0.8231]\n",
      "2021-10-30 05:09:05.642619: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:09:06.129236: lr: 0.009639\n",
      "2021-10-30 05:09:06.181423: saving checkpoint...\n",
      "2021-10-30 05:09:06.858593: done, saving took 0.71 seconds\n",
      "2021-10-30 05:09:07.244913: This epoch took 187.239140 s\n",
      "\n",
      "2021-10-30 05:09:07.253171: \n",
      "epoch:  4\n",
      "2021-10-30 05:11:59.716950: train loss : -0.8141\n",
      "2021-10-30 05:12:12.900294: validation loss: -0.8111\n",
      "2021-10-30 05:12:12.903934: Average global foreground Dice: [0.8238]\n",
      "2021-10-30 05:12:12.910010: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:12:13.405297: lr: 0.009549\n",
      "2021-10-30 05:12:13.457861: saving checkpoint...\n",
      "2021-10-30 05:12:14.221055: done, saving took 0.80 seconds\n",
      "2021-10-30 05:12:14.623315: This epoch took 187.364418 s\n",
      "\n",
      "2021-10-30 05:12:14.631399: \n",
      "epoch:  5\n",
      "2021-10-30 05:15:07.116611: train loss : -0.8233\n",
      "2021-10-30 05:15:20.288733: validation loss: -0.8182\n",
      "2021-10-30 05:15:20.292910: Average global foreground Dice: [0.8325]\n",
      "2021-10-30 05:15:20.298607: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:15:20.774908: lr: 0.009458\n",
      "2021-10-30 05:15:20.813978: saving checkpoint...\n",
      "2021-10-30 05:15:21.567871: done, saving took 0.77 seconds\n",
      "2021-10-30 05:15:22.024080: This epoch took 187.386230 s\n",
      "\n",
      "2021-10-30 05:15:22.044806: \n",
      "epoch:  6\n",
      "2021-10-30 05:18:14.479959: train loss : -0.8271\n",
      "2021-10-30 05:18:27.646819: validation loss: -0.8222\n",
      "2021-10-30 05:18:27.650467: Average global foreground Dice: [0.8343]\n",
      "2021-10-30 05:18:27.656315: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:18:28.137845: lr: 0.009368\n",
      "2021-10-30 05:18:28.177708: saving checkpoint...\n",
      "2021-10-30 05:18:28.921807: done, saving took 0.77 seconds\n",
      "2021-10-30 05:18:29.324458: This epoch took 187.271694 s\n",
      "\n",
      "2021-10-30 05:18:29.332809: \n",
      "epoch:  7\n",
      "2021-10-30 05:21:21.753144: train loss : -0.8318\n",
      "2021-10-30 05:21:34.938675: validation loss: -0.8234\n",
      "2021-10-30 05:21:34.943885: Average global foreground Dice: [0.8355]\n",
      "2021-10-30 05:21:34.950966: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:21:35.500734: lr: 0.009277\n",
      "2021-10-30 05:21:35.538409: saving checkpoint...\n",
      "2021-10-30 05:21:36.214490: done, saving took 0.70 seconds\n",
      "2021-10-30 05:21:36.618042: This epoch took 187.279322 s\n",
      "\n",
      "2021-10-30 05:21:36.625971: \n",
      "epoch:  8\n",
      "2021-10-30 05:24:29.267808: train loss : -0.8384\n",
      "2021-10-30 05:24:42.466532: validation loss: -0.8284\n",
      "2021-10-30 05:24:42.471667: Average global foreground Dice: [0.8396]\n",
      "2021-10-30 05:24:42.477828: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:24:42.960881: lr: 0.009186\n",
      "2021-10-30 05:24:43.002129: saving checkpoint...\n",
      "2021-10-30 05:24:43.737437: done, saving took 0.75 seconds\n",
      "2021-10-30 05:24:44.165033: This epoch took 187.532462 s\n",
      "\n",
      "2021-10-30 05:24:44.173936: \n",
      "epoch:  9\n",
      "2021-10-30 05:27:36.915429: train loss : -0.8411\n",
      "2021-10-30 05:27:50.104235: validation loss: -0.8319\n",
      "2021-10-30 05:27:50.107938: Average global foreground Dice: [0.8435]\n",
      "2021-10-30 05:27:50.115101: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:27:50.588690: lr: 0.009095\n",
      "2021-10-30 05:27:50.627858: saving checkpoint...\n",
      "2021-10-30 05:27:51.359450: done, saving took 0.75 seconds\n",
      "2021-10-30 05:27:51.742609: This epoch took 187.561981 s\n",
      "\n",
      "2021-10-30 05:27:51.750690: \n",
      "epoch:  10\n",
      "2021-10-30 05:30:44.740905: train loss : -0.8441\n",
      "2021-10-30 05:30:57.932547: validation loss: -0.8272\n",
      "2021-10-30 05:30:57.936357: Average global foreground Dice: [0.8387]\n",
      "2021-10-30 05:30:57.943082: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:30:58.425433: lr: 0.009004\n",
      "2021-10-30 05:30:58.463767: saving checkpoint...\n",
      "2021-10-30 05:30:59.198277: done, saving took 0.75 seconds\n",
      "2021-10-30 05:30:59.698499: This epoch took 187.940283 s\n",
      "\n",
      "2021-10-30 05:30:59.706399: \n",
      "epoch:  11\n",
      "2021-10-30 05:33:52.304312: train loss : -0.8474\n",
      "2021-10-30 05:34:05.494230: validation loss: -0.8319\n",
      "2021-10-30 05:34:05.498338: Average global foreground Dice: [0.8445]\n",
      "2021-10-30 05:34:05.506156: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:34:05.985734: lr: 0.008913\n",
      "2021-10-30 05:34:06.022562: saving checkpoint...\n",
      "2021-10-30 05:34:06.755911: done, saving took 0.75 seconds\n",
      "2021-10-30 05:34:07.186958: This epoch took 187.475046 s\n",
      "\n",
      "2021-10-30 05:34:07.195470: \n",
      "epoch:  12\n",
      "2021-10-30 05:37:00.126413: train loss : -0.8497\n",
      "2021-10-30 05:37:13.313943: validation loss: -0.8262\n",
      "2021-10-30 05:37:13.317636: Average global foreground Dice: [0.8385]\n",
      "2021-10-30 05:37:13.324533: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:37:13.908638: lr: 0.008822\n",
      "2021-10-30 05:37:13.946177: saving checkpoint...\n",
      "2021-10-30 05:37:14.601752: done, saving took 0.67 seconds\n",
      "2021-10-30 05:37:15.062713: This epoch took 187.860098 s\n",
      "\n",
      "2021-10-30 05:37:15.070453: \n",
      "epoch:  13\n",
      "2021-10-30 05:40:08.114590: train loss : -0.8519\n",
      "2021-10-30 05:40:21.299564: validation loss: -0.8407\n",
      "2021-10-30 05:40:21.303117: Average global foreground Dice: [0.8518]\n",
      "2021-10-30 05:40:21.310123: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:40:21.793915: lr: 0.008731\n",
      "2021-10-30 05:40:21.832776: saving checkpoint...\n",
      "2021-10-30 05:40:22.564471: done, saving took 0.75 seconds\n",
      "2021-10-30 05:40:22.991188: This epoch took 187.913230 s\n",
      "\n",
      "2021-10-30 05:40:22.999571: \n",
      "epoch:  14\n",
      "2021-10-30 05:43:15.994836: train loss : -0.8540\n",
      "2021-10-30 05:43:29.187510: validation loss: -0.8404\n",
      "2021-10-30 05:43:29.190842: Average global foreground Dice: [0.8515]\n",
      "2021-10-30 05:43:29.196482: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:43:29.685138: lr: 0.008639\n",
      "2021-10-30 05:43:29.722044: saving checkpoint...\n",
      "2021-10-30 05:43:30.463817: done, saving took 0.76 seconds\n",
      "2021-10-30 05:43:30.864989: This epoch took 187.858808 s\n",
      "\n",
      "2021-10-30 05:43:30.875394: \n",
      "epoch:  15\n",
      "2021-10-30 05:46:24.035842: train loss : -0.8555\n",
      "2021-10-30 05:46:37.218374: validation loss: -0.8395\n",
      "2021-10-30 05:46:37.222330: Average global foreground Dice: [0.8514]\n",
      "2021-10-30 05:46:37.228683: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:46:37.709444: lr: 0.008548\n",
      "2021-10-30 05:46:37.748268: saving checkpoint...\n",
      "2021-10-30 05:46:38.497380: done, saving took 0.77 seconds\n",
      "2021-10-30 05:46:38.920549: This epoch took 188.037770 s\n",
      "\n",
      "2021-10-30 05:46:38.928884: \n",
      "epoch:  16\n",
      "2021-10-30 05:49:32.510960: train loss : -0.8585\n",
      "2021-10-30 05:49:45.688849: validation loss: -0.8292\n",
      "2021-10-30 05:49:45.692353: Average global foreground Dice: [0.8408]\n",
      "2021-10-30 05:49:45.699084: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:49:46.177208: lr: 0.008456\n",
      "2021-10-30 05:49:46.211253: saving checkpoint...\n",
      "2021-10-30 05:49:46.884886: done, saving took 0.69 seconds\n",
      "2021-10-30 05:49:47.281961: This epoch took 188.346585 s\n",
      "\n",
      "2021-10-30 05:49:47.290271: \n",
      "epoch:  17\n",
      "2021-10-30 05:52:40.959759: train loss : -0.8603\n",
      "2021-10-30 05:52:54.162158: validation loss: -0.8376\n",
      "2021-10-30 05:52:54.165930: Average global foreground Dice: [0.848]\n",
      "2021-10-30 05:52:54.172574: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:52:54.722327: lr: 0.008364\n",
      "2021-10-30 05:52:54.762862: saving checkpoint...\n",
      "2021-10-30 05:52:55.536909: done, saving took 0.79 seconds\n",
      "2021-10-30 05:52:55.944511: This epoch took 188.648103 s\n",
      "\n",
      "2021-10-30 05:52:55.952637: \n",
      "epoch:  18\n",
      "2021-10-30 05:55:49.575226: train loss : -0.8635\n",
      "2021-10-30 05:56:02.765357: validation loss: -0.8397\n",
      "2021-10-30 05:56:02.769419: Average global foreground Dice: [0.8491]\n",
      "2021-10-30 05:56:02.776525: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:56:03.265878: lr: 0.008272\n",
      "2021-10-30 05:56:03.304429: saving checkpoint...\n",
      "2021-10-30 05:56:04.044091: done, saving took 0.76 seconds\n",
      "2021-10-30 05:56:04.490886: This epoch took 188.531375 s\n",
      "\n",
      "2021-10-30 05:56:04.499808: \n",
      "epoch:  19\n",
      "2021-10-30 05:58:58.127048: train loss : -0.8631\n",
      "2021-10-30 05:59:11.325929: validation loss: -0.8398\n",
      "2021-10-30 05:59:11.329639: Average global foreground Dice: [0.8498]\n",
      "2021-10-30 05:59:11.335650: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 05:59:11.817687: lr: 0.008181\n",
      "2021-10-30 05:59:11.855094: saving checkpoint...\n",
      "2021-10-30 05:59:12.589023: done, saving took 0.75 seconds\n",
      "2021-10-30 05:59:13.030025: This epoch took 188.523964 s\n",
      "\n",
      "2021-10-30 05:59:13.038150: \n",
      "epoch:  20\n",
      "2021-10-30 06:02:06.695337: train loss : -0.8634\n",
      "2021-10-30 06:02:19.898272: validation loss: -0.8392\n",
      "2021-10-30 06:02:19.902463: Average global foreground Dice: [0.8501]\n",
      "2021-10-30 06:02:19.910209: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:02:20.389325: lr: 0.008088\n",
      "2021-10-30 06:02:20.430385: saving checkpoint...\n",
      "2021-10-30 06:02:21.092433: done, saving took 0.68 seconds\n",
      "2021-10-30 06:02:21.489019: This epoch took 188.443275 s\n",
      "\n",
      "2021-10-30 06:02:21.497646: \n",
      "epoch:  21\n",
      "2021-10-30 06:05:15.179028: train loss : -0.8661\n",
      "2021-10-30 06:05:28.379163: validation loss: -0.8298\n",
      "2021-10-30 06:05:28.383022: Average global foreground Dice: [0.8415]\n",
      "2021-10-30 06:05:28.389703: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:05:28.872513: lr: 0.007996\n",
      "2021-10-30 06:05:28.905036: saving checkpoint...\n",
      "2021-10-30 06:05:29.650547: done, saving took 0.76 seconds\n",
      "2021-10-30 06:05:30.074471: This epoch took 188.569540 s\n",
      "\n",
      "2021-10-30 06:05:30.083100: \n",
      "epoch:  22\n",
      "2021-10-30 06:08:23.789274: train loss : -0.8674\n",
      "2021-10-30 06:08:37.014567: validation loss: -0.8328\n",
      "2021-10-30 06:08:37.018306: Average global foreground Dice: [0.843]\n",
      "2021-10-30 06:08:37.024554: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:08:37.575885: lr: 0.007904\n",
      "2021-10-30 06:08:37.615331: saving checkpoint...\n",
      "2021-10-30 06:08:38.361562: done, saving took 0.77 seconds\n",
      "2021-10-30 06:08:38.797217: This epoch took 188.706800 s\n",
      "\n",
      "2021-10-30 06:08:38.805327: \n",
      "epoch:  23\n",
      "2021-10-30 06:11:32.638015: train loss : -0.8688\n",
      "2021-10-30 06:11:45.822108: validation loss: -0.8379\n",
      "2021-10-30 06:11:45.825905: Average global foreground Dice: [0.849]\n",
      "2021-10-30 06:11:45.833677: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:11:46.309710: lr: 0.007811\n",
      "2021-10-30 06:11:46.348219: saving checkpoint...\n",
      "2021-10-30 06:11:47.095125: done, saving took 0.77 seconds\n",
      "2021-10-30 06:11:47.483337: This epoch took 188.670127 s\n",
      "\n",
      "2021-10-30 06:11:47.491153: \n",
      "epoch:  24\n",
      "2021-10-30 06:14:41.462967: train loss : -0.8706\n",
      "2021-10-30 06:14:54.658964: validation loss: -0.8351\n",
      "2021-10-30 06:14:54.664780: Average global foreground Dice: [0.8471]\n",
      "2021-10-30 06:14:54.671849: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:14:55.196840: lr: 0.007719\n",
      "2021-10-30 06:14:55.231863: saving checkpoint...\n",
      "2021-10-30 06:14:55.892109: done, saving took 0.68 seconds\n",
      "2021-10-30 06:14:56.301878: This epoch took 188.804416 s\n",
      "\n",
      "2021-10-30 06:14:56.310849: \n",
      "epoch:  25\n",
      "2021-10-30 06:17:50.143311: train loss : -0.8704\n",
      "2021-10-30 06:18:03.307247: validation loss: -0.8362\n",
      "2021-10-30 06:18:03.311014: Average global foreground Dice: [0.8475]\n",
      "2021-10-30 06:18:03.317681: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:18:03.796336: lr: 0.007626\n",
      "2021-10-30 06:18:03.834884: saving checkpoint...\n",
      "2021-10-30 06:18:04.572911: done, saving took 0.76 seconds\n",
      "2021-10-30 06:18:05.038789: This epoch took 188.721474 s\n",
      "\n",
      "2021-10-30 06:18:05.047138: \n",
      "epoch:  26\n",
      "2021-10-30 06:20:58.984641: train loss : -0.8718\n",
      "2021-10-30 06:21:12.179821: validation loss: -0.8361\n",
      "2021-10-30 06:21:12.184147: Average global foreground Dice: [0.8461]\n",
      "2021-10-30 06:21:12.192048: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:21:12.670254: lr: 0.007533\n",
      "2021-10-30 06:21:12.706012: saving checkpoint...\n",
      "2021-10-30 06:21:13.451711: done, saving took 0.76 seconds\n",
      "2021-10-30 06:21:13.882154: This epoch took 188.828197 s\n",
      "\n",
      "2021-10-30 06:21:13.890392: \n",
      "epoch:  27\n",
      "2021-10-30 06:24:07.805953: train loss : -0.8735\n",
      "2021-10-30 06:24:20.995869: validation loss: -0.8336\n",
      "2021-10-30 06:24:20.999532: Average global foreground Dice: [0.844]\n",
      "2021-10-30 06:24:21.007033: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:24:21.557188: lr: 0.00744\n",
      "2021-10-30 06:24:21.618109: saving checkpoint...\n",
      "2021-10-30 06:24:22.345972: done, saving took 0.75 seconds\n",
      "2021-10-30 06:24:22.735254: This epoch took 188.837857 s\n",
      "\n",
      "2021-10-30 06:24:22.743906: \n",
      "epoch:  28\n",
      "2021-10-30 06:27:16.763102: train loss : -0.8740\n",
      "2021-10-30 06:27:29.973654: validation loss: -0.8392\n",
      "2021-10-30 06:27:29.977340: Average global foreground Dice: [0.8484]\n",
      "2021-10-30 06:27:29.984564: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:27:30.467540: lr: 0.007347\n",
      "2021-10-30 06:27:30.506098: saving checkpoint...\n",
      "2021-10-30 06:27:31.264127: done, saving took 0.78 seconds\n",
      "2021-10-30 06:27:31.788863: This epoch took 189.038053 s\n",
      "\n",
      "2021-10-30 06:27:31.797045: \n",
      "epoch:  29\n",
      "2021-10-30 06:30:25.928605: train loss : -0.8758\n",
      "2021-10-30 06:30:39.115802: validation loss: -0.8349\n",
      "2021-10-30 06:30:39.119642: Average global foreground Dice: [0.8453]\n",
      "2021-10-30 06:30:39.126794: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:30:39.604273: lr: 0.007254\n",
      "2021-10-30 06:30:39.642695: saving checkpoint...\n",
      "2021-10-30 06:30:40.317784: done, saving took 0.69 seconds\n",
      "2021-10-30 06:30:40.707684: This epoch took 188.904175 s\n",
      "\n",
      "2021-10-30 06:30:40.715974: \n",
      "epoch:  30\n",
      "2021-10-30 06:33:34.902727: train loss : -0.8760\n",
      "2021-10-30 06:33:48.085464: validation loss: -0.8295\n",
      "2021-10-30 06:33:48.089066: Average global foreground Dice: [0.8405]\n",
      "2021-10-30 06:33:48.095591: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:33:48.579425: lr: 0.007161\n",
      "2021-10-30 06:33:48.612530: saving checkpoint...\n",
      "2021-10-30 06:33:49.355299: done, saving took 0.76 seconds\n",
      "2021-10-30 06:33:49.806624: This epoch took 189.084120 s\n",
      "\n",
      "2021-10-30 06:33:49.814670: \n",
      "epoch:  31\n",
      "2021-10-30 06:36:44.181362: train loss : -0.8771\n",
      "2021-10-30 06:36:57.374696: validation loss: -0.8354\n",
      "2021-10-30 06:36:57.378464: Average global foreground Dice: [0.8465]\n",
      "2021-10-30 06:36:57.385264: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:36:57.869577: lr: 0.007067\n",
      "2021-10-30 06:36:57.906677: saving checkpoint...\n",
      "2021-10-30 06:36:58.652689: done, saving took 0.77 seconds\n",
      "2021-10-30 06:36:59.052650: This epoch took 189.231147 s\n",
      "\n",
      "2021-10-30 06:36:59.061023: \n",
      "epoch:  32\n",
      "2021-10-30 06:39:53.525140: train loss : -0.8774\n",
      "2021-10-30 06:40:06.704573: validation loss: -0.8352\n",
      "2021-10-30 06:40:06.708402: Average global foreground Dice: [0.8461]\n",
      "2021-10-30 06:40:06.715103: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:40:07.262895: lr: 0.006974\n",
      "2021-10-30 06:40:07.301265: saving checkpoint...\n",
      "2021-10-30 06:40:08.042475: done, saving took 0.76 seconds\n",
      "2021-10-30 06:40:08.486660: This epoch took 189.418850 s\n",
      "\n",
      "2021-10-30 06:40:08.495416: \n",
      "epoch:  33\n",
      "2021-10-30 06:43:02.924849: train loss : -0.8785\n",
      "2021-10-30 06:43:16.106094: validation loss: -0.8361\n",
      "2021-10-30 06:43:16.109612: Average global foreground Dice: [0.8462]\n",
      "2021-10-30 06:43:16.116118: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:43:16.596483: lr: 0.00688\n",
      "2021-10-30 06:43:16.630828: saving checkpoint...\n",
      "2021-10-30 06:43:17.300087: done, saving took 0.69 seconds\n",
      "2021-10-30 06:43:17.717281: This epoch took 189.215111 s\n",
      "\n",
      "2021-10-30 06:43:17.725398: \n",
      "epoch:  34\n",
      "2021-10-30 06:46:12.377806: train loss : -0.8811\n",
      "2021-10-30 06:46:25.568427: validation loss: -0.8424\n",
      "2021-10-30 06:46:25.572189: Average global foreground Dice: [0.853]\n",
      "2021-10-30 06:46:25.578835: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:46:26.067195: lr: 0.006786\n",
      "2021-10-30 06:46:26.104316: saving checkpoint...\n",
      "2021-10-30 06:46:26.855875: done, saving took 0.77 seconds\n",
      "2021-10-30 06:46:27.275111: This epoch took 189.542296 s\n",
      "\n",
      "2021-10-30 06:46:27.283117: \n",
      "epoch:  35\n",
      "2021-10-30 06:49:21.901753: train loss : -0.8805\n",
      "2021-10-30 06:49:35.101866: validation loss: -0.8362\n",
      "2021-10-30 06:49:35.111648: Average global foreground Dice: [0.8452]\n",
      "2021-10-30 06:49:35.117659: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:49:35.600879: lr: 0.006692\n",
      "2021-10-30 06:49:35.641755: saving checkpoint...\n",
      "2021-10-30 06:49:36.401166: done, saving took 0.78 seconds\n",
      "2021-10-30 06:49:36.820202: This epoch took 189.530057 s\n",
      "\n",
      "2021-10-30 06:49:36.827911: \n",
      "epoch:  36\n",
      "2021-10-30 06:52:31.382090: train loss : -0.8833\n",
      "2021-10-30 06:52:44.596860: validation loss: -0.8347\n",
      "2021-10-30 06:52:44.600863: Average global foreground Dice: [0.8448]\n",
      "2021-10-30 06:52:44.606468: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:52:45.094306: lr: 0.006598\n",
      "2021-10-30 06:52:45.143009: saving checkpoint...\n",
      "2021-10-30 06:52:45.898329: done, saving took 0.79 seconds\n",
      "2021-10-30 06:52:46.273361: This epoch took 189.438380 s\n",
      "\n",
      "2021-10-30 06:52:46.281866: \n",
      "epoch:  37\n",
      "2021-10-30 06:55:40.935328: train loss : -0.8824\n",
      "2021-10-30 06:55:54.138649: validation loss: -0.8347\n",
      "2021-10-30 06:55:54.142377: Average global foreground Dice: [0.846]\n",
      "2021-10-30 06:55:54.148860: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:55:54.700149: lr: 0.006504\n",
      "2021-10-30 06:55:54.740287: saving checkpoint...\n",
      "2021-10-30 06:55:55.393894: done, saving took 0.67 seconds\n",
      "2021-10-30 06:55:55.814865: This epoch took 189.526842 s\n",
      "\n",
      "2021-10-30 06:55:55.822844: \n",
      "epoch:  38\n",
      "2021-10-30 06:58:50.554689: train loss : -0.8826\n",
      "2021-10-30 06:59:03.749916: validation loss: -0.8343\n",
      "2021-10-30 06:59:03.754340: Average global foreground Dice: [0.8445]\n",
      "2021-10-30 06:59:03.761183: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 06:59:04.243414: lr: 0.006409\n",
      "2021-10-30 06:59:04.279847: saving checkpoint...\n",
      "2021-10-30 06:59:05.013078: done, saving took 0.75 seconds\n",
      "2021-10-30 06:59:05.412575: This epoch took 189.582711 s\n",
      "\n",
      "2021-10-30 06:59:05.420914: \n",
      "epoch:  39\n",
      "2021-10-30 07:02:00.179686: train loss : -0.8833\n",
      "2021-10-30 07:02:13.398295: validation loss: -0.8352\n",
      "2021-10-30 07:02:13.402585: Average global foreground Dice: [0.8451]\n",
      "2021-10-30 07:02:13.410233: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:02:13.895798: lr: 0.006314\n",
      "2021-10-30 07:02:13.932876: saving checkpoint...\n",
      "2021-10-30 07:02:14.665533: done, saving took 0.75 seconds\n",
      "2021-10-30 07:02:15.066899: This epoch took 189.639514 s\n",
      "\n",
      "2021-10-30 07:02:15.075059: \n",
      "epoch:  40\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-30 07:05:09.976255: train loss : -0.8846\n",
      "2021-10-30 07:05:23.185421: validation loss: -0.8368\n",
      "2021-10-30 07:05:23.189225: Average global foreground Dice: [0.8468]\n",
      "2021-10-30 07:05:23.196790: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:05:23.683468: lr: 0.00622\n",
      "2021-10-30 07:05:23.729112: saving checkpoint...\n",
      "2021-10-30 07:05:24.473235: done, saving took 0.76 seconds\n",
      "2021-10-30 07:05:24.909958: This epoch took 189.827083 s\n",
      "\n",
      "2021-10-30 07:05:24.917549: \n",
      "epoch:  41\n",
      "2021-10-30 07:08:19.587950: train loss : -0.8863\n",
      "2021-10-30 07:08:32.786695: validation loss: -0.8410\n",
      "2021-10-30 07:08:32.790349: Average global foreground Dice: [0.8507]\n",
      "2021-10-30 07:08:32.798335: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:08:33.285253: lr: 0.006125\n",
      "2021-10-30 07:08:33.329741: saving checkpoint...\n",
      "2021-10-30 07:08:34.074270: done, saving took 0.77 seconds\n",
      "2021-10-30 07:08:34.519404: This epoch took 189.594712 s\n",
      "\n",
      "2021-10-30 07:08:34.527129: \n",
      "epoch:  42\n",
      "2021-10-30 07:11:29.166018: train loss : -0.8868\n",
      "2021-10-30 07:11:42.369864: validation loss: -0.8418\n",
      "2021-10-30 07:11:42.373257: Average global foreground Dice: [0.8509]\n",
      "2021-10-30 07:11:42.379942: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:11:42.933655: lr: 0.00603\n",
      "2021-10-30 07:11:42.971582: saving checkpoint...\n",
      "2021-10-30 07:11:43.710699: done, saving took 0.76 seconds\n",
      "2021-10-30 07:11:44.135304: This epoch took 189.600691 s\n",
      "\n",
      "2021-10-30 07:11:44.143322: \n",
      "epoch:  43\n",
      "2021-10-30 07:14:38.960894: train loss : -0.8878\n",
      "2021-10-30 07:14:52.140082: validation loss: -0.8401\n",
      "2021-10-30 07:14:52.145581: Average global foreground Dice: [0.8495]\n",
      "2021-10-30 07:14:52.152419: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:14:52.681271: lr: 0.005934\n",
      "2021-10-30 07:14:52.718307: saving checkpoint...\n",
      "2021-10-30 07:14:53.464907: done, saving took 0.77 seconds\n",
      "2021-10-30 07:14:53.867287: This epoch took 189.716533 s\n",
      "\n",
      "2021-10-30 07:14:53.875362: \n",
      "epoch:  44\n",
      "2021-10-30 07:17:48.527817: train loss : -0.8878\n",
      "2021-10-30 07:18:01.715810: validation loss: -0.8343\n",
      "2021-10-30 07:18:01.719597: Average global foreground Dice: [0.8438]\n",
      "2021-10-30 07:18:01.726052: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:18:02.202854: lr: 0.005839\n",
      "2021-10-30 07:18:02.221874: This epoch took 188.339581 s\n",
      "\n",
      "2021-10-30 07:18:02.229449: \n",
      "epoch:  45\n",
      "2021-10-30 07:20:56.835711: train loss : -0.8868\n",
      "2021-10-30 07:21:10.037886: validation loss: -0.8417\n",
      "2021-10-30 07:21:10.041457: Average global foreground Dice: [0.8501]\n",
      "2021-10-30 07:21:10.048963: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:21:10.538941: lr: 0.005743\n",
      "2021-10-30 07:21:10.580320: saving checkpoint...\n",
      "2021-10-30 07:21:11.325685: done, saving took 0.76 seconds\n",
      "2021-10-30 07:21:11.727698: This epoch took 189.491761 s\n",
      "\n",
      "2021-10-30 07:21:11.736488: \n",
      "epoch:  46\n",
      "2021-10-30 07:24:06.306242: train loss : -0.8886\n",
      "2021-10-30 07:24:19.501367: validation loss: -0.8441\n",
      "2021-10-30 07:24:19.505763: Average global foreground Dice: [0.8524]\n",
      "2021-10-30 07:24:19.513999: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:24:19.997956: lr: 0.005647\n",
      "2021-10-30 07:24:20.048334: saving checkpoint...\n",
      "2021-10-30 07:24:20.726499: done, saving took 0.71 seconds\n",
      "2021-10-30 07:24:21.240121: This epoch took 189.496583 s\n",
      "\n",
      "2021-10-30 07:24:21.249679: \n",
      "epoch:  47\n",
      "2021-10-30 07:27:16.022604: train loss : -0.8915\n",
      "2021-10-30 07:27:29.219669: validation loss: -0.8455\n",
      "2021-10-30 07:27:29.223503: Average global foreground Dice: [0.8535]\n",
      "2021-10-30 07:27:29.230344: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:27:29.775295: lr: 0.005551\n",
      "2021-10-30 07:27:29.813474: saving checkpoint...\n",
      "2021-10-30 07:27:30.570544: done, saving took 0.78 seconds\n",
      "2021-10-30 07:27:31.017497: This epoch took 189.760244 s\n",
      "\n",
      "2021-10-30 07:27:31.025718: \n",
      "epoch:  48\n",
      "2021-10-30 07:30:25.707974: train loss : -0.8912\n",
      "2021-10-30 07:30:38.888835: validation loss: -0.8428\n",
      "2021-10-30 07:30:38.892693: Average global foreground Dice: [0.8522]\n",
      "2021-10-30 07:30:38.902036: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:30:39.390658: lr: 0.005455\n",
      "2021-10-30 07:30:39.423004: saving checkpoint...\n",
      "2021-10-30 07:30:40.174279: done, saving took 0.77 seconds\n",
      "2021-10-30 07:30:40.640792: This epoch took 189.608205 s\n",
      "\n",
      "2021-10-30 07:30:40.649456: \n",
      "epoch:  49\n",
      "2021-10-30 07:33:35.221119: train loss : -0.8897\n",
      "2021-10-30 07:33:48.417709: validation loss: -0.8373\n",
      "2021-10-30 07:33:48.421444: Average global foreground Dice: [0.8468]\n",
      "2021-10-30 07:33:48.427573: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:33:48.919551: lr: 0.005359\n",
      "2021-10-30 07:33:48.937462: saving scheduled checkpoint file...\n",
      "2021-10-30 07:33:48.963328: saving checkpoint...\n",
      "2021-10-30 07:33:49.561538: done, saving took 0.62 seconds\n",
      "2021-10-30 07:33:50.042347: done\n",
      "2021-10-30 07:33:50.050673: This epoch took 189.393623 s\n",
      "\n",
      "2021-10-30 07:33:50.058495: \n",
      "epoch:  50\n",
      "2021-10-30 07:36:44.538513: train loss : -0.8930\n",
      "2021-10-30 07:36:57.738309: validation loss: -0.8399\n",
      "2021-10-30 07:36:57.743784: Average global foreground Dice: [0.8484]\n",
      "2021-10-30 07:36:57.750565: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:36:58.235750: lr: 0.005262\n",
      "2021-10-30 07:36:58.251862: This epoch took 188.187533 s\n",
      "\n",
      "2021-10-30 07:36:58.259323: \n",
      "epoch:  51\n",
      "2021-10-30 07:39:52.918001: train loss : -0.8922\n",
      "2021-10-30 07:40:06.117867: validation loss: -0.8383\n",
      "2021-10-30 07:40:06.121727: Average global foreground Dice: [0.847]\n",
      "2021-10-30 07:40:06.128800: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:40:06.617988: lr: 0.005166\n",
      "2021-10-30 07:40:06.638554: This epoch took 188.372740 s\n",
      "\n",
      "2021-10-30 07:40:06.644516: \n",
      "epoch:  52\n",
      "2021-10-30 07:43:01.130237: train loss : -0.8931\n",
      "2021-10-30 07:43:14.289933: validation loss: -0.8385\n",
      "2021-10-30 07:43:14.293390: Average global foreground Dice: [0.8479]\n",
      "2021-10-30 07:43:14.299904: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:43:14.787443: lr: 0.005069\n",
      "2021-10-30 07:43:14.806265: This epoch took 188.154570 s\n",
      "\n",
      "2021-10-30 07:43:14.813310: \n",
      "epoch:  53\n",
      "2021-10-30 07:46:09.275750: train loss : -0.8933\n",
      "2021-10-30 07:46:22.460571: validation loss: -0.8310\n",
      "2021-10-30 07:46:22.464980: Average global foreground Dice: [0.8389]\n",
      "2021-10-30 07:46:22.472001: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:46:22.964431: lr: 0.004971\n",
      "2021-10-30 07:46:22.985516: This epoch took 188.165125 s\n",
      "\n",
      "2021-10-30 07:46:22.992630: \n",
      "epoch:  54\n",
      "2021-10-30 07:49:17.434257: train loss : -0.8938\n",
      "2021-10-30 07:49:30.608471: validation loss: -0.8374\n",
      "2021-10-30 07:49:30.612815: Average global foreground Dice: [0.8472]\n",
      "2021-10-30 07:49:30.619576: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:49:31.101559: lr: 0.004874\n",
      "2021-10-30 07:49:31.120551: This epoch took 188.121248 s\n",
      "\n",
      "2021-10-30 07:49:31.127515: \n",
      "epoch:  55\n",
      "2021-10-30 07:52:25.768057: train loss : -0.8953\n",
      "2021-10-30 07:52:38.944473: validation loss: -0.8416\n",
      "2021-10-30 07:52:38.947985: Average global foreground Dice: [0.851]\n",
      "2021-10-30 07:52:38.954395: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:52:39.442822: lr: 0.004776\n",
      "2021-10-30 07:52:39.464712: This epoch took 188.330327 s\n",
      "\n",
      "2021-10-30 07:52:39.471117: \n",
      "epoch:  56\n",
      "2021-10-30 07:55:34.377560: train loss : -0.8942\n",
      "2021-10-30 07:55:47.583564: validation loss: -0.8400\n",
      "2021-10-30 07:55:47.587566: Average global foreground Dice: [0.8497]\n",
      "2021-10-30 07:55:47.594687: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:55:48.132222: lr: 0.004679\n",
      "2021-10-30 07:55:48.152075: This epoch took 188.674386 s\n",
      "\n",
      "2021-10-30 07:55:48.159130: \n",
      "epoch:  57\n",
      "2021-10-30 07:58:43.317403: train loss : -0.8949\n",
      "2021-10-30 07:58:56.519905: validation loss: -0.8420\n",
      "2021-10-30 07:58:56.523571: Average global foreground Dice: [0.8515]\n",
      "2021-10-30 07:58:56.530658: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 07:58:57.027147: lr: 0.004581\n",
      "2021-10-30 07:58:57.074680: saving checkpoint...\n",
      "2021-10-30 07:58:57.823688: done, saving took 0.78 seconds\n",
      "2021-10-30 07:58:58.248926: This epoch took 190.083106 s\n",
      "\n",
      "2021-10-30 07:58:58.256985: \n",
      "epoch:  58\n",
      "2021-10-30 08:01:53.269346: train loss : -0.8968\n",
      "2021-10-30 08:02:06.453254: validation loss: -0.8393\n",
      "2021-10-30 08:02:06.457096: Average global foreground Dice: [0.8494]\n",
      "2021-10-30 08:02:06.464011: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:02:07.013172: lr: 0.004482\n",
      "2021-10-30 08:02:07.053253: saving checkpoint...\n",
      "2021-10-30 08:02:07.791410: done, saving took 0.76 seconds\n",
      "2021-10-30 08:02:08.228861: This epoch took 189.964930 s\n",
      "\n",
      "2021-10-30 08:02:08.237364: \n",
      "epoch:  59\n",
      "2021-10-30 08:05:03.307654: train loss : -0.8962\n",
      "2021-10-30 08:05:16.506297: validation loss: -0.8349\n",
      "2021-10-30 08:05:16.510197: Average global foreground Dice: [0.8463]\n",
      "2021-10-30 08:05:16.516636: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:05:17.004869: lr: 0.004384\n",
      "2021-10-30 08:05:17.024227: This epoch took 188.780162 s\n",
      "\n",
      "2021-10-30 08:05:17.030604: \n",
      "epoch:  60\n",
      "2021-10-30 08:08:12.097243: train loss : -0.8970\n",
      "2021-10-30 08:08:25.304869: validation loss: -0.8395\n",
      "2021-10-30 08:08:25.308941: Average global foreground Dice: [0.8472]\n",
      "2021-10-30 08:08:25.315662: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:08:25.801435: lr: 0.004285\n",
      "2021-10-30 08:08:25.818539: This epoch took 188.780747 s\n",
      "\n",
      "2021-10-30 08:08:25.825576: \n",
      "epoch:  61\n",
      "2021-10-30 08:11:20.711796: train loss : -0.8990\n",
      "2021-10-30 08:11:33.904369: validation loss: -0.8353\n",
      "2021-10-30 08:11:33.909472: Average global foreground Dice: [0.8455]\n",
      "2021-10-30 08:11:33.917150: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:11:34.403706: lr: 0.004186\n",
      "2021-10-30 08:11:34.421984: This epoch took 188.589108 s\n",
      "\n",
      "2021-10-30 08:11:34.428746: \n",
      "epoch:  62\n",
      "2021-10-30 08:14:29.163542: train loss : -0.8985\n",
      "2021-10-30 08:14:42.359831: validation loss: -0.8403\n",
      "2021-10-30 08:14:42.365520: Average global foreground Dice: [0.8489]\n",
      "2021-10-30 08:14:42.372698: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:14:42.876235: lr: 0.004087\n",
      "2021-10-30 08:14:42.896516: This epoch took 188.460830 s\n",
      "\n",
      "2021-10-30 08:14:42.903562: \n",
      "epoch:  63\n",
      "2021-10-30 08:17:37.620671: train loss : -0.8989\n",
      "2021-10-30 08:17:50.822041: validation loss: -0.8381\n",
      "2021-10-30 08:17:50.825719: Average global foreground Dice: [0.8475]\n",
      "2021-10-30 08:17:50.833447: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:17:51.384543: lr: 0.003987\n",
      "2021-10-30 08:17:51.404300: This epoch took 188.493395 s\n",
      "\n",
      "2021-10-30 08:17:51.410473: \n",
      "epoch:  64\n",
      "2021-10-30 08:20:46.235242: train loss : -0.9003\n",
      "2021-10-30 08:20:59.481608: validation loss: -0.8398\n",
      "2021-10-30 08:20:59.485562: Average global foreground Dice: [0.8482]\n",
      "2021-10-30 08:20:59.491785: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:20:59.984609: lr: 0.003887\n",
      "2021-10-30 08:21:00.004517: This epoch took 188.587748 s\n",
      "\n",
      "2021-10-30 08:21:00.010571: \n",
      "epoch:  65\n",
      "2021-10-30 08:23:54.943499: train loss : -0.9007\n",
      "2021-10-30 08:24:08.150110: validation loss: -0.8422\n",
      "2021-10-30 08:24:08.153764: Average global foreground Dice: [0.8519]\n",
      "2021-10-30 08:24:08.160109: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:24:08.649629: lr: 0.003787\n",
      "2021-10-30 08:24:08.686302: saving checkpoint...\n",
      "2021-10-30 08:24:09.421931: done, saving took 0.75 seconds\n",
      "2021-10-30 08:24:09.817730: This epoch took 189.799989 s\n",
      "\n",
      "2021-10-30 08:24:09.826866: \n",
      "epoch:  66\n",
      "2021-10-30 08:27:04.651809: train loss : -0.9011\n",
      "2021-10-30 08:27:17.878207: validation loss: -0.8404\n",
      "2021-10-30 08:27:17.882071: Average global foreground Dice: [0.8491]\n",
      "2021-10-30 08:27:17.888673: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:27:18.425847: lr: 0.003687\n",
      "2021-10-30 08:27:18.467820: saving checkpoint...\n",
      "2021-10-30 08:27:19.206941: done, saving took 0.76 seconds\n",
      "2021-10-30 08:27:19.642651: This epoch took 189.808910 s\n",
      "\n",
      "2021-10-30 08:27:19.651169: \n",
      "epoch:  67\n",
      "2021-10-30 08:30:14.307038: train loss : -0.9007\n",
      "2021-10-30 08:30:27.515334: validation loss: -0.8409\n",
      "2021-10-30 08:30:27.518964: Average global foreground Dice: [0.8494]\n",
      "2021-10-30 08:30:27.526137: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:30:28.027940: lr: 0.003586\n",
      "2021-10-30 08:30:28.064745: saving checkpoint...\n",
      "2021-10-30 08:30:28.815282: done, saving took 0.77 seconds\n",
      "2021-10-30 08:30:29.214590: This epoch took 189.556267 s\n",
      "\n",
      "2021-10-30 08:30:29.222782: \n",
      "epoch:  68\n",
      "2021-10-30 08:33:23.883244: train loss : -0.9018\n",
      "2021-10-30 08:33:37.069551: validation loss: -0.8405\n",
      "2021-10-30 08:33:37.073728: Average global foreground Dice: [0.8489]\n",
      "2021-10-30 08:33:37.080627: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:33:37.637854: lr: 0.003485\n",
      "2021-10-30 08:33:37.678153: saving checkpoint...\n",
      "2021-10-30 08:33:38.355834: done, saving took 0.70 seconds\n",
      "2021-10-30 08:33:38.755345: This epoch took 189.525801 s\n",
      "\n",
      "2021-10-30 08:33:38.763046: \n",
      "epoch:  69\n",
      "2021-10-30 08:36:33.401575: train loss : -0.9020\n",
      "2021-10-30 08:36:46.591804: validation loss: -0.8440\n",
      "2021-10-30 08:36:46.596074: Average global foreground Dice: [0.8521]\n",
      "2021-10-30 08:36:46.603720: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:36:47.096189: lr: 0.003384\n",
      "2021-10-30 08:36:47.134351: saving checkpoint...\n",
      "2021-10-30 08:36:47.895098: done, saving took 0.78 seconds\n",
      "2021-10-30 08:36:48.289923: This epoch took 189.519596 s\n",
      "\n",
      "2021-10-30 08:36:48.298447: \n",
      "epoch:  70\n",
      "2021-10-30 08:39:43.069144: train loss : -0.9039\n",
      "2021-10-30 08:39:56.253165: validation loss: -0.8381\n",
      "2021-10-30 08:39:56.257049: Average global foreground Dice: [0.8473]\n",
      "2021-10-30 08:39:56.264216: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:39:56.751119: lr: 0.003282\n",
      "2021-10-30 08:39:56.771731: This epoch took 188.466942 s\n",
      "\n",
      "2021-10-30 08:39:56.778648: \n",
      "epoch:  71\n",
      "2021-10-30 08:42:51.589427: train loss : -0.9035\n",
      "2021-10-30 08:43:04.782773: validation loss: -0.8382\n",
      "2021-10-30 08:43:04.787577: Average global foreground Dice: [0.8472]\n",
      "2021-10-30 08:43:04.794042: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:43:05.332330: lr: 0.00318\n",
      "2021-10-30 08:43:05.350689: This epoch took 188.564931 s\n",
      "\n",
      "2021-10-30 08:43:05.357707: \n",
      "epoch:  72\n",
      "2021-10-30 08:46:00.168014: train loss : -0.9051\n",
      "2021-10-30 08:46:13.343835: validation loss: -0.8421\n",
      "2021-10-30 08:46:13.347910: Average global foreground Dice: [0.8496]\n",
      "2021-10-30 08:46:13.355216: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:46:13.849784: lr: 0.003078\n",
      "2021-10-30 08:46:13.871161: This epoch took 188.506399 s\n",
      "\n",
      "2021-10-30 08:46:13.877821: \n",
      "epoch:  73\n",
      "2021-10-30 08:49:08.601151: train loss : -0.9046\n",
      "2021-10-30 08:49:21.796335: validation loss: -0.8381\n",
      "2021-10-30 08:49:21.800123: Average global foreground Dice: [0.8478]\n",
      "2021-10-30 08:49:21.806592: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:49:22.364410: lr: 0.002975\n",
      "2021-10-30 08:49:22.383037: This epoch took 188.497822 s\n",
      "\n",
      "2021-10-30 08:49:22.389946: \n",
      "epoch:  74\n",
      "2021-10-30 08:52:17.157544: train loss : -0.9055\n",
      "2021-10-30 08:52:30.366097: validation loss: -0.8383\n",
      "2021-10-30 08:52:30.370008: Average global foreground Dice: [0.8473]\n",
      "2021-10-30 08:52:30.376755: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:52:30.863779: lr: 0.002872\n",
      "2021-10-30 08:52:30.884528: This epoch took 188.488444 s\n",
      "\n",
      "2021-10-30 08:52:30.891318: \n",
      "epoch:  75\n",
      "2021-10-30 08:55:25.808528: train loss : -0.9051\n",
      "2021-10-30 08:55:38.988931: validation loss: -0.8409\n",
      "2021-10-30 08:55:38.992754: Average global foreground Dice: [0.8498]\n",
      "2021-10-30 08:55:39.000011: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:55:39.499671: lr: 0.002768\n",
      "2021-10-30 08:55:39.530454: This epoch took 188.631382 s\n",
      "\n",
      "2021-10-30 08:55:39.537944: \n",
      "epoch:  76\n",
      "2021-10-30 08:58:34.530937: train loss : -0.9058\n",
      "2021-10-30 08:58:47.722114: validation loss: -0.8398\n",
      "2021-10-30 08:58:47.726150: Average global foreground Dice: [0.8484]\n",
      "2021-10-30 08:58:47.733365: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 08:58:48.238899: lr: 0.002664\n",
      "2021-10-30 08:58:48.269334: This epoch took 188.723984 s\n",
      "\n",
      "2021-10-30 08:58:48.276665: \n",
      "epoch:  77\n",
      "2021-10-30 09:01:43.316221: train loss : -0.9074\n",
      "2021-10-30 09:01:56.499342: validation loss: -0.8389\n",
      "2021-10-30 09:01:56.503338: Average global foreground Dice: [0.8478]\n",
      "2021-10-30 09:01:56.510014: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:01:56.999530: lr: 0.00256\n",
      "2021-10-30 09:01:57.030106: This epoch took 188.747029 s\n",
      "\n",
      "2021-10-30 09:01:57.037462: \n",
      "epoch:  78\n",
      "2021-10-30 09:04:52.091250: train loss : -0.9064\n",
      "2021-10-30 09:05:05.272854: validation loss: -0.8382\n",
      "2021-10-30 09:05:05.276490: Average global foreground Dice: [0.8472]\n",
      "2021-10-30 09:05:05.282564: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:05:05.784438: lr: 0.002455\n",
      "2021-10-30 09:05:05.805921: This epoch took 188.760940 s\n",
      "\n",
      "2021-10-30 09:05:05.812632: \n",
      "epoch:  79\n",
      "2021-10-30 09:08:01.026221: train loss : -0.9077\n",
      "2021-10-30 09:08:14.223682: validation loss: -0.8378\n",
      "2021-10-30 09:08:14.227369: Average global foreground Dice: [0.8458]\n",
      "2021-10-30 09:08:14.233771: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:08:14.724159: lr: 0.002349\n",
      "2021-10-30 09:08:14.742871: This epoch took 188.923433 s\n",
      "\n",
      "2021-10-30 09:08:14.751179: \n",
      "epoch:  80\n",
      "2021-10-30 09:11:09.949353: train loss : -0.9077\n",
      "2021-10-30 09:11:23.149145: validation loss: -0.8407\n",
      "2021-10-30 09:11:23.153079: Average global foreground Dice: [0.8484]\n",
      "2021-10-30 09:11:23.160923: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:11:23.652974: lr: 0.002243\n",
      "2021-10-30 09:11:23.676725: This epoch took 188.918656 s\n",
      "\n",
      "2021-10-30 09:11:23.683326: \n",
      "epoch:  81\n",
      "2021-10-30 09:14:18.693763: train loss : -0.9089\n",
      "2021-10-30 09:14:31.898714: validation loss: -0.8369\n",
      "2021-10-30 09:14:31.902562: Average global foreground Dice: [0.8458]\n",
      "2021-10-30 09:14:31.909514: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:14:32.403872: lr: 0.002137\n",
      "2021-10-30 09:14:32.424521: This epoch took 188.734274 s\n",
      "\n",
      "2021-10-30 09:14:32.432103: \n",
      "epoch:  82\n",
      "2021-10-30 09:17:27.410442: train loss : -0.9094\n",
      "2021-10-30 09:17:40.616243: validation loss: -0.8390\n",
      "2021-10-30 09:17:40.620072: Average global foreground Dice: [0.8477]\n",
      "2021-10-30 09:17:40.627197: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:17:41.110292: lr: 0.00203\n",
      "2021-10-30 09:17:41.129678: This epoch took 188.688798 s\n",
      "\n",
      "2021-10-30 09:17:41.136700: \n",
      "epoch:  83\n",
      "2021-10-30 09:20:36.041379: train loss : -0.9088\n",
      "2021-10-30 09:20:49.249324: validation loss: -0.8385\n",
      "2021-10-30 09:20:49.253093: Average global foreground Dice: [0.8475]\n",
      "2021-10-30 09:20:49.260457: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:20:49.744187: lr: 0.001922\n",
      "2021-10-30 09:20:49.765883: This epoch took 188.622985 s\n",
      "\n",
      "2021-10-30 09:20:49.772759: \n",
      "epoch:  84\n",
      "2021-10-30 09:23:44.604688: train loss : -0.9111\n",
      "2021-10-30 09:23:57.809337: validation loss: -0.8399\n",
      "2021-10-30 09:23:57.812944: Average global foreground Dice: [0.848]\n",
      "2021-10-30 09:23:57.820031: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:23:58.308521: lr: 0.001813\n",
      "2021-10-30 09:23:58.322754: This epoch took 188.541677 s\n",
      "\n",
      "2021-10-30 09:23:58.329897: \n",
      "epoch:  85\n",
      "2021-10-30 09:26:53.134925: train loss : -0.9110\n",
      "2021-10-30 09:27:06.349915: validation loss: -0.8403\n",
      "2021-10-30 09:27:06.353858: Average global foreground Dice: [0.8485]\n",
      "2021-10-30 09:27:06.360483: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:27:06.842481: lr: 0.001704\n",
      "2021-10-30 09:27:06.874879: This epoch took 188.538315 s\n",
      "\n",
      "2021-10-30 09:27:06.882087: \n",
      "epoch:  86\n",
      "2021-10-30 09:30:01.895972: train loss : -0.9102\n",
      "2021-10-30 09:30:15.078278: validation loss: -0.8376\n",
      "2021-10-30 09:30:15.082856: Average global foreground Dice: [0.8462]\n",
      "2021-10-30 09:30:15.088836: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:30:15.573685: lr: 0.001594\n",
      "2021-10-30 09:30:15.595244: This epoch took 188.705747 s\n",
      "\n",
      "2021-10-30 09:30:15.602612: \n",
      "epoch:  87\n",
      "2021-10-30 09:33:10.514632: train loss : -0.9119\n",
      "2021-10-30 09:33:23.712947: validation loss: -0.8391\n",
      "2021-10-30 09:33:23.717052: Average global foreground Dice: [0.848]\n",
      "2021-10-30 09:33:23.724523: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:33:24.208895: lr: 0.001483\n",
      "2021-10-30 09:33:24.227839: This epoch took 188.618114 s\n",
      "\n",
      "2021-10-30 09:33:24.234564: \n",
      "epoch:  88\n",
      "2021-10-30 09:36:19.587071: train loss : -0.9123\n",
      "2021-10-30 09:36:32.794868: validation loss: -0.8414\n",
      "2021-10-30 09:36:32.798893: Average global foreground Dice: [0.8495]\n",
      "2021-10-30 09:36:32.804842: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:36:33.284929: lr: 0.001372\n",
      "2021-10-30 09:36:33.305274: This epoch took 189.063833 s\n",
      "\n",
      "2021-10-30 09:36:33.311637: \n",
      "epoch:  89\n",
      "2021-10-30 09:39:28.354698: train loss : -0.9121\n",
      "2021-10-30 09:39:41.571941: validation loss: -0.8408\n",
      "2021-10-30 09:39:41.575945: Average global foreground Dice: [0.8489]\n",
      "2021-10-30 09:39:41.581670: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:39:42.143589: lr: 0.001259\n",
      "2021-10-30 09:39:42.163505: This epoch took 188.845039 s\n",
      "\n",
      "2021-10-30 09:39:42.170331: \n",
      "epoch:  90\n",
      "2021-10-30 09:42:37.282094: train loss : -0.9130\n",
      "2021-10-30 09:42:50.458372: validation loss: -0.8381\n",
      "2021-10-30 09:42:50.461882: Average global foreground Dice: [0.8463]\n",
      "2021-10-30 09:42:50.468642: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:42:50.952562: lr: 0.001145\n",
      "2021-10-30 09:42:50.972769: This epoch took 188.795696 s\n",
      "\n",
      "2021-10-30 09:42:50.979650: \n",
      "epoch:  91\n",
      "2021-10-30 09:45:46.234002: train loss : -0.9137\n",
      "2021-10-30 09:45:59.440554: validation loss: -0.8363\n",
      "2021-10-30 09:45:59.444337: Average global foreground Dice: [0.8452]\n",
      "2021-10-30 09:45:59.451204: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:45:59.937200: lr: 0.00103\n",
      "2021-10-30 09:45:59.959647: This epoch took 188.972990 s\n",
      "\n",
      "2021-10-30 09:45:59.966572: \n",
      "epoch:  92\n",
      "2021-10-30 09:48:55.118228: train loss : -0.9139\n",
      "2021-10-30 09:49:08.305984: validation loss: -0.8411\n",
      "2021-10-30 09:49:08.311248: Average global foreground Dice: [0.8491]\n",
      "2021-10-30 09:49:08.318154: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:49:08.805021: lr: 0.000913\n",
      "2021-10-30 09:49:08.825212: This epoch took 188.851928 s\n",
      "\n",
      "2021-10-30 09:49:08.832568: \n",
      "epoch:  93\n",
      "2021-10-30 09:52:04.116147: train loss : -0.9148\n",
      "2021-10-30 09:52:17.333542: validation loss: -0.8378\n",
      "2021-10-30 09:52:17.337371: Average global foreground Dice: [0.8461]\n",
      "2021-10-30 09:52:17.344615: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:52:17.829801: lr: 0.000795\n",
      "2021-10-30 09:52:17.849121: This epoch took 189.009769 s\n",
      "\n",
      "2021-10-30 09:52:17.855436: \n",
      "epoch:  94\n",
      "2021-10-30 09:55:13.260512: train loss : -0.9152\n",
      "2021-10-30 09:55:26.479789: validation loss: -0.8414\n",
      "2021-10-30 09:55:26.483536: Average global foreground Dice: [0.8499]\n",
      "2021-10-30 09:55:26.490168: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:55:26.975589: lr: 0.000675\n",
      "2021-10-30 09:55:26.994884: This epoch took 189.132912 s\n",
      "\n",
      "2021-10-30 09:55:27.001370: \n",
      "epoch:  95\n",
      "2021-10-30 09:58:22.172841: train loss : -0.9155\n",
      "2021-10-30 09:58:35.394679: validation loss: -0.8359\n",
      "2021-10-30 09:58:35.399259: Average global foreground Dice: [0.845]\n",
      "2021-10-30 09:58:35.405816: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 09:58:35.890294: lr: 0.000552\n",
      "2021-10-30 09:58:35.909020: This epoch took 188.900439 s\n",
      "\n",
      "2021-10-30 09:58:35.916857: \n",
      "epoch:  96\n",
      "2021-10-30 10:01:31.234459: train loss : -0.9163\n",
      "2021-10-30 10:01:44.436620: validation loss: -0.8372\n",
      "2021-10-30 10:01:44.440888: Average global foreground Dice: [0.8458]\n",
      "2021-10-30 10:01:44.447922: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 10:01:44.932458: lr: 0.000426\n",
      "2021-10-30 10:01:44.956692: This epoch took 189.033039 s\n",
      "\n",
      "2021-10-30 10:01:44.963224: \n",
      "epoch:  97\n",
      "2021-10-30 10:04:40.162561: train loss : -0.9164\n",
      "2021-10-30 10:04:53.364868: validation loss: -0.8399\n",
      "2021-10-30 10:04:53.369493: Average global foreground Dice: [0.8481]\n",
      "2021-10-30 10:04:53.375933: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 10:04:53.871931: lr: 0.000296\n",
      "2021-10-30 10:04:53.894405: This epoch took 188.924520 s\n",
      "\n",
      "2021-10-30 10:04:53.901621: \n",
      "epoch:  98\n",
      "2021-10-30 10:07:48.901576: train loss : -0.9168\n",
      "2021-10-30 10:08:02.095254: validation loss: -0.8389\n",
      "2021-10-30 10:08:02.098593: Average global foreground Dice: [0.8463]\n",
      "2021-10-30 10:08:02.105331: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 10:08:02.591383: lr: 0.000158\n",
      "2021-10-30 10:08:02.615117: This epoch took 188.706396 s\n",
      "\n",
      "2021-10-30 10:08:02.622035: \n",
      "epoch:  99\n",
      "2021-10-30 10:10:57.630482: train loss : -0.9170\n",
      "2021-10-30 10:11:10.829854: validation loss: -0.8440\n",
      "2021-10-30 10:11:10.833848: Average global foreground Dice: [0.852]\n",
      "2021-10-30 10:11:10.840100: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-30 10:11:11.330440: lr: 0.0\n",
      "2021-10-30 10:11:11.355443: saving scheduled checkpoint file...\n",
      "2021-10-30 10:11:11.385571: saving checkpoint...\n",
      "2021-10-30 10:11:12.156499: done, saving took 0.79 seconds\n",
      "2021-10-30 10:11:12.568133: done\n",
      "2021-10-30 10:11:12.576631: This epoch took 189.947606 s\n",
      "\n",
      "2021-10-30 10:11:12.602292: saving checkpoint...\n",
      "2021-10-30 10:11:13.202442: done, saving took 0.62 seconds\n",
      "23090558_20120330 (3, 263, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090564_20130312 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090568_20121018 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090569_20120607 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120613 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150908 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090593_20120625 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130103 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090600_20121108 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090603_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090607_20120420 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090609_20120510 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160119 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160510 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090646_20120718 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-30 10:13:06.997930: finished prediction\n",
      "2021-10-30 10:13:07.003968: evaluation of raw predictions\n",
      "2021-10-30 10:13:08.863204: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8332730194930255\n",
      "after:  0.8263333729871855\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Model 1\n",
    "\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 0\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 1\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 2\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 3\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 4\n",
    "\n",
    "# !nnUNet_predict -i /mnt/temp/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data/Task555_PETCT/imagesTs/ -o /mnt/backup/working/nnUNet/nnunet/nnUNet_Prediction_Results/Task555_PETCT/2d_CEGDL/ -t 577 -tr nnUNetTrainerV2_Loss_CEGDL -m 2d --disable_tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "using model stored in  /mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1\n",
      "This model expects 2 input modalities for each image\n",
      "Found 1 unique case ids, here are some examples: ['23010018_20141226']\n",
      "If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc\n",
      "number of cases: 1\n",
      "number of cases that still need to be predicted: 1\n",
      "emptying cuda cache\n",
      "loading parameters for folds, None\n",
      "folds is None so we will automatically look for output folders (not using 'all'!)\n",
      "found the following folds:  ['/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4']\n",
      "using the following model files:  ['/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4/model_final_checkpoint.model']\n",
      "starting preprocessing generator\n",
      "starting prediction...\n",
      "preprocessing /tf/2d_sample/23010018_20141226.nii.gz\n",
      "using preprocessor PreprocessorFor2D\n",
      "before crop: (2, 284, 200, 200) after crop: (2, 284, 173, 173) spacing: [1. 1. 1.] \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 284, 173, 173)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 284, 173, 173)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "(2, 284, 173, 173)\n",
      "This worker has ended successfully, no errors to report\n",
      "predicting /tf/2d_sample/23010018_20141226.nii.gz\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "inference done. Now waiting for the segmentation export to finish...\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "WARNING! Cannot run postprocessing because the postprocessing file is missing. Make sure to run consolidate_folds in the output folder of the model first!\n",
      "The folder you need to run this in is /mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "using model stored in  /mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1\n",
      "This model expects 2 input modalities for each image\n",
      "Found 1 unique case ids, here are some examples: ['23010018_20141226']\n",
      "If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc\n",
      "number of cases: 1\n",
      "number of cases that still need to be predicted: 1\n",
      "emptying cuda cache\n",
      "loading parameters for folds, None\n",
      "folds is None so we will automatically look for output folders (not using 'all'!)\n",
      "found the following folds:  ['/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4']\n",
      "using the following model files:  ['/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4/model_final_checkpoint.model']\n",
      "starting preprocessing generator\n",
      "starting prediction...\n",
      "preprocessing /tf/3d_sample/23010018_20141226.nii.gz\n",
      "using preprocessor GenericPreprocessor\n",
      "before crop: (2, 284, 200, 200) after crop: (2, 284, 173, 173) spacing: [1. 1. 1.] \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 284, 173, 173)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 284, 173, 173)} \n",
      "\n",
      "(2, 284, 173, 173)\n",
      "This worker has ended successfully, no errors to report\n",
      "predicting /tf/3d_sample/23010018_20141226.nii.gz\n",
      "debug: mirroring False mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: False\n",
      "data shape: (2, 284, 173, 173)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 28], [0, 38, 77], [0, 38, 77]]\n",
      "number of tiles: 18\n",
      "computing Gaussian\n",
      "prediction done\n",
      "debug: mirroring False mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: False\n",
      "data shape: (2, 284, 173, 173)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 28], [0, 38, 77], [0, 38, 77]]\n",
      "number of tiles: 18\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "debug: mirroring False mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: False\n",
      "data shape: (2, 284, 173, 173)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 28], [0, 38, 77], [0, 38, 77]]\n",
      "number of tiles: 18\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "debug: mirroring False mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: False\n",
      "data shape: (2, 284, 173, 173)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 28], [0, 38, 77], [0, 38, 77]]\n",
      "number of tiles: 18\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "debug: mirroring False mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: False\n",
      "data shape: (2, 284, 173, 173)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 28], [0, 38, 77], [0, 38, 77]]\n",
      "number of tiles: 18\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "inference done. Now waiting for the segmentation export to finish...\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "WARNING! Cannot run postprocessing because the postprocessing file is missing. Make sure to run consolidate_folds in the output folder of the model first!\r\n",
      "The folder you need to run this in is /mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1\r\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_predict -i /tf/sample -o /tf/2d_sample/ -t 555 -tr nnUNetTrainerV2 -m 2d --disable_tta\n",
    "!nnUNet_predict -i /tf/sample -o /tf/3d_sample/ -t 555 -tr nnUNetTrainerV2 -m 3d_fullres --disable_tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-10-24 10:41:17.530384: Creating new 5-fold cross-validation split...\n",
      "2021-10-24 10:41:17.552254: Desired fold for training: 0\n",
      "2021-10-24 10:41:17.559065: This split has 40 training and 40 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-24 10:41:26.394751: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-24 10:41:36.594757: Unable to plot network architecture:\n",
      "2021-10-24 10:41:36.725125: No module named 'hiddenlayer'\n",
      "2021-10-24 10:41:36.848667: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-24 10:41:36.976663: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-24 10:41:37.166430: \n",
      "\n",
      "2021-10-24 10:41:37.285095: \n",
      "epoch:  0\n",
      "2021-10-24 10:44:46.063938: train loss : -0.2429\n",
      "2021-10-24 10:44:59.527561: validation loss: -0.6284\n",
      "2021-10-24 10:44:59.533731: Average global foreground Dice: [0.7059]\n",
      "2021-10-24 10:44:59.540667: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 10:44:59.999803: lr: 0.00982\n",
      "2021-10-24 10:45:00.016869: This epoch took 202.654157 s\n",
      "\n",
      "2021-10-24 10:45:00.024058: \n",
      "epoch:  1\n",
      "2021-10-24 10:47:59.006362: train loss : -0.6634\n",
      "2021-10-24 10:48:12.431507: validation loss: -0.7325\n",
      "2021-10-24 10:48:12.435939: Average global foreground Dice: [0.8017]\n",
      "2021-10-24 10:48:12.442757: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 10:48:12.984833: lr: 0.009639\n",
      "2021-10-24 10:48:13.053959: saving checkpoint...\n",
      "2021-10-24 10:48:14.003763: done, saving took 0.99 seconds\n",
      "2021-10-24 10:48:14.528953: This epoch took 194.498498 s\n",
      "\n",
      "2021-10-24 10:48:14.547295: \n",
      "epoch:  2\n",
      "2021-10-24 10:51:12.488868: train loss : -0.7656\n",
      "2021-10-24 10:51:25.910579: validation loss: -0.8046\n",
      "2021-10-24 10:51:25.917163: Average global foreground Dice: [0.8266]\n",
      "2021-10-24 10:51:25.923897: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 10:51:26.569456: lr: 0.009458\n",
      "2021-10-24 10:51:26.619889: saving checkpoint...\n",
      "2021-10-24 10:51:27.712971: done, saving took 1.11 seconds\n",
      "2021-10-24 10:51:28.202699: This epoch took 193.647921 s\n",
      "\n",
      "2021-10-24 10:51:28.219888: \n",
      "epoch:  3\n",
      "2021-10-24 10:54:25.712136: train loss : -0.8008\n",
      "2021-10-24 10:54:39.130751: validation loss: -0.8167\n",
      "2021-10-24 10:54:39.135186: Average global foreground Dice: [0.8344]\n",
      "2021-10-24 10:54:39.141755: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 10:54:39.678124: lr: 0.009277\n",
      "2021-10-24 10:54:39.747457: saving checkpoint...\n",
      "2021-10-24 10:54:40.850347: done, saving took 1.14 seconds\n",
      "2021-10-24 10:54:41.306365: This epoch took 193.080083 s\n",
      "\n",
      "2021-10-24 10:54:41.324924: \n",
      "epoch:  4\n",
      "2021-10-24 10:57:39.687553: train loss : -0.8145\n",
      "2021-10-24 10:57:53.177413: validation loss: -0.8139\n",
      "2021-10-24 10:57:53.183298: Average global foreground Dice: [0.8308]\n",
      "2021-10-24 10:57:53.190133: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 10:57:53.748195: lr: 0.009095\n",
      "2021-10-24 10:57:53.820045: saving checkpoint...\n",
      "2021-10-24 10:57:54.924407: done, saving took 1.14 seconds\n",
      "2021-10-24 10:57:55.685010: This epoch took 194.353788 s\n",
      "\n",
      "2021-10-24 10:57:55.705449: \n",
      "epoch:  5\n",
      "2021-10-24 11:00:54.091327: train loss : -0.8254\n",
      "2021-10-24 11:01:07.588946: validation loss: -0.8076\n",
      "2021-10-24 11:01:07.593099: Average global foreground Dice: [0.8232]\n",
      "2021-10-24 11:01:07.599639: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:01:08.098719: lr: 0.008913\n",
      "2021-10-24 11:01:08.140248: saving checkpoint...\n",
      "2021-10-24 11:01:09.214026: done, saving took 1.09 seconds\n",
      "2021-10-24 11:01:09.669068: This epoch took 193.957631 s\n",
      "\n",
      "2021-10-24 11:01:09.677526: \n",
      "epoch:  6\n",
      "2021-10-24 11:04:08.242592: train loss : -0.8336\n",
      "2021-10-24 11:04:21.757736: validation loss: -0.8228\n",
      "2021-10-24 11:04:21.762376: Average global foreground Dice: [0.8391]\n",
      "2021-10-24 11:04:21.768647: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:04:22.322287: lr: 0.008731\n",
      "2021-10-24 11:04:22.371044: saving checkpoint...\n",
      "2021-10-24 11:04:23.506667: done, saving took 1.16 seconds\n",
      "2021-10-24 11:04:23.952897: This epoch took 194.268546 s\n",
      "\n",
      "2021-10-24 11:04:23.961185: \n",
      "epoch:  7\n",
      "2021-10-24 11:07:22.540674: train loss : -0.8402\n",
      "2021-10-24 11:07:36.059767: validation loss: -0.8231\n",
      "2021-10-24 11:07:36.066867: Average global foreground Dice: [0.8363]\n",
      "2021-10-24 11:07:36.070904: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:07:36.604266: lr: 0.008548\n",
      "2021-10-24 11:07:36.655800: saving checkpoint...\n",
      "2021-10-24 11:07:37.808782: done, saving took 1.18 seconds\n",
      "2021-10-24 11:07:38.501275: This epoch took 194.533338 s\n",
      "\n",
      "2021-10-24 11:07:38.509340: \n",
      "epoch:  8\n",
      "2021-10-24 11:10:37.708094: train loss : -0.8439\n",
      "2021-10-24 11:10:51.211594: validation loss: -0.8208\n",
      "2021-10-24 11:10:51.215853: Average global foreground Dice: [0.8353]\n",
      "2021-10-24 11:10:51.222504: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:10:51.729414: lr: 0.008364\n",
      "2021-10-24 11:10:51.771959: saving checkpoint...\n",
      "2021-10-24 11:10:52.867378: done, saving took 1.11 seconds\n",
      "2021-10-24 11:10:53.350804: This epoch took 194.835327 s\n",
      "\n",
      "2021-10-24 11:10:53.358775: \n",
      "epoch:  9\n",
      "2021-10-24 11:13:52.353994: train loss : -0.8496\n",
      "2021-10-24 11:14:05.840366: validation loss: -0.8242\n",
      "2021-10-24 11:14:05.845122: Average global foreground Dice: [0.8389]\n",
      "2021-10-24 11:14:05.851219: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:14:06.351952: lr: 0.008181\n",
      "2021-10-24 11:14:06.394261: saving checkpoint...\n",
      "2021-10-24 11:14:07.481982: done, saving took 1.11 seconds\n",
      "2021-10-24 11:14:07.948627: This epoch took 194.583042 s\n",
      "\n",
      "2021-10-24 11:14:07.957515: \n",
      "epoch:  10\n",
      "2021-10-24 11:17:06.925238: train loss : -0.8542\n",
      "2021-10-24 11:17:20.434444: validation loss: -0.8180\n",
      "2021-10-24 11:17:20.439053: Average global foreground Dice: [0.8327]\n",
      "2021-10-24 11:17:20.446082: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:17:21.006571: lr: 0.007996\n",
      "2021-10-24 11:17:21.044064: saving checkpoint...\n",
      "2021-10-24 11:17:22.169806: done, saving took 1.14 seconds\n",
      "2021-10-24 11:17:22.623943: This epoch took 194.659315 s\n",
      "\n",
      "2021-10-24 11:17:22.634687: \n",
      "epoch:  11\n",
      "2021-10-24 11:20:21.758855: train loss : -0.8569\n",
      "2021-10-24 11:20:35.273767: validation loss: -0.8192\n",
      "2021-10-24 11:20:35.278338: Average global foreground Dice: [0.8329]\n",
      "2021-10-24 11:20:35.297875: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:20:35.845567: lr: 0.007811\n",
      "2021-10-24 11:20:35.903039: saving checkpoint...\n",
      "2021-10-24 11:20:37.034940: done, saving took 1.17 seconds\n",
      "2021-10-24 11:20:37.488809: This epoch took 194.847810 s\n",
      "\n",
      "2021-10-24 11:20:37.498241: \n",
      "epoch:  12\n",
      "2021-10-24 11:23:36.683834: train loss : -0.8609\n",
      "2021-10-24 11:23:50.209072: validation loss: -0.8266\n",
      "2021-10-24 11:23:50.215249: Average global foreground Dice: [0.8397]\n",
      "2021-10-24 11:23:50.222142: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:23:50.765050: lr: 0.007626\n",
      "2021-10-24 11:23:50.811469: saving checkpoint...\n",
      "2021-10-24 11:23:51.941480: done, saving took 1.15 seconds\n",
      "2021-10-24 11:23:52.410031: This epoch took 194.905041 s\n",
      "\n",
      "2021-10-24 11:23:52.418665: \n",
      "epoch:  13\n",
      "2021-10-24 11:26:51.664809: train loss : -0.8629\n",
      "2021-10-24 11:27:05.144647: validation loss: -0.8240\n",
      "2021-10-24 11:27:05.148889: Average global foreground Dice: [0.8384]\n",
      "2021-10-24 11:27:05.156318: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:27:05.754862: lr: 0.00744\n",
      "2021-10-24 11:27:05.797117: saving checkpoint...\n",
      "2021-10-24 11:27:06.881797: done, saving took 1.10 seconds\n",
      "2021-10-24 11:27:07.349966: This epoch took 194.923394 s\n",
      "\n",
      "2021-10-24 11:27:07.358560: \n",
      "epoch:  14\n",
      "2021-10-24 11:30:06.591059: train loss : -0.8651\n",
      "2021-10-24 11:30:20.088139: validation loss: -0.8308\n",
      "2021-10-24 11:30:20.092532: Average global foreground Dice: [0.844]\n",
      "2021-10-24 11:30:20.099876: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:30:20.617631: lr: 0.007254\n",
      "2021-10-24 11:30:20.660104: saving checkpoint...\n",
      "2021-10-24 11:30:21.736314: done, saving took 1.10 seconds\n",
      "2021-10-24 11:30:22.164234: This epoch took 194.798321 s\n",
      "\n",
      "2021-10-24 11:30:22.173383: \n",
      "epoch:  15\n",
      "2021-10-24 11:33:21.695371: train loss : -0.8670\n",
      "2021-10-24 11:33:35.198244: validation loss: -0.8216\n",
      "2021-10-24 11:33:35.202698: Average global foreground Dice: [0.8349]\n",
      "2021-10-24 11:33:35.208903: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:33:35.750308: lr: 0.007067\n",
      "2021-10-24 11:33:35.789441: saving checkpoint...\n",
      "2021-10-24 11:33:36.859804: done, saving took 1.09 seconds\n",
      "2021-10-24 11:33:37.357631: This epoch took 195.176616 s\n",
      "\n",
      "2021-10-24 11:33:37.366076: \n",
      "epoch:  16\n",
      "2021-10-24 11:36:37.107399: train loss : -0.8693\n",
      "2021-10-24 11:36:50.624498: validation loss: -0.8187\n",
      "2021-10-24 11:36:50.629404: Average global foreground Dice: [0.8302]\n",
      "2021-10-24 11:36:50.635949: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:36:51.202266: lr: 0.00688\n",
      "2021-10-24 11:36:51.246199: saving checkpoint...\n",
      "2021-10-24 11:36:52.402948: done, saving took 1.18 seconds\n",
      "2021-10-24 11:36:52.859659: This epoch took 195.486957 s\n",
      "\n",
      "2021-10-24 11:36:52.867492: \n",
      "epoch:  17\n",
      "2021-10-24 11:39:52.621273: train loss : -0.8720\n",
      "2021-10-24 11:40:06.151651: validation loss: -0.8280\n",
      "2021-10-24 11:40:06.155945: Average global foreground Dice: [0.8398]\n",
      "2021-10-24 11:40:06.163048: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:40:06.674631: lr: 0.006692\n",
      "2021-10-24 11:40:06.712574: saving checkpoint...\n",
      "2021-10-24 11:40:07.841662: done, saving took 1.15 seconds\n",
      "2021-10-24 11:40:08.363688: This epoch took 195.489536 s\n",
      "\n",
      "2021-10-24 11:40:08.372579: \n",
      "epoch:  18\n",
      "2021-10-24 11:43:08.127904: train loss : -0.8735\n",
      "2021-10-24 11:43:21.632085: validation loss: -0.8214\n",
      "2021-10-24 11:43:21.636242: Average global foreground Dice: [0.8347]\n",
      "2021-10-24 11:43:21.643111: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:43:22.189233: lr: 0.006504\n",
      "2021-10-24 11:43:22.253289: saving checkpoint...\n",
      "2021-10-24 11:43:23.413907: done, saving took 1.19 seconds\n",
      "2021-10-24 11:43:23.874923: This epoch took 195.495360 s\n",
      "\n",
      "2021-10-24 11:43:23.894519: \n",
      "epoch:  19\n",
      "2021-10-24 11:46:23.747987: train loss : -0.8759\n",
      "2021-10-24 11:46:37.276960: validation loss: -0.8298\n",
      "2021-10-24 11:46:37.281265: Average global foreground Dice: [0.8423]\n",
      "2021-10-24 11:46:37.287560: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:46:37.801247: lr: 0.006314\n",
      "2021-10-24 11:46:37.855013: saving checkpoint...\n",
      "2021-10-24 11:46:38.976715: done, saving took 1.14 seconds\n",
      "2021-10-24 11:46:39.563599: This epoch took 195.662594 s\n",
      "\n",
      "2021-10-24 11:46:39.581393: \n",
      "epoch:  20\n",
      "2021-10-24 11:49:39.410604: train loss : -0.8768\n",
      "2021-10-24 11:49:52.931951: validation loss: -0.8152\n",
      "2021-10-24 11:49:52.938014: Average global foreground Dice: [0.8269]\n",
      "2021-10-24 11:49:52.944830: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:49:53.488292: lr: 0.006125\n",
      "2021-10-24 11:49:53.539789: saving checkpoint...\n",
      "2021-10-24 11:49:54.599390: done, saving took 1.08 seconds\n",
      "2021-10-24 11:49:55.064709: This epoch took 195.475034 s\n",
      "\n",
      "2021-10-24 11:49:55.084599: \n",
      "epoch:  21\n",
      "2021-10-24 11:52:54.866449: train loss : -0.8774\n",
      "2021-10-24 11:53:08.381022: validation loss: -0.8271\n",
      "2021-10-24 11:53:08.385345: Average global foreground Dice: [0.8396]\n",
      "2021-10-24 11:53:08.393133: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:53:08.938925: lr: 0.005934\n",
      "2021-10-24 11:53:08.988194: saving checkpoint...\n",
      "2021-10-24 11:53:10.095807: done, saving took 1.13 seconds\n",
      "2021-10-24 11:53:10.690241: This epoch took 195.597764 s\n",
      "\n",
      "2021-10-24 11:53:10.708832: \n",
      "epoch:  22\n",
      "2021-10-24 11:56:10.498618: train loss : -0.8797\n",
      "2021-10-24 11:56:24.006025: validation loss: -0.8341\n",
      "2021-10-24 11:56:24.010350: Average global foreground Dice: [0.8458]\n",
      "2021-10-24 11:56:24.017565: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:56:24.589038: lr: 0.005743\n",
      "2021-10-24 11:56:24.650965: saving checkpoint...\n",
      "2021-10-24 11:56:25.732804: done, saving took 1.11 seconds\n",
      "2021-10-24 11:56:26.161520: This epoch took 195.445794 s\n",
      "\n",
      "2021-10-24 11:56:26.179568: \n",
      "epoch:  23\n",
      "2021-10-24 11:59:25.826359: train loss : -0.8812\n",
      "2021-10-24 11:59:39.326884: validation loss: -0.8275\n",
      "2021-10-24 11:59:39.331336: Average global foreground Dice: [0.8427]\n",
      "2021-10-24 11:59:39.337463: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:59:39.886425: lr: 0.005551\n",
      "2021-10-24 11:59:39.940508: saving checkpoint...\n",
      "2021-10-24 11:59:41.056011: done, saving took 1.13 seconds\n",
      "2021-10-24 11:59:41.510773: This epoch took 195.324583 s\n",
      "\n",
      "2021-10-24 11:59:41.529165: \n",
      "epoch:  24\n",
      "2021-10-24 12:02:41.631804: train loss : -0.8816\n",
      "2021-10-24 12:02:55.142759: validation loss: -0.8302\n",
      "2021-10-24 12:02:55.147366: Average global foreground Dice: [0.8443]\n",
      "2021-10-24 12:02:55.153354: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:02:55.789290: lr: 0.005359\n",
      "2021-10-24 12:02:55.834933: saving checkpoint...\n",
      "2021-10-24 12:02:56.914081: done, saving took 1.10 seconds\n",
      "2021-10-24 12:02:57.365261: This epoch took 195.828951 s\n",
      "\n",
      "2021-10-24 12:02:57.377926: \n",
      "epoch:  25\n",
      "2021-10-24 12:05:57.404379: train loss : -0.8847\n",
      "2021-10-24 12:06:10.899161: validation loss: -0.8240\n",
      "2021-10-24 12:06:10.904834: Average global foreground Dice: [0.8365]\n",
      "2021-10-24 12:06:10.911530: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:06:11.442488: lr: 0.005166\n",
      "2021-10-24 12:06:11.485333: saving checkpoint...\n",
      "2021-10-24 12:06:12.566167: done, saving took 1.10 seconds\n",
      "2021-10-24 12:06:13.025949: This epoch took 195.640855 s\n",
      "\n",
      "2021-10-24 12:06:13.033815: \n",
      "epoch:  26\n",
      "2021-10-24 12:09:13.116567: train loss : -0.8863\n",
      "2021-10-24 12:09:26.626986: validation loss: -0.8215\n",
      "2021-10-24 12:09:26.633126: Average global foreground Dice: [0.8364]\n",
      "2021-10-24 12:09:26.640738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:09:27.177408: lr: 0.004971\n",
      "2021-10-24 12:09:27.222076: saving checkpoint...\n",
      "2021-10-24 12:09:28.304369: done, saving took 1.10 seconds\n",
      "2021-10-24 12:09:28.770015: This epoch took 195.730068 s\n",
      "\n",
      "2021-10-24 12:09:28.778757: \n",
      "epoch:  27\n",
      "2021-10-24 12:12:28.943443: train loss : -0.8871\n",
      "2021-10-24 12:12:42.463267: validation loss: -0.8298\n",
      "2021-10-24 12:12:42.467986: Average global foreground Dice: [0.8426]\n",
      "2021-10-24 12:12:42.475015: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:12:43.013001: lr: 0.004776\n",
      "2021-10-24 12:12:43.053337: saving checkpoint...\n",
      "2021-10-24 12:12:44.182062: done, saving took 1.15 seconds\n",
      "2021-10-24 12:12:44.641690: This epoch took 195.855899 s\n",
      "\n",
      "2021-10-24 12:12:44.652529: \n",
      "epoch:  28\n",
      "2021-10-24 12:15:44.748107: train loss : -0.8869\n",
      "2021-10-24 12:15:58.266768: validation loss: -0.8290\n",
      "2021-10-24 12:15:58.271503: Average global foreground Dice: [0.8423]\n",
      "2021-10-24 12:15:58.278030: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:15:58.819058: lr: 0.004581\n",
      "2021-10-24 12:15:58.861418: saving checkpoint...\n",
      "2021-10-24 12:15:59.966037: done, saving took 1.12 seconds\n",
      "2021-10-24 12:16:00.469034: This epoch took 195.808477 s\n",
      "\n",
      "2021-10-24 12:16:00.478995: \n",
      "epoch:  29\n",
      "2021-10-24 12:19:00.555289: train loss : -0.8892\n",
      "2021-10-24 12:19:14.073941: validation loss: -0.8201\n",
      "2021-10-24 12:19:14.078376: Average global foreground Dice: [0.8334]\n",
      "2021-10-24 12:19:14.085302: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:19:14.645028: lr: 0.004384\n",
      "2021-10-24 12:19:14.683708: saving checkpoint...\n",
      "2021-10-24 12:19:15.870352: done, saving took 1.21 seconds\n",
      "2021-10-24 12:19:16.410535: This epoch took 195.924583 s\n",
      "\n",
      "2021-10-24 12:19:16.418780: \n",
      "epoch:  30\n",
      "2021-10-24 12:22:16.516326: train loss : -0.8907\n",
      "2021-10-24 12:22:30.033717: validation loss: -0.8262\n",
      "2021-10-24 12:22:30.038184: Average global foreground Dice: [0.8404]\n",
      "2021-10-24 12:22:30.045017: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:22:30.613456: lr: 0.004186\n",
      "2021-10-24 12:22:30.652058: saving checkpoint...\n",
      "2021-10-24 12:22:31.725896: done, saving took 1.09 seconds\n",
      "2021-10-24 12:22:32.191760: This epoch took 195.765626 s\n",
      "\n",
      "2021-10-24 12:22:32.200913: \n",
      "epoch:  31\n",
      "2021-10-24 12:25:32.357908: train loss : -0.8918\n",
      "2021-10-24 12:25:45.890304: validation loss: -0.8293\n",
      "2021-10-24 12:25:45.895193: Average global foreground Dice: [0.8418]\n",
      "2021-10-24 12:25:45.902081: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:25:46.434301: lr: 0.003987\n",
      "2021-10-24 12:25:46.475422: saving checkpoint...\n",
      "2021-10-24 12:25:47.590447: done, saving took 1.13 seconds\n",
      "2021-10-24 12:25:48.100945: This epoch took 195.893266 s\n",
      "\n",
      "2021-10-24 12:25:48.109157: \n",
      "epoch:  32\n",
      "2021-10-24 12:28:48.571952: train loss : -0.8922\n",
      "2021-10-24 12:29:02.091926: validation loss: -0.8188\n",
      "2021-10-24 12:29:02.098297: Average global foreground Dice: [0.8321]\n",
      "2021-10-24 12:29:02.105480: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:29:02.671580: lr: 0.003787\n",
      "2021-10-24 12:29:02.697476: This epoch took 194.581879 s\n",
      "\n",
      "2021-10-24 12:29:02.704314: \n",
      "epoch:  33\n",
      "2021-10-24 12:32:03.244176: train loss : -0.8924\n",
      "2021-10-24 12:32:16.749488: validation loss: -0.8329\n",
      "2021-10-24 12:32:16.754905: Average global foreground Dice: [0.8449]\n",
      "2021-10-24 12:32:16.762637: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:32:17.316799: lr: 0.003586\n",
      "2021-10-24 12:32:17.366597: saving checkpoint...\n",
      "2021-10-24 12:32:18.479241: done, saving took 1.14 seconds\n",
      "2021-10-24 12:32:18.963683: This epoch took 196.252927 s\n",
      "\n",
      "2021-10-24 12:32:18.973291: \n",
      "epoch:  34\n",
      "2021-10-24 12:35:19.368593: train loss : -0.8930\n",
      "2021-10-24 12:35:32.911174: validation loss: -0.8223\n",
      "2021-10-24 12:35:32.915651: Average global foreground Dice: [0.8352]\n",
      "2021-10-24 12:35:32.922389: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:35:33.479438: lr: 0.003384\n",
      "2021-10-24 12:35:33.530026: saving checkpoint...\n",
      "2021-10-24 12:35:34.609591: done, saving took 1.11 seconds\n",
      "2021-10-24 12:35:35.255088: This epoch took 196.274286 s\n",
      "\n",
      "2021-10-24 12:35:35.262630: \n",
      "epoch:  35\n",
      "2021-10-24 12:38:35.626751: train loss : -0.8955\n",
      "2021-10-24 12:38:49.136237: validation loss: -0.8235\n",
      "2021-10-24 12:38:49.140781: Average global foreground Dice: [0.8369]\n",
      "2021-10-24 12:38:49.147872: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:38:49.719172: lr: 0.00318\n",
      "2021-10-24 12:38:49.758122: saving checkpoint...\n",
      "2021-10-24 12:38:50.852067: done, saving took 1.11 seconds\n",
      "2021-10-24 12:38:51.326270: This epoch took 196.056997 s\n",
      "\n",
      "2021-10-24 12:38:51.335242: \n",
      "epoch:  36\n",
      "2021-10-24 12:41:51.847439: train loss : -0.8969\n",
      "2021-10-24 12:42:05.379141: validation loss: -0.8293\n",
      "2021-10-24 12:42:05.383654: Average global foreground Dice: [0.8414]\n",
      "2021-10-24 12:42:05.392025: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:42:05.907405: lr: 0.002975\n",
      "2021-10-24 12:42:05.948387: saving checkpoint...\n",
      "2021-10-24 12:42:07.049860: done, saving took 1.12 seconds\n",
      "2021-10-24 12:42:07.761740: This epoch took 196.417835 s\n",
      "\n",
      "2021-10-24 12:42:07.770682: \n",
      "epoch:  37\n",
      "2021-10-24 12:45:08.273642: train loss : -0.8979\n",
      "2021-10-24 12:45:21.798979: validation loss: -0.8197\n",
      "2021-10-24 12:45:21.803170: Average global foreground Dice: [0.8327]\n",
      "2021-10-24 12:45:21.809987: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:45:22.355364: lr: 0.002768\n",
      "2021-10-24 12:45:22.373688: This epoch took 194.596322 s\n",
      "\n",
      "2021-10-24 12:45:22.380360: \n",
      "epoch:  38\n",
      "2021-10-24 12:48:22.895744: train loss : -0.8989\n",
      "2021-10-24 12:48:36.400154: validation loss: -0.8274\n",
      "2021-10-24 12:48:36.404709: Average global foreground Dice: [0.8409]\n",
      "2021-10-24 12:48:36.411267: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:48:36.970501: lr: 0.00256\n",
      "2021-10-24 12:48:37.006126: saving checkpoint...\n",
      "2021-10-24 12:48:38.134378: done, saving took 1.15 seconds\n",
      "2021-10-24 12:48:38.600187: This epoch took 196.212776 s\n",
      "\n",
      "2021-10-24 12:48:38.608962: \n",
      "epoch:  39\n",
      "2021-10-24 12:51:39.056837: train loss : -0.9001\n",
      "2021-10-24 12:51:52.574257: validation loss: -0.8276\n",
      "2021-10-24 12:51:52.578789: Average global foreground Dice: [0.8383]\n",
      "2021-10-24 12:51:52.585828: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:51:53.135673: lr: 0.002349\n",
      "2021-10-24 12:51:53.177020: saving checkpoint...\n",
      "2021-10-24 12:51:54.294431: done, saving took 1.14 seconds\n",
      "2021-10-24 12:51:54.742460: This epoch took 196.125967 s\n",
      "\n",
      "2021-10-24 12:51:54.752787: \n",
      "epoch:  40\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-24 12:54:55.576948: train loss : -0.9000\n",
      "2021-10-24 12:55:09.113497: validation loss: -0.8312\n",
      "2021-10-24 12:55:09.118048: Average global foreground Dice: [0.8438]\n",
      "2021-10-24 12:55:09.125240: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:55:09.680993: lr: 0.002137\n",
      "2021-10-24 12:55:09.737142: saving checkpoint...\n",
      "2021-10-24 12:55:10.842761: done, saving took 1.13 seconds\n",
      "2021-10-24 12:55:11.323063: This epoch took 196.563090 s\n",
      "\n",
      "2021-10-24 12:55:11.331163: \n",
      "epoch:  41\n",
      "2021-10-24 12:58:11.679102: train loss : -0.9034\n",
      "2021-10-24 12:58:25.209019: validation loss: -0.8249\n",
      "2021-10-24 12:58:25.213950: Average global foreground Dice: [0.8368]\n",
      "2021-10-24 12:58:25.220607: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:58:25.832985: lr: 0.001922\n",
      "2021-10-24 12:58:25.853077: This epoch took 194.514632 s\n",
      "\n",
      "2021-10-24 12:58:25.859869: \n",
      "epoch:  42\n",
      "2021-10-24 13:01:26.398830: train loss : -0.9040\n",
      "2021-10-24 13:01:39.926729: validation loss: -0.8256\n",
      "2021-10-24 13:01:39.932673: Average global foreground Dice: [0.8376]\n",
      "2021-10-24 13:01:39.939479: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:01:40.476460: lr: 0.001704\n",
      "2021-10-24 13:01:40.518458: saving checkpoint...\n",
      "2021-10-24 13:01:41.598654: done, saving took 1.10 seconds\n",
      "2021-10-24 13:01:42.118777: This epoch took 196.252033 s\n",
      "\n",
      "2021-10-24 13:01:42.127532: \n",
      "epoch:  43\n",
      "2021-10-24 13:04:42.653624: train loss : -0.9043\n",
      "2021-10-24 13:04:56.168559: validation loss: -0.8272\n",
      "2021-10-24 13:04:56.174624: Average global foreground Dice: [0.839]\n",
      "2021-10-24 13:04:56.181554: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:04:56.692003: lr: 0.001483\n",
      "2021-10-24 13:04:56.731940: saving checkpoint...\n",
      "2021-10-24 13:04:57.835081: done, saving took 1.12 seconds\n",
      "2021-10-24 13:04:58.274525: This epoch took 196.140154 s\n",
      "\n",
      "2021-10-24 13:04:58.282564: \n",
      "epoch:  44\n",
      "2021-10-24 13:07:58.666734: train loss : -0.9050\n",
      "2021-10-24 13:08:12.191715: validation loss: -0.8263\n",
      "2021-10-24 13:08:12.196169: Average global foreground Dice: [0.838]\n",
      "2021-10-24 13:08:12.202738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:08:12.750528: lr: 0.001259\n",
      "2021-10-24 13:08:12.790706: saving checkpoint...\n",
      "2021-10-24 13:08:13.874686: done, saving took 1.10 seconds\n",
      "2021-10-24 13:08:14.543884: This epoch took 196.254589 s\n",
      "\n",
      "2021-10-24 13:08:14.553154: \n",
      "epoch:  45\n",
      "2021-10-24 13:11:15.045040: train loss : -0.9057\n",
      "2021-10-24 13:11:28.590396: validation loss: -0.8240\n",
      "2021-10-24 13:11:28.594665: Average global foreground Dice: [0.8358]\n",
      "2021-10-24 13:11:28.601408: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:11:29.139450: lr: 0.00103\n",
      "2021-10-24 13:11:29.159481: This epoch took 194.599126 s\n",
      "\n",
      "2021-10-24 13:11:29.166360: \n",
      "epoch:  46\n",
      "2021-10-24 13:14:29.744107: train loss : -0.9060\n",
      "2021-10-24 13:14:43.287308: validation loss: -0.8239\n",
      "2021-10-24 13:14:43.291849: Average global foreground Dice: [0.837]\n",
      "2021-10-24 13:14:43.298547: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:14:43.857263: lr: 0.000795\n",
      "2021-10-24 13:14:43.877330: This epoch took 194.703977 s\n",
      "\n",
      "2021-10-24 13:14:43.884272: \n",
      "epoch:  47\n",
      "2021-10-24 13:17:44.425053: train loss : -0.9082\n",
      "2021-10-24 13:17:57.956280: validation loss: -0.8184\n",
      "2021-10-24 13:17:57.961633: Average global foreground Dice: [0.8317]\n",
      "2021-10-24 13:17:57.971985: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:17:58.481414: lr: 0.000552\n",
      "2021-10-24 13:17:58.497418: This epoch took 194.606810 s\n",
      "\n",
      "2021-10-24 13:17:58.507049: \n",
      "epoch:  48\n",
      "2021-10-24 13:20:59.189025: train loss : -0.9077\n",
      "2021-10-24 13:21:12.717654: validation loss: -0.8199\n",
      "2021-10-24 13:21:12.721893: Average global foreground Dice: [0.8328]\n",
      "2021-10-24 13:21:12.730991: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:21:13.295860: lr: 0.000296\n",
      "2021-10-24 13:21:13.317796: This epoch took 194.799896 s\n",
      "\n",
      "2021-10-24 13:21:13.326078: \n",
      "epoch:  49\n",
      "2021-10-24 13:24:14.277965: train loss : -0.9088\n",
      "2021-10-24 13:24:27.796461: validation loss: -0.8240\n",
      "2021-10-24 13:24:27.800963: Average global foreground Dice: [0.8365]\n",
      "2021-10-24 13:24:27.807361: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:24:28.345997: lr: 0.0\n",
      "2021-10-24 13:24:28.366463: saving scheduled checkpoint file...\n",
      "2021-10-24 13:24:28.394214: saving checkpoint...\n",
      "2021-10-24 13:24:29.348693: done, saving took 0.98 seconds\n",
      "2021-10-24 13:24:29.774601: done\n",
      "2021-10-24 13:24:29.783638: This epoch took 196.450797 s\n",
      "\n",
      "2021-10-24 13:24:29.809769: saving checkpoint...\n",
      "2021-10-24 13:24:30.742802: done, saving took 0.95 seconds\n",
      "23090559_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090563_20151 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090567_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090584_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090589_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090590_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090592_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090596_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090599_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090604_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090608_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090614_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090615_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090616_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090617_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090620_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090627_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090628_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090631_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090634_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090635_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090636_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090640_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-24 13:29:26.549421: finished prediction\n",
      "2021-10-24 13:29:26.555833: evaluation of raw predictions\n",
      "2021-10-24 13:29:30.145727: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8308992737772268\n",
      "after:  0.8308746294340972\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-10-24 13:29:47.416392: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-10-24 13:29:47.439077: The split file contains 2 splits.\n",
      "2021-10-24 13:29:47.445198: Desired fold for training: 1\n",
      "2021-10-24 13:29:47.452076: This split has 40 training and 40 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-24 13:29:51.602617: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-24 13:30:02.289120: Unable to plot network architecture:\n",
      "2021-10-24 13:30:02.425066: No module named 'hiddenlayer'\n",
      "2021-10-24 13:30:02.564654: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-24 13:30:02.656566: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-24 13:30:02.756930: \n",
      "\n",
      "2021-10-24 13:30:02.860720: \n",
      "epoch:  0\n",
      "2021-10-24 13:33:20.478953: train loss : -0.3093\n",
      "2021-10-24 13:33:34.243168: validation loss: -0.6849\n",
      "2021-10-24 13:33:34.247638: Average global foreground Dice: [0.7196]\n",
      "2021-10-24 13:33:34.253887: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:33:34.736280: lr: 0.00982\n",
      "2021-10-24 13:33:34.753988: This epoch took 211.801292 s\n",
      "\n",
      "2021-10-24 13:33:34.761931: \n",
      "epoch:  1\n",
      "2021-10-24 13:36:35.155726: train loss : -0.7275\n",
      "2021-10-24 13:36:48.936562: validation loss: -0.7731\n",
      "2021-10-24 13:36:48.941263: Average global foreground Dice: [0.7931]\n",
      "2021-10-24 13:36:48.947916: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:36:49.447848: lr: 0.009639\n",
      "2021-10-24 13:36:49.488218: saving checkpoint...\n",
      "2021-10-24 13:36:50.448651: done, saving took 0.98 seconds\n",
      "2021-10-24 13:36:50.879380: This epoch took 196.111327 s\n",
      "\n",
      "2021-10-24 13:36:50.888358: \n",
      "epoch:  2\n",
      "2021-10-24 13:39:50.845416: train loss : -0.7877\n",
      "2021-10-24 13:40:04.611577: validation loss: -0.7977\n",
      "2021-10-24 13:40:04.615973: Average global foreground Dice: [0.8144]\n",
      "2021-10-24 13:40:04.626283: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:40:05.264827: lr: 0.009458\n",
      "2021-10-24 13:40:05.303283: saving checkpoint...\n",
      "2021-10-24 13:40:06.382324: done, saving took 1.10 seconds\n",
      "2021-10-24 13:40:06.895134: This epoch took 196.000086 s\n",
      "\n",
      "2021-10-24 13:40:06.903036: \n",
      "epoch:  3\n",
      "2021-10-24 13:43:06.965099: train loss : -0.8100\n",
      "2021-10-24 13:43:20.735370: validation loss: -0.7983\n",
      "2021-10-24 13:43:20.739705: Average global foreground Dice: [0.8166]\n",
      "2021-10-24 13:43:20.746173: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:43:21.244801: lr: 0.009277\n",
      "2021-10-24 13:43:21.295605: saving checkpoint...\n",
      "2021-10-24 13:43:22.355316: done, saving took 1.08 seconds\n",
      "2021-10-24 13:43:22.831310: This epoch took 195.921274 s\n",
      "\n",
      "2021-10-24 13:43:22.851567: \n",
      "epoch:  4\n",
      "2021-10-24 13:46:22.923440: train loss : -0.8235\n",
      "2021-10-24 13:46:36.688985: validation loss: -0.8060\n",
      "2021-10-24 13:46:36.695359: Average global foreground Dice: [0.8228]\n",
      "2021-10-24 13:46:36.702399: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:46:37.255460: lr: 0.009095\n",
      "2021-10-24 13:46:37.311130: saving checkpoint...\n",
      "2021-10-24 13:46:38.411627: done, saving took 1.12 seconds\n",
      "2021-10-24 13:46:38.922602: This epoch took 196.064225 s\n",
      "\n",
      "2021-10-24 13:46:38.939681: \n",
      "epoch:  5\n",
      "2021-10-24 13:49:39.047000: train loss : -0.8313\n",
      "2021-10-24 13:49:52.809064: validation loss: -0.8197\n",
      "2021-10-24 13:49:52.813410: Average global foreground Dice: [0.8311]\n",
      "2021-10-24 13:49:52.819435: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:49:53.368926: lr: 0.008913\n",
      "2021-10-24 13:49:53.419334: saving checkpoint...\n",
      "2021-10-24 13:49:54.490732: done, saving took 1.09 seconds\n",
      "2021-10-24 13:49:54.923074: This epoch took 195.976412 s\n",
      "\n",
      "2021-10-24 13:49:54.943800: \n",
      "epoch:  6\n",
      "2021-10-24 13:52:55.007815: train loss : -0.8402\n",
      "2021-10-24 13:53:08.783525: validation loss: -0.8136\n",
      "2021-10-24 13:53:08.787981: Average global foreground Dice: [0.8271]\n",
      "2021-10-24 13:53:08.793867: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:53:09.309471: lr: 0.008731\n",
      "2021-10-24 13:53:09.357110: saving checkpoint...\n",
      "2021-10-24 13:53:10.436089: done, saving took 1.10 seconds\n",
      "2021-10-24 13:53:10.901045: This epoch took 195.951159 s\n",
      "\n",
      "2021-10-24 13:53:10.919713: \n",
      "epoch:  7\n",
      "2021-10-24 13:56:10.969311: train loss : -0.8441\n",
      "2021-10-24 13:56:24.765534: validation loss: -0.8144\n",
      "2021-10-24 13:56:24.770043: Average global foreground Dice: [0.8275]\n",
      "2021-10-24 13:56:24.777278: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:56:25.310712: lr: 0.008548\n",
      "2021-10-24 13:56:25.360400: saving checkpoint...\n",
      "2021-10-24 13:56:26.504049: done, saving took 1.16 seconds\n",
      "2021-10-24 13:56:26.932477: This epoch took 196.005382 s\n",
      "\n",
      "2021-10-24 13:56:26.952926: \n",
      "epoch:  8\n",
      "2021-10-24 13:59:27.542699: train loss : -0.8490\n",
      "2021-10-24 13:59:41.345287: validation loss: -0.8232\n",
      "2021-10-24 13:59:41.350571: Average global foreground Dice: [0.8349]\n",
      "2021-10-24 13:59:41.356848: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:59:41.855174: lr: 0.008364\n",
      "2021-10-24 13:59:41.904809: saving checkpoint...\n",
      "2021-10-24 13:59:43.011690: done, saving took 1.13 seconds\n",
      "2021-10-24 13:59:43.480415: This epoch took 196.521197 s\n",
      "\n",
      "2021-10-24 13:59:43.501023: \n",
      "epoch:  9\n",
      "2021-10-24 14:02:44.119778: train loss : -0.8533\n",
      "2021-10-24 14:02:57.911741: validation loss: -0.8178\n",
      "2021-10-24 14:02:57.915898: Average global foreground Dice: [0.8298]\n",
      "2021-10-24 14:02:57.922295: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:02:58.433414: lr: 0.008181\n",
      "2021-10-24 14:02:58.483601: saving checkpoint...\n",
      "2021-10-24 14:02:59.910426: done, saving took 1.45 seconds\n",
      "2021-10-24 14:03:00.126529: This epoch took 196.618574 s\n",
      "\n",
      "2021-10-24 14:03:00.147055: \n",
      "epoch:  10\n",
      "2021-10-24 14:06:00.789150: train loss : -0.8575\n",
      "2021-10-24 14:06:14.600449: validation loss: -0.8188\n",
      "2021-10-24 14:06:14.604778: Average global foreground Dice: [0.8317]\n",
      "2021-10-24 14:06:14.612396: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:06:15.142766: lr: 0.007996\n",
      "2021-10-24 14:06:15.195911: saving checkpoint...\n",
      "2021-10-24 14:06:16.337523: done, saving took 1.16 seconds\n",
      "2021-10-24 14:06:16.748363: This epoch took 196.594434 s\n",
      "\n",
      "2021-10-24 14:06:16.766126: \n",
      "epoch:  11\n",
      "2021-10-24 14:09:17.762249: train loss : -0.8603\n",
      "2021-10-24 14:09:31.568960: validation loss: -0.8212\n",
      "2021-10-24 14:09:31.573224: Average global foreground Dice: [0.8333]\n",
      "2021-10-24 14:09:31.579461: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:09:32.064471: lr: 0.007811\n",
      "2021-10-24 14:09:32.113682: saving checkpoint...\n",
      "2021-10-24 14:09:33.208858: done, saving took 1.11 seconds\n",
      "2021-10-24 14:09:33.621937: This epoch took 196.848973 s\n",
      "\n",
      "2021-10-24 14:09:33.640787: \n",
      "epoch:  12\n",
      "2021-10-24 14:12:34.418630: train loss : -0.8626\n",
      "2021-10-24 14:12:48.227175: validation loss: -0.8125\n",
      "2021-10-24 14:12:48.232064: Average global foreground Dice: [0.826]\n",
      "2021-10-24 14:12:48.238421: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:12:48.736948: lr: 0.007626\n",
      "2021-10-24 14:12:48.790872: saving checkpoint...\n",
      "2021-10-24 14:12:50.092745: done, saving took 1.33 seconds\n",
      "2021-10-24 14:12:50.199325: This epoch took 196.552430 s\n",
      "\n",
      "2021-10-24 14:12:50.217016: \n",
      "epoch:  13\n",
      "2021-10-24 14:15:51.166147: train loss : -0.8650\n",
      "2021-10-24 14:16:04.974886: validation loss: -0.8185\n",
      "2021-10-24 14:16:04.979511: Average global foreground Dice: [0.8318]\n",
      "2021-10-24 14:16:04.986708: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:16:05.587203: lr: 0.00744\n",
      "2021-10-24 14:16:05.639789: saving checkpoint...\n",
      "2021-10-24 14:16:06.767027: done, saving took 1.15 seconds\n",
      "2021-10-24 14:16:07.240066: This epoch took 197.015598 s\n",
      "\n",
      "2021-10-24 14:16:07.260152: \n",
      "epoch:  14\n",
      "2021-10-24 14:19:08.315233: train loss : -0.8688\n",
      "2021-10-24 14:19:22.123161: validation loss: -0.8218\n",
      "2021-10-24 14:19:22.127299: Average global foreground Dice: [0.8315]\n",
      "2021-10-24 14:19:22.134505: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:19:22.644301: lr: 0.007254\n",
      "2021-10-24 14:19:22.696707: saving checkpoint...\n",
      "2021-10-24 14:19:23.809355: done, saving took 1.13 seconds\n",
      "2021-10-24 14:19:24.152200: This epoch took 196.885172 s\n",
      "\n",
      "2021-10-24 14:19:24.172111: \n",
      "epoch:  15\n",
      "2021-10-24 14:22:25.099377: train loss : -0.8707\n",
      "2021-10-24 14:22:38.878529: validation loss: -0.8202\n",
      "2021-10-24 14:22:38.882743: Average global foreground Dice: [0.8329]\n",
      "2021-10-24 14:22:38.889547: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:22:39.432708: lr: 0.007067\n",
      "2021-10-24 14:22:39.483006: saving checkpoint...\n",
      "2021-10-24 14:22:40.575268: done, saving took 1.11 seconds\n",
      "2021-10-24 14:22:41.022128: This epoch took 196.843458 s\n",
      "\n",
      "2021-10-24 14:22:41.039065: \n",
      "epoch:  16\n",
      "2021-10-24 14:25:42.722994: train loss : -0.8712\n",
      "2021-10-24 14:25:56.513341: validation loss: -0.8182\n",
      "2021-10-24 14:25:56.517580: Average global foreground Dice: [0.831]\n",
      "2021-10-24 14:25:56.523071: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:25:57.060405: lr: 0.00688\n",
      "2021-10-24 14:25:57.108605: saving checkpoint...\n",
      "2021-10-24 14:25:58.204958: done, saving took 1.12 seconds\n",
      "2021-10-24 14:25:58.660503: This epoch took 197.614330 s\n",
      "\n",
      "2021-10-24 14:25:58.678979: \n",
      "epoch:  17\n",
      "2021-10-24 14:29:00.047720: train loss : -0.8745\n",
      "2021-10-24 14:29:13.889712: validation loss: -0.8242\n",
      "2021-10-24 14:29:13.894362: Average global foreground Dice: [0.8343]\n",
      "2021-10-24 14:29:13.903271: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:29:14.451412: lr: 0.006692\n",
      "2021-10-24 14:29:14.502840: saving checkpoint...\n",
      "2021-10-24 14:29:15.619940: done, saving took 1.14 seconds\n",
      "2021-10-24 14:29:15.855949: This epoch took 197.167412 s\n",
      "\n",
      "2021-10-24 14:29:15.875077: \n",
      "epoch:  18\n",
      "2021-10-24 14:32:17.390726: train loss : -0.8773\n",
      "2021-10-24 14:32:31.188395: validation loss: -0.8188\n",
      "2021-10-24 14:32:31.192958: Average global foreground Dice: [0.8295]\n",
      "2021-10-24 14:32:31.199289: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:32:31.695045: lr: 0.006504\n",
      "2021-10-24 14:32:31.744686: saving checkpoint...\n",
      "2021-10-24 14:32:32.926815: done, saving took 1.20 seconds\n",
      "2021-10-24 14:32:33.179650: This epoch took 197.297466 s\n",
      "\n",
      "2021-10-24 14:32:33.200074: \n",
      "epoch:  19\n",
      "2021-10-24 14:35:34.785459: train loss : -0.8785\n",
      "2021-10-24 14:35:48.592790: validation loss: -0.8253\n",
      "2021-10-24 14:35:48.597162: Average global foreground Dice: [0.8359]\n",
      "2021-10-24 14:35:48.603696: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:35:49.104351: lr: 0.006314\n",
      "2021-10-24 14:35:49.145687: saving checkpoint...\n",
      "2021-10-24 14:35:50.250195: done, saving took 1.12 seconds\n",
      "2021-10-24 14:35:50.522208: This epoch took 197.315021 s\n",
      "\n",
      "2021-10-24 14:35:50.530648: \n",
      "epoch:  20\n",
      "2021-10-24 14:38:52.262195: train loss : -0.8796\n",
      "2021-10-24 14:39:06.078467: validation loss: -0.8225\n",
      "2021-10-24 14:39:06.082711: Average global foreground Dice: [0.8336]\n",
      "2021-10-24 14:39:06.089103: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:39:06.625906: lr: 0.006125\n",
      "2021-10-24 14:39:06.664541: saving checkpoint...\n",
      "2021-10-24 14:39:07.787275: done, saving took 1.14 seconds\n",
      "2021-10-24 14:39:08.286754: This epoch took 197.749230 s\n",
      "\n",
      "2021-10-24 14:39:08.295883: \n",
      "epoch:  21\n",
      "2021-10-24 14:42:09.910554: train loss : -0.8803\n",
      "2021-10-24 14:42:23.728842: validation loss: -0.8209\n",
      "2021-10-24 14:42:23.733713: Average global foreground Dice: [0.8312]\n",
      "2021-10-24 14:42:23.740746: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:42:24.251086: lr: 0.005934\n",
      "2021-10-24 14:42:24.294313: saving checkpoint...\n",
      "2021-10-24 14:42:25.392356: done, saving took 1.12 seconds\n",
      "2021-10-24 14:42:25.868253: This epoch took 197.564692 s\n",
      "\n",
      "2021-10-24 14:42:25.877178: \n",
      "epoch:  22\n",
      "2021-10-24 14:45:27.591436: train loss : -0.8830\n",
      "2021-10-24 14:45:41.415761: validation loss: -0.8233\n",
      "2021-10-24 14:45:41.421883: Average global foreground Dice: [0.8344]\n",
      "2021-10-24 14:45:41.428388: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:45:41.938165: lr: 0.005743\n",
      "2021-10-24 14:45:41.979968: saving checkpoint...\n",
      "2021-10-24 14:45:43.082557: done, saving took 1.12 seconds\n",
      "2021-10-24 14:45:43.646414: This epoch took 197.762017 s\n",
      "\n",
      "2021-10-24 14:45:43.654883: \n",
      "epoch:  23\n",
      "2021-10-24 14:48:45.496958: train loss : -0.8831\n",
      "2021-10-24 14:48:59.302753: validation loss: -0.8202\n",
      "2021-10-24 14:48:59.307390: Average global foreground Dice: [0.8306]\n",
      "2021-10-24 14:48:59.313595: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:48:59.839273: lr: 0.005551\n",
      "2021-10-24 14:48:59.879687: saving checkpoint...\n",
      "2021-10-24 14:49:00.968297: done, saving took 1.11 seconds\n",
      "2021-10-24 14:49:01.442817: This epoch took 197.780477 s\n",
      "\n",
      "2021-10-24 14:49:01.452352: \n",
      "epoch:  24\n",
      "2021-10-24 14:52:03.840474: train loss : -0.8841\n",
      "2021-10-24 14:52:17.666490: validation loss: -0.8196\n",
      "2021-10-24 14:52:17.671134: Average global foreground Dice: [0.8311]\n",
      "2021-10-24 14:52:17.678287: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:52:18.247311: lr: 0.005359\n",
      "2021-10-24 14:52:18.287887: saving checkpoint...\n",
      "2021-10-24 14:52:19.387598: done, saving took 1.12 seconds\n",
      "2021-10-24 14:52:20.037084: This epoch took 198.578296 s\n",
      "\n",
      "2021-10-24 14:52:20.046385: \n",
      "epoch:  25\n",
      "2021-10-24 14:55:22.408056: train loss : -0.8859\n",
      "2021-10-24 14:55:36.224878: validation loss: -0.8246\n",
      "2021-10-24 14:55:36.229284: Average global foreground Dice: [0.8338]\n",
      "2021-10-24 14:55:36.236154: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:55:36.798869: lr: 0.005166\n",
      "2021-10-24 14:55:36.841222: saving checkpoint...\n",
      "2021-10-24 14:55:37.952287: done, saving took 1.13 seconds\n",
      "2021-10-24 14:55:38.369857: This epoch took 198.315696 s\n",
      "\n",
      "2021-10-24 14:55:38.378203: \n",
      "epoch:  26\n",
      "2021-10-24 14:58:40.622093: train loss : -0.8881\n",
      "2021-10-24 14:58:54.447504: validation loss: -0.8276\n",
      "2021-10-24 14:58:54.452104: Average global foreground Dice: [0.8382]\n",
      "2021-10-24 14:58:54.459153: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:58:54.948999: lr: 0.004971\n",
      "2021-10-24 14:58:54.993112: saving checkpoint...\n",
      "2021-10-24 14:58:56.122318: done, saving took 1.15 seconds\n",
      "2021-10-24 14:58:56.567559: This epoch took 198.182318 s\n",
      "\n",
      "2021-10-24 14:58:56.576102: \n",
      "epoch:  27\n",
      "2021-10-24 15:01:58.897054: train loss : -0.8889\n",
      "2021-10-24 15:02:12.708836: validation loss: -0.8201\n",
      "2021-10-24 15:02:12.713595: Average global foreground Dice: [0.8306]\n",
      "2021-10-24 15:02:12.720997: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:02:13.254570: lr: 0.004776\n",
      "2021-10-24 15:02:13.293255: saving checkpoint...\n",
      "2021-10-24 15:02:14.391556: done, saving took 1.12 seconds\n",
      "2021-10-24 15:02:15.173669: This epoch took 198.591621 s\n",
      "\n",
      "2021-10-24 15:02:15.183445: \n",
      "epoch:  28\n",
      "2021-10-24 15:05:17.431828: train loss : -0.8899\n",
      "2021-10-24 15:05:31.257568: validation loss: -0.8245\n",
      "2021-10-24 15:05:31.263896: Average global foreground Dice: [0.8349]\n",
      "2021-10-24 15:05:31.270395: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:05:31.805266: lr: 0.004581\n",
      "2021-10-24 15:05:31.846129: saving checkpoint...\n",
      "2021-10-24 15:05:32.950243: done, saving took 1.12 seconds\n",
      "2021-10-24 15:05:33.502775: This epoch took 198.312057 s\n",
      "\n",
      "2021-10-24 15:05:33.511519: \n",
      "epoch:  29\n",
      "2021-10-24 15:08:35.906508: train loss : -0.8920\n",
      "2021-10-24 15:08:49.725973: validation loss: -0.8185\n",
      "2021-10-24 15:08:49.731056: Average global foreground Dice: [0.8298]\n",
      "2021-10-24 15:08:49.738089: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:08:50.300544: lr: 0.004384\n",
      "2021-10-24 15:08:50.343464: saving checkpoint...\n",
      "2021-10-24 15:08:51.507568: done, saving took 1.18 seconds\n",
      "2021-10-24 15:08:51.943580: This epoch took 198.425317 s\n",
      "\n",
      "2021-10-24 15:08:51.952016: \n",
      "epoch:  30\n",
      "2021-10-24 15:11:54.368151: train loss : -0.8924\n",
      "2021-10-24 15:12:08.194981: validation loss: -0.8186\n",
      "2021-10-24 15:12:08.199623: Average global foreground Dice: [0.8292]\n",
      "2021-10-24 15:12:08.205604: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:12:08.740736: lr: 0.004186\n",
      "2021-10-24 15:12:08.783179: saving checkpoint...\n",
      "2021-10-24 15:12:09.863384: done, saving took 1.10 seconds\n",
      "2021-10-24 15:12:10.153154: This epoch took 198.193837 s\n",
      "\n",
      "2021-10-24 15:12:10.161377: \n",
      "epoch:  31\n",
      "2021-10-24 15:15:12.573116: train loss : -0.8926\n",
      "2021-10-24 15:15:26.402346: validation loss: -0.8191\n",
      "2021-10-24 15:15:26.408420: Average global foreground Dice: [0.8283]\n",
      "2021-10-24 15:15:26.415038: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:15:26.936662: lr: 0.003987\n",
      "2021-10-24 15:15:26.978928: saving checkpoint...\n",
      "2021-10-24 15:15:28.094644: done, saving took 1.13 seconds\n",
      "2021-10-24 15:15:28.568905: This epoch took 198.400805 s\n",
      "\n",
      "2021-10-24 15:15:28.577415: \n",
      "epoch:  32\n",
      "2021-10-24 15:18:31.104983: train loss : -0.8945\n",
      "2021-10-24 15:18:44.952777: validation loss: -0.8218\n",
      "2021-10-24 15:18:44.957221: Average global foreground Dice: [0.8316]\n",
      "2021-10-24 15:18:44.965222: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:18:45.484275: lr: 0.003787\n",
      "2021-10-24 15:18:45.522958: saving checkpoint...\n",
      "2021-10-24 15:18:46.629845: done, saving took 1.13 seconds\n",
      "2021-10-24 15:18:46.928361: This epoch took 198.343654 s\n",
      "\n",
      "2021-10-24 15:18:46.937084: \n",
      "epoch:  33\n",
      "2021-10-24 15:21:49.471540: train loss : -0.8959\n",
      "2021-10-24 15:22:03.292659: validation loss: -0.8244\n",
      "2021-10-24 15:22:03.297091: Average global foreground Dice: [0.8347]\n",
      "2021-10-24 15:22:03.303971: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:22:03.800031: lr: 0.003586\n",
      "2021-10-24 15:22:03.845041: saving checkpoint...\n",
      "2021-10-24 15:22:04.961337: done, saving took 1.14 seconds\n",
      "2021-10-24 15:22:05.305530: This epoch took 198.361514 s\n",
      "\n",
      "2021-10-24 15:22:05.314645: \n",
      "epoch:  34\n",
      "2021-10-24 15:25:07.819792: train loss : -0.8971\n",
      "2021-10-24 15:25:21.638763: validation loss: -0.8214\n",
      "2021-10-24 15:25:21.643069: Average global foreground Dice: [0.8323]\n",
      "2021-10-24 15:25:21.650599: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:25:22.204802: lr: 0.003384\n",
      "2021-10-24 15:25:22.243183: saving checkpoint...\n",
      "2021-10-24 15:25:23.368754: done, saving took 1.14 seconds\n",
      "2021-10-24 15:25:23.719625: This epoch took 198.397324 s\n",
      "\n",
      "2021-10-24 15:25:23.728498: \n",
      "epoch:  35\n",
      "2021-10-24 15:28:26.257487: train loss : -0.8985\n",
      "2021-10-24 15:28:40.095924: validation loss: -0.8254\n",
      "2021-10-24 15:28:40.100186: Average global foreground Dice: [0.8352]\n",
      "2021-10-24 15:28:40.107288: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:28:40.720721: lr: 0.00318\n",
      "2021-10-24 15:28:40.759612: saving checkpoint...\n",
      "2021-10-24 15:28:41.884460: done, saving took 1.14 seconds\n",
      "2021-10-24 15:28:42.124166: This epoch took 198.388572 s\n",
      "\n",
      "2021-10-24 15:28:42.132710: \n",
      "epoch:  36\n",
      "2021-10-24 15:31:44.658720: train loss : -0.8987\n",
      "2021-10-24 15:31:58.476579: validation loss: -0.8223\n",
      "2021-10-24 15:31:58.480747: Average global foreground Dice: [0.8322]\n",
      "2021-10-24 15:31:58.487129: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:31:59.026065: lr: 0.002975\n",
      "2021-10-24 15:31:59.080904: saving checkpoint...\n",
      "2021-10-24 15:32:00.165009: done, saving took 1.10 seconds\n",
      "2021-10-24 15:32:00.612230: This epoch took 198.472549 s\n",
      "\n",
      "2021-10-24 15:32:00.620926: \n",
      "epoch:  37\n",
      "2021-10-24 15:35:03.139813: train loss : -0.9001\n",
      "2021-10-24 15:35:16.987903: validation loss: -0.8220\n",
      "2021-10-24 15:35:16.992487: Average global foreground Dice: [0.8316]\n",
      "2021-10-24 15:35:16.999561: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:35:17.498540: lr: 0.002768\n",
      "2021-10-24 15:35:17.539523: saving checkpoint...\n",
      "2021-10-24 15:35:18.618386: done, saving took 1.10 seconds\n",
      "2021-10-24 15:35:19.058152: This epoch took 198.426982 s\n",
      "\n",
      "2021-10-24 15:35:19.066747: \n",
      "epoch:  38\n",
      "2021-10-24 15:38:21.581141: train loss : -0.9014\n",
      "2021-10-24 15:38:35.413106: validation loss: -0.8217\n",
      "2021-10-24 15:38:35.417685: Average global foreground Dice: [0.8316]\n",
      "2021-10-24 15:38:35.424768: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:38:35.925754: lr: 0.00256\n",
      "2021-10-24 15:38:35.965469: saving checkpoint...\n",
      "2021-10-24 15:38:37.042141: done, saving took 1.10 seconds\n",
      "2021-10-24 15:38:37.490672: This epoch took 198.410596 s\n",
      "\n",
      "2021-10-24 15:38:37.499718: \n",
      "epoch:  39\n",
      "2021-10-24 15:41:40.032419: train loss : -0.9014\n",
      "2021-10-24 15:41:53.873705: validation loss: -0.8228\n",
      "2021-10-24 15:41:53.878748: Average global foreground Dice: [0.8326]\n",
      "2021-10-24 15:41:53.885628: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:41:54.388413: lr: 0.002349\n",
      "2021-10-24 15:41:54.426805: saving checkpoint...\n",
      "2021-10-24 15:41:55.543717: done, saving took 1.14 seconds\n",
      "2021-10-24 15:41:56.085442: This epoch took 198.577537 s\n",
      "\n",
      "2021-10-24 15:41:56.093126: \n",
      "epoch:  40\n",
      "2021-10-24 15:44:58.656851: train loss : -0.9034\n",
      "2021-10-24 15:45:12.486019: validation loss: -0.8207\n",
      "2021-10-24 15:45:12.490833: Average global foreground Dice: [0.8296]\n",
      "2021-10-24 15:45:12.497831: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:45:13.021674: lr: 0.002137\n",
      "2021-10-24 15:45:13.043581: This epoch took 196.943210 s\n",
      "\n",
      "2021-10-24 15:45:13.049759: \n",
      "epoch:  41\n",
      "2021-10-24 15:48:15.631480: train loss : -0.9037\n",
      "2021-10-24 15:48:29.453587: validation loss: -0.8245\n",
      "2021-10-24 15:48:29.457869: Average global foreground Dice: [0.8354]\n",
      "2021-10-24 15:48:29.464570: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:48:29.979172: lr: 0.001922\n",
      "2021-10-24 15:48:30.017819: saving checkpoint...\n",
      "2021-10-24 15:48:31.114498: done, saving took 1.12 seconds\n",
      "2021-10-24 15:48:31.525322: This epoch took 198.469027 s\n",
      "\n",
      "2021-10-24 15:48:31.533783: \n",
      "epoch:  42\n",
      "2021-10-24 15:51:34.105742: train loss : -0.9049\n",
      "2021-10-24 15:51:47.940150: validation loss: -0.8210\n",
      "2021-10-24 15:51:47.944455: Average global foreground Dice: [0.8314]\n",
      "2021-10-24 15:51:47.950786: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:51:48.441867: lr: 0.001704\n",
      "2021-10-24 15:51:48.489631: saving checkpoint...\n",
      "2021-10-24 15:51:49.634890: done, saving took 1.16 seconds\n",
      "2021-10-24 15:51:50.058549: This epoch took 198.517689 s\n",
      "\n",
      "2021-10-24 15:51:50.076082: \n",
      "epoch:  43\n",
      "2021-10-24 15:54:52.643731: train loss : -0.9059\n",
      "2021-10-24 15:55:06.470773: validation loss: -0.8212\n",
      "2021-10-24 15:55:06.474874: Average global foreground Dice: [0.8309]\n",
      "2021-10-24 15:55:06.481726: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:55:07.019156: lr: 0.001483\n",
      "2021-10-24 15:55:07.070592: saving checkpoint...\n",
      "2021-10-24 15:55:08.156786: done, saving took 1.10 seconds\n",
      "2021-10-24 15:55:08.604662: This epoch took 198.521251 s\n",
      "\n",
      "2021-10-24 15:55:08.621973: \n",
      "epoch:  44\n",
      "2021-10-24 15:58:11.211591: train loss : -0.9075\n",
      "2021-10-24 15:58:25.052803: validation loss: -0.8221\n",
      "2021-10-24 15:58:25.057271: Average global foreground Dice: [0.8314]\n",
      "2021-10-24 15:58:25.066427: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:58:25.597961: lr: 0.001259\n",
      "2021-10-24 15:58:25.647578: saving checkpoint...\n",
      "2021-10-24 15:58:26.742911: done, saving took 1.11 seconds\n",
      "2021-10-24 15:58:27.189745: This epoch took 198.559943 s\n",
      "\n",
      "2021-10-24 15:58:27.210825: \n",
      "epoch:  45\n",
      "2021-10-24 16:01:29.790074: train loss : -0.9082\n",
      "2021-10-24 16:01:43.621813: validation loss: -0.8185\n",
      "2021-10-24 16:01:43.626059: Average global foreground Dice: [0.8295]\n",
      "2021-10-24 16:01:43.633101: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:01:44.163768: lr: 0.00103\n",
      "2021-10-24 16:01:44.190769: This epoch took 196.972761 s\n",
      "\n",
      "2021-10-24 16:01:44.196869: \n",
      "epoch:  46\n",
      "2021-10-24 16:04:46.772324: train loss : -0.9092\n",
      "2021-10-24 16:05:00.593273: validation loss: -0.8188\n",
      "2021-10-24 16:05:00.598009: Average global foreground Dice: [0.8287]\n",
      "2021-10-24 16:05:00.604993: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:05:01.120240: lr: 0.000795\n",
      "2021-10-24 16:05:01.145230: This epoch took 196.942465 s\n",
      "\n",
      "2021-10-24 16:05:01.151948: \n",
      "epoch:  47\n",
      "2021-10-24 16:08:03.734428: train loss : -0.9085\n",
      "2021-10-24 16:08:17.592523: validation loss: -0.8226\n",
      "2021-10-24 16:08:17.598331: Average global foreground Dice: [0.8308]\n",
      "2021-10-24 16:08:17.605269: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:08:18.137016: lr: 0.000552\n",
      "2021-10-24 16:08:18.171635: This epoch took 197.012337 s\n",
      "\n",
      "2021-10-24 16:08:18.178523: \n",
      "epoch:  48\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-24 16:11:20.760252: train loss : -0.9100\n",
      "2021-10-24 16:11:34.583089: validation loss: -0.8215\n",
      "2021-10-24 16:11:34.587889: Average global foreground Dice: [0.8309]\n",
      "2021-10-24 16:11:34.594177: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:11:35.140652: lr: 0.000296\n",
      "2021-10-24 16:11:35.171732: This epoch took 196.986079 s\n",
      "\n",
      "2021-10-24 16:11:35.178463: \n",
      "epoch:  49\n",
      "2021-10-24 16:14:37.732688: train loss : -0.9108\n",
      "2021-10-24 16:14:51.559486: validation loss: -0.8198\n",
      "2021-10-24 16:14:51.564175: Average global foreground Dice: [0.8293]\n",
      "2021-10-24 16:14:51.570872: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:14:52.137721: lr: 0.0\n",
      "2021-10-24 16:14:52.171845: saving scheduled checkpoint file...\n",
      "2021-10-24 16:14:52.202032: saving checkpoint...\n",
      "2021-10-24 16:14:53.146780: done, saving took 0.97 seconds\n",
      "2021-10-24 16:14:53.660241: done\n",
      "2021-10-24 16:14:53.679339: This epoch took 198.493607 s\n",
      "\n",
      "2021-10-24 16:14:53.704604: saving checkpoint...\n",
      "2021-10-24 16:14:54.632037: done, saving took 0.95 seconds\n",
      "23090557_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090558_20120 (3, 263, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090560_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090562_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090564_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090566_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090568_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090569_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090571_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090593_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090597_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090600_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090603_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090607_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090609_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090619_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090621_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090629_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090637_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090644_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090646_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-24 16:19:49.183383: finished prediction\n",
      "2021-10-24 16:19:49.189948: evaluation of raw predictions\n",
      "2021-10-24 16:19:52.848907: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8183778978503475\n",
      "after:  0.8156732730565895\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-10-24 16:20:11.044228: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-10-24 16:20:11.065658: The split file contains 2 splits.\n",
      "2021-10-24 16:20:11.072833: Desired fold for training: 2\n",
      "2021-10-24 16:20:11.079596: INFO: You requested fold 2 for training but splits contain only 2 folds. I am now creating a random (but seeded) 80:20 split!\n",
      "2021-10-24 16:20:11.087375: This random 80:20 split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-24 16:20:15.245847: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-24 16:20:24.528749: Unable to plot network architecture:\n",
      "2021-10-24 16:20:24.596909: No module named 'hiddenlayer'\n",
      "2021-10-24 16:20:24.740541: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-24 16:20:24.868563: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-24 16:20:24.974388: \n",
      "\n",
      "2021-10-24 16:20:25.094062: \n",
      "epoch:  0\n",
      "2021-10-24 16:23:41.898482: train loss : -0.2389\n",
      "2021-10-24 16:23:55.350923: validation loss: -0.6184\n",
      "2021-10-24 16:23:55.355438: Average global foreground Dice: [0.6963]\n",
      "2021-10-24 16:23:55.362920: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:23:55.827195: lr: 0.00982\n",
      "2021-10-24 16:23:55.849755: This epoch took 210.677068 s\n",
      "\n",
      "2021-10-24 16:23:55.856828: \n",
      "epoch:  1\n",
      "2021-10-24 16:26:55.558709: train loss : -0.6599\n",
      "2021-10-24 16:27:09.050184: validation loss: -0.7338\n",
      "2021-10-24 16:27:09.054962: Average global foreground Dice: [0.8006]\n",
      "2021-10-24 16:27:09.061552: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:27:09.552909: lr: 0.009639\n",
      "2021-10-24 16:27:09.623401: saving checkpoint...\n",
      "2021-10-24 16:27:10.636101: done, saving took 1.05 seconds\n",
      "2021-10-24 16:27:11.179689: This epoch took 195.315481 s\n",
      "\n",
      "2021-10-24 16:27:11.192743: \n",
      "epoch:  2\n",
      "2021-10-24 16:30:10.797293: train loss : -0.7613\n",
      "2021-10-24 16:30:24.287940: validation loss: -0.7959\n",
      "2021-10-24 16:30:24.292886: Average global foreground Dice: [0.8167]\n",
      "2021-10-24 16:30:24.298473: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:30:24.814223: lr: 0.009458\n",
      "2021-10-24 16:30:24.879171: saving checkpoint...\n",
      "2021-10-24 16:30:25.972119: done, saving took 1.13 seconds\n",
      "2021-10-24 16:30:26.419363: This epoch took 195.220027 s\n",
      "\n",
      "2021-10-24 16:30:26.438511: \n",
      "epoch:  3\n",
      "2021-10-24 16:33:25.753616: train loss : -0.7957\n",
      "2021-10-24 16:33:39.260753: validation loss: -0.8106\n",
      "2021-10-24 16:33:39.265273: Average global foreground Dice: [0.8261]\n",
      "2021-10-24 16:33:39.273257: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:33:39.829906: lr: 0.009277\n",
      "2021-10-24 16:33:39.891814: saving checkpoint...\n",
      "2021-10-24 16:33:40.969778: done, saving took 1.11 seconds\n",
      "2021-10-24 16:33:41.432138: This epoch took 194.986816 s\n",
      "\n",
      "2021-10-24 16:33:41.462077: \n",
      "epoch:  4\n",
      "2021-10-24 16:36:40.592069: train loss : -0.8091\n",
      "2021-10-24 16:36:54.085686: validation loss: -0.8224\n",
      "2021-10-24 16:36:54.090173: Average global foreground Dice: [0.8358]\n",
      "2021-10-24 16:36:54.096238: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:36:54.671120: lr: 0.009095\n",
      "2021-10-24 16:36:54.732998: saving checkpoint...\n",
      "2021-10-24 16:36:55.792921: done, saving took 1.09 seconds\n",
      "2021-10-24 16:36:56.279621: This epoch took 194.810510 s\n",
      "\n",
      "2021-10-24 16:36:56.300285: \n",
      "epoch:  5\n",
      "2021-10-24 16:39:55.337314: train loss : -0.8225\n",
      "2021-10-24 16:40:08.829611: validation loss: -0.8253\n",
      "2021-10-24 16:40:08.833927: Average global foreground Dice: [0.8392]\n",
      "2021-10-24 16:40:08.840932: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:40:09.344505: lr: 0.008913\n",
      "2021-10-24 16:40:09.404686: saving checkpoint...\n",
      "2021-10-24 16:40:10.524012: done, saving took 1.15 seconds\n",
      "2021-10-24 16:40:11.017902: This epoch took 194.711008 s\n",
      "\n",
      "2021-10-24 16:40:11.035527: \n",
      "epoch:  6\n",
      "2021-10-24 16:43:10.265429: train loss : -0.8283\n",
      "2021-10-24 16:43:23.749088: validation loss: -0.8307\n",
      "2021-10-24 16:43:23.754769: Average global foreground Dice: [0.8428]\n",
      "2021-10-24 16:43:23.761584: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:43:24.349077: lr: 0.008731\n",
      "2021-10-24 16:43:24.406563: saving checkpoint...\n",
      "2021-10-24 16:43:25.559319: done, saving took 1.18 seconds\n",
      "2021-10-24 16:43:26.030099: This epoch took 194.987828 s\n",
      "\n",
      "2021-10-24 16:43:26.042338: \n",
      "epoch:  7\n",
      "2021-10-24 16:46:25.239428: train loss : -0.8321\n",
      "2021-10-24 16:46:38.738487: validation loss: -0.8272\n",
      "2021-10-24 16:46:38.742905: Average global foreground Dice: [0.8403]\n",
      "2021-10-24 16:46:38.750110: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:46:39.289551: lr: 0.008548\n",
      "2021-10-24 16:46:39.340976: saving checkpoint...\n",
      "2021-10-24 16:46:40.457259: done, saving took 1.15 seconds\n",
      "2021-10-24 16:46:40.958399: This epoch took 194.908051 s\n",
      "\n",
      "2021-10-24 16:46:40.967031: \n",
      "epoch:  8\n",
      "2021-10-24 16:49:40.464757: train loss : -0.8372\n",
      "2021-10-24 16:49:53.969375: validation loss: -0.8231\n",
      "2021-10-24 16:49:53.973957: Average global foreground Dice: [0.8365]\n",
      "2021-10-24 16:49:53.980542: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:49:54.507431: lr: 0.008364\n",
      "2021-10-24 16:49:54.547313: saving checkpoint...\n",
      "2021-10-24 16:49:55.656388: done, saving took 1.13 seconds\n",
      "2021-10-24 16:49:56.095288: This epoch took 195.120805 s\n",
      "\n",
      "2021-10-24 16:49:56.104683: \n",
      "epoch:  9\n",
      "2021-10-24 16:52:55.642510: train loss : -0.8415\n",
      "2021-10-24 16:53:09.154500: validation loss: -0.8298\n",
      "2021-10-24 16:53:09.159187: Average global foreground Dice: [0.8406]\n",
      "2021-10-24 16:53:09.165560: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:53:09.701430: lr: 0.008181\n",
      "2021-10-24 16:53:09.739639: saving checkpoint...\n",
      "2021-10-24 16:53:10.820111: done, saving took 1.10 seconds\n",
      "2021-10-24 16:53:11.290828: This epoch took 195.179713 s\n",
      "\n",
      "2021-10-24 16:53:11.299295: \n",
      "epoch:  10\n",
      "2021-10-24 16:56:10.891892: train loss : -0.8438\n",
      "2021-10-24 16:56:24.410502: validation loss: -0.8272\n",
      "2021-10-24 16:56:24.415142: Average global foreground Dice: [0.8385]\n",
      "2021-10-24 16:56:24.421611: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:56:24.954571: lr: 0.007996\n",
      "2021-10-24 16:56:24.999336: saving checkpoint...\n",
      "2021-10-24 16:56:26.089102: done, saving took 1.11 seconds\n",
      "2021-10-24 16:56:26.524270: This epoch took 195.217305 s\n",
      "\n",
      "2021-10-24 16:56:26.533204: \n",
      "epoch:  11\n",
      "2021-10-24 16:59:26.153882: train loss : -0.8462\n",
      "2021-10-24 16:59:39.675897: validation loss: -0.8244\n",
      "2021-10-24 16:59:39.680318: Average global foreground Dice: [0.8362]\n",
      "2021-10-24 16:59:39.687509: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:59:40.199681: lr: 0.007811\n",
      "2021-10-24 16:59:40.237581: saving checkpoint...\n",
      "2021-10-24 16:59:41.350101: done, saving took 1.13 seconds\n",
      "2021-10-24 16:59:41.785038: This epoch took 195.244239 s\n",
      "\n",
      "2021-10-24 16:59:41.793792: \n",
      "epoch:  12\n",
      "2021-10-24 17:02:41.418074: train loss : -0.8515\n",
      "2021-10-24 17:02:54.918193: validation loss: -0.8223\n",
      "2021-10-24 17:02:54.922853: Average global foreground Dice: [0.8338]\n",
      "2021-10-24 17:02:54.929908: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:02:55.490706: lr: 0.007626\n",
      "2021-10-24 17:02:55.557355: saving checkpoint...\n",
      "2021-10-24 17:02:56.655466: done, saving took 1.14 seconds\n",
      "2021-10-24 17:02:57.151786: This epoch took 195.350551 s\n",
      "\n",
      "2021-10-24 17:02:57.160051: \n",
      "epoch:  13\n",
      "2021-10-24 17:05:56.714574: train loss : -0.8527\n",
      "2021-10-24 17:06:10.193537: validation loss: -0.8311\n",
      "2021-10-24 17:06:10.198076: Average global foreground Dice: [0.843]\n",
      "2021-10-24 17:06:10.205443: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:06:10.738383: lr: 0.00744\n",
      "2021-10-24 17:06:10.777604: saving checkpoint...\n",
      "2021-10-24 17:06:11.876755: done, saving took 1.12 seconds\n",
      "2021-10-24 17:06:12.307589: This epoch took 195.140914 s\n",
      "\n",
      "2021-10-24 17:06:12.316059: \n",
      "epoch:  14\n",
      "2021-10-24 17:09:11.888185: train loss : -0.8551\n",
      "2021-10-24 17:09:25.390951: validation loss: -0.8317\n",
      "2021-10-24 17:09:25.395882: Average global foreground Dice: [0.8428]\n",
      "2021-10-24 17:09:25.403181: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:09:25.918406: lr: 0.007254\n",
      "2021-10-24 17:09:25.961221: saving checkpoint...\n",
      "2021-10-24 17:09:27.065701: done, saving took 1.12 seconds\n",
      "2021-10-24 17:09:27.567547: This epoch took 195.244143 s\n",
      "\n",
      "2021-10-24 17:09:27.576889: \n",
      "epoch:  15\n",
      "2021-10-24 17:12:27.100083: train loss : -0.8597\n",
      "2021-10-24 17:12:40.584228: validation loss: -0.8328\n",
      "2021-10-24 17:12:40.589142: Average global foreground Dice: [0.8429]\n",
      "2021-10-24 17:12:40.601152: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:12:41.160880: lr: 0.007067\n",
      "2021-10-24 17:12:41.201529: saving checkpoint...\n",
      "2021-10-24 17:12:42.306479: done, saving took 1.12 seconds\n",
      "2021-10-24 17:12:42.858814: This epoch took 195.275226 s\n",
      "\n",
      "2021-10-24 17:12:42.867675: \n",
      "epoch:  16\n",
      "2021-10-24 17:15:42.690679: train loss : -0.8605\n",
      "2021-10-24 17:15:56.185823: validation loss: -0.8306\n",
      "2021-10-24 17:15:56.190434: Average global foreground Dice: [0.8407]\n",
      "2021-10-24 17:15:56.197742: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:15:56.747689: lr: 0.00688\n",
      "2021-10-24 17:15:56.791020: saving checkpoint...\n",
      "2021-10-24 17:15:57.865984: done, saving took 1.09 seconds\n",
      "2021-10-24 17:15:58.314243: This epoch took 195.439651 s\n",
      "\n",
      "2021-10-24 17:15:58.322372: \n",
      "epoch:  17\n",
      "2021-10-24 17:18:58.182813: train loss : -0.8615\n",
      "2021-10-24 17:19:11.687631: validation loss: -0.8220\n",
      "2021-10-24 17:19:11.692454: Average global foreground Dice: [0.8338]\n",
      "2021-10-24 17:19:11.699386: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:19:12.289241: lr: 0.006692\n",
      "2021-10-24 17:19:12.339317: saving checkpoint...\n",
      "2021-10-24 17:19:13.450827: done, saving took 1.14 seconds\n",
      "2021-10-24 17:19:13.923532: This epoch took 195.594085 s\n",
      "\n",
      "2021-10-24 17:19:13.931799: \n",
      "epoch:  18\n",
      "2021-10-24 17:22:13.922566: train loss : -0.8646\n",
      "2021-10-24 17:22:27.444672: validation loss: -0.8297\n",
      "2021-10-24 17:22:27.449692: Average global foreground Dice: [0.8406]\n",
      "2021-10-24 17:22:27.457294: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:22:28.000073: lr: 0.006504\n",
      "2021-10-24 17:22:28.037791: saving checkpoint...\n",
      "2021-10-24 17:22:29.135133: done, saving took 1.12 seconds\n",
      "2021-10-24 17:22:29.598633: This epoch took 195.659354 s\n",
      "\n",
      "2021-10-24 17:22:29.606790: \n",
      "epoch:  19\n",
      "2021-10-24 17:25:29.553661: train loss : -0.8654\n",
      "2021-10-24 17:25:43.046974: validation loss: -0.8312\n",
      "2021-10-24 17:25:43.052573: Average global foreground Dice: [0.8415]\n",
      "2021-10-24 17:25:43.059647: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:25:43.618699: lr: 0.006314\n",
      "2021-10-24 17:25:43.661427: saving checkpoint...\n",
      "2021-10-24 17:25:44.765550: done, saving took 1.12 seconds\n",
      "2021-10-24 17:25:45.264056: This epoch took 195.650010 s\n",
      "\n",
      "2021-10-24 17:25:45.272446: \n",
      "epoch:  20\n",
      "2021-10-24 17:28:45.211194: train loss : -0.8654\n",
      "2021-10-24 17:28:58.688919: validation loss: -0.8282\n",
      "2021-10-24 17:28:58.693215: Average global foreground Dice: [0.8396]\n",
      "2021-10-24 17:28:58.699513: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:28:59.287506: lr: 0.006125\n",
      "2021-10-24 17:28:59.329283: saving checkpoint...\n",
      "2021-10-24 17:29:00.449567: done, saving took 1.14 seconds\n",
      "2021-10-24 17:29:00.881000: This epoch took 195.601408 s\n",
      "\n",
      "2021-10-24 17:29:00.891104: \n",
      "epoch:  21\n",
      "2021-10-24 17:32:00.811327: train loss : -0.8676\n",
      "2021-10-24 17:32:14.310374: validation loss: -0.8336\n",
      "2021-10-24 17:32:14.314568: Average global foreground Dice: [0.8443]\n",
      "2021-10-24 17:32:14.321455: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:32:14.809780: lr: 0.005934\n",
      "2021-10-24 17:32:14.849575: saving checkpoint...\n",
      "2021-10-24 17:32:15.952789: done, saving took 1.12 seconds\n",
      "2021-10-24 17:32:16.465436: This epoch took 195.567456 s\n",
      "\n",
      "2021-10-24 17:32:16.474289: \n",
      "epoch:  22\n",
      "2021-10-24 17:35:16.436061: train loss : -0.8683\n",
      "2021-10-24 17:35:29.947770: validation loss: -0.8335\n",
      "2021-10-24 17:35:29.952478: Average global foreground Dice: [0.8444]\n",
      "2021-10-24 17:35:29.959309: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:35:30.553303: lr: 0.005743\n",
      "2021-10-24 17:35:30.602040: saving checkpoint...\n",
      "2021-10-24 17:35:31.693426: done, saving took 1.12 seconds\n",
      "2021-10-24 17:35:32.183152: This epoch took 195.701973 s\n",
      "\n",
      "2021-10-24 17:35:32.191714: \n",
      "epoch:  23\n",
      "2021-10-24 17:38:32.193845: train loss : -0.8706\n",
      "2021-10-24 17:38:45.707114: validation loss: -0.8319\n",
      "2021-10-24 17:38:45.712270: Average global foreground Dice: [0.842]\n",
      "2021-10-24 17:38:45.719506: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:38:46.254645: lr: 0.005551\n",
      "2021-10-24 17:38:46.296455: saving checkpoint...\n",
      "2021-10-24 17:38:47.415062: done, saving took 1.14 seconds\n",
      "2021-10-24 17:38:47.859161: This epoch took 195.660492 s\n",
      "\n",
      "2021-10-24 17:38:47.867286: \n",
      "epoch:  24\n",
      "2021-10-24 17:41:48.094194: train loss : -0.8721\n",
      "2021-10-24 17:42:01.589217: validation loss: -0.8364\n",
      "2021-10-24 17:42:01.593582: Average global foreground Dice: [0.8481]\n",
      "2021-10-24 17:42:01.600415: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:42:02.155130: lr: 0.005359\n",
      "2021-10-24 17:42:02.192776: saving checkpoint...\n",
      "2021-10-24 17:42:03.287066: done, saving took 1.11 seconds\n",
      "2021-10-24 17:42:03.720230: This epoch took 195.845917 s\n",
      "\n",
      "2021-10-24 17:42:03.728549: \n",
      "epoch:  25\n",
      "2021-10-24 17:45:04.010607: train loss : -0.8743\n",
      "2021-10-24 17:45:17.519547: validation loss: -0.8378\n",
      "2021-10-24 17:45:17.524621: Average global foreground Dice: [0.8485]\n",
      "2021-10-24 17:45:17.531304: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:45:18.042542: lr: 0.005166\n",
      "2021-10-24 17:45:18.082065: saving checkpoint...\n",
      "2021-10-24 17:45:19.202045: done, saving took 1.14 seconds\n",
      "2021-10-24 17:45:19.677360: This epoch took 195.942227 s\n",
      "\n",
      "2021-10-24 17:45:19.686295: \n",
      "epoch:  26\n",
      "2021-10-24 17:48:19.890135: train loss : -0.8753\n",
      "2021-10-24 17:48:33.381615: validation loss: -0.8311\n",
      "2021-10-24 17:48:33.386569: Average global foreground Dice: [0.8419]\n",
      "2021-10-24 17:48:33.392890: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:48:33.889623: lr: 0.004971\n",
      "2021-10-24 17:48:33.931380: saving checkpoint...\n",
      "2021-10-24 17:48:35.025139: done, saving took 1.11 seconds\n",
      "2021-10-24 17:48:35.500753: This epoch took 195.807418 s\n",
      "\n",
      "2021-10-24 17:48:35.509042: \n",
      "epoch:  27\n",
      "2021-10-24 17:51:35.700157: train loss : -0.8759\n",
      "2021-10-24 17:51:49.201236: validation loss: -0.8385\n",
      "2021-10-24 17:51:49.205524: Average global foreground Dice: [0.8481]\n",
      "2021-10-24 17:51:49.212593: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:51:49.787356: lr: 0.004776\n",
      "2021-10-24 17:51:49.834239: saving checkpoint...\n",
      "2021-10-24 17:51:50.962817: done, saving took 1.15 seconds\n",
      "2021-10-24 17:51:51.441643: This epoch took 195.925964 s\n",
      "\n",
      "2021-10-24 17:51:51.450515: \n",
      "epoch:  28\n",
      "2021-10-24 17:54:51.706387: train loss : -0.8778\n",
      "2021-10-24 17:55:05.205952: validation loss: -0.8318\n",
      "2021-10-24 17:55:05.210474: Average global foreground Dice: [0.8419]\n",
      "2021-10-24 17:55:05.217352: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:55:05.733396: lr: 0.004581\n",
      "2021-10-24 17:55:05.775747: saving checkpoint...\n",
      "2021-10-24 17:55:06.901090: done, saving took 1.14 seconds\n",
      "2021-10-24 17:55:07.365745: This epoch took 195.907126 s\n",
      "\n",
      "2021-10-24 17:55:07.374493: \n",
      "epoch:  29\n",
      "2021-10-24 17:58:07.637203: train loss : -0.8769\n",
      "2021-10-24 17:58:21.124530: validation loss: -0.8306\n",
      "2021-10-24 17:58:21.129675: Average global foreground Dice: [0.8426]\n",
      "2021-10-24 17:58:21.136329: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:58:21.664054: lr: 0.004384\n",
      "2021-10-24 17:58:21.704091: saving checkpoint...\n",
      "2021-10-24 17:58:22.784372: done, saving took 1.10 seconds\n",
      "2021-10-24 17:58:23.223920: This epoch took 195.843347 s\n",
      "\n",
      "2021-10-24 17:58:23.232588: \n",
      "epoch:  30\n",
      "2021-10-24 18:01:23.469794: train loss : -0.8791\n",
      "2021-10-24 18:01:36.982090: validation loss: -0.8342\n",
      "2021-10-24 18:01:36.986677: Average global foreground Dice: [0.8449]\n",
      "2021-10-24 18:01:36.994155: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:01:37.533588: lr: 0.004186\n",
      "2021-10-24 18:01:37.594815: saving checkpoint...\n",
      "2021-10-24 18:01:38.703232: done, saving took 1.13 seconds\n",
      "2021-10-24 18:01:39.211961: This epoch took 195.972973 s\n",
      "\n",
      "2021-10-24 18:01:39.233690: \n",
      "epoch:  31\n",
      "2021-10-24 18:04:39.481895: train loss : -0.8816\n",
      "2021-10-24 18:04:52.999821: validation loss: -0.8299\n",
      "2021-10-24 18:04:53.004696: Average global foreground Dice: [0.8412]\n",
      "2021-10-24 18:04:53.013244: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:04:53.513892: lr: 0.003987\n",
      "2021-10-24 18:04:53.558436: saving checkpoint...\n",
      "2021-10-24 18:04:54.653403: done, saving took 1.11 seconds\n",
      "2021-10-24 18:04:55.099867: This epoch took 195.858057 s\n",
      "\n",
      "2021-10-24 18:04:55.112764: \n",
      "epoch:  32\n",
      "2021-10-24 18:07:55.672203: train loss : -0.8801\n",
      "2021-10-24 18:08:09.170772: validation loss: -0.8363\n",
      "2021-10-24 18:08:09.175253: Average global foreground Dice: [0.8444]\n",
      "2021-10-24 18:08:09.181630: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:08:09.782739: lr: 0.003787\n",
      "2021-10-24 18:08:09.839643: saving checkpoint...\n",
      "2021-10-24 18:08:10.964788: done, saving took 1.15 seconds\n",
      "2021-10-24 18:08:11.550846: This epoch took 196.431197 s\n",
      "\n",
      "2021-10-24 18:08:11.568077: \n",
      "epoch:  33\n",
      "2021-10-24 18:11:12.162881: train loss : -0.8817\n",
      "2021-10-24 18:11:25.682047: validation loss: -0.8327\n",
      "2021-10-24 18:11:25.687875: Average global foreground Dice: [0.8439]\n",
      "2021-10-24 18:11:25.695719: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:11:26.220572: lr: 0.003586\n",
      "2021-10-24 18:11:26.269052: saving checkpoint...\n",
      "2021-10-24 18:11:27.420590: done, saving took 1.17 seconds\n",
      "2021-10-24 18:11:27.948349: This epoch took 196.374518 s\n",
      "\n",
      "2021-10-24 18:11:27.963903: \n",
      "epoch:  34\n",
      "2021-10-24 18:14:28.530597: train loss : -0.8843\n",
      "2021-10-24 18:14:42.069953: validation loss: -0.8333\n",
      "2021-10-24 18:14:42.075371: Average global foreground Dice: [0.8429]\n",
      "2021-10-24 18:14:42.084673: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:14:42.645382: lr: 0.003384\n",
      "2021-10-24 18:14:42.692353: saving checkpoint...\n",
      "2021-10-24 18:14:43.727312: done, saving took 1.05 seconds\n",
      "2021-10-24 18:14:44.154091: This epoch took 196.183503 s\n",
      "\n",
      "2021-10-24 18:14:44.169590: \n",
      "epoch:  35\n",
      "2021-10-24 18:17:44.778395: train loss : -0.8851\n",
      "2021-10-24 18:17:58.302064: validation loss: -0.8356\n",
      "2021-10-24 18:17:58.307667: Average global foreground Dice: [0.8465]\n",
      "2021-10-24 18:17:58.314485: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:17:58.815025: lr: 0.00318\n",
      "2021-10-24 18:17:58.873797: saving checkpoint...\n",
      "2021-10-24 18:17:59.922400: done, saving took 1.07 seconds\n",
      "2021-10-24 18:18:00.393982: This epoch took 196.216700 s\n",
      "\n",
      "2021-10-24 18:18:00.415255: \n",
      "epoch:  36\n",
      "2021-10-24 18:21:01.005107: train loss : -0.8862\n",
      "2021-10-24 18:21:14.514577: validation loss: -0.8339\n",
      "2021-10-24 18:21:14.519646: Average global foreground Dice: [0.8435]\n",
      "2021-10-24 18:21:14.527031: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:21:15.094203: lr: 0.002975\n",
      "2021-10-24 18:21:15.154670: saving checkpoint...\n",
      "2021-10-24 18:21:16.210922: done, saving took 1.08 seconds\n",
      "2021-10-24 18:21:16.660651: This epoch took 196.237839 s\n",
      "\n",
      "2021-10-24 18:21:16.679232: \n",
      "epoch:  37\n",
      "2021-10-24 18:24:17.223517: train loss : -0.8870\n",
      "2021-10-24 18:24:30.747156: validation loss: -0.8372\n",
      "2021-10-24 18:24:30.752129: Average global foreground Dice: [0.8467]\n",
      "2021-10-24 18:24:30.759934: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:24:31.328067: lr: 0.002768\n",
      "2021-10-24 18:24:31.388408: saving checkpoint...\n",
      "2021-10-24 18:24:32.498948: done, saving took 1.14 seconds\n",
      "2021-10-24 18:24:32.972363: This epoch took 196.285597 s\n",
      "\n",
      "2021-10-24 18:24:32.993053: \n",
      "epoch:  38\n",
      "2021-10-24 18:27:33.564617: train loss : -0.8880\n",
      "2021-10-24 18:27:47.070179: validation loss: -0.8336\n",
      "2021-10-24 18:27:47.076040: Average global foreground Dice: [0.8436]\n",
      "2021-10-24 18:27:47.083359: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:27:47.603707: lr: 0.00256\n",
      "2021-10-24 18:27:47.654607: saving checkpoint...\n",
      "2021-10-24 18:27:48.764005: done, saving took 1.13 seconds\n",
      "2021-10-24 18:27:49.213881: This epoch took 196.212129 s\n",
      "\n",
      "2021-10-24 18:27:49.231735: \n",
      "epoch:  39\n",
      "2021-10-24 18:30:49.781325: train loss : -0.8884\n",
      "2021-10-24 18:31:03.287900: validation loss: -0.8313\n",
      "2021-10-24 18:31:03.293002: Average global foreground Dice: [0.8398]\n",
      "2021-10-24 18:31:03.301824: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:31:03.807715: lr: 0.002349\n",
      "2021-10-24 18:31:03.843557: This epoch took 194.603903 s\n",
      "\n",
      "2021-10-24 18:31:03.851281: \n",
      "epoch:  40\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-24 18:34:04.857699: train loss : -0.8902\n",
      "2021-10-24 18:34:18.376063: validation loss: -0.8325\n",
      "2021-10-24 18:34:18.381257: Average global foreground Dice: [0.8418]\n",
      "2021-10-24 18:34:18.389126: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:34:18.892980: lr: 0.002137\n",
      "2021-10-24 18:34:18.947917: saving checkpoint...\n",
      "2021-10-24 18:34:20.108385: done, saving took 1.18 seconds\n",
      "2021-10-24 18:34:20.581839: This epoch took 196.722869 s\n",
      "\n",
      "2021-10-24 18:34:20.602900: \n",
      "epoch:  41\n",
      "2021-10-24 18:37:21.111490: train loss : -0.8902\n",
      "2021-10-24 18:37:34.634158: validation loss: -0.8333\n",
      "2021-10-24 18:37:34.639050: Average global foreground Dice: [0.845]\n",
      "2021-10-24 18:37:34.646010: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:37:35.194911: lr: 0.001922\n",
      "2021-10-24 18:37:35.243142: saving checkpoint...\n",
      "2021-10-24 18:37:36.362480: done, saving took 1.14 seconds\n",
      "2021-10-24 18:37:36.914187: This epoch took 196.303683 s\n",
      "\n",
      "2021-10-24 18:37:36.933645: \n",
      "epoch:  42\n",
      "2021-10-24 18:40:37.543367: train loss : -0.8924\n",
      "2021-10-24 18:40:51.047939: validation loss: -0.8334\n",
      "2021-10-24 18:40:51.053080: Average global foreground Dice: [0.8443]\n",
      "2021-10-24 18:40:51.059664: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:40:51.623563: lr: 0.001704\n",
      "2021-10-24 18:40:51.675959: saving checkpoint...\n",
      "2021-10-24 18:40:52.819046: done, saving took 1.16 seconds\n",
      "2021-10-24 18:40:53.305315: This epoch took 196.364106 s\n",
      "\n",
      "2021-10-24 18:40:53.323579: \n",
      "epoch:  43\n",
      "2021-10-24 18:43:53.886818: train loss : -0.8919\n",
      "2021-10-24 18:44:07.389854: validation loss: -0.8325\n",
      "2021-10-24 18:44:07.393995: Average global foreground Dice: [0.8437]\n",
      "2021-10-24 18:44:07.400511: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:44:07.939168: lr: 0.001483\n",
      "2021-10-24 18:44:07.991062: saving checkpoint...\n",
      "2021-10-24 18:44:09.089123: done, saving took 1.12 seconds\n",
      "2021-10-24 18:44:09.795132: This epoch took 196.464301 s\n",
      "\n",
      "2021-10-24 18:44:09.815638: \n",
      "epoch:  44\n",
      "2021-10-24 18:47:10.244709: train loss : -0.8935\n",
      "2021-10-24 18:47:23.766731: validation loss: -0.8332\n",
      "2021-10-24 18:47:23.771177: Average global foreground Dice: [0.8428]\n",
      "2021-10-24 18:47:23.778421: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:47:24.271805: lr: 0.001259\n",
      "2021-10-24 18:47:24.322526: saving checkpoint...\n",
      "2021-10-24 18:47:25.464900: done, saving took 1.16 seconds\n",
      "2021-10-24 18:47:25.895721: This epoch took 196.073371 s\n",
      "\n",
      "2021-10-24 18:47:25.916142: \n",
      "epoch:  45\n",
      "2021-10-24 18:50:26.559340: train loss : -0.8945\n",
      "2021-10-24 18:50:40.058450: validation loss: -0.8353\n",
      "2021-10-24 18:50:40.063176: Average global foreground Dice: [0.8449]\n",
      "2021-10-24 18:50:40.072790: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:50:40.571276: lr: 0.00103\n",
      "2021-10-24 18:50:40.617624: saving checkpoint...\n",
      "2021-10-24 18:50:41.698539: done, saving took 1.10 seconds\n",
      "2021-10-24 18:50:42.174907: This epoch took 196.251664 s\n",
      "\n",
      "2021-10-24 18:50:42.189291: \n",
      "epoch:  46\n",
      "2021-10-24 18:53:42.764614: train loss : -0.8965\n",
      "2021-10-24 18:53:56.283766: validation loss: -0.8328\n",
      "2021-10-24 18:53:56.288130: Average global foreground Dice: [0.8431]\n",
      "2021-10-24 18:53:56.295005: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:53:56.810464: lr: 0.000795\n",
      "2021-10-24 18:53:56.866980: saving checkpoint...\n",
      "2021-10-24 18:53:57.951999: done, saving took 1.10 seconds\n",
      "2021-10-24 18:53:58.519123: This epoch took 196.323459 s\n",
      "\n",
      "2021-10-24 18:53:58.538424: \n",
      "epoch:  47\n",
      "2021-10-24 18:56:59.132831: train loss : -0.8969\n",
      "2021-10-24 18:57:12.651338: validation loss: -0.8366\n",
      "2021-10-24 18:57:12.655716: Average global foreground Dice: [0.8461]\n",
      "2021-10-24 18:57:12.662535: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:57:13.256841: lr: 0.000552\n",
      "2021-10-24 18:57:13.309756: saving checkpoint...\n",
      "2021-10-24 18:57:14.400476: done, saving took 1.11 seconds\n",
      "2021-10-24 18:57:14.850260: This epoch took 196.295041 s\n",
      "\n",
      "2021-10-24 18:57:14.868678: \n",
      "epoch:  48\n",
      "2021-10-24 19:00:15.512765: train loss : -0.8970\n",
      "2021-10-24 19:00:28.996361: validation loss: -0.8370\n",
      "2021-10-24 19:00:29.001189: Average global foreground Dice: [0.8466]\n",
      "2021-10-24 19:00:29.013641: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:00:29.559589: lr: 0.000296\n",
      "2021-10-24 19:00:29.622289: saving checkpoint...\n",
      "2021-10-24 19:00:30.737904: done, saving took 1.13 seconds\n",
      "2021-10-24 19:00:31.276778: This epoch took 196.400264 s\n",
      "\n",
      "2021-10-24 19:00:31.295285: \n",
      "epoch:  49\n",
      "2021-10-24 19:03:32.287638: train loss : -0.8991\n",
      "2021-10-24 19:03:45.800519: validation loss: -0.8327\n",
      "2021-10-24 19:03:45.806076: Average global foreground Dice: [0.8423]\n",
      "2021-10-24 19:03:45.815950: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:03:46.375590: lr: 0.0\n",
      "2021-10-24 19:03:46.407490: saving scheduled checkpoint file...\n",
      "2021-10-24 19:03:46.435362: saving checkpoint...\n",
      "2021-10-24 19:03:47.392352: done, saving took 0.98 seconds\n",
      "2021-10-24 19:03:47.838507: done\n",
      "2021-10-24 19:03:47.856525: This epoch took 196.554411 s\n",
      "\n",
      "2021-10-24 19:03:47.882207: saving checkpoint...\n",
      "2021-10-24 19:03:48.857545: done, saving took 0.99 seconds\n",
      "23090559_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-24 19:05:47.986095: finished prediction\n",
      "2021-10-24 19:05:47.995601: evaluation of raw predictions\n",
      "2021-10-24 19:05:50.106542: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8359750599923186\n",
      "after:  0.8359750599923186\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-10-24 19:06:03.363327: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-10-24 19:06:03.386248: The split file contains 2 splits.\n",
      "2021-10-24 19:06:03.392496: Desired fold for training: 3\n",
      "2021-10-24 19:06:03.398860: INFO: You requested fold 3 for training but splits contain only 2 folds. I am now creating a random (but seeded) 80:20 split!\n",
      "2021-10-24 19:06:03.405875: This random 80:20 split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-24 19:06:07.560171: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-24 19:06:16.656745: Unable to plot network architecture:\n",
      "2021-10-24 19:06:16.772617: No module named 'hiddenlayer'\n",
      "2021-10-24 19:06:16.880615: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-24 19:06:16.976770: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-24 19:06:17.142101: \n",
      "\n",
      "2021-10-24 19:06:17.325146: \n",
      "epoch:  0\n",
      "2021-10-24 19:09:34.157400: train loss : -0.3071\n",
      "2021-10-24 19:09:47.651990: validation loss: -0.6651\n",
      "2021-10-24 19:09:47.656502: Average global foreground Dice: [0.7336]\n",
      "2021-10-24 19:09:47.663306: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:09:48.130426: lr: 0.00982\n",
      "2021-10-24 19:09:48.152444: This epoch took 210.694984 s\n",
      "\n",
      "2021-10-24 19:09:48.158111: \n",
      "epoch:  1\n",
      "2021-10-24 19:12:46.767506: train loss : -0.6759\n",
      "2021-10-24 19:13:00.258781: validation loss: -0.7464\n",
      "2021-10-24 19:13:00.263005: Average global foreground Dice: [0.8164]\n",
      "2021-10-24 19:13:00.269747: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:13:00.769947: lr: 0.009639\n",
      "2021-10-24 19:13:00.833949: saving checkpoint...\n",
      "2021-10-24 19:13:01.839029: done, saving took 1.05 seconds\n",
      "2021-10-24 19:13:02.315118: This epoch took 194.150783 s\n",
      "\n",
      "2021-10-24 19:13:02.323460: \n",
      "epoch:  2\n",
      "2021-10-24 19:16:00.848135: train loss : -0.7559\n",
      "2021-10-24 19:16:14.334497: validation loss: -0.8117\n",
      "2021-10-24 19:16:14.339264: Average global foreground Dice: [0.8287]\n",
      "2021-10-24 19:16:14.346052: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:16:14.890389: lr: 0.009458\n",
      "2021-10-24 19:16:14.933163: saving checkpoint...\n",
      "2021-10-24 19:16:16.068242: done, saving took 1.15 seconds\n",
      "2021-10-24 19:16:16.532532: This epoch took 194.201877 s\n",
      "\n",
      "2021-10-24 19:16:16.541910: \n",
      "epoch:  3\n",
      "2021-10-24 19:19:14.801013: train loss : -0.7989\n",
      "2021-10-24 19:19:28.291130: validation loss: -0.8214\n",
      "2021-10-24 19:19:28.297066: Average global foreground Dice: [0.8378]\n",
      "2021-10-24 19:19:28.303599: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:19:28.858623: lr: 0.009277\n",
      "2021-10-24 19:19:28.899181: saving checkpoint...\n",
      "2021-10-24 19:19:29.971205: done, saving took 1.09 seconds\n",
      "2021-10-24 19:19:30.515662: This epoch took 193.964619 s\n",
      "\n",
      "2021-10-24 19:19:30.524408: \n",
      "epoch:  4\n",
      "2021-10-24 19:22:28.623270: train loss : -0.8119\n",
      "2021-10-24 19:22:42.113350: validation loss: -0.8321\n",
      "2021-10-24 19:22:42.118301: Average global foreground Dice: [0.8456]\n",
      "2021-10-24 19:22:42.125548: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:22:42.638556: lr: 0.009095\n",
      "2021-10-24 19:22:42.678183: saving checkpoint...\n",
      "2021-10-24 19:22:43.785696: done, saving took 1.13 seconds\n",
      "2021-10-24 19:22:44.231262: This epoch took 193.699395 s\n",
      "\n",
      "2021-10-24 19:22:44.239965: \n",
      "epoch:  5\n",
      "2021-10-24 19:25:42.474105: train loss : -0.8203\n",
      "2021-10-24 19:25:55.972202: validation loss: -0.8295\n",
      "2021-10-24 19:25:55.977381: Average global foreground Dice: [0.8441]\n",
      "2021-10-24 19:25:55.984068: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:25:56.504347: lr: 0.008913\n",
      "2021-10-24 19:25:56.550919: saving checkpoint...\n",
      "2021-10-24 19:25:57.700815: done, saving took 1.17 seconds\n",
      "2021-10-24 19:25:58.226105: This epoch took 193.979300 s\n",
      "\n",
      "2021-10-24 19:25:58.234742: \n",
      "epoch:  6\n",
      "2021-10-24 19:28:56.593500: train loss : -0.8275\n",
      "2021-10-24 19:29:10.106490: validation loss: -0.8378\n",
      "2021-10-24 19:29:10.111096: Average global foreground Dice: [0.8512]\n",
      "2021-10-24 19:29:10.116943: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:29:10.665791: lr: 0.008731\n",
      "2021-10-24 19:29:10.707468: saving checkpoint...\n",
      "2021-10-24 19:29:11.868124: done, saving took 1.18 seconds\n",
      "2021-10-24 19:29:12.347675: This epoch took 194.106697 s\n",
      "\n",
      "2021-10-24 19:29:12.356139: \n",
      "epoch:  7\n",
      "2021-10-24 19:32:10.748062: train loss : -0.8302\n",
      "2021-10-24 19:32:24.236907: validation loss: -0.8373\n",
      "2021-10-24 19:32:24.241793: Average global foreground Dice: [0.8486]\n",
      "2021-10-24 19:32:24.248446: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:32:24.758801: lr: 0.008548\n",
      "2021-10-24 19:32:24.798096: saving checkpoint...\n",
      "2021-10-24 19:32:25.901828: done, saving took 1.12 seconds\n",
      "2021-10-24 19:32:26.393343: This epoch took 194.030946 s\n",
      "\n",
      "2021-10-24 19:32:26.418282: \n",
      "epoch:  8\n",
      "2021-10-24 19:35:25.136766: train loss : -0.8365\n",
      "2021-10-24 19:35:38.650529: validation loss: -0.8388\n",
      "2021-10-24 19:35:38.654994: Average global foreground Dice: [0.8501]\n",
      "2021-10-24 19:35:38.661929: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:35:39.162210: lr: 0.008364\n",
      "2021-10-24 19:35:39.200405: saving checkpoint...\n",
      "2021-10-24 19:35:40.299541: done, saving took 1.12 seconds\n",
      "2021-10-24 19:35:40.754303: This epoch took 194.329144 s\n",
      "\n",
      "2021-10-24 19:35:40.762787: \n",
      "epoch:  9\n",
      "2021-10-24 19:38:39.540963: train loss : -0.8416\n",
      "2021-10-24 19:38:53.046642: validation loss: -0.8376\n",
      "2021-10-24 19:38:53.050921: Average global foreground Dice: [0.8474]\n",
      "2021-10-24 19:38:53.058090: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:38:53.566916: lr: 0.008181\n",
      "2021-10-24 19:38:53.605599: saving checkpoint...\n",
      "2021-10-24 19:38:54.695460: done, saving took 1.11 seconds\n",
      "2021-10-24 19:38:55.172355: This epoch took 194.403607 s\n",
      "\n",
      "2021-10-24 19:38:55.181003: \n",
      "epoch:  10\n",
      "2021-10-24 19:41:53.985646: train loss : -0.8433\n",
      "2021-10-24 19:42:07.486750: validation loss: -0.8353\n",
      "2021-10-24 19:42:07.492036: Average global foreground Dice: [0.8476]\n",
      "2021-10-24 19:42:07.504890: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:42:08.025289: lr: 0.007996\n",
      "2021-10-24 19:42:08.067571: saving checkpoint...\n",
      "2021-10-24 19:42:09.161975: done, saving took 1.12 seconds\n",
      "2021-10-24 19:42:09.627872: This epoch took 194.439423 s\n",
      "\n",
      "2021-10-24 19:42:09.637007: \n",
      "epoch:  11\n",
      "2021-10-24 19:45:08.521969: train loss : -0.8463\n",
      "2021-10-24 19:45:22.027928: validation loss: -0.8472\n",
      "2021-10-24 19:45:22.032926: Average global foreground Dice: [0.8575]\n",
      "2021-10-24 19:45:22.040148: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:45:22.568842: lr: 0.007811\n",
      "2021-10-24 19:45:22.607549: saving checkpoint...\n",
      "2021-10-24 19:45:23.779262: done, saving took 1.19 seconds\n",
      "2021-10-24 19:45:24.263857: This epoch took 194.619936 s\n",
      "\n",
      "2021-10-24 19:45:24.273363: \n",
      "epoch:  12\n",
      "2021-10-24 19:48:23.200451: train loss : -0.8493\n",
      "2021-10-24 19:48:36.712567: validation loss: -0.8423\n",
      "2021-10-24 19:48:36.717820: Average global foreground Dice: [0.8541]\n",
      "2021-10-24 19:48:36.723924: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:48:37.268757: lr: 0.007626\n",
      "2021-10-24 19:48:37.308351: saving checkpoint...\n",
      "2021-10-24 19:48:38.406435: done, saving took 1.12 seconds\n",
      "2021-10-24 19:48:38.921892: This epoch took 194.640483 s\n",
      "\n",
      "2021-10-24 19:48:38.930620: \n",
      "epoch:  13\n",
      "2021-10-24 19:51:37.957740: train loss : -0.8507\n",
      "2021-10-24 19:51:51.475684: validation loss: -0.8380\n",
      "2021-10-24 19:51:51.479932: Average global foreground Dice: [0.8497]\n",
      "2021-10-24 19:51:51.486984: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:51:52.003292: lr: 0.00744\n",
      "2021-10-24 19:51:52.047175: saving checkpoint...\n",
      "2021-10-24 19:51:53.149737: done, saving took 1.12 seconds\n",
      "2021-10-24 19:51:53.574804: This epoch took 194.636885 s\n",
      "\n",
      "2021-10-24 19:51:53.583558: \n",
      "epoch:  14\n",
      "2021-10-24 19:54:52.641249: train loss : -0.8538\n",
      "2021-10-24 19:55:06.145430: validation loss: -0.8306\n",
      "2021-10-24 19:55:06.149841: Average global foreground Dice: [0.8392]\n",
      "2021-10-24 19:55:06.157485: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:55:06.678977: lr: 0.007254\n",
      "2021-10-24 19:55:06.717026: saving checkpoint...\n",
      "2021-10-24 19:55:07.835215: done, saving took 1.14 seconds\n",
      "2021-10-24 19:55:08.391299: This epoch took 194.800567 s\n",
      "\n",
      "2021-10-24 19:55:08.399598: \n",
      "epoch:  15\n",
      "2021-10-24 19:58:07.519516: train loss : -0.8555\n",
      "2021-10-24 19:58:21.037383: validation loss: -0.8448\n",
      "2021-10-24 19:58:21.042086: Average global foreground Dice: [0.8558]\n",
      "2021-10-24 19:58:21.048834: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:58:21.554718: lr: 0.007067\n",
      "2021-10-24 19:58:21.595253: saving checkpoint...\n",
      "2021-10-24 19:58:22.726876: done, saving took 1.15 seconds\n",
      "2021-10-24 19:58:23.187196: This epoch took 194.781129 s\n",
      "\n",
      "2021-10-24 19:58:23.195963: \n",
      "epoch:  16\n",
      "2021-10-24 20:01:22.821624: train loss : -0.8586\n",
      "2021-10-24 20:01:36.328006: validation loss: -0.8397\n",
      "2021-10-24 20:01:36.332357: Average global foreground Dice: [0.852]\n",
      "2021-10-24 20:01:36.339876: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:01:36.904104: lr: 0.00688\n",
      "2021-10-24 20:01:36.943414: saving checkpoint...\n",
      "2021-10-24 20:01:38.049835: done, saving took 1.13 seconds\n",
      "2021-10-24 20:01:38.485233: This epoch took 195.282063 s\n",
      "\n",
      "2021-10-24 20:01:38.493772: \n",
      "epoch:  17\n",
      "2021-10-24 20:04:38.083255: train loss : -0.8607\n",
      "2021-10-24 20:04:51.604350: validation loss: -0.8457\n",
      "2021-10-24 20:04:51.608621: Average global foreground Dice: [0.856]\n",
      "2021-10-24 20:04:51.616213: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:04:52.206330: lr: 0.006692\n",
      "2021-10-24 20:04:52.247398: saving checkpoint...\n",
      "2021-10-24 20:04:53.358740: done, saving took 1.13 seconds\n",
      "2021-10-24 20:04:53.893064: This epoch took 195.392284 s\n",
      "\n",
      "2021-10-24 20:04:53.901250: \n",
      "epoch:  18\n",
      "2021-10-24 20:07:53.513623: train loss : -0.8627\n",
      "2021-10-24 20:08:06.993000: validation loss: -0.8446\n",
      "2021-10-24 20:08:06.997364: Average global foreground Dice: [0.8556]\n",
      "2021-10-24 20:08:07.022184: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:08:07.583380: lr: 0.006504\n",
      "2021-10-24 20:08:07.624229: saving checkpoint...\n",
      "2021-10-24 20:08:08.697434: done, saving took 1.09 seconds\n",
      "2021-10-24 20:08:09.140573: This epoch took 195.232635 s\n",
      "\n",
      "2021-10-24 20:08:09.148990: \n",
      "epoch:  19\n",
      "2021-10-24 20:11:08.877974: train loss : -0.8635\n",
      "2021-10-24 20:11:22.393513: validation loss: -0.8412\n",
      "2021-10-24 20:11:22.397781: Average global foreground Dice: [0.8518]\n",
      "2021-10-24 20:11:22.404762: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:11:22.938565: lr: 0.006314\n",
      "2021-10-24 20:11:22.989018: saving checkpoint...\n",
      "2021-10-24 20:11:24.074382: done, saving took 1.10 seconds\n",
      "2021-10-24 20:11:24.538747: This epoch took 195.382639 s\n",
      "\n",
      "2021-10-24 20:11:24.558319: \n",
      "epoch:  20\n",
      "2021-10-24 20:14:24.392318: train loss : -0.8654\n",
      "2021-10-24 20:14:37.898515: validation loss: -0.8391\n",
      "2021-10-24 20:14:37.902966: Average global foreground Dice: [0.8479]\n",
      "2021-10-24 20:14:37.909149: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:14:38.432449: lr: 0.006125\n",
      "2021-10-24 20:14:38.479470: saving checkpoint...\n",
      "2021-10-24 20:14:39.559992: done, saving took 1.10 seconds\n",
      "2021-10-24 20:14:39.987528: This epoch took 195.422009 s\n",
      "\n",
      "2021-10-24 20:14:40.006894: \n",
      "epoch:  21\n",
      "2021-10-24 20:17:39.731362: train loss : -0.8662\n",
      "2021-10-24 20:17:53.243068: validation loss: -0.8430\n",
      "2021-10-24 20:17:53.248284: Average global foreground Dice: [0.8532]\n",
      "2021-10-24 20:17:53.255656: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:17:53.774890: lr: 0.005934\n",
      "2021-10-24 20:17:53.823981: saving checkpoint...\n",
      "2021-10-24 20:17:54.904573: done, saving took 1.10 seconds\n",
      "2021-10-24 20:17:55.436399: This epoch took 195.421902 s\n",
      "\n",
      "2021-10-24 20:17:55.455128: \n",
      "epoch:  22\n",
      "2021-10-24 20:20:55.137953: train loss : -0.8682\n",
      "2021-10-24 20:21:08.647611: validation loss: -0.8424\n",
      "2021-10-24 20:21:08.652105: Average global foreground Dice: [0.8539]\n",
      "2021-10-24 20:21:08.658649: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:21:09.272467: lr: 0.005743\n",
      "2021-10-24 20:21:09.315314: saving checkpoint...\n",
      "2021-10-24 20:21:10.432645: done, saving took 1.14 seconds\n",
      "2021-10-24 20:21:10.978644: This epoch took 195.516651 s\n",
      "\n",
      "2021-10-24 20:21:10.990609: \n",
      "epoch:  23\n",
      "2021-10-24 20:24:10.792255: train loss : -0.8706\n",
      "2021-10-24 20:24:24.295926: validation loss: -0.8463\n",
      "2021-10-24 20:24:24.301042: Average global foreground Dice: [0.8564]\n",
      "2021-10-24 20:24:24.307601: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:24:24.861260: lr: 0.005551\n",
      "2021-10-24 20:24:24.909134: saving checkpoint...\n",
      "2021-10-24 20:24:26.004306: done, saving took 1.11 seconds\n",
      "2021-10-24 20:24:26.466582: This epoch took 195.469139 s\n",
      "\n",
      "2021-10-24 20:24:26.486424: \n",
      "epoch:  24\n",
      "2021-10-24 20:27:26.598994: train loss : -0.8707\n",
      "2021-10-24 20:27:40.109450: validation loss: -0.8438\n",
      "2021-10-24 20:27:40.115873: Average global foreground Dice: [0.8552]\n",
      "2021-10-24 20:27:40.122932: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:27:40.663037: lr: 0.005359\n",
      "2021-10-24 20:27:40.712775: saving checkpoint...\n",
      "2021-10-24 20:27:41.793876: done, saving took 1.10 seconds\n",
      "2021-10-24 20:27:42.231386: This epoch took 195.738579 s\n",
      "\n",
      "2021-10-24 20:27:42.251078: \n",
      "epoch:  25\n",
      "2021-10-24 20:30:42.297537: train loss : -0.8722\n",
      "2021-10-24 20:30:55.781240: validation loss: -0.8458\n",
      "2021-10-24 20:30:55.785505: Average global foreground Dice: [0.8587]\n",
      "2021-10-24 20:30:55.792471: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:30:56.328140: lr: 0.005166\n",
      "2021-10-24 20:30:56.376411: saving checkpoint...\n",
      "2021-10-24 20:30:57.494452: done, saving took 1.14 seconds\n",
      "2021-10-24 20:30:57.936478: This epoch took 195.678261 s\n",
      "\n",
      "2021-10-24 20:30:57.949350: \n",
      "epoch:  26\n",
      "2021-10-24 20:33:58.092050: train loss : -0.8725\n",
      "2021-10-24 20:34:11.600411: validation loss: -0.8463\n",
      "2021-10-24 20:34:11.604885: Average global foreground Dice: [0.8563]\n",
      "2021-10-24 20:34:11.611393: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:34:12.103964: lr: 0.004971\n",
      "2021-10-24 20:34:12.155625: saving checkpoint...\n",
      "2021-10-24 20:34:13.229659: done, saving took 1.09 seconds\n",
      "2021-10-24 20:34:13.725153: This epoch took 195.769376 s\n",
      "\n",
      "2021-10-24 20:34:13.743847: \n",
      "epoch:  27\n",
      "2021-10-24 20:37:13.756466: train loss : -0.8751\n",
      "2021-10-24 20:37:27.280590: validation loss: -0.8443\n",
      "2021-10-24 20:37:27.285224: Average global foreground Dice: [0.8541]\n",
      "2021-10-24 20:37:27.292682: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:37:27.847142: lr: 0.004776\n",
      "2021-10-24 20:37:27.890557: saving checkpoint...\n",
      "2021-10-24 20:37:28.972230: done, saving took 1.10 seconds\n",
      "2021-10-24 20:37:29.414706: This epoch took 195.663735 s\n",
      "\n",
      "2021-10-24 20:37:29.427645: \n",
      "epoch:  28\n",
      "2021-10-24 20:40:29.430617: train loss : -0.8753\n",
      "2021-10-24 20:40:42.962739: validation loss: -0.8472\n",
      "2021-10-24 20:40:42.967549: Average global foreground Dice: [0.8575]\n",
      "2021-10-24 20:40:42.974368: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:40:43.480361: lr: 0.004581\n",
      "2021-10-24 20:40:43.532151: saving checkpoint...\n",
      "2021-10-24 20:40:44.667077: done, saving took 1.16 seconds\n",
      "2021-10-24 20:40:45.094934: This epoch took 195.660518 s\n",
      "\n",
      "2021-10-24 20:40:45.111120: \n",
      "epoch:  29\n",
      "2021-10-24 20:43:45.257913: train loss : -0.8781\n",
      "2021-10-24 20:43:58.758244: validation loss: -0.8403\n",
      "2021-10-24 20:43:58.762536: Average global foreground Dice: [0.8507]\n",
      "2021-10-24 20:43:58.769228: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:43:59.342475: lr: 0.004384\n",
      "2021-10-24 20:43:59.392658: saving checkpoint...\n",
      "2021-10-24 20:44:00.502725: done, saving took 1.13 seconds\n",
      "2021-10-24 20:44:00.941894: This epoch took 195.824826 s\n",
      "\n",
      "2021-10-24 20:44:00.961099: \n",
      "epoch:  30\n",
      "2021-10-24 20:47:01.103423: train loss : -0.8789\n",
      "2021-10-24 20:47:14.609956: validation loss: -0.8456\n",
      "2021-10-24 20:47:14.614327: Average global foreground Dice: [0.8555]\n",
      "2021-10-24 20:47:14.620962: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:47:15.162141: lr: 0.004186\n",
      "2021-10-24 20:47:15.210159: saving checkpoint...\n",
      "2021-10-24 20:47:16.323178: done, saving took 1.13 seconds\n",
      "2021-10-24 20:47:16.817091: This epoch took 195.849412 s\n",
      "\n",
      "2021-10-24 20:47:16.834619: \n",
      "epoch:  31\n",
      "2021-10-24 20:50:16.962036: train loss : -0.8783\n",
      "2021-10-24 20:50:30.482783: validation loss: -0.8401\n",
      "2021-10-24 20:50:30.490282: Average global foreground Dice: [0.8521]\n",
      "2021-10-24 20:50:30.497220: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:50:30.988949: lr: 0.003987\n",
      "2021-10-24 20:50:31.036572: saving checkpoint...\n",
      "2021-10-24 20:50:32.122655: done, saving took 1.10 seconds\n",
      "2021-10-24 20:50:32.578667: This epoch took 195.738247 s\n",
      "\n",
      "2021-10-24 20:50:32.597607: \n",
      "epoch:  32\n",
      "2021-10-24 20:53:32.938265: train loss : -0.8813\n",
      "2021-10-24 20:53:46.457581: validation loss: -0.8402\n",
      "2021-10-24 20:53:46.462327: Average global foreground Dice: [0.851]\n",
      "2021-10-24 20:53:46.468738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:53:47.029584: lr: 0.003787\n",
      "2021-10-24 20:53:47.076813: saving checkpoint...\n",
      "2021-10-24 20:53:48.173058: done, saving took 1.12 seconds\n",
      "2021-10-24 20:53:48.686304: This epoch took 196.081703 s\n",
      "\n",
      "2021-10-24 20:53:48.705587: \n",
      "epoch:  33\n",
      "2021-10-24 20:56:49.157914: train loss : -0.8813\n",
      "2021-10-24 20:57:02.669090: validation loss: -0.8491\n",
      "2021-10-24 20:57:02.673124: Average global foreground Dice: [0.8595]\n",
      "2021-10-24 20:57:02.679794: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:57:03.221306: lr: 0.003586\n",
      "2021-10-24 20:57:03.273523: saving checkpoint...\n",
      "2021-10-24 20:57:04.376037: done, saving took 1.12 seconds\n",
      "2021-10-24 20:57:04.957453: This epoch took 196.245773 s\n",
      "\n",
      "2021-10-24 20:57:04.977200: \n",
      "epoch:  34\n",
      "2021-10-24 21:00:05.362079: train loss : -0.8827\n",
      "2021-10-24 21:00:18.879603: validation loss: -0.8415\n",
      "2021-10-24 21:00:18.884384: Average global foreground Dice: [0.8537]\n",
      "2021-10-24 21:00:18.891463: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:00:19.393363: lr: 0.003384\n",
      "2021-10-24 21:00:19.449546: saving checkpoint...\n",
      "2021-10-24 21:00:20.554314: done, saving took 1.12 seconds\n",
      "2021-10-24 21:00:21.027516: This epoch took 196.044086 s\n",
      "\n",
      "2021-10-24 21:00:21.055364: \n",
      "epoch:  35\n",
      "2021-10-24 21:03:21.432864: train loss : -0.8840\n",
      "2021-10-24 21:03:34.944624: validation loss: -0.8466\n",
      "2021-10-24 21:03:34.948809: Average global foreground Dice: [0.856]\n",
      "2021-10-24 21:03:34.955522: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:03:35.493067: lr: 0.00318\n",
      "2021-10-24 21:03:35.545927: saving checkpoint...\n",
      "2021-10-24 21:03:36.644983: done, saving took 1.12 seconds\n",
      "2021-10-24 21:03:37.162036: This epoch took 196.091770 s\n",
      "\n",
      "2021-10-24 21:03:37.182102: \n",
      "epoch:  36\n",
      "2021-10-24 21:06:37.635693: train loss : -0.8847\n",
      "2021-10-24 21:06:51.170818: validation loss: -0.8447\n",
      "2021-10-24 21:06:51.175451: Average global foreground Dice: [0.8552]\n",
      "2021-10-24 21:06:51.182359: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:06:51.753886: lr: 0.002975\n",
      "2021-10-24 21:06:51.802243: saving checkpoint...\n",
      "2021-10-24 21:06:52.900029: done, saving took 1.12 seconds\n",
      "2021-10-24 21:06:53.360753: This epoch took 196.171076 s\n",
      "\n",
      "2021-10-24 21:06:53.380265: \n",
      "epoch:  37\n",
      "2021-10-24 21:09:53.854273: train loss : -0.8872\n",
      "2021-10-24 21:10:07.358170: validation loss: -0.8442\n",
      "2021-10-24 21:10:07.362674: Average global foreground Dice: [0.8545]\n",
      "2021-10-24 21:10:07.369496: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:10:07.937498: lr: 0.002768\n",
      "2021-10-24 21:10:07.991174: saving checkpoint...\n",
      "2021-10-24 21:10:09.112023: done, saving took 1.14 seconds\n",
      "2021-10-24 21:10:09.555897: This epoch took 196.168413 s\n",
      "\n",
      "2021-10-24 21:10:09.573916: \n",
      "epoch:  38\n",
      "2021-10-24 21:13:10.033255: train loss : -0.8884\n",
      "2021-10-24 21:13:23.545261: validation loss: -0.8459\n",
      "2021-10-24 21:13:23.549670: Average global foreground Dice: [0.857]\n",
      "2021-10-24 21:13:23.555330: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:13:24.057527: lr: 0.00256\n",
      "2021-10-24 21:13:24.108918: saving checkpoint...\n",
      "2021-10-24 21:13:25.222131: done, saving took 1.13 seconds\n",
      "2021-10-24 21:13:25.734516: This epoch took 196.153501 s\n",
      "\n",
      "2021-10-24 21:13:25.751969: \n",
      "epoch:  39\n",
      "2021-10-24 21:16:26.220123: train loss : -0.8869\n",
      "2021-10-24 21:16:39.726118: validation loss: -0.8422\n",
      "2021-10-24 21:16:39.730926: Average global foreground Dice: [0.8534]\n",
      "2021-10-24 21:16:39.739423: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:16:40.318105: lr: 0.002349\n",
      "2021-10-24 21:16:40.365588: saving checkpoint...\n",
      "2021-10-24 21:16:41.436803: done, saving took 1.09 seconds\n",
      "2021-10-24 21:16:42.061702: This epoch took 196.303185 s\n",
      "\n",
      "2021-10-24 21:16:42.080043: \n",
      "epoch:  40\n",
      "2021-10-24 21:19:42.865904: train loss : -0.8892\n",
      "2021-10-24 21:19:56.367764: validation loss: -0.8391\n",
      "2021-10-24 21:19:56.372035: Average global foreground Dice: [0.8493]\n",
      "2021-10-24 21:19:56.378818: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:19:56.874765: lr: 0.002137\n",
      "2021-10-24 21:19:56.903404: This epoch took 194.815837 s\n",
      "\n",
      "2021-10-24 21:19:56.909889: \n",
      "epoch:  41\n",
      "2021-10-24 21:22:57.755781: train loss : -0.8903\n",
      "2021-10-24 21:23:11.268363: validation loss: -0.8434\n",
      "2021-10-24 21:23:11.272996: Average global foreground Dice: [0.8542]\n",
      "2021-10-24 21:23:11.279376: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:23:11.813110: lr: 0.001922\n",
      "2021-10-24 21:23:11.832417: This epoch took 194.916174 s\n",
      "\n",
      "2021-10-24 21:23:11.839489: \n",
      "epoch:  42\n",
      "2021-10-24 21:26:12.665371: train loss : -0.8913\n",
      "2021-10-24 21:26:26.173390: validation loss: -0.8411\n",
      "2021-10-24 21:26:26.177794: Average global foreground Dice: [0.8514]\n",
      "2021-10-24 21:26:26.184153: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:26:26.772123: lr: 0.001704\n",
      "2021-10-24 21:26:26.795922: This epoch took 194.949138 s\n",
      "\n",
      "2021-10-24 21:26:26.802881: \n",
      "epoch:  43\n",
      "2021-10-24 21:29:27.646216: train loss : -0.8917\n",
      "2021-10-24 21:29:41.169516: validation loss: -0.8425\n",
      "2021-10-24 21:29:41.173763: Average global foreground Dice: [0.8543]\n",
      "2021-10-24 21:29:41.179682: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:29:41.725157: lr: 0.001483\n",
      "2021-10-24 21:29:41.763471: saving checkpoint...\n",
      "2021-10-24 21:29:42.886478: done, saving took 1.14 seconds\n",
      "2021-10-24 21:29:43.322553: This epoch took 196.512511 s\n",
      "\n",
      "2021-10-24 21:29:43.330790: \n",
      "epoch:  44\n",
      "2021-10-24 21:32:44.127639: train loss : -0.8934\n",
      "2021-10-24 21:32:57.652104: validation loss: -0.8412\n",
      "2021-10-24 21:32:57.656378: Average global foreground Dice: [0.8505]\n",
      "2021-10-24 21:32:57.662894: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:32:58.151142: lr: 0.001259\n",
      "2021-10-24 21:32:58.170524: This epoch took 194.833139 s\n",
      "\n",
      "2021-10-24 21:32:58.177583: \n",
      "epoch:  45\n",
      "2021-10-24 21:35:58.961307: train loss : -0.8946\n",
      "2021-10-24 21:36:12.466415: validation loss: -0.8412\n",
      "2021-10-24 21:36:12.470798: Average global foreground Dice: [0.8508]\n",
      "2021-10-24 21:36:12.478164: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:36:13.037525: lr: 0.00103\n",
      "2021-10-24 21:36:13.061516: This epoch took 194.877023 s\n",
      "\n",
      "2021-10-24 21:36:13.068466: \n",
      "epoch:  46\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-24 21:39:13.623476: train loss : -0.8957\n",
      "2021-10-24 21:39:27.139353: validation loss: -0.8376\n",
      "2021-10-24 21:39:27.143535: Average global foreground Dice: [0.8486]\n",
      "2021-10-24 21:39:27.149673: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:39:27.652062: lr: 0.000795\n",
      "2021-10-24 21:39:27.674906: This epoch took 194.599746 s\n",
      "\n",
      "2021-10-24 21:39:27.681940: \n",
      "epoch:  47\n",
      "2021-10-24 21:42:28.188291: train loss : -0.8952\n",
      "2021-10-24 21:42:41.697711: validation loss: -0.8398\n",
      "2021-10-24 21:42:41.702407: Average global foreground Dice: [0.8507]\n",
      "2021-10-24 21:42:41.708687: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:42:42.242358: lr: 0.000552\n",
      "2021-10-24 21:42:42.264740: This epoch took 194.575569 s\n",
      "\n",
      "2021-10-24 21:42:42.271478: \n",
      "epoch:  48\n",
      "2021-10-24 21:45:42.926270: train loss : -0.8974\n",
      "2021-10-24 21:45:56.441639: validation loss: -0.8438\n",
      "2021-10-24 21:45:56.446295: Average global foreground Dice: [0.8544]\n",
      "2021-10-24 21:45:56.453100: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:45:56.993740: lr: 0.000296\n",
      "2021-10-24 21:45:57.012025: This epoch took 194.708218 s\n",
      "\n",
      "2021-10-24 21:45:57.018618: \n",
      "epoch:  49\n",
      "2021-10-24 21:48:57.635880: train loss : -0.8969\n",
      "2021-10-24 21:49:11.143610: validation loss: -0.8454\n",
      "2021-10-24 21:49:11.148071: Average global foreground Dice: [0.8551]\n",
      "2021-10-24 21:49:11.156070: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:49:11.705513: lr: 0.0\n",
      "2021-10-24 21:49:11.720886: saving scheduled checkpoint file...\n",
      "2021-10-24 21:49:11.750935: saving checkpoint...\n",
      "2021-10-24 21:49:12.715417: done, saving took 0.98 seconds\n",
      "2021-10-24 21:49:13.203496: done\n",
      "2021-10-24 21:49:13.212761: This epoch took 196.186833 s\n",
      "\n",
      "2021-10-24 21:49:13.238732: saving checkpoint...\n",
      "2021-10-24 21:49:14.198663: done, saving took 0.98 seconds\n",
      "23090559_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-24 21:51:15.602918: finished prediction\n",
      "2021-10-24 21:51:15.608304: evaluation of raw predictions\n",
      "2021-10-24 21:51:17.710832: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.845940120988292\n",
      "after:  0.8458202553518164\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-10-24 21:51:30.419887: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-10-24 21:51:30.447813: The split file contains 2 splits.\n",
      "2021-10-24 21:51:30.453307: Desired fold for training: 4\n",
      "2021-10-24 21:51:30.459938: INFO: You requested fold 4 for training but splits contain only 2 folds. I am now creating a random (but seeded) 80:20 split!\n",
      "2021-10-24 21:51:30.467949: This random 80:20 split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-24 21:51:34.637051: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-24 21:51:45.825256: Unable to plot network architecture:\n",
      "2021-10-24 21:51:45.936460: No module named 'hiddenlayer'\n",
      "2021-10-24 21:51:46.130623: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-24 21:51:46.184592: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-24 21:51:46.282207: \n",
      "\n",
      "2021-10-24 21:51:46.365255: \n",
      "epoch:  0\n",
      "2021-10-24 21:55:02.196150: train loss : -0.2671\n",
      "2021-10-24 21:55:15.681125: validation loss: -0.6490\n",
      "2021-10-24 21:55:15.689395: Average global foreground Dice: [0.7249]\n",
      "2021-10-24 21:55:15.691819: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:55:16.173418: lr: 0.00982\n",
      "2021-10-24 21:55:16.192772: This epoch took 209.716221 s\n",
      "\n",
      "2021-10-24 21:55:16.198856: \n",
      "epoch:  1\n",
      "2021-10-24 21:58:15.115894: train loss : -0.6793\n",
      "2021-10-24 21:58:28.562808: validation loss: -0.7337\n",
      "2021-10-24 21:58:28.568099: Average global foreground Dice: [0.7982]\n",
      "2021-10-24 21:58:28.575493: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:58:29.085123: lr: 0.009639\n",
      "2021-10-24 21:58:29.140976: saving checkpoint...\n",
      "2021-10-24 21:58:30.158081: done, saving took 1.05 seconds\n",
      "2021-10-24 21:58:30.606269: This epoch took 194.401820 s\n",
      "\n",
      "2021-10-24 21:58:30.614437: \n",
      "epoch:  2\n",
      "2021-10-24 22:01:29.092119: train loss : -0.7706\n",
      "2021-10-24 22:01:42.540669: validation loss: -0.8009\n",
      "2021-10-24 22:01:42.545529: Average global foreground Dice: [0.8224]\n",
      "2021-10-24 22:01:42.551485: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:01:43.056829: lr: 0.009458\n",
      "2021-10-24 22:01:43.108621: saving checkpoint...\n",
      "2021-10-24 22:01:44.246897: done, saving took 1.18 seconds\n",
      "2021-10-24 22:01:44.748765: This epoch took 194.128371 s\n",
      "\n",
      "2021-10-24 22:01:44.757569: \n",
      "epoch:  3\n",
      "2021-10-24 22:04:42.973184: train loss : -0.8004\n",
      "2021-10-24 22:04:56.421646: validation loss: -0.8067\n",
      "2021-10-24 22:04:56.426030: Average global foreground Dice: [0.8283]\n",
      "2021-10-24 22:04:56.432904: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:04:56.962026: lr: 0.009277\n",
      "2021-10-24 22:04:57.014067: saving checkpoint...\n",
      "2021-10-24 22:04:58.101743: done, saving took 1.12 seconds\n",
      "2021-10-24 22:04:58.624892: This epoch took 193.861017 s\n",
      "\n",
      "2021-10-24 22:04:58.633550: \n",
      "epoch:  4\n",
      "2021-10-24 22:07:56.796019: train loss : -0.8164\n",
      "2021-10-24 22:08:10.243724: validation loss: -0.8121\n",
      "2021-10-24 22:08:10.248640: Average global foreground Dice: [0.8301]\n",
      "2021-10-24 22:08:10.255281: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:08:10.803059: lr: 0.009095\n",
      "2021-10-24 22:08:10.863198: saving checkpoint...\n",
      "2021-10-24 22:08:11.976206: done, saving took 1.15 seconds\n",
      "2021-10-24 22:08:12.440868: This epoch took 193.800567 s\n",
      "\n",
      "2021-10-24 22:08:12.450736: \n",
      "epoch:  5\n",
      "2021-10-24 22:11:10.599980: train loss : -0.8239\n",
      "2021-10-24 22:11:24.073961: validation loss: -0.8280\n",
      "2021-10-24 22:11:24.080763: Average global foreground Dice: [0.8434]\n",
      "2021-10-24 22:11:24.088047: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:11:24.616607: lr: 0.008913\n",
      "2021-10-24 22:11:24.654405: saving checkpoint...\n",
      "2021-10-24 22:11:25.767296: done, saving took 1.13 seconds\n",
      "2021-10-24 22:11:26.244543: This epoch took 193.786933 s\n",
      "\n",
      "2021-10-24 22:11:26.252941: \n",
      "epoch:  6\n",
      "2021-10-24 22:14:24.557034: train loss : -0.8296\n",
      "2021-10-24 22:14:38.006505: validation loss: -0.8300\n",
      "2021-10-24 22:14:38.011215: Average global foreground Dice: [0.8482]\n",
      "2021-10-24 22:14:38.020338: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:14:38.512670: lr: 0.008731\n",
      "2021-10-24 22:14:38.559405: saving checkpoint...\n",
      "2021-10-24 22:14:39.675581: done, saving took 1.14 seconds\n",
      "2021-10-24 22:14:40.109632: This epoch took 193.851017 s\n",
      "\n",
      "2021-10-24 22:14:40.123190: \n",
      "epoch:  7\n",
      "2021-10-24 22:17:38.404788: train loss : -0.8349\n",
      "2021-10-24 22:17:51.851311: validation loss: -0.8316\n",
      "2021-10-24 22:17:51.855648: Average global foreground Dice: [0.8463]\n",
      "2021-10-24 22:17:51.864465: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:17:52.431226: lr: 0.008548\n",
      "2021-10-24 22:17:52.481606: saving checkpoint...\n",
      "2021-10-24 22:17:53.568366: done, saving took 1.11 seconds\n",
      "2021-10-24 22:17:54.032346: This epoch took 193.903009 s\n",
      "\n",
      "2021-10-24 22:17:54.046900: \n",
      "epoch:  8\n",
      "2021-10-24 22:20:52.674662: train loss : -0.8373\n",
      "2021-10-24 22:21:06.143711: validation loss: -0.8318\n",
      "2021-10-24 22:21:06.148894: Average global foreground Dice: [0.8444]\n",
      "2021-10-24 22:21:06.156223: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:21:06.680258: lr: 0.008364\n",
      "2021-10-24 22:21:06.724456: saving checkpoint...\n",
      "2021-10-24 22:21:07.825227: done, saving took 1.12 seconds\n",
      "2021-10-24 22:21:08.288249: This epoch took 194.234673 s\n",
      "\n",
      "2021-10-24 22:21:08.304551: \n",
      "epoch:  9\n",
      "2021-10-24 22:24:07.001653: train loss : -0.8415\n",
      "2021-10-24 22:24:20.453288: validation loss: -0.8335\n",
      "2021-10-24 22:24:20.458028: Average global foreground Dice: [0.8477]\n",
      "2021-10-24 22:24:20.465118: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:24:21.000405: lr: 0.008181\n",
      "2021-10-24 22:24:21.045321: saving checkpoint...\n",
      "2021-10-24 22:24:22.116463: done, saving took 1.09 seconds\n",
      "2021-10-24 22:24:22.629553: This epoch took 194.317802 s\n",
      "\n",
      "2021-10-24 22:24:22.643672: \n",
      "epoch:  10\n",
      "2021-10-24 22:27:21.434546: train loss : -0.8448\n",
      "2021-10-24 22:27:34.913526: validation loss: -0.8328\n",
      "2021-10-24 22:27:34.918506: Average global foreground Dice: [0.8473]\n",
      "2021-10-24 22:27:34.930262: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:27:35.499487: lr: 0.007996\n",
      "2021-10-24 22:27:35.541872: saving checkpoint...\n",
      "2021-10-24 22:27:36.655800: done, saving took 1.13 seconds\n",
      "2021-10-24 22:27:37.214910: This epoch took 194.564375 s\n",
      "\n",
      "2021-10-24 22:27:37.230280: \n",
      "epoch:  11\n",
      "2021-10-24 22:30:35.860377: train loss : -0.8480\n",
      "2021-10-24 22:30:49.327211: validation loss: -0.8383\n",
      "2021-10-24 22:30:49.331835: Average global foreground Dice: [0.8531]\n",
      "2021-10-24 22:30:49.338742: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:30:49.824818: lr: 0.007811\n",
      "2021-10-24 22:30:49.869525: saving checkpoint...\n",
      "2021-10-24 22:30:50.954245: done, saving took 1.10 seconds\n",
      "2021-10-24 22:30:51.412033: This epoch took 194.173791 s\n",
      "\n",
      "2021-10-24 22:30:51.426468: \n",
      "epoch:  12\n",
      "2021-10-24 22:33:49.967989: train loss : -0.8521\n",
      "2021-10-24 22:34:03.435780: validation loss: -0.8378\n",
      "2021-10-24 22:34:03.440109: Average global foreground Dice: [0.8526]\n",
      "2021-10-24 22:34:03.447101: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:34:03.974695: lr: 0.007626\n",
      "2021-10-24 22:34:04.019155: saving checkpoint...\n",
      "2021-10-24 22:34:05.192853: done, saving took 1.19 seconds\n",
      "2021-10-24 22:34:05.746625: This epoch took 194.313067 s\n",
      "\n",
      "2021-10-24 22:34:05.762133: \n",
      "epoch:  13\n",
      "2021-10-24 22:37:04.483712: train loss : -0.8535\n",
      "2021-10-24 22:37:17.925117: validation loss: -0.8349\n",
      "2021-10-24 22:37:17.929556: Average global foreground Dice: [0.8494]\n",
      "2021-10-24 22:37:17.937068: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:37:18.437821: lr: 0.00744\n",
      "2021-10-24 22:37:18.478862: saving checkpoint...\n",
      "2021-10-24 22:37:19.566130: done, saving took 1.11 seconds\n",
      "2021-10-24 22:37:20.047319: This epoch took 194.277445 s\n",
      "\n",
      "2021-10-24 22:37:20.061718: \n",
      "epoch:  14\n",
      "2021-10-24 22:40:18.898462: train loss : -0.8561\n",
      "2021-10-24 22:40:32.357677: validation loss: -0.8395\n",
      "2021-10-24 22:40:32.362124: Average global foreground Dice: [0.8533]\n",
      "2021-10-24 22:40:32.369827: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:40:32.860515: lr: 0.007254\n",
      "2021-10-24 22:40:32.906566: saving checkpoint...\n",
      "2021-10-24 22:40:33.987832: done, saving took 1.10 seconds\n",
      "2021-10-24 22:40:34.424916: This epoch took 194.356458 s\n",
      "\n",
      "2021-10-24 22:40:34.438391: \n",
      "epoch:  15\n",
      "2021-10-24 22:43:33.218078: train loss : -0.8574\n",
      "2021-10-24 22:43:46.680515: validation loss: -0.8394\n",
      "2021-10-24 22:43:46.685225: Average global foreground Dice: [0.8539]\n",
      "2021-10-24 22:43:46.692225: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:43:47.189428: lr: 0.007067\n",
      "2021-10-24 22:43:47.236903: saving checkpoint...\n",
      "2021-10-24 22:43:48.351099: done, saving took 1.13 seconds\n",
      "2021-10-24 22:43:48.845577: This epoch took 194.400370 s\n",
      "\n",
      "2021-10-24 22:43:48.858832: \n",
      "epoch:  16\n",
      "2021-10-24 22:46:48.190327: train loss : -0.8581\n",
      "2021-10-24 22:47:01.660403: validation loss: -0.8399\n",
      "2021-10-24 22:47:01.664681: Average global foreground Dice: [0.8541]\n",
      "2021-10-24 22:47:01.673325: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:47:02.212524: lr: 0.00688\n",
      "2021-10-24 22:47:02.261553: saving checkpoint...\n",
      "2021-10-24 22:47:03.398769: done, saving took 1.16 seconds\n",
      "2021-10-24 22:47:03.920179: This epoch took 195.054559 s\n",
      "\n",
      "2021-10-24 22:47:03.936529: \n",
      "epoch:  17\n",
      "2021-10-24 22:50:03.382044: train loss : -0.8606\n",
      "2021-10-24 22:50:16.844536: validation loss: -0.8449\n",
      "2021-10-24 22:50:16.848706: Average global foreground Dice: [0.8586]\n",
      "2021-10-24 22:50:16.855397: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:50:17.395066: lr: 0.006692\n",
      "2021-10-24 22:50:17.442607: saving checkpoint...\n",
      "2021-10-24 22:50:18.543522: done, saving took 1.12 seconds\n",
      "2021-10-24 22:50:19.036638: This epoch took 195.092884 s\n",
      "\n",
      "2021-10-24 22:50:19.056811: \n",
      "epoch:  18\n",
      "2021-10-24 22:53:18.463355: train loss : -0.8633\n",
      "2021-10-24 22:53:31.929659: validation loss: -0.8412\n",
      "2021-10-24 22:53:31.934248: Average global foreground Dice: [0.8527]\n",
      "2021-10-24 22:53:31.941103: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:53:32.515566: lr: 0.006504\n",
      "2021-10-24 22:53:32.562876: saving checkpoint...\n",
      "2021-10-24 22:53:33.645752: done, saving took 1.10 seconds\n",
      "2021-10-24 22:53:34.123498: This epoch took 195.060216 s\n",
      "\n",
      "2021-10-24 22:53:34.142477: \n",
      "epoch:  19\n",
      "2021-10-24 22:56:33.569693: train loss : -0.8651\n",
      "2021-10-24 22:56:47.054075: validation loss: -0.8423\n",
      "2021-10-24 22:56:47.058414: Average global foreground Dice: [0.8544]\n",
      "2021-10-24 22:56:47.065161: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:56:47.605366: lr: 0.006314\n",
      "2021-10-24 22:56:47.656471: saving checkpoint...\n",
      "2021-10-24 22:56:48.787770: done, saving took 1.15 seconds\n",
      "2021-10-24 22:56:49.204414: This epoch took 195.052046 s\n",
      "\n",
      "2021-10-24 22:56:49.228524: \n",
      "epoch:  20\n",
      "2021-10-24 22:59:48.488714: train loss : -0.8666\n",
      "2021-10-24 23:00:01.956659: validation loss: -0.8435\n",
      "2021-10-24 23:00:01.960999: Average global foreground Dice: [0.856]\n",
      "2021-10-24 23:00:01.969179: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:00:02.531418: lr: 0.006125\n",
      "2021-10-24 23:00:02.582331: saving checkpoint...\n",
      "2021-10-24 23:00:03.711007: done, saving took 1.15 seconds\n",
      "2021-10-24 23:00:04.521357: This epoch took 195.286032 s\n",
      "\n",
      "2021-10-24 23:00:04.535524: \n",
      "epoch:  21\n",
      "2021-10-24 23:03:03.952863: train loss : -0.8678\n",
      "2021-10-24 23:03:17.436359: validation loss: -0.8418\n",
      "2021-10-24 23:03:17.440919: Average global foreground Dice: [0.8547]\n",
      "2021-10-24 23:03:17.447510: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:03:17.939337: lr: 0.005934\n",
      "2021-10-24 23:03:17.987980: saving checkpoint...\n",
      "2021-10-24 23:03:19.104769: done, saving took 1.14 seconds\n",
      "2021-10-24 23:03:19.587239: This epoch took 195.044610 s\n",
      "\n",
      "2021-10-24 23:03:19.606684: \n",
      "epoch:  22\n",
      "2021-10-24 23:06:19.075511: train loss : -0.8687\n",
      "2021-10-24 23:06:32.553458: validation loss: -0.8427\n",
      "2021-10-24 23:06:32.557963: Average global foreground Dice: [0.8544]\n",
      "2021-10-24 23:06:32.564921: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:06:33.057862: lr: 0.005743\n",
      "2021-10-24 23:06:33.108797: saving checkpoint...\n",
      "2021-10-24 23:06:34.212104: done, saving took 1.12 seconds\n",
      "2021-10-24 23:06:34.666928: This epoch took 195.053309 s\n",
      "\n",
      "2021-10-24 23:06:34.685662: \n",
      "epoch:  23\n",
      "2021-10-24 23:09:34.108971: train loss : -0.8698\n",
      "2021-10-24 23:09:47.575773: validation loss: -0.8435\n",
      "2021-10-24 23:09:47.581277: Average global foreground Dice: [0.8534]\n",
      "2021-10-24 23:09:47.586914: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:09:48.138260: lr: 0.005551\n",
      "2021-10-24 23:09:48.189065: saving checkpoint...\n",
      "2021-10-24 23:09:49.285644: done, saving took 1.12 seconds\n",
      "2021-10-24 23:09:49.815325: This epoch took 195.122973 s\n",
      "\n",
      "2021-10-24 23:09:49.835582: \n",
      "epoch:  24\n",
      "2021-10-24 23:12:49.576941: train loss : -0.8721\n",
      "2021-10-24 23:13:03.036395: validation loss: -0.8434\n",
      "2021-10-24 23:13:03.040180: Average global foreground Dice: [0.8549]\n",
      "2021-10-24 23:13:03.047044: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:13:03.549637: lr: 0.005359\n",
      "2021-10-24 23:13:03.589393: saving checkpoint...\n",
      "2021-10-24 23:13:04.693112: done, saving took 1.12 seconds\n",
      "2021-10-24 23:13:05.138122: This epoch took 195.295879 s\n",
      "\n",
      "2021-10-24 23:13:05.150789: \n",
      "epoch:  25\n",
      "2021-10-24 23:16:04.861068: train loss : -0.8741\n",
      "2021-10-24 23:16:18.332420: validation loss: -0.8434\n",
      "2021-10-24 23:16:18.336749: Average global foreground Dice: [0.854]\n",
      "2021-10-24 23:16:18.343350: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:16:18.881341: lr: 0.005166\n",
      "2021-10-24 23:16:18.930132: saving checkpoint...\n",
      "2021-10-24 23:16:20.043763: done, saving took 1.13 seconds\n",
      "2021-10-24 23:16:20.470268: This epoch took 195.312125 s\n",
      "\n",
      "2021-10-24 23:16:20.491317: \n",
      "epoch:  26\n",
      "2021-10-24 23:19:20.124768: train loss : -0.8742\n",
      "2021-10-24 23:19:33.575426: validation loss: -0.8450\n",
      "2021-10-24 23:19:33.579844: Average global foreground Dice: [0.8561]\n",
      "2021-10-24 23:19:33.586967: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:19:34.075721: lr: 0.004971\n",
      "2021-10-24 23:19:34.124824: saving checkpoint...\n",
      "2021-10-24 23:19:35.269660: done, saving took 1.16 seconds\n",
      "2021-10-24 23:19:35.754997: This epoch took 195.256852 s\n",
      "\n",
      "2021-10-24 23:19:35.772998: \n",
      "epoch:  27\n",
      "2021-10-24 23:22:35.542785: train loss : -0.8773\n",
      "2021-10-24 23:22:48.994541: validation loss: -0.8452\n",
      "2021-10-24 23:22:48.999161: Average global foreground Dice: [0.8565]\n",
      "2021-10-24 23:22:49.005623: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:22:49.573690: lr: 0.004776\n",
      "2021-10-24 23:22:49.612652: saving checkpoint...\n",
      "2021-10-24 23:22:50.703521: done, saving took 1.11 seconds\n",
      "2021-10-24 23:22:51.195014: This epoch took 195.415083 s\n",
      "\n",
      "2021-10-24 23:22:51.203552: \n",
      "epoch:  28\n",
      "2021-10-24 23:25:51.081951: train loss : -0.8772\n",
      "2021-10-24 23:26:04.543948: validation loss: -0.8436\n",
      "2021-10-24 23:26:04.548469: Average global foreground Dice: [0.8533]\n",
      "2021-10-24 23:26:04.554763: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:26:05.101505: lr: 0.004581\n",
      "2021-10-24 23:26:05.144191: saving checkpoint...\n",
      "2021-10-24 23:26:06.295110: done, saving took 1.17 seconds\n",
      "2021-10-24 23:26:06.858492: This epoch took 195.648282 s\n",
      "\n",
      "2021-10-24 23:26:06.868235: \n",
      "epoch:  29\n",
      "2021-10-24 23:29:06.589618: train loss : -0.8772\n",
      "2021-10-24 23:29:20.055730: validation loss: -0.8403\n",
      "2021-10-24 23:29:20.061430: Average global foreground Dice: [0.8531]\n",
      "2021-10-24 23:29:20.068162: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:29:20.570872: lr: 0.004384\n",
      "2021-10-24 23:29:20.606152: saving checkpoint...\n",
      "2021-10-24 23:29:21.726361: done, saving took 1.14 seconds\n",
      "2021-10-24 23:29:22.241479: This epoch took 195.366368 s\n",
      "\n",
      "2021-10-24 23:29:22.249694: \n",
      "epoch:  30\n",
      "2021-10-24 23:32:22.174414: train loss : -0.8793\n",
      "2021-10-24 23:32:35.661609: validation loss: -0.8420\n",
      "2021-10-24 23:32:35.665709: Average global foreground Dice: [0.8541]\n",
      "2021-10-24 23:32:35.672548: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:32:36.206122: lr: 0.004186\n",
      "2021-10-24 23:32:36.247699: saving checkpoint...\n",
      "2021-10-24 23:32:37.368197: done, saving took 1.14 seconds\n",
      "2021-10-24 23:32:37.831140: This epoch took 195.574981 s\n",
      "\n",
      "2021-10-24 23:32:37.839144: \n",
      "epoch:  31\n",
      "2021-10-24 23:35:37.588873: train loss : -0.8810\n",
      "2021-10-24 23:35:51.055271: validation loss: -0.8413\n",
      "2021-10-24 23:35:51.059961: Average global foreground Dice: [0.8531]\n",
      "2021-10-24 23:35:51.066322: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:35:51.579397: lr: 0.003987\n",
      "2021-10-24 23:35:51.617986: saving checkpoint...\n",
      "2021-10-24 23:35:52.743800: done, saving took 1.14 seconds\n",
      "2021-10-24 23:35:53.174271: This epoch took 195.328647 s\n",
      "\n",
      "2021-10-24 23:35:53.186482: \n",
      "epoch:  32\n",
      "2021-10-24 23:38:53.137879: train loss : -0.8805\n",
      "2021-10-24 23:39:06.593904: validation loss: -0.8400\n",
      "2021-10-24 23:39:06.599736: Average global foreground Dice: [0.8524]\n",
      "2021-10-24 23:39:06.606137: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:39:07.101360: lr: 0.003787\n",
      "2021-10-24 23:39:07.141276: saving checkpoint...\n",
      "2021-10-24 23:39:08.255003: done, saving took 1.13 seconds\n",
      "2021-10-24 23:39:08.767619: This epoch took 195.574060 s\n",
      "\n",
      "2021-10-24 23:39:08.775942: \n",
      "epoch:  33\n",
      "2021-10-24 23:42:08.738632: train loss : -0.8828\n",
      "2021-10-24 23:42:22.209795: validation loss: -0.8421\n",
      "2021-10-24 23:42:22.214818: Average global foreground Dice: [0.8531]\n",
      "2021-10-24 23:42:22.222176: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:42:22.767568: lr: 0.003586\n",
      "2021-10-24 23:42:22.807226: saving checkpoint...\n",
      "2021-10-24 23:42:23.896072: done, saving took 1.11 seconds\n",
      "2021-10-24 23:42:24.369624: This epoch took 195.586533 s\n",
      "\n",
      "2021-10-24 23:42:24.377780: \n",
      "epoch:  34\n",
      "2021-10-24 23:45:24.384783: train loss : -0.8845\n",
      "2021-10-24 23:45:37.820406: validation loss: -0.8440\n",
      "2021-10-24 23:45:37.825105: Average global foreground Dice: [0.8552]\n",
      "2021-10-24 23:45:37.831628: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:45:38.426276: lr: 0.003384\n",
      "2021-10-24 23:45:38.464577: saving checkpoint...\n",
      "2021-10-24 23:45:39.604822: done, saving took 1.16 seconds\n",
      "2021-10-24 23:45:40.046019: This epoch took 195.661438 s\n",
      "\n",
      "2021-10-24 23:45:40.054121: \n",
      "epoch:  35\n",
      "2021-10-24 23:48:40.091965: train loss : -0.8847\n",
      "2021-10-24 23:48:53.548801: validation loss: -0.8480\n",
      "2021-10-24 23:48:53.552954: Average global foreground Dice: [0.8592]\n",
      "2021-10-24 23:48:53.559439: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:48:54.114409: lr: 0.00318\n",
      "2021-10-24 23:48:54.152989: saving checkpoint...\n",
      "2021-10-24 23:48:55.265372: done, saving took 1.13 seconds\n",
      "2021-10-24 23:48:55.737017: This epoch took 195.676802 s\n",
      "\n",
      "2021-10-24 23:48:55.745822: \n",
      "epoch:  36\n",
      "2021-10-24 23:51:55.681602: train loss : -0.8859\n",
      "2021-10-24 23:52:09.147662: validation loss: -0.8414\n",
      "2021-10-24 23:52:09.151843: Average global foreground Dice: [0.8538]\n",
      "2021-10-24 23:52:09.158115: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:52:09.657582: lr: 0.002975\n",
      "2021-10-24 23:52:09.701147: saving checkpoint...\n",
      "2021-10-24 23:52:10.819004: done, saving took 1.14 seconds\n",
      "2021-10-24 23:52:11.459786: This epoch took 195.706870 s\n",
      "\n",
      "2021-10-24 23:52:11.468647: \n",
      "epoch:  37\n",
      "2021-10-24 23:55:11.432466: train loss : -0.8870\n",
      "2021-10-24 23:55:24.871190: validation loss: -0.8444\n",
      "2021-10-24 23:55:24.875666: Average global foreground Dice: [0.8558]\n",
      "2021-10-24 23:55:24.882903: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:55:25.380063: lr: 0.002768\n",
      "2021-10-24 23:55:25.419537: saving checkpoint...\n",
      "2021-10-24 23:55:26.509398: done, saving took 1.11 seconds\n",
      "2021-10-24 23:55:26.965193: This epoch took 195.489547 s\n",
      "\n",
      "2021-10-24 23:55:26.973555: \n",
      "epoch:  38\n",
      "2021-10-24 23:58:26.953574: train loss : -0.8879\n",
      "2021-10-24 23:58:40.440801: validation loss: -0.8439\n",
      "2021-10-24 23:58:40.445659: Average global foreground Dice: [0.8556]\n",
      "2021-10-24 23:58:40.452028: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:58:40.991878: lr: 0.00256\n",
      "2021-10-24 23:58:41.030901: saving checkpoint...\n",
      "2021-10-24 23:58:42.120248: done, saving took 1.11 seconds\n",
      "2021-10-24 23:58:42.558003: This epoch took 195.577667 s\n",
      "\n",
      "2021-10-24 23:58:42.567479: \n",
      "epoch:  39\n",
      "2021-10-25 00:01:42.618201: train loss : -0.8884\n",
      "2021-10-25 00:01:56.096727: validation loss: -0.8430\n",
      "2021-10-25 00:01:56.101619: Average global foreground Dice: [0.8544]\n",
      "2021-10-25 00:01:56.109376: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:01:56.672310: lr: 0.002349\n",
      "2021-10-25 00:01:56.712495: saving checkpoint...\n",
      "2021-10-25 00:01:57.820297: done, saving took 1.13 seconds\n",
      "2021-10-25 00:01:58.265532: This epoch took 195.690955 s\n",
      "\n",
      "2021-10-25 00:01:58.273932: \n",
      "epoch:  40\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-25 00:04:58.440549: train loss : -0.8910\n",
      "2021-10-25 00:05:11.915466: validation loss: -0.8438\n",
      "2021-10-25 00:05:11.921558: Average global foreground Dice: [0.8557]\n",
      "2021-10-25 00:05:11.931128: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:05:12.489412: lr: 0.002137\n",
      "2021-10-25 00:05:12.532986: saving checkpoint...\n",
      "2021-10-25 00:05:13.659077: done, saving took 1.14 seconds\n",
      "2021-10-25 00:05:14.136315: This epoch took 195.854314 s\n",
      "\n",
      "2021-10-25 00:05:14.145371: \n",
      "epoch:  41\n",
      "2021-10-25 00:08:14.218396: train loss : -0.8906\n",
      "2021-10-25 00:08:27.679959: validation loss: -0.8470\n",
      "2021-10-25 00:08:27.684738: Average global foreground Dice: [0.8588]\n",
      "2021-10-25 00:08:27.693003: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:08:28.180746: lr: 0.001922\n",
      "2021-10-25 00:08:28.220582: saving checkpoint...\n",
      "2021-10-25 00:08:29.364574: done, saving took 1.16 seconds\n",
      "2021-10-25 00:08:29.826011: This epoch took 195.669696 s\n",
      "\n",
      "2021-10-25 00:08:29.835675: \n",
      "epoch:  42\n",
      "2021-10-25 00:11:29.959551: train loss : -0.8919\n",
      "2021-10-25 00:11:43.434301: validation loss: -0.8443\n",
      "2021-10-25 00:11:43.438723: Average global foreground Dice: [0.8569]\n",
      "2021-10-25 00:11:43.446705: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:11:43.983253: lr: 0.001704\n",
      "2021-10-25 00:11:44.034036: saving checkpoint...\n",
      "2021-10-25 00:11:45.147081: done, saving took 1.14 seconds\n",
      "2021-10-25 00:11:45.728830: This epoch took 195.885005 s\n",
      "\n",
      "2021-10-25 00:11:45.737992: \n",
      "epoch:  43\n",
      "2021-10-25 00:14:45.824793: train loss : -0.8923\n",
      "2021-10-25 00:14:59.299669: validation loss: -0.8428\n",
      "2021-10-25 00:14:59.304401: Average global foreground Dice: [0.8537]\n",
      "2021-10-25 00:14:59.317704: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:14:59.849114: lr: 0.001483\n",
      "2021-10-25 00:14:59.899544: saving checkpoint...\n",
      "2021-10-25 00:15:01.023319: done, saving took 1.15 seconds\n",
      "2021-10-25 00:15:01.486564: This epoch took 195.739010 s\n",
      "\n",
      "2021-10-25 00:15:01.497859: \n",
      "epoch:  44\n",
      "2021-10-25 00:18:01.550891: train loss : -0.8944\n",
      "2021-10-25 00:18:15.032896: validation loss: -0.8426\n",
      "2021-10-25 00:18:15.037412: Average global foreground Dice: [0.8547]\n",
      "2021-10-25 00:18:15.057990: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:18:15.616737: lr: 0.001259\n",
      "2021-10-25 00:18:15.656089: saving checkpoint...\n",
      "2021-10-25 00:18:16.743292: done, saving took 1.11 seconds\n",
      "2021-10-25 00:18:17.278919: This epoch took 195.771959 s\n",
      "\n",
      "2021-10-25 00:18:17.287414: \n",
      "epoch:  45\n",
      "2021-10-25 00:21:17.347584: train loss : -0.8944\n",
      "2021-10-25 00:21:30.817395: validation loss: -0.8437\n",
      "2021-10-25 00:21:30.822236: Average global foreground Dice: [0.8548]\n",
      "2021-10-25 00:21:30.829099: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:21:31.320963: lr: 0.00103\n",
      "2021-10-25 00:21:31.359647: saving checkpoint...\n",
      "2021-10-25 00:21:32.455167: done, saving took 1.11 seconds\n",
      "2021-10-25 00:21:32.942211: This epoch took 195.648254 s\n",
      "\n",
      "2021-10-25 00:21:32.952642: \n",
      "epoch:  46\n",
      "2021-10-25 00:24:33.141174: train loss : -0.8960\n",
      "2021-10-25 00:24:46.594903: validation loss: -0.8431\n",
      "2021-10-25 00:24:46.599231: Average global foreground Dice: [0.8563]\n",
      "2021-10-25 00:24:46.607379: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:24:47.144616: lr: 0.000795\n",
      "2021-10-25 00:24:47.183496: saving checkpoint...\n",
      "2021-10-25 00:24:48.293984: done, saving took 1.13 seconds\n",
      "2021-10-25 00:24:48.845616: This epoch took 195.886398 s\n",
      "\n",
      "2021-10-25 00:24:48.853985: \n",
      "epoch:  47\n",
      "2021-10-25 00:27:48.870083: train loss : -0.8976\n",
      "2021-10-25 00:28:02.346172: validation loss: -0.8453\n",
      "2021-10-25 00:28:02.350840: Average global foreground Dice: [0.857]\n",
      "2021-10-25 00:28:02.358055: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:28:02.860328: lr: 0.000552\n",
      "2021-10-25 00:28:02.896674: saving checkpoint...\n",
      "2021-10-25 00:28:03.996668: done, saving took 1.12 seconds\n",
      "2021-10-25 00:28:04.536537: This epoch took 195.675730 s\n",
      "\n",
      "2021-10-25 00:28:04.545433: \n",
      "epoch:  48\n",
      "2021-10-25 00:31:04.446261: train loss : -0.8970\n",
      "2021-10-25 00:31:17.906904: validation loss: -0.8438\n",
      "2021-10-25 00:31:17.911828: Average global foreground Dice: [0.8552]\n",
      "2021-10-25 00:31:17.921145: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:31:18.489462: lr: 0.000296\n",
      "2021-10-25 00:31:18.547734: saving checkpoint...\n",
      "2021-10-25 00:31:19.663722: done, saving took 1.14 seconds\n",
      "2021-10-25 00:31:20.249044: This epoch took 195.696680 s\n",
      "\n",
      "2021-10-25 00:31:20.268377: \n",
      "epoch:  49\n",
      "2021-10-25 00:34:20.082641: train loss : -0.8983\n",
      "2021-10-25 00:34:33.534087: validation loss: -0.8421\n",
      "2021-10-25 00:34:33.538690: Average global foreground Dice: [0.8536]\n",
      "2021-10-25 00:34:33.545929: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:34:34.146600: lr: 0.0\n",
      "2021-10-25 00:34:34.172658: saving scheduled checkpoint file...\n",
      "2021-10-25 00:34:34.197928: saving checkpoint...\n",
      "2021-10-25 00:34:35.172415: done, saving took 0.99 seconds\n",
      "2021-10-25 00:34:35.725542: done\n",
      "2021-10-25 00:34:35.739541: This epoch took 195.463941 s\n",
      "\n",
      "2021-10-25 00:34:35.765414: saving checkpoint...\n",
      "2021-10-25 00:34:36.733920: done, saving took 0.99 seconds\n",
      "23090562_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090567_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-25 00:36:34.012980: finished prediction\n",
      "2021-10-25 00:36:34.020977: evaluation of raw predictions\n",
      "2021-10-25 00:36:36.165757: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8452586547501958\n",
      "after:  0.845594269274395\n",
      "Removing all but the largest foreground region improved results!\n",
      "for_which_classes [1]\n",
      "min_valid_object_sizes None\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[[1]]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Model 2\n",
    "os.chdir(main_dir)\n",
    "\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 0\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 1\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 2\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 3\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 4\n",
    "\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "using model stored in  /mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1\n",
      "This model expects 2 input modalities for each image\n",
      "Found 3 unique case ids, here are some examples: ['23010017_20141226' '23010018_20141226' '23010017_20141226']\n",
      "If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc\n",
      "number of cases: 3\n",
      "number of cases that still need to be predicted: 3\n",
      "emptying cuda cache\n",
      "loading parameters for folds, None\n",
      "folds is None so we will automatically look for output folders (not using 'all'!)\n",
      "found the following folds:  ['/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4']\n",
      "using the following model files:  ['/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4/model_final_checkpoint.model']\n",
      "starting preprocessing generator\n",
      "starting prediction...\n",
      "preprocessing /tf/2d_fold12345/23010017_20141226.nii.gz\n",
      "using preprocessor PreprocessorFor2D\n",
      "preprocessing /tf/2d_fold12345/23010018_20141226.nii.gz\n",
      "using preprocessor PreprocessorFor2D\n",
      "preprocessing /tf/2d_fold12345/23010019_20141224.nii.gz\n",
      "using preprocessor PreprocessorFor2D\n",
      "before crop: (2, 284, 200, 200) after crop: (2, 284, 173, 173) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 284, 200, 200) after crop: (2, 284, 192, 192) spacing: [1. 1. 1.] \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 284, 173, 173)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 284, 173, 173)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "(2, 284, 173, 173)\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 284, 192, 192)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 284, 192, 192)} \n",
      "\n",
      "normalization...\n",
      "This worker has ended successfully, no errors to report\n",
      "before crop: (2, 326, 200, 200) after crop: (2, 326, 174, 173) spacing: [1. 1. 1.] \n",
      "\n",
      "predicting /tf/2d_fold12345/23010018_20141226.nii.gz\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "normalization done\n",
      "(2, 284, 192, 192)\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 326, 174, 173)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 326, 174, 173)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "(2, 326, 174, 173)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "predicting /tf/2d_fold12345/23010017_20141226.nii.gz\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "This worker has ended successfully, no errors to report\n",
      "predicting /tf/2d_fold12345/23010019_20141224.nii.gz\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "This worker has ended successfully, no errors to report\n",
      "inference done. Now waiting for the segmentation export to finish...\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "WARNING! Cannot run postprocessing because the postprocessing file is missing. Make sure to run consolidate_folds in the output folder of the model first!\n",
      "The folder you need to run this in is /mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1\n"
     ]
    }
   ],
   "source": [
    "os.listdir('/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/')\n",
    "!nnUNet_predict -i /tf/sample_input -o /tf/2d_fold12345/ -t 555 -tr nnUNetTrainerV2 -m 2d --disable_tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-01 00:47:40.774766: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-01 00:47:40.797921: The split file contains 5 splits.\n",
      "2021-11-01 00:47:40.804965: Desired fold for training: 0\n",
      "2021-11-01 00:47:40.811581: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-01 00:47:45.115251: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-01 00:47:59.361436: Unable to plot network architecture:\n",
      "2021-11-01 00:47:59.365009: No module named 'hiddenlayer'\n",
      "2021-11-01 00:47:59.372101: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-01 00:47:59.439123: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-01 00:47:59.552233: \n",
      "\n",
      "2021-11-01 00:47:59.558735: \n",
      "epoch:  0\n",
      "2021-11-01 00:52:44.801494: train loss : -0.2108\n",
      "2021-11-01 00:53:02.430489: validation loss: -0.5793\n",
      "2021-11-01 00:53:02.434421: Average global foreground Dice: [0.6351]\n",
      "2021-11-01 00:53:02.442129: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 00:53:02.864995: lr: 0.00991\n",
      "2021-11-01 00:53:02.893811: This epoch took 303.327215 s\n",
      "\n",
      "2021-11-01 00:53:02.901271: \n",
      "epoch:  1\n",
      "2021-11-01 00:57:39.776719: train loss : -0.5968\n",
      "2021-11-01 00:57:57.775292: validation loss: -0.7133\n",
      "2021-11-01 00:57:57.778772: Average global foreground Dice: [0.7555]\n",
      "2021-11-01 00:57:57.784144: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 00:57:58.261504: lr: 0.00982\n",
      "2021-11-01 00:57:58.366781: saving checkpoint...\n",
      "2021-11-01 00:57:59.336629: done, saving took 1.05 seconds\n",
      "2021-11-01 00:57:59.935369: This epoch took 297.027184 s\n",
      "\n",
      "2021-11-01 00:57:59.953921: \n",
      "epoch:  2\n",
      "2021-11-01 01:02:35.460531: train loss : -0.6739\n",
      "2021-11-01 01:02:53.192924: validation loss: -0.7342\n",
      "2021-11-01 01:02:53.196529: Average global foreground Dice: [0.7744]\n",
      "2021-11-01 01:02:53.203192: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 01:02:53.699455: lr: 0.00973\n",
      "2021-11-01 01:02:53.807085: saving checkpoint...\n",
      "2021-11-01 01:02:54.935134: done, saving took 1.20 seconds\n",
      "2021-11-01 01:02:55.547206: This epoch took 295.586554 s\n",
      "\n",
      "2021-11-01 01:02:55.565979: \n",
      "epoch:  3\n",
      "2021-11-01 01:07:31.365751: train loss : -0.7122\n",
      "2021-11-01 01:07:49.117864: validation loss: -0.7781\n",
      "2021-11-01 01:07:49.121994: Average global foreground Dice: [0.8138]\n",
      "2021-11-01 01:07:49.131687: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 01:07:49.615602: lr: 0.009639\n",
      "2021-11-01 01:07:49.711833: saving checkpoint...\n",
      "2021-11-01 01:07:50.903707: done, saving took 1.25 seconds\n",
      "2021-11-01 01:07:51.547348: This epoch took 295.974003 s\n",
      "\n",
      "2021-11-01 01:07:51.565266: \n",
      "epoch:  4\n",
      "2021-11-01 01:12:26.232891: train loss : -0.7437\n",
      "2021-11-01 01:12:43.678335: validation loss: -0.7796\n",
      "2021-11-01 01:12:43.683152: Average global foreground Dice: [0.8132]\n",
      "2021-11-01 01:12:43.690597: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 01:12:44.165306: lr: 0.009549\n",
      "2021-11-01 01:12:44.250263: saving checkpoint...\n",
      "2021-11-01 01:12:45.402880: done, saving took 1.20 seconds\n",
      "2021-11-01 01:12:46.003215: This epoch took 294.432079 s\n",
      "\n",
      "2021-11-01 01:12:46.022614: \n",
      "epoch:  5\n",
      "2021-11-01 01:17:20.608668: train loss : -0.7549\n",
      "2021-11-01 01:17:38.185026: validation loss: -0.8019\n",
      "2021-11-01 01:17:38.188961: Average global foreground Dice: [0.8344]\n",
      "2021-11-01 01:17:38.194820: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 01:17:38.672000: lr: 0.009458\n",
      "2021-11-01 01:17:38.768612: saving checkpoint...\n",
      "2021-11-01 01:17:39.906808: done, saving took 1.21 seconds\n",
      "2021-11-01 01:17:40.528033: This epoch took 294.499123 s\n",
      "\n",
      "2021-11-01 01:17:40.546157: \n",
      "epoch:  6\n",
      "2021-11-01 01:22:15.719792: train loss : -0.7740\n",
      "2021-11-01 01:22:33.442759: validation loss: -0.8131\n",
      "2021-11-01 01:22:33.446267: Average global foreground Dice: [0.8419]\n",
      "2021-11-01 01:22:33.451825: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 01:22:33.930285: lr: 0.009368\n",
      "2021-11-01 01:22:34.017768: saving checkpoint...\n",
      "2021-11-01 01:22:35.167097: done, saving took 1.21 seconds\n",
      "2021-11-01 01:22:35.789532: This epoch took 295.236729 s\n",
      "\n",
      "2021-11-01 01:22:35.807112: \n",
      "epoch:  7\n",
      "2021-11-01 01:27:09.869614: train loss : -0.7768\n",
      "2021-11-01 01:27:27.403277: validation loss: -0.8144\n",
      "2021-11-01 01:27:27.406841: Average global foreground Dice: [0.8336]\n",
      "2021-11-01 01:27:27.412957: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 01:27:27.900244: lr: 0.009277\n",
      "2021-11-01 01:27:27.989354: saving checkpoint...\n",
      "2021-11-01 01:27:29.143832: done, saving took 1.21 seconds\n",
      "2021-11-01 01:27:29.768281: This epoch took 293.954852 s\n",
      "\n",
      "2021-11-01 01:27:29.785702: \n",
      "epoch:  8\n",
      "2021-11-01 01:32:04.322387: train loss : -0.7896\n",
      "2021-11-01 01:32:22.006173: validation loss: -0.8229\n",
      "2021-11-01 01:32:22.009922: Average global foreground Dice: [0.8458]\n",
      "2021-11-01 01:32:22.015397: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 01:32:22.509517: lr: 0.009186\n",
      "2021-11-01 01:32:22.596056: saving checkpoint...\n",
      "2021-11-01 01:32:23.721868: done, saving took 1.18 seconds\n",
      "2021-11-01 01:32:24.415381: This epoch took 294.620577 s\n",
      "\n",
      "2021-11-01 01:32:24.435876: \n",
      "epoch:  9\n",
      "2021-11-01 01:36:58.988588: train loss : -0.7909\n",
      "2021-11-01 01:37:16.629945: validation loss: -0.8273\n",
      "2021-11-01 01:37:16.633824: Average global foreground Dice: [0.8442]\n",
      "2021-11-01 01:37:16.641055: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 01:37:17.125328: lr: 0.009095\n",
      "2021-11-01 01:37:17.211982: saving checkpoint...\n",
      "2021-11-01 01:37:18.456126: done, saving took 1.30 seconds\n",
      "2021-11-01 01:37:19.057876: This epoch took 294.614457 s\n",
      "\n",
      "2021-11-01 01:37:19.078049: \n",
      "epoch:  10\n",
      "2021-11-01 01:41:53.511170: train loss : -0.7926\n",
      "2021-11-01 01:42:11.074342: validation loss: -0.8267\n",
      "2021-11-01 01:42:11.078671: Average global foreground Dice: [0.8524]\n",
      "2021-11-01 01:42:11.086317: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 01:42:11.570494: lr: 0.009004\n",
      "2021-11-01 01:42:11.658108: saving checkpoint...\n",
      "2021-11-01 01:42:12.817035: done, saving took 1.22 seconds\n",
      "2021-11-01 01:42:13.430860: This epoch took 294.345772 s\n",
      "\n",
      "2021-11-01 01:42:13.450530: \n",
      "epoch:  11\n",
      "2021-11-01 01:46:47.811185: train loss : -0.7989\n",
      "2021-11-01 01:47:05.107400: validation loss: -0.8181\n",
      "2021-11-01 01:47:05.111489: Average global foreground Dice: [0.8413]\n",
      "2021-11-01 01:47:05.118130: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 01:47:05.582650: lr: 0.008913\n",
      "2021-11-01 01:47:05.646038: saving checkpoint...\n",
      "2021-11-01 01:47:06.857901: done, saving took 1.24 seconds\n",
      "2021-11-01 01:47:07.622297: This epoch took 294.164046 s\n",
      "\n",
      "2021-11-01 01:47:07.641872: \n",
      "epoch:  12\n",
      "2021-11-01 01:51:41.295010: train loss : -0.8081\n",
      "2021-11-01 01:51:59.080962: validation loss: -0.8351\n",
      "2021-11-01 01:51:59.084901: Average global foreground Dice: [0.85]\n",
      "2021-11-01 01:51:59.091933: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 01:51:59.559902: lr: 0.008822\n",
      "2021-11-01 01:51:59.620242: saving checkpoint...\n",
      "2021-11-01 01:52:00.853957: done, saving took 1.26 seconds\n",
      "2021-11-01 01:52:01.491775: This epoch took 293.841894 s\n",
      "\n",
      "2021-11-01 01:52:01.510552: \n",
      "epoch:  13\n",
      "2021-11-01 01:56:37.181343: train loss : -0.8116\n",
      "2021-11-01 01:56:54.557239: validation loss: -0.8403\n",
      "2021-11-01 01:56:54.561131: Average global foreground Dice: [0.8604]\n",
      "2021-11-01 01:56:54.568601: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 01:56:55.042324: lr: 0.008731\n",
      "2021-11-01 01:56:55.103109: saving checkpoint...\n",
      "2021-11-01 01:56:56.286759: done, saving took 1.21 seconds\n",
      "2021-11-01 01:56:56.888088: This epoch took 295.369982 s\n",
      "\n",
      "2021-11-01 01:56:56.908285: \n",
      "epoch:  14\n",
      "2021-11-01 02:01:29.735652: train loss : -0.8147\n",
      "2021-11-01 02:01:47.105632: validation loss: -0.8380\n",
      "2021-11-01 02:01:47.109445: Average global foreground Dice: [0.855]\n",
      "2021-11-01 02:01:47.116167: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 02:01:47.583030: lr: 0.008639\n",
      "2021-11-01 02:01:47.646796: saving checkpoint...\n",
      "2021-11-01 02:01:48.861357: done, saving took 1.24 seconds\n",
      "2021-11-01 02:01:49.525260: This epoch took 292.609752 s\n",
      "\n",
      "2021-11-01 02:01:49.544647: \n",
      "epoch:  15\n",
      "2021-11-01 02:06:24.956633: train loss : -0.8145\n",
      "2021-11-01 02:06:42.264301: validation loss: -0.8314\n",
      "2021-11-01 02:06:42.268060: Average global foreground Dice: [0.8535]\n",
      "2021-11-01 02:06:42.274591: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 02:06:42.746142: lr: 0.008548\n",
      "2021-11-01 02:06:42.807102: saving checkpoint...\n",
      "2021-11-01 02:06:43.970695: done, saving took 1.19 seconds\n",
      "2021-11-01 02:06:44.547355: This epoch took 294.994687 s\n",
      "\n",
      "2021-11-01 02:06:44.567503: \n",
      "epoch:  16\n",
      "2021-11-01 02:11:19.073510: train loss : -0.8139\n",
      "2021-11-01 02:11:36.420714: validation loss: -0.8453\n",
      "2021-11-01 02:11:36.424871: Average global foreground Dice: [0.8592]\n",
      "2021-11-01 02:11:36.431578: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 02:11:36.903054: lr: 0.008456\n",
      "2021-11-01 02:11:36.961568: saving checkpoint...\n",
      "2021-11-01 02:11:38.118331: done, saving took 1.19 seconds\n",
      "2021-11-01 02:11:38.861629: This epoch took 294.287090 s\n",
      "\n",
      "2021-11-01 02:11:38.877036: \n",
      "epoch:  17\n",
      "2021-11-01 02:16:13.599314: train loss : -0.8230\n",
      "2021-11-01 02:16:30.963347: validation loss: -0.8434\n",
      "2021-11-01 02:16:30.966747: Average global foreground Dice: [0.8591]\n",
      "2021-11-01 02:16:30.972647: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 02:16:31.442993: lr: 0.008364\n",
      "2021-11-01 02:16:31.521667: saving checkpoint...\n",
      "2021-11-01 02:16:32.664114: done, saving took 1.19 seconds\n",
      "2021-11-01 02:16:33.260831: This epoch took 294.376048 s\n",
      "\n",
      "2021-11-01 02:16:33.281707: \n",
      "epoch:  18\n",
      "2021-11-01 02:21:11.233674: train loss : -0.8153\n",
      "2021-11-01 02:21:28.690172: validation loss: -0.8429\n",
      "2021-11-01 02:21:28.693987: Average global foreground Dice: [0.8604]\n",
      "2021-11-01 02:21:28.700432: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 02:21:29.162689: lr: 0.008272\n",
      "2021-11-01 02:21:29.247327: saving checkpoint...\n",
      "2021-11-01 02:21:30.373813: done, saving took 1.19 seconds\n",
      "2021-11-01 02:21:30.949913: This epoch took 297.660535 s\n",
      "\n",
      "2021-11-01 02:21:30.958965: \n",
      "epoch:  19\n",
      "2021-11-01 02:26:08.856257: train loss : -0.8173\n",
      "2021-11-01 02:26:26.298702: validation loss: -0.8338\n",
      "2021-11-01 02:26:26.303047: Average global foreground Dice: [0.8487]\n",
      "2021-11-01 02:26:26.310494: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 02:26:26.775495: lr: 0.008181\n",
      "2021-11-01 02:26:26.882814: saving checkpoint...\n",
      "2021-11-01 02:26:28.037413: done, saving took 1.23 seconds\n",
      "2021-11-01 02:26:28.625333: This epoch took 297.657906 s\n",
      "\n",
      "2021-11-01 02:26:28.643217: \n",
      "epoch:  20\n",
      "2021-11-01 02:31:06.670056: train loss : -0.8214\n",
      "2021-11-01 02:31:24.427506: validation loss: -0.8330\n",
      "2021-11-01 02:31:24.431559: Average global foreground Dice: [0.8495]\n",
      "2021-11-01 02:31:24.438441: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 02:31:24.966286: lr: 0.008088\n",
      "2021-11-01 02:31:25.070443: saving checkpoint...\n",
      "2021-11-01 02:31:26.194251: done, saving took 1.20 seconds\n",
      "2021-11-01 02:31:26.787589: This epoch took 298.136520 s\n",
      "\n",
      "2021-11-01 02:31:26.805895: \n",
      "epoch:  21\n",
      "2021-11-01 02:36:05.215792: train loss : -0.8184\n",
      "2021-11-01 02:36:22.946033: validation loss: -0.8452\n",
      "2021-11-01 02:36:22.950989: Average global foreground Dice: [0.8597]\n",
      "2021-11-01 02:36:22.956776: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 02:36:23.434360: lr: 0.007996\n",
      "2021-11-01 02:36:23.524019: saving checkpoint...\n",
      "2021-11-01 02:36:24.715083: done, saving took 1.26 seconds\n",
      "2021-11-01 02:36:25.312322: This epoch took 298.499534 s\n",
      "\n",
      "2021-11-01 02:36:25.321058: \n",
      "epoch:  22\n",
      "2021-11-01 02:41:03.166393: train loss : -0.8186\n",
      "2021-11-01 02:41:20.903108: validation loss: -0.8339\n",
      "2021-11-01 02:41:20.906635: Average global foreground Dice: [0.8471]\n",
      "2021-11-01 02:41:20.913099: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 02:41:21.392246: lr: 0.007904\n",
      "2021-11-01 02:41:21.473977: saving checkpoint...\n",
      "2021-11-01 02:41:22.590534: done, saving took 1.18 seconds\n",
      "2021-11-01 02:41:23.195512: This epoch took 297.866786 s\n",
      "\n",
      "2021-11-01 02:41:23.203313: \n",
      "epoch:  23\n",
      "2021-11-01 02:46:01.323166: train loss : -0.8232\n",
      "2021-11-01 02:46:19.053815: validation loss: -0.8374\n",
      "2021-11-01 02:46:19.058398: Average global foreground Dice: [0.8517]\n",
      "2021-11-01 02:46:19.065471: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 02:46:19.529156: lr: 0.007811\n",
      "2021-11-01 02:46:19.622606: saving checkpoint...\n",
      "2021-11-01 02:46:20.815222: done, saving took 1.26 seconds\n",
      "2021-11-01 02:46:21.474043: This epoch took 298.263748 s\n",
      "\n",
      "2021-11-01 02:46:21.494423: \n",
      "epoch:  24\n",
      "2021-11-01 02:51:00.485626: train loss : -0.8251\n",
      "2021-11-01 02:51:17.963755: validation loss: -0.8521\n",
      "2021-11-01 02:51:17.968619: Average global foreground Dice: [0.8643]\n",
      "2021-11-01 02:51:17.975193: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 02:51:18.438299: lr: 0.007719\n",
      "2021-11-01 02:51:18.487597: saving checkpoint...\n",
      "2021-11-01 02:51:19.607539: done, saving took 1.15 seconds\n",
      "2021-11-01 02:51:20.294452: This epoch took 298.792907 s\n",
      "\n",
      "2021-11-01 02:51:20.303374: \n",
      "epoch:  25\n",
      "2021-11-01 02:55:59.050755: train loss : -0.8293\n",
      "2021-11-01 02:56:16.515130: validation loss: -0.8326\n",
      "2021-11-01 02:56:16.519044: Average global foreground Dice: [0.8466]\n",
      "2021-11-01 02:56:16.525811: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 02:56:16.986780: lr: 0.007626\n",
      "2021-11-01 02:56:17.037704: saving checkpoint...\n",
      "2021-11-01 02:56:18.145657: done, saving took 1.14 seconds\n",
      "2021-11-01 02:56:18.757805: This epoch took 298.446697 s\n",
      "\n",
      "2021-11-01 02:56:18.766468: \n",
      "epoch:  26\n",
      "2021-11-01 03:00:57.932405: train loss : -0.8214\n",
      "2021-11-01 03:01:15.696061: validation loss: -0.8331\n",
      "2021-11-01 03:01:15.699422: Average global foreground Dice: [0.8506]\n",
      "2021-11-01 03:01:15.706008: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 03:01:16.174442: lr: 0.007533\n",
      "2021-11-01 03:01:16.261183: saving checkpoint...\n",
      "2021-11-01 03:01:17.399765: done, saving took 1.20 seconds\n",
      "2021-11-01 03:01:18.023936: This epoch took 299.250342 s\n",
      "\n",
      "2021-11-01 03:01:18.041643: \n",
      "epoch:  27\n",
      "2021-11-01 03:05:57.107012: train loss : -0.8310\n",
      "2021-11-01 03:06:14.839693: validation loss: -0.8377\n",
      "2021-11-01 03:06:14.843414: Average global foreground Dice: [0.858]\n",
      "2021-11-01 03:06:14.850084: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 03:06:15.332408: lr: 0.00744\n",
      "2021-11-01 03:06:15.418113: saving checkpoint...\n",
      "2021-11-01 03:06:16.666974: done, saving took 1.30 seconds\n",
      "2021-11-01 03:06:17.323115: This epoch took 299.274018 s\n",
      "\n",
      "2021-11-01 03:06:17.343398: \n",
      "epoch:  28\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-01 03:10:56.028386: train loss : -0.8335\n",
      "2021-11-01 03:11:13.764509: validation loss: -0.8461\n",
      "2021-11-01 03:11:13.767687: Average global foreground Dice: [0.8576]\n",
      "2021-11-01 03:11:13.773288: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 03:11:14.254656: lr: 0.007347\n",
      "2021-11-01 03:11:14.347012: saving checkpoint...\n",
      "2021-11-01 03:11:15.587694: done, saving took 1.29 seconds\n",
      "2021-11-01 03:11:16.232593: This epoch took 298.881949 s\n",
      "\n",
      "2021-11-01 03:11:16.253079: \n",
      "epoch:  29\n",
      "2021-11-01 03:15:53.810308: train loss : -0.8370\n",
      "2021-11-01 03:16:11.567261: validation loss: -0.8460\n",
      "2021-11-01 03:16:11.571408: Average global foreground Dice: [0.8585]\n",
      "2021-11-01 03:16:11.578042: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 03:16:12.055132: lr: 0.007254\n",
      "2021-11-01 03:16:12.140647: saving checkpoint...\n",
      "2021-11-01 03:16:13.432661: done, saving took 1.34 seconds\n",
      "2021-11-01 03:16:14.040596: This epoch took 297.779542 s\n",
      "\n",
      "2021-11-01 03:16:14.061291: \n",
      "epoch:  30\n",
      "2021-11-01 03:20:52.102364: train loss : -0.8349\n",
      "2021-11-01 03:21:09.613257: validation loss: -0.8301\n",
      "2021-11-01 03:21:09.616893: Average global foreground Dice: [0.8467]\n",
      "2021-11-01 03:21:09.626134: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 03:21:10.094579: lr: 0.007161\n",
      "2021-11-01 03:21:10.155066: saving checkpoint...\n",
      "2021-11-01 03:21:11.375864: done, saving took 1.25 seconds\n",
      "2021-11-01 03:21:12.002044: This epoch took 297.933434 s\n",
      "\n",
      "2021-11-01 03:21:12.020105: \n",
      "epoch:  31\n",
      "2021-11-01 03:25:50.196613: train loss : -0.8293\n",
      "2021-11-01 03:26:07.702091: validation loss: -0.8493\n",
      "2021-11-01 03:26:07.705891: Average global foreground Dice: [0.8634]\n",
      "2021-11-01 03:26:07.712899: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 03:26:08.180182: lr: 0.007067\n",
      "2021-11-01 03:26:08.238347: saving checkpoint...\n",
      "2021-11-01 03:26:09.353284: done, saving took 1.14 seconds\n",
      "2021-11-01 03:26:09.967867: This epoch took 297.940749 s\n",
      "\n",
      "2021-11-01 03:26:09.986181: \n",
      "epoch:  32\n",
      "2021-11-01 03:30:47.077412: train loss : -0.8334\n",
      "2021-11-01 03:31:04.574945: validation loss: -0.8497\n",
      "2021-11-01 03:31:04.578544: Average global foreground Dice: [0.862]\n",
      "2021-11-01 03:31:04.585699: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 03:31:05.063284: lr: 0.006974\n",
      "2021-11-01 03:31:05.121743: saving checkpoint...\n",
      "2021-11-01 03:31:06.344856: done, saving took 1.25 seconds\n",
      "2021-11-01 03:31:06.984845: This epoch took 296.991419 s\n",
      "\n",
      "2021-11-01 03:31:07.002492: \n",
      "epoch:  33\n",
      "2021-11-01 03:35:43.769401: train loss : -0.8269\n",
      "2021-11-01 03:36:01.228691: validation loss: -0.8485\n",
      "2021-11-01 03:36:01.232904: Average global foreground Dice: [0.8615]\n",
      "2021-11-01 03:36:01.241629: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 03:36:01.711220: lr: 0.00688\n",
      "2021-11-01 03:36:01.773672: saving checkpoint...\n",
      "2021-11-01 03:36:02.991319: done, saving took 1.25 seconds\n",
      "2021-11-01 03:36:03.625281: This epoch took 296.616138 s\n",
      "\n",
      "2021-11-01 03:36:03.646149: \n",
      "epoch:  34\n",
      "2021-11-01 03:40:40.146523: train loss : -0.8275\n",
      "2021-11-01 03:40:57.643459: validation loss: -0.8471\n",
      "2021-11-01 03:40:57.646728: Average global foreground Dice: [0.8605]\n",
      "2021-11-01 03:40:57.653283: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 03:40:58.128329: lr: 0.006786\n",
      "2021-11-01 03:40:58.187094: saving checkpoint...\n",
      "2021-11-01 03:40:59.430047: done, saving took 1.27 seconds\n",
      "2021-11-01 03:41:00.019222: This epoch took 296.365775 s\n",
      "\n",
      "2021-11-01 03:41:00.038782: \n",
      "epoch:  35\n",
      "2021-11-01 03:45:36.196048: train loss : -0.8355\n",
      "2021-11-01 03:45:53.690034: validation loss: -0.8532\n",
      "2021-11-01 03:45:53.693744: Average global foreground Dice: [0.868]\n",
      "2021-11-01 03:45:53.700958: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 03:45:54.175070: lr: 0.006692\n",
      "2021-11-01 03:45:54.233554: saving checkpoint...\n",
      "2021-11-01 03:45:55.504482: done, saving took 1.30 seconds\n",
      "2021-11-01 03:45:56.113704: This epoch took 296.066722 s\n",
      "\n",
      "2021-11-01 03:45:56.134407: \n",
      "epoch:  36\n",
      "2021-11-01 03:50:32.390738: train loss : -0.8336\n",
      "2021-11-01 03:50:49.871080: validation loss: -0.8507\n",
      "2021-11-01 03:50:49.875021: Average global foreground Dice: [0.8628]\n",
      "2021-11-01 03:50:49.881768: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 03:50:50.346983: lr: 0.006598\n",
      "2021-11-01 03:50:50.424300: saving checkpoint...\n",
      "2021-11-01 03:50:51.649787: done, saving took 1.27 seconds\n",
      "2021-11-01 03:50:52.295169: This epoch took 296.154298 s\n",
      "\n",
      "2021-11-01 03:50:52.314963: \n",
      "epoch:  37\n",
      "2021-11-01 03:55:27.979144: train loss : -0.8368\n",
      "2021-11-01 03:55:45.450129: validation loss: -0.8517\n",
      "2021-11-01 03:55:45.455152: Average global foreground Dice: [0.8641]\n",
      "2021-11-01 03:55:45.463788: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 03:55:46.002755: lr: 0.006504\n",
      "2021-11-01 03:55:46.087645: saving checkpoint...\n",
      "2021-11-01 03:55:47.219996: done, saving took 1.19 seconds\n",
      "2021-11-01 03:55:47.888523: This epoch took 295.565703 s\n",
      "\n",
      "2021-11-01 03:55:47.898841: \n",
      "epoch:  38\n",
      "2021-11-01 04:00:24.232325: train loss : -0.8438\n",
      "2021-11-01 04:00:41.966933: validation loss: -0.8452\n",
      "2021-11-01 04:00:41.970872: Average global foreground Dice: [0.8588]\n",
      "2021-11-01 04:00:41.977787: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 04:00:42.458084: lr: 0.006409\n",
      "2021-11-01 04:00:42.541863: saving checkpoint...\n",
      "2021-11-01 04:00:43.669514: done, saving took 1.19 seconds\n",
      "2021-11-01 04:00:44.279274: This epoch took 296.370253 s\n",
      "\n",
      "2021-11-01 04:00:44.288873: \n",
      "epoch:  39\n",
      "2021-11-01 04:05:21.209816: train loss : -0.8374\n",
      "2021-11-01 04:05:39.330731: validation loss: -0.8453\n",
      "2021-11-01 04:05:39.334548: Average global foreground Dice: [0.8594]\n",
      "2021-11-01 04:05:39.339901: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 04:05:39.821078: lr: 0.006314\n",
      "2021-11-01 04:05:39.908593: saving checkpoint...\n",
      "2021-11-01 04:05:41.160045: done, saving took 1.31 seconds\n",
      "2021-11-01 04:05:41.761347: This epoch took 297.465492 s\n",
      "\n",
      "2021-11-01 04:05:41.778986: \n",
      "epoch:  40\n",
      "2021-11-01 04:10:18.981341: train loss : -0.8379\n",
      "2021-11-01 04:10:36.928007: validation loss: -0.8506\n",
      "2021-11-01 04:10:36.931842: Average global foreground Dice: [0.8666]\n",
      "2021-11-01 04:10:36.938725: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 04:10:37.419846: lr: 0.00622\n",
      "2021-11-01 04:10:37.500680: saving checkpoint...\n",
      "2021-11-01 04:10:38.629868: done, saving took 1.19 seconds\n",
      "2021-11-01 04:10:39.235142: This epoch took 297.449708 s\n",
      "\n",
      "2021-11-01 04:10:39.243247: \n",
      "epoch:  41\n",
      "2021-11-01 04:15:17.541538: train loss : -0.8391\n",
      "2021-11-01 04:15:35.417043: validation loss: -0.8533\n",
      "2021-11-01 04:15:35.420974: Average global foreground Dice: [0.8635]\n",
      "2021-11-01 04:15:35.427495: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 04:15:35.893543: lr: 0.006125\n",
      "2021-11-01 04:15:35.983240: saving checkpoint...\n",
      "2021-11-01 04:15:37.248717: done, saving took 1.33 seconds\n",
      "2021-11-01 04:15:37.927636: This epoch took 298.676831 s\n",
      "\n",
      "2021-11-01 04:15:37.946309: \n",
      "epoch:  42\n",
      "2021-11-01 04:20:15.927703: train loss : -0.8431\n",
      "2021-11-01 04:20:33.481219: validation loss: -0.8314\n",
      "2021-11-01 04:20:33.485243: Average global foreground Dice: [0.8478]\n",
      "2021-11-01 04:20:33.491756: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 04:20:33.952804: lr: 0.00603\n",
      "2021-11-01 04:20:33.979834: This epoch took 296.027219 s\n",
      "\n",
      "2021-11-01 04:20:33.985876: \n",
      "epoch:  43\n",
      "2021-11-01 04:25:11.775313: train loss : -0.8437\n",
      "2021-11-01 04:25:29.498256: validation loss: -0.8504\n",
      "2021-11-01 04:25:29.501941: Average global foreground Dice: [0.8609]\n",
      "2021-11-01 04:25:29.508886: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 04:25:29.973675: lr: 0.005934\n",
      "2021-11-01 04:25:30.007720: This epoch took 296.014661 s\n",
      "\n",
      "2021-11-01 04:25:30.016288: \n",
      "epoch:  44\n",
      "2021-11-01 04:30:07.230790: train loss : -0.8427\n",
      "2021-11-01 04:30:24.733551: validation loss: -0.8449\n",
      "2021-11-01 04:30:24.737418: Average global foreground Dice: [0.8557]\n",
      "2021-11-01 04:30:24.744757: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 04:30:25.215585: lr: 0.005839\n",
      "2021-11-01 04:30:25.245528: This epoch took 295.221533 s\n",
      "\n",
      "2021-11-01 04:30:25.252635: \n",
      "epoch:  45\n",
      "2021-11-01 04:35:01.516430: train loss : -0.8419\n",
      "2021-11-01 04:35:19.265348: validation loss: -0.8404\n",
      "2021-11-01 04:35:19.268870: Average global foreground Dice: [0.8524]\n",
      "2021-11-01 04:35:19.274712: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 04:35:19.746862: lr: 0.005743\n",
      "2021-11-01 04:35:19.771457: This epoch took 294.512282 s\n",
      "\n",
      "2021-11-01 04:35:19.777621: \n",
      "epoch:  46\n",
      "2021-11-01 04:39:57.095953: train loss : -0.8443\n",
      "2021-11-01 04:40:14.809137: validation loss: -0.8437\n",
      "2021-11-01 04:40:14.813432: Average global foreground Dice: [0.8554]\n",
      "2021-11-01 04:40:14.824954: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 04:40:15.304285: lr: 0.005647\n",
      "2021-11-01 04:40:15.323922: This epoch took 295.538634 s\n",
      "\n",
      "2021-11-01 04:40:15.332750: \n",
      "epoch:  47\n",
      "2021-11-01 04:44:51.967664: train loss : -0.8466\n",
      "2021-11-01 04:45:09.693133: validation loss: -0.8572\n",
      "2021-11-01 04:45:09.696601: Average global foreground Dice: [0.8643]\n",
      "2021-11-01 04:45:09.702660: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 04:45:10.173544: lr: 0.005551\n",
      "2021-11-01 04:45:10.265877: saving checkpoint...\n",
      "2021-11-01 04:45:11.490434: done, saving took 1.30 seconds\n",
      "2021-11-01 04:45:12.141779: This epoch took 296.802387 s\n",
      "\n",
      "2021-11-01 04:45:12.149989: \n",
      "epoch:  48\n",
      "2021-11-01 04:49:48.084935: train loss : -0.8459\n",
      "2021-11-01 04:50:05.823722: validation loss: -0.8575\n",
      "2021-11-01 04:50:05.827364: Average global foreground Dice: [0.8661]\n",
      "2021-11-01 04:50:05.834187: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 04:50:06.298323: lr: 0.005455\n",
      "2021-11-01 04:50:06.403479: saving checkpoint...\n",
      "2021-11-01 04:50:07.523368: done, saving took 1.20 seconds\n",
      "2021-11-01 04:50:08.153887: This epoch took 295.996066 s\n",
      "\n",
      "2021-11-01 04:50:08.166339: \n",
      "epoch:  49\n",
      "2021-11-01 04:54:43.918663: train loss : -0.8462\n",
      "2021-11-01 04:55:01.690876: validation loss: -0.8450\n",
      "2021-11-01 04:55:01.694897: Average global foreground Dice: [0.8589]\n",
      "2021-11-01 04:55:01.701865: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 04:55:02.186989: lr: 0.005359\n",
      "2021-11-01 04:55:02.206109: saving scheduled checkpoint file...\n",
      "2021-11-01 04:55:02.283530: saving checkpoint...\n",
      "2021-11-01 04:55:03.297478: done, saving took 1.08 seconds\n",
      "2021-11-01 04:55:03.919424: done\n",
      "2021-11-01 04:55:03.957199: saving checkpoint...\n",
      "2021-11-01 04:55:05.086309: done, saving took 1.16 seconds\n",
      "2021-11-01 04:55:05.720148: This epoch took 297.546677 s\n",
      "\n",
      "2021-11-01 04:55:05.729094: \n",
      "epoch:  50\n",
      "2021-11-01 04:59:40.540292: train loss : -0.8477\n",
      "2021-11-01 04:59:57.991332: validation loss: -0.8462\n",
      "2021-11-01 04:59:57.995120: Average global foreground Dice: [0.8561]\n",
      "2021-11-01 04:59:58.003208: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 04:59:58.465847: lr: 0.005262\n",
      "2021-11-01 04:59:58.482433: This epoch took 292.745822 s\n",
      "\n",
      "2021-11-01 04:59:58.489763: \n",
      "epoch:  51\n",
      "2021-11-01 05:04:34.159018: train loss : -0.8493\n",
      "2021-11-01 05:04:51.580284: validation loss: -0.8577\n",
      "2021-11-01 05:04:51.583678: Average global foreground Dice: [0.8675]\n",
      "2021-11-01 05:04:51.590355: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 05:04:52.056775: lr: 0.005166\n",
      "2021-11-01 05:04:52.107908: saving checkpoint...\n",
      "2021-11-01 05:04:53.322374: done, saving took 1.24 seconds\n",
      "2021-11-01 05:04:53.929020: This epoch took 295.431521 s\n",
      "\n",
      "2021-11-01 05:04:53.943061: \n",
      "epoch:  52\n",
      "2021-11-01 05:09:29.907697: train loss : -0.8533\n",
      "2021-11-01 05:09:47.695661: validation loss: -0.8518\n",
      "2021-11-01 05:09:47.699954: Average global foreground Dice: [0.8632]\n",
      "2021-11-01 05:09:47.707117: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 05:09:48.174357: lr: 0.005069\n",
      "2021-11-01 05:09:48.225621: saving checkpoint...\n",
      "2021-11-01 05:09:49.333013: done, saving took 1.14 seconds\n",
      "2021-11-01 05:09:49.929549: This epoch took 295.979769 s\n",
      "\n",
      "2021-11-01 05:09:49.939937: \n",
      "epoch:  53\n",
      "2021-11-01 05:14:27.189630: train loss : -0.8455\n",
      "2021-11-01 05:14:44.654729: validation loss: -0.8504\n",
      "2021-11-01 05:14:44.658527: Average global foreground Dice: [0.8619]\n",
      "2021-11-01 05:14:44.666100: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 05:14:45.132640: lr: 0.004971\n",
      "2021-11-01 05:14:45.179096: saving checkpoint...\n",
      "2021-11-01 05:14:46.288123: done, saving took 1.14 seconds\n",
      "2021-11-01 05:14:46.899915: This epoch took 296.952195 s\n",
      "\n",
      "2021-11-01 05:14:46.908482: \n",
      "epoch:  54\n",
      "2021-11-01 05:19:25.026936: train loss : -0.8459\n",
      "2021-11-01 05:19:42.491669: validation loss: -0.8430\n",
      "2021-11-01 05:19:42.495198: Average global foreground Dice: [0.8561]\n",
      "2021-11-01 05:19:42.501448: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 05:19:42.964018: lr: 0.004874\n",
      "2021-11-01 05:19:42.998331: This epoch took 296.081863 s\n",
      "\n",
      "2021-11-01 05:19:43.005854: \n",
      "epoch:  55\n",
      "2021-11-01 05:24:21.457474: train loss : -0.8479\n",
      "2021-11-01 05:24:39.053478: validation loss: -0.8359\n",
      "2021-11-01 05:24:39.056999: Average global foreground Dice: [0.85]\n",
      "2021-11-01 05:24:39.064530: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 05:24:39.530986: lr: 0.004776\n",
      "2021-11-01 05:24:39.548808: This epoch took 296.534484 s\n",
      "\n",
      "2021-11-01 05:24:39.556182: \n",
      "epoch:  56\n",
      "2021-11-01 05:29:18.469079: train loss : -0.8480\n",
      "2021-11-01 05:29:35.922038: validation loss: -0.8507\n",
      "2021-11-01 05:29:35.925857: Average global foreground Dice: [0.8607]\n",
      "2021-11-01 05:29:35.932415: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 05:29:36.398466: lr: 0.004679\n",
      "2021-11-01 05:29:36.414217: This epoch took 296.850796 s\n",
      "\n",
      "2021-11-01 05:29:36.421845: \n",
      "epoch:  57\n",
      "2021-11-01 05:34:14.934371: train loss : -0.8500\n",
      "2021-11-01 05:34:32.411114: validation loss: -0.8491\n",
      "2021-11-01 05:34:32.415727: Average global foreground Dice: [0.8578]\n",
      "2021-11-01 05:34:32.428174: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 05:34:32.900297: lr: 0.004581\n",
      "2021-11-01 05:34:32.916080: This epoch took 296.486665 s\n",
      "\n",
      "2021-11-01 05:34:32.924938: \n",
      "epoch:  58\n",
      "2021-11-01 05:39:09.601199: train loss : -0.8453\n",
      "2021-11-01 05:39:27.061107: validation loss: -0.8479\n",
      "2021-11-01 05:39:27.065909: Average global foreground Dice: [0.8581]\n",
      "2021-11-01 05:39:27.072697: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 05:39:27.543303: lr: 0.004482\n",
      "2021-11-01 05:39:27.559697: This epoch took 294.627102 s\n",
      "\n",
      "2021-11-01 05:39:27.567225: \n",
      "epoch:  59\n",
      "2021-11-01 05:44:03.815916: train loss : -0.8503\n",
      "2021-11-01 05:44:21.327826: validation loss: -0.8500\n",
      "2021-11-01 05:44:21.331536: Average global foreground Dice: [0.8595]\n",
      "2021-11-01 05:44:21.338141: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 05:44:21.811833: lr: 0.004384\n",
      "2021-11-01 05:44:21.827538: This epoch took 294.252727 s\n",
      "\n",
      "2021-11-01 05:44:21.834508: \n",
      "epoch:  60\n",
      "2021-11-01 05:48:58.567367: train loss : -0.8526\n",
      "2021-11-01 05:49:16.276703: validation loss: -0.8553\n",
      "2021-11-01 05:49:16.280255: Average global foreground Dice: [0.8674]\n",
      "2021-11-01 05:49:16.287650: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 05:49:16.765798: lr: 0.004285\n",
      "2021-11-01 05:49:16.851620: saving checkpoint...\n",
      "2021-11-01 05:49:18.081551: done, saving took 1.30 seconds\n",
      "2021-11-01 05:49:18.699440: This epoch took 296.858062 s\n",
      "\n",
      "2021-11-01 05:49:18.709097: \n",
      "epoch:  61\n",
      "2021-11-01 05:53:55.046964: train loss : -0.8564\n",
      "2021-11-01 05:54:12.834492: validation loss: -0.8552\n",
      "2021-11-01 05:54:12.838716: Average global foreground Dice: [0.8632]\n",
      "2021-11-01 05:54:12.845907: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 05:54:13.323562: lr: 0.004186\n",
      "2021-11-01 05:54:13.403648: saving checkpoint...\n",
      "2021-11-01 05:54:14.514729: done, saving took 1.18 seconds\n",
      "2021-11-01 05:54:15.094249: This epoch took 296.377573 s\n",
      "\n",
      "2021-11-01 05:54:15.102192: \n",
      "epoch:  62\n",
      "2021-11-01 05:58:52.068891: train loss : -0.8549\n",
      "2021-11-01 05:59:09.846084: validation loss: -0.8507\n",
      "2021-11-01 05:59:09.849970: Average global foreground Dice: [0.8622]\n",
      "2021-11-01 05:59:09.857682: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 05:59:10.338845: lr: 0.004087\n",
      "2021-11-01 05:59:10.422620: saving checkpoint...\n",
      "2021-11-01 05:59:11.561392: done, saving took 1.20 seconds\n",
      "2021-11-01 05:59:12.268664: This epoch took 297.156325 s\n",
      "\n",
      "2021-11-01 05:59:12.277828: \n",
      "epoch:  63\n",
      "2021-11-01 06:03:48.952999: train loss : -0.8555\n",
      "2021-11-01 06:04:06.677782: validation loss: -0.8549\n",
      "2021-11-01 06:04:06.681793: Average global foreground Dice: [0.8652]\n",
      "2021-11-01 06:04:06.688634: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 06:04:07.168212: lr: 0.003987\n",
      "2021-11-01 06:04:07.249923: saving checkpoint...\n",
      "2021-11-01 06:04:08.367464: done, saving took 1.18 seconds\n",
      "2021-11-01 06:04:08.980891: This epoch took 296.694966 s\n",
      "\n",
      "2021-11-01 06:04:08.989856: \n",
      "epoch:  64\n",
      "2021-11-01 06:08:45.657911: train loss : -0.8536\n",
      "2021-11-01 06:09:03.483868: validation loss: -0.8543\n",
      "2021-11-01 06:09:03.487778: Average global foreground Dice: [0.8628]\n",
      "2021-11-01 06:09:03.494001: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 06:09:03.975266: lr: 0.003887\n",
      "2021-11-01 06:09:04.051539: saving checkpoint...\n",
      "2021-11-01 06:09:05.235092: done, saving took 1.24 seconds\n",
      "2021-11-01 06:09:05.907343: This epoch took 296.911056 s\n",
      "\n",
      "2021-11-01 06:09:05.918738: \n",
      "epoch:  65\n",
      "2021-11-01 06:13:42.305109: train loss : -0.8507\n",
      "2021-11-01 06:13:59.723708: validation loss: -0.8533\n",
      "2021-11-01 06:13:59.729690: Average global foreground Dice: [0.8622]\n",
      "2021-11-01 06:13:59.735994: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 06:14:00.203987: lr: 0.003787\n",
      "2021-11-01 06:14:00.250398: saving checkpoint...\n",
      "2021-11-01 06:14:01.354840: done, saving took 1.13 seconds\n",
      "2021-11-01 06:14:01.996327: This epoch took 296.070052 s\n",
      "\n",
      "2021-11-01 06:14:02.004909: \n",
      "epoch:  66\n",
      "2021-11-01 06:18:40.325232: train loss : -0.8593\n",
      "2021-11-01 06:18:57.772624: validation loss: -0.8583\n",
      "2021-11-01 06:18:57.778257: Average global foreground Dice: [0.8706]\n",
      "2021-11-01 06:18:57.786160: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 06:18:58.262137: lr: 0.003687\n",
      "2021-11-01 06:18:58.309752: saving checkpoint...\n",
      "2021-11-01 06:18:59.423075: done, saving took 1.14 seconds\n",
      "2021-11-01 06:19:00.028720: This epoch took 298.015792 s\n",
      "\n",
      "2021-11-01 06:19:00.037542: \n",
      "epoch:  67\n",
      "2021-11-01 06:23:38.280446: train loss : -0.8556\n",
      "2021-11-01 06:23:55.749974: validation loss: -0.8462\n",
      "2021-11-01 06:23:55.753220: Average global foreground Dice: [0.8584]\n",
      "2021-11-01 06:23:55.759636: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 06:23:56.224561: lr: 0.003586\n",
      "2021-11-01 06:23:56.245054: This epoch took 296.199957 s\n",
      "\n",
      "2021-11-01 06:23:56.252009: \n",
      "epoch:  68\n",
      "2021-11-01 06:28:34.545774: train loss : -0.8556\n",
      "2021-11-01 06:28:52.024370: validation loss: -0.8450\n",
      "2021-11-01 06:28:52.028047: Average global foreground Dice: [0.8539]\n",
      "2021-11-01 06:28:52.034984: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 06:28:52.509223: lr: 0.003485\n",
      "2021-11-01 06:28:52.527353: This epoch took 296.267504 s\n",
      "\n",
      "2021-11-01 06:28:52.534573: \n",
      "epoch:  69\n",
      "2021-11-01 06:33:30.887803: train loss : -0.8575\n",
      "2021-11-01 06:33:48.387008: validation loss: -0.8434\n",
      "2021-11-01 06:33:48.391514: Average global foreground Dice: [0.8562]\n",
      "2021-11-01 06:33:48.397636: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 06:33:48.867212: lr: 0.003384\n",
      "2021-11-01 06:33:48.899287: This epoch took 296.357996 s\n",
      "\n",
      "2021-11-01 06:33:48.907247: \n",
      "epoch:  70\n",
      "2021-11-01 06:38:26.914560: train loss : -0.8602\n",
      "2021-11-01 06:38:44.404711: validation loss: -0.8472\n",
      "2021-11-01 06:38:44.408294: Average global foreground Dice: [0.8563]\n",
      "2021-11-01 06:38:44.415255: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 06:38:44.894146: lr: 0.003282\n",
      "2021-11-01 06:38:44.930480: This epoch took 296.015946 s\n",
      "\n",
      "2021-11-01 06:38:44.939860: \n",
      "epoch:  71\n",
      "2021-11-01 06:43:23.311621: train loss : -0.8576\n",
      "2021-11-01 06:43:40.756169: validation loss: -0.8495\n",
      "2021-11-01 06:43:40.759702: Average global foreground Dice: [0.8608]\n",
      "2021-11-01 06:43:40.766471: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 06:43:41.235241: lr: 0.00318\n",
      "2021-11-01 06:43:41.252188: This epoch took 296.302456 s\n",
      "\n",
      "2021-11-01 06:43:41.259520: \n",
      "epoch:  72\n",
      "2021-11-01 06:48:19.459240: train loss : -0.8602\n",
      "2021-11-01 06:48:37.033080: validation loss: -0.8431\n",
      "2021-11-01 06:48:37.037048: Average global foreground Dice: [0.8494]\n",
      "2021-11-01 06:48:37.043671: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 06:48:37.517066: lr: 0.003078\n",
      "2021-11-01 06:48:37.536595: This epoch took 296.269874 s\n",
      "\n",
      "2021-11-01 06:48:37.544791: \n",
      "epoch:  73\n",
      "2021-11-01 06:53:15.913276: train loss : -0.8571\n",
      "2021-11-01 06:53:33.354685: validation loss: -0.8535\n",
      "2021-11-01 06:53:33.359286: Average global foreground Dice: [0.862]\n",
      "2021-11-01 06:53:33.366273: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 06:53:33.839482: lr: 0.002975\n",
      "2021-11-01 06:53:33.857504: This epoch took 296.305838 s\n",
      "\n",
      "2021-11-01 06:53:33.864491: \n",
      "epoch:  74\n",
      "2021-11-01 06:58:12.847476: train loss : -0.8512\n",
      "2021-11-01 06:58:30.372565: validation loss: -0.8500\n",
      "2021-11-01 06:58:30.375981: Average global foreground Dice: [0.8586]\n",
      "2021-11-01 06:58:30.382818: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 06:58:30.851829: lr: 0.002872\n",
      "2021-11-01 06:58:30.877275: This epoch took 297.005459 s\n",
      "\n",
      "2021-11-01 06:58:30.885609: \n",
      "epoch:  75\n",
      "2021-11-01 07:03:09.771191: train loss : -0.8626\n",
      "2021-11-01 07:03:27.227948: validation loss: -0.8532\n",
      "2021-11-01 07:03:27.232304: Average global foreground Dice: [0.8615]\n",
      "2021-11-01 07:03:27.239500: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 07:03:27.714301: lr: 0.002768\n",
      "2021-11-01 07:03:27.732960: This epoch took 296.839257 s\n",
      "\n",
      "2021-11-01 07:03:27.739231: \n",
      "epoch:  76\n",
      "2021-11-01 07:08:06.793270: train loss : -0.8620\n",
      "2021-11-01 07:08:24.507055: validation loss: -0.8451\n",
      "2021-11-01 07:08:24.510654: Average global foreground Dice: [0.8565]\n",
      "2021-11-01 07:08:24.517192: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 07:08:25.054632: lr: 0.002664\n",
      "2021-11-01 07:08:25.071432: This epoch took 297.324993 s\n",
      "\n",
      "2021-11-01 07:08:25.078017: \n",
      "epoch:  77\n",
      "2021-11-01 07:13:04.333245: train loss : -0.8583\n",
      "2021-11-01 07:13:22.050984: validation loss: -0.8543\n",
      "2021-11-01 07:13:22.055266: Average global foreground Dice: [0.8628]\n",
      "2021-11-01 07:13:22.061950: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 07:13:22.555471: lr: 0.00256\n",
      "2021-11-01 07:13:22.577291: This epoch took 297.492835 s\n",
      "\n",
      "2021-11-01 07:13:22.586570: \n",
      "epoch:  78\n",
      "2021-11-01 07:18:01.029718: train loss : -0.8635\n",
      "2021-11-01 07:18:18.770300: validation loss: -0.8497\n",
      "2021-11-01 07:18:18.774643: Average global foreground Dice: [0.8594]\n",
      "2021-11-01 07:18:18.781403: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 07:18:19.271770: lr: 0.002455\n",
      "2021-11-01 07:18:19.294775: This epoch took 296.701274 s\n",
      "\n",
      "2021-11-01 07:18:19.304595: \n",
      "epoch:  79\n",
      "2021-11-01 07:22:58.479624: train loss : -0.8631\n",
      "2021-11-01 07:23:16.193920: validation loss: -0.8504\n",
      "2021-11-01 07:23:16.197504: Average global foreground Dice: [0.8601]\n",
      "2021-11-01 07:23:16.203980: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 07:23:16.692596: lr: 0.002349\n",
      "2021-11-01 07:23:16.711444: This epoch took 297.399838 s\n",
      "\n",
      "2021-11-01 07:23:16.718083: \n",
      "epoch:  80\n",
      "2021-11-01 07:27:55.071203: train loss : -0.8626\n",
      "2021-11-01 07:28:12.865157: validation loss: -0.8468\n",
      "2021-11-01 07:28:12.868448: Average global foreground Dice: [0.8553]\n",
      "2021-11-01 07:28:12.875035: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 07:28:13.365689: lr: 0.002243\n",
      "2021-11-01 07:28:13.387260: This epoch took 296.662784 s\n",
      "\n",
      "2021-11-01 07:28:13.394728: \n",
      "epoch:  81\n",
      "2021-11-01 07:32:52.172859: train loss : -0.8607\n",
      "2021-11-01 07:33:09.813667: validation loss: -0.8467\n",
      "2021-11-01 07:33:09.817257: Average global foreground Dice: [0.8553]\n",
      "2021-11-01 07:33:09.823142: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 07:33:10.307827: lr: 0.002137\n",
      "2021-11-01 07:33:10.325625: This epoch took 296.923390 s\n",
      "\n",
      "2021-11-01 07:33:10.333442: \n",
      "epoch:  82\n",
      "2021-11-01 07:37:48.605188: train loss : -0.8662\n",
      "2021-11-01 07:38:06.042612: validation loss: -0.8477\n",
      "2021-11-01 07:38:06.048983: Average global foreground Dice: [0.8547]\n",
      "2021-11-01 07:38:06.056285: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 07:38:06.536066: lr: 0.00203\n",
      "2021-11-01 07:38:06.555480: This epoch took 296.215913 s\n",
      "\n",
      "2021-11-01 07:38:06.561825: \n",
      "epoch:  83\n",
      "2021-11-01 07:42:44.682292: train loss : -0.8622\n",
      "2021-11-01 07:43:02.102000: validation loss: -0.8481\n",
      "2021-11-01 07:43:02.106007: Average global foreground Dice: [0.8576]\n",
      "2021-11-01 07:43:02.113008: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 07:43:02.630979: lr: 0.001922\n",
      "2021-11-01 07:43:02.648963: This epoch took 296.080217 s\n",
      "\n",
      "2021-11-01 07:43:02.655977: \n",
      "epoch:  84\n",
      "2021-11-01 07:47:40.864634: train loss : -0.8651\n",
      "2021-11-01 07:47:58.738060: validation loss: -0.8428\n",
      "2021-11-01 07:47:58.741936: Average global foreground Dice: [0.8502]\n",
      "2021-11-01 07:47:58.748830: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 07:47:59.270317: lr: 0.001813\n",
      "2021-11-01 07:47:59.292312: This epoch took 296.629991 s\n",
      "\n",
      "2021-11-01 07:47:59.300584: \n",
      "epoch:  85\n",
      "2021-11-01 07:52:37.578669: train loss : -0.8671\n",
      "2021-11-01 07:52:55.316530: validation loss: -0.8482\n",
      "2021-11-01 07:52:55.319752: Average global foreground Dice: [0.8585]\n",
      "2021-11-01 07:52:55.326275: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 07:52:55.815517: lr: 0.001704\n",
      "2021-11-01 07:52:55.834475: This epoch took 296.525775 s\n",
      "\n",
      "2021-11-01 07:52:55.841159: \n",
      "epoch:  86\n",
      "2021-11-01 07:57:34.764592: train loss : -0.8660\n",
      "2021-11-01 07:57:52.490437: validation loss: -0.8453\n",
      "2021-11-01 07:57:52.494965: Average global foreground Dice: [0.8543]\n",
      "2021-11-01 07:57:52.502261: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 07:57:52.990360: lr: 0.001594\n",
      "2021-11-01 07:57:53.008085: This epoch took 297.160670 s\n",
      "\n",
      "2021-11-01 07:57:53.015779: \n",
      "epoch:  87\n",
      "2021-11-01 08:02:32.142353: train loss : -0.8662\n",
      "2021-11-01 08:02:49.925916: validation loss: -0.8515\n",
      "2021-11-01 08:02:49.929424: Average global foreground Dice: [0.86]\n",
      "2021-11-01 08:02:49.935922: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 08:02:50.424269: lr: 0.001483\n",
      "2021-11-01 08:02:50.443737: This epoch took 297.420034 s\n",
      "\n",
      "2021-11-01 08:02:50.451097: \n",
      "epoch:  88\n",
      "2021-11-01 08:07:28.510904: train loss : -0.8666\n",
      "2021-11-01 08:07:46.468169: validation loss: -0.8412\n",
      "2021-11-01 08:07:46.471668: Average global foreground Dice: [0.8487]\n",
      "2021-11-01 08:07:46.477974: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 08:07:46.962948: lr: 0.001372\n",
      "2021-11-01 08:07:46.981000: This epoch took 296.522941 s\n",
      "\n",
      "2021-11-01 08:07:46.988887: \n",
      "epoch:  89\n",
      "2021-11-01 08:12:25.459453: train loss : -0.8653\n",
      "2021-11-01 08:12:43.191000: validation loss: -0.8537\n",
      "2021-11-01 08:12:43.195356: Average global foreground Dice: [0.8616]\n",
      "2021-11-01 08:12:43.202158: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 08:12:43.687759: lr: 0.001259\n",
      "2021-11-01 08:12:43.706172: This epoch took 296.710470 s\n",
      "\n",
      "2021-11-01 08:12:43.712696: \n",
      "epoch:  90\n",
      "2021-11-01 08:17:21.785286: train loss : -0.8710\n",
      "2021-11-01 08:17:39.531208: validation loss: -0.8505\n",
      "2021-11-01 08:17:39.535487: Average global foreground Dice: [0.8582]\n",
      "2021-11-01 08:17:39.543029: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 08:17:40.031841: lr: 0.001145\n",
      "2021-11-01 08:17:40.052123: This epoch took 296.333025 s\n",
      "\n",
      "2021-11-01 08:17:40.059244: \n",
      "epoch:  91\n",
      "2021-11-01 08:22:17.099086: train loss : -0.8691\n",
      "2021-11-01 08:22:34.824418: validation loss: -0.8483\n",
      "2021-11-01 08:22:34.828171: Average global foreground Dice: [0.8569]\n",
      "2021-11-01 08:22:34.835374: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 08:22:35.323961: lr: 0.00103\n",
      "2021-11-01 08:22:35.342002: This epoch took 295.276289 s\n",
      "\n",
      "2021-11-01 08:22:35.348831: \n",
      "epoch:  92\n",
      "2021-11-01 08:27:11.638622: train loss : -0.8684\n",
      "2021-11-01 08:27:29.087029: validation loss: -0.8511\n",
      "2021-11-01 08:27:29.090909: Average global foreground Dice: [0.8576]\n",
      "2021-11-01 08:27:29.097797: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 08:27:29.573375: lr: 0.000913\n",
      "2021-11-01 08:27:29.591642: This epoch took 294.235386 s\n",
      "\n",
      "2021-11-01 08:27:29.597968: \n",
      "epoch:  93\n",
      "2021-11-01 08:32:06.770833: train loss : -0.8698\n",
      "2021-11-01 08:32:24.506380: validation loss: -0.8522\n",
      "2021-11-01 08:32:24.510071: Average global foreground Dice: [0.8608]\n",
      "2021-11-01 08:32:24.516335: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 08:32:24.995816: lr: 0.000795\n",
      "2021-11-01 08:32:25.013689: This epoch took 295.408343 s\n",
      "\n",
      "2021-11-01 08:32:25.019728: \n",
      "epoch:  94\n",
      "2021-11-01 08:37:01.730232: train loss : -0.8706\n",
      "2021-11-01 08:37:19.198468: validation loss: -0.8443\n",
      "2021-11-01 08:37:19.202502: Average global foreground Dice: [0.8505]\n",
      "2021-11-01 08:37:19.209614: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 08:37:19.685634: lr: 0.000675\n",
      "2021-11-01 08:37:19.705400: This epoch took 294.679326 s\n",
      "\n",
      "2021-11-01 08:37:19.713671: \n",
      "epoch:  95\n",
      "2021-11-01 08:41:56.295427: train loss : -0.8698\n",
      "2021-11-01 08:42:14.029364: validation loss: -0.8519\n",
      "2021-11-01 08:42:14.032856: Average global foreground Dice: [0.8614]\n",
      "2021-11-01 08:42:14.039143: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 08:42:14.525443: lr: 0.000552\n",
      "2021-11-01 08:42:14.543926: This epoch took 294.822964 s\n",
      "\n",
      "2021-11-01 08:42:14.551316: \n",
      "epoch:  96\n",
      "2021-11-01 08:46:51.459854: train loss : -0.8681\n",
      "2021-11-01 08:47:09.179321: validation loss: -0.8493\n",
      "2021-11-01 08:47:09.185194: Average global foreground Dice: [0.8573]\n",
      "2021-11-01 08:47:09.191961: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 08:47:09.674745: lr: 0.000426\n",
      "2021-11-01 08:47:09.693004: This epoch took 295.134314 s\n",
      "\n",
      "2021-11-01 08:47:09.700940: \n",
      "epoch:  97\n",
      "2021-11-01 08:51:45.913378: train loss : -0.8743\n",
      "2021-11-01 08:52:03.610515: validation loss: -0.8433\n",
      "2021-11-01 08:52:03.614795: Average global foreground Dice: [0.8494]\n",
      "2021-11-01 08:52:03.621684: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 08:52:04.104640: lr: 0.000296\n",
      "2021-11-01 08:52:04.123791: This epoch took 294.415231 s\n",
      "\n",
      "2021-11-01 08:52:04.130642: \n",
      "epoch:  98\n",
      "2021-11-01 08:56:38.744242: train loss : -0.8710\n",
      "2021-11-01 08:56:56.363662: validation loss: -0.8498\n",
      "2021-11-01 08:56:56.367844: Average global foreground Dice: [0.8562]\n",
      "2021-11-01 08:56:56.375015: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 08:56:56.862164: lr: 0.000158\n",
      "2021-11-01 08:56:56.880988: This epoch took 292.743168 s\n",
      "\n",
      "2021-11-01 08:56:56.888265: \n",
      "epoch:  99\n",
      "2021-11-01 09:01:30.258276: train loss : -0.8759\n",
      "2021-11-01 09:01:47.715891: validation loss: -0.8490\n",
      "2021-11-01 09:01:47.719625: Average global foreground Dice: [0.8569]\n",
      "2021-11-01 09:01:47.726125: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 09:01:48.214341: lr: 0.0\n",
      "2021-11-01 09:01:48.231465: saving scheduled checkpoint file...\n",
      "2021-11-01 09:01:48.311045: saving checkpoint...\n",
      "2021-11-01 09:01:49.592567: done, saving took 1.35 seconds\n",
      "2021-11-01 09:01:50.203417: done\n",
      "2021-11-01 09:01:50.211507: This epoch took 293.315365 s\n",
      "\n",
      "2021-11-01 09:01:50.247553: saving checkpoint...\n",
      "2021-11-01 09:01:51.192211: done, saving took 0.97 seconds\n",
      "23090559_20150812 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120330 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090563_20151216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130226 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090584_20120523 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090589_20140219 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090592_20130218 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090614_20120402 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090620_20130617 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090627_20160608 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090628_20150204 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090635_20140710 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090640_20140711 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121227 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-01 09:05:10.017802: finished prediction\n",
      "2021-11-01 09:05:10.032405: evaluation of raw predictions\n",
      "2021-11-01 09:05:11.975411: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8630305695766627\n",
      "after:  0.8630305695766627\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-01 09:05:23.954549: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-01 09:05:23.976821: The split file contains 5 splits.\n",
      "2021-11-01 09:05:23.984942: Desired fold for training: 1\n",
      "2021-11-01 09:05:23.991136: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-01 09:05:28.275227: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-01 09:05:35.869485: Unable to plot network architecture:\n",
      "2021-11-01 09:05:35.939168: No module named 'hiddenlayer'\n",
      "2021-11-01 09:05:35.949151: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-01 09:05:35.955563: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-01 09:05:36.040138: \n",
      "\n",
      "2021-11-01 09:05:36.046457: \n",
      "epoch:  0\n",
      "2021-11-01 09:10:36.692339: train loss : -0.1611\n",
      "2021-11-01 09:10:54.256218: validation loss: -0.5446\n",
      "2021-11-01 09:10:54.260968: Average global foreground Dice: [0.6308]\n",
      "2021-11-01 09:10:54.268197: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 09:10:54.685657: lr: 0.00991\n",
      "2021-11-01 09:10:54.703638: This epoch took 318.650942 s\n",
      "\n",
      "2021-11-01 09:10:54.710282: \n",
      "epoch:  1\n",
      "2021-11-01 09:15:27.379889: train loss : -0.5999\n",
      "2021-11-01 09:15:44.934774: validation loss: -0.6791\n",
      "2021-11-01 09:15:44.938617: Average global foreground Dice: [0.708]\n",
      "2021-11-01 09:15:44.946171: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 09:15:45.433997: lr: 0.00982\n",
      "2021-11-01 09:15:45.527624: saving checkpoint...\n",
      "2021-11-01 09:15:46.486715: done, saving took 1.04 seconds\n",
      "2021-11-01 09:15:47.139196: This epoch took 292.421027 s\n",
      "\n",
      "2021-11-01 09:15:47.147992: \n",
      "epoch:  2\n",
      "2021-11-01 09:20:19.212428: train loss : -0.6683\n",
      "2021-11-01 09:20:36.756379: validation loss: -0.7410\n",
      "2021-11-01 09:20:36.760399: Average global foreground Dice: [0.7766]\n",
      "2021-11-01 09:20:36.767013: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 09:20:37.261722: lr: 0.00973\n",
      "2021-11-01 09:20:37.355773: saving checkpoint...\n",
      "2021-11-01 09:20:38.594304: done, saving took 1.32 seconds\n",
      "2021-11-01 09:20:39.211133: This epoch took 292.055694 s\n",
      "\n",
      "2021-11-01 09:20:39.218779: \n",
      "epoch:  3\n",
      "2021-11-01 09:25:10.932369: train loss : -0.7101\n",
      "2021-11-01 09:25:28.462859: validation loss: -0.7794\n",
      "2021-11-01 09:25:28.466646: Average global foreground Dice: [0.8158]\n",
      "2021-11-01 09:25:28.473590: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 09:25:28.973421: lr: 0.009639\n",
      "2021-11-01 09:25:29.069177: saving checkpoint...\n",
      "2021-11-01 09:25:30.376464: done, saving took 1.39 seconds\n",
      "2021-11-01 09:25:31.113741: This epoch took 291.889334 s\n",
      "\n",
      "2021-11-01 09:25:31.121685: \n",
      "epoch:  4\n",
      "2021-11-01 09:30:02.622277: train loss : -0.7354\n",
      "2021-11-01 09:30:20.156210: validation loss: -0.7838\n",
      "2021-11-01 09:30:20.160631: Average global foreground Dice: [0.8198]\n",
      "2021-11-01 09:30:20.166861: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 09:30:20.663105: lr: 0.009549\n",
      "2021-11-01 09:30:20.757647: saving checkpoint...\n",
      "2021-11-01 09:30:22.007354: done, saving took 1.33 seconds\n",
      "2021-11-01 09:30:22.713865: This epoch took 291.585121 s\n",
      "\n",
      "2021-11-01 09:30:22.722284: \n",
      "epoch:  5\n",
      "2021-11-01 09:34:54.405284: train loss : -0.7617\n",
      "2021-11-01 09:35:11.905785: validation loss: -0.7968\n",
      "2021-11-01 09:35:11.909438: Average global foreground Dice: [0.8189]\n",
      "2021-11-01 09:35:11.915166: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 09:35:12.464241: lr: 0.009458\n",
      "2021-11-01 09:35:12.559846: saving checkpoint...\n",
      "2021-11-01 09:35:13.810626: done, saving took 1.33 seconds\n",
      "2021-11-01 09:35:14.422719: This epoch took 291.693769 s\n",
      "\n",
      "2021-11-01 09:35:14.430705: \n",
      "epoch:  6\n",
      "2021-11-01 09:39:45.836192: train loss : -0.7693\n",
      "2021-11-01 09:40:03.311254: validation loss: -0.7970\n",
      "2021-11-01 09:40:03.315513: Average global foreground Dice: [0.8252]\n",
      "2021-11-01 09:40:03.321833: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 09:40:03.813617: lr: 0.009368\n",
      "2021-11-01 09:40:03.905270: saving checkpoint...\n",
      "2021-11-01 09:40:05.135013: done, saving took 1.30 seconds\n",
      "2021-11-01 09:40:05.763848: This epoch took 291.325185 s\n",
      "\n",
      "2021-11-01 09:40:05.771963: \n",
      "epoch:  7\n",
      "2021-11-01 09:44:36.490169: train loss : -0.7801\n",
      "2021-11-01 09:44:54.001350: validation loss: -0.8010\n",
      "2021-11-01 09:44:54.005163: Average global foreground Dice: [0.8264]\n",
      "2021-11-01 09:44:54.010726: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 09:44:54.508071: lr: 0.009277\n",
      "2021-11-01 09:44:54.600468: saving checkpoint...\n",
      "2021-11-01 09:44:55.830106: done, saving took 1.30 seconds\n",
      "2021-11-01 09:44:56.435427: This epoch took 290.655834 s\n",
      "\n",
      "2021-11-01 09:44:56.443603: \n",
      "epoch:  8\n",
      "2021-11-01 09:49:28.271175: train loss : -0.7782\n",
      "2021-11-01 09:49:45.749215: validation loss: -0.8102\n",
      "2021-11-01 09:49:45.753015: Average global foreground Dice: [0.83]\n",
      "2021-11-01 09:49:45.759778: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 09:49:46.249630: lr: 0.009186\n",
      "2021-11-01 09:49:46.341917: saving checkpoint...\n",
      "2021-11-01 09:49:47.581441: done, saving took 1.32 seconds\n",
      "2021-11-01 09:49:48.159748: This epoch took 291.708265 s\n",
      "\n",
      "2021-11-01 09:49:48.168648: \n",
      "epoch:  9\n",
      "2021-11-01 09:54:19.779493: train loss : -0.7879\n",
      "2021-11-01 09:54:37.316024: validation loss: -0.8149\n",
      "2021-11-01 09:54:37.319454: Average global foreground Dice: [0.8322]\n",
      "2021-11-01 09:54:37.325851: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 09:54:37.818614: lr: 0.009095\n",
      "2021-11-01 09:54:37.903348: saving checkpoint...\n",
      "2021-11-01 09:54:39.207573: done, saving took 1.37 seconds\n",
      "2021-11-01 09:54:39.811132: This epoch took 291.634925 s\n",
      "\n",
      "2021-11-01 09:54:39.819409: \n",
      "epoch:  10\n",
      "2021-11-01 09:59:10.492560: train loss : -0.7979\n",
      "2021-11-01 09:59:27.800126: validation loss: -0.8071\n",
      "2021-11-01 09:59:27.804217: Average global foreground Dice: [0.8251]\n",
      "2021-11-01 09:59:27.810849: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 09:59:28.287682: lr: 0.009004\n",
      "2021-11-01 09:59:28.332481: saving checkpoint...\n",
      "2021-11-01 09:59:29.562084: done, saving took 1.26 seconds\n",
      "2021-11-01 09:59:30.236747: This epoch took 290.409557 s\n",
      "\n",
      "2021-11-01 09:59:30.245520: \n",
      "epoch:  11\n",
      "2021-11-01 10:04:00.586566: train loss : -0.8024\n",
      "2021-11-01 10:04:17.875859: validation loss: -0.8041\n",
      "2021-11-01 10:04:17.879207: Average global foreground Dice: [0.8208]\n",
      "2021-11-01 10:04:17.885830: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 10:04:18.360167: lr: 0.008913\n",
      "2021-11-01 10:04:18.408147: saving checkpoint...\n",
      "2021-11-01 10:04:19.632419: done, saving took 1.25 seconds\n",
      "2021-11-01 10:04:20.257267: This epoch took 290.004580 s\n",
      "\n",
      "2021-11-01 10:04:20.265852: \n",
      "epoch:  12\n",
      "2021-11-01 10:08:50.194930: train loss : -0.8019\n",
      "2021-11-01 10:09:07.409023: validation loss: -0.8151\n",
      "2021-11-01 10:09:07.413077: Average global foreground Dice: [0.8306]\n",
      "2021-11-01 10:09:07.419425: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 10:09:07.896616: lr: 0.008822\n",
      "2021-11-01 10:09:07.941091: saving checkpoint...\n",
      "2021-11-01 10:09:09.179101: done, saving took 1.27 seconds\n",
      "2021-11-01 10:09:09.813714: This epoch took 289.540031 s\n",
      "\n",
      "2021-11-01 10:09:09.822401: \n",
      "epoch:  13\n",
      "2021-11-01 10:13:40.989689: train loss : -0.8072\n",
      "2021-11-01 10:13:58.278703: validation loss: -0.8113\n",
      "2021-11-01 10:13:58.282371: Average global foreground Dice: [0.8277]\n",
      "2021-11-01 10:13:58.289016: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 10:13:58.766527: lr: 0.008731\n",
      "2021-11-01 10:13:58.811315: saving checkpoint...\n",
      "2021-11-01 10:14:00.047536: done, saving took 1.27 seconds\n",
      "2021-11-01 10:14:00.669372: This epoch took 290.840214 s\n",
      "\n",
      "2021-11-01 10:14:00.678035: \n",
      "epoch:  14\n",
      "2021-11-01 10:18:31.561424: train loss : -0.8145\n",
      "2021-11-01 10:18:48.804912: validation loss: -0.8223\n",
      "2021-11-01 10:18:48.808882: Average global foreground Dice: [0.835]\n",
      "2021-11-01 10:18:48.815857: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 10:18:49.297484: lr: 0.008639\n",
      "2021-11-01 10:18:49.341544: saving checkpoint...\n",
      "2021-11-01 10:18:50.582440: done, saving took 1.27 seconds\n",
      "2021-11-01 10:18:51.174265: This epoch took 290.488639 s\n",
      "\n",
      "2021-11-01 10:18:51.183441: \n",
      "epoch:  15\n",
      "2021-11-01 10:23:22.188220: train loss : -0.8163\n",
      "2021-11-01 10:23:39.508617: validation loss: -0.8131\n",
      "2021-11-01 10:23:39.512262: Average global foreground Dice: [0.8266]\n",
      "2021-11-01 10:23:39.518307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 10:23:40.065874: lr: 0.008548\n",
      "2021-11-01 10:23:40.111428: saving checkpoint...\n",
      "2021-11-01 10:23:41.340556: done, saving took 1.26 seconds\n",
      "2021-11-01 10:23:41.980087: This epoch took 290.789183 s\n",
      "\n",
      "2021-11-01 10:23:41.987810: \n",
      "epoch:  16\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-01 10:28:12.796419: train loss : -0.8149\n",
      "2021-11-01 10:28:30.049619: validation loss: -0.8277\n",
      "2021-11-01 10:28:30.053548: Average global foreground Dice: [0.8434]\n",
      "2021-11-01 10:28:30.060785: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 10:28:30.533378: lr: 0.008456\n",
      "2021-11-01 10:28:30.580163: saving checkpoint...\n",
      "2021-11-01 10:28:31.813504: done, saving took 1.26 seconds\n",
      "2021-11-01 10:28:32.436875: This epoch took 290.441453 s\n",
      "\n",
      "2021-11-01 10:28:32.445360: \n",
      "epoch:  17\n",
      "2021-11-01 10:33:02.535046: train loss : -0.8194\n",
      "2021-11-01 10:33:19.774014: validation loss: -0.8269\n",
      "2021-11-01 10:33:19.778040: Average global foreground Dice: [0.8427]\n",
      "2021-11-01 10:33:19.785106: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 10:33:20.259212: lr: 0.008364\n",
      "2021-11-01 10:33:20.303412: saving checkpoint...\n",
      "2021-11-01 10:33:21.548258: done, saving took 1.27 seconds\n",
      "2021-11-01 10:33:22.171253: This epoch took 289.718714 s\n",
      "\n",
      "2021-11-01 10:33:22.179695: \n",
      "epoch:  18\n",
      "2021-11-01 10:37:51.382722: train loss : -0.8184\n",
      "2021-11-01 10:38:08.867178: validation loss: -0.8223\n",
      "2021-11-01 10:38:08.870676: Average global foreground Dice: [0.8346]\n",
      "2021-11-01 10:38:08.877661: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 10:38:09.346181: lr: 0.008272\n",
      "2021-11-01 10:38:09.392617: saving checkpoint...\n",
      "2021-11-01 10:38:10.628430: done, saving took 1.26 seconds\n",
      "2021-11-01 10:38:11.222353: This epoch took 289.035142 s\n",
      "\n",
      "2021-11-01 10:38:11.231436: \n",
      "epoch:  19\n",
      "2021-11-01 10:42:40.309074: train loss : -0.8260\n",
      "2021-11-01 10:42:57.523925: validation loss: -0.8285\n",
      "2021-11-01 10:42:57.527444: Average global foreground Dice: [0.8448]\n",
      "2021-11-01 10:42:57.533771: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 10:42:58.008800: lr: 0.008181\n",
      "2021-11-01 10:42:58.054864: saving checkpoint...\n",
      "2021-11-01 10:42:59.330551: done, saving took 1.30 seconds\n",
      "2021-11-01 10:42:59.928365: This epoch took 288.689901 s\n",
      "\n",
      "2021-11-01 10:42:59.936523: \n",
      "epoch:  20\n",
      "2021-11-01 10:47:28.975127: train loss : -0.8240\n",
      "2021-11-01 10:47:46.213418: validation loss: -0.8262\n",
      "2021-11-01 10:47:46.217424: Average global foreground Dice: [0.8415]\n",
      "2021-11-01 10:47:46.223473: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 10:47:46.697847: lr: 0.008088\n",
      "2021-11-01 10:47:46.744793: saving checkpoint...\n",
      "2021-11-01 10:47:47.965563: done, saving took 1.25 seconds\n",
      "2021-11-01 10:47:48.572935: This epoch took 288.629714 s\n",
      "\n",
      "2021-11-01 10:47:48.581590: \n",
      "epoch:  21\n",
      "2021-11-01 10:52:17.794936: train loss : -0.8236\n",
      "2021-11-01 10:52:35.217906: validation loss: -0.8153\n",
      "2021-11-01 10:52:35.221892: Average global foreground Dice: [0.8287]\n",
      "2021-11-01 10:52:35.229117: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 10:52:35.711295: lr: 0.007996\n",
      "2021-11-01 10:52:35.780370: saving checkpoint...\n",
      "2021-11-01 10:52:37.068934: done, saving took 1.34 seconds\n",
      "2021-11-01 10:52:37.728554: This epoch took 289.139394 s\n",
      "\n",
      "2021-11-01 10:52:37.737349: \n",
      "epoch:  22\n",
      "2021-11-01 10:57:05.774487: train loss : -0.8234\n",
      "2021-11-01 10:57:22.994615: validation loss: -0.8310\n",
      "2021-11-01 10:57:22.998302: Average global foreground Dice: [0.8434]\n",
      "2021-11-01 10:57:23.005116: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 10:57:23.470844: lr: 0.007904\n",
      "2021-11-01 10:57:23.517823: saving checkpoint...\n",
      "2021-11-01 10:57:24.743857: done, saving took 1.25 seconds\n",
      "2021-11-01 10:57:25.347264: This epoch took 287.602231 s\n",
      "\n",
      "2021-11-01 10:57:25.355586: \n",
      "epoch:  23\n",
      "2021-11-01 11:01:53.665077: train loss : -0.8248\n",
      "2021-11-01 11:02:10.899822: validation loss: -0.8252\n",
      "2021-11-01 11:02:10.904001: Average global foreground Dice: [0.8415]\n",
      "2021-11-01 11:02:10.911016: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 11:02:11.374373: lr: 0.007811\n",
      "2021-11-01 11:02:11.420956: saving checkpoint...\n",
      "2021-11-01 11:02:12.639576: done, saving took 1.25 seconds\n",
      "2021-11-01 11:02:13.269025: This epoch took 287.905627 s\n",
      "\n",
      "2021-11-01 11:02:13.277396: \n",
      "epoch:  24\n",
      "2021-11-01 11:06:41.873452: train loss : -0.8264\n",
      "2021-11-01 11:06:59.145337: validation loss: -0.8205\n",
      "2021-11-01 11:06:59.151870: Average global foreground Dice: [0.834]\n",
      "2021-11-01 11:06:59.159101: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 11:06:59.628375: lr: 0.007719\n",
      "2021-11-01 11:06:59.675886: saving checkpoint...\n",
      "2021-11-01 11:07:00.919710: done, saving took 1.27 seconds\n",
      "2021-11-01 11:07:01.615950: This epoch took 288.331104 s\n",
      "\n",
      "2021-11-01 11:07:01.624544: \n",
      "epoch:  25\n",
      "2021-11-01 11:11:29.863641: train loss : -0.8310\n",
      "2021-11-01 11:11:47.104465: validation loss: -0.8270\n",
      "2021-11-01 11:11:47.107971: Average global foreground Dice: [0.8365]\n",
      "2021-11-01 11:11:47.114488: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 11:11:47.585102: lr: 0.007626\n",
      "2021-11-01 11:11:47.630423: saving checkpoint...\n",
      "2021-11-01 11:11:48.869860: done, saving took 1.27 seconds\n",
      "2021-11-01 11:11:49.489037: This epoch took 287.856502 s\n",
      "\n",
      "2021-11-01 11:11:49.498007: \n",
      "epoch:  26\n",
      "2021-11-01 11:16:16.577631: train loss : -0.8306\n",
      "2021-11-01 11:16:33.909433: validation loss: -0.8153\n",
      "2021-11-01 11:16:33.913175: Average global foreground Dice: [0.8235]\n",
      "2021-11-01 11:16:33.919916: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 11:16:34.387183: lr: 0.007533\n",
      "2021-11-01 11:16:34.431820: saving checkpoint...\n",
      "2021-11-01 11:16:35.681144: done, saving took 1.28 seconds\n",
      "2021-11-01 11:16:36.286929: This epoch took 286.781987 s\n",
      "\n",
      "2021-11-01 11:16:36.295259: \n",
      "epoch:  27\n",
      "2021-11-01 11:21:05.683477: train loss : -0.8283\n",
      "2021-11-01 11:21:22.902664: validation loss: -0.8268\n",
      "2021-11-01 11:21:22.907661: Average global foreground Dice: [0.8418]\n",
      "2021-11-01 11:21:22.914214: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 11:21:23.379720: lr: 0.00744\n",
      "2021-11-01 11:21:23.426556: saving checkpoint...\n",
      "2021-11-01 11:21:24.588922: done, saving took 1.19 seconds\n",
      "2021-11-01 11:21:25.206864: This epoch took 288.904694 s\n",
      "\n",
      "2021-11-01 11:21:25.215116: \n",
      "epoch:  28\n",
      "2021-11-01 11:25:53.366597: train loss : -0.8331\n",
      "2021-11-01 11:26:10.687550: validation loss: -0.8276\n",
      "2021-11-01 11:26:10.691011: Average global foreground Dice: [0.8418]\n",
      "2021-11-01 11:26:10.697845: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 11:26:11.159339: lr: 0.007347\n",
      "2021-11-01 11:26:11.206430: saving checkpoint...\n",
      "2021-11-01 11:26:12.308414: done, saving took 1.13 seconds\n",
      "2021-11-01 11:26:12.977811: This epoch took 287.755724 s\n",
      "\n",
      "2021-11-01 11:26:12.991761: \n",
      "epoch:  29\n",
      "2021-11-01 11:30:42.016178: train loss : -0.8332\n",
      "2021-11-01 11:30:59.228856: validation loss: -0.8292\n",
      "2021-11-01 11:30:59.234000: Average global foreground Dice: [0.8453]\n",
      "2021-11-01 11:30:59.240671: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 11:30:59.707506: lr: 0.007254\n",
      "2021-11-01 11:30:59.755179: saving checkpoint...\n",
      "2021-11-01 11:31:00.844805: done, saving took 1.12 seconds\n",
      "2021-11-01 11:31:01.477506: This epoch took 288.478173 s\n",
      "\n",
      "2021-11-01 11:31:01.486429: \n",
      "epoch:  30\n",
      "2021-11-01 11:35:30.060766: train loss : -0.8349\n",
      "2021-11-01 11:35:47.284261: validation loss: -0.8254\n",
      "2021-11-01 11:35:47.287644: Average global foreground Dice: [0.8346]\n",
      "2021-11-01 11:35:47.293674: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 11:35:47.759718: lr: 0.007161\n",
      "2021-11-01 11:35:47.806000: saving checkpoint...\n",
      "2021-11-01 11:35:48.916330: done, saving took 1.14 seconds\n",
      "2021-11-01 11:35:49.486089: This epoch took 287.992064 s\n",
      "\n",
      "2021-11-01 11:35:49.494025: \n",
      "epoch:  31\n",
      "2021-11-01 11:40:17.837184: train loss : -0.8394\n",
      "2021-11-01 11:40:35.043174: validation loss: -0.8301\n",
      "2021-11-01 11:40:35.046602: Average global foreground Dice: [0.8431]\n",
      "2021-11-01 11:40:35.054140: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 11:40:35.520595: lr: 0.007067\n",
      "2021-11-01 11:40:35.566323: saving checkpoint...\n",
      "2021-11-01 11:40:36.681282: done, saving took 1.14 seconds\n",
      "2021-11-01 11:40:37.262532: This epoch took 287.760974 s\n",
      "\n",
      "2021-11-01 11:40:37.271316: \n",
      "epoch:  32\n",
      "2021-11-01 11:45:05.765576: train loss : -0.8419\n",
      "2021-11-01 11:45:23.056411: validation loss: -0.8293\n",
      "2021-11-01 11:45:23.069647: Average global foreground Dice: [0.8403]\n",
      "2021-11-01 11:45:23.076747: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 11:45:23.542428: lr: 0.006974\n",
      "2021-11-01 11:45:23.592584: saving checkpoint...\n",
      "2021-11-01 11:45:24.685078: done, saving took 1.12 seconds\n",
      "2021-11-01 11:45:25.368618: This epoch took 288.089344 s\n",
      "\n",
      "2021-11-01 11:45:25.377087: \n",
      "epoch:  33\n",
      "2021-11-01 11:49:53.279622: train loss : -0.8305\n",
      "2021-11-01 11:50:10.456179: validation loss: -0.8273\n",
      "2021-11-01 11:50:10.459759: Average global foreground Dice: [0.8431]\n",
      "2021-11-01 11:50:10.465810: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 11:50:10.934353: lr: 0.00688\n",
      "2021-11-01 11:50:10.984826: saving checkpoint...\n",
      "2021-11-01 11:50:12.135658: done, saving took 1.18 seconds\n",
      "2021-11-01 11:50:12.737156: This epoch took 287.352235 s\n",
      "\n",
      "2021-11-01 11:50:12.745670: \n",
      "epoch:  34\n",
      "2021-11-01 11:54:41.161887: train loss : -0.8417\n",
      "2021-11-01 11:54:58.370064: validation loss: -0.8315\n",
      "2021-11-01 11:54:58.373309: Average global foreground Dice: [0.8408]\n",
      "2021-11-01 11:54:58.379813: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 11:54:58.847550: lr: 0.006786\n",
      "2021-11-01 11:54:58.893523: saving checkpoint...\n",
      "2021-11-01 11:54:59.992364: done, saving took 1.13 seconds\n",
      "2021-11-01 11:55:00.580713: This epoch took 287.826963 s\n",
      "\n",
      "2021-11-01 11:55:00.590463: \n",
      "epoch:  35\n",
      "2021-11-01 11:59:29.812864: train loss : -0.8401\n",
      "2021-11-01 11:59:47.012711: validation loss: -0.8330\n",
      "2021-11-01 11:59:47.016847: Average global foreground Dice: [0.8455]\n",
      "2021-11-01 11:59:47.023946: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 11:59:47.496077: lr: 0.006692\n",
      "2021-11-01 11:59:47.541898: saving checkpoint...\n",
      "2021-11-01 11:59:48.640796: done, saving took 1.13 seconds\n",
      "2021-11-01 11:59:49.232386: This epoch took 288.635046 s\n",
      "\n",
      "2021-11-01 11:59:49.240038: \n",
      "epoch:  36\n",
      "2021-11-01 12:04:18.476435: train loss : -0.8372\n",
      "2021-11-01 12:04:35.734359: validation loss: -0.8441\n",
      "2021-11-01 12:04:35.738149: Average global foreground Dice: [0.8549]\n",
      "2021-11-01 12:04:35.744434: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 12:04:36.214999: lr: 0.006598\n",
      "2021-11-01 12:04:36.259937: saving checkpoint...\n",
      "2021-11-01 12:04:37.370263: done, saving took 1.14 seconds\n",
      "2021-11-01 12:04:37.960273: This epoch took 288.713400 s\n",
      "\n",
      "2021-11-01 12:04:37.969499: \n",
      "epoch:  37\n",
      "2021-11-01 12:09:07.950634: train loss : -0.8410\n",
      "2021-11-01 12:09:25.222848: validation loss: -0.8467\n",
      "2021-11-01 12:09:25.226522: Average global foreground Dice: [0.8572]\n",
      "2021-11-01 12:09:25.233478: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 12:09:25.700356: lr: 0.006504\n",
      "2021-11-01 12:09:25.746474: saving checkpoint...\n",
      "2021-11-01 12:09:26.865995: done, saving took 1.15 seconds\n",
      "2021-11-01 12:09:27.454925: This epoch took 289.478714 s\n",
      "\n",
      "2021-11-01 12:09:27.464010: \n",
      "epoch:  38\n",
      "2021-11-01 12:13:57.170497: train loss : -0.8453\n",
      "2021-11-01 12:14:14.439686: validation loss: -0.8316\n",
      "2021-11-01 12:14:14.443491: Average global foreground Dice: [0.8411]\n",
      "2021-11-01 12:14:14.451185: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 12:14:14.923842: lr: 0.006409\n",
      "2021-11-01 12:14:14.969656: saving checkpoint...\n",
      "2021-11-01 12:14:16.099273: done, saving took 1.16 seconds\n",
      "2021-11-01 12:14:16.749117: This epoch took 289.277619 s\n",
      "\n",
      "2021-11-01 12:14:16.759271: \n",
      "epoch:  39\n",
      "2021-11-01 12:18:45.909473: train loss : -0.8439\n",
      "2021-11-01 12:19:03.167953: validation loss: -0.8376\n",
      "2021-11-01 12:19:03.172196: Average global foreground Dice: [0.8492]\n",
      "2021-11-01 12:19:03.178760: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 12:19:03.650605: lr: 0.006314\n",
      "2021-11-01 12:19:03.695689: saving checkpoint...\n",
      "2021-11-01 12:19:04.863637: done, saving took 1.20 seconds\n",
      "2021-11-01 12:19:05.458720: This epoch took 288.692598 s\n",
      "\n",
      "2021-11-01 12:19:05.467561: \n",
      "epoch:  40\n",
      "2021-11-01 12:23:34.224613: train loss : -0.8481\n",
      "2021-11-01 12:23:51.433907: validation loss: -0.8386\n",
      "2021-11-01 12:23:51.437689: Average global foreground Dice: [0.8499]\n",
      "2021-11-01 12:23:51.444701: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 12:23:51.919373: lr: 0.00622\n",
      "2021-11-01 12:23:51.967155: saving checkpoint...\n",
      "2021-11-01 12:23:53.073436: done, saving took 1.14 seconds\n",
      "2021-11-01 12:23:53.718425: This epoch took 288.243217 s\n",
      "\n",
      "2021-11-01 12:23:53.727114: \n",
      "epoch:  41\n",
      "2021-11-01 12:28:22.484759: train loss : -0.8466\n",
      "2021-11-01 12:28:39.670014: validation loss: -0.8331\n",
      "2021-11-01 12:28:39.674071: Average global foreground Dice: [0.8457]\n",
      "2021-11-01 12:28:39.680766: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 12:28:40.141287: lr: 0.006125\n",
      "2021-11-01 12:28:40.186799: saving checkpoint...\n",
      "2021-11-01 12:28:41.304432: done, saving took 1.15 seconds\n",
      "2021-11-01 12:28:41.994071: This epoch took 288.259744 s\n",
      "\n",
      "2021-11-01 12:28:42.002502: \n",
      "epoch:  42\n",
      "2021-11-01 12:33:10.339289: train loss : -0.8423\n",
      "2021-11-01 12:33:27.564589: validation loss: -0.8301\n",
      "2021-11-01 12:33:27.569799: Average global foreground Dice: [0.8401]\n",
      "2021-11-01 12:33:27.576520: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 12:33:28.040287: lr: 0.00603\n",
      "2021-11-01 12:33:28.057757: This epoch took 286.047102 s\n",
      "\n",
      "2021-11-01 12:33:28.065588: \n",
      "epoch:  43\n",
      "2021-11-01 12:37:57.403688: train loss : -0.8422\n",
      "2021-11-01 12:38:14.632735: validation loss: -0.8300\n",
      "2021-11-01 12:38:14.637226: Average global foreground Dice: [0.8434]\n",
      "2021-11-01 12:38:14.644500: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 12:38:15.107409: lr: 0.005934\n",
      "2021-11-01 12:38:15.152330: saving checkpoint...\n",
      "2021-11-01 12:38:16.262125: done, saving took 1.14 seconds\n",
      "2021-11-01 12:38:16.868235: This epoch took 288.794268 s\n",
      "\n",
      "2021-11-01 12:38:16.876966: \n",
      "epoch:  44\n",
      "2021-11-01 12:42:45.366991: train loss : -0.8393\n",
      "2021-11-01 12:43:02.606602: validation loss: -0.8357\n",
      "2021-11-01 12:43:02.609884: Average global foreground Dice: [0.8454]\n",
      "2021-11-01 12:43:02.617312: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 12:43:03.079926: lr: 0.005839\n",
      "2021-11-01 12:43:03.125904: saving checkpoint...\n",
      "2021-11-01 12:43:04.249747: done, saving took 1.15 seconds\n",
      "2021-11-01 12:43:04.906493: This epoch took 288.022091 s\n",
      "\n",
      "2021-11-01 12:43:04.915427: \n",
      "epoch:  45\n",
      "2021-11-01 12:47:35.059316: train loss : -0.8433\n",
      "2021-11-01 12:47:52.367401: validation loss: -0.8421\n",
      "2021-11-01 12:47:52.371796: Average global foreground Dice: [0.856]\n",
      "2021-11-01 12:47:52.378608: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 12:47:52.847280: lr: 0.005743\n",
      "2021-11-01 12:47:52.921453: saving checkpoint...\n",
      "2021-11-01 12:47:54.041926: done, saving took 1.18 seconds\n",
      "2021-11-01 12:47:54.630595: This epoch took 289.707542 s\n",
      "\n",
      "2021-11-01 12:47:54.639071: \n",
      "epoch:  46\n",
      "2021-11-01 12:52:24.776301: train loss : -0.8503\n",
      "2021-11-01 12:52:42.195869: validation loss: -0.8398\n",
      "2021-11-01 12:52:42.199757: Average global foreground Dice: [0.8524]\n",
      "2021-11-01 12:52:42.206615: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 12:52:42.683678: lr: 0.005647\n",
      "2021-11-01 12:52:42.758390: saving checkpoint...\n",
      "2021-11-01 12:52:43.892299: done, saving took 1.19 seconds\n",
      "2021-11-01 12:52:44.548194: This epoch took 289.901791 s\n",
      "\n",
      "2021-11-01 12:52:44.555957: \n",
      "epoch:  47\n",
      "2021-11-01 12:57:14.102188: train loss : -0.8502\n",
      "2021-11-01 12:57:31.467924: validation loss: -0.8345\n",
      "2021-11-01 12:57:31.471612: Average global foreground Dice: [0.848]\n",
      "2021-11-01 12:57:31.479206: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 12:57:31.967399: lr: 0.005551\n",
      "2021-11-01 12:57:32.044187: saving checkpoint...\n",
      "2021-11-01 12:57:33.177139: done, saving took 1.19 seconds\n",
      "2021-11-01 12:57:33.840791: This epoch took 289.277611 s\n",
      "\n",
      "2021-11-01 12:57:33.849874: \n",
      "epoch:  48\n",
      "2021-11-01 13:02:03.983096: train loss : -0.8437\n",
      "2021-11-01 13:02:21.528965: validation loss: -0.8344\n",
      "2021-11-01 13:02:21.532758: Average global foreground Dice: [0.8454]\n",
      "2021-11-01 13:02:21.539651: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 13:02:22.025947: lr: 0.005455\n",
      "2021-11-01 13:02:22.104560: saving checkpoint...\n",
      "2021-11-01 13:02:23.277015: done, saving took 1.23 seconds\n",
      "2021-11-01 13:02:23.882195: This epoch took 290.025186 s\n",
      "\n",
      "2021-11-01 13:02:23.892110: \n",
      "epoch:  49\n",
      "2021-11-01 13:06:52.363703: train loss : -0.8513\n",
      "2021-11-01 13:07:09.562201: validation loss: -0.8345\n",
      "2021-11-01 13:07:09.566671: Average global foreground Dice: [0.8453]\n",
      "2021-11-01 13:07:09.573574: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 13:07:10.043128: lr: 0.005359\n",
      "2021-11-01 13:07:10.061778: saving scheduled checkpoint file...\n",
      "2021-11-01 13:07:10.098730: saving checkpoint...\n",
      "2021-11-01 13:07:11.044268: done, saving took 0.97 seconds\n",
      "2021-11-01 13:07:11.633836: done\n",
      "2021-11-01 13:07:11.672672: saving checkpoint...\n",
      "2021-11-01 13:07:12.786290: done, saving took 1.14 seconds\n",
      "2021-11-01 13:07:13.407558: This epoch took 289.507989 s\n",
      "\n",
      "2021-11-01 13:07:13.416225: \n",
      "epoch:  50\n",
      "2021-11-01 13:11:42.507022: train loss : -0.8454\n",
      "2021-11-01 13:11:59.724266: validation loss: -0.8320\n",
      "2021-11-01 13:11:59.730203: Average global foreground Dice: [0.8404]\n",
      "2021-11-01 13:11:59.737691: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 13:12:00.202680: lr: 0.005262\n",
      "2021-11-01 13:12:00.220166: This epoch took 286.796984 s\n",
      "\n",
      "2021-11-01 13:12:00.228500: \n",
      "epoch:  51\n",
      "2021-11-01 13:16:29.255054: train loss : -0.8480\n",
      "2021-11-01 13:16:46.471626: validation loss: -0.8352\n",
      "2021-11-01 13:16:46.475900: Average global foreground Dice: [0.846]\n",
      "2021-11-01 13:16:46.482896: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 13:16:46.951600: lr: 0.005166\n",
      "2021-11-01 13:16:46.967046: This epoch took 286.731585 s\n",
      "\n",
      "2021-11-01 13:16:46.973879: \n",
      "epoch:  52\n",
      "2021-11-01 13:21:16.622192: train loss : -0.8524\n",
      "2021-11-01 13:21:33.848487: validation loss: -0.8307\n",
      "2021-11-01 13:21:33.851961: Average global foreground Dice: [0.8359]\n",
      "2021-11-01 13:21:33.858811: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 13:21:34.323973: lr: 0.005069\n",
      "2021-11-01 13:21:34.339902: This epoch took 287.357409 s\n",
      "\n",
      "2021-11-01 13:21:34.350838: \n",
      "epoch:  53\n",
      "2021-11-01 13:26:04.980855: train loss : -0.8479\n",
      "2021-11-01 13:26:22.212112: validation loss: -0.8285\n",
      "2021-11-01 13:26:22.215970: Average global foreground Dice: [0.8419]\n",
      "2021-11-01 13:26:22.223971: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 13:26:22.697396: lr: 0.004971\n",
      "2021-11-01 13:26:22.711829: This epoch took 288.354266 s\n",
      "\n",
      "2021-11-01 13:26:22.718345: \n",
      "epoch:  54\n",
      "2021-11-01 13:30:53.728930: train loss : -0.8471\n",
      "2021-11-01 13:31:11.026435: validation loss: -0.8310\n",
      "2021-11-01 13:31:11.030352: Average global foreground Dice: [0.8414]\n",
      "2021-11-01 13:31:11.040935: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 13:31:11.506808: lr: 0.004874\n",
      "2021-11-01 13:31:11.540789: This epoch took 288.815866 s\n",
      "\n",
      "2021-11-01 13:31:11.547298: \n",
      "epoch:  55\n",
      "2021-11-01 13:35:41.672002: train loss : -0.8525\n",
      "2021-11-01 13:35:58.904226: validation loss: -0.8354\n",
      "2021-11-01 13:35:58.908138: Average global foreground Dice: [0.8429]\n",
      "2021-11-01 13:35:58.914867: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 13:35:59.382972: lr: 0.004776\n",
      "2021-11-01 13:35:59.409265: This epoch took 287.855296 s\n",
      "\n",
      "2021-11-01 13:35:59.415763: \n",
      "epoch:  56\n",
      "2021-11-01 13:40:30.216896: train loss : -0.8514\n",
      "2021-11-01 13:40:47.442905: validation loss: -0.8311\n",
      "2021-11-01 13:40:47.447191: Average global foreground Dice: [0.8403]\n",
      "2021-11-01 13:40:47.454392: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 13:40:47.918402: lr: 0.004679\n",
      "2021-11-01 13:40:47.933704: This epoch took 288.510111 s\n",
      "\n",
      "2021-11-01 13:40:47.940769: \n",
      "epoch:  57\n",
      "2021-11-01 13:45:19.916789: train loss : -0.8540\n",
      "2021-11-01 13:45:37.346475: validation loss: -0.8298\n",
      "2021-11-01 13:45:37.351005: Average global foreground Dice: [0.8356]\n",
      "2021-11-01 13:45:37.357947: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 13:45:37.835438: lr: 0.004581\n",
      "2021-11-01 13:45:37.852875: This epoch took 289.905050 s\n",
      "\n",
      "2021-11-01 13:45:37.860941: \n",
      "epoch:  58\n",
      "2021-11-01 13:50:09.240844: train loss : -0.8569\n",
      "2021-11-01 13:50:26.484834: validation loss: -0.8427\n",
      "2021-11-01 13:50:26.489328: Average global foreground Dice: [0.8533]\n",
      "2021-11-01 13:50:26.498459: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 13:50:26.973135: lr: 0.004482\n",
      "2021-11-01 13:50:26.991270: This epoch took 289.121997 s\n",
      "\n",
      "2021-11-01 13:50:26.998271: \n",
      "epoch:  59\n",
      "2021-11-01 13:54:58.062263: train loss : -0.8535\n",
      "2021-11-01 13:55:15.295223: validation loss: -0.8392\n",
      "2021-11-01 13:55:15.299672: Average global foreground Dice: [0.8474]\n",
      "2021-11-01 13:55:15.307277: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 13:55:15.776408: lr: 0.004384\n",
      "2021-11-01 13:55:15.793090: This epoch took 288.788233 s\n",
      "\n",
      "2021-11-01 13:55:15.801167: \n",
      "epoch:  60\n",
      "2021-11-01 13:59:46.033142: train loss : -0.8593\n",
      "2021-11-01 14:00:03.350716: validation loss: -0.8404\n",
      "2021-11-01 14:00:03.355684: Average global foreground Dice: [0.8526]\n",
      "2021-11-01 14:00:03.362350: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 14:00:03.833951: lr: 0.004285\n",
      "2021-11-01 14:00:03.878634: saving checkpoint...\n",
      "2021-11-01 14:00:04.992159: done, saving took 1.14 seconds\n",
      "2021-11-01 14:00:05.629968: This epoch took 289.820514 s\n",
      "\n",
      "2021-11-01 14:00:05.645661: \n",
      "epoch:  61\n",
      "2021-11-01 14:04:36.959019: train loss : -0.8568\n",
      "2021-11-01 14:04:54.199794: validation loss: -0.8441\n",
      "2021-11-01 14:04:54.203555: Average global foreground Dice: [0.8533]\n",
      "2021-11-01 14:04:54.210671: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 14:04:54.683827: lr: 0.004186\n",
      "2021-11-01 14:04:54.729475: saving checkpoint...\n",
      "2021-11-01 14:04:55.834219: done, saving took 1.13 seconds\n",
      "2021-11-01 14:04:56.473449: This epoch took 290.819176 s\n",
      "\n",
      "2021-11-01 14:04:56.482739: \n",
      "epoch:  62\n",
      "2021-11-01 14:09:28.041758: train loss : -0.8587\n",
      "2021-11-01 14:09:45.328015: validation loss: -0.8336\n",
      "2021-11-01 14:09:45.331579: Average global foreground Dice: [0.8439]\n",
      "2021-11-01 14:09:45.338170: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 14:09:45.847646: lr: 0.004087\n",
      "2021-11-01 14:09:45.863219: This epoch took 289.373704 s\n",
      "\n",
      "2021-11-01 14:09:45.870093: \n",
      "epoch:  63\n",
      "2021-11-01 14:14:17.601738: train loss : -0.8580\n",
      "2021-11-01 14:14:34.873530: validation loss: -0.8401\n",
      "2021-11-01 14:14:34.877856: Average global foreground Dice: [0.8486]\n",
      "2021-11-01 14:14:34.885580: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 14:14:35.351896: lr: 0.003987\n",
      "2021-11-01 14:14:35.396116: saving checkpoint...\n",
      "2021-11-01 14:14:36.499822: done, saving took 1.13 seconds\n",
      "2021-11-01 14:14:37.117784: This epoch took 291.240195 s\n",
      "\n",
      "2021-11-01 14:14:37.126331: \n",
      "epoch:  64\n",
      "2021-11-01 14:19:08.832944: train loss : -0.8603\n",
      "2021-11-01 14:19:26.078718: validation loss: -0.8459\n",
      "2021-11-01 14:19:26.083229: Average global foreground Dice: [0.8553]\n",
      "2021-11-01 14:19:26.090493: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 14:19:26.559756: lr: 0.003887\n",
      "2021-11-01 14:19:26.605393: saving checkpoint...\n",
      "2021-11-01 14:19:27.706193: done, saving took 1.13 seconds\n",
      "2021-11-01 14:19:28.381067: This epoch took 291.247468 s\n",
      "\n",
      "2021-11-01 14:19:28.389455: \n",
      "epoch:  65\n",
      "2021-11-01 14:24:00.758003: train loss : -0.8591\n",
      "2021-11-01 14:24:18.063939: validation loss: -0.8455\n",
      "2021-11-01 14:24:18.068255: Average global foreground Dice: [0.8568]\n",
      "2021-11-01 14:24:18.075900: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 14:24:18.543979: lr: 0.003787\n",
      "2021-11-01 14:24:18.592428: saving checkpoint...\n",
      "2021-11-01 14:24:19.763645: done, saving took 1.20 seconds\n",
      "2021-11-01 14:24:20.435924: This epoch took 292.039937 s\n",
      "\n",
      "2021-11-01 14:24:20.444644: \n",
      "epoch:  66\n",
      "2021-11-01 14:28:52.204350: train loss : -0.8642\n",
      "2021-11-01 14:29:09.486099: validation loss: -0.8374\n",
      "2021-11-01 14:29:09.491748: Average global foreground Dice: [0.848]\n",
      "2021-11-01 14:29:09.498239: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 14:29:09.976182: lr: 0.003687\n",
      "2021-11-01 14:29:10.025607: saving checkpoint...\n",
      "2021-11-01 14:29:11.134760: done, saving took 1.14 seconds\n",
      "2021-11-01 14:29:11.735141: This epoch took 291.283263 s\n",
      "\n",
      "2021-11-01 14:29:11.743711: \n",
      "epoch:  67\n",
      "2021-11-01 14:33:43.718488: train loss : -0.8595\n",
      "2021-11-01 14:34:00.977202: validation loss: -0.8345\n",
      "2021-11-01 14:34:00.981424: Average global foreground Dice: [0.8412]\n",
      "2021-11-01 14:34:00.988113: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 14:34:01.459328: lr: 0.003586\n",
      "2021-11-01 14:34:01.481979: This epoch took 289.730681 s\n",
      "\n",
      "2021-11-01 14:34:01.490332: \n",
      "epoch:  68\n",
      "2021-11-01 14:38:34.187271: train loss : -0.8575\n",
      "2021-11-01 14:38:51.448941: validation loss: -0.8354\n",
      "2021-11-01 14:38:51.452758: Average global foreground Dice: [0.8464]\n",
      "2021-11-01 14:38:51.460032: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 14:38:51.928903: lr: 0.003485\n",
      "2021-11-01 14:38:51.947259: This epoch took 290.449330 s\n",
      "\n",
      "2021-11-01 14:38:51.954145: \n",
      "epoch:  69\n",
      "2021-11-01 14:43:25.832933: train loss : -0.8620\n",
      "2021-11-01 14:43:43.174604: validation loss: -0.8438\n",
      "2021-11-01 14:43:43.178897: Average global foreground Dice: [0.854]\n",
      "2021-11-01 14:43:43.184914: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 14:43:43.658408: lr: 0.003384\n",
      "2021-11-01 14:43:43.705296: saving checkpoint...\n",
      "2021-11-01 14:43:44.812545: done, saving took 1.14 seconds\n",
      "2021-11-01 14:43:45.614597: This epoch took 293.653284 s\n",
      "\n",
      "2021-11-01 14:43:45.623543: \n",
      "epoch:  70\n",
      "2021-11-01 14:48:21.508776: train loss : -0.8633\n",
      "2021-11-01 14:48:38.915976: validation loss: -0.8463\n",
      "2021-11-01 14:48:38.919594: Average global foreground Dice: [0.8572]\n",
      "2021-11-01 14:48:38.925870: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 14:48:39.396898: lr: 0.003282\n",
      "2021-11-01 14:48:39.467308: saving checkpoint...\n",
      "2021-11-01 14:48:40.694053: done, saving took 1.26 seconds\n",
      "2021-11-01 14:48:41.316896: This epoch took 295.685580 s\n",
      "\n",
      "2021-11-01 14:48:41.335932: \n",
      "epoch:  71\n",
      "2021-11-01 14:53:16.027956: train loss : -0.8622\n",
      "2021-11-01 14:53:33.350111: validation loss: -0.8345\n",
      "2021-11-01 14:53:33.353807: Average global foreground Dice: [0.849]\n",
      "2021-11-01 14:53:33.360435: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 14:53:33.836313: lr: 0.00318\n",
      "2021-11-01 14:53:33.903927: saving checkpoint...\n",
      "2021-11-01 14:53:35.140255: done, saving took 1.27 seconds\n",
      "2021-11-01 14:53:35.800569: This epoch took 294.457001 s\n",
      "\n",
      "2021-11-01 14:53:35.822328: \n",
      "epoch:  72\n",
      "2021-11-01 14:58:10.869550: train loss : -0.8624\n",
      "2021-11-01 14:58:28.194813: validation loss: -0.8350\n",
      "2021-11-01 14:58:28.199357: Average global foreground Dice: [0.8444]\n",
      "2021-11-01 14:58:28.207159: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 14:58:28.679877: lr: 0.003078\n",
      "2021-11-01 14:58:28.714042: This epoch took 292.883905 s\n",
      "\n",
      "2021-11-01 14:58:28.721077: \n",
      "epoch:  73\n",
      "2021-11-01 15:03:04.101209: train loss : -0.8633\n",
      "2021-11-01 15:03:21.646590: validation loss: -0.8406\n",
      "2021-11-01 15:03:21.651690: Average global foreground Dice: [0.8531]\n",
      "2021-11-01 15:03:21.659598: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 15:03:22.191531: lr: 0.002975\n",
      "2021-11-01 15:03:22.242956: saving checkpoint...\n",
      "2021-11-01 15:03:23.345179: done, saving took 1.13 seconds\n",
      "2021-11-01 15:03:24.060064: This epoch took 295.331990 s\n",
      "\n",
      "2021-11-01 15:03:24.068937: \n",
      "epoch:  74\n",
      "2021-11-01 15:07:59.281060: train loss : -0.8603\n",
      "2021-11-01 15:08:16.653460: validation loss: -0.8398\n",
      "2021-11-01 15:08:16.658723: Average global foreground Dice: [0.85]\n",
      "2021-11-01 15:08:16.665885: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 15:08:17.144220: lr: 0.002872\n",
      "2021-11-01 15:08:17.211067: saving checkpoint...\n",
      "2021-11-01 15:08:18.430452: done, saving took 1.25 seconds\n",
      "2021-11-01 15:08:19.108359: This epoch took 295.032687 s\n",
      "\n",
      "2021-11-01 15:08:19.128149: \n",
      "epoch:  75\n",
      "2021-11-01 15:12:54.146948: train loss : -0.8665\n",
      "2021-11-01 15:13:11.598068: validation loss: -0.8417\n",
      "2021-11-01 15:13:11.601916: Average global foreground Dice: [0.8502]\n",
      "2021-11-01 15:13:11.609315: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 15:13:12.080512: lr: 0.002768\n",
      "2021-11-01 15:13:12.143446: saving checkpoint...\n",
      "2021-11-01 15:13:13.363176: done, saving took 1.25 seconds\n",
      "2021-11-01 15:13:13.977481: This epoch took 294.842478 s\n",
      "\n",
      "2021-11-01 15:13:13.997913: \n",
      "epoch:  76\n",
      "2021-11-01 15:17:50.812013: train loss : -0.8646\n",
      "2021-11-01 15:18:08.206533: validation loss: -0.8454\n",
      "2021-11-01 15:18:08.210887: Average global foreground Dice: [0.8566]\n",
      "2021-11-01 15:18:08.217942: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 15:18:08.698593: lr: 0.002664\n",
      "2021-11-01 15:18:08.757682: saving checkpoint...\n",
      "2021-11-01 15:18:09.914572: done, saving took 1.19 seconds\n",
      "2021-11-01 15:18:10.511653: This epoch took 296.506522 s\n",
      "\n",
      "2021-11-01 15:18:10.519701: \n",
      "epoch:  77\n",
      "2021-11-01 15:22:47.276172: train loss : -0.8651\n",
      "2021-11-01 15:23:04.593888: validation loss: -0.8405\n",
      "2021-11-01 15:23:04.597398: Average global foreground Dice: [0.8479]\n",
      "2021-11-01 15:23:04.603701: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 15:23:05.085418: lr: 0.00256\n",
      "2021-11-01 15:23:05.119040: This epoch took 294.591898 s\n",
      "\n",
      "2021-11-01 15:23:05.125369: \n",
      "epoch:  78\n",
      "2021-11-01 15:27:40.736383: train loss : -0.8674\n",
      "2021-11-01 15:27:58.204736: validation loss: -0.8424\n",
      "2021-11-01 15:27:58.209047: Average global foreground Dice: [0.8538]\n",
      "2021-11-01 15:27:58.218190: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 15:27:58.700042: lr: 0.002455\n",
      "2021-11-01 15:27:58.764152: saving checkpoint...\n",
      "2021-11-01 15:27:59.938766: done, saving took 1.20 seconds\n",
      "2021-11-01 15:28:00.582116: This epoch took 295.450435 s\n",
      "\n",
      "2021-11-01 15:28:00.594371: \n",
      "epoch:  79\n",
      "2021-11-01 15:32:35.303525: train loss : -0.8669\n",
      "2021-11-01 15:32:52.731801: validation loss: -0.8416\n",
      "2021-11-01 15:32:52.735628: Average global foreground Dice: [0.848]\n",
      "2021-11-01 15:32:52.742271: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 15:32:53.280845: lr: 0.002349\n",
      "2021-11-01 15:32:53.316764: This epoch took 292.715772 s\n",
      "\n",
      "2021-11-01 15:32:53.324041: \n",
      "epoch:  80\n",
      "2021-11-01 15:37:28.540272: train loss : -0.8726\n",
      "2021-11-01 15:37:45.912049: validation loss: -0.8350\n",
      "2021-11-01 15:37:45.915734: Average global foreground Dice: [0.8436]\n",
      "2021-11-01 15:37:45.922799: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 15:37:46.406453: lr: 0.002243\n",
      "2021-11-01 15:37:46.443280: This epoch took 293.111504 s\n",
      "\n",
      "2021-11-01 15:37:46.451576: \n",
      "epoch:  81\n",
      "2021-11-01 15:42:21.356366: train loss : -0.8688\n",
      "2021-11-01 15:42:38.752211: validation loss: -0.8391\n",
      "2021-11-01 15:42:38.756185: Average global foreground Dice: [0.8494]\n",
      "2021-11-01 15:42:38.762981: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 15:42:39.241424: lr: 0.002137\n",
      "2021-11-01 15:42:39.277658: This epoch took 292.818159 s\n",
      "\n",
      "2021-11-01 15:42:39.285059: \n",
      "epoch:  82\n",
      "2021-11-01 15:47:14.333609: train loss : -0.8730\n",
      "2021-11-01 15:47:31.674864: validation loss: -0.8441\n",
      "2021-11-01 15:47:31.679112: Average global foreground Dice: [0.8518]\n",
      "2021-11-01 15:47:31.686312: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 15:47:32.161465: lr: 0.00203\n",
      "2021-11-01 15:47:32.195172: This epoch took 292.902552 s\n",
      "\n",
      "2021-11-01 15:47:32.201959: \n",
      "epoch:  83\n",
      "2021-11-01 15:52:08.003237: train loss : -0.8706\n",
      "2021-11-01 15:52:25.442718: validation loss: -0.8388\n",
      "2021-11-01 15:52:25.446939: Average global foreground Dice: [0.8473]\n",
      "2021-11-01 15:52:25.454002: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 15:52:25.928283: lr: 0.001922\n",
      "2021-11-01 15:52:25.962881: This epoch took 293.753978 s\n",
      "\n",
      "2021-11-01 15:52:25.970681: \n",
      "epoch:  84\n",
      "2021-11-01 15:57:01.203267: train loss : -0.8690\n",
      "2021-11-01 15:57:18.750638: validation loss: -0.8432\n",
      "2021-11-01 15:57:18.754250: Average global foreground Dice: [0.8542]\n",
      "2021-11-01 15:57:18.761406: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 15:57:19.233883: lr: 0.001813\n",
      "2021-11-01 15:57:19.269048: This epoch took 293.290190 s\n",
      "\n",
      "2021-11-01 15:57:19.276407: \n",
      "epoch:  85\n",
      "2021-11-01 16:01:54.662480: train loss : -0.8720\n",
      "2021-11-01 16:02:12.207060: validation loss: -0.8403\n",
      "2021-11-01 16:02:12.210850: Average global foreground Dice: [0.8479]\n",
      "2021-11-01 16:02:12.217480: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 16:02:12.689362: lr: 0.001704\n",
      "2021-11-01 16:02:12.722330: This epoch took 293.438082 s\n",
      "\n",
      "2021-11-01 16:02:12.728462: \n",
      "epoch:  86\n",
      "2021-11-01 16:06:49.464045: train loss : -0.8711\n",
      "2021-11-01 16:07:06.936789: validation loss: -0.8361\n",
      "2021-11-01 16:07:06.940915: Average global foreground Dice: [0.8471]\n",
      "2021-11-01 16:07:06.948496: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 16:07:07.422907: lr: 0.001594\n",
      "2021-11-01 16:07:07.458738: This epoch took 294.723260 s\n",
      "\n",
      "2021-11-01 16:07:07.466440: \n",
      "epoch:  87\n",
      "2021-11-01 16:11:44.307132: train loss : -0.8685\n",
      "2021-11-01 16:12:01.835381: validation loss: -0.8454\n",
      "2021-11-01 16:12:01.839682: Average global foreground Dice: [0.8552]\n",
      "2021-11-01 16:12:01.846431: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 16:12:02.321491: lr: 0.001483\n",
      "2021-11-01 16:12:02.354621: This epoch took 294.879546 s\n",
      "\n",
      "2021-11-01 16:12:02.361859: \n",
      "epoch:  88\n",
      "2021-11-01 16:16:40.157364: train loss : -0.8706\n",
      "2021-11-01 16:16:57.706304: validation loss: -0.8375\n",
      "2021-11-01 16:16:57.710700: Average global foreground Dice: [0.8469]\n",
      "2021-11-01 16:16:57.717868: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 16:16:58.236519: lr: 0.001372\n",
      "2021-11-01 16:16:58.275333: This epoch took 295.905910 s\n",
      "\n",
      "2021-11-01 16:16:58.283886: \n",
      "epoch:  89\n",
      "2021-11-01 16:21:33.456421: train loss : -0.8706\n",
      "2021-11-01 16:21:50.782753: validation loss: -0.8486\n",
      "2021-11-01 16:21:50.786342: Average global foreground Dice: [0.8549]\n",
      "2021-11-01 16:21:50.793286: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 16:21:51.265179: lr: 0.001259\n",
      "2021-11-01 16:21:51.328312: saving checkpoint...\n",
      "2021-11-01 16:21:52.555316: done, saving took 1.26 seconds\n",
      "2021-11-01 16:21:53.167978: This epoch took 294.875709 s\n",
      "\n",
      "2021-11-01 16:21:53.187117: \n",
      "epoch:  90\n",
      "2021-11-01 16:26:27.965972: train loss : -0.8696\n",
      "2021-11-01 16:26:45.279990: validation loss: -0.8399\n",
      "2021-11-01 16:26:45.284000: Average global foreground Dice: [0.849]\n",
      "2021-11-01 16:26:45.290150: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 16:26:45.766297: lr: 0.001145\n",
      "2021-11-01 16:26:45.803541: This epoch took 292.610014 s\n",
      "\n",
      "2021-11-01 16:26:45.811435: \n",
      "epoch:  91\n",
      "2021-11-01 16:31:20.488637: train loss : -0.8732\n",
      "2021-11-01 16:31:37.800643: validation loss: -0.8450\n",
      "2021-11-01 16:31:37.804244: Average global foreground Dice: [0.8531]\n",
      "2021-11-01 16:31:37.811176: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 16:31:38.287764: lr: 0.00103\n",
      "2021-11-01 16:31:38.351047: saving checkpoint...\n",
      "2021-11-01 16:31:39.596820: done, saving took 1.28 seconds\n",
      "2021-11-01 16:31:40.262240: This epoch took 294.443705 s\n",
      "\n",
      "2021-11-01 16:31:40.282000: \n",
      "epoch:  92\n",
      "2021-11-01 16:36:15.150730: train loss : -0.8720\n",
      "2021-11-01 16:36:32.673118: validation loss: -0.8451\n",
      "2021-11-01 16:36:32.677112: Average global foreground Dice: [0.856]\n",
      "2021-11-01 16:36:32.684444: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 16:36:33.156225: lr: 0.000913\n",
      "2021-11-01 16:36:33.222098: saving checkpoint...\n",
      "2021-11-01 16:36:34.431546: done, saving took 1.24 seconds\n",
      "2021-11-01 16:36:35.187254: This epoch took 294.889686 s\n",
      "\n",
      "2021-11-01 16:36:35.206843: \n",
      "epoch:  93\n",
      "2021-11-01 16:41:09.403045: train loss : -0.8721\n",
      "2021-11-01 16:41:26.778975: validation loss: -0.8404\n",
      "2021-11-01 16:41:26.782705: Average global foreground Dice: [0.8477]\n",
      "2021-11-01 16:41:26.789298: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 16:41:27.264964: lr: 0.000795\n",
      "2021-11-01 16:41:27.298794: This epoch took 292.084527 s\n",
      "\n",
      "2021-11-01 16:41:27.305868: \n",
      "epoch:  94\n",
      "2021-11-01 16:46:03.822076: train loss : -0.8732\n",
      "2021-11-01 16:46:21.225004: validation loss: -0.8370\n",
      "2021-11-01 16:46:21.229254: Average global foreground Dice: [0.8446]\n",
      "2021-11-01 16:46:21.236485: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 16:46:21.710461: lr: 0.000675\n",
      "2021-11-01 16:46:21.747311: This epoch took 294.434852 s\n",
      "\n",
      "2021-11-01 16:46:21.756848: \n",
      "epoch:  95\n",
      "2021-11-01 16:50:58.655090: train loss : -0.8714\n",
      "2021-11-01 16:51:16.062090: validation loss: -0.8417\n",
      "2021-11-01 16:51:16.066713: Average global foreground Dice: [0.8536]\n",
      "2021-11-01 16:51:16.074572: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 16:51:16.550355: lr: 0.000552\n",
      "2021-11-01 16:51:16.589326: This epoch took 294.825770 s\n",
      "\n",
      "2021-11-01 16:51:16.597537: \n",
      "epoch:  96\n",
      "2021-11-01 16:55:54.150778: train loss : -0.8751\n",
      "2021-11-01 16:56:11.520918: validation loss: -0.8492\n",
      "2021-11-01 16:56:11.525362: Average global foreground Dice: [0.8568]\n",
      "2021-11-01 16:56:11.533350: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 16:56:12.010672: lr: 0.000426\n",
      "2021-11-01 16:56:12.063057: saving checkpoint...\n",
      "2021-11-01 16:56:13.297243: done, saving took 1.26 seconds\n",
      "2021-11-01 16:56:13.934689: This epoch took 297.328612 s\n",
      "\n",
      "2021-11-01 16:56:13.942449: \n",
      "epoch:  97\n",
      "2021-11-01 17:00:52.568120: train loss : -0.8724\n",
      "2021-11-01 17:01:09.987316: validation loss: -0.8478\n",
      "2021-11-01 17:01:09.991267: Average global foreground Dice: [0.8566]\n",
      "2021-11-01 17:01:09.998176: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 17:01:10.521648: lr: 0.000296\n",
      "2021-11-01 17:01:10.587459: saving checkpoint...\n",
      "2021-11-01 17:01:11.807970: done, saving took 1.25 seconds\n",
      "2021-11-01 17:01:12.456646: This epoch took 298.505922 s\n",
      "\n",
      "2021-11-01 17:01:12.475379: \n",
      "epoch:  98\n",
      "2021-11-01 17:05:48.801436: train loss : -0.8734\n",
      "2021-11-01 17:06:06.289872: validation loss: -0.8490\n",
      "2021-11-01 17:06:06.294591: Average global foreground Dice: [0.8572]\n",
      "2021-11-01 17:06:06.301473: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 17:06:06.780785: lr: 0.000158\n",
      "2021-11-01 17:06:06.843790: saving checkpoint...\n",
      "2021-11-01 17:06:08.068229: done, saving took 1.25 seconds\n",
      "2021-11-01 17:06:08.745241: This epoch took 296.263431 s\n",
      "\n",
      "2021-11-01 17:06:08.765054: \n",
      "epoch:  99\n",
      "2021-11-01 17:10:45.241505: train loss : -0.8762\n",
      "2021-11-01 17:11:03.037091: validation loss: -0.8419\n",
      "2021-11-01 17:11:03.041063: Average global foreground Dice: [0.8505]\n",
      "2021-11-01 17:11:03.047153: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 17:11:03.526255: lr: 0.0\n",
      "2021-11-01 17:11:03.561363: saving scheduled checkpoint file...\n",
      "2021-11-01 17:11:03.597901: saving checkpoint...\n",
      "2021-11-01 17:11:04.842632: done, saving took 1.27 seconds\n",
      "2021-11-01 17:11:05.500466: done\n",
      "2021-11-01 17:11:05.520063: This epoch took 296.748557 s\n",
      "\n",
      "2021-11-01 17:11:05.556645: saving checkpoint...\n",
      "2021-11-01 17:11:06.503760: done, saving took 0.98 seconds\n",
      "23090567_20160819 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150401 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130213 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120627 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090590_20121212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160706 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090599_20140701 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130225 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090604_20140303 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090615_20140403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090617_20140211 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120406 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160111 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130213 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090631_20130128 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090634_20150409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-01 17:14:25.522898: finished prediction\n",
      "2021-11-01 17:14:25.532140: evaluation of raw predictions\n",
      "2021-11-01 17:14:27.508276: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8559858734158238\n",
      "after:  0.8559858734158238\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-01 17:14:40.649698: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-01 17:14:40.671276: The split file contains 5 splits.\n",
      "2021-11-01 17:14:40.677571: Desired fold for training: 2\n",
      "2021-11-01 17:14:40.685197: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-01 17:14:44.996441: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-01 17:14:52.668443: Unable to plot network architecture:\n",
      "2021-11-01 17:14:52.671526: No module named 'hiddenlayer'\n",
      "2021-11-01 17:14:52.738283: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-01 17:14:52.745003: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-01 17:14:52.755674: \n",
      "\n",
      "2021-11-01 17:14:52.761846: \n",
      "epoch:  0\n",
      "2021-11-01 17:19:52.048429: train loss : -0.2237\n",
      "2021-11-01 17:20:09.759291: validation loss: -0.5803\n",
      "2021-11-01 17:20:09.762778: Average global foreground Dice: [0.6338]\n",
      "2021-11-01 17:20:09.769557: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 17:20:10.183725: lr: 0.00991\n",
      "2021-11-01 17:20:10.213598: This epoch took 317.444809 s\n",
      "\n",
      "2021-11-01 17:20:10.220993: \n",
      "epoch:  1\n",
      "2021-11-01 17:24:45.006387: train loss : -0.6134\n",
      "2021-11-01 17:25:02.666999: validation loss: -0.6819\n",
      "2021-11-01 17:25:02.672218: Average global foreground Dice: [0.7249]\n",
      "2021-11-01 17:25:02.678679: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 17:25:03.154708: lr: 0.00982\n",
      "2021-11-01 17:25:03.267704: saving checkpoint...\n",
      "2021-11-01 17:25:04.239578: done, saving took 1.05 seconds\n",
      "2021-11-01 17:25:04.867393: This epoch took 294.638595 s\n",
      "\n",
      "2021-11-01 17:25:04.885786: \n",
      "epoch:  2\n",
      "2021-11-01 17:29:38.755904: train loss : -0.6867\n",
      "2021-11-01 17:29:56.376879: validation loss: -0.7071\n",
      "2021-11-01 17:29:56.380672: Average global foreground Dice: [0.754]\n",
      "2021-11-01 17:29:56.386032: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 17:29:56.879661: lr: 0.00973\n",
      "2021-11-01 17:29:56.991086: saving checkpoint...\n",
      "2021-11-01 17:29:58.234173: done, saving took 1.32 seconds\n",
      "2021-11-01 17:29:58.933645: This epoch took 294.040787 s\n",
      "\n",
      "2021-11-01 17:29:58.950885: \n",
      "epoch:  3\n",
      "2021-11-01 17:34:34.980462: train loss : -0.7265\n",
      "2021-11-01 17:34:52.746690: validation loss: -0.7555\n",
      "2021-11-01 17:34:52.750732: Average global foreground Dice: [0.7959]\n",
      "2021-11-01 17:34:52.758676: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 17:34:53.258694: lr: 0.009639\n",
      "2021-11-01 17:34:53.368685: saving checkpoint...\n",
      "2021-11-01 17:34:54.659375: done, saving took 1.37 seconds\n",
      "2021-11-01 17:34:55.281386: This epoch took 296.323843 s\n",
      "\n",
      "2021-11-01 17:34:55.301878: \n",
      "epoch:  4\n",
      "2021-11-01 17:39:30.944165: train loss : -0.7551\n",
      "2021-11-01 17:39:48.672288: validation loss: -0.7668\n",
      "2021-11-01 17:39:48.676023: Average global foreground Dice: [0.8043]\n",
      "2021-11-01 17:39:48.682576: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 17:39:49.179539: lr: 0.009549\n",
      "2021-11-01 17:39:49.288742: saving checkpoint...\n",
      "2021-11-01 17:39:50.542437: done, saving took 1.33 seconds\n",
      "2021-11-01 17:39:51.221256: This epoch took 295.913680 s\n",
      "\n",
      "2021-11-01 17:39:51.241786: \n",
      "epoch:  5\n",
      "2021-11-01 17:44:26.660558: train loss : -0.7668\n",
      "2021-11-01 17:44:44.380408: validation loss: -0.7566\n",
      "2021-11-01 17:44:44.384038: Average global foreground Dice: [0.7921]\n",
      "2021-11-01 17:44:44.390119: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 17:44:44.879889: lr: 0.009458\n",
      "2021-11-01 17:44:44.980057: saving checkpoint...\n",
      "2021-11-01 17:44:46.228094: done, saving took 1.32 seconds\n",
      "2021-11-01 17:44:46.863585: This epoch took 295.616402 s\n",
      "\n",
      "2021-11-01 17:44:46.884497: \n",
      "epoch:  6\n",
      "2021-11-01 17:49:22.152094: train loss : -0.7793\n",
      "2021-11-01 17:49:39.945937: validation loss: -0.7855\n",
      "2021-11-01 17:49:39.949507: Average global foreground Dice: [0.815]\n",
      "2021-11-01 17:49:39.955528: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 17:49:40.451343: lr: 0.009368\n",
      "2021-11-01 17:49:40.546976: saving checkpoint...\n",
      "2021-11-01 17:49:41.790463: done, saving took 1.30 seconds\n",
      "2021-11-01 17:49:42.409412: This epoch took 295.518103 s\n",
      "\n",
      "2021-11-01 17:49:42.429770: \n",
      "epoch:  7\n",
      "2021-11-01 17:54:17.462309: train loss : -0.7851\n",
      "2021-11-01 17:54:34.950688: validation loss: -0.7971\n",
      "2021-11-01 17:54:34.954502: Average global foreground Dice: [0.8252]\n",
      "2021-11-01 17:54:34.961275: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 17:54:35.437891: lr: 0.009277\n",
      "2021-11-01 17:54:35.500596: saving checkpoint...\n",
      "2021-11-01 17:54:36.738234: done, saving took 1.27 seconds\n",
      "2021-11-01 17:54:37.343575: This epoch took 294.907159 s\n",
      "\n",
      "2021-11-01 17:54:37.362942: \n",
      "epoch:  8\n",
      "2021-11-01 17:59:14.042535: train loss : -0.7990\n",
      "2021-11-01 17:59:31.494142: validation loss: -0.7950\n",
      "2021-11-01 17:59:31.497456: Average global foreground Dice: [0.8225]\n",
      "2021-11-01 17:59:31.504501: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 17:59:31.989692: lr: 0.009186\n",
      "2021-11-01 17:59:32.050999: saving checkpoint...\n",
      "2021-11-01 17:59:33.298158: done, saving took 1.28 seconds\n",
      "2021-11-01 17:59:33.992782: This epoch took 296.623358 s\n",
      "\n",
      "2021-11-01 17:59:34.011265: \n",
      "epoch:  9\n",
      "2021-11-01 18:04:10.729026: train loss : -0.8024\n",
      "2021-11-01 18:04:28.528689: validation loss: -0.7921\n",
      "2021-11-01 18:04:28.532626: Average global foreground Dice: [0.816]\n",
      "2021-11-01 18:04:28.539057: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 18:04:29.029301: lr: 0.009095\n",
      "2021-11-01 18:04:29.121298: saving checkpoint...\n",
      "2021-11-01 18:04:30.957181: done, saving took 1.89 seconds\n",
      "2021-11-01 18:04:31.079050: This epoch took 297.061444 s\n",
      "\n",
      "2021-11-01 18:04:31.098104: \n",
      "epoch:  10\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-01 18:09:06.584044: train loss : -0.7948\n",
      "2021-11-01 18:09:24.086765: validation loss: -0.7736\n",
      "2021-11-01 18:09:24.090534: Average global foreground Dice: [0.7987]\n",
      "2021-11-01 18:09:24.096712: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 18:09:24.574990: lr: 0.009004\n",
      "2021-11-01 18:09:24.638402: saving checkpoint...\n",
      "2021-11-01 18:09:25.855528: done, saving took 1.25 seconds\n",
      "2021-11-01 18:09:26.632208: This epoch took 295.527511 s\n",
      "\n",
      "2021-11-01 18:09:26.650897: \n",
      "epoch:  11\n",
      "2021-11-01 18:14:00.305230: train loss : -0.8064\n",
      "2021-11-01 18:14:17.618809: validation loss: -0.8070\n",
      "2021-11-01 18:14:17.622962: Average global foreground Dice: [0.8332]\n",
      "2021-11-01 18:14:17.629808: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 18:14:18.105920: lr: 0.008913\n",
      "2021-11-01 18:14:18.167794: saving checkpoint...\n",
      "2021-11-01 18:14:19.398009: done, saving took 1.26 seconds\n",
      "2021-11-01 18:14:20.032582: This epoch took 293.373504 s\n",
      "\n",
      "2021-11-01 18:14:20.050633: \n",
      "epoch:  12\n",
      "2021-11-01 18:18:52.535980: train loss : -0.8139\n",
      "2021-11-01 18:19:09.789935: validation loss: -0.8021\n",
      "2021-11-01 18:19:09.794058: Average global foreground Dice: [0.8347]\n",
      "2021-11-01 18:19:09.801409: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 18:19:10.285187: lr: 0.008822\n",
      "2021-11-01 18:19:10.345627: saving checkpoint...\n",
      "2021-11-01 18:19:11.577484: done, saving took 1.26 seconds\n",
      "2021-11-01 18:19:12.197632: This epoch took 292.140523 s\n",
      "\n",
      "2021-11-01 18:19:12.216607: \n",
      "epoch:  13\n",
      "2021-11-01 18:23:46.601980: train loss : -0.8193\n",
      "2021-11-01 18:24:04.063957: validation loss: -0.8018\n",
      "2021-11-01 18:24:04.069436: Average global foreground Dice: [0.8322]\n",
      "2021-11-01 18:24:04.076434: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 18:24:04.554333: lr: 0.008731\n",
      "2021-11-01 18:24:04.614790: saving checkpoint...\n",
      "2021-11-01 18:24:05.858314: done, saving took 1.27 seconds\n",
      "2021-11-01 18:24:06.465122: This epoch took 294.241210 s\n",
      "\n",
      "2021-11-01 18:24:06.483650: \n",
      "epoch:  14\n",
      "2021-11-01 18:28:41.494626: train loss : -0.8184\n",
      "2021-11-01 18:28:59.297220: validation loss: -0.8175\n",
      "2021-11-01 18:28:59.301064: Average global foreground Dice: [0.8416]\n",
      "2021-11-01 18:28:59.307171: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 18:28:59.776686: lr: 0.008639\n",
      "2021-11-01 18:28:59.834556: saving checkpoint...\n",
      "2021-11-01 18:29:01.058115: done, saving took 1.25 seconds\n",
      "2021-11-01 18:29:01.735388: This epoch took 295.243926 s\n",
      "\n",
      "2021-11-01 18:29:01.757550: \n",
      "epoch:  15\n",
      "2021-11-01 18:33:36.422606: train loss : -0.8211\n",
      "2021-11-01 18:33:53.998482: validation loss: -0.8099\n",
      "2021-11-01 18:33:54.003809: Average global foreground Dice: [0.8373]\n",
      "2021-11-01 18:33:54.011058: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 18:33:54.486863: lr: 0.008548\n",
      "2021-11-01 18:33:54.569654: saving checkpoint...\n",
      "2021-11-01 18:33:55.866139: done, saving took 1.35 seconds\n",
      "2021-11-01 18:33:56.538271: This epoch took 294.772773 s\n",
      "\n",
      "2021-11-01 18:33:56.560243: \n",
      "epoch:  16\n",
      "2021-11-01 18:38:31.094557: train loss : -0.8246\n",
      "2021-11-01 18:38:48.581555: validation loss: -0.8172\n",
      "2021-11-01 18:38:48.586890: Average global foreground Dice: [0.8395]\n",
      "2021-11-01 18:38:48.593969: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 18:38:49.070765: lr: 0.008456\n",
      "2021-11-01 18:38:49.132420: saving checkpoint...\n",
      "2021-11-01 18:38:50.355755: done, saving took 1.25 seconds\n",
      "2021-11-01 18:38:51.001089: This epoch took 294.431791 s\n",
      "\n",
      "2021-11-01 18:38:51.020865: \n",
      "epoch:  17\n",
      "2021-11-01 18:43:25.883535: train loss : -0.8272\n",
      "2021-11-01 18:43:43.314426: validation loss: -0.8192\n",
      "2021-11-01 18:43:43.319198: Average global foreground Dice: [0.8415]\n",
      "2021-11-01 18:43:43.326118: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 18:43:43.800065: lr: 0.008364\n",
      "2021-11-01 18:43:43.859802: saving checkpoint...\n",
      "2021-11-01 18:43:45.098076: done, saving took 1.27 seconds\n",
      "2021-11-01 18:43:45.761232: This epoch took 294.732585 s\n",
      "\n",
      "2021-11-01 18:43:45.780872: \n",
      "epoch:  18\n",
      "2021-11-01 18:48:22.212623: train loss : -0.8200\n",
      "2021-11-01 18:48:39.948836: validation loss: -0.8091\n",
      "2021-11-01 18:48:39.952672: Average global foreground Dice: [0.8297]\n",
      "2021-11-01 18:48:39.958811: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 18:48:40.428909: lr: 0.008272\n",
      "2021-11-01 18:48:40.488588: saving checkpoint...\n",
      "2021-11-01 18:48:41.702814: done, saving took 1.24 seconds\n",
      "2021-11-01 18:48:42.341355: This epoch took 296.553781 s\n",
      "\n",
      "2021-11-01 18:48:42.361911: \n",
      "epoch:  19\n",
      "2021-11-01 18:53:19.325676: train loss : -0.8194\n",
      "2021-11-01 18:53:36.859162: validation loss: -0.8225\n",
      "2021-11-01 18:53:36.862692: Average global foreground Dice: [0.8463]\n",
      "2021-11-01 18:53:36.869536: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 18:53:37.339614: lr: 0.008181\n",
      "2021-11-01 18:53:37.402489: saving checkpoint...\n",
      "2021-11-01 18:53:38.662102: done, saving took 1.29 seconds\n",
      "2021-11-01 18:53:39.282936: This epoch took 296.913646 s\n",
      "\n",
      "2021-11-01 18:53:39.302342: \n",
      "epoch:  20\n",
      "2021-11-01 18:58:15.691221: train loss : -0.8240\n",
      "2021-11-01 18:58:33.219889: validation loss: -0.8134\n",
      "2021-11-01 18:58:33.223738: Average global foreground Dice: [0.8363]\n",
      "2021-11-01 18:58:33.230470: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 18:58:33.707096: lr: 0.008088\n",
      "2021-11-01 18:58:33.796880: saving checkpoint...\n",
      "2021-11-01 18:58:35.058107: done, saving took 1.32 seconds\n",
      "2021-11-01 18:58:35.687886: This epoch took 296.377021 s\n",
      "\n",
      "2021-11-01 18:58:35.708148: \n",
      "epoch:  21\n",
      "2021-11-01 19:03:12.518381: train loss : -0.8274\n",
      "2021-11-01 19:03:30.355789: validation loss: -0.8114\n",
      "2021-11-01 19:03:30.359655: Average global foreground Dice: [0.8353]\n",
      "2021-11-01 19:03:30.366688: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 19:03:30.844320: lr: 0.007996\n",
      "2021-11-01 19:03:30.928902: saving checkpoint...\n",
      "2021-11-01 19:03:32.189953: done, saving took 1.32 seconds\n",
      "2021-11-01 19:03:32.825733: This epoch took 297.110365 s\n",
      "\n",
      "2021-11-01 19:03:32.845867: \n",
      "epoch:  22\n",
      "2021-11-01 19:08:10.079182: train loss : -0.8221\n",
      "2021-11-01 19:08:27.812674: validation loss: -0.8123\n",
      "2021-11-01 19:08:27.817219: Average global foreground Dice: [0.8363]\n",
      "2021-11-01 19:08:27.823450: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 19:08:28.307627: lr: 0.007904\n",
      "2021-11-01 19:08:28.392273: saving checkpoint...\n",
      "2021-11-01 19:08:29.693126: done, saving took 1.36 seconds\n",
      "2021-11-01 19:08:30.299930: This epoch took 297.445977 s\n",
      "\n",
      "2021-11-01 19:08:30.319790: \n",
      "epoch:  23\n",
      "2021-11-01 19:13:06.963372: train loss : -0.8294\n",
      "2021-11-01 19:13:24.488363: validation loss: -0.8206\n",
      "2021-11-01 19:13:24.492164: Average global foreground Dice: [0.8452]\n",
      "2021-11-01 19:13:24.498708: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 19:13:24.963515: lr: 0.007811\n",
      "2021-11-01 19:13:25.024883: saving checkpoint...\n",
      "2021-11-01 19:13:26.254144: done, saving took 1.26 seconds\n",
      "2021-11-01 19:13:26.896137: This epoch took 296.568203 s\n",
      "\n",
      "2021-11-01 19:13:26.914796: \n",
      "epoch:  24\n",
      "2021-11-01 19:18:03.607241: train loss : -0.8321\n",
      "2021-11-01 19:18:21.130812: validation loss: -0.8142\n",
      "2021-11-01 19:18:21.135016: Average global foreground Dice: [0.8366]\n",
      "2021-11-01 19:18:21.142224: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 19:18:21.612941: lr: 0.007719\n",
      "2021-11-01 19:18:21.677003: saving checkpoint...\n",
      "2021-11-01 19:18:22.917875: done, saving took 1.27 seconds\n",
      "2021-11-01 19:18:23.588591: This epoch took 296.666164 s\n",
      "\n",
      "2021-11-01 19:18:23.605901: \n",
      "epoch:  25\n",
      "2021-11-01 19:23:00.678863: train loss : -0.8325\n",
      "2021-11-01 19:23:18.137467: validation loss: -0.8200\n",
      "2021-11-01 19:23:18.141036: Average global foreground Dice: [0.8419]\n",
      "2021-11-01 19:23:18.147670: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 19:23:18.616486: lr: 0.007626\n",
      "2021-11-01 19:23:18.677481: saving checkpoint...\n",
      "2021-11-01 19:23:19.921029: done, saving took 1.27 seconds\n",
      "2021-11-01 19:23:20.540854: This epoch took 296.927121 s\n",
      "\n",
      "2021-11-01 19:23:20.559956: \n",
      "epoch:  26\n",
      "2021-11-01 19:27:58.720496: train loss : -0.8344\n",
      "2021-11-01 19:28:16.231156: validation loss: -0.8169\n",
      "2021-11-01 19:28:16.235195: Average global foreground Dice: [0.84]\n",
      "2021-11-01 19:28:16.242605: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 19:28:16.711403: lr: 0.007533\n",
      "2021-11-01 19:28:16.775329: saving checkpoint...\n",
      "2021-11-01 19:28:17.996268: done, saving took 1.25 seconds\n",
      "2021-11-01 19:28:18.684414: This epoch took 298.118037 s\n",
      "\n",
      "2021-11-01 19:28:18.703928: \n",
      "epoch:  27\n",
      "2021-11-01 19:32:57.021301: train loss : -0.8363\n",
      "2021-11-01 19:33:14.796913: validation loss: -0.8278\n",
      "2021-11-01 19:33:14.801332: Average global foreground Dice: [0.8467]\n",
      "2021-11-01 19:33:14.808740: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 19:33:15.283047: lr: 0.00744\n",
      "2021-11-01 19:33:15.378777: saving checkpoint...\n",
      "2021-11-01 19:33:16.629113: done, saving took 1.31 seconds\n",
      "2021-11-01 19:33:17.384760: This epoch took 298.672262 s\n",
      "\n",
      "2021-11-01 19:33:17.405161: \n",
      "epoch:  28\n",
      "2021-11-01 19:37:56.251466: train loss : -0.8399\n",
      "2021-11-01 19:38:13.769755: validation loss: -0.8179\n",
      "2021-11-01 19:38:13.773166: Average global foreground Dice: [0.8394]\n",
      "2021-11-01 19:38:13.780052: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 19:38:14.250321: lr: 0.007347\n",
      "2021-11-01 19:38:14.311703: saving checkpoint...\n",
      "2021-11-01 19:38:15.598343: done, saving took 1.31 seconds\n",
      "2021-11-01 19:38:16.203661: This epoch took 298.790547 s\n",
      "\n",
      "2021-11-01 19:38:16.226410: \n",
      "epoch:  29\n",
      "2021-11-01 19:42:54.847838: train loss : -0.8353\n",
      "2021-11-01 19:43:12.377874: validation loss: -0.8176\n",
      "2021-11-01 19:43:12.382363: Average global foreground Dice: [0.8427]\n",
      "2021-11-01 19:43:12.388728: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 19:43:12.858662: lr: 0.007254\n",
      "2021-11-01 19:43:12.923356: saving checkpoint...\n",
      "2021-11-01 19:43:14.152020: done, saving took 1.26 seconds\n",
      "2021-11-01 19:43:14.781003: This epoch took 298.547050 s\n",
      "\n",
      "2021-11-01 19:43:14.800023: \n",
      "epoch:  30\n",
      "2021-11-01 19:47:53.176513: train loss : -0.8386\n",
      "2021-11-01 19:48:10.666112: validation loss: -0.8152\n",
      "2021-11-01 19:48:10.671077: Average global foreground Dice: [0.8386]\n",
      "2021-11-01 19:48:10.678209: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 19:48:11.150366: lr: 0.007161\n",
      "2021-11-01 19:48:11.211476: saving checkpoint...\n",
      "2021-11-01 19:48:12.439314: done, saving took 1.26 seconds\n",
      "2021-11-01 19:48:13.085605: This epoch took 298.278033 s\n",
      "\n",
      "2021-11-01 19:48:13.107069: \n",
      "epoch:  31\n",
      "2021-11-01 19:52:51.773863: train loss : -0.8382\n",
      "2021-11-01 19:53:09.416160: validation loss: -0.8288\n",
      "2021-11-01 19:53:09.421736: Average global foreground Dice: [0.8454]\n",
      "2021-11-01 19:53:09.428880: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 19:53:09.896183: lr: 0.007067\n",
      "2021-11-01 19:53:09.955765: saving checkpoint...\n",
      "2021-11-01 19:53:11.193911: done, saving took 1.27 seconds\n",
      "2021-11-01 19:53:12.044702: This epoch took 298.930368 s\n",
      "\n",
      "2021-11-01 19:53:12.065044: \n",
      "epoch:  32\n",
      "2021-11-01 19:57:50.760041: train loss : -0.8400\n",
      "2021-11-01 19:58:08.353343: validation loss: -0.8224\n",
      "2021-11-01 19:58:08.357625: Average global foreground Dice: [0.8405]\n",
      "2021-11-01 19:58:08.365439: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 19:58:08.834966: lr: 0.006974\n",
      "2021-11-01 19:58:08.895530: saving checkpoint...\n",
      "2021-11-01 19:58:10.123004: done, saving took 1.26 seconds\n",
      "2021-11-01 19:58:10.799308: This epoch took 298.726296 s\n",
      "\n",
      "2021-11-01 19:58:10.819120: \n",
      "epoch:  33\n",
      "2021-11-01 20:02:49.604480: train loss : -0.8380\n",
      "2021-11-01 20:03:07.202081: validation loss: -0.8074\n",
      "2021-11-01 20:03:07.206191: Average global foreground Dice: [0.8321]\n",
      "2021-11-01 20:03:07.212949: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 20:03:07.685461: lr: 0.00688\n",
      "2021-11-01 20:03:07.747299: saving checkpoint...\n",
      "2021-11-01 20:03:08.988476: done, saving took 1.27 seconds\n",
      "2021-11-01 20:03:09.651470: This epoch took 298.824913 s\n",
      "\n",
      "2021-11-01 20:03:09.673595: \n",
      "epoch:  34\n",
      "2021-11-01 20:07:48.790591: train loss : -0.8447\n",
      "2021-11-01 20:08:06.523679: validation loss: -0.8188\n",
      "2021-11-01 20:08:06.529289: Average global foreground Dice: [0.8384]\n",
      "2021-11-01 20:08:06.536681: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 20:08:07.020320: lr: 0.006786\n",
      "2021-11-01 20:08:07.113641: saving checkpoint...\n",
      "2021-11-01 20:08:08.388527: done, saving took 1.33 seconds\n",
      "2021-11-01 20:08:08.993959: This epoch took 299.312315 s\n",
      "\n",
      "2021-11-01 20:08:09.014632: \n",
      "epoch:  35\n",
      "2021-11-01 20:12:47.927587: train loss : -0.8401\n",
      "2021-11-01 20:13:05.483121: validation loss: -0.8295\n",
      "2021-11-01 20:13:05.487481: Average global foreground Dice: [0.8457]\n",
      "2021-11-01 20:13:05.494718: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 20:13:05.970746: lr: 0.006692\n",
      "2021-11-01 20:13:06.035556: saving checkpoint...\n",
      "2021-11-01 20:13:07.263072: done, saving took 1.26 seconds\n",
      "2021-11-01 20:13:07.920283: This epoch took 298.897697 s\n",
      "\n",
      "2021-11-01 20:13:07.942259: \n",
      "epoch:  36\n",
      "2021-11-01 20:17:46.910633: train loss : -0.8401\n",
      "2021-11-01 20:18:04.340092: validation loss: -0.8129\n",
      "2021-11-01 20:18:04.344190: Average global foreground Dice: [0.8335]\n",
      "2021-11-01 20:18:04.351215: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 20:18:04.822703: lr: 0.006598\n",
      "2021-11-01 20:18:04.882404: saving checkpoint...\n",
      "2021-11-01 20:18:06.103418: done, saving took 1.25 seconds\n",
      "2021-11-01 20:18:06.764362: This epoch took 298.814420 s\n",
      "\n",
      "2021-11-01 20:18:06.785104: \n",
      "epoch:  37\n",
      "2021-11-01 20:22:45.718654: train loss : -0.8453\n",
      "2021-11-01 20:23:03.168897: validation loss: -0.8306\n",
      "2021-11-01 20:23:03.172686: Average global foreground Dice: [0.8479]\n",
      "2021-11-01 20:23:03.179434: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 20:23:03.650282: lr: 0.006504\n",
      "2021-11-01 20:23:03.713501: saving checkpoint...\n",
      "2021-11-01 20:23:04.939297: done, saving took 1.25 seconds\n",
      "2021-11-01 20:23:05.714016: This epoch took 298.921154 s\n",
      "\n",
      "2021-11-01 20:23:05.734830: \n",
      "epoch:  38\n",
      "2021-11-01 20:27:44.181484: train loss : -0.8478\n",
      "2021-11-01 20:28:01.683162: validation loss: -0.8232\n",
      "2021-11-01 20:28:01.687385: Average global foreground Dice: [0.8429]\n",
      "2021-11-01 20:28:01.694269: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 20:28:02.210778: lr: 0.006409\n",
      "2021-11-01 20:28:02.268831: saving checkpoint...\n",
      "2021-11-01 20:28:03.488766: done, saving took 1.25 seconds\n",
      "2021-11-01 20:28:04.124914: This epoch took 298.383169 s\n",
      "\n",
      "2021-11-01 20:28:04.144221: \n",
      "epoch:  39\n",
      "2021-11-01 20:32:42.723965: train loss : -0.8461\n",
      "2021-11-01 20:33:00.240644: validation loss: -0.8244\n",
      "2021-11-01 20:33:00.244345: Average global foreground Dice: [0.8424]\n",
      "2021-11-01 20:33:00.251499: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 20:33:00.727281: lr: 0.006314\n",
      "2021-11-01 20:33:00.812150: saving checkpoint...\n",
      "2021-11-01 20:33:02.050371: done, saving took 1.29 seconds\n",
      "2021-11-01 20:33:02.686437: This epoch took 298.534268 s\n",
      "\n",
      "2021-11-01 20:33:02.705077: \n",
      "epoch:  40\n",
      "2021-11-01 20:37:41.687176: train loss : -0.8466\n",
      "2021-11-01 20:37:59.439460: validation loss: -0.8282\n",
      "2021-11-01 20:37:59.443455: Average global foreground Dice: [0.8467]\n",
      "2021-11-01 20:37:59.449868: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 20:37:59.945617: lr: 0.00622\n",
      "2021-11-01 20:38:00.036849: saving checkpoint...\n",
      "2021-11-01 20:38:01.314252: done, saving took 1.33 seconds\n",
      "2021-11-01 20:38:02.020197: This epoch took 299.307591 s\n",
      "\n",
      "2021-11-01 20:38:02.039997: \n",
      "epoch:  41\n",
      "2021-11-01 20:42:40.714367: train loss : -0.8494\n",
      "2021-11-01 20:42:58.340271: validation loss: -0.8162\n",
      "2021-11-01 20:42:58.344231: Average global foreground Dice: [0.8407]\n",
      "2021-11-01 20:42:58.351066: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 20:42:58.826777: lr: 0.006125\n",
      "2021-11-01 20:42:58.894839: saving checkpoint...\n",
      "2021-11-01 20:43:00.127991: done, saving took 1.26 seconds\n",
      "2021-11-01 20:43:00.791803: This epoch took 298.745694 s\n",
      "\n",
      "2021-11-01 20:43:00.811977: \n",
      "epoch:  42\n",
      "2021-11-01 20:47:39.074412: train loss : -0.8471\n",
      "2021-11-01 20:47:56.592178: validation loss: -0.8016\n",
      "2021-11-01 20:47:56.596081: Average global foreground Dice: [0.829]\n",
      "2021-11-01 20:47:56.603070: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 20:47:57.099603: lr: 0.00603\n",
      "2021-11-01 20:47:57.132267: This epoch took 296.313060 s\n",
      "\n",
      "2021-11-01 20:47:57.140618: \n",
      "epoch:  43\n",
      "2021-11-01 20:52:35.968476: train loss : -0.8509\n",
      "2021-11-01 20:52:53.711998: validation loss: -0.8289\n",
      "2021-11-01 20:52:53.717719: Average global foreground Dice: [0.8467]\n",
      "2021-11-01 20:52:53.724792: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 20:52:54.205236: lr: 0.005934\n",
      "2021-11-01 20:52:54.310414: saving checkpoint...\n",
      "2021-11-01 20:52:55.550230: done, saving took 1.31 seconds\n",
      "2021-11-01 20:52:56.208210: This epoch took 299.059283 s\n",
      "\n",
      "2021-11-01 20:52:56.230994: \n",
      "epoch:  44\n",
      "2021-11-01 20:57:35.147865: train loss : -0.8515\n",
      "2021-11-01 20:57:52.901900: validation loss: -0.8329\n",
      "2021-11-01 20:57:52.907192: Average global foreground Dice: [0.8497]\n",
      "2021-11-01 20:57:52.916696: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 20:57:53.399168: lr: 0.005839\n",
      "2021-11-01 20:57:53.505198: saving checkpoint...\n",
      "2021-11-01 20:57:54.763630: done, saving took 1.33 seconds\n",
      "2021-11-01 20:57:55.401696: This epoch took 299.161493 s\n",
      "\n",
      "2021-11-01 20:57:55.418248: \n",
      "epoch:  45\n",
      "2021-11-01 21:02:34.498495: train loss : -0.8502\n",
      "2021-11-01 21:02:52.286133: validation loss: -0.8244\n",
      "2021-11-01 21:02:52.290023: Average global foreground Dice: [0.8459]\n",
      "2021-11-01 21:02:52.297501: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 21:02:52.787076: lr: 0.005743\n",
      "2021-11-01 21:02:52.894624: saving checkpoint...\n",
      "2021-11-01 21:02:54.145352: done, saving took 1.33 seconds\n",
      "2021-11-01 21:02:54.766422: This epoch took 299.340977 s\n",
      "\n",
      "2021-11-01 21:02:54.783690: \n",
      "epoch:  46\n",
      "2021-11-01 21:07:33.965051: train loss : -0.8546\n",
      "2021-11-01 21:07:51.697717: validation loss: -0.8269\n",
      "2021-11-01 21:07:51.702467: Average global foreground Dice: [0.8452]\n",
      "2021-11-01 21:07:51.709527: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 21:07:52.193592: lr: 0.005647\n",
      "2021-11-01 21:07:52.300448: saving checkpoint...\n",
      "2021-11-01 21:07:53.543539: done, saving took 1.31 seconds\n",
      "2021-11-01 21:07:54.219691: This epoch took 299.428781 s\n",
      "\n",
      "2021-11-01 21:07:54.237398: \n",
      "epoch:  47\n",
      "2021-11-01 21:12:29.206070: train loss : -0.8524\n",
      "2021-11-01 21:12:46.886441: validation loss: -0.8247\n",
      "2021-11-01 21:12:46.891203: Average global foreground Dice: [0.843]\n",
      "2021-11-01 21:12:46.898352: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 21:12:47.381544: lr: 0.005551\n",
      "2021-11-01 21:12:47.487707: saving checkpoint...\n",
      "2021-11-01 21:12:48.754649: done, saving took 1.34 seconds\n",
      "2021-11-01 21:12:49.445645: This epoch took 295.201365 s\n",
      "\n",
      "2021-11-01 21:12:49.466843: \n",
      "epoch:  48\n",
      "2021-11-01 21:17:25.491878: train loss : -0.8513\n",
      "2021-11-01 21:17:43.211693: validation loss: -0.8135\n",
      "2021-11-01 21:17:43.215661: Average global foreground Dice: [0.8324]\n",
      "2021-11-01 21:17:43.222524: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 21:17:43.704232: lr: 0.005455\n",
      "2021-11-01 21:17:43.738413: This epoch took 294.263295 s\n",
      "\n",
      "2021-11-01 21:17:43.745888: \n",
      "epoch:  49\n",
      "2021-11-01 21:22:19.914811: train loss : -0.8543\n",
      "2021-11-01 21:22:37.542820: validation loss: -0.8328\n",
      "2021-11-01 21:22:37.546820: Average global foreground Dice: [0.8501]\n",
      "2021-11-01 21:22:37.553830: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 21:22:38.038698: lr: 0.005359\n",
      "2021-11-01 21:22:38.074119: saving scheduled checkpoint file...\n",
      "2021-11-01 21:22:38.154607: saving checkpoint...\n",
      "2021-11-01 21:22:39.121469: done, saving took 1.04 seconds\n",
      "2021-11-01 21:22:39.889362: done\n",
      "2021-11-01 21:22:39.971215: saving checkpoint...\n",
      "2021-11-01 21:22:41.215255: done, saving took 1.31 seconds\n",
      "2021-11-01 21:22:41.880510: This epoch took 298.126853 s\n",
      "\n",
      "2021-11-01 21:22:41.900659: \n",
      "epoch:  50\n",
      "2021-11-01 21:27:19.426386: train loss : -0.8553\n",
      "2021-11-01 21:27:37.166320: validation loss: -0.8288\n",
      "2021-11-01 21:27:37.170603: Average global foreground Dice: [0.845]\n",
      "2021-11-01 21:27:37.178254: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 21:27:37.737973: lr: 0.005262\n",
      "2021-11-01 21:27:37.801809: saving checkpoint...\n",
      "2021-11-01 21:27:39.043825: done, saving took 1.27 seconds\n",
      "2021-11-01 21:27:39.683378: This epoch took 297.774342 s\n",
      "\n",
      "2021-11-01 21:27:39.702847: \n",
      "epoch:  51\n",
      "2021-11-01 21:32:17.435449: train loss : -0.8550\n",
      "2021-11-01 21:32:34.895912: validation loss: -0.8286\n",
      "2021-11-01 21:32:34.899758: Average global foreground Dice: [0.8468]\n",
      "2021-11-01 21:32:34.907362: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 21:32:35.382559: lr: 0.005166\n",
      "2021-11-01 21:32:35.449422: saving checkpoint...\n",
      "2021-11-01 21:32:36.693244: done, saving took 1.27 seconds\n",
      "2021-11-01 21:32:37.381098: This epoch took 297.670099 s\n",
      "\n",
      "2021-11-01 21:32:37.400904: \n",
      "epoch:  52\n",
      "2021-11-01 21:37:15.123851: train loss : -0.8551\n",
      "2021-11-01 21:37:32.591320: validation loss: -0.8341\n",
      "2021-11-01 21:37:32.596784: Average global foreground Dice: [0.8541]\n",
      "2021-11-01 21:37:32.604946: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 21:37:33.081061: lr: 0.005069\n",
      "2021-11-01 21:37:33.147556: saving checkpoint...\n",
      "2021-11-01 21:37:34.363966: done, saving took 1.24 seconds\n",
      "2021-11-01 21:37:34.996762: This epoch took 297.587826 s\n",
      "\n",
      "2021-11-01 21:37:35.015878: \n",
      "epoch:  53\n",
      "2021-11-01 21:42:12.538390: train loss : -0.8569\n",
      "2021-11-01 21:42:30.012697: validation loss: -0.8162\n",
      "2021-11-01 21:42:30.016603: Average global foreground Dice: [0.8375]\n",
      "2021-11-01 21:42:30.023979: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 21:42:30.502662: lr: 0.004971\n",
      "2021-11-01 21:42:30.537743: This epoch took 295.514474 s\n",
      "\n",
      "2021-11-01 21:42:30.545521: \n",
      "epoch:  54\n",
      "2021-11-01 21:47:08.413540: train loss : -0.8586\n",
      "2021-11-01 21:47:25.889259: validation loss: -0.8156\n",
      "2021-11-01 21:47:25.893191: Average global foreground Dice: [0.8343]\n",
      "2021-11-01 21:47:25.900777: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 21:47:26.374235: lr: 0.004874\n",
      "2021-11-01 21:47:26.408219: This epoch took 295.854998 s\n",
      "\n",
      "2021-11-01 21:47:26.416131: \n",
      "epoch:  55\n",
      "2021-11-01 21:52:04.113633: train loss : -0.8527\n",
      "2021-11-01 21:52:21.581633: validation loss: -0.8281\n",
      "2021-11-01 21:52:21.585104: Average global foreground Dice: [0.8428]\n",
      "2021-11-01 21:52:21.592014: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 21:52:22.065141: lr: 0.004776\n",
      "2021-11-01 21:52:22.102498: This epoch took 295.678576 s\n",
      "\n",
      "2021-11-01 21:52:22.110397: \n",
      "epoch:  56\n",
      "2021-11-01 21:57:00.358578: train loss : -0.8586\n",
      "2021-11-01 21:57:17.945698: validation loss: -0.8278\n",
      "2021-11-01 21:57:17.949952: Average global foreground Dice: [0.8455]\n",
      "2021-11-01 21:57:17.957128: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 21:57:18.431441: lr: 0.004679\n",
      "2021-11-01 21:57:18.470937: This epoch took 296.352866 s\n",
      "\n",
      "2021-11-01 21:57:18.478299: \n",
      "epoch:  57\n",
      "2021-11-01 22:01:57.448553: train loss : -0.8603\n",
      "2021-11-01 22:02:15.024642: validation loss: -0.8294\n",
      "2021-11-01 22:02:15.028960: Average global foreground Dice: [0.8454]\n",
      "2021-11-01 22:02:15.035552: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 22:02:15.508017: lr: 0.004581\n",
      "2021-11-01 22:02:15.545066: This epoch took 297.059139 s\n",
      "\n",
      "2021-11-01 22:02:15.552594: \n",
      "epoch:  58\n",
      "2021-11-01 22:06:54.254444: train loss : -0.8606\n",
      "2021-11-01 22:07:11.747018: validation loss: -0.8281\n",
      "2021-11-01 22:07:11.751635: Average global foreground Dice: [0.8476]\n",
      "2021-11-01 22:07:11.758369: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 22:07:12.233136: lr: 0.004482\n",
      "2021-11-01 22:07:12.298232: saving checkpoint...\n",
      "2021-11-01 22:07:13.536328: done, saving took 1.27 seconds\n",
      "2021-11-01 22:07:14.146434: This epoch took 298.586300 s\n",
      "\n",
      "2021-11-01 22:07:14.164949: \n",
      "epoch:  59\n",
      "2021-11-01 22:11:52.926737: train loss : -0.8638\n",
      "2021-11-01 22:12:10.502864: validation loss: -0.8223\n",
      "2021-11-01 22:12:10.507508: Average global foreground Dice: [0.8404]\n",
      "2021-11-01 22:12:10.515126: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 22:12:10.992733: lr: 0.004384\n",
      "2021-11-01 22:12:11.032828: This epoch took 296.861389 s\n",
      "\n",
      "2021-11-01 22:12:11.040816: \n",
      "epoch:  60\n",
      "2021-11-01 22:16:49.871971: train loss : -0.8590\n",
      "2021-11-01 22:17:07.485168: validation loss: -0.8303\n",
      "2021-11-01 22:17:07.489454: Average global foreground Dice: [0.846]\n",
      "2021-11-01 22:17:07.495671: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 22:17:07.972563: lr: 0.004285\n",
      "2021-11-01 22:17:08.043440: saving checkpoint...\n",
      "2021-11-01 22:17:09.259176: done, saving took 1.25 seconds\n",
      "2021-11-01 22:17:09.881742: This epoch took 298.833253 s\n",
      "\n",
      "2021-11-01 22:17:09.901779: \n",
      "epoch:  61\n",
      "2021-11-01 22:21:48.763706: train loss : -0.8615\n",
      "2021-11-01 22:22:06.270617: validation loss: -0.8312\n",
      "2021-11-01 22:22:06.275447: Average global foreground Dice: [0.8511]\n",
      "2021-11-01 22:22:06.282710: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 22:22:06.759669: lr: 0.004186\n",
      "2021-11-01 22:22:06.850361: saving checkpoint...\n",
      "2021-11-01 22:22:07.998832: done, saving took 1.21 seconds\n",
      "2021-11-01 22:22:08.609674: This epoch took 298.700672 s\n",
      "\n",
      "2021-11-01 22:22:08.629342: \n",
      "epoch:  62\n",
      "2021-11-01 22:26:43.717706: train loss : -0.8632\n",
      "2021-11-01 22:27:01.439377: validation loss: -0.8169\n",
      "2021-11-01 22:27:01.443428: Average global foreground Dice: [0.8404]\n",
      "2021-11-01 22:27:01.451051: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 22:27:01.933449: lr: 0.004087\n",
      "2021-11-01 22:27:01.977863: This epoch took 293.335616 s\n",
      "\n",
      "2021-11-01 22:27:01.986543: \n",
      "epoch:  63\n",
      "2021-11-01 22:31:39.868300: train loss : -0.8628\n",
      "2021-11-01 22:31:57.622668: validation loss: -0.8183\n",
      "2021-11-01 22:31:57.626530: Average global foreground Dice: [0.8356]\n",
      "2021-11-01 22:31:57.632854: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 22:31:58.120924: lr: 0.003987\n",
      "2021-11-01 22:31:58.159731: This epoch took 296.165821 s\n",
      "\n",
      "2021-11-01 22:31:58.166999: \n",
      "epoch:  64\n",
      "2021-11-01 22:36:37.155008: train loss : -0.8606\n",
      "2021-11-01 22:36:54.891616: validation loss: -0.8377\n",
      "2021-11-01 22:36:54.895487: Average global foreground Dice: [0.8529]\n",
      "2021-11-01 22:36:54.902612: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 22:36:55.391189: lr: 0.003887\n",
      "2021-11-01 22:36:55.425946: This epoch took 297.250415 s\n",
      "\n",
      "2021-11-01 22:36:55.433292: \n",
      "epoch:  65\n",
      "2021-11-01 22:41:34.547899: train loss : -0.8613\n",
      "2021-11-01 22:41:52.333688: validation loss: -0.8228\n",
      "2021-11-01 22:41:52.337586: Average global foreground Dice: [0.84]\n",
      "2021-11-01 22:41:52.344610: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 22:41:52.830285: lr: 0.003787\n",
      "2021-11-01 22:41:52.866017: This epoch took 297.425707 s\n",
      "\n",
      "2021-11-01 22:41:52.873725: \n",
      "epoch:  66\n",
      "2021-11-01 22:46:32.042881: train loss : -0.8629\n",
      "2021-11-01 22:46:49.660217: validation loss: -0.8254\n",
      "2021-11-01 22:46:49.664260: Average global foreground Dice: [0.8455]\n",
      "2021-11-01 22:46:49.671432: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 22:46:50.146175: lr: 0.003687\n",
      "2021-11-01 22:46:50.180256: This epoch took 297.299356 s\n",
      "\n",
      "2021-11-01 22:46:50.188315: \n",
      "epoch:  67\n",
      "2021-11-01 22:51:29.060205: train loss : -0.8638\n",
      "2021-11-01 22:51:46.493632: validation loss: -0.8315\n",
      "2021-11-01 22:51:46.497463: Average global foreground Dice: [0.8457]\n",
      "2021-11-01 22:51:46.504766: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 22:51:46.983936: lr: 0.003586\n",
      "2021-11-01 22:51:47.015768: This epoch took 296.820428 s\n",
      "\n",
      "2021-11-01 22:51:47.022204: \n",
      "epoch:  68\n",
      "2021-11-01 22:56:26.114560: train loss : -0.8647\n",
      "2021-11-01 22:56:43.572990: validation loss: -0.8302\n",
      "2021-11-01 22:56:43.577125: Average global foreground Dice: [0.8434]\n",
      "2021-11-01 22:56:43.584641: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 22:56:44.064350: lr: 0.003485\n",
      "2021-11-01 22:56:44.102369: This epoch took 297.072196 s\n",
      "\n",
      "2021-11-01 22:56:44.110623: \n",
      "epoch:  69\n",
      "2021-11-01 23:01:23.165512: train loss : -0.8639\n",
      "2021-11-01 23:01:40.742817: validation loss: -0.8235\n",
      "2021-11-01 23:01:40.746571: Average global foreground Dice: [0.8387]\n",
      "2021-11-01 23:01:40.753041: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 23:01:41.228886: lr: 0.003384\n",
      "2021-11-01 23:01:41.264250: This epoch took 297.146246 s\n",
      "\n",
      "2021-11-01 23:01:41.271706: \n",
      "epoch:  70\n",
      "2021-11-01 23:06:20.815711: train loss : -0.8659\n",
      "2021-11-01 23:06:38.547367: validation loss: -0.8204\n",
      "2021-11-01 23:06:38.551081: Average global foreground Dice: [0.8381]\n",
      "2021-11-01 23:06:38.559222: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 23:06:39.046433: lr: 0.003282\n",
      "2021-11-01 23:06:39.084422: This epoch took 297.805374 s\n",
      "\n",
      "2021-11-01 23:06:39.091962: \n",
      "epoch:  71\n",
      "2021-11-01 23:11:18.331794: train loss : -0.8670\n",
      "2021-11-01 23:11:36.077779: validation loss: -0.8199\n",
      "2021-11-01 23:11:36.081860: Average global foreground Dice: [0.8367]\n",
      "2021-11-01 23:11:36.088826: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 23:11:36.577400: lr: 0.00318\n",
      "2021-11-01 23:11:36.612322: This epoch took 297.513151 s\n",
      "\n",
      "2021-11-01 23:11:36.619813: \n",
      "epoch:  72\n",
      "2021-11-01 23:16:15.918783: train loss : -0.8629\n",
      "2021-11-01 23:16:33.666690: validation loss: -0.8423\n",
      "2021-11-01 23:16:33.670605: Average global foreground Dice: [0.8549]\n",
      "2021-11-01 23:16:33.677557: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 23:16:34.171595: lr: 0.003078\n",
      "2021-11-01 23:16:34.206689: This epoch took 297.576705 s\n",
      "\n",
      "2021-11-01 23:16:34.213445: \n",
      "epoch:  73\n",
      "2021-11-01 23:21:13.814510: train loss : -0.8655\n",
      "2021-11-01 23:21:31.562057: validation loss: -0.8259\n",
      "2021-11-01 23:21:31.566453: Average global foreground Dice: [0.8404]\n",
      "2021-11-01 23:21:31.572843: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 23:21:32.056483: lr: 0.002975\n",
      "2021-11-01 23:21:32.091145: This epoch took 297.870043 s\n",
      "\n",
      "2021-11-01 23:21:32.099090: \n",
      "epoch:  74\n",
      "2021-11-01 23:26:11.406961: train loss : -0.8678\n",
      "2021-11-01 23:26:29.216839: validation loss: -0.8183\n",
      "2021-11-01 23:26:29.220436: Average global foreground Dice: [0.8384]\n",
      "2021-11-01 23:26:29.227238: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 23:26:29.721312: lr: 0.002872\n",
      "2021-11-01 23:26:29.755787: This epoch took 297.649585 s\n",
      "\n",
      "2021-11-01 23:26:29.763146: \n",
      "epoch:  75\n",
      "2021-11-01 23:31:08.918161: train loss : -0.8647\n",
      "2021-11-01 23:31:26.670521: validation loss: -0.8388\n",
      "2021-11-01 23:31:26.674002: Average global foreground Dice: [0.8532]\n",
      "2021-11-01 23:31:26.681099: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 23:31:27.173658: lr: 0.002768\n",
      "2021-11-01 23:31:27.201148: This epoch took 297.430651 s\n",
      "\n",
      "2021-11-01 23:31:27.208855: \n",
      "epoch:  76\n",
      "2021-11-01 23:36:05.672178: train loss : -0.8670\n",
      "2021-11-01 23:36:23.413906: validation loss: -0.8407\n",
      "2021-11-01 23:36:23.417660: Average global foreground Dice: [0.8506]\n",
      "2021-11-01 23:36:23.424597: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 23:36:23.981924: lr: 0.002664\n",
      "2021-11-01 23:36:24.044182: saving checkpoint...\n",
      "2021-11-01 23:36:25.456794: done, saving took 1.44 seconds\n",
      "2021-11-01 23:36:26.118829: This epoch took 298.902476 s\n",
      "\n",
      "2021-11-01 23:36:26.137564: \n",
      "epoch:  77\n",
      "2021-11-01 23:41:04.629984: train loss : -0.8653\n",
      "2021-11-01 23:41:22.184584: validation loss: -0.8249\n",
      "2021-11-01 23:41:22.188449: Average global foreground Dice: [0.8389]\n",
      "2021-11-01 23:41:22.195634: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 23:41:22.681154: lr: 0.00256\n",
      "2021-11-01 23:41:22.717879: This epoch took 296.571988 s\n",
      "\n",
      "2021-11-01 23:41:22.726125: \n",
      "epoch:  78\n",
      "2021-11-01 23:46:01.363330: train loss : -0.8666\n",
      "2021-11-01 23:46:18.817920: validation loss: -0.8230\n",
      "2021-11-01 23:46:18.821821: Average global foreground Dice: [0.842]\n",
      "2021-11-01 23:46:18.828566: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 23:46:19.352985: lr: 0.002455\n",
      "2021-11-01 23:46:19.391479: This epoch took 296.657062 s\n",
      "\n",
      "2021-11-01 23:46:19.399272: \n",
      "epoch:  79\n",
      "2021-11-01 23:50:58.384481: train loss : -0.8689\n",
      "2021-11-01 23:51:15.899312: validation loss: -0.8285\n",
      "2021-11-01 23:51:15.904876: Average global foreground Dice: [0.8456]\n",
      "2021-11-01 23:51:15.911748: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 23:51:16.392859: lr: 0.002349\n",
      "2021-11-01 23:51:16.424468: This epoch took 297.016907 s\n",
      "\n",
      "2021-11-01 23:51:16.433087: \n",
      "epoch:  80\n",
      "2021-11-01 23:55:55.056905: train loss : -0.8709\n",
      "2021-11-01 23:56:12.553699: validation loss: -0.8425\n",
      "2021-11-01 23:56:12.557695: Average global foreground Dice: [0.8537]\n",
      "2021-11-01 23:56:12.565233: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-01 23:56:13.047216: lr: 0.002243\n",
      "2021-11-01 23:56:13.143782: saving checkpoint...\n",
      "2021-11-01 23:56:14.398369: done, saving took 1.32 seconds\n",
      "2021-11-01 23:56:15.057997: This epoch took 298.617487 s\n",
      "\n",
      "2021-11-01 23:56:15.070032: \n",
      "epoch:  81\n",
      "2021-11-02 00:00:53.968963: train loss : -0.8688\n",
      "2021-11-02 00:01:11.687665: validation loss: -0.8295\n",
      "2021-11-02 00:01:11.691537: Average global foreground Dice: [0.8418]\n",
      "2021-11-02 00:01:11.698159: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 00:01:12.236972: lr: 0.002137\n",
      "2021-11-02 00:01:12.256328: This epoch took 297.179543 s\n",
      "\n",
      "2021-11-02 00:01:12.264350: \n",
      "epoch:  82\n",
      "2021-11-02 00:05:50.811510: train loss : -0.8698\n",
      "2021-11-02 00:06:08.533101: validation loss: -0.8284\n",
      "2021-11-02 00:06:08.537107: Average global foreground Dice: [0.8445]\n",
      "2021-11-02 00:06:08.544063: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 00:06:09.024612: lr: 0.00203\n",
      "2021-11-02 00:06:09.044176: This epoch took 296.772257 s\n",
      "\n",
      "2021-11-02 00:06:09.051327: \n",
      "epoch:  83\n",
      "2021-11-02 00:10:47.878292: train loss : -0.8727\n",
      "2021-11-02 00:11:05.610854: validation loss: -0.8241\n",
      "2021-11-02 00:11:05.614854: Average global foreground Dice: [0.839]\n",
      "2021-11-02 00:11:05.622063: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 00:11:06.103709: lr: 0.001922\n",
      "2021-11-02 00:11:06.123279: This epoch took 297.065075 s\n",
      "\n",
      "2021-11-02 00:11:06.132059: \n",
      "epoch:  84\n",
      "2021-11-02 00:15:45.438753: train loss : -0.8689\n",
      "2021-11-02 00:16:02.990134: validation loss: -0.8331\n",
      "2021-11-02 00:16:02.993721: Average global foreground Dice: [0.8468]\n",
      "2021-11-02 00:16:03.001173: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 00:16:03.466564: lr: 0.001813\n",
      "2021-11-02 00:16:03.486238: This epoch took 297.346449 s\n",
      "\n",
      "2021-11-02 00:16:03.493410: \n",
      "epoch:  85\n",
      "2021-11-02 00:20:42.599897: train loss : -0.8728\n",
      "2021-11-02 00:21:00.086300: validation loss: -0.8198\n",
      "2021-11-02 00:21:00.090709: Average global foreground Dice: [0.8369]\n",
      "2021-11-02 00:21:00.098142: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 00:21:00.570852: lr: 0.001704\n",
      "2021-11-02 00:21:00.591272: This epoch took 297.090482 s\n",
      "\n",
      "2021-11-02 00:21:00.599719: \n",
      "epoch:  86\n",
      "2021-11-02 00:25:39.293353: train loss : -0.8702\n",
      "2021-11-02 00:25:56.720585: validation loss: -0.8241\n",
      "2021-11-02 00:25:56.726044: Average global foreground Dice: [0.8394]\n",
      "2021-11-02 00:25:56.733026: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 00:25:57.254867: lr: 0.001594\n",
      "2021-11-02 00:25:57.273086: This epoch took 296.665432 s\n",
      "\n",
      "2021-11-02 00:25:57.280921: \n",
      "epoch:  87\n",
      "2021-11-02 00:30:35.901780: train loss : -0.8721\n",
      "2021-11-02 00:30:53.441158: validation loss: -0.8147\n",
      "2021-11-02 00:30:53.444990: Average global foreground Dice: [0.8319]\n",
      "2021-11-02 00:30:53.452946: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 00:30:53.927912: lr: 0.001483\n",
      "2021-11-02 00:30:53.946529: This epoch took 296.657615 s\n",
      "\n",
      "2021-11-02 00:30:53.953624: \n",
      "epoch:  88\n",
      "2021-11-02 00:35:32.510731: train loss : -0.8726\n",
      "2021-11-02 00:35:50.027798: validation loss: -0.8233\n",
      "2021-11-02 00:35:50.031774: Average global foreground Dice: [0.8394]\n",
      "2021-11-02 00:35:50.039040: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 00:35:50.515513: lr: 0.001372\n",
      "2021-11-02 00:35:50.532695: This epoch took 296.571435 s\n",
      "\n",
      "2021-11-02 00:35:50.539119: \n",
      "epoch:  89\n",
      "2021-11-02 00:40:29.129117: train loss : -0.8730\n",
      "2021-11-02 00:40:46.868586: validation loss: -0.8199\n",
      "2021-11-02 00:40:46.872079: Average global foreground Dice: [0.8384]\n",
      "2021-11-02 00:40:46.880181: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 00:40:47.364202: lr: 0.001259\n",
      "2021-11-02 00:40:47.381950: This epoch took 296.836172 s\n",
      "\n",
      "2021-11-02 00:40:47.389611: \n",
      "epoch:  90\n",
      "2021-11-02 00:45:26.124483: train loss : -0.8746\n",
      "2021-11-02 00:45:43.923331: validation loss: -0.8239\n",
      "2021-11-02 00:45:43.927223: Average global foreground Dice: [0.8375]\n",
      "2021-11-02 00:45:43.933967: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 00:45:44.420547: lr: 0.001145\n",
      "2021-11-02 00:45:44.439349: This epoch took 297.042368 s\n",
      "\n",
      "2021-11-02 00:45:44.447460: \n",
      "epoch:  91\n",
      "2021-11-02 00:50:23.199358: train loss : -0.8739\n",
      "2021-11-02 00:50:40.927751: validation loss: -0.8361\n",
      "2021-11-02 00:50:40.931857: Average global foreground Dice: [0.8478]\n",
      "2021-11-02 00:50:40.938403: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 00:50:41.424244: lr: 0.00103\n",
      "2021-11-02 00:50:41.442416: This epoch took 296.986627 s\n",
      "\n",
      "2021-11-02 00:50:41.450408: \n",
      "epoch:  92\n",
      "2021-11-02 00:55:03.857700: train loss : -0.8704\n",
      "2021-11-02 00:55:20.343348: validation loss: -0.8326\n",
      "2021-11-02 00:55:20.347208: Average global foreground Dice: [0.8483]\n",
      "2021-11-02 00:55:20.353586: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 00:55:20.847768: lr: 0.000913\n",
      "2021-11-02 00:55:20.866447: This epoch took 279.408506 s\n",
      "\n",
      "2021-11-02 00:55:20.873426: \n",
      "epoch:  93\n",
      "2021-11-02 00:59:48.000918: train loss : -0.8739\n",
      "2021-11-02 01:00:05.622107: validation loss: -0.8203\n",
      "2021-11-02 01:00:05.626613: Average global foreground Dice: [0.834]\n",
      "2021-11-02 01:00:05.633319: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 01:00:06.126977: lr: 0.000795\n",
      "2021-11-02 01:00:06.164314: This epoch took 285.283182 s\n",
      "\n",
      "2021-11-02 01:00:06.171689: \n",
      "epoch:  94\n",
      "2021-11-02 01:04:43.730238: train loss : -0.8745\n",
      "2021-11-02 01:05:01.346519: validation loss: -0.8400\n",
      "2021-11-02 01:05:01.351214: Average global foreground Dice: [0.8521]\n",
      "2021-11-02 01:05:01.358744: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 01:05:01.852166: lr: 0.000675\n",
      "2021-11-02 01:05:01.886583: This epoch took 295.707185 s\n",
      "\n",
      "2021-11-02 01:05:01.892809: \n",
      "epoch:  95\n",
      "2021-11-02 01:09:39.512441: train loss : -0.8734\n",
      "2021-11-02 01:09:57.056719: validation loss: -0.8318\n",
      "2021-11-02 01:09:57.060776: Average global foreground Dice: [0.848]\n",
      "2021-11-02 01:09:57.067621: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 01:09:57.542364: lr: 0.000552\n",
      "2021-11-02 01:09:57.581026: This epoch took 295.680018 s\n",
      "\n",
      "2021-11-02 01:09:57.587303: \n",
      "epoch:  96\n",
      "2021-11-02 01:14:34.508975: train loss : -0.8744\n",
      "2021-11-02 01:14:51.819224: validation loss: -0.8275\n",
      "2021-11-02 01:14:51.823138: Average global foreground Dice: [0.8404]\n",
      "2021-11-02 01:14:51.831198: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 01:14:52.313624: lr: 0.000426\n",
      "2021-11-02 01:14:52.348099: This epoch took 294.754173 s\n",
      "\n",
      "2021-11-02 01:14:52.355774: \n",
      "epoch:  97\n",
      "2021-11-02 01:19:29.800122: train loss : -0.8770\n",
      "2021-11-02 01:19:47.110487: validation loss: -0.8347\n",
      "2021-11-02 01:19:47.113822: Average global foreground Dice: [0.8444]\n",
      "2021-11-02 01:19:47.120809: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 01:19:47.602973: lr: 0.000296\n",
      "2021-11-02 01:19:47.639703: This epoch took 295.276793 s\n",
      "\n",
      "2021-11-02 01:19:47.646518: \n",
      "epoch:  98\n",
      "2021-11-02 01:24:25.152357: train loss : -0.8779\n",
      "2021-11-02 01:24:42.675805: validation loss: -0.8276\n",
      "2021-11-02 01:24:42.679672: Average global foreground Dice: [0.8436]\n",
      "2021-11-02 01:24:42.685617: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 01:24:43.165642: lr: 0.000158\n",
      "2021-11-02 01:24:43.197826: This epoch took 295.543711 s\n",
      "\n",
      "2021-11-02 01:24:43.205439: \n",
      "epoch:  99\n",
      "2021-11-02 01:29:19.732171: train loss : -0.8747\n",
      "2021-11-02 01:29:37.063461: validation loss: -0.8290\n",
      "2021-11-02 01:29:37.069302: Average global foreground Dice: [0.8447]\n",
      "2021-11-02 01:29:37.079194: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 01:29:37.562562: lr: 0.0\n",
      "2021-11-02 01:29:37.595617: saving scheduled checkpoint file...\n",
      "2021-11-02 01:29:37.670253: saving checkpoint...\n",
      "2021-11-02 01:29:38.923173: done, saving took 1.32 seconds\n",
      "2021-11-02 01:29:39.542245: done\n",
      "2021-11-02 01:29:39.562155: This epoch took 296.349627 s\n",
      "\n",
      "2021-11-02 01:29:39.643561: saving checkpoint...\n",
      "2021-11-02 01:29:40.610432: done, saving took 1.04 seconds\n",
      "23090566_20141114 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090571_20120517 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131226 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160308 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131025 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090596_20150112 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120619 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090608_20120718 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151210 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121213 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090616_20140331 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090619_20121210 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090629_20120830 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090636_20121018 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150522 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-02 01:32:59.780551: finished prediction\n",
      "2021-11-02 01:32:59.791353: evaluation of raw predictions\n",
      "2021-11-02 01:33:01.755220: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.840129865793885\n",
      "after:  0.840129865793885\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-02 01:33:14.622874: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-02 01:33:14.645153: The split file contains 5 splits.\n",
      "2021-11-02 01:33:14.651493: Desired fold for training: 3\n",
      "2021-11-02 01:33:14.657913: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-02 01:33:18.988189: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-02 01:33:24.438990: Unable to plot network architecture:\n",
      "2021-11-02 01:33:24.442376: No module named 'hiddenlayer'\n",
      "2021-11-02 01:33:24.448154: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-02 01:33:24.454949: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-02 01:33:24.541182: \n",
      "\n",
      "2021-11-02 01:33:24.547482: \n",
      "epoch:  0\n",
      "2021-11-02 01:38:26.618260: train loss : -0.2289\n",
      "2021-11-02 01:38:44.350410: validation loss: -0.6110\n",
      "2021-11-02 01:38:44.354553: Average global foreground Dice: [0.6687]\n",
      "2021-11-02 01:38:44.361157: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 01:38:44.774075: lr: 0.00991\n",
      "2021-11-02 01:38:44.807139: This epoch took 320.252860 s\n",
      "\n",
      "2021-11-02 01:38:44.814020: \n",
      "epoch:  1\n",
      "2021-11-02 01:43:21.370426: train loss : -0.6150\n",
      "2021-11-02 01:43:39.123007: validation loss: -0.6383\n",
      "2021-11-02 01:43:39.127324: Average global foreground Dice: [0.687]\n",
      "2021-11-02 01:43:39.133811: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 01:43:39.612535: lr: 0.00982\n",
      "2021-11-02 01:43:39.715310: saving checkpoint...\n",
      "2021-11-02 01:43:40.683777: done, saving took 1.04 seconds\n",
      "2021-11-02 01:43:41.369182: This epoch took 296.548584 s\n",
      "\n",
      "2021-11-02 01:43:41.389886: \n",
      "epoch:  2\n",
      "2021-11-02 01:48:16.694778: train loss : -0.6848\n",
      "2021-11-02 01:48:34.574936: validation loss: -0.7331\n",
      "2021-11-02 01:48:34.578941: Average global foreground Dice: [0.7657]\n",
      "2021-11-02 01:48:34.585403: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 01:48:35.081880: lr: 0.00973\n",
      "2021-11-02 01:48:35.184035: saving checkpoint...\n",
      "2021-11-02 01:48:36.314183: done, saving took 1.20 seconds\n",
      "2021-11-02 01:48:36.986027: This epoch took 295.588615 s\n",
      "\n",
      "2021-11-02 01:48:37.004141: \n",
      "epoch:  3\n",
      "2021-11-02 01:53:11.737408: train loss : -0.7154\n",
      "2021-11-02 01:53:29.481852: validation loss: -0.7473\n",
      "2021-11-02 01:53:29.485872: Average global foreground Dice: [0.7769]\n",
      "2021-11-02 01:53:29.491949: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 01:53:29.980569: lr: 0.009639\n",
      "2021-11-02 01:53:30.083742: saving checkpoint...\n",
      "2021-11-02 01:53:31.389422: done, saving took 1.38 seconds\n",
      "2021-11-02 01:53:32.032557: This epoch took 295.021186 s\n",
      "\n",
      "2021-11-02 01:53:32.054514: \n",
      "epoch:  4\n",
      "2021-11-02 01:58:07.282097: train loss : -0.7397\n",
      "2021-11-02 01:58:24.855291: validation loss: -0.7653\n",
      "2021-11-02 01:58:24.859679: Average global foreground Dice: [0.8001]\n",
      "2021-11-02 01:58:24.868106: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 01:58:25.343820: lr: 0.009549\n",
      "2021-11-02 01:58:25.445423: saving checkpoint...\n",
      "2021-11-02 01:58:26.741628: done, saving took 1.37 seconds\n",
      "2021-11-02 01:58:27.455373: This epoch took 295.393367 s\n",
      "\n",
      "2021-11-02 01:58:27.470102: \n",
      "epoch:  5\n",
      "2021-11-02 02:03:02.688072: train loss : -0.7589\n",
      "2021-11-02 02:03:20.421156: validation loss: -0.7804\n",
      "2021-11-02 02:03:20.425293: Average global foreground Dice: [0.8128]\n",
      "2021-11-02 02:03:20.432112: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 02:03:20.922126: lr: 0.009458\n",
      "2021-11-02 02:03:21.025406: saving checkpoint...\n",
      "2021-11-02 02:03:22.269526: done, saving took 1.32 seconds\n",
      "2021-11-02 02:03:22.896120: This epoch took 295.418713 s\n",
      "\n",
      "2021-11-02 02:03:22.916418: \n",
      "epoch:  6\n",
      "2021-11-02 02:07:58.215567: train loss : -0.7628\n",
      "2021-11-02 02:08:16.021604: validation loss: -0.7899\n",
      "2021-11-02 02:08:16.025180: Average global foreground Dice: [0.8273]\n",
      "2021-11-02 02:08:16.030737: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 02:08:16.516232: lr: 0.009368\n",
      "2021-11-02 02:08:16.621172: saving checkpoint...\n",
      "2021-11-02 02:08:17.776755: done, saving took 1.23 seconds\n",
      "2021-11-02 02:08:18.387132: This epoch took 295.463556 s\n",
      "\n",
      "2021-11-02 02:08:18.408828: \n",
      "epoch:  7\n",
      "2021-11-02 02:12:53.596561: train loss : -0.7791\n",
      "2021-11-02 02:13:11.339551: validation loss: -0.7943\n",
      "2021-11-02 02:13:11.343355: Average global foreground Dice: [0.8323]\n",
      "2021-11-02 02:13:11.350068: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 02:13:11.850856: lr: 0.009277\n",
      "2021-11-02 02:13:11.955192: saving checkpoint...\n",
      "2021-11-02 02:13:13.159347: done, saving took 1.28 seconds\n",
      "2021-11-02 02:13:13.745180: This epoch took 295.329712 s\n",
      "\n",
      "2021-11-02 02:13:13.764629: \n",
      "epoch:  8\n",
      "2021-11-02 02:17:49.206959: train loss : -0.7825\n",
      "2021-11-02 02:18:06.775065: validation loss: -0.8061\n",
      "2021-11-02 02:18:06.778903: Average global foreground Dice: [0.8352]\n",
      "2021-11-02 02:18:06.785500: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 02:18:07.270772: lr: 0.009186\n",
      "2021-11-02 02:18:07.365902: saving checkpoint...\n",
      "2021-11-02 02:18:08.608854: done, saving took 1.31 seconds\n",
      "2021-11-02 02:18:09.253171: This epoch took 295.481166 s\n",
      "\n",
      "2021-11-02 02:18:09.274752: \n",
      "epoch:  9\n",
      "2021-11-02 02:22:45.314359: train loss : -0.7900\n",
      "2021-11-02 02:23:02.951625: validation loss: -0.8121\n",
      "2021-11-02 02:23:02.955512: Average global foreground Dice: [0.8421]\n",
      "2021-11-02 02:23:02.962631: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 02:23:03.434134: lr: 0.009095\n",
      "2021-11-02 02:23:03.519266: saving checkpoint...\n",
      "2021-11-02 02:23:04.706936: done, saving took 1.24 seconds\n",
      "2021-11-02 02:23:05.316285: This epoch took 296.034109 s\n",
      "\n",
      "2021-11-02 02:23:05.335971: \n",
      "epoch:  10\n",
      "2021-11-02 02:27:40.783822: train loss : -0.8046\n",
      "2021-11-02 02:27:58.543916: validation loss: -0.8264\n",
      "2021-11-02 02:27:58.547620: Average global foreground Dice: [0.8501]\n",
      "2021-11-02 02:27:58.554472: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 02:27:59.057723: lr: 0.009004\n",
      "2021-11-02 02:27:59.165767: saving checkpoint...\n",
      "2021-11-02 02:28:00.410727: done, saving took 1.32 seconds\n",
      "2021-11-02 02:28:01.044980: This epoch took 295.702242 s\n",
      "\n",
      "2021-11-02 02:28:01.063182: \n",
      "epoch:  11\n",
      "2021-11-02 02:32:37.297748: train loss : -0.8028\n",
      "2021-11-02 02:32:55.023446: validation loss: -0.7971\n",
      "2021-11-02 02:32:55.027401: Average global foreground Dice: [0.8272]\n",
      "2021-11-02 02:32:55.034401: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 02:32:55.526517: lr: 0.008913\n",
      "2021-11-02 02:32:55.634636: saving checkpoint...\n",
      "2021-11-02 02:32:56.866744: done, saving took 1.30 seconds\n",
      "2021-11-02 02:32:57.510330: This epoch took 296.440115 s\n",
      "\n",
      "2021-11-02 02:32:57.528302: \n",
      "epoch:  12\n",
      "2021-11-02 02:37:33.989002: train loss : -0.8064\n",
      "2021-11-02 02:37:51.756123: validation loss: -0.8274\n",
      "2021-11-02 02:37:51.760223: Average global foreground Dice: [0.8515]\n",
      "2021-11-02 02:37:51.767274: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 02:37:52.268175: lr: 0.008822\n",
      "2021-11-02 02:37:52.367650: saving checkpoint...\n",
      "2021-11-02 02:37:53.623469: done, saving took 1.32 seconds\n",
      "2021-11-02 02:37:54.255382: This epoch took 296.719137 s\n",
      "\n",
      "2021-11-02 02:37:54.274438: \n",
      "epoch:  13\n",
      "2021-11-02 02:42:30.210378: train loss : -0.8020\n",
      "2021-11-02 02:42:47.859691: validation loss: -0.8219\n",
      "2021-11-02 02:42:47.865055: Average global foreground Dice: [0.8483]\n",
      "2021-11-02 02:42:47.872034: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 02:42:48.352976: lr: 0.008731\n",
      "2021-11-02 02:42:48.444041: saving checkpoint...\n",
      "2021-11-02 02:42:49.680630: done, saving took 1.30 seconds\n",
      "2021-11-02 02:42:50.293139: This epoch took 296.012403 s\n",
      "\n",
      "2021-11-02 02:42:50.301430: \n",
      "epoch:  14\n",
      "2021-11-02 02:47:26.540340: train loss : -0.8117\n",
      "2021-11-02 02:47:44.305560: validation loss: -0.8221\n",
      "2021-11-02 02:47:44.309802: Average global foreground Dice: [0.8431]\n",
      "2021-11-02 02:47:44.317126: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 02:47:44.815914: lr: 0.008639\n",
      "2021-11-02 02:47:44.890252: saving checkpoint...\n",
      "2021-11-02 02:47:45.997555: done, saving took 1.16 seconds\n",
      "2021-11-02 02:47:46.613913: This epoch took 296.304549 s\n",
      "\n",
      "2021-11-02 02:47:46.623007: \n",
      "epoch:  15\n",
      "2021-11-02 02:52:23.192855: train loss : -0.8168\n",
      "2021-11-02 02:52:40.925062: validation loss: -0.8259\n",
      "2021-11-02 02:52:40.929250: Average global foreground Dice: [0.8508]\n",
      "2021-11-02 02:52:40.935881: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 02:52:41.435119: lr: 0.008548\n",
      "2021-11-02 02:52:41.521161: saving checkpoint...\n",
      "2021-11-02 02:52:42.739663: done, saving took 1.28 seconds\n",
      "2021-11-02 02:52:43.383402: This epoch took 296.753342 s\n",
      "\n",
      "2021-11-02 02:52:43.403657: \n",
      "epoch:  16\n",
      "2021-11-02 02:57:21.124157: train loss : -0.8196\n",
      "2021-11-02 02:57:38.880118: validation loss: -0.8347\n",
      "2021-11-02 02:57:38.883614: Average global foreground Dice: [0.8547]\n",
      "2021-11-02 02:57:38.891469: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 02:57:39.394212: lr: 0.008456\n",
      "2021-11-02 02:57:39.483361: saving checkpoint...\n",
      "2021-11-02 02:57:40.697140: done, saving took 1.29 seconds\n",
      "2021-11-02 02:57:41.332076: This epoch took 297.921839 s\n",
      "\n",
      "2021-11-02 02:57:41.341189: \n",
      "epoch:  17\n",
      "2021-11-02 03:02:19.080763: train loss : -0.8168\n",
      "2021-11-02 03:02:36.705794: validation loss: -0.8329\n",
      "2021-11-02 03:02:36.710234: Average global foreground Dice: [0.8517]\n",
      "2021-11-02 03:02:36.717339: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 03:02:37.201841: lr: 0.008364\n",
      "2021-11-02 03:02:37.308955: saving checkpoint...\n",
      "2021-11-02 03:02:38.447814: done, saving took 1.21 seconds\n",
      "2021-11-02 03:02:39.077790: This epoch took 297.729461 s\n",
      "\n",
      "2021-11-02 03:02:39.099103: \n",
      "epoch:  18\n",
      "2021-11-02 03:07:16.667463: train loss : -0.8223\n",
      "2021-11-02 03:07:34.392304: validation loss: -0.8244\n",
      "2021-11-02 03:07:34.395998: Average global foreground Dice: [0.8425]\n",
      "2021-11-02 03:07:34.401421: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 03:07:34.894293: lr: 0.008272\n",
      "2021-11-02 03:07:34.995155: saving checkpoint...\n",
      "2021-11-02 03:07:36.117306: done, saving took 1.19 seconds\n",
      "2021-11-02 03:07:36.765583: This epoch took 297.657859 s\n",
      "\n",
      "2021-11-02 03:07:36.784513: \n",
      "epoch:  19\n",
      "2021-11-02 03:12:14.941122: train loss : -0.8158\n",
      "2021-11-02 03:12:32.700166: validation loss: -0.8254\n",
      "2021-11-02 03:12:32.703761: Average global foreground Dice: [0.8431]\n",
      "2021-11-02 03:12:32.710450: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 03:12:33.202937: lr: 0.008181\n",
      "2021-11-02 03:12:33.307468: saving checkpoint...\n",
      "2021-11-02 03:12:34.440320: done, saving took 1.21 seconds\n",
      "2021-11-02 03:12:35.091109: This epoch took 298.299789 s\n",
      "\n",
      "2021-11-02 03:12:35.110339: \n",
      "epoch:  20\n",
      "2021-11-02 03:17:13.147330: train loss : -0.8178\n",
      "2021-11-02 03:17:30.728679: validation loss: -0.8226\n",
      "2021-11-02 03:17:30.733499: Average global foreground Dice: [0.8453]\n",
      "2021-11-02 03:17:30.741646: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 03:17:31.221398: lr: 0.008088\n",
      "2021-11-02 03:17:31.311284: saving checkpoint...\n",
      "2021-11-02 03:17:32.437198: done, saving took 1.18 seconds\n",
      "2021-11-02 03:17:33.114669: This epoch took 297.996369 s\n",
      "\n",
      "2021-11-02 03:17:33.134101: \n",
      "epoch:  21\n",
      "2021-11-02 03:22:11.138401: train loss : -0.8217\n",
      "2021-11-02 03:22:28.884597: validation loss: -0.8342\n",
      "2021-11-02 03:22:28.888395: Average global foreground Dice: [0.8546]\n",
      "2021-11-02 03:22:28.895239: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 03:22:29.377482: lr: 0.007996\n",
      "2021-11-02 03:22:29.480065: saving checkpoint...\n",
      "2021-11-02 03:22:30.677177: done, saving took 1.27 seconds\n",
      "2021-11-02 03:22:31.129872: This epoch took 297.986355 s\n",
      "\n",
      "2021-11-02 03:22:31.146679: \n",
      "epoch:  22\n",
      "2021-11-02 03:27:05.864447: train loss : -0.8247\n",
      "2021-11-02 03:27:23.321285: validation loss: -0.8212\n",
      "2021-11-02 03:27:23.324943: Average global foreground Dice: [0.8343]\n",
      "2021-11-02 03:27:23.331351: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 03:27:23.813798: lr: 0.007904\n",
      "2021-11-02 03:27:23.918195: saving checkpoint...\n",
      "2021-11-02 03:27:25.067903: done, saving took 1.22 seconds\n",
      "2021-11-02 03:27:25.681765: This epoch took 294.527056 s\n",
      "\n",
      "2021-11-02 03:27:25.699327: \n",
      "epoch:  23\n",
      "2021-11-02 03:32:03.126190: train loss : -0.8285\n",
      "2021-11-02 03:32:20.860259: validation loss: -0.8343\n",
      "2021-11-02 03:32:20.866405: Average global foreground Dice: [0.8556]\n",
      "2021-11-02 03:32:20.872685: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 03:32:21.364229: lr: 0.007811\n",
      "2021-11-02 03:32:21.470792: saving checkpoint...\n",
      "2021-11-02 03:32:22.605761: done, saving took 1.21 seconds\n",
      "2021-11-02 03:32:23.253610: This epoch took 297.546005 s\n",
      "\n",
      "2021-11-02 03:32:23.273178: \n",
      "epoch:  24\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-02 03:37:01.664420: train loss : -0.8222\n",
      "2021-11-02 03:37:19.430771: validation loss: -0.8286\n",
      "2021-11-02 03:37:19.434860: Average global foreground Dice: [0.8491]\n",
      "2021-11-02 03:37:19.441933: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 03:37:19.944151: lr: 0.007719\n",
      "2021-11-02 03:37:20.044910: saving checkpoint...\n",
      "2021-11-02 03:37:21.188518: done, saving took 1.21 seconds\n",
      "2021-11-02 03:37:21.836926: This epoch took 298.556218 s\n",
      "\n",
      "2021-11-02 03:37:21.854446: \n",
      "epoch:  25\n",
      "2021-11-02 03:41:59.901189: train loss : -0.8265\n",
      "2021-11-02 03:42:17.663710: validation loss: -0.8249\n",
      "2021-11-02 03:42:17.667526: Average global foreground Dice: [0.8463]\n",
      "2021-11-02 03:42:17.675091: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 03:42:18.174705: lr: 0.007626\n",
      "2021-11-02 03:42:18.256502: saving checkpoint...\n",
      "2021-11-02 03:42:19.377996: done, saving took 1.18 seconds\n",
      "2021-11-02 03:42:20.065145: This epoch took 298.203592 s\n",
      "\n",
      "2021-11-02 03:42:20.076866: \n",
      "epoch:  26\n",
      "2021-11-02 03:46:58.281373: train loss : -0.8270\n",
      "2021-11-02 03:47:16.017503: validation loss: -0.8441\n",
      "2021-11-02 03:47:16.021791: Average global foreground Dice: [0.8641]\n",
      "2021-11-02 03:47:16.029020: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 03:47:16.529008: lr: 0.007533\n",
      "2021-11-02 03:47:16.622192: saving checkpoint...\n",
      "2021-11-02 03:47:17.770080: done, saving took 1.21 seconds\n",
      "2021-11-02 03:47:18.370884: This epoch took 298.287271 s\n",
      "\n",
      "2021-11-02 03:47:18.391958: \n",
      "epoch:  27\n",
      "2021-11-02 03:51:56.589057: train loss : -0.8296\n",
      "2021-11-02 03:52:14.337141: validation loss: -0.8412\n",
      "2021-11-02 03:52:14.341045: Average global foreground Dice: [0.8586]\n",
      "2021-11-02 03:52:14.347813: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 03:52:14.840248: lr: 0.00744\n",
      "2021-11-02 03:52:14.916263: saving checkpoint...\n",
      "2021-11-02 03:52:16.079276: done, saving took 1.22 seconds\n",
      "2021-11-02 03:52:16.689351: This epoch took 298.288860 s\n",
      "\n",
      "2021-11-02 03:52:16.698260: \n",
      "epoch:  28\n",
      "2021-11-02 03:56:54.393099: train loss : -0.8264\n",
      "2021-11-02 03:57:11.862481: validation loss: -0.8384\n",
      "2021-11-02 03:57:11.867635: Average global foreground Dice: [0.8574]\n",
      "2021-11-02 03:57:11.875423: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 03:57:12.349838: lr: 0.007347\n",
      "2021-11-02 03:57:12.411293: saving checkpoint...\n",
      "2021-11-02 03:57:13.572408: done, saving took 1.19 seconds\n",
      "2021-11-02 03:57:14.197156: This epoch took 297.491360 s\n",
      "\n",
      "2021-11-02 03:57:14.211441: \n",
      "epoch:  29\n",
      "2021-11-02 04:01:51.814811: train loss : -0.8352\n",
      "2021-11-02 04:02:09.312768: validation loss: -0.8379\n",
      "2021-11-02 04:02:09.316274: Average global foreground Dice: [0.8544]\n",
      "2021-11-02 04:02:09.322701: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 04:02:09.797798: lr: 0.007254\n",
      "2021-11-02 04:02:09.846045: saving checkpoint...\n",
      "2021-11-02 04:02:10.956908: done, saving took 1.14 seconds\n",
      "2021-11-02 04:02:11.573336: This epoch took 297.354574 s\n",
      "\n",
      "2021-11-02 04:02:11.581639: \n",
      "epoch:  30\n",
      "2021-11-02 04:06:49.241576: train loss : -0.8319\n",
      "2021-11-02 04:07:06.794935: validation loss: -0.8319\n",
      "2021-11-02 04:07:06.799231: Average global foreground Dice: [0.8538]\n",
      "2021-11-02 04:07:06.805791: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 04:07:07.279400: lr: 0.007161\n",
      "2021-11-02 04:07:07.327494: saving checkpoint...\n",
      "2021-11-02 04:07:08.427607: done, saving took 1.13 seconds\n",
      "2021-11-02 04:07:09.043355: This epoch took 297.454252 s\n",
      "\n",
      "2021-11-02 04:07:09.052526: \n",
      "epoch:  31\n",
      "2021-11-02 04:11:46.390805: train loss : -0.8321\n",
      "2021-11-02 04:12:03.863603: validation loss: -0.8317\n",
      "2021-11-02 04:12:03.867854: Average global foreground Dice: [0.8571]\n",
      "2021-11-02 04:12:03.875247: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 04:12:04.356365: lr: 0.007067\n",
      "2021-11-02 04:12:04.416115: saving checkpoint...\n",
      "2021-11-02 04:12:05.553027: done, saving took 1.17 seconds\n",
      "2021-11-02 04:12:06.207886: This epoch took 297.149433 s\n",
      "\n",
      "2021-11-02 04:12:06.228317: \n",
      "epoch:  32\n",
      "2021-11-02 04:16:44.573806: train loss : -0.8287\n",
      "2021-11-02 04:17:02.203416: validation loss: -0.8360\n",
      "2021-11-02 04:17:02.209331: Average global foreground Dice: [0.852]\n",
      "2021-11-02 04:17:02.216112: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 04:17:02.695823: lr: 0.006974\n",
      "2021-11-02 04:17:02.748764: saving checkpoint...\n",
      "2021-11-02 04:17:03.858948: done, saving took 1.14 seconds\n",
      "2021-11-02 04:17:04.476654: This epoch took 298.240221 s\n",
      "\n",
      "2021-11-02 04:17:04.485548: \n",
      "epoch:  33\n",
      "2021-11-02 04:21:43.684342: train loss : -0.8329\n",
      "2021-11-02 04:22:01.212931: validation loss: -0.8333\n",
      "2021-11-02 04:22:01.217116: Average global foreground Dice: [0.8506]\n",
      "2021-11-02 04:22:01.225013: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 04:22:01.703372: lr: 0.00688\n",
      "2021-11-02 04:22:01.763717: saving checkpoint...\n",
      "2021-11-02 04:22:02.954895: done, saving took 1.22 seconds\n",
      "2021-11-02 04:22:03.569858: This epoch took 299.077305 s\n",
      "\n",
      "2021-11-02 04:22:03.589136: \n",
      "epoch:  34\n",
      "2021-11-02 04:26:42.070873: train loss : -0.8365\n",
      "2021-11-02 04:26:59.577475: validation loss: -0.8321\n",
      "2021-11-02 04:26:59.581173: Average global foreground Dice: [0.8524]\n",
      "2021-11-02 04:26:59.587724: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 04:27:00.089606: lr: 0.006786\n",
      "2021-11-02 04:27:00.150203: saving checkpoint...\n",
      "2021-11-02 04:27:01.390773: done, saving took 1.27 seconds\n",
      "2021-11-02 04:27:02.062651: This epoch took 298.467108 s\n",
      "\n",
      "2021-11-02 04:27:02.082131: \n",
      "epoch:  35\n",
      "2021-11-02 04:31:40.843636: train loss : -0.8354\n",
      "2021-11-02 04:31:58.348924: validation loss: -0.8384\n",
      "2021-11-02 04:31:58.352774: Average global foreground Dice: [0.8604]\n",
      "2021-11-02 04:31:58.360666: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 04:31:58.840760: lr: 0.006692\n",
      "2021-11-02 04:31:58.897041: saving checkpoint...\n",
      "2021-11-02 04:32:00.003791: done, saving took 1.14 seconds\n",
      "2021-11-02 04:32:00.611144: This epoch took 298.521485 s\n",
      "\n",
      "2021-11-02 04:32:00.626758: \n",
      "epoch:  36\n",
      "2021-11-02 04:36:39.266960: train loss : -0.8411\n",
      "2021-11-02 04:36:56.755007: validation loss: -0.8464\n",
      "2021-11-02 04:36:56.759217: Average global foreground Dice: [0.8662]\n",
      "2021-11-02 04:36:56.765401: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 04:36:57.240122: lr: 0.006598\n",
      "2021-11-02 04:36:57.293515: saving checkpoint...\n",
      "2021-11-02 04:36:58.404157: done, saving took 1.14 seconds\n",
      "2021-11-02 04:36:59.035389: This epoch took 298.400480 s\n",
      "\n",
      "2021-11-02 04:36:59.044034: \n",
      "epoch:  37\n",
      "2021-11-02 04:41:37.746034: train loss : -0.8363\n",
      "2021-11-02 04:41:55.286498: validation loss: -0.8350\n",
      "2021-11-02 04:41:55.290349: Average global foreground Dice: [0.8551]\n",
      "2021-11-02 04:41:55.297029: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 04:41:55.832291: lr: 0.006504\n",
      "2021-11-02 04:41:55.909714: saving checkpoint...\n",
      "2021-11-02 04:41:57.033297: done, saving took 1.18 seconds\n",
      "2021-11-02 04:41:57.655256: This epoch took 298.605150 s\n",
      "\n",
      "2021-11-02 04:41:57.663028: \n",
      "epoch:  38\n",
      "2021-11-02 04:46:36.484432: train loss : -0.8350\n",
      "2021-11-02 04:46:54.231035: validation loss: -0.8403\n",
      "2021-11-02 04:46:54.236207: Average global foreground Dice: [0.861]\n",
      "2021-11-02 04:46:54.243025: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 04:46:54.745187: lr: 0.006409\n",
      "2021-11-02 04:46:54.826430: saving checkpoint...\n",
      "2021-11-02 04:46:55.943294: done, saving took 1.18 seconds\n",
      "2021-11-02 04:46:56.534400: This epoch took 298.864663 s\n",
      "\n",
      "2021-11-02 04:46:56.543137: \n",
      "epoch:  39\n",
      "2021-11-02 04:51:35.094255: train loss : -0.8387\n",
      "2021-11-02 04:51:52.791998: validation loss: -0.8437\n",
      "2021-11-02 04:51:52.795801: Average global foreground Dice: [0.8613]\n",
      "2021-11-02 04:51:52.802172: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 04:51:53.351735: lr: 0.006314\n",
      "2021-11-02 04:51:53.399450: saving checkpoint...\n",
      "2021-11-02 04:51:54.506142: done, saving took 1.14 seconds\n",
      "2021-11-02 04:51:55.105192: This epoch took 298.554062 s\n",
      "\n",
      "2021-11-02 04:51:55.113372: \n",
      "epoch:  40\n",
      "2021-11-02 04:56:33.841518: train loss : -0.8450\n",
      "2021-11-02 04:56:51.281310: validation loss: -0.8459\n",
      "2021-11-02 04:56:51.284870: Average global foreground Dice: [0.8659]\n",
      "2021-11-02 04:56:51.291317: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 04:56:51.772201: lr: 0.00622\n",
      "2021-11-02 04:56:51.822020: saving checkpoint...\n",
      "2021-11-02 04:56:52.924589: done, saving took 1.13 seconds\n",
      "2021-11-02 04:56:53.638892: This epoch took 298.517876 s\n",
      "\n",
      "2021-11-02 04:56:53.647337: \n",
      "epoch:  41\n",
      "2021-11-02 05:01:32.468977: train loss : -0.8442\n",
      "2021-11-02 05:01:50.063273: validation loss: -0.8480\n",
      "2021-11-02 05:01:50.066857: Average global foreground Dice: [0.8615]\n",
      "2021-11-02 05:01:50.073694: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 05:01:50.546321: lr: 0.006125\n",
      "2021-11-02 05:01:50.617821: saving checkpoint...\n",
      "2021-11-02 05:01:51.751027: done, saving took 1.16 seconds\n",
      "2021-11-02 05:01:53.116471: This epoch took 299.461598 s\n",
      "\n",
      "2021-11-02 05:01:53.126624: \n",
      "epoch:  42\n",
      "2021-11-02 05:06:32.271971: train loss : -0.8443\n",
      "2021-11-02 05:06:49.814159: validation loss: -0.8392\n",
      "2021-11-02 05:06:49.817744: Average global foreground Dice: [0.8557]\n",
      "2021-11-02 05:06:49.824291: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 05:06:50.297656: lr: 0.00603\n",
      "2021-11-02 05:06:50.347740: saving checkpoint...\n",
      "2021-11-02 05:06:51.462968: done, saving took 1.14 seconds\n",
      "2021-11-02 05:06:52.047364: This epoch took 298.912225 s\n",
      "\n",
      "2021-11-02 05:06:52.055485: \n",
      "epoch:  43\n",
      "2021-11-02 05:11:31.260453: train loss : -0.8420\n",
      "2021-11-02 05:11:48.700241: validation loss: -0.8423\n",
      "2021-11-02 05:11:48.705392: Average global foreground Dice: [0.8586]\n",
      "2021-11-02 05:11:48.712817: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 05:11:49.186131: lr: 0.005934\n",
      "2021-11-02 05:11:49.233514: saving checkpoint...\n",
      "2021-11-02 05:11:50.336924: done, saving took 1.13 seconds\n",
      "2021-11-02 05:11:50.917278: This epoch took 298.855071 s\n",
      "\n",
      "2021-11-02 05:11:50.925473: \n",
      "epoch:  44\n",
      "2021-11-02 05:16:29.389705: train loss : -0.8450\n",
      "2021-11-02 05:16:47.114129: validation loss: -0.8409\n",
      "2021-11-02 05:16:47.117449: Average global foreground Dice: [0.86]\n",
      "2021-11-02 05:16:47.123051: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 05:16:47.595261: lr: 0.005839\n",
      "2021-11-02 05:16:47.674440: saving checkpoint...\n",
      "2021-11-02 05:16:48.789477: done, saving took 1.17 seconds\n",
      "2021-11-02 05:16:49.390872: This epoch took 298.458567 s\n",
      "\n",
      "2021-11-02 05:16:49.399154: \n",
      "epoch:  45\n",
      "2021-11-02 05:21:28.110345: train loss : -0.8459\n",
      "2021-11-02 05:21:45.654059: validation loss: -0.8413\n",
      "2021-11-02 05:21:45.659335: Average global foreground Dice: [0.8595]\n",
      "2021-11-02 05:21:45.665834: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 05:21:46.145822: lr: 0.005743\n",
      "2021-11-02 05:21:46.222386: saving checkpoint...\n",
      "2021-11-02 05:21:47.381011: done, saving took 1.22 seconds\n",
      "2021-11-02 05:21:47.976388: This epoch took 298.569359 s\n",
      "\n",
      "2021-11-02 05:21:47.985115: \n",
      "epoch:  46\n",
      "2021-11-02 05:26:26.463838: train loss : -0.8384\n",
      "2021-11-02 05:26:43.877272: validation loss: -0.8329\n",
      "2021-11-02 05:26:43.881165: Average global foreground Dice: [0.8473]\n",
      "2021-11-02 05:26:43.888022: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 05:26:44.361435: lr: 0.005647\n",
      "2021-11-02 05:26:44.381010: This epoch took 296.388464 s\n",
      "\n",
      "2021-11-02 05:26:44.388538: \n",
      "epoch:  47\n",
      "2021-11-02 05:31:22.934367: train loss : -0.8434\n",
      "2021-11-02 05:31:40.377240: validation loss: -0.8444\n",
      "2021-11-02 05:31:40.381350: Average global foreground Dice: [0.8591]\n",
      "2021-11-02 05:31:40.389139: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 05:31:40.863749: lr: 0.005551\n",
      "2021-11-02 05:31:40.881457: This epoch took 296.486561 s\n",
      "\n",
      "2021-11-02 05:31:40.888982: \n",
      "epoch:  48\n",
      "2021-11-02 05:36:19.814045: train loss : -0.8428\n",
      "2021-11-02 05:36:37.291537: validation loss: -0.8351\n",
      "2021-11-02 05:36:37.295478: Average global foreground Dice: [0.8513]\n",
      "2021-11-02 05:36:37.302410: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 05:36:37.779307: lr: 0.005455\n",
      "2021-11-02 05:36:37.799150: This epoch took 296.902725 s\n",
      "\n",
      "2021-11-02 05:36:37.806232: \n",
      "epoch:  49\n",
      "2021-11-02 05:41:16.520017: train loss : -0.8452\n",
      "2021-11-02 05:41:33.963346: validation loss: -0.8366\n",
      "2021-11-02 05:41:33.967024: Average global foreground Dice: [0.8566]\n",
      "2021-11-02 05:41:33.973512: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 05:41:34.445296: lr: 0.005359\n",
      "2021-11-02 05:41:34.465634: saving scheduled checkpoint file...\n",
      "2021-11-02 05:41:34.520011: saving checkpoint...\n",
      "2021-11-02 05:41:35.489034: done, saving took 1.02 seconds\n",
      "2021-11-02 05:41:36.130486: done\n",
      "2021-11-02 05:41:36.139032: This epoch took 298.325527 s\n",
      "\n",
      "2021-11-02 05:41:36.146127: \n",
      "epoch:  50\n",
      "2021-11-02 05:46:15.494208: train loss : -0.8448\n",
      "2021-11-02 05:46:33.052864: validation loss: -0.8384\n",
      "2021-11-02 05:46:33.057445: Average global foreground Dice: [0.8546]\n",
      "2021-11-02 05:46:33.065064: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 05:46:33.541762: lr: 0.005262\n",
      "2021-11-02 05:46:33.560997: This epoch took 297.407426 s\n",
      "\n",
      "2021-11-02 05:46:33.567629: \n",
      "epoch:  51\n",
      "2021-11-02 05:51:12.988775: train loss : -0.8449\n",
      "2021-11-02 05:51:30.751673: validation loss: -0.8378\n",
      "2021-11-02 05:51:30.755508: Average global foreground Dice: [0.8535]\n",
      "2021-11-02 05:51:30.761466: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 05:51:31.254407: lr: 0.005166\n",
      "2021-11-02 05:51:31.274066: This epoch took 297.700395 s\n",
      "\n",
      "2021-11-02 05:51:31.281991: \n",
      "epoch:  52\n",
      "2021-11-02 05:56:10.127262: train loss : -0.8423\n",
      "2021-11-02 05:56:27.842056: validation loss: -0.8398\n",
      "2021-11-02 05:56:27.845571: Average global foreground Dice: [0.8552]\n",
      "2021-11-02 05:56:27.852744: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 05:56:28.346436: lr: 0.005069\n",
      "2021-11-02 05:56:28.373831: This epoch took 297.083985 s\n",
      "\n",
      "2021-11-02 05:56:28.381452: \n",
      "epoch:  53\n",
      "2021-11-02 06:01:07.277108: train loss : -0.8485\n",
      "2021-11-02 06:01:25.016630: validation loss: -0.8446\n",
      "2021-11-02 06:01:25.021519: Average global foreground Dice: [0.8628]\n",
      "2021-11-02 06:01:25.029598: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 06:01:25.517449: lr: 0.004971\n",
      "2021-11-02 06:01:25.615058: saving checkpoint...\n",
      "2021-11-02 06:01:26.899669: done, saving took 1.35 seconds\n",
      "2021-11-02 06:01:27.538233: This epoch took 299.149899 s\n",
      "\n",
      "2021-11-02 06:01:27.556983: \n",
      "epoch:  54\n",
      "2021-11-02 06:06:06.347788: train loss : -0.8508\n",
      "2021-11-02 06:06:23.823967: validation loss: -0.8486\n",
      "2021-11-02 06:06:23.827991: Average global foreground Dice: [0.8676]\n",
      "2021-11-02 06:06:23.835185: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 06:06:24.322505: lr: 0.004874\n",
      "2021-11-02 06:06:24.389239: saving checkpoint...\n",
      "2021-11-02 06:06:25.797832: done, saving took 1.44 seconds\n",
      "2021-11-02 06:06:26.403797: This epoch took 298.839047 s\n",
      "\n",
      "2021-11-02 06:06:26.422843: \n",
      "epoch:  55\n",
      "2021-11-02 06:11:04.447096: train loss : -0.8480\n",
      "2021-11-02 06:11:21.906135: validation loss: -0.8409\n",
      "2021-11-02 06:11:21.910111: Average global foreground Dice: [0.8571]\n",
      "2021-11-02 06:11:21.916924: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 06:11:22.400586: lr: 0.004776\n",
      "2021-11-02 06:11:22.463125: saving checkpoint...\n",
      "2021-11-02 06:11:23.651550: done, saving took 1.22 seconds\n",
      "2021-11-02 06:11:24.260633: This epoch took 297.830311 s\n",
      "\n",
      "2021-11-02 06:11:24.280266: \n",
      "epoch:  56\n",
      "2021-11-02 06:16:02.694459: train loss : -0.8476\n",
      "2021-11-02 06:16:20.236040: validation loss: -0.8427\n",
      "2021-11-02 06:16:20.240060: Average global foreground Dice: [0.8604]\n",
      "2021-11-02 06:16:20.247561: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 06:16:20.727879: lr: 0.004679\n",
      "2021-11-02 06:16:20.789711: saving checkpoint...\n",
      "2021-11-02 06:16:22.026860: done, saving took 1.27 seconds\n",
      "2021-11-02 06:16:22.641447: This epoch took 298.354136 s\n",
      "\n",
      "2021-11-02 06:16:22.661228: \n",
      "epoch:  57\n",
      "2021-11-02 06:21:00.719739: train loss : -0.8514\n",
      "2021-11-02 06:21:18.380190: validation loss: -0.8480\n",
      "2021-11-02 06:21:18.387150: Average global foreground Dice: [0.8618]\n",
      "2021-11-02 06:21:18.394562: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 06:21:18.877211: lr: 0.004581\n",
      "2021-11-02 06:21:18.939719: saving checkpoint...\n",
      "2021-11-02 06:21:20.119864: done, saving took 1.21 seconds\n",
      "2021-11-02 06:21:20.808953: This epoch took 298.141356 s\n",
      "\n",
      "2021-11-02 06:21:20.827275: \n",
      "epoch:  58\n",
      "2021-11-02 06:25:58.943094: train loss : -0.8518\n",
      "2021-11-02 06:26:16.669086: validation loss: -0.8417\n",
      "2021-11-02 06:26:16.673918: Average global foreground Dice: [0.8563]\n",
      "2021-11-02 06:26:16.680972: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 06:26:17.179300: lr: 0.004482\n",
      "2021-11-02 06:26:17.215893: This epoch took 296.381765 s\n",
      "\n",
      "2021-11-02 06:26:17.223886: \n",
      "epoch:  59\n",
      "2021-11-02 06:30:55.256826: train loss : -0.8527\n",
      "2021-11-02 06:31:13.076736: validation loss: -0.8458\n",
      "2021-11-02 06:31:13.080918: Average global foreground Dice: [0.8633]\n",
      "2021-11-02 06:31:13.086954: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 06:31:13.584277: lr: 0.004384\n",
      "2021-11-02 06:31:13.676835: saving checkpoint...\n",
      "2021-11-02 06:31:14.959851: done, saving took 1.34 seconds\n",
      "2021-11-02 06:31:15.588746: This epoch took 298.358034 s\n",
      "\n",
      "2021-11-02 06:31:15.608076: \n",
      "epoch:  60\n",
      "2021-11-02 06:35:53.337916: train loss : -0.8526\n",
      "2021-11-02 06:36:10.836465: validation loss: -0.8423\n",
      "2021-11-02 06:36:10.841892: Average global foreground Dice: [0.8589]\n",
      "2021-11-02 06:36:10.847674: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 06:36:11.332247: lr: 0.004285\n",
      "2021-11-02 06:36:11.396060: saving checkpoint...\n",
      "2021-11-02 06:36:12.638537: done, saving took 1.27 seconds\n",
      "2021-11-02 06:36:13.259326: This epoch took 297.645345 s\n",
      "\n",
      "2021-11-02 06:36:13.278647: \n",
      "epoch:  61\n",
      "2021-11-02 06:40:51.285203: train loss : -0.8467\n",
      "2021-11-02 06:41:08.790304: validation loss: -0.8503\n",
      "2021-11-02 06:41:08.795750: Average global foreground Dice: [0.861]\n",
      "2021-11-02 06:41:08.802659: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 06:41:09.288205: lr: 0.004186\n",
      "2021-11-02 06:41:09.352777: saving checkpoint...\n",
      "2021-11-02 06:41:10.581329: done, saving took 1.26 seconds\n",
      "2021-11-02 06:41:11.188628: This epoch took 297.902316 s\n",
      "\n",
      "2021-11-02 06:41:11.208051: \n",
      "epoch:  62\n",
      "2021-11-02 06:45:48.960552: train loss : -0.8543\n",
      "2021-11-02 06:46:06.400979: validation loss: -0.8471\n",
      "2021-11-02 06:46:06.404607: Average global foreground Dice: [0.864]\n",
      "2021-11-02 06:46:06.411153: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 06:46:06.892451: lr: 0.004087\n",
      "2021-11-02 06:46:06.958730: saving checkpoint...\n",
      "2021-11-02 06:46:08.157251: done, saving took 1.23 seconds\n",
      "2021-11-02 06:46:08.756248: This epoch took 297.541583 s\n",
      "\n",
      "2021-11-02 06:46:08.775243: \n",
      "epoch:  63\n",
      "2021-11-02 06:50:47.541423: train loss : -0.8547\n",
      "2021-11-02 06:51:05.173670: validation loss: -0.8462\n",
      "2021-11-02 06:51:05.177612: Average global foreground Dice: [0.8618]\n",
      "2021-11-02 06:51:05.184267: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 06:51:05.667857: lr: 0.003987\n",
      "2021-11-02 06:51:05.734519: saving checkpoint...\n",
      "2021-11-02 06:51:06.961473: done, saving took 1.26 seconds\n",
      "2021-11-02 06:51:07.579054: This epoch took 298.796621 s\n",
      "\n",
      "2021-11-02 06:51:07.598891: \n",
      "epoch:  64\n",
      "2021-11-02 06:55:46.461599: train loss : -0.8540\n",
      "2021-11-02 06:56:03.937145: validation loss: -0.8365\n",
      "2021-11-02 06:56:03.941164: Average global foreground Dice: [0.8557]\n",
      "2021-11-02 06:56:03.947828: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 06:56:04.429298: lr: 0.003887\n",
      "2021-11-02 06:56:04.468395: This epoch took 296.861218 s\n",
      "\n",
      "2021-11-02 06:56:04.477510: \n",
      "epoch:  65\n",
      "2021-11-02 07:00:42.842705: train loss : -0.8488\n",
      "2021-11-02 07:01:00.271848: validation loss: -0.8428\n",
      "2021-11-02 07:01:00.275726: Average global foreground Dice: [0.8623]\n",
      "2021-11-02 07:01:00.282617: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 07:01:00.767136: lr: 0.003787\n",
      "2021-11-02 07:01:00.803682: This epoch took 296.317960 s\n",
      "\n",
      "2021-11-02 07:01:00.810154: \n",
      "epoch:  66\n",
      "2021-11-02 07:05:35.257599: train loss : -0.8520\n",
      "2021-11-02 07:05:52.527869: validation loss: -0.8507\n",
      "2021-11-02 07:05:52.531608: Average global foreground Dice: [0.8673]\n",
      "2021-11-02 07:05:52.537932: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 07:05:53.087078: lr: 0.003687\n",
      "2021-11-02 07:05:53.151197: saving checkpoint...\n",
      "2021-11-02 07:05:54.367882: done, saving took 1.25 seconds\n",
      "2021-11-02 07:05:54.961345: This epoch took 294.143678 s\n",
      "\n",
      "2021-11-02 07:05:54.981099: \n",
      "epoch:  67\n",
      "2021-11-02 07:10:29.059318: train loss : -0.8543\n",
      "2021-11-02 07:10:46.361916: validation loss: -0.8380\n",
      "2021-11-02 07:10:46.365938: Average global foreground Dice: [0.8552]\n",
      "2021-11-02 07:10:46.372972: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 07:10:46.858513: lr: 0.003586\n",
      "2021-11-02 07:10:46.886348: This epoch took 291.897641 s\n",
      "\n",
      "2021-11-02 07:10:46.893787: \n",
      "epoch:  68\n",
      "2021-11-02 07:15:21.039996: train loss : -0.8582\n",
      "2021-11-02 07:15:38.488583: validation loss: -0.8483\n",
      "2021-11-02 07:15:38.494193: Average global foreground Dice: [0.8663]\n",
      "2021-11-02 07:15:38.501285: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 07:15:38.987874: lr: 0.003485\n",
      "2021-11-02 07:15:39.056849: saving checkpoint...\n",
      "2021-11-02 07:15:40.314487: done, saving took 1.29 seconds\n",
      "2021-11-02 07:15:40.934876: This epoch took 294.032371 s\n",
      "\n",
      "2021-11-02 07:15:40.954857: \n",
      "epoch:  69\n",
      "2021-11-02 07:20:15.337194: train loss : -0.8554\n",
      "2021-11-02 07:20:32.607840: validation loss: -0.8477\n",
      "2021-11-02 07:20:32.611628: Average global foreground Dice: [0.865]\n",
      "2021-11-02 07:20:32.618703: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 07:20:33.098552: lr: 0.003384\n",
      "2021-11-02 07:20:33.147362: saving checkpoint...\n",
      "2021-11-02 07:20:34.286890: done, saving took 1.17 seconds\n",
      "2021-11-02 07:20:34.903344: This epoch took 293.941216 s\n",
      "\n",
      "2021-11-02 07:20:34.911745: \n",
      "epoch:  70\n",
      "2021-11-02 07:25:08.491363: train loss : -0.8569\n",
      "2021-11-02 07:25:25.898567: validation loss: -0.8373\n",
      "2021-11-02 07:25:25.902988: Average global foreground Dice: [0.8558]\n",
      "2021-11-02 07:25:25.910005: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 07:25:26.394015: lr: 0.003282\n",
      "2021-11-02 07:25:26.414675: This epoch took 291.494954 s\n",
      "\n",
      "2021-11-02 07:25:26.422718: \n",
      "epoch:  71\n",
      "2021-11-02 07:30:00.847550: train loss : -0.8576\n",
      "2021-11-02 07:30:18.406309: validation loss: -0.8477\n",
      "2021-11-02 07:30:18.411474: Average global foreground Dice: [0.8623]\n",
      "2021-11-02 07:30:18.417322: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 07:30:18.915835: lr: 0.00318\n",
      "2021-11-02 07:30:18.934228: This epoch took 292.503110 s\n",
      "\n",
      "2021-11-02 07:30:18.941857: \n",
      "epoch:  72\n",
      "2021-11-02 07:34:53.553608: train loss : -0.8576\n",
      "2021-11-02 07:35:11.115828: validation loss: -0.8513\n",
      "2021-11-02 07:35:11.119423: Average global foreground Dice: [0.8656]\n",
      "2021-11-02 07:35:11.126062: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 07:35:11.623208: lr: 0.003078\n",
      "2021-11-02 07:35:11.708663: saving checkpoint...\n",
      "2021-11-02 07:35:12.963204: done, saving took 1.32 seconds\n",
      "2021-11-02 07:35:14.247794: This epoch took 295.298058 s\n",
      "\n",
      "2021-11-02 07:35:14.256565: \n",
      "epoch:  73\n",
      "2021-11-02 07:39:48.969308: train loss : -0.8564\n",
      "2021-11-02 07:40:06.541714: validation loss: -0.8472\n",
      "2021-11-02 07:40:06.545670: Average global foreground Dice: [0.8626]\n",
      "2021-11-02 07:40:06.552613: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 07:40:07.113261: lr: 0.002975\n",
      "2021-11-02 07:40:07.162529: saving checkpoint...\n",
      "2021-11-02 07:40:08.393748: done, saving took 1.26 seconds\n",
      "2021-11-02 07:40:09.298593: This epoch took 295.034418 s\n",
      "\n",
      "2021-11-02 07:40:09.307121: \n",
      "epoch:  74\n",
      "2021-11-02 07:44:42.830948: train loss : -0.8587\n",
      "2021-11-02 07:45:00.086888: validation loss: -0.8534\n",
      "2021-11-02 07:45:00.090853: Average global foreground Dice: [0.87]\n",
      "2021-11-02 07:45:00.096938: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 07:45:00.588409: lr: 0.002872\n",
      "2021-11-02 07:45:00.636758: saving checkpoint...\n",
      "2021-11-02 07:45:01.868280: done, saving took 1.26 seconds\n",
      "2021-11-02 07:45:02.629064: This epoch took 293.315175 s\n",
      "\n",
      "2021-11-02 07:45:02.637467: \n",
      "epoch:  75\n",
      "2021-11-02 07:49:36.406892: train loss : -0.8610\n",
      "2021-11-02 07:49:53.655210: validation loss: -0.8460\n",
      "2021-11-02 07:49:53.659398: Average global foreground Dice: [0.8623]\n",
      "2021-11-02 07:49:53.666438: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 07:49:54.150286: lr: 0.002768\n",
      "2021-11-02 07:49:54.198208: saving checkpoint...\n",
      "2021-11-02 07:49:55.408652: done, saving took 1.24 seconds\n",
      "2021-11-02 07:49:56.083392: This epoch took 293.438937 s\n",
      "\n",
      "2021-11-02 07:49:56.092595: \n",
      "epoch:  76\n",
      "2021-11-02 07:54:18.276289: train loss : -0.8611\n",
      "2021-11-02 07:54:34.644025: validation loss: -0.8347\n",
      "2021-11-02 07:54:34.648074: Average global foreground Dice: [0.8533]\n",
      "2021-11-02 07:54:34.655127: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 07:54:35.143599: lr: 0.002664\n",
      "2021-11-02 07:54:35.164888: This epoch took 279.057885 s\n",
      "\n",
      "2021-11-02 07:54:35.172433: \n",
      "epoch:  77\n",
      "2021-11-02 07:58:58.219055: train loss : -0.8621\n",
      "2021-11-02 07:59:15.615595: validation loss: -0.8529\n",
      "2021-11-02 07:59:15.619441: Average global foreground Dice: [0.8673]\n",
      "2021-11-02 07:59:15.626335: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 07:59:16.114357: lr: 0.00256\n",
      "2021-11-02 07:59:16.133838: This epoch took 280.954267 s\n",
      "\n",
      "2021-11-02 07:59:16.141329: \n",
      "epoch:  78\n",
      "2021-11-02 08:03:52.033469: train loss : -0.8584\n",
      "2021-11-02 08:04:09.523706: validation loss: -0.8457\n",
      "2021-11-02 08:04:09.527694: Average global foreground Dice: [0.8611]\n",
      "2021-11-02 08:04:09.534381: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 08:04:10.023569: lr: 0.002455\n",
      "2021-11-02 08:04:10.040221: This epoch took 293.891644 s\n",
      "\n",
      "2021-11-02 08:04:10.047127: \n",
      "epoch:  79\n",
      "2021-11-02 08:08:46.291471: train loss : -0.8641\n",
      "2021-11-02 08:09:03.686539: validation loss: -0.8414\n",
      "2021-11-02 08:09:03.690605: Average global foreground Dice: [0.8581]\n",
      "2021-11-02 08:09:03.697453: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 08:09:04.186534: lr: 0.002349\n",
      "2021-11-02 08:09:04.206536: This epoch took 294.151789 s\n",
      "\n",
      "2021-11-02 08:09:04.213721: \n",
      "epoch:  80\n",
      "2021-11-02 08:13:38.796387: train loss : -0.8598\n",
      "2021-11-02 08:13:56.185790: validation loss: -0.8442\n",
      "2021-11-02 08:13:56.189194: Average global foreground Dice: [0.8611]\n",
      "2021-11-02 08:13:56.196702: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 08:13:56.685426: lr: 0.002243\n",
      "2021-11-02 08:13:56.705316: This epoch took 292.484250 s\n",
      "\n",
      "2021-11-02 08:13:56.711890: \n",
      "epoch:  81\n",
      "2021-11-02 08:18:30.559048: train loss : -0.8608\n",
      "2021-11-02 08:18:47.817294: validation loss: -0.8393\n",
      "2021-11-02 08:18:47.821227: Average global foreground Dice: [0.8548]\n",
      "2021-11-02 08:18:47.827740: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 08:18:48.316816: lr: 0.002137\n",
      "2021-11-02 08:18:48.336830: This epoch took 291.618745 s\n",
      "\n",
      "2021-11-02 08:18:48.343441: \n",
      "epoch:  82\n",
      "2021-11-02 08:23:21.741616: train loss : -0.8632\n",
      "2021-11-02 08:23:39.151155: validation loss: -0.8461\n",
      "2021-11-02 08:23:39.154979: Average global foreground Dice: [0.8612]\n",
      "2021-11-02 08:23:39.161939: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 08:23:39.645464: lr: 0.00203\n",
      "2021-11-02 08:23:39.667476: This epoch took 291.316503 s\n",
      "\n",
      "2021-11-02 08:23:39.677313: \n",
      "epoch:  83\n",
      "2021-11-02 08:28:11.824178: train loss : -0.8674\n",
      "2021-11-02 08:28:29.056106: validation loss: -0.8486\n",
      "2021-11-02 08:28:29.059515: Average global foreground Dice: [0.8615]\n",
      "2021-11-02 08:28:29.065515: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 08:28:29.542258: lr: 0.001922\n",
      "2021-11-02 08:28:29.560321: This epoch took 289.875417 s\n",
      "\n",
      "2021-11-02 08:28:29.567529: \n",
      "epoch:  84\n",
      "2021-11-02 08:33:01.715701: train loss : -0.8647\n",
      "2021-11-02 08:33:18.959505: validation loss: -0.8532\n",
      "2021-11-02 08:33:18.965419: Average global foreground Dice: [0.8679]\n",
      "2021-11-02 08:33:18.972905: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 08:33:19.451269: lr: 0.001813\n",
      "2021-11-02 08:33:19.478069: This epoch took 289.903538 s\n",
      "\n",
      "2021-11-02 08:33:19.486377: \n",
      "epoch:  85\n",
      "2021-11-02 08:37:51.625984: train loss : -0.8668\n",
      "2021-11-02 08:38:08.871125: validation loss: -0.8493\n",
      "2021-11-02 08:38:08.876262: Average global foreground Dice: [0.8638]\n",
      "2021-11-02 08:38:08.882888: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 08:38:09.372728: lr: 0.001704\n",
      "2021-11-02 08:38:09.391505: This epoch took 289.896795 s\n",
      "\n",
      "2021-11-02 08:38:09.398550: \n",
      "epoch:  86\n",
      "2021-11-02 08:42:42.298764: train loss : -0.8696\n",
      "2021-11-02 08:42:59.598539: validation loss: -0.8562\n",
      "2021-11-02 08:42:59.602121: Average global foreground Dice: [0.8707]\n",
      "2021-11-02 08:42:59.609076: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 08:43:00.134176: lr: 0.001594\n",
      "2021-11-02 08:43:00.181726: saving checkpoint...\n",
      "2021-11-02 08:43:01.421039: done, saving took 1.27 seconds\n",
      "2021-11-02 08:43:02.082469: This epoch took 292.675574 s\n",
      "\n",
      "2021-11-02 08:43:02.092893: \n",
      "epoch:  87\n",
      "2021-11-02 08:47:34.249054: train loss : -0.8650\n",
      "2021-11-02 08:47:51.485278: validation loss: -0.8489\n",
      "2021-11-02 08:47:51.489181: Average global foreground Dice: [0.8646]\n",
      "2021-11-02 08:47:51.495931: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 08:47:51.982111: lr: 0.001483\n",
      "2021-11-02 08:47:52.031042: saving checkpoint...\n",
      "2021-11-02 08:47:53.277389: done, saving took 1.27 seconds\n",
      "2021-11-02 08:47:54.034495: This epoch took 291.933916 s\n",
      "\n",
      "2021-11-02 08:47:54.043239: \n",
      "epoch:  88\n",
      "2021-11-02 08:52:26.325135: train loss : -0.8686\n",
      "2021-11-02 08:52:43.566390: validation loss: -0.8436\n",
      "2021-11-02 08:52:43.570257: Average global foreground Dice: [0.8612]\n",
      "2021-11-02 08:52:43.576156: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 08:52:44.061685: lr: 0.001372\n",
      "2021-11-02 08:52:44.082240: This epoch took 290.031495 s\n",
      "\n",
      "2021-11-02 08:52:44.089651: \n",
      "epoch:  89\n",
      "2021-11-02 08:57:16.480972: train loss : -0.8707\n",
      "2021-11-02 08:57:33.872360: validation loss: -0.8488\n",
      "2021-11-02 08:57:33.876690: Average global foreground Dice: [0.8647]\n",
      "2021-11-02 08:57:33.883941: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 08:57:34.373691: lr: 0.001259\n",
      "2021-11-02 08:57:34.435835: saving checkpoint...\n",
      "2021-11-02 08:57:35.688336: done, saving took 1.28 seconds\n",
      "2021-11-02 08:57:36.290594: This epoch took 292.193436 s\n",
      "\n",
      "2021-11-02 08:57:36.307279: \n",
      "epoch:  90\n",
      "2021-11-02 09:02:08.698285: train loss : -0.8698\n",
      "2021-11-02 09:02:25.932276: validation loss: -0.8488\n",
      "2021-11-02 09:02:25.935930: Average global foreground Dice: [0.8635]\n",
      "2021-11-02 09:02:25.942756: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 09:02:26.432353: lr: 0.001145\n",
      "2021-11-02 09:02:26.515111: saving checkpoint...\n",
      "2021-11-02 09:02:27.783014: done, saving took 1.33 seconds\n",
      "2021-11-02 09:02:28.389853: This epoch took 292.076466 s\n",
      "\n",
      "2021-11-02 09:02:28.397960: \n",
      "epoch:  91\n",
      "2021-11-02 09:07:00.862752: train loss : -0.8702\n",
      "2021-11-02 09:07:18.293268: validation loss: -0.8424\n",
      "2021-11-02 09:07:18.297258: Average global foreground Dice: [0.8586]\n",
      "2021-11-02 09:07:18.304153: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 09:07:18.800440: lr: 0.00103\n",
      "2021-11-02 09:07:18.837609: This epoch took 290.432576 s\n",
      "\n",
      "2021-11-02 09:07:18.844972: \n",
      "epoch:  92\n",
      "2021-11-02 09:11:51.041808: train loss : -0.8722\n",
      "2021-11-02 09:12:08.478780: validation loss: -0.8493\n",
      "2021-11-02 09:12:08.482938: Average global foreground Dice: [0.8677]\n",
      "2021-11-02 09:12:08.489600: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 09:12:08.982541: lr: 0.000913\n",
      "2021-11-02 09:12:09.082248: saving checkpoint...\n",
      "2021-11-02 09:12:10.362270: done, saving took 1.34 seconds\n",
      "2021-11-02 09:12:10.976810: This epoch took 292.123964 s\n",
      "\n",
      "2021-11-02 09:12:10.995216: \n",
      "epoch:  93\n",
      "2021-11-02 09:16:42.071609: train loss : -0.8702\n",
      "2021-11-02 09:16:59.309669: validation loss: -0.8518\n",
      "2021-11-02 09:16:59.313127: Average global foreground Dice: [0.865]\n",
      "2021-11-02 09:16:59.320067: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 09:16:59.806599: lr: 0.000795\n",
      "2021-11-02 09:16:59.853605: saving checkpoint...\n",
      "2021-11-02 09:17:01.082079: done, saving took 1.26 seconds\n",
      "2021-11-02 09:17:01.782710: This epoch took 290.780522 s\n",
      "\n",
      "2021-11-02 09:17:01.791115: \n",
      "epoch:  94\n",
      "2021-11-02 09:21:32.147606: train loss : -0.8693\n",
      "2021-11-02 09:21:49.375944: validation loss: -0.8520\n",
      "2021-11-02 09:21:49.379775: Average global foreground Dice: [0.8685]\n",
      "2021-11-02 09:21:49.385790: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 09:21:49.873783: lr: 0.000675\n",
      "2021-11-02 09:21:49.922138: saving checkpoint...\n",
      "2021-11-02 09:21:51.142862: done, saving took 1.25 seconds\n",
      "2021-11-02 09:21:51.803532: This epoch took 290.005448 s\n",
      "\n",
      "2021-11-02 09:21:51.812452: \n",
      "epoch:  95\n",
      "2021-11-02 09:26:23.056476: train loss : -0.8729\n",
      "2021-11-02 09:26:40.315973: validation loss: -0.8520\n",
      "2021-11-02 09:26:40.319751: Average global foreground Dice: [0.8675]\n",
      "2021-11-02 09:26:40.326605: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 09:26:40.815579: lr: 0.000552\n",
      "2021-11-02 09:26:40.864287: saving checkpoint...\n",
      "2021-11-02 09:26:42.080711: done, saving took 1.25 seconds\n",
      "2021-11-02 09:26:42.783361: This epoch took 290.963928 s\n",
      "\n",
      "2021-11-02 09:26:42.791575: \n",
      "epoch:  96\n",
      "2021-11-02 09:31:13.403030: train loss : -0.8713\n",
      "2021-11-02 09:31:30.636280: validation loss: -0.8585\n",
      "2021-11-02 09:31:30.639852: Average global foreground Dice: [0.8723]\n",
      "2021-11-02 09:31:30.646475: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 09:31:31.136384: lr: 0.000426\n",
      "2021-11-02 09:31:31.184062: saving checkpoint...\n",
      "2021-11-02 09:31:32.421146: done, saving took 1.27 seconds\n",
      "2021-11-02 09:31:33.063329: This epoch took 290.264397 s\n",
      "\n",
      "2021-11-02 09:31:33.072026: \n",
      "epoch:  97\n",
      "2021-11-02 09:36:04.995694: train loss : -0.8735\n",
      "2021-11-02 09:36:22.322261: validation loss: -0.8509\n",
      "2021-11-02 09:36:22.327910: Average global foreground Dice: [0.8687]\n",
      "2021-11-02 09:36:22.334519: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 09:36:22.823107: lr: 0.000296\n",
      "2021-11-02 09:36:22.870231: saving checkpoint...\n",
      "2021-11-02 09:36:24.113838: done, saving took 1.27 seconds\n",
      "2021-11-02 09:36:24.720196: This epoch took 291.641057 s\n",
      "\n",
      "2021-11-02 09:36:24.728641: \n",
      "epoch:  98\n",
      "2021-11-02 09:40:56.340197: train loss : -0.8719\n",
      "2021-11-02 09:41:13.591297: validation loss: -0.8505\n",
      "2021-11-02 09:41:13.595111: Average global foreground Dice: [0.8674]\n",
      "2021-11-02 09:41:13.602314: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 09:41:14.087282: lr: 0.000158\n",
      "2021-11-02 09:41:14.157954: saving checkpoint...\n",
      "2021-11-02 09:41:15.448061: done, saving took 1.34 seconds\n",
      "2021-11-02 09:41:16.073669: This epoch took 291.338509 s\n",
      "\n",
      "2021-11-02 09:41:16.081858: \n",
      "epoch:  99\n",
      "2021-11-02 09:45:47.807748: train loss : -0.8704\n",
      "2021-11-02 09:46:05.042045: validation loss: -0.8567\n",
      "2021-11-02 09:46:05.045755: Average global foreground Dice: [0.8699]\n",
      "2021-11-02 09:46:05.051959: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 09:46:05.534609: lr: 0.0\n",
      "2021-11-02 09:46:05.552524: saving scheduled checkpoint file...\n",
      "2021-11-02 09:46:05.589091: saving checkpoint...\n",
      "2021-11-02 09:46:06.811471: done, saving took 1.25 seconds\n",
      "2021-11-02 09:46:07.518953: done\n",
      "2021-11-02 09:46:07.557417: saving checkpoint...\n",
      "2021-11-02 09:46:08.784036: done, saving took 1.26 seconds\n",
      "2021-11-02 09:46:09.460822: This epoch took 293.371960 s\n",
      "\n",
      "2021-11-02 09:46:09.497784: saving checkpoint...\n",
      "2021-11-02 09:46:10.432233: done, saving took 0.96 seconds\n",
      "23090557_20130717 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090560_20160114 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090562_20140206 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141215 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130626 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140124 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121015 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090597_20130227 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130208 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090621_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150105 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130807 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090637_20140401 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131126 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090644_20131216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-02 09:49:26.700413: finished prediction\n",
      "2021-11-02 09:49:26.712593: evaluation of raw predictions\n",
      "2021-11-02 09:49:28.622500: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8613486453344841\n",
      "after:  0.8613486453344841\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-02 09:49:41.221192: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-02 09:49:41.243190: The split file contains 5 splits.\n",
      "2021-11-02 09:49:41.250168: Desired fold for training: 4\n",
      "2021-11-02 09:49:41.257136: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-02 09:49:45.553283: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-02 09:50:02.938070: Unable to plot network architecture:\n",
      "2021-11-02 09:50:02.941315: No module named 'hiddenlayer'\n",
      "2021-11-02 09:50:02.947620: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-02 09:50:02.954790: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-02 09:50:03.039193: \n",
      "\n",
      "2021-11-02 09:50:03.045464: \n",
      "epoch:  0\n",
      "2021-11-02 09:54:52.477389: train loss : -0.1638\n",
      "2021-11-02 09:55:09.806160: validation loss: -0.5394\n",
      "2021-11-02 09:55:09.810062: Average global foreground Dice: [0.6223]\n",
      "2021-11-02 09:55:09.817051: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 09:55:10.239681: lr: 0.00991\n",
      "2021-11-02 09:55:10.256886: This epoch took 307.204523 s\n",
      "\n",
      "2021-11-02 09:55:10.265046: \n",
      "epoch:  1\n",
      "2021-11-02 09:59:39.416379: train loss : -0.5766\n",
      "2021-11-02 09:59:56.798881: validation loss: -0.6664\n",
      "2021-11-02 09:59:56.802568: Average global foreground Dice: [0.71]\n",
      "2021-11-02 09:59:56.808934: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 09:59:57.290979: lr: 0.00982\n",
      "2021-11-02 09:59:57.384665: saving checkpoint...\n",
      "2021-11-02 09:59:58.351526: done, saving took 1.04 seconds\n",
      "2021-11-02 09:59:59.033968: This epoch took 288.762047 s\n",
      "\n",
      "2021-11-02 09:59:59.042284: \n",
      "epoch:  2\n",
      "2021-11-02 10:04:29.188006: train loss : -0.6619\n",
      "2021-11-02 10:04:46.943826: validation loss: -0.6904\n",
      "2021-11-02 10:04:46.947483: Average global foreground Dice: [0.7228]\n",
      "2021-11-02 10:04:46.954062: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 10:04:47.450201: lr: 0.00973\n",
      "2021-11-02 10:04:47.533016: saving checkpoint...\n",
      "2021-11-02 10:04:48.770439: done, saving took 1.30 seconds\n",
      "2021-11-02 10:04:49.390186: This epoch took 290.340789 s\n",
      "\n",
      "2021-11-02 10:04:49.398067: \n",
      "epoch:  3\n",
      "2021-11-02 10:09:18.806469: train loss : -0.7149\n",
      "2021-11-02 10:09:36.156303: validation loss: -0.7399\n",
      "2021-11-02 10:09:36.160335: Average global foreground Dice: [0.7784]\n",
      "2021-11-02 10:09:36.166718: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 10:09:36.660770: lr: 0.009639\n",
      "2021-11-02 10:09:36.736721: saving checkpoint...\n",
      "2021-11-02 10:09:38.042117: done, saving took 1.37 seconds\n",
      "2021-11-02 10:09:38.647990: This epoch took 289.244343 s\n",
      "\n",
      "2021-11-02 10:09:38.656761: \n",
      "epoch:  4\n",
      "2021-11-02 10:14:05.934622: train loss : -0.7432\n",
      "2021-11-02 10:14:23.116907: validation loss: -0.7745\n",
      "2021-11-02 10:14:23.121000: Average global foreground Dice: [0.8135]\n",
      "2021-11-02 10:14:23.126807: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 10:14:23.647840: lr: 0.009549\n",
      "2021-11-02 10:14:23.782467: saving checkpoint...\n",
      "2021-11-02 10:14:25.140663: done, saving took 1.41 seconds\n",
      "2021-11-02 10:14:26.097165: This epoch took 287.433958 s\n",
      "\n",
      "2021-11-02 10:14:26.106738: \n",
      "epoch:  5\n",
      "2021-11-02 10:18:52.936722: train loss : -0.7588\n",
      "2021-11-02 10:19:10.181467: validation loss: -0.7901\n",
      "2021-11-02 10:19:10.185017: Average global foreground Dice: [0.8246]\n",
      "2021-11-02 10:19:10.191253: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 10:19:10.663732: lr: 0.009458\n",
      "2021-11-02 10:19:10.749408: saving checkpoint...\n",
      "2021-11-02 10:19:11.979890: done, saving took 1.29 seconds\n",
      "2021-11-02 10:19:12.668134: This epoch took 286.554519 s\n",
      "\n",
      "2021-11-02 10:19:12.676835: \n",
      "epoch:  6\n",
      "2021-11-02 10:23:41.032932: train loss : -0.7769\n",
      "2021-11-02 10:23:58.455813: validation loss: -0.7946\n",
      "2021-11-02 10:23:58.459802: Average global foreground Dice: [0.828]\n",
      "2021-11-02 10:23:58.465336: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 10:23:58.947869: lr: 0.009368\n",
      "2021-11-02 10:23:59.029880: saving checkpoint...\n",
      "2021-11-02 10:24:00.267676: done, saving took 1.30 seconds\n",
      "2021-11-02 10:24:01.092886: This epoch took 288.408859 s\n",
      "\n",
      "2021-11-02 10:24:01.102464: \n",
      "epoch:  7\n",
      "2021-11-02 10:28:30.100207: train loss : -0.7821\n",
      "2021-11-02 10:28:47.421759: validation loss: -0.8045\n",
      "2021-11-02 10:28:47.425453: Average global foreground Dice: [0.8292]\n",
      "2021-11-02 10:28:47.432549: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 10:28:47.911232: lr: 0.009277\n",
      "2021-11-02 10:28:47.994432: saving checkpoint...\n",
      "2021-11-02 10:28:49.237006: done, saving took 1.31 seconds\n",
      "2021-11-02 10:28:49.985860: This epoch took 288.876855 s\n",
      "\n",
      "2021-11-02 10:28:49.993973: \n",
      "epoch:  8\n",
      "2021-11-02 10:33:19.235318: train loss : -0.7869\n",
      "2021-11-02 10:33:36.567834: validation loss: -0.8100\n",
      "2021-11-02 10:33:36.571373: Average global foreground Dice: [0.8376]\n",
      "2021-11-02 10:33:36.577745: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 10:33:37.055522: lr: 0.009186\n",
      "2021-11-02 10:33:37.131350: saving checkpoint...\n",
      "2021-11-02 10:33:38.390175: done, saving took 1.32 seconds\n",
      "2021-11-02 10:33:39.010980: This epoch took 289.009802 s\n",
      "\n",
      "2021-11-02 10:33:39.019059: \n",
      "epoch:  9\n",
      "2021-11-02 10:38:08.128740: train loss : -0.7824\n",
      "2021-11-02 10:38:25.459871: validation loss: -0.8094\n",
      "2021-11-02 10:38:25.463531: Average global foreground Dice: [0.8332]\n",
      "2021-11-02 10:38:25.469963: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 10:38:25.949786: lr: 0.009095\n",
      "2021-11-02 10:38:26.031096: saving checkpoint...\n",
      "2021-11-02 10:38:27.321876: done, saving took 1.35 seconds\n",
      "2021-11-02 10:38:27.963212: This epoch took 288.936734 s\n",
      "\n",
      "2021-11-02 10:38:27.971621: \n",
      "epoch:  10\n",
      "2021-11-02 10:42:56.128999: train loss : -0.7969\n",
      "2021-11-02 10:43:13.331665: validation loss: -0.8141\n",
      "2021-11-02 10:43:13.335672: Average global foreground Dice: [0.8364]\n",
      "2021-11-02 10:43:13.341966: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 10:43:13.836921: lr: 0.009004\n",
      "2021-11-02 10:43:13.886095: saving checkpoint...\n",
      "2021-11-02 10:43:15.112113: done, saving took 1.25 seconds\n",
      "2021-11-02 10:43:15.924792: This epoch took 287.945529 s\n",
      "\n",
      "2021-11-02 10:43:15.934037: \n",
      "epoch:  11\n",
      "2021-11-02 10:47:44.652910: train loss : -0.8014\n",
      "2021-11-02 10:48:01.842691: validation loss: -0.8138\n",
      "2021-11-02 10:48:01.846804: Average global foreground Dice: [0.8363]\n",
      "2021-11-02 10:48:01.853982: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 10:48:02.319674: lr: 0.008913\n",
      "2021-11-02 10:48:02.382716: saving checkpoint...\n",
      "2021-11-02 10:48:03.618064: done, saving took 1.26 seconds\n",
      "2021-11-02 10:48:04.403367: This epoch took 288.461570 s\n",
      "\n",
      "2021-11-02 10:48:04.421619: \n",
      "epoch:  12\n",
      "2021-11-02 10:52:31.938499: train loss : -0.8047\n",
      "2021-11-02 10:52:49.127980: validation loss: -0.8165\n",
      "2021-11-02 10:52:49.133167: Average global foreground Dice: [0.8424]\n",
      "2021-11-02 10:52:49.139769: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 10:52:49.607825: lr: 0.008822\n",
      "2021-11-02 10:52:49.659546: saving checkpoint...\n",
      "2021-11-02 10:52:50.910658: done, saving took 1.28 seconds\n",
      "2021-11-02 10:52:51.674355: This epoch took 287.245914 s\n",
      "\n",
      "2021-11-02 10:52:51.682667: \n",
      "epoch:  13\n",
      "2021-11-02 10:57:19.950738: train loss : -0.8036\n",
      "2021-11-02 10:57:37.166097: validation loss: -0.8121\n",
      "2021-11-02 10:57:37.170176: Average global foreground Dice: [0.8333]\n",
      "2021-11-02 10:57:37.177720: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 10:57:37.642312: lr: 0.008731\n",
      "2021-11-02 10:57:37.687466: saving checkpoint...\n",
      "2021-11-02 10:57:38.916359: done, saving took 1.26 seconds\n",
      "2021-11-02 10:57:39.589216: This epoch took 287.899319 s\n",
      "\n",
      "2021-11-02 10:57:39.597800: \n",
      "epoch:  14\n",
      "2021-11-02 11:02:07.313861: train loss : -0.8113\n",
      "2021-11-02 11:02:24.469088: validation loss: -0.8194\n",
      "2021-11-02 11:02:24.473073: Average global foreground Dice: [0.8398]\n",
      "2021-11-02 11:02:24.479024: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 11:02:24.949831: lr: 0.008639\n",
      "2021-11-02 11:02:24.994879: saving checkpoint...\n",
      "2021-11-02 11:02:26.368212: done, saving took 1.40 seconds\n",
      "2021-11-02 11:02:27.018703: This epoch took 287.413286 s\n",
      "\n",
      "2021-11-02 11:02:27.027242: \n",
      "epoch:  15\n",
      "2021-11-02 11:06:55.434436: train loss : -0.8124\n",
      "2021-11-02 11:07:12.869095: validation loss: -0.8263\n",
      "2021-11-02 11:07:12.872966: Average global foreground Dice: [0.8432]\n",
      "2021-11-02 11:07:12.879899: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 11:07:13.350482: lr: 0.008548\n",
      "2021-11-02 11:07:13.426501: saving checkpoint...\n",
      "2021-11-02 11:07:14.715475: done, saving took 1.35 seconds\n",
      "2021-11-02 11:07:15.320704: This epoch took 288.285709 s\n",
      "\n",
      "2021-11-02 11:07:15.329136: \n",
      "epoch:  16\n",
      "2021-11-02 11:11:44.820414: train loss : -0.8152\n",
      "2021-11-02 11:12:02.018277: validation loss: -0.8266\n",
      "2021-11-02 11:12:02.021931: Average global foreground Dice: [0.8484]\n",
      "2021-11-02 11:12:02.029346: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 11:12:02.502259: lr: 0.008456\n",
      "2021-11-02 11:12:02.547513: saving checkpoint...\n",
      "2021-11-02 11:12:03.782101: done, saving took 1.26 seconds\n",
      "2021-11-02 11:12:04.384545: This epoch took 289.048691 s\n",
      "\n",
      "2021-11-02 11:12:04.392997: \n",
      "epoch:  17\n",
      "2021-11-02 11:16:32.986163: train loss : -0.8209\n",
      "2021-11-02 11:16:50.184185: validation loss: -0.8340\n",
      "2021-11-02 11:16:50.187950: Average global foreground Dice: [0.8483]\n",
      "2021-11-02 11:16:50.194015: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 11:16:50.668556: lr: 0.008364\n",
      "2021-11-02 11:16:50.713947: saving checkpoint...\n",
      "2021-11-02 11:16:51.940217: done, saving took 1.25 seconds\n",
      "2021-11-02 11:16:52.667380: This epoch took 288.267537 s\n",
      "\n",
      "2021-11-02 11:16:52.675395: \n",
      "epoch:  18\n",
      "2021-11-02 11:21:21.666193: train loss : -0.8261\n",
      "2021-11-02 11:21:38.874066: validation loss: -0.8218\n",
      "2021-11-02 11:21:38.877833: Average global foreground Dice: [0.8411]\n",
      "2021-11-02 11:21:38.884616: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 11:21:39.352396: lr: 0.008272\n",
      "2021-11-02 11:21:39.399032: saving checkpoint...\n",
      "2021-11-02 11:21:40.632427: done, saving took 1.26 seconds\n",
      "2021-11-02 11:21:41.267179: This epoch took 288.585844 s\n",
      "\n",
      "2021-11-02 11:21:41.274810: \n",
      "epoch:  19\n",
      "2021-11-02 11:26:10.073959: train loss : -0.8218\n",
      "2021-11-02 11:26:27.497212: validation loss: -0.8287\n",
      "2021-11-02 11:26:27.501170: Average global foreground Dice: [0.8479]\n",
      "2021-11-02 11:26:27.507447: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 11:26:27.975813: lr: 0.008181\n",
      "2021-11-02 11:26:28.029155: saving checkpoint...\n",
      "2021-11-02 11:26:29.278480: done, saving took 1.28 seconds\n",
      "2021-11-02 11:26:29.906468: This epoch took 288.624843 s\n",
      "\n",
      "2021-11-02 11:26:29.916121: \n",
      "epoch:  20\n",
      "2021-11-02 11:30:59.751450: train loss : -0.8235\n",
      "2021-11-02 11:31:17.077849: validation loss: -0.8140\n",
      "2021-11-02 11:31:17.082311: Average global foreground Dice: [0.8353]\n",
      "2021-11-02 11:31:17.088858: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 11:31:17.562722: lr: 0.008088\n",
      "2021-11-02 11:31:17.633554: saving checkpoint...\n",
      "2021-11-02 11:31:18.888433: done, saving took 1.31 seconds\n",
      "2021-11-02 11:31:19.535423: This epoch took 289.611974 s\n",
      "\n",
      "2021-11-02 11:31:19.543516: \n",
      "epoch:  21\n",
      "2021-11-02 11:35:49.484211: train loss : -0.8264\n",
      "2021-11-02 11:36:07.109922: validation loss: -0.8336\n",
      "2021-11-02 11:36:07.114213: Average global foreground Dice: [0.8548]\n",
      "2021-11-02 11:36:07.120762: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 11:36:07.599909: lr: 0.007996\n",
      "2021-11-02 11:36:07.671851: saving checkpoint...\n",
      "2021-11-02 11:36:08.924145: done, saving took 1.31 seconds\n",
      "2021-11-02 11:36:09.574038: This epoch took 290.023429 s\n",
      "\n",
      "2021-11-02 11:36:09.582957: \n",
      "epoch:  22\n",
      "2021-11-02 11:40:39.100797: train loss : -0.8249\n",
      "2021-11-02 11:40:56.402795: validation loss: -0.8255\n",
      "2021-11-02 11:40:56.406573: Average global foreground Dice: [0.8429]\n",
      "2021-11-02 11:40:56.424122: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 11:40:56.912059: lr: 0.007904\n",
      "2021-11-02 11:40:56.985424: saving checkpoint...\n",
      "2021-11-02 11:40:58.264731: done, saving took 1.34 seconds\n",
      "2021-11-02 11:40:58.948524: This epoch took 289.358325 s\n",
      "\n",
      "2021-11-02 11:40:58.957383: \n",
      "epoch:  23\n",
      "2021-11-02 11:45:27.637773: train loss : -0.8285\n",
      "2021-11-02 11:45:44.851094: validation loss: -0.8201\n",
      "2021-11-02 11:45:44.855510: Average global foreground Dice: [0.8369]\n",
      "2021-11-02 11:45:44.862288: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 11:45:45.330764: lr: 0.007811\n",
      "2021-11-02 11:45:45.375985: saving checkpoint...\n",
      "2021-11-02 11:45:46.602607: done, saving took 1.26 seconds\n",
      "2021-11-02 11:45:47.314599: This epoch took 288.350380 s\n",
      "\n",
      "2021-11-02 11:45:47.323076: \n",
      "epoch:  24\n",
      "2021-11-02 11:50:16.978199: train loss : -0.8271\n",
      "2021-11-02 11:50:34.220083: validation loss: -0.8295\n",
      "2021-11-02 11:50:34.223847: Average global foreground Dice: [0.8465]\n",
      "2021-11-02 11:50:34.231241: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 11:50:34.696446: lr: 0.007719\n",
      "2021-11-02 11:50:34.741655: saving checkpoint...\n",
      "2021-11-02 11:50:35.961780: done, saving took 1.25 seconds\n",
      "2021-11-02 11:50:36.664799: This epoch took 289.333755 s\n",
      "\n",
      "2021-11-02 11:50:36.673662: \n",
      "epoch:  25\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-02 11:55:05.877634: train loss : -0.8276\n",
      "2021-11-02 11:55:23.055314: validation loss: -0.8231\n",
      "2021-11-02 11:55:23.059479: Average global foreground Dice: [0.8433]\n",
      "2021-11-02 11:55:23.066226: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 11:55:23.537257: lr: 0.007626\n",
      "2021-11-02 11:55:23.581880: saving checkpoint...\n",
      "2021-11-02 11:55:24.829560: done, saving took 1.28 seconds\n",
      "2021-11-02 11:55:25.488745: This epoch took 288.808599 s\n",
      "\n",
      "2021-11-02 11:55:25.496748: \n",
      "epoch:  26\n",
      "2021-11-02 11:59:54.198061: train loss : -0.8318\n",
      "2021-11-02 12:00:11.482496: validation loss: -0.8235\n",
      "2021-11-02 12:00:11.486673: Average global foreground Dice: [0.8458]\n",
      "2021-11-02 12:00:11.493271: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 12:00:11.959949: lr: 0.007533\n",
      "2021-11-02 12:00:12.005474: saving checkpoint...\n",
      "2021-11-02 12:00:13.254595: done, saving took 1.28 seconds\n",
      "2021-11-02 12:00:13.860160: This epoch took 288.357642 s\n",
      "\n",
      "2021-11-02 12:00:13.868490: \n",
      "epoch:  27\n",
      "2021-11-02 12:04:43.510082: train loss : -0.8286\n",
      "2021-11-02 12:05:00.682124: validation loss: -0.8247\n",
      "2021-11-02 12:05:00.686168: Average global foreground Dice: [0.8441]\n",
      "2021-11-02 12:05:00.691826: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 12:05:01.165251: lr: 0.00744\n",
      "2021-11-02 12:05:01.209810: saving checkpoint...\n",
      "2021-11-02 12:05:02.476184: done, saving took 1.30 seconds\n",
      "2021-11-02 12:05:03.081224: This epoch took 289.205453 s\n",
      "\n",
      "2021-11-02 12:05:03.090335: \n",
      "epoch:  28\n",
      "2021-11-02 12:09:32.077565: train loss : -0.8283\n",
      "2021-11-02 12:09:49.399498: validation loss: -0.8273\n",
      "2021-11-02 12:09:49.403662: Average global foreground Dice: [0.843]\n",
      "2021-11-02 12:09:49.409757: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 12:09:49.887592: lr: 0.007347\n",
      "2021-11-02 12:09:49.968504: saving checkpoint...\n",
      "2021-11-02 12:09:51.245087: done, saving took 1.34 seconds\n",
      "2021-11-02 12:09:51.883275: This epoch took 288.785630 s\n",
      "\n",
      "2021-11-02 12:09:51.891249: \n",
      "epoch:  29\n",
      "2021-11-02 12:14:20.492203: train loss : -0.8341\n",
      "2021-11-02 12:14:37.694710: validation loss: -0.8292\n",
      "2021-11-02 12:14:37.698957: Average global foreground Dice: [0.8483]\n",
      "2021-11-02 12:14:37.705980: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 12:14:38.173246: lr: 0.007254\n",
      "2021-11-02 12:14:38.222791: saving checkpoint...\n",
      "2021-11-02 12:14:39.448852: done, saving took 1.25 seconds\n",
      "2021-11-02 12:14:40.225885: This epoch took 288.328007 s\n",
      "\n",
      "2021-11-02 12:14:40.234235: \n",
      "epoch:  30\n",
      "2021-11-02 12:19:09.142295: train loss : -0.8372\n",
      "2021-11-02 12:19:26.349618: validation loss: -0.8390\n",
      "2021-11-02 12:19:26.353486: Average global foreground Dice: [0.8531]\n",
      "2021-11-02 12:19:26.360139: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 12:19:26.832592: lr: 0.007161\n",
      "2021-11-02 12:19:26.879634: saving checkpoint...\n",
      "2021-11-02 12:19:28.105126: done, saving took 1.25 seconds\n",
      "2021-11-02 12:19:28.978220: This epoch took 288.736578 s\n",
      "\n",
      "2021-11-02 12:19:28.987178: \n",
      "epoch:  31\n",
      "2021-11-02 12:23:58.150284: train loss : -0.8361\n",
      "2021-11-02 12:24:15.383533: validation loss: -0.8297\n",
      "2021-11-02 12:24:15.387411: Average global foreground Dice: [0.8481]\n",
      "2021-11-02 12:24:15.394478: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 12:24:15.864282: lr: 0.007067\n",
      "2021-11-02 12:24:15.917893: saving checkpoint...\n",
      "2021-11-02 12:24:17.162588: done, saving took 1.27 seconds\n",
      "2021-11-02 12:24:17.921975: This epoch took 288.927502 s\n",
      "\n",
      "2021-11-02 12:24:17.930120: \n",
      "epoch:  32\n",
      "2021-11-02 12:28:46.779645: train loss : -0.8322\n",
      "2021-11-02 12:29:04.244283: validation loss: -0.8360\n",
      "2021-11-02 12:29:04.248965: Average global foreground Dice: [0.8496]\n",
      "2021-11-02 12:29:04.255729: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 12:29:04.733375: lr: 0.006974\n",
      "2021-11-02 12:29:04.787678: saving checkpoint...\n",
      "2021-11-02 12:29:06.034583: done, saving took 1.28 seconds\n",
      "2021-11-02 12:29:06.899888: This epoch took 288.961811 s\n",
      "\n",
      "2021-11-02 12:29:06.933838: \n",
      "epoch:  33\n",
      "2021-11-02 12:33:36.272019: train loss : -0.8390\n",
      "2021-11-02 12:33:53.453099: validation loss: -0.8333\n",
      "2021-11-02 12:33:53.457028: Average global foreground Dice: [0.8494]\n",
      "2021-11-02 12:33:53.464634: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 12:33:53.932224: lr: 0.00688\n",
      "2021-11-02 12:33:54.007045: saving checkpoint...\n",
      "2021-11-02 12:33:55.247840: done, saving took 1.30 seconds\n",
      "2021-11-02 12:33:57.701350: This epoch took 290.740947 s\n",
      "\n",
      "2021-11-02 12:33:57.710010: \n",
      "epoch:  34\n",
      "2021-11-02 12:38:28.382643: train loss : -0.8377\n",
      "2021-11-02 12:38:46.599508: validation loss: -0.8333\n",
      "2021-11-02 12:38:46.602890: Average global foreground Dice: [0.8492]\n",
      "2021-11-02 12:38:46.609964: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 12:38:47.082102: lr: 0.006786\n",
      "2021-11-02 12:38:47.157552: saving checkpoint...\n",
      "2021-11-02 12:38:48.445885: done, saving took 1.35 seconds\n",
      "2021-11-02 12:38:49.050561: This epoch took 291.332587 s\n",
      "\n",
      "2021-11-02 12:38:49.058999: \n",
      "epoch:  35\n",
      "2021-11-02 12:43:18.479279: train loss : -0.8404\n",
      "2021-11-02 12:43:35.778676: validation loss: -0.8298\n",
      "2021-11-02 12:43:35.782836: Average global foreground Dice: [0.8497]\n",
      "2021-11-02 12:43:35.789458: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 12:43:36.259267: lr: 0.006692\n",
      "2021-11-02 12:43:36.373712: saving checkpoint...\n",
      "2021-11-02 12:43:37.597220: done, saving took 1.25 seconds\n",
      "2021-11-02 12:43:38.333217: This epoch took 289.267015 s\n",
      "\n",
      "2021-11-02 12:43:38.342314: \n",
      "epoch:  36\n",
      "2021-11-02 12:48:08.154423: train loss : -0.8353\n",
      "2021-11-02 12:48:25.339630: validation loss: -0.8329\n",
      "2021-11-02 12:48:25.343285: Average global foreground Dice: [0.8499]\n",
      "2021-11-02 12:48:25.349741: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 12:48:25.828320: lr: 0.006598\n",
      "2021-11-02 12:48:25.872698: saving checkpoint...\n",
      "2021-11-02 12:48:27.119307: done, saving took 1.28 seconds\n",
      "2021-11-02 12:48:27.729823: This epoch took 289.379617 s\n",
      "\n",
      "2021-11-02 12:48:27.737877: \n",
      "epoch:  37\n",
      "2021-11-02 12:52:57.694575: train loss : -0.8380\n",
      "2021-11-02 12:53:14.910346: validation loss: -0.8252\n",
      "2021-11-02 12:53:14.914451: Average global foreground Dice: [0.8423]\n",
      "2021-11-02 12:53:14.921839: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 12:53:15.392391: lr: 0.006504\n",
      "2021-11-02 12:53:15.438215: saving checkpoint...\n",
      "2021-11-02 12:53:16.676993: done, saving took 1.27 seconds\n",
      "2021-11-02 12:53:17.334884: This epoch took 289.589377 s\n",
      "\n",
      "2021-11-02 12:53:17.343262: \n",
      "epoch:  38\n",
      "2021-11-02 12:57:47.144319: train loss : -0.8390\n",
      "2021-11-02 12:58:04.382460: validation loss: -0.8351\n",
      "2021-11-02 12:58:04.386494: Average global foreground Dice: [0.8481]\n",
      "2021-11-02 12:58:04.393660: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 12:58:04.860320: lr: 0.006409\n",
      "2021-11-02 12:58:04.906362: saving checkpoint...\n",
      "2021-11-02 12:58:06.136861: done, saving took 1.26 seconds\n",
      "2021-11-02 12:58:06.901365: This epoch took 289.550661 s\n",
      "\n",
      "2021-11-02 12:58:06.909876: \n",
      "epoch:  39\n",
      "2021-11-02 13:02:37.154452: train loss : -0.8446\n",
      "2021-11-02 13:02:54.474417: validation loss: -0.8349\n",
      "2021-11-02 13:02:54.478547: Average global foreground Dice: [0.8493]\n",
      "2021-11-02 13:02:54.485916: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 13:02:54.966023: lr: 0.006314\n",
      "2021-11-02 13:02:55.043838: saving checkpoint...\n",
      "2021-11-02 13:02:56.320557: done, saving took 1.34 seconds\n",
      "2021-11-02 13:02:56.945472: This epoch took 290.027777 s\n",
      "\n",
      "2021-11-02 13:02:56.956950: \n",
      "epoch:  40\n",
      "2021-11-02 13:07:27.404917: train loss : -0.8442\n",
      "2021-11-02 13:07:44.751402: validation loss: -0.8327\n",
      "2021-11-02 13:07:44.755734: Average global foreground Dice: [0.8526]\n",
      "2021-11-02 13:07:44.762117: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 13:07:45.254910: lr: 0.00622\n",
      "2021-11-02 13:07:45.325127: saving checkpoint...\n",
      "2021-11-02 13:07:46.608638: done, saving took 1.34 seconds\n",
      "2021-11-02 13:07:47.300986: This epoch took 290.335706 s\n",
      "\n",
      "2021-11-02 13:07:47.309261: \n",
      "epoch:  41\n",
      "2021-11-02 13:12:16.156235: train loss : -0.8430\n",
      "2021-11-02 13:12:33.330788: validation loss: -0.8427\n",
      "2021-11-02 13:12:33.334672: Average global foreground Dice: [0.8568]\n",
      "2021-11-02 13:12:33.341154: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 13:12:33.806451: lr: 0.006125\n",
      "2021-11-02 13:12:33.850430: saving checkpoint...\n",
      "2021-11-02 13:12:35.080943: done, saving took 1.26 seconds\n",
      "2021-11-02 13:12:35.672759: This epoch took 288.356991 s\n",
      "\n",
      "2021-11-02 13:12:35.681167: \n",
      "epoch:  42\n",
      "2021-11-02 13:17:04.497139: train loss : -0.8425\n",
      "2021-11-02 13:17:21.715011: validation loss: -0.8470\n",
      "2021-11-02 13:17:21.718991: Average global foreground Dice: [0.8616]\n",
      "2021-11-02 13:17:21.725860: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 13:17:22.190521: lr: 0.00603\n",
      "2021-11-02 13:17:22.234924: saving checkpoint...\n",
      "2021-11-02 13:17:23.459956: done, saving took 1.25 seconds\n",
      "2021-11-02 13:17:24.097360: This epoch took 288.408985 s\n",
      "\n",
      "2021-11-02 13:17:24.105882: \n",
      "epoch:  43\n",
      "2021-11-02 13:21:53.204678: train loss : -0.8433\n",
      "2021-11-02 13:22:10.450774: validation loss: -0.8441\n",
      "2021-11-02 13:22:10.455372: Average global foreground Dice: [0.8562]\n",
      "2021-11-02 13:22:10.462132: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 13:22:10.977050: lr: 0.005934\n",
      "2021-11-02 13:22:11.025808: saving checkpoint...\n",
      "2021-11-02 13:22:12.255570: done, saving took 1.26 seconds\n",
      "2021-11-02 13:22:12.883269: This epoch took 288.770046 s\n",
      "\n",
      "2021-11-02 13:22:12.891772: \n",
      "epoch:  44\n",
      "2021-11-02 13:26:42.664582: train loss : -0.8437\n",
      "2021-11-02 13:26:59.921825: validation loss: -0.8340\n",
      "2021-11-02 13:26:59.925626: Average global foreground Dice: [0.852]\n",
      "2021-11-02 13:26:59.931930: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 13:27:00.399922: lr: 0.005839\n",
      "2021-11-02 13:27:00.445524: saving checkpoint...\n",
      "2021-11-02 13:27:01.660161: done, saving took 1.24 seconds\n",
      "2021-11-02 13:27:02.300303: This epoch took 289.401773 s\n",
      "\n",
      "2021-11-02 13:27:02.309222: \n",
      "epoch:  45\n",
      "2021-11-02 13:31:31.398997: train loss : -0.8456\n",
      "2021-11-02 13:31:48.567430: validation loss: -0.8455\n",
      "2021-11-02 13:31:48.570981: Average global foreground Dice: [0.8595]\n",
      "2021-11-02 13:31:48.578173: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 13:31:49.046472: lr: 0.005743\n",
      "2021-11-02 13:31:49.090689: saving checkpoint...\n",
      "2021-11-02 13:31:50.325769: done, saving took 1.26 seconds\n",
      "2021-11-02 13:31:50.975899: This epoch took 288.659663 s\n",
      "\n",
      "2021-11-02 13:31:50.985184: \n",
      "epoch:  46\n",
      "2021-11-02 13:36:21.084112: train loss : -0.8449\n",
      "2021-11-02 13:36:38.392485: validation loss: -0.8438\n",
      "2021-11-02 13:36:38.395904: Average global foreground Dice: [0.8597]\n",
      "2021-11-02 13:36:38.401585: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 13:36:38.878528: lr: 0.005647\n",
      "2021-11-02 13:36:38.946094: saving checkpoint...\n",
      "2021-11-02 13:36:40.181960: done, saving took 1.29 seconds\n",
      "2021-11-02 13:36:40.906067: This epoch took 289.908438 s\n",
      "\n",
      "2021-11-02 13:36:40.914635: \n",
      "epoch:  47\n",
      "2021-11-02 13:41:11.767756: train loss : -0.8455\n",
      "2021-11-02 13:41:29.195467: validation loss: -0.8311\n",
      "2021-11-02 13:41:29.199767: Average global foreground Dice: [0.8479]\n",
      "2021-11-02 13:41:29.207290: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 13:41:29.689916: lr: 0.005551\n",
      "2021-11-02 13:41:29.707266: This epoch took 288.784790 s\n",
      "\n",
      "2021-11-02 13:41:29.714949: \n",
      "epoch:  48\n",
      "2021-11-02 13:45:59.969011: train loss : -0.8487\n",
      "2021-11-02 13:46:17.381603: validation loss: -0.8360\n",
      "2021-11-02 13:46:17.385643: Average global foreground Dice: [0.8487]\n",
      "2021-11-02 13:46:17.391893: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 13:46:17.874861: lr: 0.005455\n",
      "2021-11-02 13:46:17.895272: This epoch took 288.172877 s\n",
      "\n",
      "2021-11-02 13:46:17.903154: \n",
      "epoch:  49\n",
      "2021-11-02 13:50:48.931220: train loss : -0.8479\n",
      "2021-11-02 13:51:06.328842: validation loss: -0.8390\n",
      "2021-11-02 13:51:06.332974: Average global foreground Dice: [0.8552]\n",
      "2021-11-02 13:51:06.340175: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 13:51:06.823619: lr: 0.005359\n",
      "2021-11-02 13:51:06.841494: saving scheduled checkpoint file...\n",
      "2021-11-02 13:51:06.900649: saving checkpoint...\n",
      "2021-11-02 13:51:07.870533: done, saving took 1.02 seconds\n",
      "2021-11-02 13:51:08.825881: done\n",
      "2021-11-02 13:51:08.865083: saving checkpoint...\n",
      "2021-11-02 13:51:10.087672: done, saving took 1.25 seconds\n",
      "2021-11-02 13:51:10.795602: This epoch took 292.884323 s\n",
      "\n",
      "2021-11-02 13:51:10.804628: \n",
      "epoch:  50\n",
      "2021-11-02 13:55:41.139508: train loss : -0.8507\n",
      "2021-11-02 13:55:58.473872: validation loss: -0.8388\n",
      "2021-11-02 13:55:58.477749: Average global foreground Dice: [0.8577]\n",
      "2021-11-02 13:55:58.483777: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 13:55:59.036027: lr: 0.005262\n",
      "2021-11-02 13:55:59.081641: saving checkpoint...\n",
      "2021-11-02 13:56:00.308911: done, saving took 1.26 seconds\n",
      "2021-11-02 13:56:00.930767: This epoch took 290.119292 s\n",
      "\n",
      "2021-11-02 13:56:00.939283: \n",
      "epoch:  51\n",
      "2021-11-02 14:00:30.465181: train loss : -0.8434\n",
      "2021-11-02 14:00:47.647103: validation loss: -0.8378\n",
      "2021-11-02 14:00:47.650596: Average global foreground Dice: [0.8541]\n",
      "2021-11-02 14:00:47.657613: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 14:00:48.126934: lr: 0.005166\n",
      "2021-11-02 14:00:48.172160: saving checkpoint...\n",
      "2021-11-02 14:00:49.390100: done, saving took 1.25 seconds\n",
      "2021-11-02 14:00:50.015046: This epoch took 289.068154 s\n",
      "\n",
      "2021-11-02 14:00:50.023331: \n",
      "epoch:  52\n",
      "2021-11-02 14:05:20.496765: train loss : -0.8421\n",
      "2021-11-02 14:05:37.687903: validation loss: -0.8441\n",
      "2021-11-02 14:05:37.691497: Average global foreground Dice: [0.8603]\n",
      "2021-11-02 14:05:37.698224: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 14:05:38.165304: lr: 0.005069\n",
      "2021-11-02 14:05:38.213699: saving checkpoint...\n",
      "2021-11-02 14:05:39.433822: done, saving took 1.25 seconds\n",
      "2021-11-02 14:05:40.090512: This epoch took 290.059140 s\n",
      "\n",
      "2021-11-02 14:05:40.099147: \n",
      "epoch:  53\n",
      "2021-11-02 14:10:10.480456: train loss : -0.8452\n",
      "2021-11-02 14:10:27.859344: validation loss: -0.8367\n",
      "2021-11-02 14:10:27.863012: Average global foreground Dice: [0.8481]\n",
      "2021-11-02 14:10:27.870020: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 14:10:28.342773: lr: 0.004971\n",
      "2021-11-02 14:10:28.361529: This epoch took 288.255558 s\n",
      "\n",
      "2021-11-02 14:10:28.368589: \n",
      "epoch:  54\n",
      "2021-11-02 14:14:58.881181: train loss : -0.8526\n",
      "2021-11-02 14:15:16.126048: validation loss: -0.8383\n",
      "2021-11-02 14:15:16.130269: Average global foreground Dice: [0.8522]\n",
      "2021-11-02 14:15:16.138843: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 14:15:16.611464: lr: 0.004874\n",
      "2021-11-02 14:15:16.626032: This epoch took 288.250843 s\n",
      "\n",
      "2021-11-02 14:15:16.633121: \n",
      "epoch:  55\n",
      "2021-11-02 14:19:47.122667: train loss : -0.8494\n",
      "2021-11-02 14:20:04.342477: validation loss: -0.8377\n",
      "2021-11-02 14:20:04.346772: Average global foreground Dice: [0.8554]\n",
      "2021-11-02 14:20:04.355662: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 14:20:04.823132: lr: 0.004776\n",
      "2021-11-02 14:20:04.839756: This epoch took 288.198984 s\n",
      "\n",
      "2021-11-02 14:20:04.846555: \n",
      "epoch:  56\n",
      "2021-11-02 14:24:42.002630: train loss : -0.8497\n",
      "2021-11-02 14:24:59.349258: validation loss: -0.8493\n",
      "2021-11-02 14:24:59.352965: Average global foreground Dice: [0.8663]\n",
      "2021-11-02 14:24:59.359645: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 14:24:59.826081: lr: 0.004679\n",
      "2021-11-02 14:24:59.872049: saving checkpoint...\n",
      "2021-11-02 14:25:01.102076: done, saving took 1.26 seconds\n",
      "2021-11-02 14:25:01.785330: This epoch took 296.930607 s\n",
      "\n",
      "2021-11-02 14:25:01.794067: \n",
      "epoch:  57\n",
      "2021-11-02 14:29:39.815416: train loss : -0.8499\n",
      "2021-11-02 14:29:57.102666: validation loss: -0.8354\n",
      "2021-11-02 14:29:57.107211: Average global foreground Dice: [0.8501]\n",
      "2021-11-02 14:29:57.114482: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 14:29:57.587831: lr: 0.004581\n",
      "2021-11-02 14:29:57.603125: This epoch took 295.801616 s\n",
      "\n",
      "2021-11-02 14:29:57.611120: \n",
      "epoch:  58\n",
      "2021-11-02 14:34:34.691267: train loss : -0.8500\n",
      "2021-11-02 14:34:52.240226: validation loss: -0.8350\n",
      "2021-11-02 14:34:52.245454: Average global foreground Dice: [0.8498]\n",
      "2021-11-02 14:34:52.251733: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 14:34:52.798015: lr: 0.004482\n",
      "2021-11-02 14:34:52.812706: This epoch took 295.194120 s\n",
      "\n",
      "2021-11-02 14:34:52.821565: \n",
      "epoch:  59\n",
      "2021-11-02 14:39:30.542427: train loss : -0.8515\n",
      "2021-11-02 14:39:47.919571: validation loss: -0.8456\n",
      "2021-11-02 14:39:47.923495: Average global foreground Dice: [0.8599]\n",
      "2021-11-02 14:39:47.930382: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 14:39:48.400970: lr: 0.004384\n",
      "2021-11-02 14:39:48.444693: saving checkpoint...\n",
      "2021-11-02 14:39:49.664893: done, saving took 1.25 seconds\n",
      "2021-11-02 14:39:50.273533: This epoch took 297.444359 s\n",
      "\n",
      "2021-11-02 14:39:50.282059: \n",
      "epoch:  60\n",
      "2021-11-02 14:44:26.468220: train loss : -0.8537\n",
      "2021-11-02 14:44:44.101067: validation loss: -0.8414\n",
      "2021-11-02 14:44:44.105072: Average global foreground Dice: [0.8589]\n",
      "2021-11-02 14:44:44.110955: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 14:44:44.585031: lr: 0.004285\n",
      "2021-11-02 14:44:44.630224: saving checkpoint...\n",
      "2021-11-02 14:44:45.877052: done, saving took 1.28 seconds\n",
      "2021-11-02 14:44:46.475566: This epoch took 296.185565 s\n",
      "\n",
      "2021-11-02 14:44:46.495157: \n",
      "epoch:  61\n",
      "2021-11-02 14:49:19.640464: train loss : -0.8524\n",
      "2021-11-02 14:49:36.864330: validation loss: -0.8361\n",
      "2021-11-02 14:49:36.868411: Average global foreground Dice: [0.8531]\n",
      "2021-11-02 14:49:36.874624: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 14:49:37.346673: lr: 0.004186\n",
      "2021-11-02 14:49:37.363855: This epoch took 290.861585 s\n",
      "\n",
      "2021-11-02 14:49:37.371171: \n",
      "epoch:  62\n",
      "2021-11-02 14:54:10.603675: train loss : -0.8549\n",
      "2021-11-02 14:54:28.013964: validation loss: -0.8480\n",
      "2021-11-02 14:54:28.017674: Average global foreground Dice: [0.864]\n",
      "2021-11-02 14:54:28.024738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 14:54:28.495418: lr: 0.004087\n",
      "2021-11-02 14:54:28.545190: saving checkpoint...\n",
      "2021-11-02 14:54:29.797090: done, saving took 1.28 seconds\n",
      "2021-11-02 14:54:30.533454: This epoch took 293.154913 s\n",
      "\n",
      "2021-11-02 14:54:30.541641: \n",
      "epoch:  63\n",
      "2021-11-02 14:59:08.105511: train loss : -0.8519\n",
      "2021-11-02 14:59:25.727186: validation loss: -0.8349\n",
      "2021-11-02 14:59:25.730808: Average global foreground Dice: [0.8459]\n",
      "2021-11-02 14:59:25.738256: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 14:59:26.219054: lr: 0.003987\n",
      "2021-11-02 14:59:26.236549: This epoch took 295.687394 s\n",
      "\n",
      "2021-11-02 14:59:26.244804: \n",
      "epoch:  64\n",
      "2021-11-02 15:04:01.450790: train loss : -0.8508\n",
      "2021-11-02 15:04:19.102378: validation loss: -0.8423\n",
      "2021-11-02 15:04:19.106326: Average global foreground Dice: [0.8585]\n",
      "2021-11-02 15:04:19.113471: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 15:04:19.595798: lr: 0.003887\n",
      "2021-11-02 15:04:19.612372: This epoch took 293.361148 s\n",
      "\n",
      "2021-11-02 15:04:19.622263: \n",
      "epoch:  65\n",
      "2021-11-02 15:08:53.697828: train loss : -0.8550\n",
      "2021-11-02 15:09:11.503221: validation loss: -0.8470\n",
      "2021-11-02 15:09:11.507318: Average global foreground Dice: [0.8592]\n",
      "2021-11-02 15:09:11.514181: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 15:09:11.998501: lr: 0.003787\n",
      "2021-11-02 15:09:12.014746: This epoch took 292.383393 s\n",
      "\n",
      "2021-11-02 15:09:12.023309: \n",
      "epoch:  66\n",
      "2021-11-02 15:13:46.478302: train loss : -0.8610\n",
      "2021-11-02 15:14:03.885387: validation loss: -0.8343\n",
      "2021-11-02 15:14:03.888871: Average global foreground Dice: [0.85]\n",
      "2021-11-02 15:14:03.895999: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 15:14:04.367594: lr: 0.003687\n",
      "2021-11-02 15:14:04.383121: This epoch took 292.351457 s\n",
      "\n",
      "2021-11-02 15:14:04.390225: \n",
      "epoch:  67\n",
      "2021-11-02 15:18:38.402488: train loss : -0.8544\n",
      "2021-11-02 15:18:55.823532: validation loss: -0.8498\n",
      "2021-11-02 15:18:55.827325: Average global foreground Dice: [0.8604]\n",
      "2021-11-02 15:18:55.835391: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 15:18:56.306731: lr: 0.003586\n",
      "2021-11-02 15:18:56.351378: saving checkpoint...\n",
      "2021-11-02 15:18:57.581881: done, saving took 1.26 seconds\n",
      "2021-11-02 15:18:58.182561: This epoch took 293.784545 s\n",
      "\n",
      "2021-11-02 15:18:58.191298: \n",
      "epoch:  68\n",
      "2021-11-02 15:23:36.432135: train loss : -0.8554\n",
      "2021-11-02 15:23:53.903542: validation loss: -0.8392\n",
      "2021-11-02 15:23:53.907632: Average global foreground Dice: [0.855]\n",
      "2021-11-02 15:23:53.914428: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 15:23:54.385252: lr: 0.003485\n",
      "2021-11-02 15:23:54.402726: This epoch took 296.204159 s\n",
      "\n",
      "2021-11-02 15:23:54.411342: \n",
      "epoch:  69\n",
      "2021-11-02 15:28:33.541061: train loss : -0.8559\n",
      "2021-11-02 15:28:50.986764: validation loss: -0.8352\n",
      "2021-11-02 15:28:50.990395: Average global foreground Dice: [0.8513]\n",
      "2021-11-02 15:28:50.998195: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 15:28:51.472990: lr: 0.003384\n",
      "2021-11-02 15:28:51.492106: This epoch took 297.073274 s\n",
      "\n",
      "2021-11-02 15:28:51.499490: \n",
      "epoch:  70\n",
      "2021-11-02 15:33:27.498454: train loss : -0.8587\n",
      "2021-11-02 15:33:44.733098: validation loss: -0.8399\n",
      "2021-11-02 15:33:44.736900: Average global foreground Dice: [0.8527]\n",
      "2021-11-02 15:33:44.743490: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 15:33:45.219047: lr: 0.003282\n",
      "2021-11-02 15:33:45.233605: This epoch took 293.726660 s\n",
      "\n",
      "2021-11-02 15:33:45.241022: \n",
      "epoch:  71\n",
      "2021-11-02 15:38:17.570591: train loss : -0.8584\n",
      "2021-11-02 15:38:34.890604: validation loss: -0.8474\n",
      "2021-11-02 15:38:34.894337: Average global foreground Dice: [0.8591]\n",
      "2021-11-02 15:38:34.900762: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 15:38:35.377249: lr: 0.00318\n",
      "2021-11-02 15:38:35.393068: This epoch took 290.144784 s\n",
      "\n",
      "2021-11-02 15:38:35.400062: \n",
      "epoch:  72\n",
      "2021-11-02 15:43:09.653130: train loss : -0.8576\n",
      "2021-11-02 15:43:27.394884: validation loss: -0.8482\n",
      "2021-11-02 15:43:27.399206: Average global foreground Dice: [0.8626]\n",
      "2021-11-02 15:43:27.405378: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 15:43:27.895062: lr: 0.003078\n",
      "2021-11-02 15:43:27.967395: saving checkpoint...\n",
      "2021-11-02 15:43:29.200954: done, saving took 1.29 seconds\n",
      "2021-11-02 15:43:29.802952: This epoch took 294.395047 s\n",
      "\n",
      "2021-11-02 15:43:29.811234: \n",
      "epoch:  73\n",
      "2021-11-02 15:48:05.872838: train loss : -0.8619\n",
      "2021-11-02 15:48:23.582004: validation loss: -0.8416\n",
      "2021-11-02 15:48:23.585792: Average global foreground Dice: [0.8569]\n",
      "2021-11-02 15:48:23.593146: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 15:48:24.086231: lr: 0.002975\n",
      "2021-11-02 15:48:24.160807: saving checkpoint...\n",
      "2021-11-02 15:48:25.545917: done, saving took 1.44 seconds\n",
      "2021-11-02 15:48:26.171737: This epoch took 296.353773 s\n",
      "\n",
      "2021-11-02 15:48:26.180001: \n",
      "epoch:  74\n",
      "2021-11-02 15:53:02.600523: train loss : -0.8610\n",
      "2021-11-02 15:53:20.116979: validation loss: -0.8414\n",
      "2021-11-02 15:53:20.120482: Average global foreground Dice: [0.8551]\n",
      "2021-11-02 15:53:20.127334: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 15:53:20.601017: lr: 0.002872\n",
      "2021-11-02 15:53:20.620924: This epoch took 294.434541 s\n",
      "\n",
      "2021-11-02 15:53:20.628324: \n",
      "epoch:  75\n",
      "2021-11-02 15:57:58.059412: train loss : -0.8606\n",
      "2021-11-02 15:58:15.500988: validation loss: -0.8383\n",
      "2021-11-02 15:58:15.505009: Average global foreground Dice: [0.8549]\n",
      "2021-11-02 15:58:15.511461: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 15:58:16.065408: lr: 0.002768\n",
      "2021-11-02 15:58:16.084601: This epoch took 295.449791 s\n",
      "\n",
      "2021-11-02 15:58:16.091624: \n",
      "epoch:  76\n",
      "2021-11-02 16:02:52.774338: train loss : -0.8628\n",
      "2021-11-02 16:03:10.178856: validation loss: -0.8396\n",
      "2021-11-02 16:03:10.182621: Average global foreground Dice: [0.8549]\n",
      "2021-11-02 16:03:10.189052: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 16:03:10.663604: lr: 0.002664\n",
      "2021-11-02 16:03:10.678728: This epoch took 294.579513 s\n",
      "\n",
      "2021-11-02 16:03:10.685630: \n",
      "epoch:  77\n",
      "2021-11-02 16:07:48.120584: train loss : -0.8652\n",
      "2021-11-02 16:08:05.498716: validation loss: -0.8452\n",
      "2021-11-02 16:08:05.502635: Average global foreground Dice: [0.8596]\n",
      "2021-11-02 16:08:05.509848: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 16:08:05.988376: lr: 0.00256\n",
      "2021-11-02 16:08:06.037778: saving checkpoint...\n",
      "2021-11-02 16:08:07.283979: done, saving took 1.28 seconds\n",
      "2021-11-02 16:08:07.883964: This epoch took 297.191149 s\n",
      "\n",
      "2021-11-02 16:08:07.891982: \n",
      "epoch:  78\n",
      "2021-11-02 16:12:44.600995: train loss : -0.8660\n",
      "2021-11-02 16:13:01.948469: validation loss: -0.8366\n",
      "2021-11-02 16:13:01.952131: Average global foreground Dice: [0.8549]\n",
      "2021-11-02 16:13:01.959650: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 16:13:02.439479: lr: 0.002455\n",
      "2021-11-02 16:13:02.459499: This epoch took 294.560110 s\n",
      "\n",
      "2021-11-02 16:13:02.466801: \n",
      "epoch:  79\n",
      "2021-11-02 16:17:40.159570: train loss : -0.8649\n",
      "2021-11-02 16:17:57.566779: validation loss: -0.8440\n",
      "2021-11-02 16:17:57.570709: Average global foreground Dice: [0.8606]\n",
      "2021-11-02 16:17:57.577582: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 16:17:58.062170: lr: 0.002349\n",
      "2021-11-02 16:17:58.107264: saving checkpoint...\n",
      "2021-11-02 16:17:59.345857: done, saving took 1.27 seconds\n",
      "2021-11-02 16:17:59.968062: This epoch took 297.493524 s\n",
      "\n",
      "2021-11-02 16:17:59.976790: \n",
      "epoch:  80\n",
      "2021-11-02 16:22:38.608917: train loss : -0.8659\n",
      "2021-11-02 16:22:56.304707: validation loss: -0.8381\n",
      "2021-11-02 16:22:56.308725: Average global foreground Dice: [0.8519]\n",
      "2021-11-02 16:22:56.315431: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 16:22:56.801855: lr: 0.002243\n",
      "2021-11-02 16:22:56.820914: This epoch took 296.836757 s\n",
      "\n",
      "2021-11-02 16:22:56.827784: \n",
      "epoch:  81\n",
      "2021-11-02 16:27:35.598873: train loss : -0.8647\n",
      "2021-11-02 16:27:53.266540: validation loss: -0.8494\n",
      "2021-11-02 16:27:53.270196: Average global foreground Dice: [0.8603]\n",
      "2021-11-02 16:27:53.276485: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 16:27:53.771816: lr: 0.002137\n",
      "2021-11-02 16:27:53.790084: This epoch took 296.955253 s\n",
      "\n",
      "2021-11-02 16:27:53.797968: \n",
      "epoch:  82\n",
      "2021-11-02 16:32:31.661208: train loss : -0.8636\n",
      "2021-11-02 16:32:49.361922: validation loss: -0.8382\n",
      "2021-11-02 16:32:49.365782: Average global foreground Dice: [0.8546]\n",
      "2021-11-02 16:32:49.371753: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 16:32:49.857669: lr: 0.00203\n",
      "2021-11-02 16:32:49.877888: This epoch took 296.072319 s\n",
      "\n",
      "2021-11-02 16:32:49.885178: \n",
      "epoch:  83\n",
      "2021-11-02 16:37:27.616526: train loss : -0.8666\n",
      "2021-11-02 16:37:45.274528: validation loss: -0.8482\n",
      "2021-11-02 16:37:45.278384: Average global foreground Dice: [0.8625]\n",
      "2021-11-02 16:37:45.285054: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 16:37:45.825732: lr: 0.001922\n",
      "2021-11-02 16:37:45.876258: saving checkpoint...\n",
      "2021-11-02 16:37:47.101848: done, saving took 1.25 seconds\n",
      "2021-11-02 16:37:47.831555: This epoch took 297.938836 s\n",
      "\n",
      "2021-11-02 16:37:47.840073: \n",
      "epoch:  84\n",
      "2021-11-02 16:42:24.964018: train loss : -0.8630\n",
      "2021-11-02 16:42:42.383221: validation loss: -0.8467\n",
      "2021-11-02 16:42:42.387370: Average global foreground Dice: [0.8628]\n",
      "2021-11-02 16:42:42.393988: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 16:42:42.870878: lr: 0.001813\n",
      "2021-11-02 16:42:42.922378: saving checkpoint...\n",
      "2021-11-02 16:42:44.160030: done, saving took 1.27 seconds\n",
      "2021-11-02 16:42:44.747937: This epoch took 296.900790 s\n",
      "\n",
      "2021-11-02 16:42:44.756461: \n",
      "epoch:  85\n",
      "2021-11-02 16:47:21.861296: train loss : -0.8661\n",
      "2021-11-02 16:47:39.311142: validation loss: -0.8485\n",
      "2021-11-02 16:47:39.314904: Average global foreground Dice: [0.8623]\n",
      "2021-11-02 16:47:39.321790: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 16:47:39.795906: lr: 0.001704\n",
      "2021-11-02 16:47:39.847402: saving checkpoint...\n",
      "2021-11-02 16:47:41.087057: done, saving took 1.27 seconds\n",
      "2021-11-02 16:47:41.761953: This epoch took 296.997493 s\n",
      "\n",
      "2021-11-02 16:47:41.771369: \n",
      "epoch:  86\n",
      "2021-11-02 16:52:17.683149: train loss : -0.8676\n",
      "2021-11-02 16:52:35.097864: validation loss: -0.8429\n",
      "2021-11-02 16:52:35.102146: Average global foreground Dice: [0.8605]\n",
      "2021-11-02 16:52:35.108475: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 16:52:35.581201: lr: 0.001594\n",
      "2021-11-02 16:52:35.630761: saving checkpoint...\n",
      "2021-11-02 16:52:36.857731: done, saving took 1.26 seconds\n",
      "2021-11-02 16:52:37.470760: This epoch took 295.692449 s\n",
      "\n",
      "2021-11-02 16:52:37.479104: \n",
      "epoch:  87\n",
      "2021-11-02 16:57:12.826362: train loss : -0.8676\n",
      "2021-11-02 16:57:30.246490: validation loss: -0.8420\n",
      "2021-11-02 16:57:30.250072: Average global foreground Dice: [0.8567]\n",
      "2021-11-02 16:57:30.256629: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 16:57:30.731215: lr: 0.001483\n",
      "2021-11-02 16:57:30.754002: This epoch took 293.267537 s\n",
      "\n",
      "2021-11-02 16:57:30.761765: \n",
      "epoch:  88\n",
      "2021-11-02 17:02:06.159507: train loss : -0.8680\n",
      "2021-11-02 17:02:23.548054: validation loss: -0.8437\n",
      "2021-11-02 17:02:23.551677: Average global foreground Dice: [0.8553]\n",
      "2021-11-02 17:02:23.557593: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 17:02:24.031705: lr: 0.001372\n",
      "2021-11-02 17:02:24.047831: This epoch took 293.278040 s\n",
      "\n",
      "2021-11-02 17:02:24.055353: \n",
      "epoch:  89\n",
      "2021-11-02 17:06:59.338559: train loss : -0.8691\n",
      "2021-11-02 17:07:16.854012: validation loss: -0.8469\n",
      "2021-11-02 17:07:16.858436: Average global foreground Dice: [0.8595]\n",
      "2021-11-02 17:07:16.864831: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 17:07:17.343938: lr: 0.001259\n",
      "2021-11-02 17:07:17.362821: This epoch took 293.300535 s\n",
      "\n",
      "2021-11-02 17:07:17.370372: \n",
      "epoch:  90\n",
      "2021-11-02 17:11:53.776366: train loss : -0.8690\n",
      "2021-11-02 17:12:11.417394: validation loss: -0.8445\n",
      "2021-11-02 17:12:11.423172: Average global foreground Dice: [0.8616]\n",
      "2021-11-02 17:12:11.429273: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 17:12:12.012635: lr: 0.001145\n",
      "2021-11-02 17:12:12.058795: saving checkpoint...\n",
      "2021-11-02 17:12:13.281872: done, saving took 1.25 seconds\n",
      "2021-11-02 17:12:14.056111: This epoch took 296.678382 s\n",
      "\n",
      "2021-11-02 17:12:14.064700: \n",
      "epoch:  91\n",
      "2021-11-02 17:16:49.213759: train loss : -0.8702\n",
      "2021-11-02 17:17:06.590750: validation loss: -0.8461\n",
      "2021-11-02 17:17:06.595800: Average global foreground Dice: [0.8552]\n",
      "2021-11-02 17:17:06.603201: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 17:17:07.079830: lr: 0.00103\n",
      "2021-11-02 17:17:07.099759: This epoch took 293.027517 s\n",
      "\n",
      "2021-11-02 17:17:07.108022: \n",
      "epoch:  92\n",
      "2021-11-02 17:21:42.350065: train loss : -0.8672\n",
      "2021-11-02 17:21:59.918828: validation loss: -0.8488\n",
      "2021-11-02 17:21:59.922601: Average global foreground Dice: [0.8606]\n",
      "2021-11-02 17:21:59.929030: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 17:22:00.402909: lr: 0.000913\n",
      "2021-11-02 17:22:00.425371: This epoch took 293.309455 s\n",
      "\n",
      "2021-11-02 17:22:00.433172: \n",
      "epoch:  93\n",
      "2021-11-02 17:26:36.296495: train loss : -0.8670\n",
      "2021-11-02 17:26:53.943924: validation loss: -0.8505\n",
      "2021-11-02 17:26:53.947828: Average global foreground Dice: [0.8602]\n",
      "2021-11-02 17:26:53.954838: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 17:26:54.426327: lr: 0.000795\n",
      "2021-11-02 17:26:54.481934: saving checkpoint...\n",
      "2021-11-02 17:26:55.724793: done, saving took 1.28 seconds\n",
      "2021-11-02 17:26:56.333566: This epoch took 295.893449 s\n",
      "\n",
      "2021-11-02 17:26:56.342728: \n",
      "epoch:  94\n",
      "2021-11-02 17:31:33.154600: train loss : -0.8733\n",
      "2021-11-02 17:31:50.819465: validation loss: -0.8455\n",
      "2021-11-02 17:31:50.823332: Average global foreground Dice: [0.8603]\n",
      "2021-11-02 17:31:50.829190: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 17:31:51.301594: lr: 0.000675\n",
      "2021-11-02 17:31:51.375388: saving checkpoint...\n",
      "2021-11-02 17:31:52.624150: done, saving took 1.30 seconds\n",
      "2021-11-02 17:31:53.370123: This epoch took 297.019841 s\n",
      "\n",
      "2021-11-02 17:31:53.378463: \n",
      "epoch:  95\n",
      "2021-11-02 17:36:30.701190: train loss : -0.8688\n",
      "2021-11-02 17:36:48.343794: validation loss: -0.8383\n",
      "2021-11-02 17:36:48.348076: Average global foreground Dice: [0.8543]\n",
      "2021-11-02 17:36:48.354091: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 17:36:48.841551: lr: 0.000552\n",
      "2021-11-02 17:36:48.861968: This epoch took 295.475922 s\n",
      "\n",
      "2021-11-02 17:36:48.869141: \n",
      "epoch:  96\n",
      "2021-11-02 17:41:26.145433: train loss : -0.8718\n",
      "2021-11-02 17:41:43.832043: validation loss: -0.8473\n",
      "2021-11-02 17:41:43.836383: Average global foreground Dice: [0.8614]\n",
      "2021-11-02 17:41:43.848813: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 17:41:44.341074: lr: 0.000426\n",
      "2021-11-02 17:41:44.360983: This epoch took 295.484718 s\n",
      "\n",
      "2021-11-02 17:41:44.368345: \n",
      "epoch:  97\n",
      "2021-11-02 17:46:21.700453: train loss : -0.8703\n",
      "2021-11-02 17:46:39.402770: validation loss: -0.8537\n",
      "2021-11-02 17:46:39.406810: Average global foreground Dice: [0.8622]\n",
      "2021-11-02 17:46:39.413466: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 17:46:39.911365: lr: 0.000296\n",
      "2021-11-02 17:46:39.988678: saving checkpoint...\n",
      "2021-11-02 17:46:41.283536: done, saving took 1.35 seconds\n",
      "2021-11-02 17:46:41.887847: This epoch took 297.511532 s\n",
      "\n",
      "2021-11-02 17:46:41.897258: \n",
      "epoch:  98\n",
      "2021-11-02 17:51:19.078764: train loss : -0.8692\n",
      "2021-11-02 17:51:36.478514: validation loss: -0.8405\n",
      "2021-11-02 17:51:36.482392: Average global foreground Dice: [0.8573]\n",
      "2021-11-02 17:51:36.488582: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 17:51:36.962658: lr: 0.000158\n",
      "2021-11-02 17:51:36.981133: This epoch took 295.077317 s\n",
      "\n",
      "2021-11-02 17:51:36.989137: \n",
      "epoch:  99\n",
      "2021-11-02 17:56:14.161327: train loss : -0.8675\n",
      "2021-11-02 17:56:31.633308: validation loss: -0.8491\n",
      "2021-11-02 17:56:31.637388: Average global foreground Dice: [0.8605]\n",
      "2021-11-02 17:56:31.644192: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-02 17:56:32.118583: lr: 0.0\n",
      "2021-11-02 17:56:32.138410: saving scheduled checkpoint file...\n",
      "2021-11-02 17:56:32.176472: saving checkpoint...\n",
      "2021-11-02 17:56:33.401717: done, saving took 1.25 seconds\n",
      "2021-11-02 17:56:34.060075: done\n",
      "2021-11-02 17:56:34.097557: saving checkpoint...\n",
      "2021-11-02 17:56:35.330176: done, saving took 1.26 seconds\n",
      "2021-11-02 17:56:35.915345: This epoch took 298.918317 s\n",
      "\n",
      "2021-11-02 17:56:35.952062: saving checkpoint...\n",
      "2021-11-02 17:56:36.906301: done, saving took 0.98 seconds\n",
      "23090558_20120330 (3, 263, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 263, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 7], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090564_20130312 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090568_20121018 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090569_20120607 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120613 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150908 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090593_20120625 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130103 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090600_20121108 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090603_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090607_20120420 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090609_20120510 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160119 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160510 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090646_20120718 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-02 17:59:56.043774: finished prediction\n",
      "2021-11-02 17:59:56.048736: evaluation of raw predictions\n",
      "2021-11-02 17:59:57.976460: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8587637988083598\n",
      "after:  0.8587637988083598\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Model 3\n",
    "# os.chdir(main_dir)\n",
    "\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 0\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 1\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 2\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 3\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 4\n",
    "\n",
    "# os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-03 05:17:06.932551: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-03 05:17:06.955242: The split file contains 5 splits.\n",
      "2021-11-03 05:17:06.962351: Desired fold for training: 0\n",
      "2021-11-03 05:17:06.969702: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-03 05:17:11.335814: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-03 05:17:22.639543: Unable to plot network architecture:\n",
      "2021-11-03 05:17:22.651557: No module named 'hiddenlayer'\n",
      "2021-11-03 05:17:22.658299: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-03 05:17:22.664474: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-03 05:17:22.739175: \n",
      "\n",
      "2021-11-03 05:17:22.748912: \n",
      "epoch:  0\n",
      "2021-11-03 05:22:06.775883: train loss : -0.1903\n",
      "2021-11-03 05:22:24.157891: validation loss: -0.5837\n",
      "2021-11-03 05:22:24.162014: Average global foreground Dice: [0.651]\n",
      "2021-11-03 05:22:24.170349: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 05:22:24.592353: lr: 0.00982\n",
      "2021-11-03 05:22:24.620937: This epoch took 301.866249 s\n",
      "\n",
      "2021-11-03 05:22:24.628228: \n",
      "epoch:  1\n",
      "2021-11-03 05:26:54.056759: train loss : -0.6019\n",
      "2021-11-03 05:27:11.422527: validation loss: -0.6962\n",
      "2021-11-03 05:27:11.431854: Average global foreground Dice: [0.7364]\n",
      "2021-11-03 05:27:11.438474: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 05:27:11.920060: lr: 0.009639\n",
      "2021-11-03 05:27:12.020120: saving checkpoint...\n",
      "2021-11-03 05:27:12.986021: done, saving took 1.04 seconds\n",
      "2021-11-03 05:27:13.588048: This epoch took 288.952167 s\n",
      "\n",
      "2021-11-03 05:27:13.603334: \n",
      "epoch:  2\n",
      "2021-11-03 05:31:43.153832: train loss : -0.6845\n",
      "2021-11-03 05:32:00.550356: validation loss: -0.7654\n",
      "2021-11-03 05:32:00.554452: Average global foreground Dice: [0.7949]\n",
      "2021-11-03 05:32:00.561829: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 05:32:01.041146: lr: 0.009458\n",
      "2021-11-03 05:32:01.136672: saving checkpoint...\n",
      "2021-11-03 05:32:02.384843: done, saving took 1.31 seconds\n",
      "2021-11-03 05:32:03.125411: This epoch took 289.515960 s\n",
      "\n",
      "2021-11-03 05:32:03.141015: \n",
      "epoch:  3\n",
      "2021-11-03 05:36:33.812372: train loss : -0.7310\n",
      "2021-11-03 05:36:51.240728: validation loss: -0.7702\n",
      "2021-11-03 05:36:51.246476: Average global foreground Dice: [0.8004]\n",
      "2021-11-03 05:36:51.252671: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 05:36:51.755392: lr: 0.009277\n",
      "2021-11-03 05:36:51.856984: saving checkpoint...\n",
      "2021-11-03 05:36:53.186857: done, saving took 1.40 seconds\n",
      "2021-11-03 05:36:53.842113: This epoch took 290.693020 s\n",
      "\n",
      "2021-11-03 05:36:53.861542: \n",
      "epoch:  4\n",
      "2021-11-03 05:41:23.872267: train loss : -0.7456\n",
      "2021-11-03 05:41:41.122063: validation loss: -0.8123\n",
      "2021-11-03 05:41:41.126000: Average global foreground Dice: [0.8376]\n",
      "2021-11-03 05:41:41.132859: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 05:41:41.610332: lr: 0.009095\n",
      "2021-11-03 05:41:41.681260: saving checkpoint...\n",
      "2021-11-03 05:41:42.806643: done, saving took 1.18 seconds\n",
      "2021-11-03 05:41:43.409431: This epoch took 289.541698 s\n",
      "\n",
      "2021-11-03 05:41:43.418108: \n",
      "epoch:  5\n",
      "2021-11-03 05:46:15.114032: train loss : -0.7643\n",
      "2021-11-03 05:46:32.543397: validation loss: -0.8182\n",
      "2021-11-03 05:46:32.547464: Average global foreground Dice: [0.8408]\n",
      "2021-11-03 05:46:32.554034: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 05:46:33.040834: lr: 0.008913\n",
      "2021-11-03 05:46:33.130878: saving checkpoint...\n",
      "2021-11-03 05:46:34.290363: done, saving took 1.23 seconds\n",
      "2021-11-03 05:46:34.905174: This epoch took 291.481119 s\n",
      "\n",
      "2021-11-03 05:46:34.913990: \n",
      "epoch:  6\n",
      "2021-11-03 05:51:05.828026: train loss : -0.7702\n",
      "2021-11-03 05:51:23.264280: validation loss: -0.8086\n",
      "2021-11-03 05:51:23.268170: Average global foreground Dice: [0.8286]\n",
      "2021-11-03 05:51:23.274055: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 05:51:23.782787: lr: 0.008731\n",
      "2021-11-03 05:51:23.883667: saving checkpoint...\n",
      "2021-11-03 05:51:25.279112: done, saving took 1.46 seconds\n",
      "2021-11-03 05:51:25.962986: This epoch took 291.042002 s\n",
      "\n",
      "2021-11-03 05:51:25.984488: \n",
      "epoch:  7\n",
      "2021-11-03 05:55:56.327775: train loss : -0.7803\n",
      "2021-11-03 05:56:13.719743: validation loss: -0.8140\n",
      "2021-11-03 05:56:13.723707: Average global foreground Dice: [0.835]\n",
      "2021-11-03 05:56:13.730410: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 05:56:14.225922: lr: 0.008548\n",
      "2021-11-03 05:56:14.322751: saving checkpoint...\n",
      "2021-11-03 05:56:15.574836: done, saving took 1.32 seconds\n",
      "2021-11-03 05:56:16.215699: This epoch took 290.224374 s\n",
      "\n",
      "2021-11-03 05:56:16.232303: \n",
      "epoch:  8\n",
      "2021-11-03 06:00:47.085680: train loss : -0.7866\n",
      "2021-11-03 06:01:04.642307: validation loss: -0.8200\n",
      "2021-11-03 06:01:04.646283: Average global foreground Dice: [0.8449]\n",
      "2021-11-03 06:01:04.653034: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 06:01:05.152679: lr: 0.008364\n",
      "2021-11-03 06:01:05.243553: saving checkpoint...\n",
      "2021-11-03 06:01:06.353850: done, saving took 1.18 seconds\n",
      "2021-11-03 06:01:06.986106: This epoch took 290.746942 s\n",
      "\n",
      "2021-11-03 06:01:06.994716: \n",
      "epoch:  9\n",
      "2021-11-03 06:05:37.867650: train loss : -0.7887\n",
      "2021-11-03 06:05:55.291689: validation loss: -0.8298\n",
      "2021-11-03 06:05:55.295508: Average global foreground Dice: [0.8523]\n",
      "2021-11-03 06:05:55.302106: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 06:05:55.803088: lr: 0.008181\n",
      "2021-11-03 06:05:55.881006: saving checkpoint...\n",
      "2021-11-03 06:05:57.050706: done, saving took 1.23 seconds\n",
      "2021-11-03 06:05:57.649735: This epoch took 290.646504 s\n",
      "\n",
      "2021-11-03 06:05:57.659902: \n",
      "epoch:  10\n",
      "2021-11-03 06:10:27.896193: train loss : -0.8015\n",
      "2021-11-03 06:10:45.137818: validation loss: -0.8228\n",
      "2021-11-03 06:10:45.141484: Average global foreground Dice: [0.8371]\n",
      "2021-11-03 06:10:45.147939: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 06:10:45.622198: lr: 0.007996\n",
      "2021-11-03 06:10:45.684059: saving checkpoint...\n",
      "2021-11-03 06:10:46.900077: done, saving took 1.24 seconds\n",
      "2021-11-03 06:10:47.501363: This epoch took 289.833848 s\n",
      "\n",
      "2021-11-03 06:10:47.519166: \n",
      "epoch:  11\n",
      "2021-11-03 06:15:17.366883: train loss : -0.8057\n",
      "2021-11-03 06:15:34.601929: validation loss: -0.8267\n",
      "2021-11-03 06:15:34.605888: Average global foreground Dice: [0.847]\n",
      "2021-11-03 06:15:34.612911: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 06:15:35.090685: lr: 0.007811\n",
      "2021-11-03 06:15:35.150469: saving checkpoint...\n",
      "2021-11-03 06:15:36.385159: done, saving took 1.26 seconds\n",
      "2021-11-03 06:15:37.020777: This epoch took 289.494821 s\n",
      "\n",
      "2021-11-03 06:15:37.042377: \n",
      "epoch:  12\n",
      "2021-11-03 06:20:07.770245: train loss : -0.8119\n",
      "2021-11-03 06:20:25.095088: validation loss: -0.8373\n",
      "2021-11-03 06:20:25.098508: Average global foreground Dice: [0.8559]\n",
      "2021-11-03 06:20:25.105361: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 06:20:25.569415: lr: 0.007626\n",
      "2021-11-03 06:20:25.619096: saving checkpoint...\n",
      "2021-11-03 06:20:26.725660: done, saving took 1.13 seconds\n",
      "2021-11-03 06:20:27.316884: This epoch took 290.267102 s\n",
      "\n",
      "2021-11-03 06:20:27.325202: \n",
      "epoch:  13\n",
      "2021-11-03 06:24:57.606218: train loss : -0.8116\n",
      "2021-11-03 06:25:14.853161: validation loss: -0.8297\n",
      "2021-11-03 06:25:14.856719: Average global foreground Dice: [0.8439]\n",
      "2021-11-03 06:25:14.863258: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 06:25:15.331221: lr: 0.00744\n",
      "2021-11-03 06:25:15.392692: saving checkpoint...\n",
      "2021-11-03 06:25:16.636083: done, saving took 1.27 seconds\n",
      "2021-11-03 06:25:17.249310: This epoch took 289.916872 s\n",
      "\n",
      "2021-11-03 06:25:17.267020: \n",
      "epoch:  14\n",
      "2021-11-03 06:29:47.654680: train loss : -0.8138\n",
      "2021-11-03 06:30:04.911391: validation loss: -0.8299\n",
      "2021-11-03 06:30:04.915416: Average global foreground Dice: [0.8487]\n",
      "2021-11-03 06:30:04.927197: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 06:30:05.400179: lr: 0.007254\n",
      "2021-11-03 06:30:05.462682: saving checkpoint...\n",
      "2021-11-03 06:30:06.710984: done, saving took 1.28 seconds\n",
      "2021-11-03 06:30:07.365592: This epoch took 290.091477 s\n",
      "\n",
      "2021-11-03 06:30:07.386873: \n",
      "epoch:  15\n",
      "2021-11-03 06:34:38.162023: train loss : -0.8146\n",
      "2021-11-03 06:34:55.376513: validation loss: -0.8381\n",
      "2021-11-03 06:34:55.382005: Average global foreground Dice: [0.8569]\n",
      "2021-11-03 06:34:55.388925: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 06:34:55.872627: lr: 0.007067\n",
      "2021-11-03 06:34:55.962824: saving checkpoint...\n",
      "2021-11-03 06:34:57.260354: done, saving took 1.36 seconds\n",
      "2021-11-03 06:34:57.877603: This epoch took 290.482703 s\n",
      "\n",
      "2021-11-03 06:34:57.895916: \n",
      "epoch:  16\n",
      "2021-11-03 06:39:29.661788: train loss : -0.8175\n",
      "2021-11-03 06:39:46.919914: validation loss: -0.8377\n",
      "2021-11-03 06:39:46.924007: Average global foreground Dice: [0.8583]\n",
      "2021-11-03 06:39:46.931311: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 06:39:47.405901: lr: 0.00688\n",
      "2021-11-03 06:39:47.463136: saving checkpoint...\n",
      "2021-11-03 06:39:48.668854: done, saving took 1.23 seconds\n",
      "2021-11-03 06:39:49.254025: This epoch took 291.350132 s\n",
      "\n",
      "2021-11-03 06:39:49.273777: \n",
      "epoch:  17\n",
      "2021-11-03 06:44:20.393189: train loss : -0.8144\n",
      "2021-11-03 06:44:37.807899: validation loss: -0.8444\n",
      "2021-11-03 06:44:37.811788: Average global foreground Dice: [0.8604]\n",
      "2021-11-03 06:44:37.818421: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 06:44:38.290597: lr: 0.006692\n",
      "2021-11-03 06:44:38.354578: saving checkpoint...\n",
      "2021-11-03 06:44:39.578075: done, saving took 1.25 seconds\n",
      "2021-11-03 06:44:40.222678: This epoch took 290.940823 s\n",
      "\n",
      "2021-11-03 06:44:40.240797: \n",
      "epoch:  18\n",
      "2021-11-03 06:49:11.425372: train loss : -0.8222\n",
      "2021-11-03 06:49:28.662042: validation loss: -0.8391\n",
      "2021-11-03 06:49:28.665808: Average global foreground Dice: [0.8487]\n",
      "2021-11-03 06:49:28.672703: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 06:49:29.147736: lr: 0.006504\n",
      "2021-11-03 06:49:29.209922: saving checkpoint...\n",
      "2021-11-03 06:49:30.319125: done, saving took 1.14 seconds\n",
      "2021-11-03 06:49:30.981592: This epoch took 290.731844 s\n",
      "\n",
      "2021-11-03 06:49:31.002308: \n",
      "epoch:  19\n",
      "2021-11-03 06:54:02.306164: train loss : -0.8189\n",
      "2021-11-03 06:54:19.557303: validation loss: -0.8393\n",
      "2021-11-03 06:54:19.561288: Average global foreground Dice: [0.8571]\n",
      "2021-11-03 06:54:19.568158: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 06:54:20.040426: lr: 0.006314\n",
      "2021-11-03 06:54:20.088850: saving checkpoint...\n",
      "2021-11-03 06:54:21.208788: done, saving took 1.15 seconds\n",
      "2021-11-03 06:54:21.800871: This epoch took 290.790364 s\n",
      "\n",
      "2021-11-03 06:54:21.809652: \n",
      "epoch:  20\n",
      "2021-11-03 06:58:53.584363: train loss : -0.8270\n",
      "2021-11-03 06:59:10.849490: validation loss: -0.8395\n",
      "2021-11-03 06:59:10.853489: Average global foreground Dice: [0.8555]\n",
      "2021-11-03 06:59:10.860713: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 06:59:11.330434: lr: 0.006125\n",
      "2021-11-03 06:59:11.375829: saving checkpoint...\n",
      "2021-11-03 06:59:12.496471: done, saving took 1.15 seconds\n",
      "2021-11-03 06:59:13.088206: This epoch took 291.270725 s\n",
      "\n",
      "2021-11-03 06:59:13.097484: \n",
      "epoch:  21\n",
      "2021-11-03 07:03:45.286639: train loss : -0.8228\n",
      "2021-11-03 07:04:02.722167: validation loss: -0.8463\n",
      "2021-11-03 07:04:02.725684: Average global foreground Dice: [0.8598]\n",
      "2021-11-03 07:04:02.732388: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 07:04:03.198777: lr: 0.005934\n",
      "2021-11-03 07:04:03.271084: saving checkpoint...\n",
      "2021-11-03 07:04:04.432893: done, saving took 1.22 seconds\n",
      "2021-11-03 07:04:05.090226: This epoch took 291.984406 s\n",
      "\n",
      "2021-11-03 07:04:05.099518: \n",
      "epoch:  22\n",
      "2021-11-03 07:08:37.176281: train loss : -0.8265\n",
      "2021-11-03 07:08:54.441810: validation loss: -0.8414\n",
      "2021-11-03 07:08:54.445780: Average global foreground Dice: [0.8587]\n",
      "2021-11-03 07:08:54.451850: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 07:08:54.916838: lr: 0.005743\n",
      "2021-11-03 07:08:54.979812: saving checkpoint...\n",
      "2021-11-03 07:08:56.103770: done, saving took 1.17 seconds\n",
      "2021-11-03 07:08:56.709787: This epoch took 291.602592 s\n",
      "\n",
      "2021-11-03 07:08:56.719085: \n",
      "epoch:  23\n",
      "2021-11-03 07:13:29.007606: train loss : -0.8299\n",
      "2021-11-03 07:13:46.402670: validation loss: -0.8432\n",
      "2021-11-03 07:13:46.406779: Average global foreground Dice: [0.8606]\n",
      "2021-11-03 07:13:46.413547: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 07:13:46.879812: lr: 0.005551\n",
      "2021-11-03 07:13:46.955667: saving checkpoint...\n",
      "2021-11-03 07:13:48.085455: done, saving took 1.19 seconds\n",
      "2021-11-03 07:13:48.662022: This epoch took 291.935803 s\n",
      "\n",
      "2021-11-03 07:13:48.671028: \n",
      "epoch:  24\n",
      "2021-11-03 07:18:21.797323: train loss : -0.8319\n",
      "2021-11-03 07:18:39.189997: validation loss: -0.8408\n",
      "2021-11-03 07:18:39.193607: Average global foreground Dice: [0.8602]\n",
      "2021-11-03 07:18:39.200521: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 07:18:39.674524: lr: 0.005359\n",
      "2021-11-03 07:18:39.756655: saving checkpoint...\n",
      "2021-11-03 07:18:40.892027: done, saving took 1.20 seconds\n",
      "2021-11-03 07:18:41.480757: This epoch took 292.799841 s\n",
      "\n",
      "2021-11-03 07:18:41.489158: \n",
      "epoch:  25\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-03 07:23:14.806230: train loss : -0.8302\n",
      "2021-11-03 07:23:32.178066: validation loss: -0.8523\n",
      "2021-11-03 07:23:32.182162: Average global foreground Dice: [0.8655]\n",
      "2021-11-03 07:23:32.189108: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 07:23:32.667024: lr: 0.005166\n",
      "2021-11-03 07:23:32.748515: saving checkpoint...\n",
      "2021-11-03 07:23:33.871941: done, saving took 1.19 seconds\n",
      "2021-11-03 07:23:34.438855: This epoch took 292.942017 s\n",
      "\n",
      "2021-11-03 07:23:34.447721: \n",
      "epoch:  26\n",
      "2021-11-03 07:28:05.401188: train loss : -0.8268\n",
      "2021-11-03 07:28:22.645367: validation loss: -0.8380\n",
      "2021-11-03 07:28:22.649202: Average global foreground Dice: [0.8509]\n",
      "2021-11-03 07:28:22.655833: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 07:28:23.125280: lr: 0.004971\n",
      "2021-11-03 07:28:23.197697: saving checkpoint...\n",
      "2021-11-03 07:28:24.331378: done, saving took 1.19 seconds\n",
      "2021-11-03 07:28:24.985690: This epoch took 290.530571 s\n",
      "\n",
      "2021-11-03 07:28:24.994252: \n",
      "epoch:  27\n",
      "2021-11-03 07:32:56.491861: train loss : -0.8348\n",
      "2021-11-03 07:33:13.868336: validation loss: -0.8455\n",
      "2021-11-03 07:33:13.872398: Average global foreground Dice: [0.8602]\n",
      "2021-11-03 07:33:13.879863: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 07:33:14.368810: lr: 0.004776\n",
      "2021-11-03 07:33:14.441546: saving checkpoint...\n",
      "2021-11-03 07:33:15.610885: done, saving took 1.23 seconds\n",
      "2021-11-03 07:33:16.210301: This epoch took 291.207683 s\n",
      "\n",
      "2021-11-03 07:33:16.220012: \n",
      "epoch:  28\n",
      "2021-11-03 07:37:47.139945: train loss : -0.8369\n",
      "2021-11-03 07:38:04.387076: validation loss: -0.8404\n",
      "2021-11-03 07:38:04.391176: Average global foreground Dice: [0.8581]\n",
      "2021-11-03 07:38:04.398487: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 07:38:04.866776: lr: 0.004581\n",
      "2021-11-03 07:38:04.916115: saving checkpoint...\n",
      "2021-11-03 07:38:06.111062: done, saving took 1.22 seconds\n",
      "2021-11-03 07:38:06.717449: This epoch took 290.488541 s\n",
      "\n",
      "2021-11-03 07:38:06.726846: \n",
      "epoch:  29\n",
      "2021-11-03 07:42:37.709784: train loss : -0.8339\n",
      "2021-11-03 07:42:55.024085: validation loss: -0.8464\n",
      "2021-11-03 07:42:55.028041: Average global foreground Dice: [0.8597]\n",
      "2021-11-03 07:42:55.034825: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 07:42:55.499419: lr: 0.004384\n",
      "2021-11-03 07:42:55.549054: saving checkpoint...\n",
      "2021-11-03 07:42:56.771972: done, saving took 1.25 seconds\n",
      "2021-11-03 07:42:57.424621: This epoch took 290.690433 s\n",
      "\n",
      "2021-11-03 07:42:57.433323: \n",
      "epoch:  30\n",
      "2021-11-03 07:47:28.601269: train loss : -0.8370\n",
      "2021-11-03 07:47:46.198927: validation loss: -0.8380\n",
      "2021-11-03 07:47:46.202969: Average global foreground Dice: [0.8484]\n",
      "2021-11-03 07:47:46.210076: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 07:47:46.676681: lr: 0.004186\n",
      "2021-11-03 07:47:46.735768: saving checkpoint...\n",
      "2021-11-03 07:47:47.860176: done, saving took 1.15 seconds\n",
      "2021-11-03 07:47:48.471413: This epoch took 291.031254 s\n",
      "\n",
      "2021-11-03 07:47:48.492653: \n",
      "epoch:  31\n",
      "2021-11-03 07:52:20.129682: train loss : -0.8360\n",
      "2021-11-03 07:52:37.490008: validation loss: -0.8508\n",
      "2021-11-03 07:52:37.493753: Average global foreground Dice: [0.8602]\n",
      "2021-11-03 07:52:37.501312: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 07:52:38.016616: lr: 0.003987\n",
      "2021-11-03 07:52:38.075676: saving checkpoint...\n",
      "2021-11-03 07:52:39.182673: done, saving took 1.14 seconds\n",
      "2021-11-03 07:52:39.839573: This epoch took 291.338715 s\n",
      "\n",
      "2021-11-03 07:52:39.854155: \n",
      "epoch:  32\n",
      "2021-11-03 07:57:10.674131: train loss : -0.8338\n",
      "2021-11-03 07:57:27.931851: validation loss: -0.8536\n",
      "2021-11-03 07:57:27.935755: Average global foreground Dice: [0.8662]\n",
      "2021-11-03 07:57:27.942816: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 07:57:28.413997: lr: 0.003787\n",
      "2021-11-03 07:57:28.478264: saving checkpoint...\n",
      "2021-11-03 07:57:29.580550: done, saving took 1.13 seconds\n",
      "2021-11-03 07:57:30.170856: This epoch took 290.308418 s\n",
      "\n",
      "2021-11-03 07:57:30.184380: \n",
      "epoch:  33\n",
      "2021-11-03 08:02:01.071513: train loss : -0.8363\n",
      "2021-11-03 08:02:18.309727: validation loss: -0.8401\n",
      "2021-11-03 08:02:18.313603: Average global foreground Dice: [0.8575]\n",
      "2021-11-03 08:02:18.321046: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 08:02:18.797339: lr: 0.003586\n",
      "2021-11-03 08:02:18.857285: saving checkpoint...\n",
      "2021-11-03 08:02:20.080943: done, saving took 1.25 seconds\n",
      "2021-11-03 08:02:20.728273: This epoch took 290.536632 s\n",
      "\n",
      "2021-11-03 08:02:20.746782: \n",
      "epoch:  34\n",
      "2021-11-03 08:06:52.593409: train loss : -0.8405\n",
      "2021-11-03 08:07:09.818690: validation loss: -0.8527\n",
      "2021-11-03 08:07:09.824076: Average global foreground Dice: [0.8638]\n",
      "2021-11-03 08:07:09.831003: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 08:07:10.299807: lr: 0.003384\n",
      "2021-11-03 08:07:10.358531: saving checkpoint...\n",
      "2021-11-03 08:07:11.481901: done, saving took 1.15 seconds\n",
      "2021-11-03 08:07:12.086390: This epoch took 291.332838 s\n",
      "\n",
      "2021-11-03 08:07:12.099831: \n",
      "epoch:  35\n",
      "2021-11-03 08:11:43.581964: train loss : -0.8380\n",
      "2021-11-03 08:12:00.867600: validation loss: -0.8520\n",
      "2021-11-03 08:12:00.871673: Average global foreground Dice: [0.8596]\n",
      "2021-11-03 08:12:00.878334: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 08:12:01.351911: lr: 0.00318\n",
      "2021-11-03 08:12:01.398311: saving checkpoint...\n",
      "2021-11-03 08:12:02.503817: done, saving took 1.13 seconds\n",
      "2021-11-03 08:12:03.113166: This epoch took 291.005871 s\n",
      "\n",
      "2021-11-03 08:12:03.121677: \n",
      "epoch:  36\n",
      "2021-11-03 08:16:34.993798: train loss : -0.8446\n",
      "2021-11-03 08:16:52.254179: validation loss: -0.8526\n",
      "2021-11-03 08:16:52.257919: Average global foreground Dice: [0.8655]\n",
      "2021-11-03 08:16:52.264615: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 08:16:52.732815: lr: 0.002975\n",
      "2021-11-03 08:16:52.779410: saving checkpoint...\n",
      "2021-11-03 08:16:53.902963: done, saving took 1.15 seconds\n",
      "2021-11-03 08:16:54.549498: This epoch took 291.420702 s\n",
      "\n",
      "2021-11-03 08:16:54.558880: \n",
      "epoch:  37\n",
      "2021-11-03 08:21:26.834444: train loss : -0.8410\n",
      "2021-11-03 08:21:44.072116: validation loss: -0.8510\n",
      "2021-11-03 08:21:44.077723: Average global foreground Dice: [0.8605]\n",
      "2021-11-03 08:21:44.085387: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 08:21:44.558407: lr: 0.002768\n",
      "2021-11-03 08:21:44.606021: saving checkpoint...\n",
      "2021-11-03 08:21:45.739806: done, saving took 1.16 seconds\n",
      "2021-11-03 08:21:46.431183: This epoch took 291.864614 s\n",
      "\n",
      "2021-11-03 08:21:46.439953: \n",
      "epoch:  38\n",
      "2021-11-03 08:26:19.893659: train loss : -0.8464\n",
      "2021-11-03 08:26:37.549903: validation loss: -0.8509\n",
      "2021-11-03 08:26:37.553820: Average global foreground Dice: [0.8615]\n",
      "2021-11-03 08:26:37.560975: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 08:26:38.034365: lr: 0.00256\n",
      "2021-11-03 08:26:38.105623: saving checkpoint...\n",
      "2021-11-03 08:26:39.246568: done, saving took 1.19 seconds\n",
      "2021-11-03 08:26:39.822934: This epoch took 293.375666 s\n",
      "\n",
      "2021-11-03 08:26:39.830587: \n",
      "epoch:  39\n",
      "2021-11-03 08:31:13.016833: train loss : -0.8458\n",
      "2021-11-03 08:31:30.431397: validation loss: -0.8519\n",
      "2021-11-03 08:31:30.435324: Average global foreground Dice: [0.8608]\n",
      "2021-11-03 08:31:30.442345: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 08:31:30.930037: lr: 0.002349\n",
      "2021-11-03 08:31:30.999045: saving checkpoint...\n",
      "2021-11-03 08:31:32.174824: done, saving took 1.23 seconds\n",
      "2021-11-03 08:31:32.761592: This epoch took 292.923906 s\n",
      "\n",
      "2021-11-03 08:31:32.770722: \n",
      "epoch:  40\n",
      "2021-11-03 08:36:05.621936: train loss : -0.8479\n",
      "2021-11-03 08:36:22.856560: validation loss: -0.8503\n",
      "2021-11-03 08:36:22.860738: Average global foreground Dice: [0.8601]\n",
      "2021-11-03 08:36:22.867922: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 08:36:23.341157: lr: 0.002137\n",
      "2021-11-03 08:36:23.387778: saving checkpoint...\n",
      "2021-11-03 08:36:24.493731: done, saving took 1.13 seconds\n",
      "2021-11-03 08:36:25.078116: This epoch took 292.300257 s\n",
      "\n",
      "2021-11-03 08:36:25.087105: \n",
      "epoch:  41\n",
      "2021-11-03 08:40:56.803224: train loss : -0.8504\n",
      "2021-11-03 08:41:14.046026: validation loss: -0.8482\n",
      "2021-11-03 08:41:14.049996: Average global foreground Dice: [0.8608]\n",
      "2021-11-03 08:41:14.057247: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 08:41:14.528100: lr: 0.001922\n",
      "2021-11-03 08:41:14.587396: saving checkpoint...\n",
      "2021-11-03 08:41:15.807809: done, saving took 1.25 seconds\n",
      "2021-11-03 08:41:16.464823: This epoch took 291.370148 s\n",
      "\n",
      "2021-11-03 08:41:16.485576: \n",
      "epoch:  42\n",
      "2021-11-03 08:45:48.303361: train loss : -0.8466\n",
      "2021-11-03 08:46:05.634070: validation loss: -0.8532\n",
      "2021-11-03 08:46:05.639584: Average global foreground Dice: [0.8623]\n",
      "2021-11-03 08:46:05.645940: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 08:46:06.121745: lr: 0.001704\n",
      "2021-11-03 08:46:06.172927: saving checkpoint...\n",
      "2021-11-03 08:46:07.292299: done, saving took 1.15 seconds\n",
      "2021-11-03 08:46:07.920008: This epoch took 291.427312 s\n",
      "\n",
      "2021-11-03 08:46:07.928906: \n",
      "epoch:  43\n",
      "2021-11-03 08:50:38.739701: train loss : -0.8509\n",
      "2021-11-03 08:50:55.963848: validation loss: -0.8534\n",
      "2021-11-03 08:50:55.967709: Average global foreground Dice: [0.8647]\n",
      "2021-11-03 08:50:55.974207: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 08:50:56.438239: lr: 0.001483\n",
      "2021-11-03 08:50:56.486869: saving checkpoint...\n",
      "2021-11-03 08:50:57.590423: done, saving took 1.13 seconds\n",
      "2021-11-03 08:50:58.223277: This epoch took 290.287413 s\n",
      "\n",
      "2021-11-03 08:50:58.232791: \n",
      "epoch:  44\n",
      "2021-11-03 08:55:27.722646: train loss : -0.8498\n",
      "2021-11-03 08:55:44.954501: validation loss: -0.8501\n",
      "2021-11-03 08:55:44.958619: Average global foreground Dice: [0.8594]\n",
      "2021-11-03 08:55:44.965112: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 08:55:45.431652: lr: 0.001259\n",
      "2021-11-03 08:55:45.477100: saving checkpoint...\n",
      "2021-11-03 08:55:46.604690: done, saving took 1.16 seconds\n",
      "2021-11-03 08:55:47.214727: This epoch took 288.973677 s\n",
      "\n",
      "2021-11-03 08:55:47.223572: \n",
      "epoch:  45\n",
      "2021-11-03 09:00:18.217216: train loss : -0.8511\n",
      "2021-11-03 09:00:35.468665: validation loss: -0.8389\n",
      "2021-11-03 09:00:35.472425: Average global foreground Dice: [0.8494]\n",
      "2021-11-03 09:00:35.478550: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 09:00:35.943142: lr: 0.00103\n",
      "2021-11-03 09:00:35.960546: This epoch took 288.730122 s\n",
      "\n",
      "2021-11-03 09:00:35.969643: \n",
      "epoch:  46\n",
      "2021-11-03 09:05:06.482459: train loss : -0.8530\n",
      "2021-11-03 09:05:23.771710: validation loss: -0.8537\n",
      "2021-11-03 09:05:23.775458: Average global foreground Dice: [0.8638]\n",
      "2021-11-03 09:05:23.781732: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 09:05:24.250829: lr: 0.000795\n",
      "2021-11-03 09:05:24.267015: This epoch took 288.286077 s\n",
      "\n",
      "2021-11-03 09:05:24.274959: \n",
      "epoch:  47\n",
      "2021-11-03 09:09:54.856307: train loss : -0.8551\n",
      "2021-11-03 09:10:12.140357: validation loss: -0.8516\n",
      "2021-11-03 09:10:12.144036: Average global foreground Dice: [0.8593]\n",
      "2021-11-03 09:10:12.150772: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 09:10:12.617203: lr: 0.000552\n",
      "2021-11-03 09:10:12.633552: This epoch took 288.350843 s\n",
      "\n",
      "2021-11-03 09:10:12.641504: \n",
      "epoch:  48\n",
      "2021-11-03 09:14:43.424024: train loss : -0.8530\n",
      "2021-11-03 09:15:00.824996: validation loss: -0.8514\n",
      "2021-11-03 09:15:00.829366: Average global foreground Dice: [0.8604]\n",
      "2021-11-03 09:15:00.835937: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 09:15:01.310964: lr: 0.000296\n",
      "2021-11-03 09:15:01.390923: saving checkpoint...\n",
      "2021-11-03 09:15:02.679533: done, saving took 1.35 seconds\n",
      "2021-11-03 09:15:03.350704: This epoch took 290.701962 s\n",
      "\n",
      "2021-11-03 09:15:03.359457: \n",
      "epoch:  49\n",
      "2021-11-03 09:19:33.326160: train loss : -0.8567\n",
      "2021-11-03 09:19:50.621032: validation loss: -0.8540\n",
      "2021-11-03 09:19:50.626902: Average global foreground Dice: [0.8619]\n",
      "2021-11-03 09:19:50.634829: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 09:19:51.118682: lr: 0.0\n",
      "2021-11-03 09:19:51.147352: saving scheduled checkpoint file...\n",
      "2021-11-03 09:19:51.213305: saving checkpoint...\n",
      "2021-11-03 09:19:52.245090: done, saving took 1.09 seconds\n",
      "2021-11-03 09:19:52.889391: done\n",
      "2021-11-03 09:19:52.936816: saving checkpoint...\n",
      "2021-11-03 09:19:54.055842: done, saving took 1.15 seconds\n",
      "2021-11-03 09:19:54.738824: This epoch took 291.371656 s\n",
      "\n",
      "2021-11-03 09:19:54.784773: saving checkpoint...\n",
      "2021-11-03 09:19:55.732388: done, saving took 0.98 seconds\n",
      "23090559_20150812 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120330 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090563_20151216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130226 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090584_20120523 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090589_20140219 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090592_20130218 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090614_20120402 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090620_20130617 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090627_20160608 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090628_20150204 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090635_20140710 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090640_20140711 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121227 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-03 09:23:12.323869: finished prediction\n",
      "2021-11-03 09:23:12.331567: evaluation of raw predictions\n",
      "2021-11-03 09:23:14.257503: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8564647874368128\n",
      "after:  0.8564647874368128\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-03 09:23:26.266222: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-03 09:23:26.289431: The split file contains 5 splits.\n",
      "2021-11-03 09:23:26.295142: Desired fold for training: 1\n",
      "2021-11-03 09:23:26.302707: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-03 09:23:30.570084: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-03 09:23:43.539281: Unable to plot network architecture:\n",
      "2021-11-03 09:23:43.542877: No module named 'hiddenlayer'\n",
      "2021-11-03 09:23:43.549557: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-03 09:23:43.556561: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-03 09:23:43.650309: \n",
      "\n",
      "2021-11-03 09:23:43.656838: \n",
      "epoch:  0\n",
      "2021-11-03 09:28:33.970636: train loss : -0.1583\n",
      "2021-11-03 09:28:51.323358: validation loss: -0.5239\n",
      "2021-11-03 09:28:51.329051: Average global foreground Dice: [0.5979]\n",
      "2021-11-03 09:28:51.335867: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 09:28:51.751525: lr: 0.00982\n",
      "2021-11-03 09:28:51.784687: This epoch took 308.121339 s\n",
      "\n",
      "2021-11-03 09:28:51.791708: \n",
      "epoch:  1\n",
      "2021-11-03 09:33:20.928334: train loss : -0.5892\n",
      "2021-11-03 09:33:38.188941: validation loss: -0.6696\n",
      "2021-11-03 09:33:38.248011: Average global foreground Dice: [0.6922]\n",
      "2021-11-03 09:33:38.255189: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 09:33:38.729297: lr: 0.009639\n",
      "2021-11-03 09:33:38.835618: saving checkpoint...\n",
      "2021-11-03 09:33:39.792018: done, saving took 1.03 seconds\n",
      "2021-11-03 09:33:40.446702: This epoch took 288.648168 s\n",
      "\n",
      "2021-11-03 09:33:40.466374: \n",
      "epoch:  2\n",
      "2021-11-03 09:38:08.738033: train loss : -0.6629\n",
      "2021-11-03 09:38:26.047894: validation loss: -0.7032\n",
      "2021-11-03 09:38:26.051700: Average global foreground Dice: [0.7457]\n",
      "2021-11-03 09:38:26.058620: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 09:38:26.541660: lr: 0.009458\n",
      "2021-11-03 09:38:26.641246: saving checkpoint...\n",
      "2021-11-03 09:38:27.911047: done, saving took 1.34 seconds\n",
      "2021-11-03 09:38:28.593187: This epoch took 288.119975 s\n",
      "\n",
      "2021-11-03 09:38:28.672576: \n",
      "epoch:  3\n",
      "2021-11-03 09:42:56.760429: train loss : -0.7154\n",
      "2021-11-03 09:43:14.101310: validation loss: -0.7492\n",
      "2021-11-03 09:43:14.105256: Average global foreground Dice: [0.7832]\n",
      "2021-11-03 09:43:14.111279: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 09:43:14.641569: lr: 0.009277\n",
      "2021-11-03 09:43:14.765635: saving checkpoint...\n",
      "2021-11-03 09:43:16.067349: done, saving took 1.37 seconds\n",
      "2021-11-03 09:43:16.690828: This epoch took 288.010401 s\n",
      "\n",
      "2021-11-03 09:43:16.797830: \n",
      "epoch:  4\n",
      "2021-11-03 09:47:44.080357: train loss : -0.7310\n",
      "2021-11-03 09:48:01.279948: validation loss: -0.7738\n",
      "2021-11-03 09:48:01.283917: Average global foreground Dice: [0.8037]\n",
      "2021-11-03 09:48:01.289892: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 09:48:01.769246: lr: 0.009095\n",
      "2021-11-03 09:48:01.874515: saving checkpoint...\n",
      "2021-11-03 09:48:03.166522: done, saving took 1.36 seconds\n",
      "2021-11-03 09:48:03.791165: This epoch took 286.985915 s\n",
      "\n",
      "2021-11-03 09:48:03.866228: \n",
      "epoch:  5\n",
      "2021-11-03 09:52:32.075830: train loss : -0.7489\n",
      "2021-11-03 09:52:49.447021: validation loss: -0.7789\n",
      "2021-11-03 09:52:49.451099: Average global foreground Dice: [0.8041]\n",
      "2021-11-03 09:52:49.458898: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 09:52:49.946879: lr: 0.008913\n",
      "2021-11-03 09:52:50.045182: saving checkpoint...\n",
      "2021-11-03 09:52:51.267992: done, saving took 1.29 seconds\n",
      "2021-11-03 09:52:51.886270: This epoch took 288.012878 s\n",
      "\n",
      "2021-11-03 09:52:51.902360: \n",
      "epoch:  6\n",
      "2021-11-03 09:57:20.639843: train loss : -0.7648\n",
      "2021-11-03 09:57:37.947531: validation loss: -0.7899\n",
      "2021-11-03 09:57:37.951436: Average global foreground Dice: [0.8146]\n",
      "2021-11-03 09:57:37.958068: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 09:57:38.450840: lr: 0.008731\n",
      "2021-11-03 09:57:38.555203: saving checkpoint...\n",
      "2021-11-03 09:57:39.799283: done, saving took 1.32 seconds\n",
      "2021-11-03 09:57:40.418721: This epoch took 288.509435 s\n",
      "\n",
      "2021-11-03 09:57:40.438405: \n",
      "epoch:  7\n",
      "2021-11-03 10:02:08.216624: train loss : -0.7791\n",
      "2021-11-03 10:02:25.456845: validation loss: -0.7976\n",
      "2021-11-03 10:02:25.460924: Average global foreground Dice: [0.8197]\n",
      "2021-11-03 10:02:25.466263: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 10:02:25.950045: lr: 0.008548\n",
      "2021-11-03 10:02:26.046389: saving checkpoint...\n",
      "2021-11-03 10:02:27.171592: done, saving took 1.19 seconds\n",
      "2021-11-03 10:02:27.809922: This epoch took 287.364926 s\n",
      "\n",
      "2021-11-03 10:02:27.823315: \n",
      "epoch:  8\n",
      "2021-11-03 10:06:56.266329: train loss : -0.7860\n",
      "2021-11-03 10:07:13.520825: validation loss: -0.8072\n",
      "2021-11-03 10:07:13.561476: Average global foreground Dice: [0.8298]\n",
      "2021-11-03 10:07:13.567235: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 10:07:14.058355: lr: 0.008364\n",
      "2021-11-03 10:07:14.207116: saving checkpoint...\n",
      "2021-11-03 10:07:15.478473: done, saving took 1.33 seconds\n",
      "2021-11-03 10:07:16.076346: This epoch took 288.246150 s\n",
      "\n",
      "2021-11-03 10:07:16.094239: \n",
      "epoch:  9\n",
      "2021-11-03 10:11:45.285081: train loss : -0.7899\n",
      "2021-11-03 10:12:02.634256: validation loss: -0.8083\n",
      "2021-11-03 10:12:02.638061: Average global foreground Dice: [0.8322]\n",
      "2021-11-03 10:12:02.644957: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 10:12:03.124053: lr: 0.008181\n",
      "2021-11-03 10:12:03.208866: saving checkpoint...\n",
      "2021-11-03 10:12:04.484977: done, saving took 1.34 seconds\n",
      "2021-11-03 10:12:05.138039: This epoch took 289.035342 s\n",
      "\n",
      "2021-11-03 10:12:05.151743: \n",
      "epoch:  10\n",
      "2021-11-03 10:16:32.863235: train loss : -0.7889\n",
      "2021-11-03 10:16:50.102848: validation loss: -0.8159\n",
      "2021-11-03 10:16:50.108748: Average global foreground Dice: [0.8359]\n",
      "2021-11-03 10:16:50.115233: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 10:16:50.580077: lr: 0.007996\n",
      "2021-11-03 10:16:50.641952: saving checkpoint...\n",
      "2021-11-03 10:16:51.922035: done, saving took 1.31 seconds\n",
      "2021-11-03 10:16:52.543225: This epoch took 287.382325 s\n",
      "\n",
      "2021-11-03 10:16:52.563786: \n",
      "epoch:  11\n",
      "2021-11-03 10:21:20.574889: train loss : -0.7994\n",
      "2021-11-03 10:21:37.874957: validation loss: -0.8133\n",
      "2021-11-03 10:21:37.878885: Average global foreground Dice: [0.8307]\n",
      "2021-11-03 10:21:37.885136: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 10:21:38.352008: lr: 0.007811\n",
      "2021-11-03 10:21:38.407378: saving checkpoint...\n",
      "2021-11-03 10:21:39.624692: done, saving took 1.25 seconds\n",
      "2021-11-03 10:21:40.271768: This epoch took 287.700455 s\n",
      "\n",
      "2021-11-03 10:21:40.284837: \n",
      "epoch:  12\n",
      "2021-11-03 10:26:08.073011: train loss : -0.8087\n",
      "2021-11-03 10:26:25.316590: validation loss: -0.8254\n",
      "2021-11-03 10:26:25.322862: Average global foreground Dice: [0.8408]\n",
      "2021-11-03 10:26:25.392175: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 10:26:25.877596: lr: 0.007626\n",
      "2021-11-03 10:26:25.939674: saving checkpoint...\n",
      "2021-11-03 10:26:27.168278: done, saving took 1.26 seconds\n",
      "2021-11-03 10:26:27.777085: This epoch took 287.485602 s\n",
      "\n",
      "2021-11-03 10:26:27.798581: \n",
      "epoch:  13\n",
      "2021-11-03 10:30:56.213248: train loss : -0.8039\n",
      "2021-11-03 10:31:13.389632: validation loss: -0.8216\n",
      "2021-11-03 10:31:13.440773: Average global foreground Dice: [0.8381]\n",
      "2021-11-03 10:31:13.447657: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 10:31:13.917666: lr: 0.00744\n",
      "2021-11-03 10:31:13.975194: saving checkpoint...\n",
      "2021-11-03 10:31:15.210500: done, saving took 1.26 seconds\n",
      "2021-11-03 10:31:15.922945: This epoch took 288.116340 s\n",
      "\n",
      "2021-11-03 10:31:16.030816: \n",
      "epoch:  14\n",
      "2021-11-03 10:35:44.017163: train loss : -0.8156\n",
      "2021-11-03 10:36:01.258804: validation loss: -0.8136\n",
      "2021-11-03 10:36:01.264261: Average global foreground Dice: [0.8327]\n",
      "2021-11-03 10:36:01.271000: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 10:36:01.738335: lr: 0.007254\n",
      "2021-11-03 10:36:01.798857: saving checkpoint...\n",
      "2021-11-03 10:36:02.916702: done, saving took 1.15 seconds\n",
      "2021-11-03 10:36:03.642314: This epoch took 287.603670 s\n",
      "\n",
      "2021-11-03 10:36:03.661342: \n",
      "epoch:  15\n",
      "2021-11-03 10:40:31.570656: train loss : -0.8117\n",
      "2021-11-03 10:40:48.757563: validation loss: -0.8258\n",
      "2021-11-03 10:40:48.761171: Average global foreground Dice: [0.8417]\n",
      "2021-11-03 10:40:48.767630: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 10:40:49.284612: lr: 0.007067\n",
      "2021-11-03 10:40:49.343309: saving checkpoint...\n",
      "2021-11-03 10:40:50.663913: done, saving took 1.35 seconds\n",
      "2021-11-03 10:40:51.327261: This epoch took 287.657458 s\n",
      "\n",
      "2021-11-03 10:40:51.346052: \n",
      "epoch:  16\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-03 10:45:19.771420: train loss : -0.8141\n",
      "2021-11-03 10:45:37.040488: validation loss: -0.8208\n",
      "2021-11-03 10:45:37.044213: Average global foreground Dice: [0.8351]\n",
      "2021-11-03 10:45:37.050797: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 10:45:37.561065: lr: 0.00688\n",
      "2021-11-03 10:45:37.620661: saving checkpoint...\n",
      "2021-11-03 10:45:38.840173: done, saving took 1.25 seconds\n",
      "2021-11-03 10:45:39.454121: This epoch took 288.101090 s\n",
      "\n",
      "2021-11-03 10:45:39.471617: \n",
      "epoch:  17\n",
      "2021-11-03 10:50:06.849283: train loss : -0.8206\n",
      "2021-11-03 10:50:24.007835: validation loss: -0.8182\n",
      "2021-11-03 10:50:24.012825: Average global foreground Dice: [0.8378]\n",
      "2021-11-03 10:50:24.020485: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 10:50:24.496994: lr: 0.006692\n",
      "2021-11-03 10:50:24.556962: saving checkpoint...\n",
      "2021-11-03 10:50:25.823506: done, saving took 1.30 seconds\n",
      "2021-11-03 10:50:26.461060: This epoch took 286.982414 s\n",
      "\n",
      "2021-11-03 10:50:26.481409: \n",
      "epoch:  18\n",
      "2021-11-03 10:54:54.213444: train loss : -0.8268\n",
      "2021-11-03 10:55:11.398453: validation loss: -0.8303\n",
      "2021-11-03 10:55:11.403876: Average global foreground Dice: [0.8438]\n",
      "2021-11-03 10:55:11.410730: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 10:55:11.880524: lr: 0.006504\n",
      "2021-11-03 10:55:11.940460: saving checkpoint...\n",
      "2021-11-03 10:55:13.165995: done, saving took 1.25 seconds\n",
      "2021-11-03 10:55:13.837299: This epoch took 287.348324 s\n",
      "\n",
      "2021-11-03 10:55:13.857902: \n",
      "epoch:  19\n",
      "2021-11-03 10:59:41.369181: train loss : -0.8208\n",
      "2021-11-03 10:59:58.573205: validation loss: -0.8278\n",
      "2021-11-03 10:59:58.579214: Average global foreground Dice: [0.8432]\n",
      "2021-11-03 10:59:58.586723: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 10:59:59.061117: lr: 0.006314\n",
      "2021-11-03 10:59:59.124362: saving checkpoint...\n",
      "2021-11-03 11:00:00.243692: done, saving took 1.15 seconds\n",
      "2021-11-03 11:00:00.865584: This epoch took 287.000950 s\n",
      "\n",
      "2021-11-03 11:00:00.885870: \n",
      "epoch:  20\n",
      "2021-11-03 11:04:28.897887: train loss : -0.8254\n",
      "2021-11-03 11:04:46.022930: validation loss: -0.8234\n",
      "2021-11-03 11:04:46.025565: Average global foreground Dice: [0.834]\n",
      "2021-11-03 11:04:46.030740: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 11:04:46.504538: lr: 0.006125\n",
      "2021-11-03 11:04:46.565003: saving checkpoint...\n",
      "2021-11-03 11:04:47.798578: done, saving took 1.26 seconds\n",
      "2021-11-03 11:04:48.360860: This epoch took 287.467562 s\n",
      "\n",
      "2021-11-03 11:04:48.379128: \n",
      "epoch:  21\n",
      "2021-11-03 11:09:16.210143: train loss : -0.8229\n",
      "2021-11-03 11:09:33.380632: validation loss: -0.8270\n",
      "2021-11-03 11:09:33.383468: Average global foreground Dice: [0.8357]\n",
      "2021-11-03 11:09:33.388657: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 11:09:33.852657: lr: 0.005934\n",
      "2021-11-03 11:09:33.911371: saving checkpoint...\n",
      "2021-11-03 11:09:35.199773: done, saving took 1.32 seconds\n",
      "2021-11-03 11:09:35.742279: This epoch took 287.357737 s\n",
      "\n",
      "2021-11-03 11:09:35.760601: \n",
      "epoch:  22\n",
      "2021-11-03 11:14:03.792113: train loss : -0.8315\n",
      "2021-11-03 11:14:20.999306: validation loss: -0.8314\n",
      "2021-11-03 11:14:21.001889: Average global foreground Dice: [0.8421]\n",
      "2021-11-03 11:14:21.007345: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 11:14:21.469542: lr: 0.005743\n",
      "2021-11-03 11:14:21.529212: saving checkpoint...\n",
      "2021-11-03 11:14:22.769653: done, saving took 1.27 seconds\n",
      "2021-11-03 11:14:23.291410: This epoch took 287.523985 s\n",
      "\n",
      "2021-11-03 11:14:23.314869: \n",
      "epoch:  23\n",
      "2021-11-03 11:18:51.416125: train loss : -0.8284\n",
      "2021-11-03 11:19:08.561589: validation loss: -0.8292\n",
      "2021-11-03 11:19:08.564323: Average global foreground Dice: [0.8414]\n",
      "2021-11-03 11:19:08.569721: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 11:19:09.026937: lr: 0.005551\n",
      "2021-11-03 11:19:09.085210: saving checkpoint...\n",
      "2021-11-03 11:19:10.317149: done, saving took 1.26 seconds\n",
      "2021-11-03 11:19:10.865000: This epoch took 287.541890 s\n",
      "\n",
      "2021-11-03 11:19:10.882900: \n",
      "epoch:  24\n",
      "2021-11-03 11:23:39.066219: train loss : -0.8342\n",
      "2021-11-03 11:23:56.242670: validation loss: -0.8333\n",
      "2021-11-03 11:23:56.246278: Average global foreground Dice: [0.8445]\n",
      "2021-11-03 11:23:56.251573: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 11:23:56.711035: lr: 0.005359\n",
      "2021-11-03 11:23:56.769220: saving checkpoint...\n",
      "2021-11-03 11:23:57.887236: done, saving took 1.15 seconds\n",
      "2021-11-03 11:23:58.430285: This epoch took 287.541860 s\n",
      "\n",
      "2021-11-03 11:23:58.444456: \n",
      "epoch:  25\n",
      "2021-11-03 11:28:26.906699: train loss : -0.8281\n",
      "2021-11-03 11:28:44.116291: validation loss: -0.8323\n",
      "2021-11-03 11:28:44.119246: Average global foreground Dice: [0.8469]\n",
      "2021-11-03 11:28:44.123410: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 11:28:44.592201: lr: 0.005166\n",
      "2021-11-03 11:28:44.676980: saving checkpoint...\n",
      "2021-11-03 11:28:45.964199: done, saving took 1.34 seconds\n",
      "2021-11-03 11:28:46.520521: This epoch took 288.070020 s\n",
      "\n",
      "2021-11-03 11:28:46.544030: \n",
      "epoch:  26\n",
      "2021-11-03 11:33:16.272043: train loss : -0.8327\n",
      "2021-11-03 11:33:33.510584: validation loss: -0.8304\n",
      "2021-11-03 11:33:33.513572: Average global foreground Dice: [0.8437]\n",
      "2021-11-03 11:33:33.518860: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 11:33:34.000176: lr: 0.004971\n",
      "2021-11-03 11:33:34.085811: saving checkpoint...\n",
      "2021-11-03 11:33:35.333341: done, saving took 1.30 seconds\n",
      "2021-11-03 11:33:35.893264: This epoch took 289.342581 s\n",
      "\n",
      "2021-11-03 11:33:35.907921: \n",
      "epoch:  27\n",
      "2021-11-03 11:38:05.356741: train loss : -0.8344\n",
      "2021-11-03 11:38:22.598031: validation loss: -0.8274\n",
      "2021-11-03 11:38:22.600953: Average global foreground Dice: [0.8376]\n",
      "2021-11-03 11:38:22.609336: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 11:38:23.088592: lr: 0.004776\n",
      "2021-11-03 11:38:23.175196: saving checkpoint...\n",
      "2021-11-03 11:38:24.469583: done, saving took 1.35 seconds\n",
      "2021-11-03 11:38:25.097085: This epoch took 289.183636 s\n",
      "\n",
      "2021-11-03 11:38:25.116816: \n",
      "epoch:  28\n",
      "2021-11-03 11:42:53.987411: train loss : -0.8347\n",
      "2021-11-03 11:43:11.103762: validation loss: -0.8354\n",
      "2021-11-03 11:43:11.107661: Average global foreground Dice: [0.8479]\n",
      "2021-11-03 11:43:11.112435: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 11:43:11.576411: lr: 0.004581\n",
      "2021-11-03 11:43:11.638309: saving checkpoint...\n",
      "2021-11-03 11:43:12.881327: done, saving took 1.27 seconds\n",
      "2021-11-03 11:43:13.453069: This epoch took 288.329969 s\n",
      "\n",
      "2021-11-03 11:43:13.472762: \n",
      "epoch:  29\n",
      "2021-11-03 11:47:42.306225: train loss : -0.8381\n",
      "2021-11-03 11:47:59.553530: validation loss: -0.8248\n",
      "2021-11-03 11:47:59.557048: Average global foreground Dice: [0.8325]\n",
      "2021-11-03 11:47:59.562627: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 11:48:00.030155: lr: 0.004384\n",
      "2021-11-03 11:48:00.078046: saving checkpoint...\n",
      "2021-11-03 11:48:01.193757: done, saving took 1.14 seconds\n",
      "2021-11-03 11:48:01.759528: This epoch took 288.280569 s\n",
      "\n",
      "2021-11-03 11:48:01.766347: \n",
      "epoch:  30\n",
      "2021-11-03 11:52:30.509289: train loss : -0.8358\n",
      "2021-11-03 11:52:47.695788: validation loss: -0.8241\n",
      "2021-11-03 11:52:47.698629: Average global foreground Dice: [0.8331]\n",
      "2021-11-03 11:52:47.704222: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 11:52:48.175456: lr: 0.004186\n",
      "2021-11-03 11:52:48.235429: saving checkpoint...\n",
      "2021-11-03 11:52:49.461877: done, saving took 1.26 seconds\n",
      "2021-11-03 11:52:50.017371: This epoch took 288.246220 s\n",
      "\n",
      "2021-11-03 11:52:50.032522: \n",
      "epoch:  31\n",
      "2021-11-03 11:57:18.388822: train loss : -0.8422\n",
      "2021-11-03 11:57:35.507856: validation loss: -0.8357\n",
      "2021-11-03 11:57:35.511568: Average global foreground Dice: [0.8477]\n",
      "2021-11-03 11:57:35.516940: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 11:57:35.982266: lr: 0.003987\n",
      "2021-11-03 11:57:36.039470: saving checkpoint...\n",
      "2021-11-03 11:57:37.268592: done, saving took 1.26 seconds\n",
      "2021-11-03 11:57:37.808340: This epoch took 287.769696 s\n",
      "\n",
      "2021-11-03 11:57:37.826196: \n",
      "epoch:  32\n",
      "2021-11-03 12:02:07.232195: train loss : -0.8403\n",
      "2021-11-03 12:02:24.425430: validation loss: -0.8374\n",
      "2021-11-03 12:02:24.427977: Average global foreground Dice: [0.8441]\n",
      "2021-11-03 12:02:24.432663: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 12:02:24.904053: lr: 0.003787\n",
      "2021-11-03 12:02:24.962566: saving checkpoint...\n",
      "2021-11-03 12:02:26.219467: done, saving took 1.29 seconds\n",
      "2021-11-03 12:02:26.792037: This epoch took 288.960125 s\n",
      "\n",
      "2021-11-03 12:02:26.807759: \n",
      "epoch:  33\n",
      "2021-11-03 12:06:56.033712: train loss : -0.8384\n",
      "2021-11-03 12:07:13.226770: validation loss: -0.8393\n",
      "2021-11-03 12:07:13.229640: Average global foreground Dice: [0.8518]\n",
      "2021-11-03 12:07:13.234698: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 12:07:13.703638: lr: 0.003586\n",
      "2021-11-03 12:07:13.762292: saving checkpoint...\n",
      "2021-11-03 12:07:15.045233: done, saving took 1.31 seconds\n",
      "2021-11-03 12:07:15.595525: This epoch took 288.782111 s\n",
      "\n",
      "2021-11-03 12:07:15.612233: \n",
      "epoch:  34\n",
      "2021-11-03 12:11:44.343304: train loss : -0.8419\n",
      "2021-11-03 12:12:01.521893: validation loss: -0.8361\n",
      "2021-11-03 12:12:01.525280: Average global foreground Dice: [0.8465]\n",
      "2021-11-03 12:12:01.531314: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 12:12:01.998830: lr: 0.003384\n",
      "2021-11-03 12:12:02.058864: saving checkpoint...\n",
      "2021-11-03 12:12:03.298524: done, saving took 1.27 seconds\n",
      "2021-11-03 12:12:03.886938: This epoch took 288.268344 s\n",
      "\n",
      "2021-11-03 12:12:03.905024: \n",
      "epoch:  35\n",
      "2021-11-03 12:16:32.733549: train loss : -0.8456\n",
      "2021-11-03 12:16:49.918467: validation loss: -0.8364\n",
      "2021-11-03 12:16:49.921538: Average global foreground Dice: [0.8451]\n",
      "2021-11-03 12:16:49.926279: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 12:16:50.396949: lr: 0.00318\n",
      "2021-11-03 12:16:50.454396: saving checkpoint...\n",
      "2021-11-03 12:16:51.676053: done, saving took 1.25 seconds\n",
      "2021-11-03 12:16:52.334290: This epoch took 288.423583 s\n",
      "\n",
      "2021-11-03 12:16:52.351978: \n",
      "epoch:  36\n",
      "2021-11-03 12:21:20.718283: train loss : -0.8451\n",
      "2021-11-03 12:21:37.923786: validation loss: -0.8313\n",
      "2021-11-03 12:21:37.926483: Average global foreground Dice: [0.8375]\n",
      "2021-11-03 12:21:37.931906: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 12:21:38.407320: lr: 0.002975\n",
      "2021-11-03 12:21:38.474578: saving checkpoint...\n",
      "2021-11-03 12:21:39.730670: done, saving took 1.28 seconds\n",
      "2021-11-03 12:21:40.359989: This epoch took 288.001955 s\n",
      "\n",
      "2021-11-03 12:21:40.383301: \n",
      "epoch:  37\n",
      "2021-11-03 12:26:09.425256: train loss : -0.8435\n",
      "2021-11-03 12:26:26.654699: validation loss: -0.8301\n",
      "2021-11-03 12:26:26.657498: Average global foreground Dice: [0.8471]\n",
      "2021-11-03 12:26:26.662902: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 12:26:27.147828: lr: 0.002768\n",
      "2021-11-03 12:26:27.221233: saving checkpoint...\n",
      "2021-11-03 12:26:28.464715: done, saving took 1.30 seconds\n",
      "2021-11-03 12:26:29.500482: This epoch took 289.108538 s\n",
      "\n",
      "2021-11-03 12:26:29.507269: \n",
      "epoch:  38\n",
      "2021-11-03 12:30:58.159346: train loss : -0.8459\n",
      "2021-11-03 12:31:15.418278: validation loss: -0.8379\n",
      "2021-11-03 12:31:15.421066: Average global foreground Dice: [0.8489]\n",
      "2021-11-03 12:31:15.426316: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 12:31:15.908713: lr: 0.00256\n",
      "2021-11-03 12:31:15.979459: saving checkpoint...\n",
      "2021-11-03 12:31:17.274538: done, saving took 1.34 seconds\n",
      "2021-11-03 12:31:18.137369: This epoch took 288.624149 s\n",
      "\n",
      "2021-11-03 12:31:18.143971: \n",
      "epoch:  39\n",
      "2021-11-03 12:35:46.476691: train loss : -0.8450\n",
      "2021-11-03 12:36:03.755328: validation loss: -0.8367\n",
      "2021-11-03 12:36:03.757977: Average global foreground Dice: [0.845]\n",
      "2021-11-03 12:36:03.762960: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 12:36:04.249540: lr: 0.002349\n",
      "2021-11-03 12:36:04.331914: saving checkpoint...\n",
      "2021-11-03 12:36:05.659993: done, saving took 1.38 seconds\n",
      "2021-11-03 12:36:06.224602: This epoch took 288.074389 s\n",
      "\n",
      "2021-11-03 12:36:06.241351: \n",
      "epoch:  40\n",
      "2021-11-03 12:40:33.757771: train loss : -0.8506\n",
      "2021-11-03 12:40:50.890924: validation loss: -0.8342\n",
      "2021-11-03 12:40:50.893758: Average global foreground Dice: [0.8439]\n",
      "2021-11-03 12:40:50.899133: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 12:40:51.368944: lr: 0.002137\n",
      "2021-11-03 12:40:51.426724: saving checkpoint...\n",
      "2021-11-03 12:40:52.667433: done, saving took 1.27 seconds\n",
      "2021-11-03 12:40:53.288806: This epoch took 287.041765 s\n",
      "\n",
      "2021-11-03 12:40:53.311123: \n",
      "epoch:  41\n",
      "2021-11-03 12:45:21.673360: train loss : -0.8457\n",
      "2021-11-03 12:45:39.045250: validation loss: -0.8460\n",
      "2021-11-03 12:45:39.047849: Average global foreground Dice: [0.8556]\n",
      "2021-11-03 12:45:39.053164: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 12:45:39.516372: lr: 0.001922\n",
      "2021-11-03 12:45:39.561637: saving checkpoint...\n",
      "2021-11-03 12:45:40.674499: done, saving took 1.14 seconds\n",
      "2021-11-03 12:45:41.400913: This epoch took 288.083158 s\n",
      "\n",
      "2021-11-03 12:45:41.408137: \n",
      "epoch:  42\n",
      "2021-11-03 12:50:09.596486: train loss : -0.8516\n",
      "2021-11-03 12:50:26.790213: validation loss: -0.8300\n",
      "2021-11-03 12:50:26.793238: Average global foreground Dice: [0.8432]\n",
      "2021-11-03 12:50:26.798857: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 12:50:27.267135: lr: 0.001704\n",
      "2021-11-03 12:50:27.312215: saving checkpoint...\n",
      "2021-11-03 12:50:28.409260: done, saving took 1.13 seconds\n",
      "2021-11-03 12:50:28.934317: This epoch took 287.520729 s\n",
      "\n",
      "2021-11-03 12:50:28.942245: \n",
      "epoch:  43\n",
      "2021-11-03 12:54:56.875362: train loss : -0.8482\n",
      "2021-11-03 12:55:14.116552: validation loss: -0.8467\n",
      "2021-11-03 12:55:14.119291: Average global foreground Dice: [0.8605]\n",
      "2021-11-03 12:55:14.124197: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 12:55:14.581298: lr: 0.001483\n",
      "2021-11-03 12:55:14.674058: saving checkpoint...\n",
      "2021-11-03 12:55:15.951975: done, saving took 1.34 seconds\n",
      "2021-11-03 12:55:16.540853: This epoch took 287.591779 s\n",
      "\n",
      "2021-11-03 12:55:16.558852: \n",
      "epoch:  44\n",
      "2021-11-03 12:59:45.349964: train loss : -0.8540\n",
      "2021-11-03 13:00:02.590079: validation loss: -0.8364\n",
      "2021-11-03 13:00:02.593288: Average global foreground Dice: [0.8431]\n",
      "2021-11-03 13:00:02.598640: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 13:00:03.079057: lr: 0.001259\n",
      "2021-11-03 13:00:03.174502: saving checkpoint...\n",
      "2021-11-03 13:00:04.432987: done, saving took 1.32 seconds\n",
      "2021-11-03 13:00:05.046242: This epoch took 288.481595 s\n",
      "\n",
      "2021-11-03 13:00:05.066469: \n",
      "epoch:  45\n",
      "2021-11-03 13:04:33.787488: train loss : -0.8550\n",
      "2021-11-03 13:04:51.173091: validation loss: -0.8410\n",
      "2021-11-03 13:04:51.175700: Average global foreground Dice: [0.8511]\n",
      "2021-11-03 13:04:51.179961: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 13:04:51.650575: lr: 0.00103\n",
      "2021-11-03 13:04:51.734157: saving checkpoint...\n",
      "2021-11-03 13:04:52.895672: done, saving took 1.22 seconds\n",
      "2021-11-03 13:04:53.436020: This epoch took 288.362916 s\n",
      "\n",
      "2021-11-03 13:04:53.442391: \n",
      "epoch:  46\n",
      "2021-11-03 13:09:21.728208: train loss : -0.8539\n",
      "2021-11-03 13:09:38.894584: validation loss: -0.8452\n",
      "2021-11-03 13:09:38.897350: Average global foreground Dice: [0.8599]\n",
      "2021-11-03 13:09:38.902400: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 13:09:39.365131: lr: 0.000795\n",
      "2021-11-03 13:09:39.429906: saving checkpoint...\n",
      "2021-11-03 13:09:40.649584: done, saving took 1.25 seconds\n",
      "2021-11-03 13:09:41.190160: This epoch took 287.743483 s\n",
      "\n",
      "2021-11-03 13:09:41.205821: \n",
      "epoch:  47\n",
      "2021-11-03 13:14:10.083081: train loss : -0.8540\n",
      "2021-11-03 13:14:27.287240: validation loss: -0.8362\n",
      "2021-11-03 13:14:27.290005: Average global foreground Dice: [0.8493]\n",
      "2021-11-03 13:14:27.297536: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 13:14:27.763498: lr: 0.000552\n",
      "2021-11-03 13:14:27.821774: saving checkpoint...\n",
      "2021-11-03 13:14:29.048682: done, saving took 1.26 seconds\n",
      "2021-11-03 13:14:29.609991: This epoch took 288.397724 s\n",
      "\n",
      "2021-11-03 13:14:29.627155: \n",
      "epoch:  48\n",
      "2021-11-03 13:18:58.848155: train loss : -0.8571\n",
      "2021-11-03 13:19:16.045671: validation loss: -0.8417\n",
      "2021-11-03 13:19:16.048207: Average global foreground Dice: [0.8521]\n",
      "2021-11-03 13:19:16.052675: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 13:19:16.513851: lr: 0.000296\n",
      "2021-11-03 13:19:16.570418: saving checkpoint...\n",
      "2021-11-03 13:19:17.821847: done, saving took 1.28 seconds\n",
      "2021-11-03 13:19:18.365044: This epoch took 288.732596 s\n",
      "\n",
      "2021-11-03 13:19:18.372417: \n",
      "epoch:  49\n",
      "2021-11-03 13:23:46.681566: train loss : -0.8564\n",
      "2021-11-03 13:24:04.022282: validation loss: -0.8412\n",
      "2021-11-03 13:24:04.025471: Average global foreground Dice: [0.8501]\n",
      "2021-11-03 13:24:04.030323: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 13:24:04.495117: lr: 0.0\n",
      "2021-11-03 13:24:04.509272: saving scheduled checkpoint file...\n",
      "2021-11-03 13:24:04.544045: saving checkpoint...\n",
      "2021-11-03 13:24:05.498759: done, saving took 0.98 seconds\n",
      "2021-11-03 13:24:06.091792: done\n",
      "2021-11-03 13:24:06.127805: saving checkpoint...\n",
      "2021-11-03 13:24:07.247013: done, saving took 1.15 seconds\n",
      "2021-11-03 13:24:07.799069: This epoch took 289.421468 s\n",
      "\n",
      "2021-11-03 13:24:07.847361: saving checkpoint...\n",
      "2021-11-03 13:24:08.814612: done, saving took 1.01 seconds\n",
      "23090567_20160819 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150401 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130213 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120627 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090590_20121212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160706 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090599_20140701 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130225 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090604_20140303 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090615_20140403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090617_20140211 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120406 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160111 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130213 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090631_20130128 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090634_20150409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-03 13:27:25.188467: finished prediction\n",
      "2021-11-03 13:27:25.195359: evaluation of raw predictions\n",
      "2021-11-03 13:27:26.690317: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8509782487659712\n",
      "after:  0.8509782487659712\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-03 13:27:38.074962: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-03 13:27:38.092357: The split file contains 5 splits.\n",
      "2021-11-03 13:27:38.096921: Desired fold for training: 2\n",
      "2021-11-03 13:27:38.100939: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-03 13:27:42.426340: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-03 13:28:02.338186: Unable to plot network architecture:\n",
      "2021-11-03 13:28:02.341092: No module named 'hiddenlayer'\n",
      "2021-11-03 13:28:02.346249: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-03 13:28:02.351946: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-03 13:28:02.361083: \n",
      "\n",
      "2021-11-03 13:28:02.365262: \n",
      "epoch:  0\n",
      "2021-11-03 13:32:51.717836: train loss : -0.2118\n",
      "2021-11-03 13:33:08.940308: validation loss: -0.6013\n",
      "2021-11-03 13:33:08.942969: Average global foreground Dice: [0.6616]\n",
      "2021-11-03 13:33:08.946894: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 13:33:09.364504: lr: 0.00982\n",
      "2021-11-03 13:33:09.399476: This epoch took 307.028840 s\n",
      "\n",
      "2021-11-03 13:33:09.408292: \n",
      "epoch:  1\n",
      "2021-11-03 13:37:37.935070: train loss : -0.6251\n",
      "2021-11-03 13:37:55.223790: validation loss: -0.6845\n",
      "2021-11-03 13:37:55.227132: Average global foreground Dice: [0.7282]\n",
      "2021-11-03 13:37:55.231385: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 13:37:55.709732: lr: 0.009639\n",
      "2021-11-03 13:37:55.812243: saving checkpoint...\n",
      "2021-11-03 13:37:56.772558: done, saving took 1.04 seconds\n",
      "2021-11-03 13:37:57.305474: This epoch took 287.889664 s\n",
      "\n",
      "2021-11-03 13:37:57.312504: \n",
      "epoch:  2\n",
      "2021-11-03 13:42:25.649158: train loss : -0.6959\n",
      "2021-11-03 13:42:42.886035: validation loss: -0.7282\n",
      "2021-11-03 13:42:42.888855: Average global foreground Dice: [0.7719]\n",
      "2021-11-03 13:42:42.893587: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 13:42:43.427614: lr: 0.009458\n",
      "2021-11-03 13:42:43.518014: saving checkpoint...\n",
      "2021-11-03 13:42:44.628673: done, saving took 1.18 seconds\n",
      "2021-11-03 13:42:45.205889: This epoch took 287.888830 s\n",
      "\n",
      "2021-11-03 13:42:45.212428: \n",
      "epoch:  3\n",
      "2021-11-03 13:47:13.287351: train loss : -0.7318\n",
      "2021-11-03 13:47:30.512505: validation loss: -0.7613\n",
      "2021-11-03 13:47:30.516312: Average global foreground Dice: [0.7951]\n",
      "2021-11-03 13:47:30.521922: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 13:47:31.015924: lr: 0.009277\n",
      "2021-11-03 13:47:31.108052: saving checkpoint...\n",
      "2021-11-03 13:47:32.419875: done, saving took 1.37 seconds\n",
      "2021-11-03 13:47:33.113495: This epoch took 287.895485 s\n",
      "\n",
      "2021-11-03 13:47:33.130459: \n",
      "epoch:  4\n",
      "2021-11-03 13:52:00.156197: train loss : -0.7422\n",
      "2021-11-03 13:52:17.373806: validation loss: -0.7544\n",
      "2021-11-03 13:52:17.377280: Average global foreground Dice: [0.7893]\n",
      "2021-11-03 13:52:17.383074: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 13:52:17.866530: lr: 0.009095\n",
      "2021-11-03 13:52:17.947424: saving checkpoint...\n",
      "2021-11-03 13:52:19.204873: done, saving took 1.31 seconds\n",
      "2021-11-03 13:52:19.752789: This epoch took 286.617498 s\n",
      "\n",
      "2021-11-03 13:52:19.778555: \n",
      "epoch:  5\n",
      "2021-11-03 13:56:47.274368: train loss : -0.7600\n",
      "2021-11-03 13:57:04.464789: validation loss: -0.7722\n",
      "2021-11-03 13:57:04.468161: Average global foreground Dice: [0.805]\n",
      "2021-11-03 13:57:04.473154: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 13:57:04.946957: lr: 0.008913\n",
      "2021-11-03 13:57:05.029019: saving checkpoint...\n",
      "2021-11-03 13:57:06.148497: done, saving took 1.19 seconds\n",
      "2021-11-03 13:57:06.677342: This epoch took 286.892723 s\n",
      "\n",
      "2021-11-03 13:57:06.684167: \n",
      "epoch:  6\n",
      "2021-11-03 14:01:35.680830: train loss : -0.7838\n",
      "2021-11-03 14:01:52.979053: validation loss: -0.7822\n",
      "2021-11-03 14:01:52.981399: Average global foreground Dice: [0.8147]\n",
      "2021-11-03 14:01:52.985371: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 14:01:53.475587: lr: 0.008731\n",
      "2021-11-03 14:01:53.572284: saving checkpoint...\n",
      "2021-11-03 14:01:54.821077: done, saving took 1.31 seconds\n",
      "2021-11-03 14:01:55.473657: This epoch took 288.783991 s\n",
      "\n",
      "2021-11-03 14:01:55.489648: \n",
      "epoch:  7\n",
      "2021-11-03 14:06:23.783031: train loss : -0.7869\n",
      "2021-11-03 14:06:41.030443: validation loss: -0.8062\n",
      "2021-11-03 14:06:41.033209: Average global foreground Dice: [0.8324]\n",
      "2021-11-03 14:06:41.038568: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 14:06:41.528710: lr: 0.008548\n",
      "2021-11-03 14:06:41.617104: saving checkpoint...\n",
      "2021-11-03 14:06:42.887545: done, saving took 1.33 seconds\n",
      "2021-11-03 14:06:43.443959: This epoch took 287.948865 s\n",
      "\n",
      "2021-11-03 14:06:43.467293: \n",
      "epoch:  8\n",
      "2021-11-03 14:11:12.695645: train loss : -0.7962\n",
      "2021-11-03 14:11:29.947948: validation loss: -0.8060\n",
      "2021-11-03 14:11:29.950437: Average global foreground Dice: [0.8312]\n",
      "2021-11-03 14:11:29.954931: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 14:11:30.443558: lr: 0.008364\n",
      "2021-11-03 14:11:30.528773: saving checkpoint...\n",
      "2021-11-03 14:11:31.665507: done, saving took 1.19 seconds\n",
      "2021-11-03 14:11:32.211812: This epoch took 288.738910 s\n",
      "\n",
      "2021-11-03 14:11:32.219158: \n",
      "epoch:  9\n",
      "2021-11-03 14:16:00.998237: train loss : -0.8054\n",
      "2021-11-03 14:16:18.319831: validation loss: -0.8129\n",
      "2021-11-03 14:16:18.322988: Average global foreground Dice: [0.8359]\n",
      "2021-11-03 14:16:18.327986: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 14:16:18.809127: lr: 0.008181\n",
      "2021-11-03 14:16:18.879020: saving checkpoint...\n",
      "2021-11-03 14:16:20.036334: done, saving took 1.21 seconds\n",
      "2021-11-03 14:16:20.557137: This epoch took 288.332705 s\n",
      "\n",
      "2021-11-03 14:16:20.564593: \n",
      "epoch:  10\n",
      "2021-11-03 14:20:48.875437: train loss : -0.8056\n",
      "2021-11-03 14:21:06.088598: validation loss: -0.7991\n",
      "2021-11-03 14:21:06.092357: Average global foreground Dice: [0.8243]\n",
      "2021-11-03 14:21:06.099248: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 14:21:06.562507: lr: 0.007996\n",
      "2021-11-03 14:21:06.625368: saving checkpoint...\n",
      "2021-11-03 14:21:07.830576: done, saving took 1.23 seconds\n",
      "2021-11-03 14:21:08.389920: This epoch took 287.820195 s\n",
      "\n",
      "2021-11-03 14:21:08.404471: \n",
      "epoch:  11\n",
      "2021-11-03 14:25:36.583245: train loss : -0.8165\n",
      "2021-11-03 14:25:53.797466: validation loss: -0.8072\n",
      "2021-11-03 14:25:53.800020: Average global foreground Dice: [0.8327]\n",
      "2021-11-03 14:25:53.804822: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 14:25:54.276951: lr: 0.007811\n",
      "2021-11-03 14:25:54.333140: saving checkpoint...\n",
      "2021-11-03 14:25:55.571575: done, saving took 1.27 seconds\n",
      "2021-11-03 14:25:56.135781: This epoch took 287.724496 s\n",
      "\n",
      "2021-11-03 14:25:56.153631: \n",
      "epoch:  12\n",
      "2021-11-03 14:30:25.407303: train loss : -0.8173\n",
      "2021-11-03 14:30:42.689503: validation loss: -0.8033\n",
      "2021-11-03 14:30:42.692832: Average global foreground Dice: [0.8279]\n",
      "2021-11-03 14:30:42.698146: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 14:30:43.171683: lr: 0.007626\n",
      "2021-11-03 14:30:43.218647: saving checkpoint...\n",
      "2021-11-03 14:30:44.331388: done, saving took 1.14 seconds\n",
      "2021-11-03 14:30:44.863061: This epoch took 288.704258 s\n",
      "\n",
      "2021-11-03 14:30:44.869569: \n",
      "epoch:  13\n",
      "2021-11-03 14:35:14.377373: train loss : -0.8168\n",
      "2021-11-03 14:35:31.626533: validation loss: -0.8155\n",
      "2021-11-03 14:35:31.629441: Average global foreground Dice: [0.8409]\n",
      "2021-11-03 14:35:31.634363: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 14:35:32.106062: lr: 0.00744\n",
      "2021-11-03 14:35:32.167069: saving checkpoint...\n",
      "2021-11-03 14:35:33.437841: done, saving took 1.30 seconds\n",
      "2021-11-03 14:35:34.001638: This epoch took 289.126319 s\n",
      "\n",
      "2021-11-03 14:35:34.024348: \n",
      "epoch:  14\n",
      "2021-11-03 14:40:03.211313: train loss : -0.8198\n",
      "2021-11-03 14:40:20.422250: validation loss: -0.8092\n",
      "2021-11-03 14:40:20.424801: Average global foreground Dice: [0.8318]\n",
      "2021-11-03 14:40:20.430056: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 14:40:20.910216: lr: 0.007254\n",
      "2021-11-03 14:40:20.969745: saving checkpoint...\n",
      "2021-11-03 14:40:22.233127: done, saving took 1.29 seconds\n",
      "2021-11-03 14:40:22.860692: This epoch took 288.828393 s\n",
      "\n",
      "2021-11-03 14:40:22.882959: \n",
      "epoch:  15\n",
      "2021-11-03 14:44:53.326739: train loss : -0.8229\n",
      "2021-11-03 14:45:10.715503: validation loss: -0.7974\n",
      "2021-11-03 14:45:10.718011: Average global foreground Dice: [0.8261]\n",
      "2021-11-03 14:45:10.723517: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 14:45:11.207933: lr: 0.007067\n",
      "2021-11-03 14:45:11.271154: saving checkpoint...\n",
      "2021-11-03 14:45:12.442405: done, saving took 1.21 seconds\n",
      "2021-11-03 14:45:12.986113: This epoch took 290.097051 s\n",
      "\n",
      "2021-11-03 14:45:12.992870: \n",
      "epoch:  16\n",
      "2021-11-03 14:49:44.189790: train loss : -0.8248\n",
      "2021-11-03 14:50:01.430563: validation loss: -0.8160\n",
      "2021-11-03 14:50:01.433214: Average global foreground Dice: [0.8386]\n",
      "2021-11-03 14:50:01.438409: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 14:50:01.914476: lr: 0.00688\n",
      "2021-11-03 14:50:02.005296: saving checkpoint...\n",
      "2021-11-03 14:50:03.144204: done, saving took 1.21 seconds\n",
      "2021-11-03 14:50:03.691291: This epoch took 290.685781 s\n",
      "\n",
      "2021-11-03 14:50:03.698644: \n",
      "epoch:  17\n",
      "2021-11-03 14:54:35.241615: train loss : -0.8291\n",
      "2021-11-03 14:54:52.880071: validation loss: -0.7984\n",
      "2021-11-03 14:54:52.883330: Average global foreground Dice: [0.8268]\n",
      "2021-11-03 14:54:52.888160: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 14:54:53.371886: lr: 0.006692\n",
      "2021-11-03 14:54:53.469764: saving checkpoint...\n",
      "2021-11-03 14:54:54.742424: done, saving took 1.34 seconds\n",
      "2021-11-03 14:54:55.303427: This epoch took 291.599362 s\n",
      "\n",
      "2021-11-03 14:54:55.326377: \n",
      "epoch:  18\n",
      "2021-11-03 14:59:26.793678: train loss : -0.8342\n",
      "2021-11-03 14:59:44.168720: validation loss: -0.8172\n",
      "2021-11-03 14:59:44.171963: Average global foreground Dice: [0.8388]\n",
      "2021-11-03 14:59:44.182149: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 14:59:44.681408: lr: 0.006504\n",
      "2021-11-03 14:59:44.766190: saving checkpoint...\n",
      "2021-11-03 14:59:46.022407: done, saving took 1.32 seconds\n",
      "2021-11-03 14:59:46.575528: This epoch took 291.242198 s\n",
      "\n",
      "2021-11-03 14:59:46.581780: \n",
      "epoch:  19\n",
      "2021-11-03 15:04:18.199830: train loss : -0.8312\n",
      "2021-11-03 15:04:35.555835: validation loss: -0.8183\n",
      "2021-11-03 15:04:35.560307: Average global foreground Dice: [0.8402]\n",
      "2021-11-03 15:04:35.565125: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 15:04:36.052002: lr: 0.006314\n",
      "2021-11-03 15:04:36.139388: saving checkpoint...\n",
      "2021-11-03 15:04:37.260545: done, saving took 1.19 seconds\n",
      "2021-11-03 15:04:37.825534: This epoch took 291.237560 s\n",
      "\n",
      "2021-11-03 15:04:37.835241: \n",
      "epoch:  20\n",
      "2021-11-03 15:09:09.435773: train loss : -0.8313\n",
      "2021-11-03 15:09:26.873464: validation loss: -0.8186\n",
      "2021-11-03 15:09:26.877775: Average global foreground Dice: [0.8399]\n",
      "2021-11-03 15:09:26.885656: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 15:09:27.377501: lr: 0.006125\n",
      "2021-11-03 15:09:27.477818: saving checkpoint...\n",
      "2021-11-03 15:09:28.769321: done, saving took 1.36 seconds\n",
      "2021-11-03 15:09:29.333865: This epoch took 291.491894 s\n",
      "\n",
      "2021-11-03 15:09:29.351253: \n",
      "epoch:  21\n",
      "2021-11-03 15:14:01.676085: train loss : -0.8311\n",
      "2021-11-03 15:14:19.225377: validation loss: -0.8186\n",
      "2021-11-03 15:14:19.228399: Average global foreground Dice: [0.8384]\n",
      "2021-11-03 15:14:19.232979: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 15:14:19.718233: lr: 0.005934\n",
      "2021-11-03 15:14:19.819476: saving checkpoint...\n",
      "2021-11-03 15:14:21.139530: done, saving took 1.38 seconds\n",
      "2021-11-03 15:14:21.721307: This epoch took 292.364243 s\n",
      "\n",
      "2021-11-03 15:14:21.749471: \n",
      "epoch:  22\n",
      "2021-11-03 15:18:53.378013: train loss : -0.8348\n",
      "2021-11-03 15:19:10.609310: validation loss: -0.8260\n",
      "2021-11-03 15:19:10.613250: Average global foreground Dice: [0.8475]\n",
      "2021-11-03 15:19:10.621482: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 15:19:11.091882: lr: 0.005743\n",
      "2021-11-03 15:19:11.154613: saving checkpoint...\n",
      "2021-11-03 15:19:12.392711: done, saving took 1.27 seconds\n",
      "2021-11-03 15:19:12.959269: This epoch took 291.202473 s\n",
      "\n",
      "2021-11-03 15:19:12.980855: \n",
      "epoch:  23\n",
      "2021-11-03 15:23:44.954655: train loss : -0.8364\n",
      "2021-11-03 15:24:02.174730: validation loss: -0.8206\n",
      "2021-11-03 15:24:02.177422: Average global foreground Dice: [0.8424]\n",
      "2021-11-03 15:24:02.182837: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 15:24:02.648286: lr: 0.005551\n",
      "2021-11-03 15:24:02.695874: saving checkpoint...\n",
      "2021-11-03 15:24:03.836638: done, saving took 1.17 seconds\n",
      "2021-11-03 15:24:04.401897: This epoch took 291.415320 s\n",
      "\n",
      "2021-11-03 15:24:04.409927: \n",
      "epoch:  24\n",
      "2021-11-03 15:28:37.649714: train loss : -0.8365\n",
      "2021-11-03 15:28:54.957290: validation loss: -0.8130\n",
      "2021-11-03 15:28:54.959805: Average global foreground Dice: [0.8385]\n",
      "2021-11-03 15:28:54.964754: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 15:28:55.437050: lr: 0.005359\n",
      "2021-11-03 15:28:55.502090: saving checkpoint...\n",
      "2021-11-03 15:28:56.741587: done, saving took 1.27 seconds\n",
      "2021-11-03 15:28:57.426670: This epoch took 293.011374 s\n",
      "\n",
      "2021-11-03 15:28:57.447335: \n",
      "epoch:  25\n",
      "2021-11-03 15:33:30.927954: train loss : -0.8390\n",
      "2021-11-03 15:33:48.226820: validation loss: -0.8276\n",
      "2021-11-03 15:33:48.230283: Average global foreground Dice: [0.8478]\n",
      "2021-11-03 15:33:48.235545: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 15:33:48.709627: lr: 0.005166\n",
      "2021-11-03 15:33:48.771033: saving checkpoint...\n",
      "2021-11-03 15:33:50.024683: done, saving took 1.28 seconds\n",
      "2021-11-03 15:33:50.596459: This epoch took 293.144048 s\n",
      "\n",
      "2021-11-03 15:33:50.613986: \n",
      "epoch:  26\n",
      "2021-11-03 15:38:25.277522: train loss : -0.8400\n",
      "2021-11-03 15:38:42.668973: validation loss: -0.8212\n",
      "2021-11-03 15:38:42.672367: Average global foreground Dice: [0.8437]\n",
      "2021-11-03 15:38:42.680087: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 15:38:43.169867: lr: 0.004971\n",
      "2021-11-03 15:38:43.255191: saving checkpoint...\n",
      "2021-11-03 15:38:44.432257: done, saving took 1.23 seconds\n",
      "2021-11-03 15:38:45.026398: This epoch took 294.406262 s\n",
      "\n",
      "2021-11-03 15:38:45.054051: \n",
      "epoch:  27\n",
      "2021-11-03 15:43:20.451127: train loss : -0.8438\n",
      "2021-11-03 15:43:38.044459: validation loss: -0.8287\n",
      "2021-11-03 15:43:38.049655: Average global foreground Dice: [0.8448]\n",
      "2021-11-03 15:43:38.057510: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 15:43:38.541433: lr: 0.004776\n",
      "2021-11-03 15:43:38.627348: saving checkpoint...\n",
      "2021-11-03 15:43:39.898952: done, saving took 1.33 seconds\n",
      "2021-11-03 15:43:40.467402: This epoch took 295.405593 s\n",
      "\n",
      "2021-11-03 15:43:40.491164: \n",
      "epoch:  28\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-03 15:48:14.979102: train loss : -0.8407\n",
      "2021-11-03 15:48:32.328249: validation loss: -0.8215\n",
      "2021-11-03 15:48:32.331311: Average global foreground Dice: [0.8417]\n",
      "2021-11-03 15:48:32.337388: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 15:48:32.810963: lr: 0.004581\n",
      "2021-11-03 15:48:32.874234: saving checkpoint...\n",
      "2021-11-03 15:48:34.128526: done, saving took 1.28 seconds\n",
      "2021-11-03 15:48:34.690121: This epoch took 294.190060 s\n",
      "\n",
      "2021-11-03 15:48:34.708274: \n",
      "epoch:  29\n",
      "2021-11-03 15:53:09.148285: train loss : -0.8405\n",
      "2021-11-03 15:53:26.557348: validation loss: -0.8040\n",
      "2021-11-03 15:53:26.559897: Average global foreground Dice: [0.829]\n",
      "2021-11-03 15:53:26.565179: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 15:53:27.041876: lr: 0.004384\n",
      "2021-11-03 15:53:27.104455: saving checkpoint...\n",
      "2021-11-03 15:53:28.342237: done, saving took 1.27 seconds\n",
      "2021-11-03 15:53:28.905964: This epoch took 294.191430 s\n",
      "\n",
      "2021-11-03 15:53:28.924377: \n",
      "epoch:  30\n",
      "2021-11-03 15:58:03.087971: train loss : -0.8424\n",
      "2021-11-03 15:58:20.447248: validation loss: -0.8160\n",
      "2021-11-03 15:58:20.450268: Average global foreground Dice: [0.8383]\n",
      "2021-11-03 15:58:20.455798: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 15:58:20.926143: lr: 0.004186\n",
      "2021-11-03 15:58:20.974883: saving checkpoint...\n",
      "2021-11-03 15:58:22.100144: done, saving took 1.15 seconds\n",
      "2021-11-03 15:58:22.644908: This epoch took 293.714640 s\n",
      "\n",
      "2021-11-03 15:58:22.657748: \n",
      "epoch:  31\n",
      "2021-11-03 16:02:56.829725: train loss : -0.8457\n",
      "2021-11-03 16:03:14.219646: validation loss: -0.8233\n",
      "2021-11-03 16:03:14.222994: Average global foreground Dice: [0.8428]\n",
      "2021-11-03 16:03:14.227380: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 16:03:14.704246: lr: 0.003987\n",
      "2021-11-03 16:03:14.764598: saving checkpoint...\n",
      "2021-11-03 16:03:16.031800: done, saving took 1.30 seconds\n",
      "2021-11-03 16:03:16.560499: This epoch took 293.897158 s\n",
      "\n",
      "2021-11-03 16:03:16.576267: \n",
      "epoch:  32\n",
      "2021-11-03 16:07:50.642419: train loss : -0.8432\n",
      "2021-11-03 16:08:08.031167: validation loss: -0.8293\n",
      "2021-11-03 16:08:08.034969: Average global foreground Dice: [0.8449]\n",
      "2021-11-03 16:08:08.044143: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 16:08:08.520164: lr: 0.003787\n",
      "2021-11-03 16:08:08.579042: saving checkpoint...\n",
      "2021-11-03 16:08:09.822725: done, saving took 1.27 seconds\n",
      "2021-11-03 16:08:10.367510: This epoch took 293.785180 s\n",
      "\n",
      "2021-11-03 16:08:10.388191: \n",
      "epoch:  33\n",
      "2021-11-03 16:12:44.409984: train loss : -0.8464\n",
      "2021-11-03 16:13:01.783062: validation loss: -0.8137\n",
      "2021-11-03 16:13:01.786222: Average global foreground Dice: [0.8322]\n",
      "2021-11-03 16:13:01.790695: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 16:13:02.260143: lr: 0.003586\n",
      "2021-11-03 16:13:02.358654: saving checkpoint...\n",
      "2021-11-03 16:13:03.534442: done, saving took 1.24 seconds\n",
      "2021-11-03 16:13:04.126435: This epoch took 293.731934 s\n",
      "\n",
      "2021-11-03 16:13:04.138642: \n",
      "epoch:  34\n",
      "2021-11-03 16:17:38.458714: train loss : -0.8482\n",
      "2021-11-03 16:17:56.009959: validation loss: -0.8087\n",
      "2021-11-03 16:17:56.013043: Average global foreground Dice: [0.8298]\n",
      "2021-11-03 16:17:56.017147: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 16:17:56.498539: lr: 0.003384\n",
      "2021-11-03 16:17:56.529668: This epoch took 292.384062 s\n",
      "\n",
      "2021-11-03 16:17:56.536605: \n",
      "epoch:  35\n",
      "2021-11-03 16:22:30.596185: train loss : -0.8512\n",
      "2021-11-03 16:22:48.181556: validation loss: -0.8097\n",
      "2021-11-03 16:22:48.185524: Average global foreground Dice: [0.8344]\n",
      "2021-11-03 16:22:48.191403: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 16:22:48.683186: lr: 0.00318\n",
      "2021-11-03 16:22:48.787922: saving checkpoint...\n",
      "2021-11-03 16:22:50.042722: done, saving took 1.33 seconds\n",
      "2021-11-03 16:22:50.600701: This epoch took 294.056854 s\n",
      "\n",
      "2021-11-03 16:22:50.619734: \n",
      "epoch:  36\n",
      "2021-11-03 16:27:25.277056: train loss : -0.8503\n",
      "2021-11-03 16:27:42.645001: validation loss: -0.8252\n",
      "2021-11-03 16:27:42.650139: Average global foreground Dice: [0.8442]\n",
      "2021-11-03 16:27:42.657843: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 16:27:43.138298: lr: 0.002975\n",
      "2021-11-03 16:27:43.247717: saving checkpoint...\n",
      "2021-11-03 16:27:44.405260: done, saving took 1.23 seconds\n",
      "2021-11-03 16:27:44.942935: This epoch took 294.314386 s\n",
      "\n",
      "2021-11-03 16:27:44.960033: \n",
      "epoch:  37\n",
      "2021-11-03 16:32:19.800901: train loss : -0.8515\n",
      "2021-11-03 16:32:37.583263: validation loss: -0.8199\n",
      "2021-11-03 16:32:37.586009: Average global foreground Dice: [0.84]\n",
      "2021-11-03 16:32:37.592411: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 16:32:38.090600: lr: 0.002768\n",
      "2021-11-03 16:32:38.187091: saving checkpoint...\n",
      "2021-11-03 16:32:39.460736: done, saving took 1.34 seconds\n",
      "2021-11-03 16:32:40.009556: This epoch took 295.043295 s\n",
      "\n",
      "2021-11-03 16:32:40.032620: \n",
      "epoch:  38\n",
      "2021-11-03 16:37:15.285166: train loss : -0.8524\n",
      "2021-11-03 16:37:32.851504: validation loss: -0.8285\n",
      "2021-11-03 16:37:32.854163: Average global foreground Dice: [0.8447]\n",
      "2021-11-03 16:37:32.859943: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 16:37:33.354421: lr: 0.00256\n",
      "2021-11-03 16:37:33.456956: saving checkpoint...\n",
      "2021-11-03 16:37:34.722791: done, saving took 1.33 seconds\n",
      "2021-11-03 16:37:35.320842: This epoch took 295.282789 s\n",
      "\n",
      "2021-11-03 16:37:35.343961: \n",
      "epoch:  39\n",
      "2021-11-03 16:42:13.764945: train loss : -0.8486\n",
      "2021-11-03 16:42:31.434246: validation loss: -0.8107\n",
      "2021-11-03 16:42:31.438106: Average global foreground Dice: [0.8286]\n",
      "2021-11-03 16:42:31.443252: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 16:42:31.927201: lr: 0.002349\n",
      "2021-11-03 16:42:31.961940: This epoch took 296.611508 s\n",
      "\n",
      "2021-11-03 16:42:31.966823: \n",
      "epoch:  40\n",
      "2021-11-03 16:47:10.621105: train loss : -0.8513\n",
      "2021-11-03 16:47:28.325345: validation loss: -0.8166\n",
      "2021-11-03 16:47:28.328086: Average global foreground Dice: [0.8347]\n",
      "2021-11-03 16:47:28.333667: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 16:47:28.886090: lr: 0.002137\n",
      "2021-11-03 16:47:28.922702: This epoch took 296.950682 s\n",
      "\n",
      "2021-11-03 16:47:28.928643: \n",
      "epoch:  41\n",
      "2021-11-03 16:52:06.916515: train loss : -0.8516\n",
      "2021-11-03 16:52:24.535372: validation loss: -0.8341\n",
      "2021-11-03 16:52:24.538085: Average global foreground Dice: [0.8497]\n",
      "2021-11-03 16:52:24.543797: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 16:52:25.028939: lr: 0.001922\n",
      "2021-11-03 16:52:25.194134: saving checkpoint...\n",
      "2021-11-03 16:52:26.447125: done, saving took 1.33 seconds\n",
      "2021-11-03 16:52:27.008134: This epoch took 298.074907 s\n",
      "\n",
      "2021-11-03 16:52:27.025498: \n",
      "epoch:  42\n",
      "2021-11-03 16:57:05.407407: train loss : -0.8545\n",
      "2021-11-03 16:57:23.103976: validation loss: -0.8152\n",
      "2021-11-03 16:57:23.106586: Average global foreground Dice: [0.8355]\n",
      "2021-11-03 16:57:23.111913: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 16:57:23.601687: lr: 0.001704\n",
      "2021-11-03 16:57:23.636646: This epoch took 296.605067 s\n",
      "\n",
      "2021-11-03 16:57:23.641926: \n",
      "epoch:  43\n",
      "2021-11-03 17:02:01.631704: train loss : -0.8543\n",
      "2021-11-03 17:02:19.247779: validation loss: -0.8302\n",
      "2021-11-03 17:02:19.252702: Average global foreground Dice: [0.8471]\n",
      "2021-11-03 17:02:19.258719: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 17:02:19.740925: lr: 0.001483\n",
      "2021-11-03 17:02:19.850048: saving checkpoint...\n",
      "2021-11-03 17:02:21.104788: done, saving took 1.33 seconds\n",
      "2021-11-03 17:02:21.664813: This epoch took 298.017427 s\n",
      "\n",
      "2021-11-03 17:02:21.683116: \n",
      "epoch:  44\n",
      "2021-11-03 17:06:59.690469: train loss : -0.8577\n",
      "2021-11-03 17:07:17.356037: validation loss: -0.8225\n",
      "2021-11-03 17:07:17.359442: Average global foreground Dice: [0.8416]\n",
      "2021-11-03 17:07:17.364450: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 17:07:17.850617: lr: 0.001259\n",
      "2021-11-03 17:07:17.952535: saving checkpoint...\n",
      "2021-11-03 17:07:19.217532: done, saving took 1.33 seconds\n",
      "2021-11-03 17:07:19.776563: This epoch took 298.088744 s\n",
      "\n",
      "2021-11-03 17:07:19.794723: \n",
      "epoch:  45\n",
      "2021-11-03 17:11:58.059191: train loss : -0.8574\n",
      "2021-11-03 17:12:15.618281: validation loss: -0.8333\n",
      "2021-11-03 17:12:15.620857: Average global foreground Dice: [0.8489]\n",
      "2021-11-03 17:12:15.626073: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 17:12:16.104103: lr: 0.00103\n",
      "2021-11-03 17:12:16.166357: saving checkpoint...\n",
      "2021-11-03 17:12:17.393905: done, saving took 1.26 seconds\n",
      "2021-11-03 17:12:17.944447: This epoch took 298.142970 s\n",
      "\n",
      "2021-11-03 17:12:17.961812: \n",
      "epoch:  46\n",
      "2021-11-03 17:16:56.541749: train loss : -0.8601\n",
      "2021-11-03 17:17:14.111916: validation loss: -0.8245\n",
      "2021-11-03 17:17:14.114926: Average global foreground Dice: [0.8423]\n",
      "2021-11-03 17:17:14.119636: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 17:17:14.600292: lr: 0.000795\n",
      "2021-11-03 17:17:14.666076: saving checkpoint...\n",
      "2021-11-03 17:17:15.846447: done, saving took 1.21 seconds\n",
      "2021-11-03 17:17:16.437956: This epoch took 298.470024 s\n",
      "\n",
      "2021-11-03 17:17:16.451683: \n",
      "epoch:  47\n",
      "2021-11-03 17:21:55.793654: train loss : -0.8586\n",
      "2021-11-03 17:22:13.278006: validation loss: -0.8302\n",
      "2021-11-03 17:22:13.281295: Average global foreground Dice: [0.8492]\n",
      "2021-11-03 17:22:13.285800: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 17:22:13.761341: lr: 0.000552\n",
      "2021-11-03 17:22:13.825963: saving checkpoint...\n",
      "2021-11-03 17:22:15.107774: done, saving took 1.31 seconds\n",
      "2021-11-03 17:22:15.662111: This epoch took 299.205213 s\n",
      "\n",
      "2021-11-03 17:22:15.684912: \n",
      "epoch:  48\n",
      "2021-11-03 17:26:54.429863: train loss : -0.8595\n",
      "2021-11-03 17:27:11.890234: validation loss: -0.8191\n",
      "2021-11-03 17:27:11.892917: Average global foreground Dice: [0.8398]\n",
      "2021-11-03 17:27:11.897203: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 17:27:12.371574: lr: 0.000296\n",
      "2021-11-03 17:27:12.411247: This epoch took 296.717486 s\n",
      "\n",
      "2021-11-03 17:27:12.417735: \n",
      "epoch:  49\n",
      "2021-11-03 17:31:50.331404: train loss : -0.8600\n",
      "2021-11-03 17:32:07.830190: validation loss: -0.8259\n",
      "2021-11-03 17:32:07.833879: Average global foreground Dice: [0.8434]\n",
      "2021-11-03 17:32:07.840028: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 17:32:08.312221: lr: 0.0\n",
      "2021-11-03 17:32:08.353442: saving scheduled checkpoint file...\n",
      "2021-11-03 17:32:08.388641: saving checkpoint...\n",
      "2021-11-03 17:32:09.359965: done, saving took 1.00 seconds\n",
      "2021-11-03 17:32:09.931865: done\n",
      "2021-11-03 17:32:10.007949: saving checkpoint...\n",
      "2021-11-03 17:32:11.251873: done, saving took 1.30 seconds\n",
      "2021-11-03 17:32:11.844826: This epoch took 299.420552 s\n",
      "\n",
      "2021-11-03 17:32:11.891302: saving checkpoint...\n",
      "2021-11-03 17:32:12.838202: done, saving took 0.98 seconds\n",
      "23090566_20141114 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090571_20120517 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131226 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160308 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131025 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090596_20150112 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120619 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090608_20120718 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151210 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121213 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090616_20140331 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090619_20121210 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090629_20120830 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090636_20121018 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150522 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-03 17:35:32.153620: finished prediction\n",
      "2021-11-03 17:35:32.161026: evaluation of raw predictions\n",
      "2021-11-03 17:35:33.860069: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8432808154744704\n",
      "after:  0.8432808154744704\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-03 17:35:44.912824: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-03 17:35:44.928700: The split file contains 5 splits.\n",
      "2021-11-03 17:35:44.933693: Desired fold for training: 3\n",
      "2021-11-03 17:35:44.938962: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-03 17:35:49.260005: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-03 17:36:04.139799: Unable to plot network architecture:\n",
      "2021-11-03 17:36:04.142157: No module named 'hiddenlayer'\n",
      "2021-11-03 17:36:04.147516: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-03 17:36:04.152311: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-03 17:36:04.159921: \n",
      "\n",
      "2021-11-03 17:36:04.164913: \n",
      "epoch:  0\n",
      "2021-11-03 17:41:01.641299: train loss : -0.2128\n",
      "2021-11-03 17:41:19.320410: validation loss: -0.6221\n",
      "2021-11-03 17:41:19.323975: Average global foreground Dice: [0.6703]\n",
      "2021-11-03 17:41:19.329318: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 17:41:19.730784: lr: 0.00982\n",
      "2021-11-03 17:41:19.754985: This epoch took 315.585137 s\n",
      "\n",
      "2021-11-03 17:41:19.760105: \n",
      "epoch:  1\n",
      "2021-11-03 17:45:53.954542: train loss : -0.6069\n",
      "2021-11-03 17:46:11.538074: validation loss: -0.6934\n",
      "2021-11-03 17:46:11.541785: Average global foreground Dice: [0.7386]\n",
      "2021-11-03 17:46:11.548460: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 17:46:12.027273: lr: 0.009639\n",
      "2021-11-03 17:46:12.134249: saving checkpoint...\n",
      "2021-11-03 17:46:13.083064: done, saving took 1.02 seconds\n",
      "2021-11-03 17:46:13.644690: This epoch took 293.879257 s\n",
      "\n",
      "2021-11-03 17:46:13.667275: \n",
      "epoch:  2\n",
      "2021-11-03 17:50:47.927121: train loss : -0.7004\n",
      "2021-11-03 17:51:05.617305: validation loss: -0.7210\n",
      "2021-11-03 17:51:05.620391: Average global foreground Dice: [0.7552]\n",
      "2021-11-03 17:51:05.624749: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 17:51:06.100499: lr: 0.009458\n",
      "2021-11-03 17:51:06.191063: saving checkpoint...\n",
      "2021-11-03 17:51:07.300513: done, saving took 1.17 seconds\n",
      "2021-11-03 17:51:07.936577: This epoch took 294.262233 s\n",
      "\n",
      "2021-11-03 17:51:07.948854: \n",
      "epoch:  3\n",
      "2021-11-03 17:55:43.102312: train loss : -0.7331\n",
      "2021-11-03 17:56:00.752881: validation loss: -0.7753\n",
      "2021-11-03 17:56:00.757346: Average global foreground Dice: [0.8157]\n",
      "2021-11-03 17:56:00.761988: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 17:56:01.244641: lr: 0.009277\n",
      "2021-11-03 17:56:01.344485: saving checkpoint...\n",
      "2021-11-03 17:56:02.638335: done, saving took 1.35 seconds\n",
      "2021-11-03 17:56:03.207777: This epoch took 295.253581 s\n",
      "\n",
      "2021-11-03 17:56:03.224284: \n",
      "epoch:  4\n",
      "2021-11-03 18:00:37.546516: train loss : -0.7505\n",
      "2021-11-03 18:00:55.095808: validation loss: -0.7695\n",
      "2021-11-03 18:00:55.098527: Average global foreground Dice: [0.8098]\n",
      "2021-11-03 18:00:55.103148: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 18:00:55.579156: lr: 0.009095\n",
      "2021-11-03 18:00:55.670533: saving checkpoint...\n",
      "2021-11-03 18:00:56.911891: done, saving took 1.30 seconds\n",
      "2021-11-03 18:00:57.492129: This epoch took 294.262808 s\n",
      "\n",
      "2021-11-03 18:00:57.509876: \n",
      "epoch:  5\n",
      "2021-11-03 18:05:32.437159: train loss : -0.7670\n",
      "2021-11-03 18:05:50.098861: validation loss: -0.7939\n",
      "2021-11-03 18:05:50.101829: Average global foreground Dice: [0.8221]\n",
      "2021-11-03 18:05:50.107423: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 18:05:50.625411: lr: 0.008913\n",
      "2021-11-03 18:05:50.725104: saving checkpoint...\n",
      "2021-11-03 18:05:51.865165: done, saving took 1.21 seconds\n",
      "2021-11-03 18:05:52.416728: This epoch took 294.900038 s\n",
      "\n",
      "2021-11-03 18:05:52.434560: \n",
      "epoch:  6\n",
      "2021-11-03 18:10:27.193649: train loss : -0.7790\n",
      "2021-11-03 18:10:44.838086: validation loss: -0.7915\n",
      "2021-11-03 18:10:44.840442: Average global foreground Dice: [0.8227]\n",
      "2021-11-03 18:10:44.845224: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 18:10:45.327382: lr: 0.008731\n",
      "2021-11-03 18:10:45.419587: saving checkpoint...\n",
      "2021-11-03 18:10:46.538104: done, saving took 1.18 seconds\n",
      "2021-11-03 18:10:47.091979: This epoch took 294.652465 s\n",
      "\n",
      "2021-11-03 18:10:47.108608: \n",
      "epoch:  7\n",
      "2021-11-03 18:15:22.226347: train loss : -0.7882\n",
      "2021-11-03 18:15:39.883941: validation loss: -0.7883\n",
      "2021-11-03 18:15:39.886495: Average global foreground Dice: [0.8209]\n",
      "2021-11-03 18:15:39.891039: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 18:15:40.382592: lr: 0.008548\n",
      "2021-11-03 18:15:40.484070: saving checkpoint...\n",
      "2021-11-03 18:15:41.762642: done, saving took 1.35 seconds\n",
      "2021-11-03 18:15:42.405995: This epoch took 295.291358 s\n",
      "\n",
      "2021-11-03 18:15:42.425618: \n",
      "epoch:  8\n",
      "2021-11-03 18:20:19.439177: train loss : -0.7918\n",
      "2021-11-03 18:20:37.074624: validation loss: -0.7936\n",
      "2021-11-03 18:20:37.077156: Average global foreground Dice: [0.827]\n",
      "2021-11-03 18:20:37.081790: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 18:20:37.572553: lr: 0.008364\n",
      "2021-11-03 18:20:37.671341: saving checkpoint...\n",
      "2021-11-03 18:20:38.934547: done, saving took 1.33 seconds\n",
      "2021-11-03 18:20:39.486991: This epoch took 297.055084 s\n",
      "\n",
      "2021-11-03 18:20:39.507152: \n",
      "epoch:  9\n",
      "2021-11-03 18:25:15.821025: train loss : -0.7998\n",
      "2021-11-03 18:25:33.496685: validation loss: -0.8129\n",
      "2021-11-03 18:25:33.499438: Average global foreground Dice: [0.8397]\n",
      "2021-11-03 18:25:33.504986: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 18:25:33.981709: lr: 0.008181\n",
      "2021-11-03 18:25:34.068779: saving checkpoint...\n",
      "2021-11-03 18:25:35.239361: done, saving took 1.23 seconds\n",
      "2021-11-03 18:25:35.837854: This epoch took 296.324623 s\n",
      "\n",
      "2021-11-03 18:25:35.850686: \n",
      "epoch:  10\n",
      "2021-11-03 18:30:11.401035: train loss : -0.8023\n",
      "2021-11-03 18:30:28.890456: validation loss: -0.8270\n",
      "2021-11-03 18:30:28.893419: Average global foreground Dice: [0.8488]\n",
      "2021-11-03 18:30:28.904034: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 18:30:29.375930: lr: 0.007996\n",
      "2021-11-03 18:30:29.443977: saving checkpoint...\n",
      "2021-11-03 18:30:30.710466: done, saving took 1.30 seconds\n",
      "2021-11-03 18:30:31.338402: This epoch took 295.480847 s\n",
      "\n",
      "2021-11-03 18:30:31.358498: \n",
      "epoch:  11\n",
      "2021-11-03 18:35:06.954603: train loss : -0.8070\n",
      "2021-11-03 18:35:24.360151: validation loss: -0.8081\n",
      "2021-11-03 18:35:24.362797: Average global foreground Dice: [0.8378]\n",
      "2021-11-03 18:35:24.367573: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 18:35:24.837144: lr: 0.007811\n",
      "2021-11-03 18:35:24.907201: saving checkpoint...\n",
      "2021-11-03 18:35:26.418364: done, saving took 1.54 seconds\n",
      "2021-11-03 18:35:26.997627: This epoch took 295.634134 s\n",
      "\n",
      "2021-11-03 18:35:27.021350: \n",
      "epoch:  12\n",
      "2021-11-03 18:40:02.951140: train loss : -0.8128\n",
      "2021-11-03 18:40:20.379798: validation loss: -0.8243\n",
      "2021-11-03 18:40:20.383455: Average global foreground Dice: [0.8455]\n",
      "2021-11-03 18:40:20.389299: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 18:40:20.858806: lr: 0.007626\n",
      "2021-11-03 18:40:20.917159: saving checkpoint...\n",
      "2021-11-03 18:40:22.026740: done, saving took 1.14 seconds\n",
      "2021-11-03 18:40:22.583540: This epoch took 295.553170 s\n",
      "\n",
      "2021-11-03 18:40:22.600325: \n",
      "epoch:  13\n",
      "2021-11-03 18:44:58.733367: train loss : -0.8108\n",
      "2021-11-03 18:45:16.183214: validation loss: -0.8265\n",
      "2021-11-03 18:45:16.185935: Average global foreground Dice: [0.8465]\n",
      "2021-11-03 18:45:16.191126: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 18:45:16.663355: lr: 0.00744\n",
      "2021-11-03 18:45:16.723092: saving checkpoint...\n",
      "2021-11-03 18:45:17.838166: done, saving took 1.14 seconds\n",
      "2021-11-03 18:45:18.416450: This epoch took 295.808906 s\n",
      "\n",
      "2021-11-03 18:45:18.431764: \n",
      "epoch:  14\n",
      "2021-11-03 18:49:54.563478: train loss : -0.8187\n",
      "2021-11-03 18:50:12.017504: validation loss: -0.8203\n",
      "2021-11-03 18:50:12.020086: Average global foreground Dice: [0.8444]\n",
      "2021-11-03 18:50:12.024542: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 18:50:12.504666: lr: 0.007254\n",
      "2021-11-03 18:50:12.564210: saving checkpoint...\n",
      "2021-11-03 18:50:13.868385: done, saving took 1.33 seconds\n",
      "2021-11-03 18:50:14.444094: This epoch took 296.005771 s\n",
      "\n",
      "2021-11-03 18:50:14.461956: \n",
      "epoch:  15\n",
      "2021-11-03 18:54:50.139713: train loss : -0.8160\n",
      "2021-11-03 18:55:07.653881: validation loss: -0.8268\n",
      "2021-11-03 18:55:07.656311: Average global foreground Dice: [0.8498]\n",
      "2021-11-03 18:55:07.661296: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 18:55:08.189131: lr: 0.007067\n",
      "2021-11-03 18:55:08.245332: saving checkpoint...\n",
      "2021-11-03 18:55:09.500704: done, saving took 1.28 seconds\n",
      "2021-11-03 18:55:10.056078: This epoch took 295.588637 s\n",
      "\n",
      "2021-11-03 18:55:10.072540: \n",
      "epoch:  16\n",
      "2021-11-03 18:59:48.206218: train loss : -0.8181\n",
      "2021-11-03 19:00:05.656879: validation loss: -0.8336\n",
      "2021-11-03 19:00:05.659537: Average global foreground Dice: [0.8521]\n",
      "2021-11-03 19:00:05.664609: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 19:00:06.137985: lr: 0.00688\n",
      "2021-11-03 19:00:06.193401: saving checkpoint...\n",
      "2021-11-03 19:00:07.296305: done, saving took 1.13 seconds\n",
      "2021-11-03 19:00:07.877915: This epoch took 297.797633 s\n",
      "\n",
      "2021-11-03 19:00:07.891327: \n",
      "epoch:  17\n",
      "2021-11-03 19:04:45.566317: train loss : -0.8215\n",
      "2021-11-03 19:05:03.037132: validation loss: -0.8269\n",
      "2021-11-03 19:05:03.040479: Average global foreground Dice: [0.8504]\n",
      "2021-11-03 19:05:03.046213: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 19:05:03.519758: lr: 0.006692\n",
      "2021-11-03 19:05:03.576942: saving checkpoint...\n",
      "2021-11-03 19:05:04.834112: done, saving took 1.29 seconds\n",
      "2021-11-03 19:05:05.401760: This epoch took 297.505533 s\n",
      "\n",
      "2021-11-03 19:05:05.424989: \n",
      "epoch:  18\n",
      "2021-11-03 19:09:43.258787: train loss : -0.8247\n",
      "2021-11-03 19:10:00.697184: validation loss: -0.8361\n",
      "2021-11-03 19:10:00.699755: Average global foreground Dice: [0.8559]\n",
      "2021-11-03 19:10:00.705236: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 19:10:01.177844: lr: 0.006504\n",
      "2021-11-03 19:10:01.242707: saving checkpoint...\n",
      "2021-11-03 19:10:02.493183: done, saving took 1.28 seconds\n",
      "2021-11-03 19:10:03.057311: This epoch took 297.622906 s\n",
      "\n",
      "2021-11-03 19:10:03.075055: \n",
      "epoch:  19\n",
      "2021-11-03 19:14:40.904230: train loss : -0.8237\n",
      "2021-11-03 19:14:58.337563: validation loss: -0.8404\n",
      "2021-11-03 19:14:58.341002: Average global foreground Dice: [0.8588]\n",
      "2021-11-03 19:14:58.346885: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 19:14:58.817991: lr: 0.006314\n",
      "2021-11-03 19:14:58.881904: saving checkpoint...\n",
      "2021-11-03 19:14:59.994355: done, saving took 1.14 seconds\n",
      "2021-11-03 19:15:00.551403: This epoch took 297.470085 s\n",
      "\n",
      "2021-11-03 19:15:00.568691: \n",
      "epoch:  20\n",
      "2021-11-03 19:19:38.569136: train loss : -0.8291\n",
      "2021-11-03 19:19:56.129604: validation loss: -0.8309\n",
      "2021-11-03 19:19:56.132381: Average global foreground Dice: [0.853]\n",
      "2021-11-03 19:19:56.137505: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 19:19:56.614179: lr: 0.006125\n",
      "2021-11-03 19:19:56.676435: saving checkpoint...\n",
      "2021-11-03 19:19:57.946270: done, saving took 1.30 seconds\n",
      "2021-11-03 19:19:58.505965: This epoch took 297.931445 s\n",
      "\n",
      "2021-11-03 19:19:58.530366: \n",
      "epoch:  21\n",
      "2021-11-03 19:24:36.429796: train loss : -0.8272\n",
      "2021-11-03 19:24:53.921409: validation loss: -0.8360\n",
      "2021-11-03 19:24:53.924071: Average global foreground Dice: [0.8528]\n",
      "2021-11-03 19:24:53.928681: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 19:24:54.400827: lr: 0.005934\n",
      "2021-11-03 19:24:54.460958: saving checkpoint...\n",
      "2021-11-03 19:24:55.778072: done, saving took 1.35 seconds\n",
      "2021-11-03 19:24:56.335093: This epoch took 297.798000 s\n",
      "\n",
      "2021-11-03 19:24:56.353475: \n",
      "epoch:  22\n",
      "2021-11-03 19:29:34.148716: train loss : -0.8303\n",
      "2021-11-03 19:29:51.613404: validation loss: -0.8399\n",
      "2021-11-03 19:29:51.616406: Average global foreground Dice: [0.8558]\n",
      "2021-11-03 19:29:51.621303: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 19:29:52.087942: lr: 0.005743\n",
      "2021-11-03 19:29:52.149646: saving checkpoint...\n",
      "2021-11-03 19:29:53.388500: done, saving took 1.27 seconds\n",
      "2021-11-03 19:29:53.969172: This epoch took 297.609606 s\n",
      "\n",
      "2021-11-03 19:29:53.986582: \n",
      "epoch:  23\n",
      "2021-11-03 19:34:31.629308: train loss : -0.8281\n",
      "2021-11-03 19:34:49.131083: validation loss: -0.8353\n",
      "2021-11-03 19:34:49.134446: Average global foreground Dice: [0.8541]\n",
      "2021-11-03 19:34:49.139691: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 19:34:49.609891: lr: 0.005551\n",
      "2021-11-03 19:34:49.674551: saving checkpoint...\n",
      "2021-11-03 19:34:50.784226: done, saving took 1.14 seconds\n",
      "2021-11-03 19:34:51.333325: This epoch took 297.340234 s\n",
      "\n",
      "2021-11-03 19:34:51.344923: \n",
      "epoch:  24\n",
      "2021-11-03 19:39:30.052287: train loss : -0.8359\n",
      "2021-11-03 19:39:47.543731: validation loss: -0.8359\n",
      "2021-11-03 19:39:47.547457: Average global foreground Dice: [0.858]\n",
      "2021-11-03 19:39:47.553994: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 19:39:48.029763: lr: 0.005359\n",
      "2021-11-03 19:39:48.092041: saving checkpoint...\n",
      "2021-11-03 19:39:49.358949: done, saving took 1.30 seconds\n",
      "2021-11-03 19:39:49.932001: This epoch took 298.580409 s\n",
      "\n",
      "2021-11-03 19:39:49.950956: \n",
      "epoch:  25\n",
      "2021-11-03 19:44:28.655115: train loss : -0.8304\n",
      "2021-11-03 19:44:46.126629: validation loss: -0.8291\n",
      "2021-11-03 19:44:46.129232: Average global foreground Dice: [0.8457]\n",
      "2021-11-03 19:44:46.134840: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 19:44:46.605586: lr: 0.005166\n",
      "2021-11-03 19:44:46.666352: saving checkpoint...\n",
      "2021-11-03 19:44:47.910578: done, saving took 1.27 seconds\n",
      "2021-11-03 19:44:48.465775: This epoch took 298.510104 s\n",
      "\n",
      "2021-11-03 19:44:48.487738: \n",
      "epoch:  26\n",
      "2021-11-03 19:49:27.473491: train loss : -0.8361\n",
      "2021-11-03 19:49:44.913985: validation loss: -0.8396\n",
      "2021-11-03 19:49:44.916487: Average global foreground Dice: [0.857]\n",
      "2021-11-03 19:49:44.921206: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 19:49:45.392639: lr: 0.004971\n",
      "2021-11-03 19:49:45.452849: saving checkpoint...\n",
      "2021-11-03 19:49:46.689513: done, saving took 1.27 seconds\n",
      "2021-11-03 19:49:47.251140: This epoch took 298.754628 s\n",
      "\n",
      "2021-11-03 19:49:47.270587: \n",
      "epoch:  27\n",
      "2021-11-03 19:54:25.946868: train loss : -0.8393\n",
      "2021-11-03 19:54:43.661053: validation loss: -0.8388\n",
      "2021-11-03 19:54:43.666232: Average global foreground Dice: [0.8565]\n",
      "2021-11-03 19:54:43.672741: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 19:54:44.159731: lr: 0.004776\n",
      "2021-11-03 19:54:44.236774: saving checkpoint...\n",
      "2021-11-03 19:54:45.559138: done, saving took 1.37 seconds\n",
      "2021-11-03 19:54:46.146643: This epoch took 298.870534 s\n",
      "\n",
      "2021-11-03 19:54:46.164685: \n",
      "epoch:  28\n",
      "2021-11-03 19:59:25.191306: train loss : -0.8368\n",
      "2021-11-03 19:59:42.640732: validation loss: -0.8391\n",
      "2021-11-03 19:59:42.643452: Average global foreground Dice: [0.8629]\n",
      "2021-11-03 19:59:42.650235: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 19:59:43.120020: lr: 0.004581\n",
      "2021-11-03 19:59:43.182101: saving checkpoint...\n",
      "2021-11-03 19:59:44.426023: done, saving took 1.27 seconds\n",
      "2021-11-03 19:59:44.970668: This epoch took 298.801512 s\n",
      "\n",
      "2021-11-03 19:59:44.988019: \n",
      "epoch:  29\n",
      "2021-11-03 20:04:24.006944: train loss : -0.8363\n",
      "2021-11-03 20:04:41.569438: validation loss: -0.8340\n",
      "2021-11-03 20:04:41.573219: Average global foreground Dice: [0.8529]\n",
      "2021-11-03 20:04:41.578431: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 20:04:42.046061: lr: 0.004384\n",
      "2021-11-03 20:04:42.114656: saving checkpoint...\n",
      "2021-11-03 20:04:43.228022: done, saving took 1.14 seconds\n",
      "2021-11-03 20:04:43.789021: This epoch took 298.794896 s\n",
      "\n",
      "2021-11-03 20:04:43.799027: \n",
      "epoch:  30\n",
      "2021-11-03 20:09:22.711219: train loss : -0.8377\n",
      "2021-11-03 20:09:40.178568: validation loss: -0.8384\n",
      "2021-11-03 20:09:40.181245: Average global foreground Dice: [0.8617]\n",
      "2021-11-03 20:09:40.186532: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 20:09:40.660372: lr: 0.004186\n",
      "2021-11-03 20:09:40.720742: saving checkpoint...\n",
      "2021-11-03 20:09:41.972089: done, saving took 1.28 seconds\n",
      "2021-11-03 20:09:42.548592: This epoch took 298.744655 s\n",
      "\n",
      "2021-11-03 20:09:42.574475: \n",
      "epoch:  31\n",
      "2021-11-03 20:14:21.341292: train loss : -0.8400\n",
      "2021-11-03 20:14:38.829408: validation loss: -0.8349\n",
      "2021-11-03 20:14:38.832364: Average global foreground Dice: [0.8567]\n",
      "2021-11-03 20:14:38.837602: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 20:14:39.354386: lr: 0.003987\n",
      "2021-11-03 20:14:39.416045: saving checkpoint...\n",
      "2021-11-03 20:14:40.696450: done, saving took 1.31 seconds\n",
      "2021-11-03 20:14:41.256042: This epoch took 298.673579 s\n",
      "\n",
      "2021-11-03 20:14:41.274697: \n",
      "epoch:  32\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-03 20:19:20.747378: train loss : -0.8423\n",
      "2021-11-03 20:19:38.211550: validation loss: -0.8409\n",
      "2021-11-03 20:19:38.214175: Average global foreground Dice: [0.8598]\n",
      "2021-11-03 20:19:38.219546: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 20:19:38.691059: lr: 0.003787\n",
      "2021-11-03 20:19:38.737589: saving checkpoint...\n",
      "2021-11-03 20:19:39.860445: done, saving took 1.15 seconds\n",
      "2021-11-03 20:19:40.405347: This epoch took 299.123530 s\n",
      "\n",
      "2021-11-03 20:19:40.412436: \n",
      "epoch:  33\n",
      "2021-11-03 20:24:19.993206: train loss : -0.8424\n",
      "2021-11-03 20:24:37.631819: validation loss: -0.8503\n",
      "2021-11-03 20:24:37.635306: Average global foreground Dice: [0.8665]\n",
      "2021-11-03 20:24:37.640076: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 20:24:38.137143: lr: 0.003586\n",
      "2021-11-03 20:24:38.223084: saving checkpoint...\n",
      "2021-11-03 20:24:39.573659: done, saving took 1.40 seconds\n",
      "2021-11-03 20:24:40.150738: This epoch took 299.731745 s\n",
      "\n",
      "2021-11-03 20:24:40.168666: \n",
      "epoch:  34\n",
      "2021-11-03 20:29:18.241007: train loss : -0.8464\n",
      "2021-11-03 20:29:35.723761: validation loss: -0.8307\n",
      "2021-11-03 20:29:35.727454: Average global foreground Dice: [0.8477]\n",
      "2021-11-03 20:29:35.733311: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 20:29:36.216173: lr: 0.003384\n",
      "2021-11-03 20:29:36.251122: This epoch took 296.075504 s\n",
      "\n",
      "2021-11-03 20:29:36.257416: \n",
      "epoch:  35\n",
      "2021-11-03 20:34:14.454451: train loss : -0.8452\n",
      "2021-11-03 20:34:31.896778: validation loss: -0.8404\n",
      "2021-11-03 20:34:31.900148: Average global foreground Dice: [0.8575]\n",
      "2021-11-03 20:34:31.905809: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 20:34:32.381866: lr: 0.00318\n",
      "2021-11-03 20:34:32.439023: saving checkpoint...\n",
      "2021-11-03 20:34:33.690732: done, saving took 1.28 seconds\n",
      "2021-11-03 20:34:34.250420: This epoch took 297.986910 s\n",
      "\n",
      "2021-11-03 20:34:34.270655: \n",
      "epoch:  36\n",
      "2021-11-03 20:39:12.174639: train loss : -0.8449\n",
      "2021-11-03 20:39:29.689442: validation loss: -0.8462\n",
      "2021-11-03 20:39:29.692228: Average global foreground Dice: [0.8628]\n",
      "2021-11-03 20:39:29.697746: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 20:39:30.172206: lr: 0.002975\n",
      "2021-11-03 20:39:30.234680: saving checkpoint...\n",
      "2021-11-03 20:39:31.486076: done, saving took 1.28 seconds\n",
      "2021-11-03 20:39:32.027799: This epoch took 297.750790 s\n",
      "\n",
      "2021-11-03 20:39:32.046353: \n",
      "epoch:  37\n",
      "2021-11-03 20:44:10.276465: train loss : -0.8490\n",
      "2021-11-03 20:44:27.916116: validation loss: -0.8398\n",
      "2021-11-03 20:44:27.918320: Average global foreground Dice: [0.8563]\n",
      "2021-11-03 20:44:27.922841: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 20:44:28.404926: lr: 0.002768\n",
      "2021-11-03 20:44:28.463526: saving checkpoint...\n",
      "2021-11-03 20:44:29.762623: done, saving took 1.33 seconds\n",
      "2021-11-03 20:44:30.329965: This epoch took 298.277410 s\n",
      "\n",
      "2021-11-03 20:44:30.359554: \n",
      "epoch:  38\n",
      "2021-11-03 20:49:08.025594: train loss : -0.8445\n",
      "2021-11-03 20:49:25.506559: validation loss: -0.8530\n",
      "2021-11-03 20:49:25.509629: Average global foreground Dice: [0.8663]\n",
      "2021-11-03 20:49:25.514497: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 20:49:25.993896: lr: 0.00256\n",
      "2021-11-03 20:49:26.083329: saving checkpoint...\n",
      "2021-11-03 20:49:27.214226: done, saving took 1.19 seconds\n",
      "2021-11-03 20:49:27.845340: This epoch took 297.477376 s\n",
      "\n",
      "2021-11-03 20:49:27.865420: \n",
      "epoch:  39\n",
      "2021-11-03 20:54:05.416530: train loss : -0.8443\n",
      "2021-11-03 20:54:23.069168: validation loss: -0.8457\n",
      "2021-11-03 20:54:23.072068: Average global foreground Dice: [0.8612]\n",
      "2021-11-03 20:54:23.078198: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 20:54:23.578592: lr: 0.002349\n",
      "2021-11-03 20:54:23.668107: saving checkpoint...\n",
      "2021-11-03 20:54:24.997664: done, saving took 1.39 seconds\n",
      "2021-11-03 20:54:25.572788: This epoch took 297.701268 s\n",
      "\n",
      "2021-11-03 20:54:25.592920: \n",
      "epoch:  40\n",
      "2021-11-03 20:59:03.421986: train loss : -0.8450\n",
      "2021-11-03 20:59:20.922111: validation loss: -0.8490\n",
      "2021-11-03 20:59:20.924323: Average global foreground Dice: [0.8607]\n",
      "2021-11-03 20:59:20.928528: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 20:59:21.405740: lr: 0.002137\n",
      "2021-11-03 20:59:21.474842: saving checkpoint...\n",
      "2021-11-03 20:59:22.714567: done, saving took 1.27 seconds\n",
      "2021-11-03 20:59:23.275211: This epoch took 297.676781 s\n",
      "\n",
      "2021-11-03 20:59:23.297117: \n",
      "epoch:  41\n",
      "2021-11-03 21:04:01.199604: train loss : -0.8473\n",
      "2021-11-03 21:04:18.659876: validation loss: -0.8465\n",
      "2021-11-03 21:04:18.662555: Average global foreground Dice: [0.8611]\n",
      "2021-11-03 21:04:18.669141: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 21:04:19.139906: lr: 0.001922\n",
      "2021-11-03 21:04:19.205401: saving checkpoint...\n",
      "2021-11-03 21:04:20.464549: done, saving took 1.29 seconds\n",
      "2021-11-03 21:04:21.045176: This epoch took 297.741616 s\n",
      "\n",
      "2021-11-03 21:04:21.064811: \n",
      "epoch:  42\n",
      "2021-11-03 21:08:59.799247: train loss : -0.8496\n",
      "2021-11-03 21:09:17.241960: validation loss: -0.8565\n",
      "2021-11-03 21:09:17.245278: Average global foreground Dice: [0.8671]\n",
      "2021-11-03 21:09:17.250741: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 21:09:17.763548: lr: 0.001704\n",
      "2021-11-03 21:09:17.826322: saving checkpoint...\n",
      "2021-11-03 21:09:18.955964: done, saving took 1.16 seconds\n",
      "2021-11-03 21:09:19.541095: This epoch took 298.468721 s\n",
      "\n",
      "2021-11-03 21:09:19.554850: \n",
      "epoch:  43\n",
      "2021-11-03 21:13:57.659038: train loss : -0.8488\n",
      "2021-11-03 21:14:15.153400: validation loss: -0.8517\n",
      "2021-11-03 21:14:15.156412: Average global foreground Dice: [0.8653]\n",
      "2021-11-03 21:14:15.161308: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 21:14:15.635155: lr: 0.001483\n",
      "2021-11-03 21:14:15.702745: saving checkpoint...\n",
      "2021-11-03 21:14:16.971362: done, saving took 1.30 seconds\n",
      "2021-11-03 21:14:17.533345: This epoch took 297.972934 s\n",
      "\n",
      "2021-11-03 21:14:17.550675: \n",
      "epoch:  44\n",
      "2021-11-03 21:18:55.574883: train loss : -0.8513\n",
      "2021-11-03 21:19:13.059351: validation loss: -0.8528\n",
      "2021-11-03 21:19:13.061962: Average global foreground Dice: [0.8624]\n",
      "2021-11-03 21:19:13.067346: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 21:19:13.538602: lr: 0.001259\n",
      "2021-11-03 21:19:13.596622: saving checkpoint...\n",
      "2021-11-03 21:19:14.840053: done, saving took 1.27 seconds\n",
      "2021-11-03 21:19:15.395707: This epoch took 297.839089 s\n",
      "\n",
      "2021-11-03 21:19:15.416920: \n",
      "epoch:  45\n",
      "2021-11-03 21:23:53.836190: train loss : -0.8520\n",
      "2021-11-03 21:24:11.321100: validation loss: -0.8520\n",
      "2021-11-03 21:24:11.324821: Average global foreground Dice: [0.8676]\n",
      "2021-11-03 21:24:11.331504: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 21:24:11.800572: lr: 0.00103\n",
      "2021-11-03 21:24:11.872719: saving checkpoint...\n",
      "2021-11-03 21:24:13.057841: done, saving took 1.21 seconds\n",
      "2021-11-03 21:24:13.642190: This epoch took 298.220694 s\n",
      "\n",
      "2021-11-03 21:24:13.667683: \n",
      "epoch:  46\n",
      "2021-11-03 21:28:51.894881: train loss : -0.8506\n",
      "2021-11-03 21:29:09.455545: validation loss: -0.8458\n",
      "2021-11-03 21:29:09.458332: Average global foreground Dice: [0.8621]\n",
      "2021-11-03 21:29:09.464760: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 21:29:09.945493: lr: 0.000795\n",
      "2021-11-03 21:29:10.008038: saving checkpoint...\n",
      "2021-11-03 21:29:11.273165: done, saving took 1.29 seconds\n",
      "2021-11-03 21:29:11.887216: This epoch took 298.211749 s\n",
      "\n",
      "2021-11-03 21:29:11.904926: \n",
      "epoch:  47\n",
      "2021-11-03 21:33:48.802622: train loss : -0.8518\n",
      "2021-11-03 21:34:06.288489: validation loss: -0.8523\n",
      "2021-11-03 21:34:06.291118: Average global foreground Dice: [0.8645]\n",
      "2021-11-03 21:34:06.295679: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 21:34:06.771890: lr: 0.000552\n",
      "2021-11-03 21:34:06.829337: saving checkpoint...\n",
      "2021-11-03 21:34:08.086009: done, saving took 1.29 seconds\n",
      "2021-11-03 21:34:08.649113: This epoch took 296.737729 s\n",
      "\n",
      "2021-11-03 21:34:08.667244: \n",
      "epoch:  48\n",
      "2021-11-03 21:38:44.946830: train loss : -0.8545\n",
      "2021-11-03 21:39:02.408175: validation loss: -0.8577\n",
      "2021-11-03 21:39:02.411155: Average global foreground Dice: [0.8685]\n",
      "2021-11-03 21:39:02.416474: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 21:39:02.956366: lr: 0.000296\n",
      "2021-11-03 21:39:03.018768: saving checkpoint...\n",
      "2021-11-03 21:39:04.289824: done, saving took 1.30 seconds\n",
      "2021-11-03 21:39:04.847050: This epoch took 296.174268 s\n",
      "\n",
      "2021-11-03 21:39:04.866899: \n",
      "epoch:  49\n",
      "2021-11-03 21:43:40.944091: train loss : -0.8588\n",
      "2021-11-03 21:43:58.490977: validation loss: -0.8501\n",
      "2021-11-03 21:43:58.494539: Average global foreground Dice: [0.8635]\n",
      "2021-11-03 21:43:58.500859: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 21:43:58.978276: lr: 0.0\n",
      "2021-11-03 21:43:59.014681: saving scheduled checkpoint file...\n",
      "2021-11-03 21:43:59.053206: saving checkpoint...\n",
      "2021-11-03 21:44:00.012658: done, saving took 0.99 seconds\n",
      "2021-11-03 21:44:00.603704: done\n",
      "2021-11-03 21:44:00.653621: saving checkpoint...\n",
      "2021-11-03 21:44:01.920588: done, saving took 1.30 seconds\n",
      "2021-11-03 21:44:02.508240: This epoch took 297.635520 s\n",
      "\n",
      "2021-11-03 21:44:02.553137: saving checkpoint...\n",
      "2021-11-03 21:44:03.506868: done, saving took 0.98 seconds\n",
      "23090557_20130717 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090560_20160114 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090562_20140206 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141215 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130626 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140124 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121015 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090597_20130227 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130208 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090621_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150105 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130807 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090637_20140401 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131126 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090644_20131216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-03 21:47:23.778946: finished prediction\n",
      "2021-11-03 21:47:23.784235: evaluation of raw predictions\n",
      "2021-11-03 21:47:25.452584: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8612578307529082\n",
      "after:  0.8644599779790278\n",
      "Removing all but the largest foreground region improved results!\n",
      "for_which_classes [1]\n",
      "min_valid_object_sizes None\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[[1]]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-03 21:47:37.092459: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-03 21:47:37.111402: The split file contains 5 splits.\n",
      "2021-11-03 21:47:37.115601: Desired fold for training: 4\n",
      "2021-11-03 21:47:37.120258: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-03 21:47:41.393210: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-03 21:47:56.738362: Unable to plot network architecture:\n",
      "2021-11-03 21:47:56.741918: No module named 'hiddenlayer'\n",
      "2021-11-03 21:47:56.749076: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-03 21:47:56.757031: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-03 21:47:56.844754: \n",
      "\n",
      "2021-11-03 21:47:56.849913: \n",
      "epoch:  0\n",
      "2021-11-03 21:52:55.050121: train loss : -0.2343\n",
      "2021-11-03 21:53:12.599667: validation loss: -0.5824\n",
      "2021-11-03 21:53:12.603010: Average global foreground Dice: [0.6412]\n",
      "2021-11-03 21:53:12.608333: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 21:53:13.011847: lr: 0.00982\n",
      "2021-11-03 21:53:13.037042: This epoch took 316.181209 s\n",
      "\n",
      "2021-11-03 21:53:13.041541: \n",
      "epoch:  1\n",
      "2021-11-03 21:57:46.103770: train loss : -0.6243\n",
      "2021-11-03 21:58:03.715086: validation loss: -0.6801\n",
      "2021-11-03 21:58:03.717843: Average global foreground Dice: [0.7324]\n",
      "2021-11-03 21:58:03.723480: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 21:58:04.197460: lr: 0.009639\n",
      "2021-11-03 21:58:04.307315: saving checkpoint...\n",
      "2021-11-03 21:58:05.260386: done, saving took 1.03 seconds\n",
      "2021-11-03 21:58:05.823947: This epoch took 292.777647 s\n",
      "\n",
      "2021-11-03 21:58:05.843775: \n",
      "epoch:  2\n",
      "2021-11-03 22:02:40.769123: train loss : -0.6831\n",
      "2021-11-03 22:02:58.424118: validation loss: -0.7247\n",
      "2021-11-03 22:02:58.426955: Average global foreground Dice: [0.7762]\n",
      "2021-11-03 22:02:58.432009: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 22:02:58.934602: lr: 0.009458\n",
      "2021-11-03 22:02:59.043364: saving checkpoint...\n",
      "2021-11-03 22:03:00.297605: done, saving took 1.33 seconds\n",
      "2021-11-03 22:03:00.875948: This epoch took 295.027398 s\n",
      "\n",
      "2021-11-03 22:03:00.895859: \n",
      "epoch:  3\n",
      "2021-11-03 22:07:35.478583: train loss : -0.7256\n",
      "2021-11-03 22:07:53.047313: validation loss: -0.7581\n",
      "2021-11-03 22:07:53.049703: Average global foreground Dice: [0.795]\n",
      "2021-11-03 22:07:53.054321: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 22:07:53.523259: lr: 0.009277\n",
      "2021-11-03 22:07:53.623328: saving checkpoint...\n",
      "2021-11-03 22:07:54.933497: done, saving took 1.38 seconds\n",
      "2021-11-03 22:07:55.482122: This epoch took 294.581017 s\n",
      "\n",
      "2021-11-03 22:07:55.502632: \n",
      "epoch:  4\n",
      "2021-11-03 22:12:30.298962: train loss : -0.7507\n",
      "2021-11-03 22:12:47.851796: validation loss: -0.7782\n",
      "2021-11-03 22:12:47.854688: Average global foreground Dice: [0.8232]\n",
      "2021-11-03 22:12:47.859166: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 22:12:48.335452: lr: 0.009095\n",
      "2021-11-03 22:12:48.451868: saving checkpoint...\n",
      "2021-11-03 22:12:49.738037: done, saving took 1.36 seconds\n",
      "2021-11-03 22:12:50.290657: This epoch took 294.782006 s\n",
      "\n",
      "2021-11-03 22:12:50.308277: \n",
      "epoch:  5\n",
      "2021-11-03 22:17:25.522057: train loss : -0.7610\n",
      "2021-11-03 22:17:43.215076: validation loss: -0.7740\n",
      "2021-11-03 22:17:43.218003: Average global foreground Dice: [0.8099]\n",
      "2021-11-03 22:17:43.223829: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 22:17:43.718882: lr: 0.008913\n",
      "2021-11-03 22:17:43.835347: saving checkpoint...\n",
      "2021-11-03 22:17:45.098460: done, saving took 1.34 seconds\n",
      "2021-11-03 22:17:45.706232: This epoch took 295.393321 s\n",
      "\n",
      "2021-11-03 22:17:45.732637: \n",
      "epoch:  6\n",
      "2021-11-03 22:22:20.739582: train loss : -0.7773\n",
      "2021-11-03 22:22:38.459081: validation loss: -0.7935\n",
      "2021-11-03 22:22:38.461819: Average global foreground Dice: [0.8265]\n",
      "2021-11-03 22:22:38.465880: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 22:22:38.956908: lr: 0.008731\n",
      "2021-11-03 22:22:39.067586: saving checkpoint...\n",
      "2021-11-03 22:22:40.318699: done, saving took 1.33 seconds\n",
      "2021-11-03 22:22:40.910343: This epoch took 295.167035 s\n",
      "\n",
      "2021-11-03 22:22:40.932290: \n",
      "epoch:  7\n",
      "2021-11-03 22:27:16.249558: train loss : -0.7819\n",
      "2021-11-03 22:27:34.085358: validation loss: -0.8026\n",
      "2021-11-03 22:27:34.087964: Average global foreground Dice: [0.8285]\n",
      "2021-11-03 22:27:34.092381: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 22:27:34.583163: lr: 0.008548\n",
      "2021-11-03 22:27:34.691342: saving checkpoint...\n",
      "2021-11-03 22:27:35.811601: done, saving took 1.20 seconds\n",
      "2021-11-03 22:27:36.377983: This epoch took 295.439924 s\n",
      "\n",
      "2021-11-03 22:27:36.399190: \n",
      "epoch:  8\n",
      "2021-11-03 22:32:12.948786: train loss : -0.7893\n",
      "2021-11-03 22:32:30.589455: validation loss: -0.7997\n",
      "2021-11-03 22:32:30.592011: Average global foreground Dice: [0.8325]\n",
      "2021-11-03 22:32:30.597085: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 22:32:31.068223: lr: 0.008364\n",
      "2021-11-03 22:32:31.183909: saving checkpoint...\n",
      "2021-11-03 22:32:32.454219: done, saving took 1.35 seconds\n",
      "2021-11-03 22:32:33.040252: This epoch took 296.634868 s\n",
      "\n",
      "2021-11-03 22:32:33.058754: \n",
      "epoch:  9\n",
      "2021-11-03 22:37:09.239752: train loss : -0.7977\n",
      "2021-11-03 22:37:26.881941: validation loss: -0.8062\n",
      "2021-11-03 22:37:26.886373: Average global foreground Dice: [0.8301]\n",
      "2021-11-03 22:37:26.891480: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 22:37:27.374493: lr: 0.008181\n",
      "2021-11-03 22:37:27.484896: saving checkpoint...\n",
      "2021-11-03 22:37:28.798968: done, saving took 1.39 seconds\n",
      "2021-11-03 22:37:29.355475: This epoch took 296.290841 s\n",
      "\n",
      "2021-11-03 22:37:29.374238: \n",
      "epoch:  10\n",
      "2021-11-03 22:42:05.573933: train loss : -0.7996\n",
      "2021-11-03 22:42:23.041402: validation loss: -0.8190\n",
      "2021-11-03 22:42:23.044096: Average global foreground Dice: [0.841]\n",
      "2021-11-03 22:42:23.049013: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 22:42:23.518265: lr: 0.007996\n",
      "2021-11-03 22:42:23.572174: saving checkpoint...\n",
      "2021-11-03 22:42:24.677969: done, saving took 1.13 seconds\n",
      "2021-11-03 22:42:25.240230: This epoch took 295.860090 s\n",
      "\n",
      "2021-11-03 22:42:25.256166: \n",
      "epoch:  11\n",
      "2021-11-03 22:47:01.462519: train loss : -0.8077\n",
      "2021-11-03 22:47:18.969688: validation loss: -0.8198\n",
      "2021-11-03 22:47:18.972396: Average global foreground Dice: [0.845]\n",
      "2021-11-03 22:47:18.976480: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 22:47:19.441650: lr: 0.007811\n",
      "2021-11-03 22:47:19.506848: saving checkpoint...\n",
      "2021-11-03 22:47:20.762173: done, saving took 1.28 seconds\n",
      "2021-11-03 22:47:21.354212: This epoch took 296.092891 s\n",
      "\n",
      "2021-11-03 22:47:21.373874: \n",
      "epoch:  12\n",
      "2021-11-03 22:51:56.717574: train loss : -0.8081\n",
      "2021-11-03 22:52:14.150671: validation loss: -0.8143\n",
      "2021-11-03 22:52:14.153323: Average global foreground Dice: [0.8356]\n",
      "2021-11-03 22:52:14.158845: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 22:52:14.630940: lr: 0.007626\n",
      "2021-11-03 22:52:14.693825: saving checkpoint...\n",
      "2021-11-03 22:52:15.938302: done, saving took 1.27 seconds\n",
      "2021-11-03 22:52:16.478490: This epoch took 295.098450 s\n",
      "\n",
      "2021-11-03 22:52:16.495595: \n",
      "epoch:  13\n",
      "2021-11-03 22:56:51.725955: train loss : -0.8151\n",
      "2021-11-03 22:57:09.225406: validation loss: -0.8217\n",
      "2021-11-03 22:57:09.228010: Average global foreground Dice: [0.8451]\n",
      "2021-11-03 22:57:09.233455: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 22:57:09.702285: lr: 0.00744\n",
      "2021-11-03 22:57:09.760076: saving checkpoint...\n",
      "2021-11-03 22:57:10.996448: done, saving took 1.27 seconds\n",
      "2021-11-03 22:57:11.517983: This epoch took 295.015872 s\n",
      "\n",
      "2021-11-03 22:57:11.538742: \n",
      "epoch:  14\n",
      "2021-11-03 23:01:47.634699: train loss : -0.8161\n",
      "2021-11-03 23:02:05.193208: validation loss: -0.8193\n",
      "2021-11-03 23:02:05.195750: Average global foreground Dice: [0.8406]\n",
      "2021-11-03 23:02:05.200986: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 23:02:05.674235: lr: 0.007254\n",
      "2021-11-03 23:02:05.763644: saving checkpoint...\n",
      "2021-11-03 23:02:07.018020: done, saving took 1.31 seconds\n",
      "2021-11-03 23:02:07.600672: This epoch took 296.057176 s\n",
      "\n",
      "2021-11-03 23:02:07.616947: \n",
      "epoch:  15\n",
      "2021-11-03 23:06:43.338745: train loss : -0.8199\n",
      "2021-11-03 23:07:01.006603: validation loss: -0.8181\n",
      "2021-11-03 23:07:01.008980: Average global foreground Dice: [0.8425]\n",
      "2021-11-03 23:07:01.014269: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 23:07:01.501815: lr: 0.007067\n",
      "2021-11-03 23:07:01.585970: saving checkpoint...\n",
      "2021-11-03 23:07:02.755504: done, saving took 1.22 seconds\n",
      "2021-11-03 23:07:03.295368: This epoch took 295.673065 s\n",
      "\n",
      "2021-11-03 23:07:03.312021: \n",
      "epoch:  16\n",
      "2021-11-03 23:11:41.547445: train loss : -0.8193\n",
      "2021-11-03 23:11:59.046644: validation loss: -0.8355\n",
      "2021-11-03 23:11:59.049943: Average global foreground Dice: [0.8522]\n",
      "2021-11-03 23:11:59.057397: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 23:11:59.524870: lr: 0.00688\n",
      "2021-11-03 23:11:59.594105: saving checkpoint...\n",
      "2021-11-03 23:12:00.826546: done, saving took 1.26 seconds\n",
      "2021-11-03 23:12:01.427230: This epoch took 298.109793 s\n",
      "\n",
      "2021-11-03 23:12:01.443261: \n",
      "epoch:  17\n",
      "2021-11-03 23:16:38.853580: train loss : -0.8211\n",
      "2021-11-03 23:16:56.453872: validation loss: -0.8269\n",
      "2021-11-03 23:16:56.456855: Average global foreground Dice: [0.8484]\n",
      "2021-11-03 23:16:56.463216: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 23:16:56.972942: lr: 0.006692\n",
      "2021-11-03 23:16:57.033721: saving checkpoint...\n",
      "2021-11-03 23:16:58.266025: done, saving took 1.26 seconds\n",
      "2021-11-03 23:16:58.797576: This epoch took 297.348161 s\n",
      "\n",
      "2021-11-03 23:16:58.816590: \n",
      "epoch:  18\n",
      "2021-11-03 23:21:36.453408: train loss : -0.8241\n",
      "2021-11-03 23:21:53.888936: validation loss: -0.8300\n",
      "2021-11-03 23:21:53.893190: Average global foreground Dice: [0.8527]\n",
      "2021-11-03 23:21:53.899668: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 23:21:54.360524: lr: 0.006504\n",
      "2021-11-03 23:21:54.424128: saving checkpoint...\n",
      "2021-11-03 23:21:55.534967: done, saving took 1.14 seconds\n",
      "2021-11-03 23:21:56.079534: This epoch took 297.256473 s\n",
      "\n",
      "2021-11-03 23:21:56.091904: \n",
      "epoch:  19\n",
      "2021-11-03 23:26:33.766689: train loss : -0.8229\n",
      "2021-11-03 23:26:51.316127: validation loss: -0.8159\n",
      "2021-11-03 23:26:51.318642: Average global foreground Dice: [0.8395]\n",
      "2021-11-03 23:26:51.324005: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 23:26:51.790481: lr: 0.006314\n",
      "2021-11-03 23:26:51.865147: saving checkpoint...\n",
      "2021-11-03 23:26:53.171551: done, saving took 1.34 seconds\n",
      "2021-11-03 23:26:53.746063: This epoch took 297.648360 s\n",
      "\n",
      "2021-11-03 23:26:53.764339: \n",
      "epoch:  20\n",
      "2021-11-03 23:31:31.702612: train loss : -0.8276\n",
      "2021-11-03 23:31:49.223579: validation loss: -0.8302\n",
      "2021-11-03 23:31:49.226080: Average global foreground Dice: [0.8475]\n",
      "2021-11-03 23:31:49.231006: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 23:31:49.694715: lr: 0.006125\n",
      "2021-11-03 23:31:49.754185: saving checkpoint...\n",
      "2021-11-03 23:31:50.993440: done, saving took 1.27 seconds\n",
      "2021-11-03 23:31:51.562772: This epoch took 297.792767 s\n",
      "\n",
      "2021-11-03 23:31:51.582397: \n",
      "epoch:  21\n",
      "2021-11-03 23:36:29.737351: train loss : -0.8277\n",
      "2021-11-03 23:36:47.379246: validation loss: -0.8314\n",
      "2021-11-03 23:36:47.381894: Average global foreground Dice: [0.8532]\n",
      "2021-11-03 23:36:47.386465: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 23:36:47.847848: lr: 0.005934\n",
      "2021-11-03 23:36:47.907710: saving checkpoint...\n",
      "2021-11-03 23:36:49.032671: done, saving took 1.17 seconds\n",
      "2021-11-03 23:36:49.609429: This epoch took 298.021333 s\n",
      "\n",
      "2021-11-03 23:36:49.616501: \n",
      "epoch:  22\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-03 23:41:26.449834: train loss : -0.8258\n",
      "2021-11-03 23:41:44.350838: validation loss: -0.8160\n",
      "2021-11-03 23:41:44.353425: Average global foreground Dice: [0.8296]\n",
      "2021-11-03 23:41:44.357527: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 23:41:44.830282: lr: 0.005743\n",
      "2021-11-03 23:41:44.901082: saving checkpoint...\n",
      "2021-11-03 23:41:46.214147: done, saving took 1.36 seconds\n",
      "2021-11-03 23:41:46.743754: This epoch took 297.121459 s\n",
      "\n",
      "2021-11-03 23:41:46.762855: \n",
      "epoch:  23\n",
      "2021-11-03 23:46:22.865053: train loss : -0.8292\n",
      "2021-11-03 23:46:40.361649: validation loss: -0.8277\n",
      "2021-11-03 23:46:40.364840: Average global foreground Dice: [0.8459]\n",
      "2021-11-03 23:46:40.369796: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 23:46:40.828221: lr: 0.005551\n",
      "2021-11-03 23:46:40.884370: saving checkpoint...\n",
      "2021-11-03 23:46:42.095297: done, saving took 1.24 seconds\n",
      "2021-11-03 23:46:42.671808: This epoch took 295.903640 s\n",
      "\n",
      "2021-11-03 23:46:42.689705: \n",
      "epoch:  24\n",
      "2021-11-03 23:51:19.215407: train loss : -0.8300\n",
      "2021-11-03 23:51:36.680743: validation loss: -0.8327\n",
      "2021-11-03 23:51:36.683425: Average global foreground Dice: [0.8454]\n",
      "2021-11-03 23:51:36.689988: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 23:51:37.155402: lr: 0.005359\n",
      "2021-11-03 23:51:37.215366: saving checkpoint...\n",
      "2021-11-03 23:51:38.488010: done, saving took 1.30 seconds\n",
      "2021-11-03 23:51:39.075582: This epoch took 296.379051 s\n",
      "\n",
      "2021-11-03 23:51:39.091944: \n",
      "epoch:  25\n",
      "2021-11-03 23:56:15.029482: train loss : -0.8266\n",
      "2021-11-03 23:56:32.512543: validation loss: -0.8355\n",
      "2021-11-03 23:56:32.516634: Average global foreground Dice: [0.8528]\n",
      "2021-11-03 23:56:32.523022: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-03 23:56:32.987945: lr: 0.005166\n",
      "2021-11-03 23:56:33.047647: saving checkpoint...\n",
      "2021-11-03 23:56:34.294630: done, saving took 1.28 seconds\n",
      "2021-11-03 23:56:34.847319: This epoch took 295.748942 s\n",
      "\n",
      "2021-11-03 23:56:34.868057: \n",
      "epoch:  26\n",
      "2021-11-04 00:01:10.743197: train loss : -0.8274\n",
      "2021-11-04 00:01:28.245553: validation loss: -0.8300\n",
      "2021-11-04 00:01:28.248146: Average global foreground Dice: [0.8485]\n",
      "2021-11-04 00:01:28.253517: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 00:01:28.713913: lr: 0.004971\n",
      "2021-11-04 00:01:28.765908: saving checkpoint...\n",
      "2021-11-04 00:01:29.895977: done, saving took 1.16 seconds\n",
      "2021-11-04 00:01:30.452042: This epoch took 295.578303 s\n",
      "\n",
      "2021-11-04 00:01:30.458649: \n",
      "epoch:  27\n",
      "2021-11-04 00:06:06.748161: train loss : -0.8403\n",
      "2021-11-04 00:06:24.313524: validation loss: -0.8371\n",
      "2021-11-04 00:06:24.317127: Average global foreground Dice: [0.8524]\n",
      "2021-11-04 00:06:24.322135: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 00:06:24.788821: lr: 0.004776\n",
      "2021-11-04 00:06:24.845516: saving checkpoint...\n",
      "2021-11-04 00:06:26.109118: done, saving took 1.29 seconds\n",
      "2021-11-04 00:06:26.703126: This epoch took 296.239317 s\n",
      "\n",
      "2021-11-04 00:06:26.726484: \n",
      "epoch:  28\n",
      "2021-11-04 00:11:03.330208: train loss : -0.8361\n",
      "2021-11-04 00:11:21.037396: validation loss: -0.8271\n",
      "2021-11-04 00:11:21.039670: Average global foreground Dice: [0.8465]\n",
      "2021-11-04 00:11:21.044554: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 00:11:21.515200: lr: 0.004581\n",
      "2021-11-04 00:11:21.592424: saving checkpoint...\n",
      "2021-11-04 00:11:22.850022: done, saving took 1.30 seconds\n",
      "2021-11-04 00:11:23.430757: This epoch took 296.697769 s\n",
      "\n",
      "2021-11-04 00:11:23.448607: \n",
      "epoch:  29\n",
      "2021-11-04 00:16:00.006313: train loss : -0.8370\n",
      "2021-11-04 00:16:17.664081: validation loss: -0.8299\n",
      "2021-11-04 00:16:17.666902: Average global foreground Dice: [0.8488]\n",
      "2021-11-04 00:16:17.671307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 00:16:18.151537: lr: 0.004384\n",
      "2021-11-04 00:16:18.224445: saving checkpoint...\n",
      "2021-11-04 00:16:19.393838: done, saving took 1.22 seconds\n",
      "2021-11-04 00:16:19.940217: This epoch took 296.484282 s\n",
      "\n",
      "2021-11-04 00:16:19.954131: \n",
      "epoch:  30\n",
      "2021-11-04 00:20:57.263370: train loss : -0.8413\n",
      "2021-11-04 00:21:14.940890: validation loss: -0.8415\n",
      "2021-11-04 00:21:14.943913: Average global foreground Dice: [0.859]\n",
      "2021-11-04 00:21:14.950496: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 00:21:15.436275: lr: 0.004186\n",
      "2021-11-04 00:21:15.518678: saving checkpoint...\n",
      "2021-11-04 00:21:16.871298: done, saving took 1.40 seconds\n",
      "2021-11-04 00:21:17.458825: This epoch took 297.498554 s\n",
      "\n",
      "2021-11-04 00:21:17.481380: \n",
      "epoch:  31\n",
      "2021-11-04 00:25:55.456716: train loss : -0.8465\n",
      "2021-11-04 00:26:12.949085: validation loss: -0.8389\n",
      "2021-11-04 00:26:12.951883: Average global foreground Dice: [0.8545]\n",
      "2021-11-04 00:26:12.957081: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 00:26:13.422370: lr: 0.003987\n",
      "2021-11-04 00:26:13.488879: saving checkpoint...\n",
      "2021-11-04 00:26:14.722566: done, saving took 1.26 seconds\n",
      "2021-11-04 00:26:15.342245: This epoch took 297.852952 s\n",
      "\n",
      "2021-11-04 00:26:15.360442: \n",
      "epoch:  32\n",
      "2021-11-04 00:30:53.103891: train loss : -0.8410\n",
      "2021-11-04 00:31:10.769584: validation loss: -0.8453\n",
      "2021-11-04 00:31:10.772614: Average global foreground Dice: [0.8622]\n",
      "2021-11-04 00:31:10.777652: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 00:31:11.247069: lr: 0.003787\n",
      "2021-11-04 00:31:11.303351: saving checkpoint...\n",
      "2021-11-04 00:31:12.563764: done, saving took 1.29 seconds\n",
      "2021-11-04 00:31:13.131192: This epoch took 297.760877 s\n",
      "\n",
      "2021-11-04 00:31:13.155285: \n",
      "epoch:  33\n",
      "2021-11-04 00:35:51.020886: train loss : -0.8402\n",
      "2021-11-04 00:36:08.471373: validation loss: -0.8397\n",
      "2021-11-04 00:36:08.474056: Average global foreground Dice: [0.856]\n",
      "2021-11-04 00:36:08.479260: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 00:36:08.945741: lr: 0.003586\n",
      "2021-11-04 00:36:09.014470: saving checkpoint...\n",
      "2021-11-04 00:36:10.275026: done, saving took 1.29 seconds\n",
      "2021-11-04 00:36:10.829285: This epoch took 297.668433 s\n",
      "\n",
      "2021-11-04 00:36:10.848257: \n",
      "epoch:  34\n",
      "2021-11-04 00:40:48.777210: train loss : -0.8385\n",
      "2021-11-04 00:41:06.221999: validation loss: -0.8158\n",
      "2021-11-04 00:41:06.224683: Average global foreground Dice: [0.8356]\n",
      "2021-11-04 00:41:06.229996: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 00:41:06.694085: lr: 0.003384\n",
      "2021-11-04 00:41:06.720047: This epoch took 295.865740 s\n",
      "\n",
      "2021-11-04 00:41:06.726777: \n",
      "epoch:  35\n",
      "2021-11-04 00:45:44.921806: train loss : -0.8401\n",
      "2021-11-04 00:46:02.387514: validation loss: -0.8393\n",
      "2021-11-04 00:46:02.389936: Average global foreground Dice: [0.8546]\n",
      "2021-11-04 00:46:02.394218: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 00:46:02.858492: lr: 0.00318\n",
      "2021-11-04 00:46:02.903299: saving checkpoint...\n",
      "2021-11-04 00:46:04.007400: done, saving took 1.13 seconds\n",
      "2021-11-04 00:46:04.570401: This epoch took 297.836881 s\n",
      "\n",
      "2021-11-04 00:46:04.578073: \n",
      "epoch:  36\n",
      "2021-11-04 00:50:42.579978: train loss : -0.8447\n",
      "2021-11-04 00:51:00.022194: validation loss: -0.8270\n",
      "2021-11-04 00:51:00.024799: Average global foreground Dice: [0.8418]\n",
      "2021-11-04 00:51:00.029758: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 00:51:00.491009: lr: 0.002975\n",
      "2021-11-04 00:51:00.512293: This epoch took 295.928053 s\n",
      "\n",
      "2021-11-04 00:51:00.517648: \n",
      "epoch:  37\n",
      "2021-11-04 00:55:38.581634: train loss : -0.8451\n",
      "2021-11-04 00:55:56.019244: validation loss: -0.8461\n",
      "2021-11-04 00:55:56.021754: Average global foreground Dice: [0.8595]\n",
      "2021-11-04 00:55:56.027128: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 00:55:56.490859: lr: 0.002768\n",
      "2021-11-04 00:55:56.534262: saving checkpoint...\n",
      "2021-11-04 00:55:57.715218: done, saving took 1.21 seconds\n",
      "2021-11-04 00:55:58.466635: This epoch took 297.943368 s\n",
      "\n",
      "2021-11-04 00:55:58.473493: \n",
      "epoch:  38\n",
      "2021-11-04 01:00:37.061792: train loss : -0.8478\n",
      "2021-11-04 01:00:54.543103: validation loss: -0.8293\n",
      "2021-11-04 01:00:54.546226: Average global foreground Dice: [0.8483]\n",
      "2021-11-04 01:00:54.551402: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 01:00:55.016908: lr: 0.00256\n",
      "2021-11-04 01:00:55.062493: saving checkpoint...\n",
      "2021-11-04 01:00:56.173111: done, saving took 1.14 seconds\n",
      "2021-11-04 01:00:56.726477: This epoch took 298.246812 s\n",
      "\n",
      "2021-11-04 01:00:56.733995: \n",
      "epoch:  39\n",
      "2021-11-04 01:05:35.579904: train loss : -0.8468\n",
      "2021-11-04 01:05:53.096617: validation loss: -0.8442\n",
      "2021-11-04 01:05:53.099282: Average global foreground Dice: [0.8579]\n",
      "2021-11-04 01:05:53.104640: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 01:05:53.575838: lr: 0.002349\n",
      "2021-11-04 01:05:53.622165: saving checkpoint...\n",
      "2021-11-04 01:05:54.730586: done, saving took 1.14 seconds\n",
      "2021-11-04 01:05:55.350956: This epoch took 298.610027 s\n",
      "\n",
      "2021-11-04 01:05:55.358110: \n",
      "epoch:  40\n",
      "2021-11-04 01:10:34.197323: train loss : -0.8463\n",
      "2021-11-04 01:10:51.635635: validation loss: -0.8469\n",
      "2021-11-04 01:10:51.638111: Average global foreground Dice: [0.8604]\n",
      "2021-11-04 01:10:51.643564: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 01:10:52.111786: lr: 0.002137\n",
      "2021-11-04 01:10:52.156442: saving checkpoint...\n",
      "2021-11-04 01:10:53.257010: done, saving took 1.13 seconds\n",
      "2021-11-04 01:10:53.823076: This epoch took 298.458749 s\n",
      "\n",
      "2021-11-04 01:10:53.830642: \n",
      "epoch:  41\n",
      "2021-11-04 01:15:32.641313: train loss : -0.8536\n",
      "2021-11-04 01:15:50.131753: validation loss: -0.8345\n",
      "2021-11-04 01:15:50.135252: Average global foreground Dice: [0.8493]\n",
      "2021-11-04 01:15:50.139214: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 01:15:50.595893: lr: 0.001922\n",
      "2021-11-04 01:15:50.639263: saving checkpoint...\n",
      "2021-11-04 01:15:51.767530: done, saving took 1.16 seconds\n",
      "2021-11-04 01:15:52.322695: This epoch took 298.485482 s\n",
      "\n",
      "2021-11-04 01:15:52.332058: \n",
      "epoch:  42\n",
      "2021-11-04 01:20:30.922565: train loss : -0.8503\n",
      "2021-11-04 01:20:48.323588: validation loss: -0.8478\n",
      "2021-11-04 01:20:48.326113: Average global foreground Dice: [0.8627]\n",
      "2021-11-04 01:20:48.331205: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 01:20:48.790152: lr: 0.001704\n",
      "2021-11-04 01:20:48.832547: saving checkpoint...\n",
      "2021-11-04 01:20:49.960539: done, saving took 1.16 seconds\n",
      "2021-11-04 01:20:50.422691: This epoch took 298.083661 s\n",
      "\n",
      "2021-11-04 01:20:50.430379: \n",
      "epoch:  43\n",
      "2021-11-04 01:25:29.300848: train loss : -0.8534\n",
      "2021-11-04 01:25:46.891600: validation loss: -0.8420\n",
      "2021-11-04 01:25:46.894178: Average global foreground Dice: [0.8562]\n",
      "2021-11-04 01:25:46.898795: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 01:25:47.357638: lr: 0.001483\n",
      "2021-11-04 01:25:47.402296: saving checkpoint...\n",
      "2021-11-04 01:25:48.525043: done, saving took 1.15 seconds\n",
      "2021-11-04 01:25:49.042146: This epoch took 298.605895 s\n",
      "\n",
      "2021-11-04 01:25:49.048996: \n",
      "epoch:  44\n",
      "2021-11-04 01:30:27.845122: train loss : -0.8548\n",
      "2021-11-04 01:30:45.313596: validation loss: -0.8435\n",
      "2021-11-04 01:30:45.316708: Average global foreground Dice: [0.8552]\n",
      "2021-11-04 01:30:45.323184: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 01:30:45.826065: lr: 0.001259\n",
      "2021-11-04 01:30:45.867644: saving checkpoint...\n",
      "2021-11-04 01:30:47.000628: done, saving took 1.16 seconds\n",
      "2021-11-04 01:30:47.539306: This epoch took 298.485212 s\n",
      "\n",
      "2021-11-04 01:30:47.548748: \n",
      "epoch:  45\n",
      "2021-11-04 01:35:26.462506: train loss : -0.8548\n",
      "2021-11-04 01:35:44.395872: validation loss: -0.8455\n",
      "2021-11-04 01:35:44.398707: Average global foreground Dice: [0.8575]\n",
      "2021-11-04 01:35:44.403052: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 01:35:44.870289: lr: 0.00103\n",
      "2021-11-04 01:35:44.914029: saving checkpoint...\n",
      "2021-11-04 01:35:46.079584: done, saving took 1.19 seconds\n",
      "2021-11-04 01:35:46.586668: This epoch took 299.032596 s\n",
      "\n",
      "2021-11-04 01:35:46.594055: \n",
      "epoch:  46\n",
      "2021-11-04 01:40:25.544564: train loss : -0.8575\n",
      "2021-11-04 01:40:43.006254: validation loss: -0.8302\n",
      "2021-11-04 01:40:43.008873: Average global foreground Dice: [0.8455]\n",
      "2021-11-04 01:40:43.012885: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 01:40:43.473635: lr: 0.000795\n",
      "2021-11-04 01:40:43.489340: This epoch took 296.890499 s\n",
      "\n",
      "2021-11-04 01:40:43.495427: \n",
      "epoch:  47\n",
      "2021-11-04 01:45:22.540975: train loss : -0.8548\n",
      "2021-11-04 01:45:39.956731: validation loss: -0.8310\n",
      "2021-11-04 01:45:39.959216: Average global foreground Dice: [0.8497]\n",
      "2021-11-04 01:45:39.964101: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 01:45:40.468714: lr: 0.000552\n",
      "2021-11-04 01:45:40.483495: This epoch took 296.981434 s\n",
      "\n",
      "2021-11-04 01:45:40.489150: \n",
      "epoch:  48\n",
      "2021-11-04 01:50:19.363419: train loss : -0.8540\n",
      "2021-11-04 01:50:36.793837: validation loss: -0.8381\n",
      "2021-11-04 01:50:36.796491: Average global foreground Dice: [0.853]\n",
      "2021-11-04 01:50:36.800962: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 01:50:37.268683: lr: 0.000296\n",
      "2021-11-04 01:50:37.301781: This epoch took 296.806311 s\n",
      "\n",
      "2021-11-04 01:50:37.307534: \n",
      "epoch:  49\n",
      "2021-11-04 01:55:16.573605: train loss : -0.8553\n",
      "2021-11-04 01:55:34.031571: validation loss: -0.8473\n",
      "2021-11-04 01:55:34.034521: Average global foreground Dice: [0.8604]\n",
      "2021-11-04 01:55:34.039142: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 01:55:34.501802: lr: 0.0\n",
      "2021-11-04 01:55:34.517801: saving scheduled checkpoint file...\n",
      "2021-11-04 01:55:34.575114: saving checkpoint...\n",
      "2021-11-04 01:55:35.528019: done, saving took 1.00 seconds\n",
      "2021-11-04 01:55:36.039443: done\n",
      "2021-11-04 01:55:36.105389: saving checkpoint...\n",
      "2021-11-04 01:55:37.347543: done, saving took 1.30 seconds\n",
      "2021-11-04 01:55:37.854507: This epoch took 300.539918 s\n",
      "\n",
      "2021-11-04 01:55:37.890355: saving checkpoint...\n",
      "2021-11-04 01:55:38.824318: done, saving took 0.96 seconds\n",
      "23090558_20120330 (3, 263, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 263, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 7], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090564_20130312 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090568_20121018 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090569_20120607 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120613 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150908 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090593_20120625 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130103 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090600_20121108 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090603_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090607_20120420 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090609_20120510 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160119 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160510 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090646_20120718 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-04 01:58:58.520023: finished prediction\n",
      "2021-11-04 01:58:58.525863: evaluation of raw predictions\n",
      "2021-11-04 01:59:00.165060: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8544157951891298\n",
      "after:  0.8544157951891298\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\r\n"
     ]
    }
   ],
   "source": [
    "# Model 3\n",
    "\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_CEGDL 555 0\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_CEGDL 555 1\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_CEGDL 555 2\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_CEGDL 555 3\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_CEGDL 555 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_Dice.nnUNetTrainerV2_Loss_Dice'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-04 07:21:43.094851: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-04 07:21:43.114364: The split file contains 5 splits.\n",
      "2021-11-04 07:21:43.120207: Desired fold for training: 0\n",
      "2021-11-04 07:21:43.125448: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-04 07:21:47.401661: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-04 07:22:10.585737: Unable to plot network architecture:\n",
      "2021-11-04 07:22:10.591848: No module named 'hiddenlayer'\n",
      "2021-11-04 07:22:10.598521: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-04 07:22:10.604451: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-04 07:22:10.638673: \n",
      "\n",
      "2021-11-04 07:22:10.644947: \n",
      "epoch:  0\n",
      "2021-11-04 07:27:49.436949: train loss : -0.0046\n",
      "2021-11-04 07:28:12.380881: validation loss: -0.0083\n",
      "2021-11-04 07:28:12.388095: Average global foreground Dice: [0.0135]\n",
      "2021-11-04 07:28:12.395557: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 07:28:12.992616: lr: 0.00982\n",
      "2021-11-04 07:28:12.998236: This epoch took 362.347049 s\n",
      "\n",
      "2021-11-04 07:28:13.004609: \n",
      "epoch:  1\n",
      "2021-11-04 07:33:38.601897: train loss : -0.0264\n",
      "2021-11-04 07:34:02.780746: validation loss: -0.2268\n",
      "2021-11-04 07:34:02.801907: Average global foreground Dice: [0.4977]\n",
      "2021-11-04 07:34:02.837338: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 07:34:05.205519: lr: 0.009639\n",
      "2021-11-04 07:34:05.471515: saving checkpoint...\n",
      "2021-11-04 07:34:07.142212: done, saving took 1.90 seconds\n",
      "2021-11-04 07:34:07.164763: This epoch took 354.154187 s\n",
      "\n",
      "2021-11-04 07:34:07.170545: \n",
      "epoch:  2\n",
      "2021-11-04 07:39:21.738680: train loss : -0.4367\n",
      "2021-11-04 07:39:41.573611: validation loss: -0.6711\n",
      "2021-11-04 07:39:41.580242: Average global foreground Dice: [0.7287]\n",
      "2021-11-04 07:39:41.586235: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 07:39:42.102041: lr: 0.009458\n",
      "2021-11-04 07:39:42.186087: saving checkpoint...\n",
      "2021-11-04 07:39:43.376281: done, saving took 1.27 seconds\n",
      "2021-11-04 07:39:43.414603: This epoch took 336.237381 s\n",
      "\n",
      "2021-11-04 07:39:43.420383: \n",
      "epoch:  3\n",
      "2021-11-04 07:44:53.472010: train loss : -0.6645\n",
      "2021-11-04 07:45:14.844234: validation loss: -0.7497\n",
      "2021-11-04 07:45:14.850454: Average global foreground Dice: [0.7792]\n",
      "2021-11-04 07:45:14.856203: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 07:45:15.393756: lr: 0.009277\n",
      "2021-11-04 07:45:15.476782: saving checkpoint...\n",
      "2021-11-04 07:45:16.590531: done, saving took 1.19 seconds\n",
      "2021-11-04 07:45:16.624301: This epoch took 333.197478 s\n",
      "\n",
      "2021-11-04 07:45:16.630527: \n",
      "epoch:  4\n",
      "2021-11-04 07:50:30.080892: train loss : -0.7099\n",
      "2021-11-04 07:50:51.492522: validation loss: -0.7758\n",
      "2021-11-04 07:50:51.498642: Average global foreground Dice: [0.8073]\n",
      "2021-11-04 07:50:51.504318: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 07:50:52.032851: lr: 0.009095\n",
      "2021-11-04 07:50:52.115672: saving checkpoint...\n",
      "2021-11-04 07:50:53.217007: done, saving took 1.18 seconds\n",
      "2021-11-04 07:50:53.244917: This epoch took 336.608718 s\n",
      "\n",
      "2021-11-04 07:50:53.250473: \n",
      "epoch:  5\n",
      "2021-11-04 07:56:04.858273: train loss : -0.7493\n",
      "2021-11-04 07:56:25.380127: validation loss: -0.7969\n",
      "2021-11-04 07:56:25.386762: Average global foreground Dice: [0.8201]\n",
      "2021-11-04 07:56:25.392981: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 07:56:25.899580: lr: 0.008913\n",
      "2021-11-04 07:56:25.934171: saving checkpoint...\n",
      "2021-11-04 07:56:27.078310: done, saving took 1.17 seconds\n",
      "2021-11-04 07:56:27.109650: This epoch took 333.852990 s\n",
      "\n",
      "2021-11-04 07:56:27.115857: \n",
      "epoch:  6\n",
      "2021-11-04 08:01:37.373466: train loss : -0.7626\n",
      "2021-11-04 08:01:58.568303: validation loss: -0.7849\n",
      "2021-11-04 08:01:58.575246: Average global foreground Dice: [0.793]\n",
      "2021-11-04 08:01:58.581475: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 08:01:59.283364: lr: 0.008731\n",
      "2021-11-04 08:01:59.352255: saving checkpoint...\n",
      "2021-11-04 08:02:00.525824: done, saving took 1.24 seconds\n",
      "2021-11-04 08:02:00.565907: This epoch took 333.443899 s\n",
      "\n",
      "2021-11-04 08:02:00.571754: \n",
      "epoch:  7\n",
      "2021-11-04 08:07:09.208385: train loss : -0.7807\n",
      "2021-11-04 08:07:28.598786: validation loss: -0.8260\n",
      "2021-11-04 08:07:28.604776: Average global foreground Dice: [0.8447]\n",
      "2021-11-04 08:07:28.610399: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 08:07:29.116293: lr: 0.008548\n",
      "2021-11-04 08:07:29.192518: saving checkpoint...\n",
      "2021-11-04 08:07:30.314760: done, saving took 1.19 seconds\n",
      "2021-11-04 08:07:30.342775: This epoch took 329.764836 s\n",
      "\n",
      "2021-11-04 08:07:30.348315: \n",
      "epoch:  8\n",
      "2021-11-04 08:12:43.342301: train loss : -0.7862\n",
      "2021-11-04 08:13:03.278891: validation loss: -0.8177\n",
      "2021-11-04 08:13:03.285623: Average global foreground Dice: [0.8394]\n",
      "2021-11-04 08:13:03.291552: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 08:13:03.806320: lr: 0.008364\n",
      "2021-11-04 08:13:03.884501: saving checkpoint...\n",
      "2021-11-04 08:13:05.063082: done, saving took 1.25 seconds\n",
      "2021-11-04 08:13:05.094426: This epoch took 334.739796 s\n",
      "\n",
      "2021-11-04 08:13:05.100210: \n",
      "epoch:  9\n",
      "2021-11-04 08:18:18.381779: train loss : -0.7918\n",
      "2021-11-04 08:18:38.020635: validation loss: -0.8260\n",
      "2021-11-04 08:18:38.027841: Average global foreground Dice: [0.841]\n",
      "2021-11-04 08:18:38.033805: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 08:18:38.525603: lr: 0.008181\n",
      "2021-11-04 08:18:38.561085: saving checkpoint...\n",
      "2021-11-04 08:18:39.666925: done, saving took 1.13 seconds\n",
      "2021-11-04 08:18:39.694515: This epoch took 334.588927 s\n",
      "\n",
      "2021-11-04 08:18:39.700590: \n",
      "epoch:  10\n",
      "2021-11-04 08:23:48.277877: train loss : -0.8000\n",
      "2021-11-04 08:24:07.673187: validation loss: -0.8355\n",
      "2021-11-04 08:24:07.680039: Average global foreground Dice: [0.851]\n",
      "2021-11-04 08:24:07.685972: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 08:24:08.195449: lr: 0.007996\n",
      "2021-11-04 08:24:08.230055: saving checkpoint...\n",
      "2021-11-04 08:24:09.430821: done, saving took 1.23 seconds\n",
      "2021-11-04 08:24:09.459231: This epoch took 329.752585 s\n",
      "\n",
      "2021-11-04 08:24:09.465234: \n",
      "epoch:  11\n",
      "2021-11-04 08:29:18.972482: train loss : -0.7977\n",
      "2021-11-04 08:29:38.381507: validation loss: -0.8359\n",
      "2021-11-04 08:29:38.388357: Average global foreground Dice: [0.854]\n",
      "2021-11-04 08:29:38.394034: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 08:29:38.903166: lr: 0.007811\n",
      "2021-11-04 08:29:38.936651: saving checkpoint...\n",
      "2021-11-04 08:29:40.054520: done, saving took 1.15 seconds\n",
      "2021-11-04 08:29:40.082725: This epoch took 330.612153 s\n",
      "\n",
      "2021-11-04 08:29:40.088371: \n",
      "epoch:  12\n",
      "2021-11-04 08:34:54.258314: train loss : -0.8030\n",
      "2021-11-04 08:35:15.871088: validation loss: -0.8343\n",
      "2021-11-04 08:35:15.878301: Average global foreground Dice: [0.8497]\n",
      "2021-11-04 08:35:15.884939: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 08:35:16.497076: lr: 0.007626\n",
      "2021-11-04 08:35:16.531317: saving checkpoint...\n",
      "2021-11-04 08:35:17.692704: done, saving took 1.19 seconds\n",
      "2021-11-04 08:35:17.723932: This epoch took 337.629374 s\n",
      "\n",
      "2021-11-04 08:35:17.730117: \n",
      "epoch:  13\n",
      "2021-11-04 08:40:32.499269: train loss : -0.8145\n",
      "2021-11-04 08:40:52.108671: validation loss: -0.8352\n",
      "2021-11-04 08:40:52.115099: Average global foreground Dice: [0.8512]\n",
      "2021-11-04 08:40:52.121181: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 08:40:52.637609: lr: 0.00744\n",
      "2021-11-04 08:40:52.696271: saving checkpoint...\n",
      "2021-11-04 08:40:53.840291: done, saving took 1.20 seconds\n",
      "2021-11-04 08:40:53.866215: This epoch took 336.130154 s\n",
      "\n",
      "2021-11-04 08:40:53.871969: \n",
      "epoch:  14\n",
      "2021-11-04 08:46:09.466110: train loss : -0.8193\n",
      "2021-11-04 08:46:29.100569: validation loss: -0.8385\n",
      "2021-11-04 08:46:29.106663: Average global foreground Dice: [0.8499]\n",
      "2021-11-04 08:46:29.112853: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 08:46:29.636803: lr: 0.007254\n",
      "2021-11-04 08:46:29.699070: saving checkpoint...\n",
      "2021-11-04 08:46:31.007724: done, saving took 1.37 seconds\n",
      "2021-11-04 08:46:31.040661: This epoch took 337.163051 s\n",
      "\n",
      "2021-11-04 08:46:31.047525: \n",
      "epoch:  15\n",
      "2021-11-04 08:51:47.765926: train loss : -0.8086\n",
      "2021-11-04 08:52:08.898453: validation loss: -0.8408\n",
      "2021-11-04 08:52:08.904969: Average global foreground Dice: [0.8561]\n",
      "2021-11-04 08:52:08.911445: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 08:52:09.422730: lr: 0.007067\n",
      "2021-11-04 08:52:09.489210: saving checkpoint...\n",
      "2021-11-04 08:52:10.629578: done, saving took 1.20 seconds\n",
      "2021-11-04 08:52:10.656585: This epoch took 339.602742 s\n",
      "\n",
      "2021-11-04 08:52:10.663503: \n",
      "epoch:  16\n",
      "2021-11-04 08:57:32.911105: train loss : -0.8128\n",
      "2021-11-04 08:57:55.600352: validation loss: -0.8313\n",
      "2021-11-04 08:57:55.607275: Average global foreground Dice: [0.8394]\n",
      "2021-11-04 08:57:55.641271: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 08:57:56.495493: lr: 0.00688\n",
      "2021-11-04 08:57:56.559056: saving checkpoint...\n",
      "2021-11-04 08:57:57.803836: done, saving took 1.30 seconds\n",
      "2021-11-04 08:57:57.844094: This epoch took 347.174342 s\n",
      "\n",
      "2021-11-04 08:57:57.852489: \n",
      "epoch:  17\n",
      "2021-11-04 09:03:15.549922: train loss : -0.8189\n",
      "2021-11-04 09:03:36.798870: validation loss: -0.8470\n",
      "2021-11-04 09:03:36.807032: Average global foreground Dice: [0.8594]\n",
      "2021-11-04 09:03:36.813892: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 09:03:37.350852: lr: 0.006692\n",
      "2021-11-04 09:03:37.385374: saving checkpoint...\n",
      "2021-11-04 09:03:38.487329: done, saving took 1.13 seconds\n",
      "2021-11-04 09:03:38.517987: This epoch took 340.659150 s\n",
      "\n",
      "2021-11-04 09:03:38.523503: \n",
      "epoch:  18\n",
      "2021-11-04 09:08:55.527099: train loss : -0.8205\n",
      "2021-11-04 09:09:14.997405: validation loss: -0.8499\n",
      "2021-11-04 09:09:15.005142: Average global foreground Dice: [0.8606]\n",
      "2021-11-04 09:09:15.010539: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 09:09:15.505216: lr: 0.006504\n",
      "2021-11-04 09:09:15.539479: saving checkpoint...\n",
      "2021-11-04 09:09:16.684994: done, saving took 1.17 seconds\n",
      "2021-11-04 09:09:16.711568: This epoch took 338.181920 s\n",
      "\n",
      "2021-11-04 09:09:16.717365: \n",
      "epoch:  19\n",
      "2021-11-04 09:14:33.750611: train loss : -0.8216\n",
      "2021-11-04 09:14:53.632316: validation loss: -0.8479\n",
      "2021-11-04 09:14:53.638985: Average global foreground Dice: [0.8603]\n",
      "2021-11-04 09:14:53.645004: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 09:14:54.145652: lr: 0.006314\n",
      "2021-11-04 09:14:54.180930: saving checkpoint...\n",
      "2021-11-04 09:14:55.306821: done, saving took 1.15 seconds\n",
      "2021-11-04 09:14:55.334871: This epoch took 338.611509 s\n",
      "\n",
      "2021-11-04 09:14:55.340239: \n",
      "epoch:  20\n",
      "2021-11-04 09:20:14.963950: train loss : -0.8235\n",
      "2021-11-04 09:20:34.567535: validation loss: -0.8533\n",
      "2021-11-04 09:20:34.574025: Average global foreground Dice: [0.8624]\n",
      "2021-11-04 09:20:34.579923: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 09:20:35.079413: lr: 0.006125\n",
      "2021-11-04 09:20:35.114742: saving checkpoint...\n",
      "2021-11-04 09:20:36.239104: done, saving took 1.15 seconds\n",
      "2021-11-04 09:20:36.267272: This epoch took 340.920723 s\n",
      "\n",
      "2021-11-04 09:20:36.273931: \n",
      "epoch:  21\n",
      "2021-11-04 09:25:57.457245: train loss : -0.8252\n",
      "2021-11-04 09:26:18.810527: validation loss: -0.8518\n",
      "2021-11-04 09:26:18.816909: Average global foreground Dice: [0.8629]\n",
      "2021-11-04 09:26:18.824403: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 09:26:19.309837: lr: 0.005934\n",
      "2021-11-04 09:26:19.345072: saving checkpoint...\n",
      "2021-11-04 09:26:20.526634: done, saving took 1.21 seconds\n",
      "2021-11-04 09:26:20.554467: This epoch took 344.268737 s\n",
      "\n",
      "2021-11-04 09:26:20.560757: \n",
      "epoch:  22\n",
      "2021-11-04 09:31:39.748027: train loss : -0.8318\n",
      "2021-11-04 09:32:00.273685: validation loss: -0.8487\n",
      "2021-11-04 09:32:00.281788: Average global foreground Dice: [0.8579]\n",
      "2021-11-04 09:32:00.287131: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 09:32:00.784106: lr: 0.005743\n",
      "2021-11-04 09:32:00.830509: saving checkpoint...\n",
      "2021-11-04 09:32:02.035412: done, saving took 1.25 seconds\n",
      "2021-11-04 09:32:02.063567: This epoch took 341.497163 s\n",
      "\n",
      "2021-11-04 09:32:02.069487: \n",
      "epoch:  23\n",
      "2021-11-04 09:37:20.489464: train loss : -0.8303\n",
      "2021-11-04 09:37:40.262197: validation loss: -0.8467\n",
      "2021-11-04 09:37:40.270512: Average global foreground Dice: [0.8556]\n",
      "2021-11-04 09:37:40.275563: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 09:37:40.801820: lr: 0.005551\n",
      "2021-11-04 09:37:40.848378: saving checkpoint...\n",
      "2021-11-04 09:37:41.981244: done, saving took 1.17 seconds\n",
      "2021-11-04 09:37:42.012864: This epoch took 339.936680 s\n",
      "\n",
      "2021-11-04 09:37:42.018999: \n",
      "epoch:  24\n",
      "2021-11-04 09:43:02.849930: train loss : -0.8236\n",
      "2021-11-04 09:43:24.530016: validation loss: -0.8369\n",
      "2021-11-04 09:43:24.536585: Average global foreground Dice: [0.8424]\n",
      "2021-11-04 09:43:24.542530: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 09:43:25.047514: lr: 0.005359\n",
      "2021-11-04 09:43:25.093795: saving checkpoint...\n",
      "2021-11-04 09:43:26.267656: done, saving took 1.21 seconds\n",
      "2021-11-04 09:43:26.297199: This epoch took 344.272346 s\n",
      "\n",
      "2021-11-04 09:43:26.302940: \n",
      "epoch:  25\n",
      "2021-11-04 09:48:49.057674: train loss : -0.8287\n",
      "2021-11-04 09:49:09.818793: validation loss: -0.8543\n",
      "2021-11-04 09:49:09.825358: Average global foreground Dice: [0.8638]\n",
      "2021-11-04 09:49:09.830421: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 09:49:10.317369: lr: 0.005166\n",
      "2021-11-04 09:49:10.352020: saving checkpoint...\n",
      "2021-11-04 09:49:11.471040: done, saving took 1.15 seconds\n",
      "2021-11-04 09:49:11.496330: This epoch took 345.187318 s\n",
      "\n",
      "2021-11-04 09:49:11.502424: \n",
      "epoch:  26\n",
      "2021-11-04 09:54:29.761044: train loss : -0.8351\n",
      "2021-11-04 09:54:49.724171: validation loss: -0.8518\n",
      "2021-11-04 09:54:49.730295: Average global foreground Dice: [0.8613]\n",
      "2021-11-04 09:54:49.736141: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 09:54:50.224837: lr: 0.004971\n",
      "2021-11-04 09:54:50.259535: saving checkpoint...\n",
      "2021-11-04 09:54:51.372067: done, saving took 1.14 seconds\n",
      "2021-11-04 09:54:51.399879: This epoch took 339.891268 s\n",
      "\n",
      "2021-11-04 09:54:51.406100: \n",
      "epoch:  27\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-04 10:00:10.420165: train loss : -0.8369\n",
      "2021-11-04 10:00:30.029696: validation loss: -0.8532\n",
      "2021-11-04 10:00:30.042697: Average global foreground Dice: [0.8597]\n",
      "2021-11-04 10:00:30.049097: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 10:00:30.550706: lr: 0.004776\n",
      "2021-11-04 10:00:30.587566: saving checkpoint...\n",
      "2021-11-04 10:00:31.746193: done, saving took 1.19 seconds\n",
      "2021-11-04 10:00:31.777524: This epoch took 340.365840 s\n",
      "\n",
      "2021-11-04 10:00:31.782984: \n",
      "epoch:  28\n",
      "2021-11-04 10:05:50.157068: train loss : -0.8361\n",
      "2021-11-04 10:06:09.691641: validation loss: -0.8517\n",
      "2021-11-04 10:06:09.698657: Average global foreground Dice: [0.8577]\n",
      "2021-11-04 10:06:09.705461: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 10:06:10.190137: lr: 0.004581\n",
      "2021-11-04 10:06:10.225242: saving checkpoint...\n",
      "2021-11-04 10:06:11.422849: done, saving took 1.23 seconds\n",
      "2021-11-04 10:06:11.452385: This epoch took 339.663196 s\n",
      "\n",
      "2021-11-04 10:06:11.458592: \n",
      "epoch:  29\n",
      "2021-11-04 10:11:28.671017: train loss : -0.8405\n",
      "2021-11-04 10:11:48.054266: validation loss: -0.8492\n",
      "2021-11-04 10:11:48.060013: Average global foreground Dice: [0.8582]\n",
      "2021-11-04 10:11:48.065639: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 10:11:48.584643: lr: 0.004384\n",
      "2021-11-04 10:11:48.619276: saving checkpoint...\n",
      "2021-11-04 10:11:49.725308: done, saving took 1.13 seconds\n",
      "2021-11-04 10:11:49.762829: This epoch took 338.298052 s\n",
      "\n",
      "2021-11-04 10:11:49.768477: \n",
      "epoch:  30\n",
      "2021-11-04 10:17:08.891299: train loss : -0.8424\n",
      "2021-11-04 10:17:29.104888: validation loss: -0.8492\n",
      "2021-11-04 10:17:29.111537: Average global foreground Dice: [0.8562]\n",
      "2021-11-04 10:17:29.117196: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 10:17:29.646338: lr: 0.004186\n",
      "2021-11-04 10:17:29.682726: saving checkpoint...\n",
      "2021-11-04 10:17:30.799731: done, saving took 1.15 seconds\n",
      "2021-11-04 10:17:30.835695: This epoch took 341.061266 s\n",
      "\n",
      "2021-11-04 10:17:30.841529: \n",
      "epoch:  31\n",
      "2021-11-04 10:22:46.882985: train loss : -0.8425\n",
      "2021-11-04 10:23:06.228604: validation loss: -0.8446\n",
      "2021-11-04 10:23:06.235527: Average global foreground Dice: [0.851]\n",
      "2021-11-04 10:23:06.241150: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 10:23:06.743165: lr: 0.003987\n",
      "2021-11-04 10:23:06.777811: saving checkpoint...\n",
      "2021-11-04 10:23:07.905394: done, saving took 1.16 seconds\n",
      "2021-11-04 10:23:07.930565: This epoch took 337.082858 s\n",
      "\n",
      "2021-11-04 10:23:07.936457: \n",
      "epoch:  32\n",
      "2021-11-04 10:28:26.889772: train loss : -0.8445\n",
      "2021-11-04 10:28:46.340109: validation loss: -0.8525\n",
      "2021-11-04 10:28:46.346444: Average global foreground Dice: [0.8638]\n",
      "2021-11-04 10:28:46.352626: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 10:28:46.848950: lr: 0.003787\n",
      "2021-11-04 10:28:46.883512: saving checkpoint...\n",
      "2021-11-04 10:28:48.024770: done, saving took 1.17 seconds\n",
      "2021-11-04 10:28:48.060558: This epoch took 340.118037 s\n",
      "\n",
      "2021-11-04 10:28:48.066323: \n",
      "epoch:  33\n",
      "2021-11-04 10:34:06.566208: train loss : -0.8439\n",
      "2021-11-04 10:34:28.892033: validation loss: -0.8503\n",
      "2021-11-04 10:34:28.937947: Average global foreground Dice: [0.8576]\n",
      "2021-11-04 10:34:28.944408: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 10:34:30.313916: lr: 0.003586\n",
      "2021-11-04 10:34:30.353814: saving checkpoint...\n",
      "2021-11-04 10:34:31.688538: done, saving took 1.37 seconds\n",
      "2021-11-04 10:34:31.728893: This epoch took 343.656277 s\n",
      "\n",
      "2021-11-04 10:34:31.734982: \n",
      "epoch:  34\n",
      "2021-11-04 10:39:48.669697: train loss : -0.8413\n",
      "2021-11-04 10:40:08.133058: validation loss: -0.8482\n",
      "2021-11-04 10:40:08.140307: Average global foreground Dice: [0.8578]\n",
      "2021-11-04 10:40:08.146869: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 10:40:08.649829: lr: 0.003384\n",
      "2021-11-04 10:40:08.689891: saving checkpoint...\n",
      "2021-11-04 10:40:09.843267: done, saving took 1.19 seconds\n",
      "2021-11-04 10:40:09.883276: This epoch took 338.142103 s\n",
      "\n",
      "2021-11-04 10:40:09.889181: \n",
      "epoch:  35\n",
      "2021-11-04 10:45:27.358497: train loss : -0.8436\n",
      "2021-11-04 10:45:46.759879: validation loss: -0.8518\n",
      "2021-11-04 10:45:46.766595: Average global foreground Dice: [0.8598]\n",
      "2021-11-04 10:45:46.772150: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 10:45:47.276809: lr: 0.00318\n",
      "2021-11-04 10:45:47.311219: saving checkpoint...\n",
      "2021-11-04 10:45:48.464725: done, saving took 1.18 seconds\n",
      "2021-11-04 10:45:48.497505: This epoch took 338.601773 s\n",
      "\n",
      "2021-11-04 10:45:48.502974: \n",
      "epoch:  36\n",
      "2021-11-04 10:51:06.838312: train loss : -0.8459\n",
      "2021-11-04 10:51:27.945609: validation loss: -0.8587\n",
      "2021-11-04 10:51:27.952411: Average global foreground Dice: [0.8654]\n",
      "2021-11-04 10:51:27.959306: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 10:51:28.502532: lr: 0.002975\n",
      "2021-11-04 10:51:28.565270: saving checkpoint...\n",
      "2021-11-04 10:51:29.560056: done, saving took 1.05 seconds\n",
      "2021-11-04 10:51:29.592914: This epoch took 341.083018 s\n",
      "\n",
      "2021-11-04 10:51:29.598934: \n",
      "epoch:  37\n",
      "2021-11-04 10:56:48.150204: train loss : -0.8453\n",
      "2021-11-04 10:57:08.379271: validation loss: -0.8576\n",
      "2021-11-04 10:57:08.386862: Average global foreground Dice: [0.8677]\n",
      "2021-11-04 10:57:08.393342: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 10:57:08.917498: lr: 0.002768\n",
      "2021-11-04 10:57:08.979470: saving checkpoint...\n",
      "2021-11-04 10:57:10.019369: done, saving took 1.10 seconds\n",
      "2021-11-04 10:57:10.048999: This epoch took 340.443957 s\n",
      "\n",
      "2021-11-04 10:57:10.055009: \n",
      "epoch:  38\n",
      "2021-11-04 11:02:27.898497: train loss : -0.8464\n",
      "2021-11-04 11:02:47.766416: validation loss: -0.8406\n",
      "2021-11-04 11:02:47.772617: Average global foreground Dice: [0.8494]\n",
      "2021-11-04 11:02:47.778223: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 11:02:48.291147: lr: 0.00256\n",
      "2021-11-04 11:02:48.349340: saving checkpoint...\n",
      "2021-11-04 11:02:49.416761: done, saving took 1.12 seconds\n",
      "2021-11-04 11:02:49.444133: This epoch took 339.383687 s\n",
      "\n",
      "2021-11-04 11:02:49.450412: \n",
      "epoch:  39\n",
      "2021-11-04 11:08:07.551843: train loss : -0.8495\n",
      "2021-11-04 11:08:28.546688: validation loss: -0.8545\n",
      "2021-11-04 11:08:28.553087: Average global foreground Dice: [0.8646]\n",
      "2021-11-04 11:08:28.559037: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 11:08:29.065255: lr: 0.002349\n",
      "2021-11-04 11:08:29.101010: saving checkpoint...\n",
      "2021-11-04 11:08:30.132294: done, saving took 1.06 seconds\n",
      "2021-11-04 11:08:30.161168: This epoch took 340.705006 s\n",
      "\n",
      "2021-11-04 11:08:30.166947: \n",
      "epoch:  40\n",
      "2021-11-04 11:13:48.785430: train loss : -0.8474\n",
      "2021-11-04 11:14:09.097992: validation loss: -0.8522\n",
      "2021-11-04 11:14:09.104649: Average global foreground Dice: [0.8606]\n",
      "2021-11-04 11:14:09.110801: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 11:14:09.596830: lr: 0.002137\n",
      "2021-11-04 11:14:09.631245: saving checkpoint...\n",
      "2021-11-04 11:14:10.690675: done, saving took 1.09 seconds\n",
      "2021-11-04 11:14:10.717402: This epoch took 340.544392 s\n",
      "\n",
      "2021-11-04 11:14:10.723641: \n",
      "epoch:  41\n",
      "2021-11-04 11:19:29.420400: train loss : -0.8493\n",
      "2021-11-04 11:19:49.009544: validation loss: -0.8571\n",
      "2021-11-04 11:19:49.016047: Average global foreground Dice: [0.8651]\n",
      "2021-11-04 11:19:49.022210: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 11:19:49.517064: lr: 0.001922\n",
      "2021-11-04 11:19:49.551447: saving checkpoint...\n",
      "2021-11-04 11:19:50.522334: done, saving took 1.00 seconds\n",
      "2021-11-04 11:19:50.554792: This epoch took 339.824523 s\n",
      "\n",
      "2021-11-04 11:19:50.560713: \n",
      "epoch:  42\n",
      "2021-11-04 11:25:10.950390: train loss : -0.8524\n",
      "2021-11-04 11:25:33.007520: validation loss: -0.8521\n",
      "2021-11-04 11:25:33.013827: Average global foreground Dice: [0.8609]\n",
      "2021-11-04 11:25:33.020159: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 11:25:33.506818: lr: 0.001704\n",
      "2021-11-04 11:25:33.541932: saving checkpoint...\n",
      "2021-11-04 11:25:34.576555: done, saving took 1.06 seconds\n",
      "2021-11-04 11:25:34.603949: This epoch took 344.037310 s\n",
      "\n",
      "2021-11-04 11:25:34.610448: \n",
      "epoch:  43\n",
      "2021-11-04 11:30:54.250565: train loss : -0.8524\n",
      "2021-11-04 11:31:14.046818: validation loss: -0.8573\n",
      "2021-11-04 11:31:14.053710: Average global foreground Dice: [0.8626]\n",
      "2021-11-04 11:31:14.059672: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 11:31:14.583846: lr: 0.001483\n",
      "2021-11-04 11:31:14.617951: saving checkpoint...\n",
      "2021-11-04 11:31:15.639025: done, saving took 1.05 seconds\n",
      "2021-11-04 11:31:15.666077: This epoch took 341.049802 s\n",
      "\n",
      "2021-11-04 11:31:15.671791: \n",
      "epoch:  44\n",
      "2021-11-04 11:36:39.066130: train loss : -0.8521\n",
      "2021-11-04 11:36:59.921220: validation loss: -0.8544\n",
      "2021-11-04 11:36:59.926839: Average global foreground Dice: [0.8609]\n",
      "2021-11-04 11:36:59.933068: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 11:37:00.421774: lr: 0.001259\n",
      "2021-11-04 11:37:00.456445: saving checkpoint...\n",
      "2021-11-04 11:37:01.475118: done, saving took 1.05 seconds\n",
      "2021-11-04 11:37:01.501349: This epoch took 345.822656 s\n",
      "\n",
      "2021-11-04 11:37:01.507385: \n",
      "epoch:  45\n",
      "2021-11-04 11:42:17.737412: train loss : -0.8532\n",
      "2021-11-04 11:42:38.677557: validation loss: -0.8537\n",
      "2021-11-04 11:42:38.684349: Average global foreground Dice: [0.8607]\n",
      "2021-11-04 11:42:38.690334: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 11:42:39.168056: lr: 0.00103\n",
      "2021-11-04 11:42:39.202787: saving checkpoint...\n",
      "2021-11-04 11:42:40.211386: done, saving took 1.04 seconds\n",
      "2021-11-04 11:42:40.238255: This epoch took 338.724634 s\n",
      "\n",
      "2021-11-04 11:42:40.244215: \n",
      "epoch:  46\n",
      "2021-11-04 11:47:56.588993: train loss : -0.8566\n",
      "2021-11-04 11:48:17.717959: validation loss: -0.8521\n",
      "2021-11-04 11:48:17.725036: Average global foreground Dice: [0.8573]\n",
      "2021-11-04 11:48:17.731436: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 11:48:18.210957: lr: 0.000795\n",
      "2021-11-04 11:48:18.246185: saving checkpoint...\n",
      "2021-11-04 11:48:19.235357: done, saving took 1.02 seconds\n",
      "2021-11-04 11:48:19.269301: This epoch took 339.019258 s\n",
      "\n",
      "2021-11-04 11:48:19.274902: \n",
      "epoch:  47\n",
      "2021-11-04 11:53:37.490371: train loss : -0.8545\n",
      "2021-11-04 11:53:56.894454: validation loss: -0.8471\n",
      "2021-11-04 11:53:56.902451: Average global foreground Dice: [0.8582]\n",
      "2021-11-04 11:53:56.908347: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 11:53:57.407429: lr: 0.000552\n",
      "2021-11-04 11:53:57.466478: saving checkpoint...\n",
      "2021-11-04 11:53:58.458323: done, saving took 1.04 seconds\n",
      "2021-11-04 11:53:58.487630: This epoch took 339.206836 s\n",
      "\n",
      "2021-11-04 11:53:58.492789: \n",
      "epoch:  48\n",
      "2021-11-04 11:59:19.779264: train loss : -0.8600\n",
      "2021-11-04 11:59:41.853178: validation loss: -0.8591\n",
      "2021-11-04 11:59:41.859666: Average global foreground Dice: [0.8643]\n",
      "2021-11-04 11:59:41.865509: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 11:59:42.439024: lr: 0.000296\n",
      "2021-11-04 11:59:42.492050: saving checkpoint...\n",
      "2021-11-04 11:59:43.513998: done, saving took 1.07 seconds\n",
      "2021-11-04 11:59:43.543765: This epoch took 345.044743 s\n",
      "\n",
      "2021-11-04 11:59:43.549804: \n",
      "epoch:  49\n",
      "2021-11-04 12:05:02.461393: train loss : -0.8581\n",
      "2021-11-04 12:05:23.813698: validation loss: -0.8564\n",
      "2021-11-04 12:05:23.820682: Average global foreground Dice: [0.8636]\n",
      "2021-11-04 12:05:23.827431: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 12:05:24.329903: lr: 0.0\n",
      "2021-11-04 12:05:24.336592: saving scheduled checkpoint file...\n",
      "2021-11-04 12:05:24.389038: saving checkpoint...\n",
      "2021-11-04 12:05:25.242151: done, saving took 0.90 seconds\n",
      "2021-11-04 12:05:25.261520: done\n",
      "2021-11-04 12:05:25.295630: saving checkpoint...\n",
      "2021-11-04 12:05:26.269721: done, saving took 1.00 seconds\n",
      "2021-11-04 12:05:26.295881: This epoch took 342.740344 s\n",
      "\n",
      "2021-11-04 12:05:26.331084: saving checkpoint...\n",
      "2021-11-04 12:05:27.173180: done, saving took 0.87 seconds\n",
      "23090559_20150812 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120330 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090563_20151216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130226 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090584_20120523 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090589_20140219 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090592_20130218 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090614_20120402 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090620_20130617 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090627_20160608 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090628_20150204 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090635_20140710 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090640_20140711 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121227 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-04 12:08:57.451168: finished prediction\n",
      "2021-11-04 12:08:57.457820: evaluation of raw predictions\n",
      "2021-11-04 12:08:59.053706: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8594171036569335\n",
      "after:  0.8594171036569335\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_Dice.nnUNetTrainerV2_Loss_Dice'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-04 12:09:10.468842: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-04 12:09:10.490317: The split file contains 5 splits.\n",
      "2021-11-04 12:09:10.496378: Desired fold for training: 1\n",
      "2021-11-04 12:09:10.501099: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-04 12:09:14.811629: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-04 12:09:24.446742: Unable to plot network architecture:\n",
      "2021-11-04 12:09:24.452812: No module named 'hiddenlayer'\n",
      "2021-11-04 12:09:24.458796: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-04 12:09:24.464500: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-04 12:09:24.478487: \n",
      "\n",
      "2021-11-04 12:09:24.484356: \n",
      "epoch:  0\n",
      "2021-11-04 12:14:58.550916: train loss : -0.0056\n",
      "2021-11-04 12:15:18.486631: validation loss: -0.0104\n",
      "2021-11-04 12:15:18.492642: Average global foreground Dice: [0.0311]\n",
      "2021-11-04 12:15:18.498680: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 12:15:18.974327: lr: 0.00982\n",
      "2021-11-04 12:15:18.979489: This epoch took 354.489177 s\n",
      "\n",
      "2021-11-04 12:15:18.985589: \n",
      "epoch:  1\n",
      "2021-11-04 12:20:26.696270: train loss : -0.0912\n",
      "2021-11-04 12:20:45.553508: validation loss: -0.4306\n",
      "2021-11-04 12:20:45.559747: Average global foreground Dice: [0.5594]\n",
      "2021-11-04 12:20:45.565516: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 12:20:46.072728: lr: 0.009639\n",
      "2021-11-04 12:20:46.156603: saving checkpoint...\n",
      "2021-11-04 12:20:47.075145: done, saving took 1.00 seconds\n",
      "2021-11-04 12:20:47.101847: This epoch took 328.111199 s\n",
      "\n",
      "2021-11-04 12:20:47.107204: \n",
      "epoch:  2\n",
      "2021-11-04 12:25:54.617894: train loss : -0.5192\n",
      "2021-11-04 12:26:13.111683: validation loss: -0.6462\n",
      "2021-11-04 12:26:13.119347: Average global foreground Dice: [0.716]\n",
      "2021-11-04 12:26:13.125267: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 12:26:13.648315: lr: 0.009458\n",
      "2021-11-04 12:26:13.728903: saving checkpoint...\n",
      "2021-11-04 12:26:14.828746: done, saving took 1.17 seconds\n",
      "2021-11-04 12:26:14.872378: This epoch took 327.759544 s\n",
      "\n",
      "2021-11-04 12:26:14.881110: \n",
      "epoch:  3\n",
      "2021-11-04 12:31:20.912033: train loss : -0.6644\n",
      "2021-11-04 12:31:39.218126: validation loss: -0.7159\n",
      "2021-11-04 12:31:39.224091: Average global foreground Dice: [0.7648]\n",
      "2021-11-04 12:31:39.230517: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 12:31:39.747340: lr: 0.009277\n",
      "2021-11-04 12:31:39.822248: saving checkpoint...\n",
      "2021-11-04 12:31:40.939345: done, saving took 1.19 seconds\n",
      "2021-11-04 12:31:40.986151: This epoch took 326.097760 s\n",
      "\n",
      "2021-11-04 12:31:40.991241: \n",
      "epoch:  4\n",
      "2021-11-04 12:36:49.900253: train loss : -0.7074\n",
      "2021-11-04 12:37:10.951530: validation loss: -0.7580\n",
      "2021-11-04 12:37:10.957595: Average global foreground Dice: [0.7907]\n",
      "2021-11-04 12:37:10.963212: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 12:37:11.492703: lr: 0.009095\n",
      "2021-11-04 12:37:11.566043: saving checkpoint...\n",
      "2021-11-04 12:37:12.715841: done, saving took 1.22 seconds\n",
      "2021-11-04 12:37:12.759785: This epoch took 331.762645 s\n",
      "\n",
      "2021-11-04 12:37:12.765764: \n",
      "epoch:  5\n",
      "2021-11-04 12:42:18.610318: train loss : -0.7424\n",
      "2021-11-04 12:42:37.663034: validation loss: -0.7675\n",
      "2021-11-04 12:42:37.670028: Average global foreground Dice: [0.7989]\n",
      "2021-11-04 12:42:37.675902: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 12:42:38.186920: lr: 0.008913\n",
      "2021-11-04 12:42:38.259851: saving checkpoint...\n",
      "2021-11-04 12:42:39.305747: done, saving took 1.11 seconds\n",
      "2021-11-04 12:42:39.338503: This epoch took 326.566756 s\n",
      "\n",
      "2021-11-04 12:42:39.344207: \n",
      "epoch:  6\n",
      "2021-11-04 12:47:47.707608: train loss : -0.7587\n",
      "2021-11-04 12:48:06.949903: validation loss: -0.7865\n",
      "2021-11-04 12:48:06.958009: Average global foreground Dice: [0.8082]\n",
      "2021-11-04 12:48:06.963972: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 12:48:07.509530: lr: 0.008731\n",
      "2021-11-04 12:48:07.581454: saving checkpoint...\n",
      "2021-11-04 12:48:08.569387: done, saving took 1.05 seconds\n",
      "2021-11-04 12:48:08.600303: This epoch took 329.249856 s\n",
      "\n",
      "2021-11-04 12:48:08.606392: \n",
      "epoch:  7\n",
      "2021-11-04 12:53:18.849807: train loss : -0.7669\n",
      "2021-11-04 12:53:38.833831: validation loss: -0.7995\n",
      "2021-11-04 12:53:38.840236: Average global foreground Dice: [0.8186]\n",
      "2021-11-04 12:53:38.845710: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 12:53:39.366065: lr: 0.008548\n",
      "2021-11-04 12:53:39.439914: saving checkpoint...\n",
      "2021-11-04 12:53:40.457501: done, saving took 1.09 seconds\n",
      "2021-11-04 12:53:40.489707: This epoch took 331.878308 s\n",
      "\n",
      "2021-11-04 12:53:40.495912: \n",
      "epoch:  8\n",
      "2021-11-04 12:58:52.171113: train loss : -0.7831\n",
      "2021-11-04 12:59:12.877716: validation loss: -0.7964\n",
      "2021-11-04 12:59:12.883966: Average global foreground Dice: [0.8196]\n",
      "2021-11-04 12:59:12.890131: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 12:59:13.474862: lr: 0.008364\n",
      "2021-11-04 12:59:13.508192: saving checkpoint...\n",
      "2021-11-04 12:59:14.547230: done, saving took 1.07 seconds\n",
      "2021-11-04 12:59:14.574444: This epoch took 334.072992 s\n",
      "\n",
      "2021-11-04 12:59:14.580506: \n",
      "epoch:  9\n",
      "2021-11-04 13:04:22.618779: train loss : -0.7893\n",
      "2021-11-04 13:04:41.319842: validation loss: -0.7933\n",
      "2021-11-04 13:04:41.326600: Average global foreground Dice: [0.8133]\n",
      "2021-11-04 13:04:41.332909: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 13:04:41.877324: lr: 0.008181\n",
      "2021-11-04 13:04:41.911481: saving checkpoint...\n",
      "2021-11-04 13:04:42.855643: done, saving took 0.97 seconds\n",
      "2021-11-04 13:04:42.880625: This epoch took 328.294518 s\n",
      "\n",
      "2021-11-04 13:04:42.886884: \n",
      "epoch:  10\n",
      "2021-11-04 13:09:52.601970: train loss : -0.7932\n",
      "2021-11-04 13:10:13.029603: validation loss: -0.8145\n",
      "2021-11-04 13:10:13.036461: Average global foreground Dice: [0.8285]\n",
      "2021-11-04 13:10:13.042986: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 13:10:13.546335: lr: 0.007996\n",
      "2021-11-04 13:10:13.580962: saving checkpoint...\n",
      "2021-11-04 13:10:14.547662: done, saving took 0.99 seconds\n",
      "2021-11-04 13:10:14.575990: This epoch took 331.683073 s\n",
      "\n",
      "2021-11-04 13:10:14.581560: \n",
      "epoch:  11\n",
      "2021-11-04 13:15:26.651124: train loss : -0.8029\n",
      "2021-11-04 13:15:45.783457: validation loss: -0.8014\n",
      "2021-11-04 13:15:45.790939: Average global foreground Dice: [0.8171]\n",
      "2021-11-04 13:15:45.797202: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 13:15:46.298060: lr: 0.007811\n",
      "2021-11-04 13:15:46.333079: saving checkpoint...\n",
      "2021-11-04 13:15:47.317635: done, saving took 1.01 seconds\n",
      "2021-11-04 13:15:47.345537: This epoch took 332.757340 s\n",
      "\n",
      "2021-11-04 13:15:47.351919: \n",
      "epoch:  12\n",
      "2021-11-04 13:21:01.996223: train loss : -0.7995\n",
      "2021-11-04 13:21:23.472758: validation loss: -0.8092\n",
      "2021-11-04 13:21:23.480259: Average global foreground Dice: [0.8301]\n",
      "2021-11-04 13:21:23.487107: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 13:21:24.253060: lr: 0.007626\n",
      "2021-11-04 13:21:24.302438: saving checkpoint...\n",
      "2021-11-04 13:21:25.295200: done, saving took 1.04 seconds\n",
      "2021-11-04 13:21:25.322676: This epoch took 337.964535 s\n",
      "\n",
      "2021-11-04 13:21:25.328980: \n",
      "epoch:  13\n",
      "2021-11-04 13:26:34.383174: train loss : -0.8114\n",
      "2021-11-04 13:26:53.887614: validation loss: -0.8219\n",
      "2021-11-04 13:26:53.894971: Average global foreground Dice: [0.8372]\n",
      "2021-11-04 13:26:53.901546: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 13:26:54.408714: lr: 0.00744\n",
      "2021-11-04 13:26:54.442905: saving checkpoint...\n",
      "2021-11-04 13:26:55.433877: done, saving took 1.02 seconds\n",
      "2021-11-04 13:26:55.463009: This epoch took 330.128064 s\n",
      "\n",
      "2021-11-04 13:26:55.470677: \n",
      "epoch:  14\n",
      "2021-11-04 13:32:00.983075: train loss : -0.8135\n",
      "2021-11-04 13:32:21.583792: validation loss: -0.8146\n",
      "2021-11-04 13:32:21.592342: Average global foreground Dice: [0.8343]\n",
      "2021-11-04 13:32:21.599286: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 13:32:22.178258: lr: 0.007254\n",
      "2021-11-04 13:32:22.213900: saving checkpoint...\n",
      "2021-11-04 13:32:23.210571: done, saving took 1.03 seconds\n",
      "2021-11-04 13:32:23.240183: This epoch took 327.763582 s\n",
      "\n",
      "2021-11-04 13:32:23.247236: \n",
      "epoch:  15\n",
      "2021-11-04 13:37:35.566143: train loss : -0.8141\n",
      "2021-11-04 13:37:55.942389: validation loss: -0.8258\n",
      "2021-11-04 13:37:55.949942: Average global foreground Dice: [0.84]\n",
      "2021-11-04 13:37:55.958763: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 13:37:56.455132: lr: 0.007067\n",
      "2021-11-04 13:37:56.489445: saving checkpoint...\n",
      "2021-11-04 13:37:57.445284: done, saving took 0.98 seconds\n",
      "2021-11-04 13:37:57.470887: This epoch took 334.216637 s\n",
      "\n",
      "2021-11-04 13:37:57.476809: \n",
      "epoch:  16\n",
      "2021-11-04 13:43:06.888341: train loss : -0.8206\n",
      "2021-11-04 13:43:25.905583: validation loss: -0.8225\n",
      "2021-11-04 13:43:25.911155: Average global foreground Dice: [0.8297]\n",
      "2021-11-04 13:43:25.918692: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 13:43:26.415303: lr: 0.00688\n",
      "2021-11-04 13:43:26.448888: saving checkpoint...\n",
      "2021-11-04 13:43:27.406474: done, saving took 0.99 seconds\n",
      "2021-11-04 13:43:27.432965: This epoch took 329.951330 s\n",
      "\n",
      "2021-11-04 13:43:27.438296: \n",
      "epoch:  17\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-04 13:48:38.953362: train loss : -0.8205\n",
      "2021-11-04 13:48:57.606632: validation loss: -0.8160\n",
      "2021-11-04 13:48:57.613419: Average global foreground Dice: [0.8287]\n",
      "2021-11-04 13:48:57.619423: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 13:48:58.129359: lr: 0.006692\n",
      "2021-11-04 13:48:58.162101: saving checkpoint...\n",
      "2021-11-04 13:48:59.144885: done, saving took 1.01 seconds\n",
      "2021-11-04 13:48:59.173465: This epoch took 331.730366 s\n",
      "\n",
      "2021-11-04 13:48:59.178748: \n",
      "epoch:  18\n",
      "2021-11-04 13:54:05.600231: train loss : -0.8219\n",
      "2021-11-04 13:54:24.481220: validation loss: -0.8174\n",
      "2021-11-04 13:54:24.487031: Average global foreground Dice: [0.8277]\n",
      "2021-11-04 13:54:24.492314: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 13:54:24.995869: lr: 0.006504\n",
      "2021-11-04 13:54:25.030382: saving checkpoint...\n",
      "2021-11-04 13:54:26.032876: done, saving took 1.03 seconds\n",
      "2021-11-04 13:54:26.059627: This epoch took 326.876733 s\n",
      "\n",
      "2021-11-04 13:54:26.064823: \n",
      "epoch:  19\n",
      "2021-11-04 13:59:38.158364: train loss : -0.8224\n",
      "2021-11-04 13:59:57.342014: validation loss: -0.8147\n",
      "2021-11-04 13:59:57.347358: Average global foreground Dice: [0.8277]\n",
      "2021-11-04 13:59:57.351935: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 13:59:57.843137: lr: 0.006314\n",
      "2021-11-04 13:59:57.878348: saving checkpoint...\n",
      "2021-11-04 13:59:58.861030: done, saving took 1.01 seconds\n",
      "2021-11-04 13:59:58.886435: This epoch took 332.816185 s\n",
      "\n",
      "2021-11-04 13:59:58.891795: \n",
      "epoch:  20\n",
      "2021-11-04 14:05:07.173947: train loss : -0.8147\n",
      "2021-11-04 14:05:25.608085: validation loss: -0.8329\n",
      "2021-11-04 14:05:25.614896: Average global foreground Dice: [0.846]\n",
      "2021-11-04 14:05:25.620785: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 14:05:26.125146: lr: 0.006125\n",
      "2021-11-04 14:05:26.191766: saving checkpoint...\n",
      "2021-11-04 14:05:27.200769: done, saving took 1.07 seconds\n",
      "2021-11-04 14:05:27.241592: This epoch took 328.344672 s\n",
      "\n",
      "2021-11-04 14:05:27.247011: \n",
      "epoch:  21\n",
      "2021-11-04 14:10:33.785341: train loss : -0.8264\n",
      "2021-11-04 14:10:52.587092: validation loss: -0.8364\n",
      "2021-11-04 14:10:52.592473: Average global foreground Dice: [0.8461]\n",
      "2021-11-04 14:10:52.597806: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 14:10:53.097426: lr: 0.005934\n",
      "2021-11-04 14:10:53.132680: saving checkpoint...\n",
      "2021-11-04 14:10:54.109000: done, saving took 1.01 seconds\n",
      "2021-11-04 14:10:54.138397: This epoch took 326.885870 s\n",
      "\n",
      "2021-11-04 14:10:54.143528: \n",
      "epoch:  22\n",
      "2021-11-04 14:16:04.788208: train loss : -0.8295\n",
      "2021-11-04 14:16:25.517498: validation loss: -0.8264\n",
      "2021-11-04 14:16:25.524181: Average global foreground Dice: [0.8352]\n",
      "2021-11-04 14:16:25.530902: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 14:16:26.075434: lr: 0.005743\n",
      "2021-11-04 14:16:26.147700: saving checkpoint...\n",
      "2021-11-04 14:16:27.138191: done, saving took 1.06 seconds\n",
      "2021-11-04 14:16:27.168992: This epoch took 333.020830 s\n",
      "\n",
      "2021-11-04 14:16:27.173657: \n",
      "epoch:  23\n",
      "2021-11-04 14:21:35.293369: train loss : -0.8335\n",
      "2021-11-04 14:21:57.173918: validation loss: -0.8300\n",
      "2021-11-04 14:21:57.179332: Average global foreground Dice: [0.8405]\n",
      "2021-11-04 14:21:57.186574: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 14:21:57.747313: lr: 0.005551\n",
      "2021-11-04 14:21:57.817771: saving checkpoint...\n",
      "2021-11-04 14:21:58.817669: done, saving took 1.07 seconds\n",
      "2021-11-04 14:21:58.846897: This epoch took 331.667855 s\n",
      "\n",
      "2021-11-04 14:21:58.851707: \n",
      "epoch:  24\n",
      "2021-11-04 14:27:09.202108: train loss : -0.8338\n",
      "2021-11-04 14:27:31.063589: validation loss: -0.8342\n",
      "2021-11-04 14:27:31.073206: Average global foreground Dice: [0.8446]\n",
      "2021-11-04 14:27:31.078556: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 14:27:32.788052: lr: 0.005359\n",
      "2021-11-04 14:27:32.870278: saving checkpoint...\n",
      "2021-11-04 14:27:33.950738: done, saving took 1.16 seconds\n",
      "2021-11-04 14:27:33.986318: This epoch took 335.129678 s\n",
      "\n",
      "2021-11-04 14:27:33.992006: \n",
      "epoch:  25\n",
      "2021-11-04 14:32:46.090246: train loss : -0.8295\n",
      "2021-11-04 14:33:08.089338: validation loss: -0.8298\n",
      "2021-11-04 14:33:08.097334: Average global foreground Dice: [0.8422]\n",
      "2021-11-04 14:33:08.102069: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 14:33:09.768664: lr: 0.005166\n",
      "2021-11-04 14:33:09.851526: saving checkpoint...\n",
      "2021-11-04 14:33:11.005957: done, saving took 1.23 seconds\n",
      "2021-11-04 14:33:11.033986: This epoch took 337.036807 s\n",
      "\n",
      "2021-11-04 14:33:11.039060: \n",
      "epoch:  26\n",
      "2021-11-04 14:38:24.217541: train loss : -0.8377\n",
      "2021-11-04 14:38:45.367597: validation loss: -0.8377\n",
      "2021-11-04 14:38:45.374108: Average global foreground Dice: [0.8489]\n",
      "2021-11-04 14:38:45.380933: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 14:38:46.035593: lr: 0.004971\n",
      "2021-11-04 14:38:46.102902: saving checkpoint...\n",
      "2021-11-04 14:38:47.379135: done, saving took 1.34 seconds\n",
      "2021-11-04 14:38:47.402404: This epoch took 336.358492 s\n",
      "\n",
      "2021-11-04 14:38:47.408093: \n",
      "epoch:  27\n",
      "2021-11-04 14:43:55.975695: train loss : -0.8360\n",
      "2021-11-04 14:44:16.519361: validation loss: -0.8317\n",
      "2021-11-04 14:44:16.524208: Average global foreground Dice: [0.8368]\n",
      "2021-11-04 14:44:16.529100: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 14:44:17.016312: lr: 0.004776\n",
      "2021-11-04 14:44:17.049602: saving checkpoint...\n",
      "2021-11-04 14:44:18.010705: done, saving took 0.99 seconds\n",
      "2021-11-04 14:44:18.034653: This epoch took 330.621715 s\n",
      "\n",
      "2021-11-04 14:44:18.039502: \n",
      "epoch:  28\n",
      "2021-11-04 14:49:27.359168: train loss : -0.8352\n",
      "2021-11-04 14:49:47.850030: validation loss: -0.8299\n",
      "2021-11-04 14:49:47.855840: Average global foreground Dice: [0.8387]\n",
      "2021-11-04 14:49:47.860616: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 14:49:48.348074: lr: 0.004581\n",
      "2021-11-04 14:49:48.382172: saving checkpoint...\n",
      "2021-11-04 14:49:49.359570: done, saving took 1.01 seconds\n",
      "2021-11-04 14:49:49.386022: This epoch took 331.341297 s\n",
      "\n",
      "2021-11-04 14:49:49.390228: \n",
      "epoch:  29\n",
      "2021-11-04 14:54:58.441645: train loss : -0.8394\n",
      "2021-11-04 14:55:16.817184: validation loss: -0.8345\n",
      "2021-11-04 14:55:16.823157: Average global foreground Dice: [0.8428]\n",
      "2021-11-04 14:55:16.828290: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 14:55:17.346779: lr: 0.004384\n",
      "2021-11-04 14:55:17.380580: saving checkpoint...\n",
      "2021-11-04 14:55:18.340777: done, saving took 0.99 seconds\n",
      "2021-11-04 14:55:18.364749: This epoch took 328.969311 s\n",
      "\n",
      "2021-11-04 14:55:18.368753: \n",
      "epoch:  30\n",
      "2021-11-04 15:00:25.750565: train loss : -0.8407\n",
      "2021-11-04 15:00:44.766137: validation loss: -0.8333\n",
      "2021-11-04 15:00:44.771867: Average global foreground Dice: [0.8425]\n",
      "2021-11-04 15:00:44.776720: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 15:00:45.316898: lr: 0.004186\n",
      "2021-11-04 15:00:45.381440: saving checkpoint...\n",
      "2021-11-04 15:00:46.380517: done, saving took 1.06 seconds\n",
      "2021-11-04 15:00:46.408676: This epoch took 328.034868 s\n",
      "\n",
      "2021-11-04 15:00:46.413529: \n",
      "epoch:  31\n",
      "2021-11-04 15:05:54.260574: train loss : -0.8453\n",
      "2021-11-04 15:06:13.443434: validation loss: -0.8323\n",
      "2021-11-04 15:06:13.451257: Average global foreground Dice: [0.8388]\n",
      "2021-11-04 15:06:13.456766: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 15:06:13.974416: lr: 0.003987\n",
      "2021-11-04 15:06:14.038334: saving checkpoint...\n",
      "2021-11-04 15:06:15.027905: done, saving took 1.05 seconds\n",
      "2021-11-04 15:06:15.058559: This epoch took 328.640050 s\n",
      "\n",
      "2021-11-04 15:06:15.063962: \n",
      "epoch:  32\n",
      "2021-11-04 15:11:28.050553: train loss : -0.8456\n",
      "2021-11-04 15:11:48.420417: validation loss: -0.8355\n",
      "2021-11-04 15:11:48.427052: Average global foreground Dice: [0.8476]\n",
      "2021-11-04 15:11:48.432680: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 15:11:48.935527: lr: 0.003787\n",
      "2021-11-04 15:11:48.998955: saving checkpoint...\n",
      "2021-11-04 15:11:50.022615: done, saving took 1.08 seconds\n",
      "2021-11-04 15:11:50.054835: This epoch took 334.985659 s\n",
      "\n",
      "2021-11-04 15:11:50.060433: \n",
      "epoch:  33\n",
      "2021-11-04 15:17:02.695759: train loss : -0.8361\n",
      "2021-11-04 15:17:24.262700: validation loss: -0.8301\n",
      "2021-11-04 15:17:24.268509: Average global foreground Dice: [0.8409]\n",
      "2021-11-04 15:17:24.272984: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 15:17:25.023312: lr: 0.003586\n",
      "2021-11-04 15:17:25.056782: saving checkpoint...\n",
      "2021-11-04 15:17:26.011612: done, saving took 0.98 seconds\n",
      "2021-11-04 15:17:26.036606: This epoch took 335.970668 s\n",
      "\n",
      "2021-11-04 15:17:26.041349: \n",
      "epoch:  34\n",
      "2021-11-04 15:22:34.506198: train loss : -0.8425\n",
      "2021-11-04 15:22:54.643912: validation loss: -0.8366\n",
      "2021-11-04 15:22:54.649611: Average global foreground Dice: [0.843]\n",
      "2021-11-04 15:22:54.655186: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 15:22:55.163993: lr: 0.003384\n",
      "2021-11-04 15:22:55.198050: saving checkpoint...\n",
      "2021-11-04 15:22:56.158534: done, saving took 0.99 seconds\n",
      "2021-11-04 15:22:56.184278: This epoch took 330.137492 s\n",
      "\n",
      "2021-11-04 15:22:56.188552: \n",
      "epoch:  35\n",
      "2021-11-04 15:28:08.799526: train loss : -0.8449\n",
      "2021-11-04 15:28:29.829472: validation loss: -0.8375\n",
      "2021-11-04 15:28:29.836122: Average global foreground Dice: [0.843]\n",
      "2021-11-04 15:28:29.841351: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 15:28:30.337866: lr: 0.00318\n",
      "2021-11-04 15:28:30.371215: saving checkpoint...\n",
      "2021-11-04 15:28:31.322669: done, saving took 0.98 seconds\n",
      "2021-11-04 15:28:31.345820: This epoch took 335.152873 s\n",
      "\n",
      "2021-11-04 15:28:31.351201: \n",
      "epoch:  36\n",
      "2021-11-04 15:33:49.797889: train loss : -0.8451\n",
      "2021-11-04 15:34:12.162658: validation loss: -0.8442\n",
      "2021-11-04 15:34:12.177392: Average global foreground Dice: [0.856]\n",
      "2021-11-04 15:34:12.183305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 15:34:14.559324: lr: 0.002975\n",
      "2021-11-04 15:34:14.642422: saving checkpoint...\n",
      "2021-11-04 15:34:16.285173: done, saving took 1.72 seconds\n",
      "2021-11-04 15:34:16.344406: This epoch took 344.987947 s\n",
      "\n",
      "2021-11-04 15:34:16.350226: \n",
      "epoch:  37\n",
      "2021-11-04 15:39:27.203372: train loss : -0.8479\n",
      "2021-11-04 15:39:47.584499: validation loss: -0.8404\n",
      "2021-11-04 15:39:47.591626: Average global foreground Dice: [0.8485]\n",
      "2021-11-04 15:39:47.595896: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 15:39:48.078895: lr: 0.002768\n",
      "2021-11-04 15:39:48.134746: saving checkpoint...\n",
      "2021-11-04 15:39:49.111326: done, saving took 1.03 seconds\n",
      "2021-11-04 15:39:49.141957: This epoch took 332.786626 s\n",
      "\n",
      "2021-11-04 15:39:49.147127: \n",
      "epoch:  38\n",
      "2021-11-04 15:44:58.798346: train loss : -0.8466\n",
      "2021-11-04 15:45:17.313111: validation loss: -0.8453\n",
      "2021-11-04 15:45:17.317962: Average global foreground Dice: [0.8555]\n",
      "2021-11-04 15:45:17.323282: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 15:45:17.837276: lr: 0.00256\n",
      "2021-11-04 15:45:17.894881: saving checkpoint...\n",
      "2021-11-04 15:45:18.956293: done, saving took 1.11 seconds\n",
      "2021-11-04 15:45:18.986026: This epoch took 329.833762 s\n",
      "\n",
      "2021-11-04 15:45:18.990858: \n",
      "epoch:  39\n",
      "2021-11-04 15:50:27.067694: train loss : -0.8519\n",
      "2021-11-04 15:50:45.442744: validation loss: -0.8276\n",
      "2021-11-04 15:50:45.448850: Average global foreground Dice: [0.835]\n",
      "2021-11-04 15:50:45.453139: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 15:50:45.946734: lr: 0.002349\n",
      "2021-11-04 15:50:45.980565: saving checkpoint...\n",
      "2021-11-04 15:50:46.968377: done, saving took 1.02 seconds\n",
      "2021-11-04 15:50:46.994050: This epoch took 327.998183 s\n",
      "\n",
      "2021-11-04 15:50:47.000095: \n",
      "epoch:  40\n",
      "2021-11-04 15:55:55.630690: train loss : -0.8506\n",
      "2021-11-04 15:56:13.882825: validation loss: -0.8236\n",
      "2021-11-04 15:56:13.889152: Average global foreground Dice: [0.8288]\n",
      "2021-11-04 15:56:13.894480: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 15:56:14.378271: lr: 0.002137\n",
      "2021-11-04 15:56:14.411821: saving checkpoint...\n",
      "2021-11-04 15:56:15.440392: done, saving took 1.06 seconds\n",
      "2021-11-04 15:56:15.466068: This epoch took 328.459712 s\n",
      "\n",
      "2021-11-04 15:56:15.471487: \n",
      "epoch:  41\n",
      "2021-11-04 16:01:27.083171: train loss : -0.8512\n",
      "2021-11-04 16:01:45.487970: validation loss: -0.8365\n",
      "2021-11-04 16:01:45.494627: Average global foreground Dice: [0.8479]\n",
      "2021-11-04 16:01:45.498955: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 16:01:45.985552: lr: 0.001922\n",
      "2021-11-04 16:01:46.019934: saving checkpoint...\n",
      "2021-11-04 16:01:46.982114: done, saving took 0.99 seconds\n",
      "2021-11-04 16:01:47.009388: This epoch took 331.532883 s\n",
      "\n",
      "2021-11-04 16:01:47.013966: \n",
      "epoch:  42\n",
      "2021-11-04 16:06:53.933127: train loss : -0.8538\n",
      "2021-11-04 16:07:12.308764: validation loss: -0.8454\n",
      "2021-11-04 16:07:12.314050: Average global foreground Dice: [0.8559]\n",
      "2021-11-04 16:07:12.319048: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 16:07:12.821856: lr: 0.001704\n",
      "2021-11-04 16:07:12.856163: saving checkpoint...\n",
      "2021-11-04 16:07:13.824438: done, saving took 1.00 seconds\n",
      "2021-11-04 16:07:13.850852: This epoch took 326.831635 s\n",
      "\n",
      "2021-11-04 16:07:13.855670: \n",
      "epoch:  43\n",
      "2021-11-04 16:12:25.194383: train loss : -0.8534\n",
      "2021-11-04 16:12:45.769906: validation loss: -0.8400\n",
      "2021-11-04 16:12:45.775402: Average global foreground Dice: [0.8503]\n",
      "2021-11-04 16:12:45.780330: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 16:12:46.269638: lr: 0.001483\n",
      "2021-11-04 16:12:46.303333: saving checkpoint...\n",
      "2021-11-04 16:12:47.275541: done, saving took 1.00 seconds\n",
      "2021-11-04 16:12:47.298293: This epoch took 333.438050 s\n",
      "\n",
      "2021-11-04 16:12:47.303763: \n",
      "epoch:  44\n",
      "2021-11-04 16:17:59.050405: train loss : -0.8560\n",
      "2021-11-04 16:18:20.658404: validation loss: -0.8392\n",
      "2021-11-04 16:18:20.685939: Average global foreground Dice: [0.8453]\n",
      "2021-11-04 16:18:20.691455: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 16:18:23.187247: lr: 0.001259\n",
      "2021-11-04 16:18:23.268316: saving checkpoint...\n",
      "2021-11-04 16:18:24.755124: done, saving took 1.56 seconds\n",
      "2021-11-04 16:18:24.792932: This epoch took 337.482449 s\n",
      "\n",
      "2021-11-04 16:18:24.798278: \n",
      "epoch:  45\n",
      "2021-11-04 16:23:32.237728: train loss : -0.8575\n",
      "2021-11-04 16:23:51.699925: validation loss: -0.8418\n",
      "2021-11-04 16:23:51.705993: Average global foreground Dice: [0.8457]\n",
      "2021-11-04 16:23:51.711508: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 16:23:52.236415: lr: 0.00103\n",
      "2021-11-04 16:23:52.297132: saving checkpoint...\n",
      "2021-11-04 16:23:53.281406: done, saving took 1.04 seconds\n",
      "2021-11-04 16:23:53.309962: This epoch took 328.504867 s\n",
      "\n",
      "2021-11-04 16:23:53.315134: \n",
      "epoch:  46\n",
      "2021-11-04 16:29:02.786575: train loss : -0.8549\n",
      "2021-11-04 16:29:22.049306: validation loss: -0.8441\n",
      "2021-11-04 16:29:22.055782: Average global foreground Dice: [0.8501]\n",
      "2021-11-04 16:29:22.061442: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 16:29:22.559387: lr: 0.000795\n",
      "2021-11-04 16:29:22.610778: saving checkpoint...\n",
      "2021-11-04 16:29:23.581661: done, saving took 1.02 seconds\n",
      "2021-11-04 16:29:23.613518: This epoch took 330.291473 s\n",
      "\n",
      "2021-11-04 16:29:23.619213: \n",
      "epoch:  47\n",
      "2021-11-04 16:34:38.075407: train loss : -0.8587\n",
      "2021-11-04 16:35:00.707364: validation loss: -0.8378\n",
      "2021-11-04 16:35:00.757690: Average global foreground Dice: [0.845]\n",
      "2021-11-04 16:35:00.763118: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 16:35:03.010937: lr: 0.000552\n",
      "2021-11-04 16:35:03.167602: saving checkpoint...\n",
      "2021-11-04 16:35:04.799595: done, saving took 1.76 seconds\n",
      "2021-11-04 16:35:04.881221: This epoch took 341.256772 s\n",
      "\n",
      "2021-11-04 16:35:04.885918: \n",
      "epoch:  48\n",
      "2021-11-04 16:40:16.169642: train loss : -0.8587\n",
      "2021-11-04 16:40:35.563408: validation loss: -0.8478\n",
      "2021-11-04 16:40:35.569251: Average global foreground Dice: [0.8515]\n",
      "2021-11-04 16:40:35.574203: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 16:40:36.071257: lr: 0.000296\n",
      "2021-11-04 16:40:36.104947: saving checkpoint...\n",
      "2021-11-04 16:40:37.045936: done, saving took 0.97 seconds\n",
      "2021-11-04 16:40:37.071316: This epoch took 332.180609 s\n",
      "\n",
      "2021-11-04 16:40:37.076485: \n",
      "epoch:  49\n",
      "2021-11-04 16:45:50.093207: train loss : -0.8573\n",
      "2021-11-04 16:46:08.854623: validation loss: -0.8501\n",
      "2021-11-04 16:46:08.861456: Average global foreground Dice: [0.8588]\n",
      "2021-11-04 16:46:08.866903: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 16:46:09.360073: lr: 0.0\n",
      "2021-11-04 16:46:09.365541: saving scheduled checkpoint file...\n",
      "2021-11-04 16:46:09.399408: saving checkpoint...\n",
      "2021-11-04 16:46:10.222051: done, saving took 0.85 seconds\n",
      "2021-11-04 16:46:10.242115: done\n",
      "2021-11-04 16:46:10.275812: saving checkpoint...\n",
      "2021-11-04 16:46:11.215702: done, saving took 0.97 seconds\n",
      "2021-11-04 16:46:11.241199: This epoch took 334.159787 s\n",
      "\n",
      "2021-11-04 16:46:11.275584: saving checkpoint...\n",
      "2021-11-04 16:46:12.120561: done, saving took 0.87 seconds\n",
      "23090567_20160819 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150401 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130213 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120627 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090590_20121212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160706 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090599_20140701 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130225 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090604_20140303 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090615_20140403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090617_20140211 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120406 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160111 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130213 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090631_20130128 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090634_20150409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-04 16:49:40.888983: finished prediction\n",
      "2021-11-04 16:49:40.894773: evaluation of raw predictions\n",
      "2021-11-04 16:49:42.324249: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8522344651280808\n",
      "after:  0.8522344651280808\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_Dice.nnUNetTrainerV2_Loss_Dice'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-04 16:49:51.368149: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-04 16:49:51.384226: The split file contains 5 splits.\n",
      "2021-11-04 16:49:51.391182: Desired fold for training: 2\n",
      "2021-11-04 16:49:51.396054: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-04 16:49:55.756159: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-04 16:50:22.888070: Unable to plot network architecture:\n",
      "2021-11-04 16:50:22.894003: No module named 'hiddenlayer'\n",
      "2021-11-04 16:50:22.898702: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-04 16:50:22.903206: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-04 16:50:22.911720: \n",
      "\n",
      "2021-11-04 16:50:22.948710: \n",
      "epoch:  0\n",
      "2021-11-04 16:56:00.754172: train loss : -0.0067\n",
      "2021-11-04 16:56:21.054164: validation loss: -0.0119\n",
      "2021-11-04 16:56:21.060098: Average global foreground Dice: [0.0302]\n",
      "2021-11-04 16:56:21.064900: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 16:56:21.487846: lr: 0.00982\n",
      "2021-11-04 16:56:21.493808: This epoch took 358.539779 s\n",
      "\n",
      "2021-11-04 16:56:21.497977: \n",
      "epoch:  1\n",
      "2021-11-04 17:01:33.504543: train loss : -0.2100\n",
      "2021-11-04 17:01:52.228818: validation loss: -0.4978\n",
      "2021-11-04 17:01:52.234167: Average global foreground Dice: [0.6337]\n",
      "2021-11-04 17:01:52.238568: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 17:01:52.744271: lr: 0.009639\n",
      "2021-11-04 17:01:52.828243: saving checkpoint...\n",
      "2021-11-04 17:01:53.645997: done, saving took 0.90 seconds\n",
      "2021-11-04 17:01:53.675342: This epoch took 332.172549 s\n",
      "\n",
      "2021-11-04 17:01:53.680772: \n",
      "epoch:  2\n",
      "2021-11-04 17:07:03.651408: train loss : -0.5478\n",
      "2021-11-04 17:07:22.843718: validation loss: -0.5957\n",
      "2021-11-04 17:07:22.850390: Average global foreground Dice: [0.7278]\n",
      "2021-11-04 17:07:22.854809: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 17:07:23.380506: lr: 0.009458\n",
      "2021-11-04 17:07:23.462518: saving checkpoint...\n",
      "2021-11-04 17:07:24.460993: done, saving took 1.08 seconds\n",
      "2021-11-04 17:07:24.488367: This epoch took 330.802260 s\n",
      "\n",
      "2021-11-04 17:07:24.492886: \n",
      "epoch:  3\n",
      "2021-11-04 17:12:34.235129: train loss : -0.6559\n",
      "2021-11-04 17:12:53.125111: validation loss: -0.7310\n",
      "2021-11-04 17:12:53.130575: Average global foreground Dice: [0.773]\n",
      "2021-11-04 17:12:53.135389: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 17:12:53.661532: lr: 0.009277\n",
      "2021-11-04 17:12:53.744716: saving checkpoint...\n",
      "2021-11-04 17:12:54.682487: done, saving took 1.02 seconds\n",
      "2021-11-04 17:12:54.716359: This epoch took 330.217831 s\n",
      "\n",
      "2021-11-04 17:12:54.721319: \n",
      "epoch:  4\n",
      "2021-11-04 17:18:10.265444: train loss : -0.7157\n",
      "2021-11-04 17:18:29.329109: validation loss: -0.7298\n",
      "2021-11-04 17:18:29.335451: Average global foreground Dice: [0.7735]\n",
      "2021-11-04 17:18:29.339606: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 17:18:29.869364: lr: 0.009095\n",
      "2021-11-04 17:18:29.951155: saving checkpoint...\n",
      "2021-11-04 17:18:30.891062: done, saving took 1.02 seconds\n",
      "2021-11-04 17:18:30.925229: This epoch took 336.200075 s\n",
      "\n",
      "2021-11-04 17:18:30.930442: \n",
      "epoch:  5\n",
      "2021-11-04 17:23:39.908023: train loss : -0.7369\n",
      "2021-11-04 17:23:58.702157: validation loss: -0.7471\n",
      "2021-11-04 17:23:58.707982: Average global foreground Dice: [0.7847]\n",
      "2021-11-04 17:23:58.712523: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 17:23:59.239042: lr: 0.008913\n",
      "2021-11-04 17:23:59.322351: saving checkpoint...\n",
      "2021-11-04 17:24:00.273764: done, saving took 1.03 seconds\n",
      "2021-11-04 17:24:00.297159: This epoch took 329.361079 s\n",
      "\n",
      "2021-11-04 17:24:00.302149: \n",
      "epoch:  6\n",
      "2021-11-04 17:29:12.757385: train loss : -0.7658\n",
      "2021-11-04 17:29:33.390860: validation loss: -0.7876\n",
      "2021-11-04 17:29:33.396644: Average global foreground Dice: [0.8168]\n",
      "2021-11-04 17:29:33.401803: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 17:29:33.902501: lr: 0.008731\n",
      "2021-11-04 17:29:33.953522: saving checkpoint...\n",
      "2021-11-04 17:29:34.909650: done, saving took 1.00 seconds\n",
      "2021-11-04 17:29:34.933962: This epoch took 334.626242 s\n",
      "\n",
      "2021-11-04 17:29:34.938624: \n",
      "epoch:  7\n",
      "2021-11-04 17:34:43.850506: train loss : -0.7820\n",
      "2021-11-04 17:35:03.322206: validation loss: -0.7800\n",
      "2021-11-04 17:35:03.326897: Average global foreground Dice: [0.8104]\n",
      "2021-11-04 17:35:03.331230: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 17:35:03.873659: lr: 0.008548\n",
      "2021-11-04 17:35:03.937481: saving checkpoint...\n",
      "2021-11-04 17:35:04.898065: done, saving took 1.02 seconds\n",
      "2021-11-04 17:35:04.921898: This epoch took 329.978708 s\n",
      "\n",
      "2021-11-04 17:35:04.926711: \n",
      "epoch:  8\n",
      "2021-11-04 17:40:17.082619: train loss : -0.7837\n",
      "2021-11-04 17:40:35.531540: validation loss: -0.7994\n",
      "2021-11-04 17:40:35.537222: Average global foreground Dice: [0.8232]\n",
      "2021-11-04 17:40:35.542428: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 17:40:36.123586: lr: 0.008364\n",
      "2021-11-04 17:40:36.156542: saving checkpoint...\n",
      "2021-11-04 17:40:37.137898: done, saving took 1.01 seconds\n",
      "2021-11-04 17:40:37.165631: This epoch took 332.235479 s\n",
      "\n",
      "2021-11-04 17:40:37.171531: \n",
      "epoch:  9\n",
      "2021-11-04 17:45:53.260776: train loss : -0.7896\n",
      "2021-11-04 17:46:14.610249: validation loss: -0.7730\n",
      "2021-11-04 17:46:14.615429: Average global foreground Dice: [0.8012]\n",
      "2021-11-04 17:46:14.620539: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 17:46:15.127401: lr: 0.008181\n",
      "2021-11-04 17:46:15.160830: saving checkpoint...\n",
      "2021-11-04 17:46:16.290729: done, saving took 1.16 seconds\n",
      "2021-11-04 17:46:16.317832: This epoch took 339.141039 s\n",
      "\n",
      "2021-11-04 17:46:16.322697: \n",
      "epoch:  10\n",
      "2021-11-04 17:51:30.006169: train loss : -0.7981\n",
      "2021-11-04 17:51:49.824484: validation loss: -0.8091\n",
      "2021-11-04 17:51:49.830606: Average global foreground Dice: [0.8353]\n",
      "2021-11-04 17:51:49.836076: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 17:51:50.334989: lr: 0.007996\n",
      "2021-11-04 17:51:50.369359: saving checkpoint...\n",
      "2021-11-04 17:51:51.317968: done, saving took 0.98 seconds\n",
      "2021-11-04 17:51:51.344725: This epoch took 335.016590 s\n",
      "\n",
      "2021-11-04 17:51:51.349930: \n",
      "epoch:  11\n",
      "2021-11-04 17:57:03.376639: train loss : -0.8089\n",
      "2021-11-04 17:57:22.725247: validation loss: -0.7940\n",
      "2021-11-04 17:57:22.731523: Average global foreground Dice: [0.8202]\n",
      "2021-11-04 17:57:22.737552: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 17:57:23.246258: lr: 0.007811\n",
      "2021-11-04 17:57:23.286714: saving checkpoint...\n",
      "2021-11-04 17:57:24.248795: done, saving took 0.99 seconds\n",
      "2021-11-04 17:57:24.277327: This epoch took 332.921830 s\n",
      "\n",
      "2021-11-04 17:57:24.283154: \n",
      "epoch:  12\n",
      "2021-11-04 18:02:35.060193: train loss : -0.8080\n",
      "2021-11-04 18:02:56.290495: validation loss: -0.8053\n",
      "2021-11-04 18:02:56.296576: Average global foreground Dice: [0.827]\n",
      "2021-11-04 18:02:56.302023: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 18:02:56.881602: lr: 0.007626\n",
      "2021-11-04 18:02:56.943686: saving checkpoint...\n",
      "2021-11-04 18:02:57.997659: done, saving took 1.11 seconds\n",
      "2021-11-04 18:02:58.025913: This epoch took 333.736452 s\n",
      "\n",
      "2021-11-04 18:02:58.031044: \n",
      "epoch:  13\n",
      "2021-11-04 18:08:13.194458: train loss : -0.8166\n",
      "2021-11-04 18:08:31.963276: validation loss: -0.8195\n",
      "2021-11-04 18:08:31.969394: Average global foreground Dice: [0.8372]\n",
      "2021-11-04 18:08:31.974715: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 18:08:32.494898: lr: 0.00744\n",
      "2021-11-04 18:08:32.555146: saving checkpoint...\n",
      "2021-11-04 18:08:33.524494: done, saving took 1.02 seconds\n",
      "2021-11-04 18:08:33.555657: This epoch took 335.519619 s\n",
      "\n",
      "2021-11-04 18:08:33.561401: \n",
      "epoch:  14\n",
      "2021-11-04 18:13:45.951544: train loss : -0.8172\n",
      "2021-11-04 18:14:06.018885: validation loss: -0.8041\n",
      "2021-11-04 18:14:06.025264: Average global foreground Dice: [0.8259]\n",
      "2021-11-04 18:14:06.031283: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 18:14:06.629167: lr: 0.007254\n",
      "2021-11-04 18:14:06.662911: saving checkpoint...\n",
      "2021-11-04 18:14:07.624960: done, saving took 0.99 seconds\n",
      "2021-11-04 18:14:07.650232: This epoch took 334.083072 s\n",
      "\n",
      "2021-11-04 18:14:07.655661: \n",
      "epoch:  15\n",
      "2021-11-04 18:19:17.690755: train loss : -0.8259\n",
      "2021-11-04 18:19:37.414819: validation loss: -0.8054\n",
      "2021-11-04 18:19:37.421792: Average global foreground Dice: [0.8301]\n",
      "2021-11-04 18:19:37.427562: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 18:19:37.941830: lr: 0.007067\n",
      "2021-11-04 18:19:37.975024: saving checkpoint...\n",
      "2021-11-04 18:19:38.939102: done, saving took 0.99 seconds\n",
      "2021-11-04 18:19:38.964931: This epoch took 331.304805 s\n",
      "\n",
      "2021-11-04 18:19:38.970345: \n",
      "epoch:  16\n",
      "2021-11-04 18:24:51.051010: train loss : -0.8240\n",
      "2021-11-04 18:25:11.939270: validation loss: -0.8125\n",
      "2021-11-04 18:25:11.945889: Average global foreground Dice: [0.8308]\n",
      "2021-11-04 18:25:11.951399: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 18:25:12.505096: lr: 0.00688\n",
      "2021-11-04 18:25:12.539971: saving checkpoint...\n",
      "2021-11-04 18:25:13.502165: done, saving took 0.99 seconds\n",
      "2021-11-04 18:25:13.525880: This epoch took 334.550189 s\n",
      "\n",
      "2021-11-04 18:25:13.531378: \n",
      "epoch:  17\n",
      "2021-11-04 18:30:28.735127: train loss : -0.8206\n",
      "2021-11-04 18:30:47.744160: validation loss: -0.8142\n",
      "2021-11-04 18:30:47.750893: Average global foreground Dice: [0.8371]\n",
      "2021-11-04 18:30:47.756669: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 18:30:48.260886: lr: 0.006692\n",
      "2021-11-04 18:30:48.295973: saving checkpoint...\n",
      "2021-11-04 18:30:49.217118: done, saving took 0.95 seconds\n",
      "2021-11-04 18:30:49.241773: This epoch took 335.705467 s\n",
      "\n",
      "2021-11-04 18:30:49.247018: \n",
      "epoch:  18\n",
      "2021-11-04 18:36:05.188531: train loss : -0.8299\n",
      "2021-11-04 18:36:25.929835: validation loss: -0.8323\n",
      "2021-11-04 18:36:25.937103: Average global foreground Dice: [0.8463]\n",
      "2021-11-04 18:36:25.942231: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 18:36:26.450434: lr: 0.006504\n",
      "2021-11-04 18:36:26.484306: saving checkpoint...\n",
      "2021-11-04 18:36:27.454832: done, saving took 1.00 seconds\n",
      "2021-11-04 18:36:27.478965: This epoch took 338.227088 s\n",
      "\n",
      "2021-11-04 18:36:27.485064: \n",
      "epoch:  19\n",
      "2021-11-04 18:41:39.207361: train loss : -0.8329\n",
      "2021-11-04 18:41:57.684930: validation loss: -0.8261\n",
      "2021-11-04 18:41:57.690321: Average global foreground Dice: [0.8421]\n",
      "2021-11-04 18:41:57.695289: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 18:41:58.202626: lr: 0.006314\n",
      "2021-11-04 18:41:58.236718: saving checkpoint...\n",
      "2021-11-04 18:41:59.186650: done, saving took 0.98 seconds\n",
      "2021-11-04 18:41:59.210887: This epoch took 331.720819 s\n",
      "\n",
      "2021-11-04 18:41:59.215689: \n",
      "epoch:  20\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-04 18:47:09.709415: train loss : -0.8350\n",
      "2021-11-04 18:47:29.317642: validation loss: -0.8106\n",
      "2021-11-04 18:47:29.325408: Average global foreground Dice: [0.833]\n",
      "2021-11-04 18:47:29.331041: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 18:47:29.835872: lr: 0.006125\n",
      "2021-11-04 18:47:29.869934: saving checkpoint...\n",
      "2021-11-04 18:47:30.901749: done, saving took 1.06 seconds\n",
      "2021-11-04 18:47:30.932346: This epoch took 331.711447 s\n",
      "\n",
      "2021-11-04 18:47:30.938076: \n",
      "epoch:  21\n",
      "2021-11-04 18:52:45.497870: train loss : -0.8344\n",
      "2021-11-04 18:53:07.509554: validation loss: -0.8267\n",
      "2021-11-04 18:53:07.573564: Average global foreground Dice: [0.8462]\n",
      "2021-11-04 18:53:07.578641: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 18:53:08.915982: lr: 0.005934\n",
      "2021-11-04 18:53:08.967839: saving checkpoint...\n",
      "2021-11-04 18:53:10.016718: done, saving took 1.08 seconds\n",
      "2021-11-04 18:53:10.043890: This epoch took 339.101149 s\n",
      "\n",
      "2021-11-04 18:53:10.049013: \n",
      "epoch:  22\n",
      "2021-11-04 18:58:22.339741: train loss : -0.8296\n",
      "2021-11-04 18:58:40.869469: validation loss: -0.8251\n",
      "2021-11-04 18:58:40.877669: Average global foreground Dice: [0.8386]\n",
      "2021-11-04 18:58:40.883448: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 18:58:41.381152: lr: 0.005743\n",
      "2021-11-04 18:58:41.416011: saving checkpoint...\n",
      "2021-11-04 18:58:42.369806: done, saving took 0.98 seconds\n",
      "2021-11-04 18:58:42.396284: This epoch took 332.341862 s\n",
      "\n",
      "2021-11-04 18:58:42.402276: \n",
      "epoch:  23\n",
      "2021-11-04 19:03:56.484102: train loss : -0.8356\n",
      "2021-11-04 19:04:18.200886: validation loss: -0.8233\n",
      "2021-11-04 19:04:18.237825: Average global foreground Dice: [0.8441]\n",
      "2021-11-04 19:04:18.243716: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 19:04:20.570384: lr: 0.005551\n",
      "2021-11-04 19:04:20.646843: saving checkpoint...\n",
      "2021-11-04 19:04:22.098775: done, saving took 1.52 seconds\n",
      "2021-11-04 19:04:22.150455: This epoch took 339.743025 s\n",
      "\n",
      "2021-11-04 19:04:22.155689: \n",
      "epoch:  24\n",
      "2021-11-04 19:09:34.156123: train loss : -0.8359\n",
      "2021-11-04 19:09:53.166707: validation loss: -0.8277\n",
      "2021-11-04 19:09:53.173595: Average global foreground Dice: [0.8451]\n",
      "2021-11-04 19:09:53.179452: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 19:09:53.682916: lr: 0.005359\n",
      "2021-11-04 19:09:53.719530: saving checkpoint...\n",
      "2021-11-04 19:09:54.681550: done, saving took 0.99 seconds\n",
      "2021-11-04 19:09:54.708477: This epoch took 332.547630 s\n",
      "\n",
      "2021-11-04 19:09:54.714669: \n",
      "epoch:  25\n",
      "2021-11-04 19:15:07.585056: train loss : -0.8319\n",
      "2021-11-04 19:15:26.371830: validation loss: -0.8332\n",
      "2021-11-04 19:15:26.377775: Average global foreground Dice: [0.8483]\n",
      "2021-11-04 19:15:26.382407: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 19:15:26.895595: lr: 0.005166\n",
      "2021-11-04 19:15:26.958678: saving checkpoint...\n",
      "2021-11-04 19:15:27.942124: done, saving took 1.04 seconds\n",
      "2021-11-04 19:15:27.973684: This epoch took 333.252984 s\n",
      "\n",
      "2021-11-04 19:15:27.979396: \n",
      "epoch:  26\n",
      "2021-11-04 19:20:37.962071: train loss : -0.8368\n",
      "2021-11-04 19:20:58.052951: validation loss: -0.8090\n",
      "2021-11-04 19:20:58.059744: Average global foreground Dice: [0.8303]\n",
      "2021-11-04 19:20:58.064893: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 19:20:58.581595: lr: 0.004971\n",
      "2021-11-04 19:20:58.646966: saving checkpoint...\n",
      "2021-11-04 19:20:59.659225: done, saving took 1.07 seconds\n",
      "2021-11-04 19:20:59.688078: This epoch took 331.704038 s\n",
      "\n",
      "2021-11-04 19:20:59.693341: \n",
      "epoch:  27\n",
      "2021-11-04 19:26:12.485107: train loss : -0.8393\n",
      "2021-11-04 19:26:30.888782: validation loss: -0.8307\n",
      "2021-11-04 19:26:30.893790: Average global foreground Dice: [0.8455]\n",
      "2021-11-04 19:26:30.899246: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 19:26:31.402942: lr: 0.004776\n",
      "2021-11-04 19:26:31.436599: saving checkpoint...\n",
      "2021-11-04 19:26:32.387510: done, saving took 0.98 seconds\n",
      "2021-11-04 19:26:32.415846: This epoch took 332.717707 s\n",
      "\n",
      "2021-11-04 19:26:32.421917: \n",
      "epoch:  28\n",
      "2021-11-04 19:31:44.836972: train loss : -0.8429\n",
      "2021-11-04 19:32:04.973803: validation loss: -0.8260\n",
      "2021-11-04 19:32:04.982202: Average global foreground Dice: [0.8431]\n",
      "2021-11-04 19:32:04.988508: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 19:32:05.480759: lr: 0.004581\n",
      "2021-11-04 19:32:05.516492: saving checkpoint...\n",
      "2021-11-04 19:32:06.460630: done, saving took 0.97 seconds\n",
      "2021-11-04 19:32:06.487532: This epoch took 334.060009 s\n",
      "\n",
      "2021-11-04 19:32:06.492784: \n",
      "epoch:  29\n",
      "2021-11-04 19:37:20.792315: train loss : -0.8455\n",
      "2021-11-04 19:37:39.479436: validation loss: -0.8195\n",
      "2021-11-04 19:37:39.485340: Average global foreground Dice: [0.8393]\n",
      "2021-11-04 19:37:39.490561: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 19:37:39.997630: lr: 0.004384\n",
      "2021-11-04 19:37:40.031127: saving checkpoint...\n",
      "2021-11-04 19:37:41.003690: done, saving took 1.00 seconds\n",
      "2021-11-04 19:37:41.032416: This epoch took 334.534098 s\n",
      "\n",
      "2021-11-04 19:37:41.036968: \n",
      "epoch:  30\n",
      "2021-11-04 19:42:53.354493: train loss : -0.8456\n",
      "2021-11-04 19:43:14.317910: validation loss: -0.8347\n",
      "2021-11-04 19:43:14.324655: Average global foreground Dice: [0.85]\n",
      "2021-11-04 19:43:14.330721: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 19:43:14.824996: lr: 0.004186\n",
      "2021-11-04 19:43:14.858686: saving checkpoint...\n",
      "2021-11-04 19:43:15.831494: done, saving took 1.00 seconds\n",
      "2021-11-04 19:43:15.856939: This epoch took 334.815028 s\n",
      "\n",
      "2021-11-04 19:43:15.861219: \n",
      "epoch:  31\n",
      "2021-11-04 19:48:26.516359: train loss : -0.8462\n",
      "2021-11-04 19:48:45.525905: validation loss: -0.8235\n",
      "2021-11-04 19:48:45.531419: Average global foreground Dice: [0.8395]\n",
      "2021-11-04 19:48:45.536684: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 19:48:46.029715: lr: 0.003987\n",
      "2021-11-04 19:48:46.063487: saving checkpoint...\n",
      "2021-11-04 19:48:47.059726: done, saving took 1.02 seconds\n",
      "2021-11-04 19:48:47.091399: This epoch took 331.224464 s\n",
      "\n",
      "2021-11-04 19:48:47.095871: \n",
      "epoch:  32\n",
      "2021-11-04 19:54:01.478130: train loss : -0.8470\n",
      "2021-11-04 19:54:22.167324: validation loss: -0.8261\n",
      "2021-11-04 19:54:22.173091: Average global foreground Dice: [0.8417]\n",
      "2021-11-04 19:54:22.177917: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 19:54:22.669426: lr: 0.003787\n",
      "2021-11-04 19:54:22.734254: saving checkpoint...\n",
      "2021-11-04 19:54:23.717524: done, saving took 1.04 seconds\n",
      "2021-11-04 19:54:23.747745: This epoch took 336.646605 s\n",
      "\n",
      "2021-11-04 19:54:23.753284: \n",
      "epoch:  33\n",
      "2021-11-04 19:59:33.486408: train loss : -0.8474\n",
      "2021-11-04 19:59:52.098978: validation loss: -0.8104\n",
      "2021-11-04 19:59:52.105436: Average global foreground Dice: [0.8312]\n",
      "2021-11-04 19:59:52.110261: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 19:59:52.603091: lr: 0.003586\n",
      "2021-11-04 19:59:52.669978: saving checkpoint...\n",
      "2021-11-04 19:59:53.627787: done, saving took 1.02 seconds\n",
      "2021-11-04 19:59:53.652417: This epoch took 329.893865 s\n",
      "\n",
      "2021-11-04 19:59:53.657130: \n",
      "epoch:  34\n",
      "2021-11-04 20:05:03.980013: train loss : -0.8488\n",
      "2021-11-04 20:05:22.367549: validation loss: -0.8325\n",
      "2021-11-04 20:05:22.372851: Average global foreground Dice: [0.8499]\n",
      "2021-11-04 20:05:22.377801: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 20:05:22.882043: lr: 0.003384\n",
      "2021-11-04 20:05:22.915917: saving checkpoint...\n",
      "2021-11-04 20:05:23.999702: done, saving took 1.11 seconds\n",
      "2021-11-04 20:05:24.025542: This epoch took 330.363085 s\n",
      "\n",
      "2021-11-04 20:05:24.030782: \n",
      "epoch:  35\n",
      "2021-11-04 20:10:37.553373: train loss : -0.8495\n",
      "2021-11-04 20:10:58.578142: validation loss: -0.8313\n",
      "2021-11-04 20:10:58.584155: Average global foreground Dice: [0.8414]\n",
      "2021-11-04 20:10:58.588970: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 20:10:59.108609: lr: 0.00318\n",
      "2021-11-04 20:10:59.142785: saving checkpoint...\n",
      "2021-11-04 20:11:00.164720: done, saving took 1.05 seconds\n",
      "2021-11-04 20:11:00.192300: This epoch took 336.156468 s\n",
      "\n",
      "2021-11-04 20:11:00.197984: \n",
      "epoch:  36\n",
      "2021-11-04 20:16:13.912691: train loss : -0.8475\n",
      "2021-11-04 20:16:33.906526: validation loss: -0.8424\n",
      "2021-11-04 20:16:33.913201: Average global foreground Dice: [0.8527]\n",
      "2021-11-04 20:16:33.918231: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 20:16:34.438570: lr: 0.002975\n",
      "2021-11-04 20:16:34.472676: saving checkpoint...\n",
      "2021-11-04 20:16:35.445662: done, saving took 1.00 seconds\n",
      "2021-11-04 20:16:35.471045: This epoch took 335.267646 s\n",
      "\n",
      "2021-11-04 20:16:35.475445: \n",
      "epoch:  37\n",
      "2021-11-04 20:21:49.894907: train loss : -0.8507\n",
      "2021-11-04 20:22:12.009313: validation loss: -0.8265\n",
      "2021-11-04 20:22:12.053261: Average global foreground Dice: [0.8424]\n",
      "2021-11-04 20:22:12.059503: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 20:22:13.937758: lr: 0.002768\n",
      "2021-11-04 20:22:13.989999: saving checkpoint...\n",
      "2021-11-04 20:22:15.248629: done, saving took 1.30 seconds\n",
      "2021-11-04 20:22:15.282191: This epoch took 339.802192 s\n",
      "\n",
      "2021-11-04 20:22:15.287768: \n",
      "epoch:  38\n",
      "2021-11-04 20:27:28.741723: train loss : -0.8523\n",
      "2021-11-04 20:27:47.541624: validation loss: -0.8256\n",
      "2021-11-04 20:27:47.547947: Average global foreground Dice: [0.8434]\n",
      "2021-11-04 20:27:47.553074: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 20:27:48.038342: lr: 0.00256\n",
      "2021-11-04 20:27:48.072957: saving checkpoint...\n",
      "2021-11-04 20:27:49.018996: done, saving took 0.97 seconds\n",
      "2021-11-04 20:27:49.045029: This epoch took 333.752714 s\n",
      "\n",
      "2021-11-04 20:27:49.050237: \n",
      "epoch:  39\n",
      "2021-11-04 20:33:05.663413: train loss : -0.8545\n",
      "2021-11-04 20:33:25.265056: validation loss: -0.8223\n",
      "2021-11-04 20:33:25.272161: Average global foreground Dice: [0.8339]\n",
      "2021-11-04 20:33:25.277015: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 20:33:25.779058: lr: 0.002349\n",
      "2021-11-04 20:33:25.812495: saving checkpoint...\n",
      "2021-11-04 20:33:26.742638: done, saving took 0.96 seconds\n",
      "2021-11-04 20:33:26.770476: This epoch took 337.715286 s\n",
      "\n",
      "2021-11-04 20:33:26.777283: \n",
      "epoch:  40\n",
      "2021-11-04 20:38:38.148513: train loss : -0.8553\n",
      "2021-11-04 20:38:56.565126: validation loss: -0.8309\n",
      "2021-11-04 20:38:56.571484: Average global foreground Dice: [0.8427]\n",
      "2021-11-04 20:38:56.576727: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 20:38:57.067950: lr: 0.002137\n",
      "2021-11-04 20:38:57.102382: saving checkpoint...\n",
      "2021-11-04 20:38:58.101845: done, saving took 1.03 seconds\n",
      "2021-11-04 20:38:58.128605: This epoch took 331.345812 s\n",
      "\n",
      "2021-11-04 20:38:58.133707: \n",
      "epoch:  41\n",
      "2021-11-04 20:44:13.070882: train loss : -0.8553\n",
      "2021-11-04 20:44:31.568362: validation loss: -0.8154\n",
      "2021-11-04 20:44:31.574665: Average global foreground Dice: [0.8331]\n",
      "2021-11-04 20:44:31.580471: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 20:44:32.068582: lr: 0.001922\n",
      "2021-11-04 20:44:32.102777: saving checkpoint...\n",
      "2021-11-04 20:44:33.097089: done, saving took 1.02 seconds\n",
      "2021-11-04 20:44:33.121574: This epoch took 334.983022 s\n",
      "\n",
      "2021-11-04 20:44:33.126849: \n",
      "epoch:  42\n",
      "2021-11-04 20:49:44.737345: train loss : -0.8553\n",
      "2021-11-04 20:50:03.288849: validation loss: -0.8288\n",
      "2021-11-04 20:50:03.295221: Average global foreground Dice: [0.8454]\n",
      "2021-11-04 20:50:03.300593: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 20:50:03.791024: lr: 0.001704\n",
      "2021-11-04 20:50:03.824956: saving checkpoint...\n",
      "2021-11-04 20:50:04.802548: done, saving took 1.01 seconds\n",
      "2021-11-04 20:50:04.827797: This epoch took 331.696609 s\n",
      "\n",
      "2021-11-04 20:50:04.832737: \n",
      "epoch:  43\n",
      "2021-11-04 20:55:16.142208: train loss : -0.8593\n",
      "2021-11-04 20:55:35.721755: validation loss: -0.8371\n",
      "2021-11-04 20:55:35.726884: Average global foreground Dice: [0.8472]\n",
      "2021-11-04 20:55:35.731092: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 20:55:36.209898: lr: 0.001483\n",
      "2021-11-04 20:55:36.243192: saving checkpoint...\n",
      "2021-11-04 20:55:37.194179: done, saving took 0.98 seconds\n",
      "2021-11-04 20:55:37.218248: This epoch took 332.380684 s\n",
      "\n",
      "2021-11-04 20:55:37.223569: \n",
      "epoch:  44\n",
      "2021-11-04 21:00:57.203336: train loss : -0.8550\n",
      "2021-11-04 21:01:17.758389: validation loss: -0.8352\n",
      "2021-11-04 21:01:17.765290: Average global foreground Dice: [0.85]\n",
      "2021-11-04 21:01:17.775619: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 21:01:18.256647: lr: 0.001259\n",
      "2021-11-04 21:01:18.289975: saving checkpoint...\n",
      "2021-11-04 21:01:19.278927: done, saving took 1.02 seconds\n",
      "2021-11-04 21:01:19.305041: This epoch took 342.076430 s\n",
      "\n",
      "2021-11-04 21:01:19.310053: \n",
      "epoch:  45\n",
      "2021-11-04 21:06:37.350049: train loss : -0.8599\n",
      "2021-11-04 21:06:58.772233: validation loss: -0.8329\n",
      "2021-11-04 21:06:58.782248: Average global foreground Dice: [0.8472]\n",
      "2021-11-04 21:06:58.788230: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 21:07:00.297307: lr: 0.00103\n",
      "2021-11-04 21:07:00.377242: saving checkpoint...\n",
      "2021-11-04 21:07:01.363141: done, saving took 1.06 seconds\n",
      "2021-11-04 21:07:01.394902: This epoch took 342.080354 s\n",
      "\n",
      "2021-11-04 21:07:01.400316: \n",
      "epoch:  46\n",
      "2021-11-04 21:12:14.173255: train loss : -0.8607\n",
      "2021-11-04 21:12:32.868685: validation loss: -0.8242\n",
      "2021-11-04 21:12:32.874902: Average global foreground Dice: [0.8427]\n",
      "2021-11-04 21:12:32.880567: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 21:12:33.378362: lr: 0.000795\n",
      "2021-11-04 21:12:33.434918: saving checkpoint...\n",
      "2021-11-04 21:12:34.412372: done, saving took 1.03 seconds\n",
      "2021-11-04 21:12:34.444723: This epoch took 333.039957 s\n",
      "\n",
      "2021-11-04 21:12:34.449913: \n",
      "epoch:  47\n",
      "2021-11-04 21:17:49.052155: train loss : -0.8591\n",
      "2021-11-04 21:18:10.142015: validation loss: -0.8298\n",
      "2021-11-04 21:18:10.148612: Average global foreground Dice: [0.8431]\n",
      "2021-11-04 21:18:10.154267: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 21:18:10.658743: lr: 0.000552\n",
      "2021-11-04 21:18:10.715272: saving checkpoint...\n",
      "2021-11-04 21:18:11.675931: done, saving took 1.01 seconds\n",
      "2021-11-04 21:18:11.701656: This epoch took 337.246411 s\n",
      "\n",
      "2021-11-04 21:18:11.706288: \n",
      "epoch:  48\n",
      "2021-11-04 21:23:30.298416: train loss : -0.8563\n",
      "2021-11-04 21:23:49.242869: validation loss: -0.8266\n",
      "2021-11-04 21:23:49.248705: Average global foreground Dice: [0.8414]\n",
      "2021-11-04 21:23:49.254101: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 21:23:49.750274: lr: 0.000296\n",
      "2021-11-04 21:23:49.806941: saving checkpoint...\n",
      "2021-11-04 21:23:50.829900: done, saving took 1.07 seconds\n",
      "2021-11-04 21:23:50.860046: This epoch took 339.149526 s\n",
      "\n",
      "2021-11-04 21:23:50.866007: \n",
      "epoch:  49\n",
      "2021-11-04 21:29:01.892863: train loss : -0.8613\n",
      "2021-11-04 21:29:20.616005: validation loss: -0.8205\n",
      "2021-11-04 21:29:20.621933: Average global foreground Dice: [0.8364]\n",
      "2021-11-04 21:29:20.626499: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 21:29:21.130015: lr: 0.0\n",
      "2021-11-04 21:29:21.135818: saving scheduled checkpoint file...\n",
      "2021-11-04 21:29:21.192968: saving checkpoint...\n",
      "2021-11-04 21:29:22.199247: done, saving took 1.06 seconds\n",
      "2021-11-04 21:29:22.222300: done\n",
      "2021-11-04 21:29:22.227293: This epoch took 331.355365 s\n",
      "\n",
      "2021-11-04 21:29:22.288746: saving checkpoint...\n",
      "2021-11-04 21:29:23.329257: done, saving took 1.09 seconds\n",
      "23090566_20141114 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090571_20120517 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131226 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160308 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131025 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090596_20150112 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120619 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090608_20120718 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151210 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121213 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090616_20140331 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090619_20121210 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090629_20120830 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090636_20121018 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150522 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-04 21:32:53.319937: finished prediction\n",
      "2021-11-04 21:32:53.326854: evaluation of raw predictions\n",
      "2021-11-04 21:32:54.783680: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8422359765293639\n",
      "after:  0.8422359765293639\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_Dice.nnUNetTrainerV2_Loss_Dice'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-04 21:33:04.095134: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-04 21:33:04.111090: The split file contains 5 splits.\n",
      "2021-11-04 21:33:04.115219: Desired fold for training: 3\n",
      "2021-11-04 21:33:04.119932: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-04 21:33:08.495334: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-04 21:33:16.543099: Unable to plot network architecture:\n",
      "2021-11-04 21:33:16.547567: No module named 'hiddenlayer'\n",
      "2021-11-04 21:33:16.552081: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-04 21:33:16.557720: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-04 21:33:16.567421: \n",
      "\n",
      "2021-11-04 21:33:16.572878: \n",
      "epoch:  0\n",
      "2021-11-04 21:39:00.394083: train loss : -0.0078\n",
      "2021-11-04 21:39:21.041649: validation loss: -0.0171\n",
      "2021-11-04 21:39:21.046666: Average global foreground Dice: [0.0342]\n",
      "2021-11-04 21:39:21.051383: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 21:39:21.488228: lr: 0.00982\n",
      "2021-11-04 21:39:21.494329: This epoch took 364.916613 s\n",
      "\n",
      "2021-11-04 21:39:21.498274: \n",
      "epoch:  1\n",
      "2021-11-04 21:44:31.400765: train loss : -0.2674\n",
      "2021-11-04 21:44:51.253388: validation loss: -0.5979\n",
      "2021-11-04 21:44:51.259885: Average global foreground Dice: [0.6697]\n",
      "2021-11-04 21:44:51.264667: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 21:44:51.803308: lr: 0.009639\n",
      "2021-11-04 21:44:51.883841: saving checkpoint...\n",
      "2021-11-04 21:44:52.726717: done, saving took 0.92 seconds\n",
      "2021-11-04 21:44:52.745710: This epoch took 331.243120 s\n",
      "\n",
      "2021-11-04 21:44:52.750493: \n",
      "epoch:  2\n",
      "2021-11-04 21:50:04.370945: train loss : -0.6061\n",
      "2021-11-04 21:50:25.458629: validation loss: -0.6699\n",
      "2021-11-04 21:50:25.463781: Average global foreground Dice: [0.7148]\n",
      "2021-11-04 21:50:25.468591: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 21:50:26.034049: lr: 0.009458\n",
      "2021-11-04 21:50:26.112447: saving checkpoint...\n",
      "2021-11-04 21:50:27.102353: done, saving took 1.06 seconds\n",
      "2021-11-04 21:50:27.129353: This epoch took 334.374980 s\n",
      "\n",
      "2021-11-04 21:50:27.134531: \n",
      "epoch:  3\n",
      "2021-11-04 21:55:37.072930: train loss : -0.6754\n",
      "2021-11-04 21:55:56.420676: validation loss: -0.7092\n",
      "2021-11-04 21:55:56.426940: Average global foreground Dice: [0.7409]\n",
      "2021-11-04 21:55:56.431783: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 21:55:56.939835: lr: 0.009277\n",
      "2021-11-04 21:55:56.996467: saving checkpoint...\n",
      "2021-11-04 21:55:57.945086: done, saving took 1.00 seconds\n",
      "2021-11-04 21:55:57.974792: This epoch took 330.835896 s\n",
      "\n",
      "2021-11-04 21:55:57.979685: \n",
      "epoch:  4\n",
      "2021-11-04 22:01:09.687363: train loss : -0.7112\n",
      "2021-11-04 22:01:28.979521: validation loss: -0.7564\n",
      "2021-11-04 22:01:28.984690: Average global foreground Dice: [0.79]\n",
      "2021-11-04 22:01:28.989398: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 22:01:29.513277: lr: 0.009095\n",
      "2021-11-04 22:01:29.569673: saving checkpoint...\n",
      "2021-11-04 22:01:30.509049: done, saving took 0.99 seconds\n",
      "2021-11-04 22:01:30.536708: This epoch took 332.552069 s\n",
      "\n",
      "2021-11-04 22:01:30.542398: \n",
      "epoch:  5\n",
      "2021-11-04 22:06:36.385239: train loss : -0.7365\n",
      "2021-11-04 22:06:54.846871: validation loss: -0.7394\n",
      "2021-11-04 22:06:54.853212: Average global foreground Dice: [0.7884]\n",
      "2021-11-04 22:06:54.858272: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 22:06:55.382714: lr: 0.008913\n",
      "2021-11-04 22:06:55.448245: saving checkpoint...\n",
      "2021-11-04 22:06:56.408916: done, saving took 1.02 seconds\n",
      "2021-11-04 22:06:56.429887: This epoch took 325.883735 s\n",
      "\n",
      "2021-11-04 22:06:56.434793: \n",
      "epoch:  6\n",
      "2021-11-04 22:12:04.154655: train loss : -0.7571\n",
      "2021-11-04 22:12:25.792292: validation loss: -0.7886\n",
      "2021-11-04 22:12:25.802494: Average global foreground Dice: [0.8173]\n",
      "2021-11-04 22:12:25.807965: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 22:12:26.781215: lr: 0.008731\n",
      "2021-11-04 22:12:26.845980: saving checkpoint...\n",
      "2021-11-04 22:12:27.840370: done, saving took 1.05 seconds\n",
      "2021-11-04 22:12:27.869330: This epoch took 331.430290 s\n",
      "\n",
      "2021-11-04 22:12:27.873760: \n",
      "epoch:  7\n",
      "2021-11-04 22:17:35.408868: train loss : -0.7658\n",
      "2021-11-04 22:17:56.782114: validation loss: -0.7654\n",
      "2021-11-04 22:17:56.789219: Average global foreground Dice: [0.7941]\n",
      "2021-11-04 22:17:56.793795: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 22:17:58.780128: lr: 0.008548\n",
      "2021-11-04 22:17:58.862766: saving checkpoint...\n",
      "2021-11-04 22:17:59.825603: done, saving took 1.04 seconds\n",
      "2021-11-04 22:17:59.852920: This epoch took 331.974872 s\n",
      "\n",
      "2021-11-04 22:17:59.857713: \n",
      "epoch:  8\n",
      "2021-11-04 22:23:08.398270: train loss : -0.7804\n",
      "2021-11-04 22:23:27.384237: validation loss: -0.7945\n",
      "2021-11-04 22:23:27.390437: Average global foreground Dice: [0.8256]\n",
      "2021-11-04 22:23:27.395550: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 22:23:27.971888: lr: 0.008364\n",
      "2021-11-04 22:23:28.004711: saving checkpoint...\n",
      "2021-11-04 22:23:28.948338: done, saving took 0.97 seconds\n",
      "2021-11-04 22:23:28.973094: This epoch took 329.109675 s\n",
      "\n",
      "2021-11-04 22:23:28.977404: \n",
      "epoch:  9\n",
      "2021-11-04 22:28:38.273906: train loss : -0.7865\n",
      "2021-11-04 22:29:00.246810: validation loss: -0.8114\n",
      "2021-11-04 22:29:00.274112: Average global foreground Dice: [0.8439]\n",
      "2021-11-04 22:29:00.279419: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 22:29:01.962765: lr: 0.008181\n",
      "2021-11-04 22:29:02.038903: saving checkpoint...\n",
      "2021-11-04 22:29:03.637164: done, saving took 1.67 seconds\n",
      "2021-11-04 22:29:03.663321: This epoch took 334.680726 s\n",
      "\n",
      "2021-11-04 22:29:03.667735: \n",
      "epoch:  10\n",
      "2021-11-04 22:34:09.874542: train loss : -0.7922\n",
      "2021-11-04 22:34:29.555566: validation loss: -0.8109\n",
      "2021-11-04 22:34:29.561790: Average global foreground Dice: [0.8324]\n",
      "2021-11-04 22:34:29.566526: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 22:34:30.093839: lr: 0.007996\n",
      "2021-11-04 22:34:30.127073: saving checkpoint...\n",
      "2021-11-04 22:34:31.075125: done, saving took 0.98 seconds\n",
      "2021-11-04 22:34:31.101541: This epoch took 327.429288 s\n",
      "\n",
      "2021-11-04 22:34:31.107093: \n",
      "epoch:  11\n",
      "2021-11-04 22:39:42.636822: train loss : -0.8036\n",
      "2021-11-04 22:40:04.084033: validation loss: -0.8220\n",
      "2021-11-04 22:40:04.090005: Average global foreground Dice: [0.8433]\n",
      "2021-11-04 22:40:04.094736: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 22:40:04.598380: lr: 0.007811\n",
      "2021-11-04 22:40:04.638479: saving checkpoint...\n",
      "2021-11-04 22:40:05.661955: done, saving took 1.06 seconds\n",
      "2021-11-04 22:40:05.688236: This epoch took 334.574968 s\n",
      "\n",
      "2021-11-04 22:40:05.693289: \n",
      "epoch:  12\n",
      "2021-11-04 22:45:20.252630: train loss : -0.7911\n",
      "2021-11-04 22:45:42.093003: validation loss: -0.8158\n",
      "2021-11-04 22:45:42.101842: Average global foreground Dice: [0.8447]\n",
      "2021-11-04 22:45:42.137510: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 22:45:44.165079: lr: 0.007626\n",
      "2021-11-04 22:45:44.217928: saving checkpoint...\n",
      "2021-11-04 22:45:45.317750: done, saving took 1.15 seconds\n",
      "2021-11-04 22:45:45.349093: This epoch took 339.650958 s\n",
      "\n",
      "2021-11-04 22:45:45.354634: \n",
      "epoch:  13\n",
      "2021-11-04 22:51:06.252668: train loss : -0.7964\n",
      "2021-11-04 22:51:29.536844: validation loss: -0.8227\n",
      "2021-11-04 22:51:29.549520: Average global foreground Dice: [0.8457]\n",
      "2021-11-04 22:51:29.555118: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 22:51:32.201396: lr: 0.00744\n",
      "2021-11-04 22:51:32.354604: saving checkpoint...\n",
      "2021-11-04 22:51:34.506505: done, saving took 2.30 seconds\n",
      "2021-11-04 22:51:34.565891: This epoch took 349.205949 s\n",
      "\n",
      "2021-11-04 22:51:34.574190: \n",
      "epoch:  14\n",
      "2021-11-04 22:56:45.892868: train loss : -0.8057\n",
      "2021-11-04 22:57:04.431676: validation loss: -0.8199\n",
      "2021-11-04 22:57:04.437981: Average global foreground Dice: [0.8422]\n",
      "2021-11-04 22:57:04.443291: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 22:57:05.040200: lr: 0.007254\n",
      "2021-11-04 22:57:05.073180: saving checkpoint...\n",
      "2021-11-04 22:57:06.047257: done, saving took 1.00 seconds\n",
      "2021-11-04 22:57:06.073267: This epoch took 331.493068 s\n",
      "\n",
      "2021-11-04 22:57:06.077711: \n",
      "epoch:  15\n",
      "2021-11-04 23:02:15.400294: train loss : -0.8172\n",
      "2021-11-04 23:02:35.042970: validation loss: -0.8272\n",
      "2021-11-04 23:02:35.049496: Average global foreground Dice: [0.846]\n",
      "2021-11-04 23:02:35.054222: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 23:02:35.549716: lr: 0.007067\n",
      "2021-11-04 23:02:35.583596: saving checkpoint...\n",
      "2021-11-04 23:02:36.517919: done, saving took 0.96 seconds\n",
      "2021-11-04 23:02:36.548684: This epoch took 330.466660 s\n",
      "\n",
      "2021-11-04 23:02:36.554103: \n",
      "epoch:  16\n",
      "2021-11-04 23:07:45.999194: train loss : -0.8146\n",
      "2021-11-04 23:08:07.115417: validation loss: -0.8269\n",
      "2021-11-04 23:08:07.121934: Average global foreground Dice: [0.8477]\n",
      "2021-11-04 23:08:07.127248: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 23:08:07.630163: lr: 0.00688\n",
      "2021-11-04 23:08:07.664254: saving checkpoint...\n",
      "2021-11-04 23:08:08.641715: done, saving took 1.01 seconds\n",
      "2021-11-04 23:08:08.669886: This epoch took 332.110920 s\n",
      "\n",
      "2021-11-04 23:08:08.674865: \n",
      "epoch:  17\n",
      "2021-11-04 23:13:20.891838: train loss : -0.8139\n",
      "2021-11-04 23:13:43.149498: validation loss: -0.8270\n",
      "2021-11-04 23:13:43.174136: Average global foreground Dice: [0.8465]\n",
      "2021-11-04 23:13:43.179664: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 23:13:45.094601: lr: 0.006692\n",
      "2021-11-04 23:13:45.167819: saving checkpoint...\n",
      "2021-11-04 23:13:46.697017: done, saving took 1.60 seconds\n",
      "2021-11-04 23:13:46.725545: This epoch took 338.045361 s\n",
      "\n",
      "2021-11-04 23:13:46.731577: \n",
      "epoch:  18\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-04 23:18:57.594520: train loss : -0.8187\n",
      "2021-11-04 23:19:20.072267: validation loss: -0.8215\n",
      "2021-11-04 23:19:20.082528: Average global foreground Dice: [0.845]\n",
      "2021-11-04 23:19:20.087519: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 23:19:21.897520: lr: 0.006504\n",
      "2021-11-04 23:19:21.950324: saving checkpoint...\n",
      "2021-11-04 23:19:23.145190: done, saving took 1.24 seconds\n",
      "2021-11-04 23:19:23.175015: This epoch took 336.437488 s\n",
      "\n",
      "2021-11-04 23:19:23.179601: \n",
      "epoch:  19\n",
      "2021-11-04 23:24:32.048303: train loss : -0.8202\n",
      "2021-11-04 23:24:50.486414: validation loss: -0.8361\n",
      "2021-11-04 23:24:50.493161: Average global foreground Dice: [0.8531]\n",
      "2021-11-04 23:24:50.498789: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 23:24:50.987958: lr: 0.006314\n",
      "2021-11-04 23:24:51.022264: saving checkpoint...\n",
      "2021-11-04 23:24:51.996250: done, saving took 1.00 seconds\n",
      "2021-11-04 23:24:52.025609: This epoch took 328.840498 s\n",
      "\n",
      "2021-11-04 23:24:52.031286: \n",
      "epoch:  20\n",
      "2021-11-04 23:29:58.812174: train loss : -0.8277\n",
      "2021-11-04 23:30:18.929519: validation loss: -0.8322\n",
      "2021-11-04 23:30:18.935740: Average global foreground Dice: [0.8534]\n",
      "2021-11-04 23:30:18.941041: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 23:30:19.453990: lr: 0.006125\n",
      "2021-11-04 23:30:19.487177: saving checkpoint...\n",
      "2021-11-04 23:30:20.494551: done, saving took 1.04 seconds\n",
      "2021-11-04 23:30:20.520638: This epoch took 328.483603 s\n",
      "\n",
      "2021-11-04 23:30:20.529471: \n",
      "epoch:  21\n",
      "2021-11-04 23:35:28.661278: train loss : -0.8214\n",
      "2021-11-04 23:35:48.429829: validation loss: -0.8274\n",
      "2021-11-04 23:35:48.437021: Average global foreground Dice: [0.8483]\n",
      "2021-11-04 23:35:48.442375: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 23:35:49.023746: lr: 0.005934\n",
      "2021-11-04 23:35:49.058106: saving checkpoint...\n",
      "2021-11-04 23:35:50.032418: done, saving took 1.00 seconds\n",
      "2021-11-04 23:35:50.059303: This epoch took 329.525131 s\n",
      "\n",
      "2021-11-04 23:35:50.064713: \n",
      "epoch:  22\n",
      "2021-11-04 23:40:56.181530: train loss : -0.8236\n",
      "2021-11-04 23:41:16.491840: validation loss: -0.8281\n",
      "2021-11-04 23:41:16.498503: Average global foreground Dice: [0.8437]\n",
      "2021-11-04 23:41:16.503243: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 23:41:16.991535: lr: 0.005743\n",
      "2021-11-04 23:41:17.024784: saving checkpoint...\n",
      "2021-11-04 23:41:18.051491: done, saving took 1.06 seconds\n",
      "2021-11-04 23:41:18.078946: This epoch took 328.009065 s\n",
      "\n",
      "2021-11-04 23:41:18.084870: \n",
      "epoch:  23\n",
      "2021-11-04 23:46:23.339219: train loss : -0.8278\n",
      "2021-11-04 23:46:41.993483: validation loss: -0.8447\n",
      "2021-11-04 23:46:41.999379: Average global foreground Dice: [0.8649]\n",
      "2021-11-04 23:46:42.004847: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 23:46:42.507909: lr: 0.005551\n",
      "2021-11-04 23:46:42.542406: saving checkpoint...\n",
      "2021-11-04 23:46:43.523250: done, saving took 1.01 seconds\n",
      "2021-11-04 23:46:43.551325: This epoch took 325.461157 s\n",
      "\n",
      "2021-11-04 23:46:43.556955: \n",
      "epoch:  24\n",
      "2021-11-04 23:51:53.562606: train loss : -0.8303\n",
      "2021-11-04 23:52:13.643412: validation loss: -0.8448\n",
      "2021-11-04 23:52:13.649193: Average global foreground Dice: [0.8612]\n",
      "2021-11-04 23:52:13.655046: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 23:52:14.159949: lr: 0.005359\n",
      "2021-11-04 23:52:14.224976: saving checkpoint...\n",
      "2021-11-04 23:52:15.226523: done, saving took 1.06 seconds\n",
      "2021-11-04 23:52:15.259001: This epoch took 331.697009 s\n",
      "\n",
      "2021-11-04 23:52:15.264542: \n",
      "epoch:  25\n",
      "2021-11-04 23:57:25.559233: train loss : -0.8331\n",
      "2021-11-04 23:57:45.507794: validation loss: -0.8279\n",
      "2021-11-04 23:57:45.523345: Average global foreground Dice: [0.8445]\n",
      "2021-11-04 23:57:45.528987: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-04 23:57:46.089612: lr: 0.005166\n",
      "2021-11-04 23:57:46.153375: saving checkpoint...\n",
      "2021-11-04 23:57:47.124984: done, saving took 1.03 seconds\n",
      "2021-11-04 23:57:47.156240: This epoch took 331.886060 s\n",
      "\n",
      "2021-11-04 23:57:47.162223: \n",
      "epoch:  26\n",
      "2021-11-05 00:02:56.801986: train loss : -0.8311\n",
      "2021-11-05 00:03:16.472592: validation loss: -0.8415\n",
      "2021-11-05 00:03:16.478348: Average global foreground Dice: [0.86]\n",
      "2021-11-05 00:03:16.483057: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 00:03:16.994739: lr: 0.004971\n",
      "2021-11-05 00:03:17.057975: saving checkpoint...\n",
      "2021-11-05 00:03:18.054359: done, saving took 1.05 seconds\n",
      "2021-11-05 00:03:18.083812: This epoch took 330.915586 s\n",
      "\n",
      "2021-11-05 00:03:18.089056: \n",
      "epoch:  27\n",
      "2021-11-05 00:08:27.851560: train loss : -0.8343\n",
      "2021-11-05 00:08:48.310730: validation loss: -0.8460\n",
      "2021-11-05 00:08:48.319144: Average global foreground Dice: [0.8651]\n",
      "2021-11-05 00:08:48.324999: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 00:08:48.843380: lr: 0.004776\n",
      "2021-11-05 00:08:48.906965: saving checkpoint...\n",
      "2021-11-05 00:08:49.900869: done, saving took 1.05 seconds\n",
      "2021-11-05 00:08:49.931012: This epoch took 331.835138 s\n",
      "\n",
      "2021-11-05 00:08:49.936010: \n",
      "epoch:  28\n",
      "2021-11-05 00:13:58.773758: train loss : -0.8384\n",
      "2021-11-05 00:14:18.334028: validation loss: -0.8200\n",
      "2021-11-05 00:14:18.339808: Average global foreground Dice: [0.8388]\n",
      "2021-11-05 00:14:18.345581: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 00:14:18.851835: lr: 0.004581\n",
      "2021-11-05 00:14:18.915998: saving checkpoint...\n",
      "2021-11-05 00:14:19.896399: done, saving took 1.04 seconds\n",
      "2021-11-05 00:14:19.927202: This epoch took 329.986430 s\n",
      "\n",
      "2021-11-05 00:14:19.934596: \n",
      "epoch:  29\n",
      "2021-11-05 00:19:28.677035: train loss : -0.8343\n",
      "2021-11-05 00:19:48.820475: validation loss: -0.8421\n",
      "2021-11-05 00:19:48.825804: Average global foreground Dice: [0.8553]\n",
      "2021-11-05 00:19:48.833335: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 00:19:49.446694: lr: 0.004384\n",
      "2021-11-05 00:19:49.510311: saving checkpoint...\n",
      "2021-11-05 00:19:51.228918: done, saving took 1.78 seconds\n",
      "2021-11-05 00:19:51.255970: This epoch took 331.316688 s\n",
      "\n",
      "2021-11-05 00:19:51.260959: \n",
      "epoch:  30\n",
      "2021-11-05 00:24:59.651278: train loss : -0.8333\n",
      "2021-11-05 00:25:18.253759: validation loss: -0.8463\n",
      "2021-11-05 00:25:18.262253: Average global foreground Dice: [0.8592]\n",
      "2021-11-05 00:25:18.267395: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 00:25:18.768351: lr: 0.004186\n",
      "2021-11-05 00:25:18.828676: saving checkpoint...\n",
      "2021-11-05 00:25:19.829037: done, saving took 1.05 seconds\n",
      "2021-11-05 00:25:19.855502: This epoch took 328.589694 s\n",
      "\n",
      "2021-11-05 00:25:19.860592: \n",
      "epoch:  31\n",
      "2021-11-05 00:30:36.563161: train loss : -0.8381\n",
      "2021-11-05 00:30:57.860706: validation loss: -0.8411\n",
      "2021-11-05 00:30:57.868051: Average global foreground Dice: [0.858]\n",
      "2021-11-05 00:30:57.873980: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 00:30:58.467855: lr: 0.003987\n",
      "2021-11-05 00:30:58.529794: saving checkpoint...\n",
      "2021-11-05 00:30:59.575513: done, saving took 1.10 seconds\n",
      "2021-11-05 00:30:59.602871: This epoch took 339.737425 s\n",
      "\n",
      "2021-11-05 00:30:59.609211: \n",
      "epoch:  32\n",
      "2021-11-05 00:36:09.478277: train loss : -0.8366\n",
      "2021-11-05 00:36:28.195095: validation loss: -0.8271\n",
      "2021-11-05 00:36:28.200663: Average global foreground Dice: [0.8445]\n",
      "2021-11-05 00:36:28.205686: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 00:36:28.703189: lr: 0.003787\n",
      "2021-11-05 00:36:28.736894: saving checkpoint...\n",
      "2021-11-05 00:36:30.225217: done, saving took 1.52 seconds\n",
      "2021-11-05 00:36:30.251328: This epoch took 330.637275 s\n",
      "\n",
      "2021-11-05 00:36:30.257009: \n",
      "epoch:  33\n",
      "2021-11-05 00:41:38.492355: train loss : -0.8368\n",
      "2021-11-05 00:41:57.593942: validation loss: -0.8337\n",
      "2021-11-05 00:41:57.600617: Average global foreground Dice: [0.8498]\n",
      "2021-11-05 00:41:57.606971: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 00:41:58.104838: lr: 0.003586\n",
      "2021-11-05 00:41:58.138200: saving checkpoint...\n",
      "2021-11-05 00:41:59.118531: done, saving took 1.01 seconds\n",
      "2021-11-05 00:41:59.141471: This epoch took 328.879486 s\n",
      "\n",
      "2021-11-05 00:41:59.146347: \n",
      "epoch:  34\n",
      "2021-11-05 00:47:08.360730: train loss : -0.8382\n",
      "2021-11-05 00:47:26.784862: validation loss: -0.8472\n",
      "2021-11-05 00:47:26.791378: Average global foreground Dice: [0.8604]\n",
      "2021-11-05 00:47:26.797315: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 00:47:27.318172: lr: 0.003384\n",
      "2021-11-05 00:47:27.352294: saving checkpoint...\n",
      "2021-11-05 00:47:28.322703: done, saving took 1.00 seconds\n",
      "2021-11-05 00:47:28.353506: This epoch took 329.202298 s\n",
      "\n",
      "2021-11-05 00:47:28.359857: \n",
      "epoch:  35\n",
      "2021-11-05 00:52:40.197164: train loss : -0.8433\n",
      "2021-11-05 00:52:59.058155: validation loss: -0.8415\n",
      "2021-11-05 00:52:59.064735: Average global foreground Dice: [0.8561]\n",
      "2021-11-05 00:52:59.070438: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 00:52:59.561377: lr: 0.00318\n",
      "2021-11-05 00:52:59.618156: saving checkpoint...\n",
      "2021-11-05 00:53:00.600297: done, saving took 1.03 seconds\n",
      "2021-11-05 00:53:00.630257: This epoch took 332.260836 s\n",
      "\n",
      "2021-11-05 00:53:00.635736: \n",
      "epoch:  36\n",
      "2021-11-05 00:58:13.610572: train loss : -0.8429\n",
      "2021-11-05 00:58:35.689409: validation loss: -0.8492\n",
      "2021-11-05 00:58:35.702020: Average global foreground Dice: [0.8625]\n",
      "2021-11-05 00:58:35.707016: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 00:58:37.641526: lr: 0.002975\n",
      "2021-11-05 00:58:37.762488: saving checkpoint...\n",
      "2021-11-05 00:58:39.208669: done, saving took 1.56 seconds\n",
      "2021-11-05 00:58:39.250304: This epoch took 338.608587 s\n",
      "\n",
      "2021-11-05 00:58:39.255986: \n",
      "epoch:  37\n",
      "2021-11-05 01:03:59.350333: train loss : -0.8443\n",
      "2021-11-05 01:04:22.375969: validation loss: -0.8403\n",
      "2021-11-05 01:04:22.382084: Average global foreground Dice: [0.8539]\n",
      "2021-11-05 01:04:22.387374: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 01:04:24.490814: lr: 0.002768\n",
      "2021-11-05 01:04:24.577775: saving checkpoint...\n",
      "2021-11-05 01:04:26.637326: done, saving took 2.14 seconds\n",
      "2021-11-05 01:04:26.696147: This epoch took 347.434386 s\n",
      "\n",
      "2021-11-05 01:04:26.702434: \n",
      "epoch:  38\n",
      "2021-11-05 01:09:10.791401: train loss : -0.8450\n",
      "2021-11-05 01:09:31.302876: validation loss: -0.8350\n",
      "2021-11-05 01:09:31.341922: Average global foreground Dice: [0.8526]\n",
      "2021-11-05 01:09:31.347273: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 01:09:32.873026: lr: 0.00256\n",
      "2021-11-05 01:09:32.968145: saving checkpoint...\n",
      "2021-11-05 01:09:34.479638: done, saving took 1.60 seconds\n",
      "2021-11-05 01:09:34.505355: This epoch took 307.796953 s\n",
      "\n",
      "2021-11-05 01:09:34.510602: \n",
      "epoch:  39\n",
      "2021-11-05 01:14:42.740276: train loss : -0.8446\n",
      "2021-11-05 01:15:01.092846: validation loss: -0.8398\n",
      "2021-11-05 01:15:01.098876: Average global foreground Dice: [0.8532]\n",
      "2021-11-05 01:15:01.104177: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 01:15:01.597427: lr: 0.002349\n",
      "2021-11-05 01:15:01.631616: saving checkpoint...\n",
      "2021-11-05 01:15:02.655170: done, saving took 1.05 seconds\n",
      "2021-11-05 01:15:02.678582: This epoch took 328.164056 s\n",
      "\n",
      "2021-11-05 01:15:02.683187: \n",
      "epoch:  40\n",
      "2021-11-05 01:20:14.572483: train loss : -0.8473\n",
      "2021-11-05 01:20:34.900768: validation loss: -0.8468\n",
      "2021-11-05 01:20:34.907439: Average global foreground Dice: [0.8613]\n",
      "2021-11-05 01:20:34.912886: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 01:20:35.417446: lr: 0.002137\n",
      "2021-11-05 01:20:35.451014: saving checkpoint...\n",
      "2021-11-05 01:20:36.415091: done, saving took 0.99 seconds\n",
      "2021-11-05 01:20:36.442735: This epoch took 333.754670 s\n",
      "\n",
      "2021-11-05 01:20:36.448092: \n",
      "epoch:  41\n",
      "2021-11-05 01:25:48.088206: train loss : -0.8439\n",
      "2021-11-05 01:26:08.112869: validation loss: -0.8457\n",
      "2021-11-05 01:26:08.119976: Average global foreground Dice: [0.8636]\n",
      "2021-11-05 01:26:08.125048: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 01:26:08.619245: lr: 0.001922\n",
      "2021-11-05 01:26:08.653192: saving checkpoint...\n",
      "2021-11-05 01:26:10.028773: done, saving took 1.40 seconds\n",
      "2021-11-05 01:26:10.058653: This epoch took 333.605738 s\n",
      "\n",
      "2021-11-05 01:26:10.063800: \n",
      "epoch:  42\n",
      "2021-11-05 01:31:21.104734: train loss : -0.8502\n",
      "2021-11-05 01:31:39.964917: validation loss: -0.8455\n",
      "2021-11-05 01:31:39.970107: Average global foreground Dice: [0.8556]\n",
      "2021-11-05 01:31:39.975638: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 01:31:40.468777: lr: 0.001704\n",
      "2021-11-05 01:31:40.520832: saving checkpoint...\n",
      "2021-11-05 01:31:41.684693: done, saving took 1.21 seconds\n",
      "2021-11-05 01:31:41.709689: This epoch took 331.640683 s\n",
      "\n",
      "2021-11-05 01:31:41.716038: \n",
      "epoch:  43\n",
      "2021-11-05 01:37:12.008247: train loss : -0.8481\n",
      "2021-11-05 01:37:34.339464: validation loss: -0.8432\n",
      "2021-11-05 01:37:34.352069: Average global foreground Dice: [0.8595]\n",
      "2021-11-05 01:37:34.357533: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 01:37:36.488495: lr: 0.001483\n",
      "2021-11-05 01:37:36.642556: saving checkpoint...\n",
      "2021-11-05 01:37:38.051108: done, saving took 1.56 seconds\n",
      "2021-11-05 01:37:38.089816: This epoch took 356.368448 s\n",
      "\n",
      "2021-11-05 01:37:38.095124: \n",
      "epoch:  44\n",
      "2021-11-05 01:42:58.859067: train loss : -0.8521\n",
      "2021-11-05 01:43:21.149568: validation loss: -0.8545\n",
      "2021-11-05 01:43:21.162138: Average global foreground Dice: [0.8633]\n",
      "2021-11-05 01:43:21.167307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 01:43:22.989802: lr: 0.001259\n",
      "2021-11-05 01:43:23.054864: saving checkpoint...\n",
      "2021-11-05 01:43:24.346546: done, saving took 1.35 seconds\n",
      "2021-11-05 01:43:24.383934: This epoch took 346.283410 s\n",
      "\n",
      "2021-11-05 01:43:24.388911: \n",
      "epoch:  45\n",
      "2021-11-05 01:48:43.297648: train loss : -0.8511\n",
      "2021-11-05 01:49:05.594748: validation loss: -0.8462\n",
      "2021-11-05 01:49:05.642807: Average global foreground Dice: [0.858]\n",
      "2021-11-05 01:49:05.648653: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 01:49:08.139714: lr: 0.00103\n",
      "2021-11-05 01:49:08.281494: saving checkpoint...\n",
      "2021-11-05 01:49:10.805845: done, saving took 2.65 seconds\n",
      "2021-11-05 01:49:10.858917: This epoch took 346.464729 s\n",
      "\n",
      "2021-11-05 01:49:10.864556: \n",
      "epoch:  46\n",
      "2021-11-05 01:54:44.212115: train loss : -0.8541\n",
      "2021-11-05 01:55:06.945800: validation loss: -0.8510\n",
      "2021-11-05 01:55:06.972197: Average global foreground Dice: [0.8638]\n",
      "2021-11-05 01:55:06.976894: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 01:55:09.039370: lr: 0.000795\n",
      "2021-11-05 01:55:09.090567: saving checkpoint...\n",
      "2021-11-05 01:55:10.737958: done, saving took 1.69 seconds\n",
      "2021-11-05 01:55:10.775185: This epoch took 359.905585 s\n",
      "\n",
      "2021-11-05 01:55:10.780391: \n",
      "epoch:  47\n",
      "2021-11-05 02:00:34.946291: train loss : -0.8505\n",
      "2021-11-05 02:00:57.102462: validation loss: -0.8494\n",
      "2021-11-05 02:00:57.141658: Average global foreground Dice: [0.8638]\n",
      "2021-11-05 02:00:57.146669: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 02:00:59.539659: lr: 0.000552\n",
      "2021-11-05 02:00:59.596816: saving checkpoint...\n",
      "2021-11-05 02:01:01.462548: done, saving took 1.92 seconds\n",
      "2021-11-05 02:01:01.490063: This epoch took 350.703847 s\n",
      "\n",
      "2021-11-05 02:01:01.495143: \n",
      "epoch:  48\n",
      "2021-11-05 02:06:22.094343: train loss : -0.8561\n",
      "2021-11-05 02:06:43.981827: validation loss: -0.8514\n",
      "2021-11-05 02:06:43.987941: Average global foreground Dice: [0.8653]\n",
      "2021-11-05 02:06:43.993201: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 02:06:46.191639: lr: 0.000296\n",
      "2021-11-05 02:06:46.282109: saving checkpoint...\n",
      "2021-11-05 02:06:47.959903: done, saving took 1.76 seconds\n",
      "2021-11-05 02:06:47.991168: This epoch took 346.490818 s\n",
      "\n",
      "2021-11-05 02:06:47.996701: \n",
      "epoch:  49\n",
      "2021-11-05 02:12:12.663964: train loss : -0.8533\n",
      "2021-11-05 02:12:35.703290: validation loss: -0.8474\n",
      "2021-11-05 02:12:35.743563: Average global foreground Dice: [0.8624]\n",
      "2021-11-05 02:12:35.749894: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 02:12:37.939538: lr: 0.0\n",
      "2021-11-05 02:12:37.950341: saving scheduled checkpoint file...\n",
      "2021-11-05 02:12:38.055803: saving checkpoint...\n",
      "2021-11-05 02:12:39.538906: done, saving took 1.58 seconds\n",
      "2021-11-05 02:12:39.566205: done\n",
      "2021-11-05 02:12:39.646249: saving checkpoint...\n",
      "2021-11-05 02:12:41.408280: done, saving took 1.84 seconds\n",
      "2021-11-05 02:12:41.458566: This epoch took 353.456860 s\n",
      "\n",
      "2021-11-05 02:12:41.538940: saving checkpoint...\n",
      "2021-11-05 02:12:42.737085: done, saving took 1.27 seconds\n",
      "23090557_20130717 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090560_20160114 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090562_20140206 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141215 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130626 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140124 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121015 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090597_20130227 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130208 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090621_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150105 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130807 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090637_20140401 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131126 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090644_20131216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-05 02:16:15.283631: finished prediction\n",
      "2021-11-05 02:16:15.288651: evaluation of raw predictions\n",
      "2021-11-05 02:16:16.918338: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8575960944722476\n",
      "after:  0.8607986871589957\n",
      "Removing all but the largest foreground region improved results!\n",
      "for_which_classes [1]\n",
      "min_valid_object_sizes None\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[[1]]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_Dice.nnUNetTrainerV2_Loss_Dice'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-05 02:16:27.332477: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-05 02:16:27.347562: The split file contains 5 splits.\n",
      "2021-11-05 02:16:27.352470: Desired fold for training: 4\n",
      "2021-11-05 02:16:27.356753: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-05 02:16:31.772259: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-05 02:16:54.864091: Unable to plot network architecture:\n",
      "2021-11-05 02:16:54.869349: No module named 'hiddenlayer'\n",
      "2021-11-05 02:16:54.873389: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-05 02:16:54.877563: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-05 02:16:54.892816: \n",
      "\n",
      "2021-11-05 02:16:54.898211: \n",
      "epoch:  0\n",
      "2021-11-05 02:22:42.802223: train loss : -0.0053\n",
      "2021-11-05 02:23:04.776613: validation loss: -0.0093\n",
      "2021-11-05 02:23:04.783914: Average global foreground Dice: [0.0087]\n",
      "2021-11-05 02:23:04.789126: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 02:23:05.901306: lr: 0.00982\n",
      "2021-11-05 02:23:05.906399: This epoch took 371.002140 s\n",
      "\n",
      "2021-11-05 02:23:05.940108: \n",
      "epoch:  1\n",
      "2021-11-05 02:28:23.650170: train loss : -0.0702\n",
      "2021-11-05 02:28:46.449859: validation loss: -0.2675\n",
      "2021-11-05 02:28:46.460642: Average global foreground Dice: [0.4676]\n",
      "2021-11-05 02:28:46.475082: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 02:28:48.639725: lr: 0.009639\n",
      "2021-11-05 02:28:48.849973: saving checkpoint...\n",
      "2021-11-05 02:28:50.537313: done, saving took 1.89 seconds\n",
      "2021-11-05 02:28:50.557537: This epoch took 344.613020 s\n",
      "\n",
      "2021-11-05 02:28:50.562611: \n",
      "epoch:  2\n",
      "2021-11-05 02:34:10.072619: train loss : -0.5686\n",
      "2021-11-05 02:34:32.390870: validation loss: -0.6315\n",
      "2021-11-05 02:34:32.437890: Average global foreground Dice: [0.6849]\n",
      "2021-11-05 02:34:32.448071: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 02:34:34.203366: lr: 0.009458\n",
      "2021-11-05 02:34:34.410115: saving checkpoint...\n",
      "2021-11-05 02:34:35.936904: done, saving took 1.70 seconds\n",
      "2021-11-05 02:34:35.983548: This epoch took 345.416636 s\n",
      "\n",
      "2021-11-05 02:34:35.988261: \n",
      "epoch:  3\n",
      "2021-11-05 02:39:53.885740: train loss : -0.6588\n",
      "2021-11-05 02:40:15.268437: validation loss: -0.6961\n",
      "2021-11-05 02:40:15.278194: Average global foreground Dice: [0.7682]\n",
      "2021-11-05 02:40:15.283300: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 02:40:16.690113: lr: 0.009277\n",
      "2021-11-05 02:40:16.779110: saving checkpoint...\n",
      "2021-11-05 02:40:17.904620: done, saving took 1.20 seconds\n",
      "2021-11-05 02:40:17.939845: This epoch took 341.947560 s\n",
      "\n",
      "2021-11-05 02:40:17.944187: \n",
      "epoch:  4\n",
      "2021-11-05 02:45:32.900243: train loss : -0.7266\n",
      "2021-11-05 02:45:54.999482: validation loss: -0.7821\n",
      "2021-11-05 02:45:55.005469: Average global foreground Dice: [0.8151]\n",
      "2021-11-05 02:45:55.037446: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 02:45:56.779160: lr: 0.009095\n",
      "2021-11-05 02:45:56.988403: saving checkpoint...\n",
      "2021-11-05 02:45:58.393046: done, saving took 1.61 seconds\n",
      "2021-11-05 02:45:58.442675: This epoch took 340.492625 s\n",
      "\n",
      "2021-11-05 02:45:58.452757: \n",
      "epoch:  5\n",
      "2021-11-05 02:51:12.591220: train loss : -0.7631\n",
      "2021-11-05 02:51:36.102147: validation loss: -0.7900\n",
      "2021-11-05 02:51:36.137837: Average global foreground Dice: [0.8202]\n",
      "2021-11-05 02:51:36.142714: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 02:51:37.837727: lr: 0.008913\n",
      "2021-11-05 02:51:38.004096: saving checkpoint...\n",
      "2021-11-05 02:51:39.903633: done, saving took 2.06 seconds\n",
      "2021-11-05 02:51:39.979921: This epoch took 341.517059 s\n",
      "\n",
      "2021-11-05 02:51:39.984560: \n",
      "epoch:  6\n",
      "2021-11-05 02:56:53.337947: train loss : -0.7775\n",
      "2021-11-05 02:57:16.760793: validation loss: -0.8039\n",
      "2021-11-05 02:57:16.788251: Average global foreground Dice: [0.8303]\n",
      "2021-11-05 02:57:16.793057: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 02:57:19.270796: lr: 0.008731\n",
      "2021-11-05 02:57:19.492764: saving checkpoint...\n",
      "2021-11-05 02:57:21.541617: done, saving took 2.27 seconds\n",
      "2021-11-05 02:57:21.637155: This epoch took 341.647606 s\n",
      "\n",
      "2021-11-05 02:57:21.642177: \n",
      "epoch:  7\n",
      "2021-11-05 03:02:44.071500: train loss : -0.7887\n",
      "2021-11-05 03:03:08.002663: validation loss: -0.8089\n",
      "2021-11-05 03:03:08.079523: Average global foreground Dice: [0.8324]\n",
      "2021-11-05 03:03:08.089470: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 03:03:10.668646: lr: 0.008548\n",
      "2021-11-05 03:03:10.868866: saving checkpoint...\n",
      "2021-11-05 03:03:13.102924: done, saving took 2.43 seconds\n",
      "2021-11-05 03:03:13.167546: This epoch took 351.520514 s\n",
      "\n",
      "2021-11-05 03:03:13.172118: \n",
      "epoch:  8\n",
      "2021-11-05 03:08:31.660640: train loss : -0.7899\n",
      "2021-11-05 03:08:53.478390: validation loss: -0.8045\n",
      "2021-11-05 03:08:53.499692: Average global foreground Dice: [0.8259]\n",
      "2021-11-05 03:08:53.536800: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 03:08:56.370182: lr: 0.008364\n",
      "2021-11-05 03:08:56.468648: saving checkpoint...\n",
      "2021-11-05 03:08:58.274959: done, saving took 1.90 seconds\n",
      "2021-11-05 03:08:58.337166: This epoch took 345.159735 s\n",
      "\n",
      "2021-11-05 03:08:58.342401: \n",
      "epoch:  9\n",
      "2021-11-05 03:14:17.193225: train loss : -0.8012\n",
      "2021-11-05 03:14:39.254085: validation loss: -0.8109\n",
      "2021-11-05 03:14:39.263005: Average global foreground Dice: [0.8288]\n",
      "2021-11-05 03:14:39.272806: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 03:14:40.494119: lr: 0.008181\n",
      "2021-11-05 03:14:40.591467: saving checkpoint...\n",
      "2021-11-05 03:14:42.258193: done, saving took 1.75 seconds\n",
      "2021-11-05 03:14:42.298915: This epoch took 343.951514 s\n",
      "\n",
      "2021-11-05 03:14:42.304512: \n",
      "epoch:  10\n",
      "2021-11-05 03:19:59.938785: train loss : -0.8066\n",
      "2021-11-05 03:20:22.766853: validation loss: -0.8220\n",
      "2021-11-05 03:20:22.796994: Average global foreground Dice: [0.8412]\n",
      "2021-11-05 03:20:22.802159: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 03:20:24.830417: lr: 0.007996\n",
      "2021-11-05 03:20:24.867902: saving checkpoint...\n",
      "2021-11-05 03:20:26.646327: done, saving took 1.81 seconds\n",
      "2021-11-05 03:20:26.684886: This epoch took 344.375182 s\n",
      "\n",
      "2021-11-05 03:20:26.690191: \n",
      "epoch:  11\n",
      "2021-11-05 03:25:57.807773: train loss : -0.8103\n",
      "2021-11-05 03:26:20.975169: validation loss: -0.8252\n",
      "2021-11-05 03:26:21.037445: Average global foreground Dice: [0.8478]\n",
      "2021-11-05 03:26:21.048630: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 03:26:23.439646: lr: 0.007811\n",
      "2021-11-05 03:26:23.491143: saving checkpoint...\n",
      "2021-11-05 03:26:25.037197: done, saving took 1.59 seconds\n",
      "2021-11-05 03:26:25.081289: This epoch took 358.385253 s\n",
      "\n",
      "2021-11-05 03:26:25.086821: \n",
      "epoch:  12\n",
      "2021-11-05 03:31:41.856936: train loss : -0.8117\n",
      "2021-11-05 03:32:04.310056: validation loss: -0.8212\n",
      "2021-11-05 03:32:04.342906: Average global foreground Dice: [0.8352]\n",
      "2021-11-05 03:32:04.353236: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 03:32:06.772331: lr: 0.007626\n",
      "2021-11-05 03:32:06.940156: saving checkpoint...\n",
      "2021-11-05 03:32:09.100857: done, saving took 2.32 seconds\n",
      "2021-11-05 03:32:09.167996: This epoch took 344.075595 s\n",
      "\n",
      "2021-11-05 03:32:09.177960: \n",
      "epoch:  13\n",
      "2021-11-05 03:37:38.998371: train loss : -0.8119\n",
      "2021-11-05 03:38:01.253150: validation loss: -0.8322\n",
      "2021-11-05 03:38:01.273460: Average global foreground Dice: [0.8474]\n",
      "2021-11-05 03:38:01.285196: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 03:38:02.904347: lr: 0.00744\n",
      "2021-11-05 03:38:03.080549: saving checkpoint...\n",
      "2021-11-05 03:38:04.409642: done, saving took 1.47 seconds\n",
      "2021-11-05 03:38:04.466840: This epoch took 355.280211 s\n",
      "\n",
      "2021-11-05 03:38:04.472088: \n",
      "epoch:  14\n",
      "2021-11-05 03:43:15.204741: train loss : -0.8169\n",
      "2021-11-05 03:43:34.748055: validation loss: -0.8151\n",
      "2021-11-05 03:43:34.755671: Average global foreground Dice: [0.8309]\n",
      "2021-11-05 03:43:34.760789: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 03:43:35.307187: lr: 0.007254\n",
      "2021-11-05 03:43:35.375292: saving checkpoint...\n",
      "2021-11-05 03:43:36.497011: done, saving took 1.18 seconds\n",
      "2021-11-05 03:43:36.535286: This epoch took 332.057453 s\n",
      "\n",
      "2021-11-05 03:43:36.540639: \n",
      "epoch:  15\n",
      "2021-11-05 03:48:50.150778: train loss : -0.8148\n",
      "2021-11-05 03:49:11.092645: validation loss: -0.8232\n",
      "2021-11-05 03:49:11.105464: Average global foreground Dice: [0.8406]\n",
      "2021-11-05 03:49:11.111140: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 03:49:11.656536: lr: 0.007067\n",
      "2021-11-05 03:49:11.727155: saving checkpoint...\n",
      "2021-11-05 03:49:12.921140: done, saving took 1.25 seconds\n",
      "2021-11-05 03:49:12.980516: This epoch took 336.434415 s\n",
      "\n",
      "2021-11-05 03:49:12.985849: \n",
      "epoch:  16\n",
      "2021-11-05 03:54:24.098217: train loss : -0.8244\n",
      "2021-11-05 03:54:44.137852: validation loss: -0.8288\n",
      "2021-11-05 03:54:44.144113: Average global foreground Dice: [0.8434]\n",
      "2021-11-05 03:54:44.149015: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 03:54:44.666912: lr: 0.00688\n",
      "2021-11-05 03:54:44.700350: saving checkpoint...\n",
      "2021-11-05 03:54:45.901351: done, saving took 1.23 seconds\n",
      "2021-11-05 03:54:45.933965: This epoch took 332.943506 s\n",
      "\n",
      "2021-11-05 03:54:45.939430: \n",
      "epoch:  17\n",
      "2021-11-05 03:59:58.178524: train loss : -0.8303\n",
      "2021-11-05 04:00:17.948785: validation loss: -0.8218\n",
      "2021-11-05 04:00:17.956499: Average global foreground Dice: [0.8435]\n",
      "2021-11-05 04:00:17.963798: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 04:00:18.476704: lr: 0.006692\n",
      "2021-11-05 04:00:18.511648: saving checkpoint...\n",
      "2021-11-05 04:00:19.554489: done, saving took 1.07 seconds\n",
      "2021-11-05 04:00:19.584233: This epoch took 333.639559 s\n",
      "\n",
      "2021-11-05 04:00:19.593397: \n",
      "epoch:  18\n",
      "2021-11-05 04:05:32.106090: train loss : -0.8219\n",
      "2021-11-05 04:05:52.155438: validation loss: -0.8336\n",
      "2021-11-05 04:05:52.161203: Average global foreground Dice: [0.8492]\n",
      "2021-11-05 04:05:52.166971: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 04:05:52.715352: lr: 0.006504\n",
      "2021-11-05 04:05:52.748320: saving checkpoint...\n",
      "2021-11-05 04:05:53.933866: done, saving took 1.21 seconds\n",
      "2021-11-05 04:05:53.974897: This epoch took 334.375814 s\n",
      "\n",
      "2021-11-05 04:05:53.980598: \n",
      "epoch:  19\n",
      "2021-11-05 04:11:07.375458: train loss : -0.8237\n",
      "2021-11-05 04:11:27.109192: validation loss: -0.8306\n",
      "2021-11-05 04:11:27.114502: Average global foreground Dice: [0.8463]\n",
      "2021-11-05 04:11:27.119755: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 04:11:27.626873: lr: 0.006314\n",
      "2021-11-05 04:11:27.694770: saving checkpoint...\n",
      "2021-11-05 04:11:28.954095: done, saving took 1.32 seconds\n",
      "2021-11-05 04:11:28.987183: This epoch took 334.999991 s\n",
      "\n",
      "2021-11-05 04:11:28.993077: \n",
      "epoch:  20\n",
      "2021-11-05 04:16:41.350554: train loss : -0.8301\n",
      "2021-11-05 04:17:02.481926: validation loss: -0.8343\n",
      "2021-11-05 04:17:02.492867: Average global foreground Dice: [0.8502]\n",
      "2021-11-05 04:17:02.501417: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 04:17:03.030408: lr: 0.006125\n",
      "2021-11-05 04:17:03.095134: saving checkpoint...\n",
      "2021-11-05 04:17:04.155957: done, saving took 1.12 seconds\n",
      "2021-11-05 04:17:04.208174: This epoch took 335.210512 s\n",
      "\n",
      "2021-11-05 04:17:04.218908: \n",
      "epoch:  21\n",
      "2021-11-05 04:22:14.627587: train loss : -0.8327\n",
      "2021-11-05 04:22:33.275304: validation loss: -0.8349\n",
      "2021-11-05 04:22:33.281904: Average global foreground Dice: [0.8492]\n",
      "2021-11-05 04:22:33.287376: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 04:22:33.840022: lr: 0.005934\n",
      "2021-11-05 04:22:33.904228: saving checkpoint...\n",
      "2021-11-05 04:22:35.050418: done, saving took 1.21 seconds\n",
      "2021-11-05 04:22:35.110472: This epoch took 330.885940 s\n",
      "\n",
      "2021-11-05 04:22:35.118934: \n",
      "epoch:  22\n",
      "2021-11-05 04:27:46.659369: train loss : -0.8320\n",
      "2021-11-05 04:28:07.281809: validation loss: -0.8406\n",
      "2021-11-05 04:28:07.287096: Average global foreground Dice: [0.8533]\n",
      "2021-11-05 04:28:07.292115: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 04:28:07.795800: lr: 0.005743\n",
      "2021-11-05 04:28:07.861718: saving checkpoint...\n",
      "2021-11-05 04:28:09.338940: done, saving took 1.54 seconds\n",
      "2021-11-05 04:28:09.375714: This epoch took 334.252028 s\n",
      "\n",
      "2021-11-05 04:28:09.381008: \n",
      "epoch:  23\n",
      "2021-11-05 04:33:26.110665: train loss : -0.8321\n",
      "2021-11-05 04:33:45.333624: validation loss: -0.8338\n",
      "2021-11-05 04:33:45.339469: Average global foreground Dice: [0.851]\n",
      "2021-11-05 04:33:45.344110: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 04:33:45.849240: lr: 0.005551\n",
      "2021-11-05 04:33:45.882448: saving checkpoint...\n",
      "2021-11-05 04:33:47.080653: done, saving took 1.23 seconds\n",
      "2021-11-05 04:33:47.118511: This epoch took 337.732384 s\n",
      "\n",
      "2021-11-05 04:33:47.128573: \n",
      "epoch:  24\n",
      "2021-11-05 04:39:01.026489: train loss : -0.8385\n",
      "2021-11-05 04:39:20.033168: validation loss: -0.8330\n",
      "2021-11-05 04:39:20.040292: Average global foreground Dice: [0.8455]\n",
      "2021-11-05 04:39:20.045714: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 04:39:20.545472: lr: 0.005359\n",
      "2021-11-05 04:39:20.579185: saving checkpoint...\n",
      "2021-11-05 04:39:21.787855: done, saving took 1.24 seconds\n",
      "2021-11-05 04:39:21.812612: This epoch took 334.674031 s\n",
      "\n",
      "2021-11-05 04:39:21.817683: \n",
      "epoch:  25\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-05 04:44:33.525724: train loss : -0.8377\n",
      "2021-11-05 04:44:52.049589: validation loss: -0.8380\n",
      "2021-11-05 04:44:52.055861: Average global foreground Dice: [0.8508]\n",
      "2021-11-05 04:44:52.061194: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 04:44:52.589118: lr: 0.005166\n",
      "2021-11-05 04:44:52.622637: saving checkpoint...\n",
      "2021-11-05 04:44:53.734699: done, saving took 1.14 seconds\n",
      "2021-11-05 04:44:53.764518: This epoch took 331.941220 s\n",
      "\n",
      "2021-11-05 04:44:53.770016: \n",
      "epoch:  26\n",
      "2021-11-05 04:50:05.078966: train loss : -0.8390\n",
      "2021-11-05 04:50:23.685156: validation loss: -0.8398\n",
      "2021-11-05 04:50:23.691095: Average global foreground Dice: [0.8556]\n",
      "2021-11-05 04:50:23.702933: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 04:50:24.216903: lr: 0.004971\n",
      "2021-11-05 04:50:24.278722: saving checkpoint...\n",
      "2021-11-05 04:50:25.545123: done, saving took 1.32 seconds\n",
      "2021-11-05 04:50:25.577294: This epoch took 331.802502 s\n",
      "\n",
      "2021-11-05 04:50:25.582189: \n",
      "epoch:  27\n",
      "2021-11-05 04:55:39.046216: train loss : -0.8403\n",
      "2021-11-05 04:55:57.721109: validation loss: -0.8403\n",
      "2021-11-05 04:55:57.727055: Average global foreground Dice: [0.855]\n",
      "2021-11-05 04:55:57.732770: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 04:55:58.237560: lr: 0.004776\n",
      "2021-11-05 04:55:58.300956: saving checkpoint...\n",
      "2021-11-05 04:55:59.291496: done, saving took 1.05 seconds\n",
      "2021-11-05 04:55:59.323107: This epoch took 333.736078 s\n",
      "\n",
      "2021-11-05 04:55:59.328079: \n",
      "epoch:  28\n",
      "2021-11-05 05:01:09.538067: train loss : -0.8415\n",
      "2021-11-05 05:01:28.174219: validation loss: -0.8414\n",
      "2021-11-05 05:01:28.186842: Average global foreground Dice: [0.8535]\n",
      "2021-11-05 05:01:28.197171: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 05:01:28.731678: lr: 0.004581\n",
      "2021-11-05 05:01:28.800062: saving checkpoint...\n",
      "2021-11-05 05:01:29.968769: done, saving took 1.23 seconds\n",
      "2021-11-05 05:01:30.008453: This epoch took 330.675682 s\n",
      "\n",
      "2021-11-05 05:01:30.013509: \n",
      "epoch:  29\n",
      "2021-11-05 05:06:50.394238: train loss : -0.8388\n",
      "2021-11-05 05:07:12.264485: validation loss: -0.8405\n",
      "2021-11-05 05:07:12.271089: Average global foreground Dice: [0.8524]\n",
      "2021-11-05 05:07:12.276013: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 05:07:12.980055: lr: 0.004384\n",
      "2021-11-05 05:07:13.049969: saving checkpoint...\n",
      "2021-11-05 05:07:14.220613: done, saving took 1.23 seconds\n",
      "2021-11-05 05:07:14.265663: This epoch took 344.247457 s\n",
      "\n",
      "2021-11-05 05:07:14.270744: \n",
      "epoch:  30\n",
      "2021-11-05 05:12:26.820477: train loss : -0.8393\n",
      "2021-11-05 05:12:45.564299: validation loss: -0.8250\n",
      "2021-11-05 05:12:45.571683: Average global foreground Dice: [0.8442]\n",
      "2021-11-05 05:12:45.576777: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 05:12:46.099167: lr: 0.004186\n",
      "2021-11-05 05:12:46.166621: saving checkpoint...\n",
      "2021-11-05 05:12:47.283209: done, saving took 1.18 seconds\n",
      "2021-11-05 05:12:47.334169: This epoch took 333.058334 s\n",
      "\n",
      "2021-11-05 05:12:47.339859: \n",
      "epoch:  31\n",
      "2021-11-05 05:18:00.250588: train loss : -0.8427\n",
      "2021-11-05 05:18:22.395919: validation loss: -0.8411\n",
      "2021-11-05 05:18:22.437734: Average global foreground Dice: [0.8603]\n",
      "2021-11-05 05:18:22.444499: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 05:18:24.357537: lr: 0.003987\n",
      "2021-11-05 05:18:24.439813: saving checkpoint...\n",
      "2021-11-05 05:18:25.817849: done, saving took 1.45 seconds\n",
      "2021-11-05 05:18:25.878339: This epoch took 338.533363 s\n",
      "\n",
      "2021-11-05 05:18:25.883997: \n",
      "epoch:  32\n",
      "2021-11-05 05:23:38.250344: train loss : -0.8422\n",
      "2021-11-05 05:23:57.120773: validation loss: -0.8339\n",
      "2021-11-05 05:23:57.127472: Average global foreground Dice: [0.8514]\n",
      "2021-11-05 05:23:57.132520: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 05:23:57.629947: lr: 0.003787\n",
      "2021-11-05 05:23:57.664007: saving checkpoint...\n",
      "2021-11-05 05:23:58.746683: done, saving took 1.11 seconds\n",
      "2021-11-05 05:23:58.788493: This epoch took 332.899159 s\n",
      "\n",
      "2021-11-05 05:23:58.793497: \n",
      "epoch:  33\n",
      "2021-11-05 05:29:10.723163: train loss : -0.8455\n",
      "2021-11-05 05:29:29.046740: validation loss: -0.8405\n",
      "2021-11-05 05:29:29.053940: Average global foreground Dice: [0.8521]\n",
      "2021-11-05 05:29:29.059011: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 05:29:29.552687: lr: 0.003586\n",
      "2021-11-05 05:29:29.586372: saving checkpoint...\n",
      "2021-11-05 05:29:30.609845: done, saving took 1.05 seconds\n",
      "2021-11-05 05:29:30.634998: This epoch took 331.830555 s\n",
      "\n",
      "2021-11-05 05:29:30.641047: \n",
      "epoch:  34\n",
      "2021-11-05 05:34:43.563711: train loss : -0.8443\n",
      "2021-11-05 05:35:04.296633: validation loss: -0.8300\n",
      "2021-11-05 05:35:04.301722: Average global foreground Dice: [0.8447]\n",
      "2021-11-05 05:35:04.306266: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 05:35:04.860765: lr: 0.003384\n",
      "2021-11-05 05:35:04.896870: saving checkpoint...\n",
      "2021-11-05 05:35:06.036825: done, saving took 1.17 seconds\n",
      "2021-11-05 05:35:06.073538: This epoch took 335.427186 s\n",
      "\n",
      "2021-11-05 05:35:06.078551: \n",
      "epoch:  35\n",
      "2021-11-05 05:40:20.780776: train loss : -0.8452\n",
      "2021-11-05 05:40:43.693947: validation loss: -0.8396\n",
      "2021-11-05 05:40:43.700540: Average global foreground Dice: [0.8541]\n",
      "2021-11-05 05:40:43.705488: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 05:40:47.075360: lr: 0.00318\n",
      "2021-11-05 05:40:47.164939: saving checkpoint...\n",
      "2021-11-05 05:40:49.437156: done, saving took 2.36 seconds\n",
      "2021-11-05 05:40:49.484557: This epoch took 343.400430 s\n",
      "\n",
      "2021-11-05 05:40:49.490972: \n",
      "epoch:  36\n",
      "2021-11-05 05:46:11.494097: train loss : -0.8466\n",
      "2021-11-05 05:46:32.856569: validation loss: -0.8308\n",
      "2021-11-05 05:46:32.862404: Average global foreground Dice: [0.8485]\n",
      "2021-11-05 05:46:32.867482: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 05:46:34.640015: lr: 0.002975\n",
      "2021-11-05 05:46:34.699213: saving checkpoint...\n",
      "2021-11-05 05:46:36.637238: done, saving took 1.99 seconds\n",
      "2021-11-05 05:46:36.695399: This epoch took 347.198921 s\n",
      "\n",
      "2021-11-05 05:46:36.702202: \n",
      "epoch:  37\n",
      "2021-11-05 05:51:58.644678: train loss : -0.8487\n",
      "2021-11-05 05:52:21.776129: validation loss: -0.8478\n",
      "2021-11-05 05:52:21.781923: Average global foreground Dice: [0.8556]\n",
      "2021-11-05 05:52:21.787501: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 05:52:25.111170: lr: 0.002768\n",
      "2021-11-05 05:52:25.279983: saving checkpoint...\n",
      "2021-11-05 05:52:27.173597: done, saving took 2.04 seconds\n",
      "2021-11-05 05:52:27.237129: This epoch took 350.529855 s\n",
      "\n",
      "2021-11-05 05:52:27.242768: \n",
      "epoch:  38\n",
      "2021-11-05 05:58:11.390762: train loss : -0.8518\n",
      "2021-11-05 05:58:33.977929: validation loss: -0.8366\n",
      "2021-11-05 05:58:33.984810: Average global foreground Dice: [0.8484]\n",
      "2021-11-05 05:58:33.990364: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 05:58:36.037361: lr: 0.00256\n",
      "2021-11-05 05:58:36.165699: saving checkpoint...\n",
      "2021-11-05 05:58:38.348952: done, saving took 2.30 seconds\n",
      "2021-11-05 05:58:38.403361: This epoch took 371.155348 s\n",
      "\n",
      "2021-11-05 05:58:38.437099: \n",
      "epoch:  39\n",
      "2021-11-05 06:03:58.809972: train loss : -0.8516\n",
      "2021-11-05 06:04:21.109979: validation loss: -0.8312\n",
      "2021-11-05 06:04:21.150641: Average global foreground Dice: [0.8528]\n",
      "2021-11-05 06:04:21.155122: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 06:04:22.788495: lr: 0.002349\n",
      "2021-11-05 06:04:22.884684: saving checkpoint...\n",
      "2021-11-05 06:04:25.066667: done, saving took 2.27 seconds\n",
      "2021-11-05 06:04:25.137188: This epoch took 346.694526 s\n",
      "\n",
      "2021-11-05 06:04:25.145223: \n",
      "epoch:  40\n",
      "2021-11-05 06:09:54.052639: train loss : -0.8495\n",
      "2021-11-05 06:10:16.474221: validation loss: -0.8442\n",
      "2021-11-05 06:10:16.494787: Average global foreground Dice: [0.8507]\n",
      "2021-11-05 06:10:16.500329: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 06:10:18.137859: lr: 0.002137\n",
      "2021-11-05 06:10:18.174144: saving checkpoint...\n",
      "2021-11-05 06:10:20.137157: done, saving took 1.99 seconds\n",
      "2021-11-05 06:10:20.168289: This epoch took 355.017453 s\n",
      "\n",
      "2021-11-05 06:10:20.173324: \n",
      "epoch:  41\n",
      "2021-11-05 06:15:40.138308: train loss : -0.8542\n",
      "2021-11-05 06:16:02.588890: validation loss: -0.8369\n",
      "2021-11-05 06:16:02.597830: Average global foreground Dice: [0.8498]\n",
      "2021-11-05 06:16:02.603117: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 06:16:04.440109: lr: 0.001922\n",
      "2021-11-05 06:16:04.494713: saving checkpoint...\n",
      "2021-11-05 06:16:06.637198: done, saving took 2.19 seconds\n",
      "2021-11-05 06:16:06.683702: This epoch took 346.505162 s\n",
      "\n",
      "2021-11-05 06:16:06.689558: \n",
      "epoch:  42\n",
      "2021-11-05 06:21:36.452398: train loss : -0.8504\n",
      "2021-11-05 06:21:59.183020: validation loss: -0.8275\n",
      "2021-11-05 06:21:59.189384: Average global foreground Dice: [0.8435]\n",
      "2021-11-05 06:21:59.195241: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 06:22:02.189121: lr: 0.001704\n",
      "2021-11-05 06:22:02.361905: saving checkpoint...\n",
      "2021-11-05 06:22:04.090896: done, saving took 1.90 seconds\n",
      "2021-11-05 06:22:04.147438: This epoch took 357.452969 s\n",
      "\n",
      "2021-11-05 06:22:04.152185: \n",
      "epoch:  43\n",
      "2021-11-05 06:27:29.361884: train loss : -0.8529\n",
      "2021-11-05 06:27:52.176041: validation loss: -0.8487\n",
      "2021-11-05 06:27:52.189547: Average global foreground Dice: [0.8612]\n",
      "2021-11-05 06:27:52.195351: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 06:27:54.668777: lr: 0.001483\n",
      "2021-11-05 06:27:54.953555: saving checkpoint...\n",
      "2021-11-05 06:27:56.937258: done, saving took 2.26 seconds\n",
      "2021-11-05 06:27:56.996532: This epoch took 352.838756 s\n",
      "\n",
      "2021-11-05 06:27:57.004734: \n",
      "epoch:  44\n",
      "2021-11-05 06:33:16.268656: train loss : -0.8560\n",
      "2021-11-05 06:33:38.585906: validation loss: -0.8439\n",
      "2021-11-05 06:33:38.606263: Average global foreground Dice: [0.8539]\n",
      "2021-11-05 06:33:38.636727: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 06:33:40.839210: lr: 0.001259\n",
      "2021-11-05 06:33:40.975799: saving checkpoint...\n",
      "2021-11-05 06:33:42.595724: done, saving took 1.75 seconds\n",
      "2021-11-05 06:33:42.647028: This epoch took 345.607574 s\n",
      "\n",
      "2021-11-05 06:33:42.652026: \n",
      "epoch:  45\n",
      "2021-11-05 06:39:01.769008: train loss : -0.8586\n",
      "2021-11-05 06:39:24.063518: validation loss: -0.8462\n",
      "2021-11-05 06:39:24.073522: Average global foreground Dice: [0.859]\n",
      "2021-11-05 06:39:24.078817: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 06:39:26.139596: lr: 0.00103\n",
      "2021-11-05 06:39:26.253485: saving checkpoint...\n",
      "2021-11-05 06:39:28.123923: done, saving took 1.98 seconds\n",
      "2021-11-05 06:39:28.166398: This epoch took 345.509273 s\n",
      "\n",
      "2021-11-05 06:39:28.171894: \n",
      "epoch:  46\n",
      "2021-11-05 06:44:48.679336: train loss : -0.8541\n",
      "2021-11-05 06:45:11.264878: validation loss: -0.8365\n",
      "2021-11-05 06:45:11.281651: Average global foreground Dice: [0.8461]\n",
      "2021-11-05 06:45:11.286934: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 06:45:13.399449: lr: 0.000795\n",
      "2021-11-05 06:45:13.569494: saving checkpoint...\n",
      "2021-11-05 06:45:15.305773: done, saving took 1.90 seconds\n",
      "2021-11-05 06:45:15.349967: This epoch took 347.172428 s\n",
      "\n",
      "2021-11-05 06:45:15.355763: \n",
      "epoch:  47\n",
      "2021-11-05 06:50:34.305363: train loss : -0.8588\n",
      "2021-11-05 06:50:56.774483: validation loss: -0.8460\n",
      "2021-11-05 06:50:56.793892: Average global foreground Dice: [0.856]\n",
      "2021-11-05 06:50:56.798871: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 06:50:58.982799: lr: 0.000552\n",
      "2021-11-05 06:50:59.166398: saving checkpoint...\n",
      "2021-11-05 06:51:00.911353: done, saving took 1.92 seconds\n",
      "2021-11-05 06:51:00.949641: This epoch took 345.589096 s\n",
      "\n",
      "2021-11-05 06:51:00.955981: \n",
      "epoch:  48\n",
      "2021-11-05 06:56:19.846611: train loss : -0.8595\n",
      "2021-11-05 06:56:43.560637: validation loss: -0.8497\n",
      "2021-11-05 06:56:43.569860: Average global foreground Dice: [0.8614]\n",
      "2021-11-05 06:56:43.576224: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 06:56:46.045845: lr: 0.000296\n",
      "2021-11-05 06:56:46.143473: saving checkpoint...\n",
      "2021-11-05 06:56:48.483214: done, saving took 2.43 seconds\n",
      "2021-11-05 06:56:48.537329: This epoch took 347.576626 s\n",
      "\n",
      "2021-11-05 06:56:48.542757: \n",
      "epoch:  49\n",
      "2021-11-05 07:02:21.248666: train loss : -0.8584\n",
      "2021-11-05 07:02:43.792561: validation loss: -0.8468\n",
      "2021-11-05 07:02:43.800406: Average global foreground Dice: [0.8605]\n",
      "2021-11-05 07:02:43.805754: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 07:02:46.245147: lr: 0.0\n",
      "2021-11-05 07:02:46.250905: saving scheduled checkpoint file...\n",
      "2021-11-05 07:02:46.338907: saving checkpoint...\n",
      "2021-11-05 07:02:48.004773: done, saving took 1.75 seconds\n",
      "2021-11-05 07:02:48.059905: done\n",
      "2021-11-05 07:02:48.147521: saving checkpoint...\n",
      "2021-11-05 07:02:49.947254: done, saving took 1.88 seconds\n",
      "2021-11-05 07:02:49.974557: This epoch took 361.426772 s\n",
      "\n",
      "2021-11-05 07:02:50.085419: saving checkpoint...\n",
      "2021-11-05 07:02:51.963902: done, saving took 1.98 seconds\n",
      "23090558_20120330 (3, 263, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 263, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 7], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090564_20130312 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090568_20121018 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090569_20120607 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120613 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150908 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090593_20120625 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130103 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090600_20121108 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090603_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090607_20120420 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090609_20120510 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160119 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160510 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090646_20120718 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-05 07:06:21.135267: finished prediction\n",
      "2021-11-05 07:06:21.140322: evaluation of raw predictions\n",
      "2021-11-05 07:06:22.686792: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8521363497027576\n",
      "after:  0.8518557514225272\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Model 4 ()\n",
    "\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_Dice 555 0\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_Dice 555 1\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_Dice 555 2\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_Dice 555 3\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_Dice 555 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CE.nnUNetTrainerV2_Loss_CE'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-05 07:22:16.623443: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-05 07:22:16.639235: The split file contains 5 splits.\n",
      "2021-11-05 07:22:16.642836: Desired fold for training: 0\n",
      "2021-11-05 07:22:16.647015: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-05 07:22:20.994680: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-05 07:22:46.287867: Unable to plot network architecture:\n",
      "2021-11-05 07:22:46.292986: No module named 'hiddenlayer'\n",
      "2021-11-05 07:22:46.298242: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-05 07:22:46.303553: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-05 07:22:46.339597: \n",
      "\n",
      "2021-11-05 07:22:46.345115: \n",
      "epoch:  0\n",
      "2021-11-05 07:28:10.459443: train loss : 0.0335\n",
      "2021-11-05 07:28:30.452396: validation loss: 0.0053\n",
      "2021-11-05 07:28:30.469113: Average global foreground Dice: [0.0]\n",
      "2021-11-05 07:28:30.474458: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 07:28:33.039338: lr: 0.00982\n",
      "2021-11-05 07:28:33.043762: This epoch took 346.693738 s\n",
      "\n",
      "2021-11-05 07:28:33.048710: \n",
      "epoch:  1\n",
      "2021-11-05 07:33:36.171572: train loss : 0.0045\n",
      "2021-11-05 07:33:54.059757: validation loss: 0.0044\n",
      "2021-11-05 07:33:54.065645: Average global foreground Dice: [0.0]\n",
      "2021-11-05 07:33:54.070320: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 07:33:54.577415: lr: 0.009639\n",
      "2021-11-05 07:33:54.581425: This epoch took 321.524813 s\n",
      "\n",
      "2021-11-05 07:33:54.585755: \n",
      "epoch:  2\n",
      "2021-11-05 07:38:56.250554: train loss : 0.0038\n",
      "2021-11-05 07:39:15.344001: validation loss: 0.0038\n",
      "2021-11-05 07:39:15.348704: Average global foreground Dice: [0.0]\n",
      "2021-11-05 07:39:15.352885: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 07:39:16.804602: lr: 0.009458\n",
      "2021-11-05 07:39:16.810492: This epoch took 322.217674 s\n",
      "\n",
      "2021-11-05 07:39:16.815128: \n",
      "epoch:  3\n",
      "2021-11-05 07:44:17.051054: train loss : 0.0033\n",
      "2021-11-05 07:44:36.644892: validation loss: 0.0031\n",
      "2021-11-05 07:44:36.661701: Average global foreground Dice: [0.0]\n",
      "2021-11-05 07:44:36.666460: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 07:44:38.184371: lr: 0.009277\n",
      "2021-11-05 07:44:38.189292: This epoch took 321.369499 s\n",
      "\n",
      "2021-11-05 07:44:38.194091: \n",
      "epoch:  4\n",
      "2021-11-05 07:49:40.349258: train loss : 0.0026\n",
      "2021-11-05 07:49:59.511456: validation loss: 0.0024\n",
      "2021-11-05 07:49:59.517137: Average global foreground Dice: [0.0188]\n",
      "2021-11-05 07:49:59.523373: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 07:50:00.372781: lr: 0.009095\n",
      "2021-11-05 07:50:00.459671: saving checkpoint...\n",
      "2021-11-05 07:50:01.301052: done, saving took 0.92 seconds\n",
      "2021-11-05 07:50:01.336801: This epoch took 323.137972 s\n",
      "\n",
      "2021-11-05 07:50:01.343203: \n",
      "epoch:  5\n",
      "2021-11-05 07:55:05.558944: train loss : 0.0022\n",
      "2021-11-05 07:55:25.700972: validation loss: 0.0020\n",
      "2021-11-05 07:55:25.742065: Average global foreground Dice: [0.5322]\n",
      "2021-11-05 07:55:25.747239: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 07:55:28.540506: lr: 0.008913\n",
      "2021-11-05 07:55:28.777799: saving checkpoint...\n",
      "2021-11-05 07:55:30.805315: done, saving took 2.25 seconds\n",
      "2021-11-05 07:55:30.891721: This epoch took 329.544109 s\n",
      "\n",
      "2021-11-05 07:55:30.896611: \n",
      "epoch:  6\n",
      "2021-11-05 08:00:34.754882: train loss : 0.0020\n",
      "2021-11-05 08:00:54.279378: validation loss: 0.0018\n",
      "2021-11-05 08:00:54.288047: Average global foreground Dice: [0.6801]\n",
      "2021-11-05 08:00:54.292286: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 08:00:56.971049: lr: 0.008731\n",
      "2021-11-05 08:00:57.194203: saving checkpoint...\n",
      "2021-11-05 08:00:59.237579: done, saving took 2.26 seconds\n",
      "2021-11-05 08:00:59.270605: This epoch took 328.369392 s\n",
      "\n",
      "2021-11-05 08:00:59.275599: \n",
      "epoch:  7\n",
      "2021-11-05 08:06:06.050403: train loss : 0.0018\n",
      "2021-11-05 08:06:25.457486: validation loss: 0.0017\n",
      "2021-11-05 08:06:25.465253: Average global foreground Dice: [0.6256]\n",
      "2021-11-05 08:06:25.470488: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 08:06:27.778790: lr: 0.008548\n",
      "2021-11-05 08:06:28.097989: saving checkpoint...\n",
      "2021-11-05 08:06:29.943040: done, saving took 2.16 seconds\n",
      "2021-11-05 08:06:30.037387: This epoch took 330.756089 s\n",
      "\n",
      "2021-11-05 08:06:30.047694: \n",
      "epoch:  8\n",
      "2021-11-05 08:11:33.383549: train loss : 0.0017\n",
      "2021-11-05 08:11:53.238209: validation loss: 0.0016\n",
      "2021-11-05 08:11:53.250418: Average global foreground Dice: [0.7189]\n",
      "2021-11-05 08:11:53.258677: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 08:11:55.637897: lr: 0.008364\n",
      "2021-11-05 08:11:55.851645: saving checkpoint...\n",
      "2021-11-05 08:11:57.555091: done, saving took 1.91 seconds\n",
      "2021-11-05 08:11:57.637446: This epoch took 327.578829 s\n",
      "\n",
      "2021-11-05 08:11:57.642952: \n",
      "epoch:  9\n",
      "2021-11-05 08:16:57.075140: train loss : 0.0016\n",
      "2021-11-05 08:17:16.069920: validation loss: 0.0016\n",
      "2021-11-05 08:17:16.077659: Average global foreground Dice: [0.7443]\n",
      "2021-11-05 08:17:16.082428: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 08:17:16.610515: lr: 0.008181\n",
      "2021-11-05 08:17:16.643359: saving checkpoint...\n",
      "2021-11-05 08:17:18.072515: done, saving took 1.46 seconds\n",
      "2021-11-05 08:17:18.097090: This epoch took 320.449517 s\n",
      "\n",
      "2021-11-05 08:17:18.102277: \n",
      "epoch:  10\n",
      "2021-11-05 08:22:20.778040: train loss : 0.0016\n",
      "2021-11-05 08:22:40.047114: validation loss: 0.0016\n",
      "2021-11-05 08:22:40.053213: Average global foreground Dice: [0.6704]\n",
      "2021-11-05 08:22:40.058320: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 08:22:40.648793: lr: 0.007996\n",
      "2021-11-05 08:22:40.683883: saving checkpoint...\n",
      "2021-11-05 08:22:41.690635: done, saving took 1.04 seconds\n",
      "2021-11-05 08:22:41.714838: This epoch took 323.606717 s\n",
      "\n",
      "2021-11-05 08:22:41.719423: \n",
      "epoch:  11\n",
      "2021-11-05 08:27:41.152725: train loss : 0.0016\n",
      "2021-11-05 08:27:59.381935: validation loss: 0.0016\n",
      "2021-11-05 08:27:59.398077: Average global foreground Dice: [0.7544]\n",
      "2021-11-05 08:27:59.409558: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 08:27:59.947913: lr: 0.007811\n",
      "2021-11-05 08:27:59.983911: saving checkpoint...\n",
      "2021-11-05 08:28:01.120061: done, saving took 1.16 seconds\n",
      "2021-11-05 08:28:01.167913: This epoch took 319.443675 s\n",
      "\n",
      "2021-11-05 08:28:01.178308: \n",
      "epoch:  12\n",
      "2021-11-05 08:32:58.910915: train loss : 0.0015\n",
      "2021-11-05 08:33:17.227721: validation loss: 0.0015\n",
      "2021-11-05 08:33:17.233895: Average global foreground Dice: [0.7258]\n",
      "2021-11-05 08:33:17.238745: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 08:33:17.759824: lr: 0.007626\n",
      "2021-11-05 08:33:17.793010: saving checkpoint...\n",
      "2021-11-05 08:33:18.768142: done, saving took 1.00 seconds\n",
      "2021-11-05 08:33:18.792824: This epoch took 317.609618 s\n",
      "\n",
      "2021-11-05 08:33:18.798034: \n",
      "epoch:  13\n",
      "2021-11-05 08:38:20.250513: train loss : 0.0014\n",
      "2021-11-05 08:38:38.978451: validation loss: 0.0015\n",
      "2021-11-05 08:38:38.984913: Average global foreground Dice: [0.7487]\n",
      "2021-11-05 08:38:38.992859: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 08:38:39.514171: lr: 0.00744\n",
      "2021-11-05 08:38:39.548201: saving checkpoint...\n",
      "2021-11-05 08:38:40.645622: done, saving took 1.13 seconds\n",
      "2021-11-05 08:38:40.681669: This epoch took 321.878697 s\n",
      "\n",
      "2021-11-05 08:38:40.686888: \n",
      "epoch:  14\n",
      "2021-11-05 08:43:42.553704: train loss : 0.0014\n",
      "2021-11-05 08:44:01.605556: validation loss: 0.0014\n",
      "2021-11-05 08:44:01.611132: Average global foreground Dice: [0.7699]\n",
      "2021-11-05 08:44:01.616246: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 08:44:02.126745: lr: 0.007254\n",
      "2021-11-05 08:44:02.161458: saving checkpoint...\n",
      "2021-11-05 08:44:03.173151: done, saving took 1.04 seconds\n",
      "2021-11-05 08:44:03.197518: This epoch took 322.505783 s\n",
      "\n",
      "2021-11-05 08:44:03.202105: \n",
      "epoch:  15\n",
      "2021-11-05 08:49:04.650167: train loss : 0.0014\n",
      "2021-11-05 08:49:23.861655: validation loss: 0.0014\n",
      "2021-11-05 08:49:23.868681: Average global foreground Dice: [0.7889]\n",
      "2021-11-05 08:49:23.874372: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 08:49:24.591312: lr: 0.007067\n",
      "2021-11-05 08:49:24.624902: saving checkpoint...\n",
      "2021-11-05 08:49:25.608211: done, saving took 1.01 seconds\n",
      "2021-11-05 08:49:25.654235: This epoch took 322.447460 s\n",
      "\n",
      "2021-11-05 08:49:25.658589: \n",
      "epoch:  16\n",
      "2021-11-05 08:54:29.063849: train loss : 0.0014\n",
      "2021-11-05 08:54:47.640842: validation loss: 0.0014\n",
      "2021-11-05 08:54:47.646003: Average global foreground Dice: [0.8015]\n",
      "2021-11-05 08:54:47.650679: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 08:54:48.160199: lr: 0.00688\n",
      "2021-11-05 08:54:48.193449: saving checkpoint...\n",
      "2021-11-05 08:54:49.713373: done, saving took 1.55 seconds\n",
      "2021-11-05 08:54:49.749515: This epoch took 324.086576 s\n",
      "\n",
      "2021-11-05 08:54:49.753776: \n",
      "epoch:  17\n",
      "2021-11-05 08:59:49.571412: train loss : 0.0013\n",
      "2021-11-05 09:00:07.671536: validation loss: 0.0013\n",
      "2021-11-05 09:00:07.676817: Average global foreground Dice: [0.7602]\n",
      "2021-11-05 09:00:07.682316: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 09:00:08.180855: lr: 0.006692\n",
      "2021-11-05 09:00:08.214062: saving checkpoint...\n",
      "2021-11-05 09:00:09.257150: done, saving took 1.07 seconds\n",
      "2021-11-05 09:00:09.292939: This epoch took 319.533287 s\n",
      "\n",
      "2021-11-05 09:00:09.298000: \n",
      "epoch:  18\n",
      "2021-11-05 09:05:13.750399: train loss : 0.0013\n",
      "2021-11-05 09:05:33.244673: validation loss: 0.0013\n",
      "2021-11-05 09:05:33.262613: Average global foreground Dice: [0.7879]\n",
      "2021-11-05 09:05:33.267700: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 09:05:34.435903: lr: 0.006504\n",
      "2021-11-05 09:05:34.475391: saving checkpoint...\n",
      "2021-11-05 09:05:35.953623: done, saving took 1.51 seconds\n",
      "2021-11-05 09:05:35.985271: This epoch took 326.681908 s\n",
      "\n",
      "2021-11-05 09:05:35.990084: \n",
      "epoch:  19\n",
      "2021-11-05 09:10:39.284243: train loss : 0.0013\n",
      "2021-11-05 09:10:58.655384: validation loss: 0.0013\n",
      "2021-11-05 09:10:58.677289: Average global foreground Dice: [0.7965]\n",
      "2021-11-05 09:10:58.689146: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 09:11:00.385719: lr: 0.006314\n",
      "2021-11-05 09:11:00.421973: saving checkpoint...\n",
      "2021-11-05 09:11:01.561607: done, saving took 1.17 seconds\n",
      "2021-11-05 09:11:01.590834: This epoch took 325.595896 s\n",
      "\n",
      "2021-11-05 09:11:01.595850: \n",
      "epoch:  20\n",
      "2021-11-05 09:16:04.864550: train loss : 0.0013\n",
      "2021-11-05 09:16:24.260836: validation loss: 0.0013\n",
      "2021-11-05 09:16:24.267994: Average global foreground Dice: [0.7837]\n",
      "2021-11-05 09:16:24.273577: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 09:16:25.567119: lr: 0.006125\n",
      "2021-11-05 09:16:25.605298: saving checkpoint...\n",
      "2021-11-05 09:16:26.904976: done, saving took 1.33 seconds\n",
      "2021-11-05 09:16:26.928784: This epoch took 325.328018 s\n",
      "\n",
      "2021-11-05 09:16:26.934222: \n",
      "epoch:  21\n",
      "2021-11-05 09:21:29.961217: train loss : 0.0013\n",
      "2021-11-05 09:21:49.194077: validation loss: 0.0013\n",
      "2021-11-05 09:21:49.198861: Average global foreground Dice: [0.7759]\n",
      "2021-11-05 09:21:49.204164: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 09:21:50.662952: lr: 0.005934\n",
      "2021-11-05 09:21:50.731532: saving checkpoint...\n",
      "2021-11-05 09:21:52.017807: done, saving took 1.35 seconds\n",
      "2021-11-05 09:21:52.041729: This epoch took 325.103047 s\n",
      "\n",
      "2021-11-05 09:21:52.047169: \n",
      "epoch:  22\n",
      "2021-11-05 09:26:54.878486: train loss : 0.0013\n",
      "2021-11-05 09:27:14.380536: validation loss: 0.0013\n",
      "2021-11-05 09:27:14.437648: Average global foreground Dice: [0.8056]\n",
      "2021-11-05 09:27:14.443032: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 09:27:16.462192: lr: 0.005743\n",
      "2021-11-05 09:27:16.542461: saving checkpoint...\n",
      "2021-11-05 09:27:18.047191: done, saving took 1.58 seconds\n",
      "2021-11-05 09:27:18.078067: This epoch took 326.026067 s\n",
      "\n",
      "2021-11-05 09:27:18.083318: \n",
      "epoch:  23\n",
      "2021-11-05 09:32:26.274797: train loss : 0.0013\n",
      "2021-11-05 09:32:46.296785: validation loss: 0.0013\n",
      "2021-11-05 09:32:46.302881: Average global foreground Dice: [0.8073]\n",
      "2021-11-05 09:32:46.308283: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 09:32:48.638301: lr: 0.005551\n",
      "2021-11-05 09:32:48.698514: saving checkpoint...\n",
      "2021-11-05 09:32:50.653538: done, saving took 2.01 seconds\n",
      "2021-11-05 09:32:50.687634: This epoch took 332.597228 s\n",
      "\n",
      "2021-11-05 09:32:50.693187: \n",
      "epoch:  24\n",
      "2021-11-05 09:37:56.550575: train loss : 0.0012\n",
      "2021-11-05 09:38:16.276467: validation loss: 0.0013\n",
      "2021-11-05 09:38:16.298142: Average global foreground Dice: [0.8033]\n",
      "2021-11-05 09:38:16.304224: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 09:38:18.656444: lr: 0.005359\n",
      "2021-11-05 09:38:18.708041: saving checkpoint...\n",
      "2021-11-05 09:38:20.580053: done, saving took 1.92 seconds\n",
      "2021-11-05 09:38:20.636700: This epoch took 329.938015 s\n",
      "\n",
      "2021-11-05 09:38:20.642030: \n",
      "epoch:  25\n",
      "2021-11-05 09:43:35.458842: train loss : 0.0012\n",
      "2021-11-05 09:43:55.356304: validation loss: 0.0012\n",
      "2021-11-05 09:43:55.382418: Average global foreground Dice: [0.807]\n",
      "2021-11-05 09:43:55.387476: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 09:43:58.202134: lr: 0.005166\n",
      "2021-11-05 09:43:58.285763: saving checkpoint...\n",
      "2021-11-05 09:44:00.237293: done, saving took 2.03 seconds\n",
      "2021-11-05 09:44:00.286412: This epoch took 339.639118 s\n",
      "\n",
      "2021-11-05 09:44:00.291582: \n",
      "epoch:  26\n",
      "2021-11-05 09:49:08.705899: train loss : 0.0012\n",
      "2021-11-05 09:49:28.448016: validation loss: 0.0012\n",
      "2021-11-05 09:49:28.465613: Average global foreground Dice: [0.7975]\n",
      "2021-11-05 09:49:28.471041: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 09:49:30.081332: lr: 0.004971\n",
      "2021-11-05 09:49:30.158309: saving checkpoint...\n",
      "2021-11-05 09:49:31.346569: done, saving took 1.26 seconds\n",
      "2021-11-05 09:49:31.378605: This epoch took 331.077560 s\n",
      "\n",
      "2021-11-05 09:49:31.387498: \n",
      "epoch:  27\n",
      "2021-11-05 09:54:38.241714: train loss : 0.0012\n",
      "2021-11-05 09:54:58.199664: validation loss: 0.0011\n",
      "2021-11-05 09:54:58.250156: Average global foreground Dice: [0.8104]\n",
      "2021-11-05 09:54:58.254591: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 09:55:00.283156: lr: 0.004776\n",
      "2021-11-05 09:55:00.339866: saving checkpoint...\n",
      "2021-11-05 09:55:01.571805: done, saving took 1.28 seconds\n",
      "2021-11-05 09:55:01.615005: This epoch took 330.219337 s\n",
      "\n",
      "2021-11-05 09:55:01.620285: \n",
      "epoch:  28\n",
      "2021-11-05 10:00:08.401573: train loss : 0.0012\n",
      "2021-11-05 10:00:28.108636: validation loss: 0.0012\n",
      "2021-11-05 10:00:28.144069: Average global foreground Dice: [0.8022]\n",
      "2021-11-05 10:00:28.149162: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 10:00:30.737949: lr: 0.004581\n",
      "2021-11-05 10:00:30.799719: saving checkpoint...\n",
      "2021-11-05 10:00:32.705657: done, saving took 1.96 seconds\n",
      "2021-11-05 10:00:32.764662: This epoch took 331.139173 s\n",
      "\n",
      "2021-11-05 10:00:32.769745: \n",
      "epoch:  29\n",
      "2021-11-05 10:05:38.361707: train loss : 0.0012\n",
      "2021-11-05 10:05:57.841428: validation loss: 0.0012\n",
      "2021-11-05 10:05:57.846812: Average global foreground Dice: [0.8188]\n",
      "2021-11-05 10:05:57.851086: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 10:05:58.998479: lr: 0.004384\n",
      "2021-11-05 10:05:59.045890: saving checkpoint...\n",
      "2021-11-05 10:06:00.931911: done, saving took 1.93 seconds\n",
      "2021-11-05 10:06:00.963657: This epoch took 328.189494 s\n",
      "\n",
      "2021-11-05 10:06:00.968845: \n",
      "epoch:  30\n",
      "2021-11-05 10:11:04.878602: train loss : 0.0012\n",
      "2021-11-05 10:11:24.244541: validation loss: 0.0011\n",
      "2021-11-05 10:11:24.249916: Average global foreground Dice: [0.8087]\n",
      "2021-11-05 10:11:24.254023: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 10:11:24.895688: lr: 0.004186\n",
      "2021-11-05 10:11:24.929459: saving checkpoint...\n",
      "2021-11-05 10:11:26.474123: done, saving took 1.57 seconds\n",
      "2021-11-05 10:11:26.497274: This epoch took 325.523823 s\n",
      "\n",
      "2021-11-05 10:11:26.502190: \n",
      "epoch:  31\n",
      "2021-11-05 10:16:33.536877: train loss : 0.0012\n",
      "2021-11-05 10:16:53.260295: validation loss: 0.0012\n",
      "2021-11-05 10:16:53.270692: Average global foreground Dice: [0.814]\n",
      "2021-11-05 10:16:53.276141: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 10:16:54.677196: lr: 0.003987\n",
      "2021-11-05 10:16:54.746685: saving checkpoint...\n",
      "2021-11-05 10:16:56.884218: done, saving took 2.20 seconds\n",
      "2021-11-05 10:16:56.916831: This epoch took 330.409575 s\n",
      "\n",
      "2021-11-05 10:16:56.921620: \n",
      "epoch:  32\n",
      "2021-11-05 10:22:00.469862: train loss : 0.0011\n",
      "2021-11-05 10:22:18.706419: validation loss: 0.0011\n",
      "2021-11-05 10:22:18.712291: Average global foreground Dice: [0.8115]\n",
      "2021-11-05 10:22:18.717651: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 10:22:19.225241: lr: 0.003787\n",
      "2021-11-05 10:22:19.258770: saving checkpoint...\n",
      "2021-11-05 10:22:20.584535: done, saving took 1.35 seconds\n",
      "2021-11-05 10:22:20.613847: This epoch took 323.686991 s\n",
      "\n",
      "2021-11-05 10:22:20.618666: \n",
      "epoch:  33\n",
      "2021-11-05 10:27:27.550348: train loss : 0.0011\n",
      "2021-11-05 10:27:47.297541: validation loss: 0.0012\n",
      "2021-11-05 10:27:47.304654: Average global foreground Dice: [0.805]\n",
      "2021-11-05 10:27:47.309742: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 10:27:49.004735: lr: 0.003586\n",
      "2021-11-05 10:27:49.065224: saving checkpoint...\n",
      "2021-11-05 10:27:51.696757: done, saving took 2.69 seconds\n",
      "2021-11-05 10:27:51.724946: This epoch took 331.101063 s\n",
      "\n",
      "2021-11-05 10:27:51.729901: \n",
      "epoch:  34\n",
      "2021-11-05 10:32:56.464028: train loss : 0.0011\n",
      "2021-11-05 10:33:15.949366: validation loss: 0.0012\n",
      "2021-11-05 10:33:15.968028: Average global foreground Dice: [0.8019]\n",
      "2021-11-05 10:33:15.972158: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 10:33:17.169726: lr: 0.003384\n",
      "2021-11-05 10:33:17.212622: saving checkpoint...\n",
      "2021-11-05 10:33:18.370544: done, saving took 1.19 seconds\n",
      "2021-11-05 10:33:18.410396: This epoch took 326.675835 s\n",
      "\n",
      "2021-11-05 10:33:18.418610: \n",
      "epoch:  35\n",
      "2021-11-05 10:38:23.270703: train loss : 0.0011\n",
      "2021-11-05 10:38:42.641763: validation loss: 0.0012\n",
      "2021-11-05 10:38:42.651284: Average global foreground Dice: [0.8114]\n",
      "2021-11-05 10:38:42.660912: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 10:38:43.565060: lr: 0.00318\n",
      "2021-11-05 10:38:43.598663: saving checkpoint...\n",
      "2021-11-05 10:38:44.613911: done, saving took 1.04 seconds\n",
      "2021-11-05 10:38:44.639473: This epoch took 326.215290 s\n",
      "\n",
      "2021-11-05 10:38:44.644318: \n",
      "epoch:  36\n",
      "2021-11-05 10:43:50.170723: train loss : 0.0011\n",
      "2021-11-05 10:44:08.529927: validation loss: 0.0011\n",
      "2021-11-05 10:44:08.535549: Average global foreground Dice: [0.7996]\n",
      "2021-11-05 10:44:08.539567: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 10:44:09.039210: lr: 0.002975\n",
      "2021-11-05 10:44:09.073858: saving checkpoint...\n",
      "2021-11-05 10:44:10.065902: done, saving took 1.02 seconds\n",
      "2021-11-05 10:44:10.089602: This epoch took 325.440365 s\n",
      "\n",
      "2021-11-05 10:44:10.093973: \n",
      "epoch:  37\n",
      "2021-11-05 10:49:14.050779: train loss : 0.0011\n",
      "2021-11-05 10:49:32.082859: validation loss: 0.0011\n",
      "2021-11-05 10:49:32.088408: Average global foreground Dice: [0.8002]\n",
      "2021-11-05 10:49:32.093409: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 10:49:32.605762: lr: 0.002768\n",
      "2021-11-05 10:49:32.638516: saving checkpoint...\n",
      "2021-11-05 10:49:33.789050: done, saving took 1.18 seconds\n",
      "2021-11-05 10:49:33.821046: This epoch took 323.722311 s\n",
      "\n",
      "2021-11-05 10:49:33.826092: \n",
      "epoch:  38\n",
      "2021-11-05 10:54:41.659032: train loss : 0.0011\n",
      "2021-11-05 10:55:01.141188: validation loss: 0.0012\n",
      "2021-11-05 10:55:01.148050: Average global foreground Dice: [0.8264]\n",
      "2021-11-05 10:55:01.153712: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 10:55:01.842815: lr: 0.00256\n",
      "2021-11-05 10:55:01.877074: saving checkpoint...\n",
      "2021-11-05 10:55:02.882854: done, saving took 1.03 seconds\n",
      "2021-11-05 10:55:02.906914: This epoch took 329.075944 s\n",
      "\n",
      "2021-11-05 10:55:02.911553: \n",
      "epoch:  39\n",
      "2021-11-05 11:00:08.862712: train loss : 0.0011\n",
      "2021-11-05 11:00:28.044755: validation loss: 0.0012\n",
      "2021-11-05 11:00:28.049842: Average global foreground Dice: [0.8099]\n",
      "2021-11-05 11:00:28.055406: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 11:00:29.218458: lr: 0.002349\n",
      "2021-11-05 11:00:29.257476: saving checkpoint...\n",
      "2021-11-05 11:00:30.454139: done, saving took 1.23 seconds\n",
      "2021-11-05 11:00:30.512660: This epoch took 327.595884 s\n",
      "\n",
      "2021-11-05 11:00:30.520638: \n",
      "epoch:  40\n",
      "2021-11-05 11:05:38.349826: train loss : 0.0011\n",
      "2021-11-05 11:05:58.252654: validation loss: 0.0011\n",
      "2021-11-05 11:05:58.259488: Average global foreground Dice: [0.8218]\n",
      "2021-11-05 11:05:58.264968: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 11:06:00.585853: lr: 0.002137\n",
      "2021-11-05 11:06:00.649330: saving checkpoint...\n",
      "2021-11-05 11:06:02.036913: done, saving took 1.44 seconds\n",
      "2021-11-05 11:06:02.085420: This epoch took 331.560075 s\n",
      "\n",
      "2021-11-05 11:06:02.093681: \n",
      "epoch:  41\n",
      "2021-11-05 11:11:08.564759: train loss : 0.0011\n",
      "2021-11-05 11:11:27.944800: validation loss: 0.0011\n",
      "2021-11-05 11:11:27.962056: Average global foreground Dice: [0.8249]\n",
      "2021-11-05 11:11:27.968063: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 11:11:28.783027: lr: 0.001922\n",
      "2021-11-05 11:11:28.817489: saving checkpoint...\n",
      "2021-11-05 11:11:29.950187: done, saving took 1.16 seconds\n",
      "2021-11-05 11:11:29.983373: This epoch took 327.881091 s\n",
      "\n",
      "2021-11-05 11:11:29.990142: \n",
      "epoch:  42\n",
      "2021-11-05 11:16:41.761518: train loss : 0.0011\n",
      "2021-11-05 11:17:00.043081: validation loss: 0.0011\n",
      "2021-11-05 11:17:00.052930: Average global foreground Dice: [0.8156]\n",
      "2021-11-05 11:17:00.062384: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 11:17:00.576165: lr: 0.001704\n",
      "2021-11-05 11:17:00.609631: saving checkpoint...\n",
      "2021-11-05 11:17:01.733510: done, saving took 1.15 seconds\n",
      "2021-11-05 11:17:01.762003: This epoch took 331.762293 s\n",
      "\n",
      "2021-11-05 11:17:01.766640: \n",
      "epoch:  43\n",
      "2021-11-05 11:22:08.459827: train loss : 0.0010\n",
      "2021-11-05 11:22:26.211156: validation loss: 0.0011\n",
      "2021-11-05 11:22:26.222176: Average global foreground Dice: [0.8122]\n",
      "2021-11-05 11:22:26.230397: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 11:22:26.733421: lr: 0.001483\n",
      "2021-11-05 11:22:26.767185: saving checkpoint...\n",
      "2021-11-05 11:22:27.768726: done, saving took 1.03 seconds\n",
      "2021-11-05 11:22:27.793479: This epoch took 326.021780 s\n",
      "\n",
      "2021-11-05 11:22:27.798285: \n",
      "epoch:  44\n",
      "2021-11-05 11:27:34.852129: train loss : 0.0011\n",
      "2021-11-05 11:27:52.585375: validation loss: 0.0012\n",
      "2021-11-05 11:27:52.591627: Average global foreground Dice: [0.8141]\n",
      "2021-11-05 11:27:52.596677: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 11:27:53.096825: lr: 0.001259\n",
      "2021-11-05 11:27:53.130681: saving checkpoint...\n",
      "2021-11-05 11:27:54.195045: done, saving took 1.09 seconds\n",
      "2021-11-05 11:27:54.229629: This epoch took 326.426000 s\n",
      "\n",
      "2021-11-05 11:27:54.234268: \n",
      "epoch:  45\n",
      "2021-11-05 11:33:01.126142: train loss : 0.0010\n",
      "2021-11-05 11:33:18.926742: validation loss: 0.0012\n",
      "2021-11-05 11:33:18.936485: Average global foreground Dice: [0.8074]\n",
      "2021-11-05 11:33:18.945235: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 11:33:19.433805: lr: 0.00103\n",
      "2021-11-05 11:33:19.467518: saving checkpoint...\n",
      "2021-11-05 11:33:20.471676: done, saving took 1.03 seconds\n",
      "2021-11-05 11:33:20.499274: This epoch took 326.260114 s\n",
      "\n",
      "2021-11-05 11:33:20.503790: \n",
      "epoch:  46\n",
      "2021-11-05 11:38:28.963693: train loss : 0.0011\n",
      "2021-11-05 11:38:47.395872: validation loss: 0.0011\n",
      "2021-11-05 11:38:47.402060: Average global foreground Dice: [0.8248]\n",
      "2021-11-05 11:38:47.407488: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 11:38:47.938359: lr: 0.000795\n",
      "2021-11-05 11:38:47.972262: saving checkpoint...\n",
      "2021-11-05 11:38:49.089403: done, saving took 1.15 seconds\n",
      "2021-11-05 11:38:49.127485: This epoch took 328.617832 s\n",
      "\n",
      "2021-11-05 11:38:49.138904: \n",
      "epoch:  47\n",
      "2021-11-05 11:43:56.523049: train loss : 0.0011\n",
      "2021-11-05 11:44:14.525369: validation loss: 0.0011\n",
      "2021-11-05 11:44:14.530450: Average global foreground Dice: [0.828]\n",
      "2021-11-05 11:44:14.535423: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 11:44:15.044901: lr: 0.000552\n",
      "2021-11-05 11:44:15.085196: saving checkpoint...\n",
      "2021-11-05 11:44:16.034728: done, saving took 0.98 seconds\n",
      "2021-11-05 11:44:16.058681: This epoch took 326.914091 s\n",
      "\n",
      "2021-11-05 11:44:16.062519: \n",
      "epoch:  48\n",
      "2021-11-05 11:49:24.313000: train loss : 0.0011\n",
      "2021-11-05 11:49:42.396259: validation loss: 0.0010\n",
      "2021-11-05 11:49:42.401749: Average global foreground Dice: [0.8233]\n",
      "2021-11-05 11:49:42.406164: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 11:49:42.915768: lr: 0.000296\n",
      "2021-11-05 11:49:42.949606: saving checkpoint...\n",
      "2021-11-05 11:49:44.013860: done, saving took 1.09 seconds\n",
      "2021-11-05 11:49:44.063082: This epoch took 327.995547 s\n",
      "\n",
      "2021-11-05 11:49:44.068552: \n",
      "epoch:  49\n",
      "2021-11-05 11:54:51.698386: train loss : 0.0011\n",
      "2021-11-05 11:55:09.451895: validation loss: 0.0011\n",
      "2021-11-05 11:55:09.458439: Average global foreground Dice: [0.8289]\n",
      "2021-11-05 11:55:09.464358: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 11:55:09.962831: lr: 0.0\n",
      "2021-11-05 11:55:09.967909: saving scheduled checkpoint file...\n",
      "2021-11-05 11:55:10.000343: saving checkpoint...\n",
      "2021-11-05 11:55:10.808098: done, saving took 0.84 seconds\n",
      "2021-11-05 11:55:10.826858: done\n",
      "2021-11-05 11:55:10.860543: saving checkpoint...\n",
      "2021-11-05 11:55:11.796273: done, saving took 0.96 seconds\n",
      "2021-11-05 11:55:11.822371: This epoch took 327.749051 s\n",
      "\n",
      "2021-11-05 11:55:11.856604: saving checkpoint...\n",
      "2021-11-05 11:55:12.679253: done, saving took 0.85 seconds\n",
      "23090559_20150812 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120330 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090563_20151216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130226 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090584_20120523 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090589_20140219 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090592_20130218 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090614_20120402 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090620_20130617 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090627_20160608 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090628_20150204 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090635_20140710 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090640_20140711 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121227 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-05 11:58:41.515684: finished prediction\n",
      "2021-11-05 11:58:41.521774: evaluation of raw predictions\n",
      "2021-11-05 11:58:43.180356: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8364522810207902\n",
      "after:  0.8364522810207902\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CE.nnUNetTrainerV2_Loss_CE'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-05 11:58:54.830271: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-05 11:58:54.844925: The split file contains 5 splits.\n",
      "2021-11-05 11:58:54.849186: Desired fold for training: 1\n",
      "2021-11-05 11:58:54.853067: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-05 11:58:59.207878: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-05 11:59:32.484111: Unable to plot network architecture:\n",
      "2021-11-05 11:59:32.489626: No module named 'hiddenlayer'\n",
      "2021-11-05 11:59:32.494614: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-05 11:59:32.499941: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-05 11:59:32.538790: \n",
      "\n",
      "2021-11-05 11:59:32.547858: \n",
      "epoch:  0\n",
      "2021-11-05 12:04:57.853908: train loss : 0.0363\n",
      "2021-11-05 12:05:16.664876: validation loss: 0.0041\n",
      "2021-11-05 12:05:16.675971: Average global foreground Dice: [0.0]\n",
      "2021-11-05 12:05:16.683044: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 12:05:17.136464: lr: 0.00982\n",
      "2021-11-05 12:05:17.142158: This epoch took 344.583956 s\n",
      "\n",
      "2021-11-05 12:05:17.147321: \n",
      "epoch:  1\n",
      "2021-11-05 12:10:13.048994: train loss : 0.0043\n",
      "2021-11-05 12:10:32.391975: validation loss: 0.0038\n",
      "2021-11-05 12:10:32.398366: Average global foreground Dice: [0.0]\n",
      "2021-11-05 12:10:32.402760: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 12:10:33.518532: lr: 0.009639\n",
      "2021-11-05 12:10:33.522661: This epoch took 316.369525 s\n",
      "\n",
      "2021-11-05 12:10:33.527250: \n",
      "epoch:  2\n",
      "2021-11-05 12:15:28.065447: train loss : 0.0037\n",
      "2021-11-05 12:15:47.885530: validation loss: 0.0032\n",
      "2021-11-05 12:15:47.891285: Average global foreground Dice: [0.0]\n",
      "2021-11-05 12:15:47.896238: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 12:15:49.978143: lr: 0.009458\n",
      "2021-11-05 12:15:49.987883: This epoch took 316.456303 s\n",
      "\n",
      "2021-11-05 12:15:49.997830: \n",
      "epoch:  3\n",
      "2021-11-05 12:20:45.848668: train loss : 0.0031\n",
      "2021-11-05 12:21:05.670866: validation loss: 0.0027\n",
      "2021-11-05 12:21:05.680302: Average global foreground Dice: [0.0983]\n",
      "2021-11-05 12:21:05.685189: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 12:21:07.777661: lr: 0.009277\n",
      "2021-11-05 12:21:07.992080: saving checkpoint...\n",
      "2021-11-05 12:21:09.265815: done, saving took 1.48 seconds\n",
      "2021-11-05 12:21:09.337273: This epoch took 319.332337 s\n",
      "\n",
      "2021-11-05 12:21:09.341775: \n",
      "epoch:  4\n",
      "2021-11-05 12:26:09.553073: train loss : 0.0025\n",
      "2021-11-05 12:26:29.057822: validation loss: 0.0021\n",
      "2021-11-05 12:26:29.068920: Average global foreground Dice: [0.535]\n",
      "2021-11-05 12:26:29.074043: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 12:26:29.815318: lr: 0.009095\n",
      "2021-11-05 12:26:29.898661: saving checkpoint...\n",
      "2021-11-05 12:26:31.095545: done, saving took 1.27 seconds\n",
      "2021-11-05 12:26:31.134539: This epoch took 321.788525 s\n",
      "\n",
      "2021-11-05 12:26:31.141266: \n",
      "epoch:  5\n",
      "2021-11-05 12:31:30.707777: train loss : 0.0022\n",
      "2021-11-05 12:31:50.644626: validation loss: 0.0018\n",
      "2021-11-05 12:31:50.650617: Average global foreground Dice: [0.6339]\n",
      "2021-11-05 12:31:50.655489: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 12:31:51.938577: lr: 0.008913\n",
      "2021-11-05 12:31:52.053225: saving checkpoint...\n",
      "2021-11-05 12:31:53.220997: done, saving took 1.27 seconds\n",
      "2021-11-05 12:31:53.243859: This epoch took 322.093875 s\n",
      "\n",
      "2021-11-05 12:31:53.249080: \n",
      "epoch:  6\n",
      "2021-11-05 12:36:54.278262: train loss : 0.0019\n",
      "2021-11-05 12:37:13.860307: validation loss: 0.0018\n",
      "2021-11-05 12:37:13.865433: Average global foreground Dice: [0.6246]\n",
      "2021-11-05 12:37:13.870420: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 12:37:16.065851: lr: 0.008731\n",
      "2021-11-05 12:37:16.140790: saving checkpoint...\n",
      "2021-11-05 12:37:17.223379: done, saving took 1.15 seconds\n",
      "2021-11-05 12:37:17.251191: This epoch took 323.997813 s\n",
      "\n",
      "2021-11-05 12:37:17.256042: \n",
      "epoch:  7\n",
      "2021-11-05 12:42:19.569006: train loss : 0.0019\n",
      "2021-11-05 12:42:39.797556: validation loss: 0.0016\n",
      "2021-11-05 12:42:39.804806: Average global foreground Dice: [0.6836]\n",
      "2021-11-05 12:42:39.837096: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 12:42:41.462373: lr: 0.008548\n",
      "2021-11-05 12:42:41.564797: saving checkpoint...\n",
      "2021-11-05 12:42:43.641776: done, saving took 2.17 seconds\n",
      "2021-11-05 12:42:43.680520: This epoch took 326.418972 s\n",
      "\n",
      "2021-11-05 12:42:43.686973: \n",
      "epoch:  8\n",
      "2021-11-05 12:47:42.666268: train loss : 0.0018\n",
      "2021-11-05 12:48:01.989475: validation loss: 0.0016\n",
      "2021-11-05 12:48:01.993824: Average global foreground Dice: [0.7043]\n",
      "2021-11-05 12:48:01.998263: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 12:48:02.520324: lr: 0.008364\n",
      "2021-11-05 12:48:02.586481: saving checkpoint...\n",
      "2021-11-05 12:48:03.623163: done, saving took 1.10 seconds\n",
      "2021-11-05 12:48:03.664695: This epoch took 319.972723 s\n",
      "\n",
      "2021-11-05 12:48:03.669131: \n",
      "epoch:  9\n",
      "2021-11-05 12:53:04.294974: train loss : 0.0016\n",
      "2021-11-05 12:53:23.269086: validation loss: 0.0014\n",
      "2021-11-05 12:53:23.275203: Average global foreground Dice: [0.7214]\n",
      "2021-11-05 12:53:23.281286: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 12:53:23.784918: lr: 0.008181\n",
      "2021-11-05 12:53:23.819196: saving checkpoint...\n",
      "2021-11-05 12:53:24.872620: done, saving took 1.08 seconds\n",
      "2021-11-05 12:53:24.906133: This epoch took 321.231323 s\n",
      "\n",
      "2021-11-05 12:53:24.911211: \n",
      "epoch:  10\n",
      "2021-11-05 12:58:23.174354: train loss : 0.0016\n",
      "2021-11-05 12:58:42.217389: validation loss: 0.0014\n",
      "2021-11-05 12:58:42.228350: Average global foreground Dice: [0.7433]\n",
      "2021-11-05 12:58:42.240277: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 12:58:42.819533: lr: 0.007996\n",
      "2021-11-05 12:58:42.912113: saving checkpoint...\n",
      "2021-11-05 12:58:43.893253: done, saving took 1.06 seconds\n",
      "2021-11-05 12:58:43.924034: This epoch took 319.007320 s\n",
      "\n",
      "2021-11-05 12:58:43.929144: \n",
      "epoch:  11\n",
      "2021-11-05 13:03:42.640490: train loss : 0.0016\n",
      "2021-11-05 13:04:00.931426: validation loss: 0.0014\n",
      "2021-11-05 13:04:00.937292: Average global foreground Dice: [0.7376]\n",
      "2021-11-05 13:04:00.943026: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 13:04:01.477768: lr: 0.007811\n",
      "2021-11-05 13:04:01.559954: saving checkpoint...\n",
      "2021-11-05 13:04:02.746688: done, saving took 1.26 seconds\n",
      "2021-11-05 13:04:02.771071: This epoch took 318.837145 s\n",
      "\n",
      "2021-11-05 13:04:02.775831: \n",
      "epoch:  12\n",
      "2021-11-05 13:08:58.515084: train loss : 0.0015\n",
      "2021-11-05 13:09:16.946760: validation loss: 0.0013\n",
      "2021-11-05 13:09:16.952222: Average global foreground Dice: [0.7663]\n",
      "2021-11-05 13:09:16.957193: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 13:09:17.484510: lr: 0.007626\n",
      "2021-11-05 13:09:17.563675: saving checkpoint...\n",
      "2021-11-05 13:09:18.541696: done, saving took 1.05 seconds\n",
      "2021-11-05 13:09:18.575836: This epoch took 315.794639 s\n",
      "\n",
      "2021-11-05 13:09:18.581275: \n",
      "epoch:  13\n",
      "2021-11-05 13:14:19.473146: train loss : 0.0014\n",
      "2021-11-05 13:14:39.608492: validation loss: 0.0013\n",
      "2021-11-05 13:14:39.641196: Average global foreground Dice: [0.761]\n",
      "2021-11-05 13:14:39.646359: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 13:14:41.337893: lr: 0.00744\n",
      "2021-11-05 13:14:41.543419: saving checkpoint...\n",
      "2021-11-05 13:14:43.387899: done, saving took 2.04 seconds\n",
      "2021-11-05 13:14:43.463397: This epoch took 324.876497 s\n",
      "\n",
      "2021-11-05 13:14:43.469006: \n",
      "epoch:  14\n",
      "2021-11-05 13:19:46.486351: train loss : 0.0014\n",
      "2021-11-05 13:20:06.770438: validation loss: 0.0012\n",
      "2021-11-05 13:20:06.775753: Average global foreground Dice: [0.7799]\n",
      "2021-11-05 13:20:06.792611: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 13:20:10.937335: lr: 0.007254\n",
      "2021-11-05 13:20:11.053451: saving checkpoint...\n",
      "2021-11-05 13:20:12.945910: done, saving took 2.00 seconds\n",
      "2021-11-05 13:20:12.980891: This epoch took 329.507198 s\n",
      "\n",
      "2021-11-05 13:20:12.988078: \n",
      "epoch:  15\n",
      "2021-11-05 13:25:15.367757: train loss : 0.0014\n",
      "2021-11-05 13:25:35.358732: validation loss: 0.0013\n",
      "2021-11-05 13:25:35.373247: Average global foreground Dice: [0.7581]\n",
      "2021-11-05 13:25:35.378018: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 13:25:36.938184: lr: 0.007067\n",
      "2021-11-05 13:25:37.047093: saving checkpoint...\n",
      "2021-11-05 13:25:38.695422: done, saving took 1.75 seconds\n",
      "2021-11-05 13:25:38.735582: This epoch took 325.738232 s\n",
      "\n",
      "2021-11-05 13:25:38.740977: \n",
      "epoch:  16\n",
      "2021-11-05 13:30:42.374041: train loss : 0.0014\n",
      "2021-11-05 13:31:02.503334: validation loss: 0.0012\n",
      "2021-11-05 13:31:02.509770: Average global foreground Dice: [0.7705]\n",
      "2021-11-05 13:31:02.541350: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 13:31:04.737695: lr: 0.00688\n",
      "2021-11-05 13:31:04.797181: saving checkpoint...\n",
      "2021-11-05 13:31:06.937102: done, saving took 2.19 seconds\n",
      "2021-11-05 13:31:06.969900: This epoch took 328.223599 s\n",
      "\n",
      "2021-11-05 13:31:06.974353: \n",
      "epoch:  17\n",
      "2021-11-05 13:36:12.268025: train loss : 0.0014\n",
      "2021-11-05 13:36:32.446571: validation loss: 0.0012\n",
      "2021-11-05 13:36:32.462289: Average global foreground Dice: [0.7687]\n",
      "2021-11-05 13:36:32.468073: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 13:36:34.537774: lr: 0.006692\n",
      "2021-11-05 13:36:34.643896: saving checkpoint...\n",
      "2021-11-05 13:36:36.289600: done, saving took 1.75 seconds\n",
      "2021-11-05 13:36:36.337495: This epoch took 329.358359 s\n",
      "\n",
      "2021-11-05 13:36:36.342071: \n",
      "epoch:  18\n",
      "2021-11-05 13:41:38.869253: train loss : 0.0013\n",
      "2021-11-05 13:41:59.141500: validation loss: 0.0012\n",
      "2021-11-05 13:41:59.167100: Average global foreground Dice: [0.7472]\n",
      "2021-11-05 13:41:59.172300: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 13:42:01.337949: lr: 0.006504\n",
      "2021-11-05 13:42:01.542785: saving checkpoint...\n",
      "2021-11-05 13:42:02.879488: done, saving took 1.54 seconds\n",
      "2021-11-05 13:42:02.926961: This epoch took 326.580030 s\n",
      "\n",
      "2021-11-05 13:42:02.932159: \n",
      "epoch:  19\n",
      "2021-11-05 13:47:07.558349: train loss : 0.0013\n",
      "2021-11-05 13:47:27.844667: validation loss: 0.0012\n",
      "2021-11-05 13:47:27.864555: Average global foreground Dice: [0.782]\n",
      "2021-11-05 13:47:27.870712: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 13:47:30.606827: lr: 0.006314\n",
      "2021-11-05 13:47:30.793138: saving checkpoint...\n",
      "2021-11-05 13:47:32.737148: done, saving took 2.10 seconds\n",
      "2021-11-05 13:47:32.769886: This epoch took 329.832596 s\n",
      "\n",
      "2021-11-05 13:47:32.775583: \n",
      "epoch:  20\n",
      "2021-11-05 13:52:34.251387: train loss : 0.0013\n",
      "2021-11-05 13:52:53.318053: validation loss: 0.0011\n",
      "2021-11-05 13:52:53.323494: Average global foreground Dice: [0.7789]\n",
      "2021-11-05 13:52:53.328120: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 13:52:53.924072: lr: 0.006125\n",
      "2021-11-05 13:52:53.957196: saving checkpoint...\n",
      "2021-11-05 13:52:55.069346: done, saving took 1.14 seconds\n",
      "2021-11-05 13:52:55.096126: This epoch took 322.314978 s\n",
      "\n",
      "2021-11-05 13:52:55.103546: \n",
      "epoch:  21\n",
      "2021-11-05 13:57:55.710161: train loss : 0.0013\n",
      "2021-11-05 13:58:14.092196: validation loss: 0.0011\n",
      "2021-11-05 13:58:14.097449: Average global foreground Dice: [0.7702]\n",
      "2021-11-05 13:58:14.102483: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 13:58:14.594419: lr: 0.005934\n",
      "2021-11-05 13:58:14.628087: saving checkpoint...\n",
      "2021-11-05 13:58:15.599499: done, saving took 1.00 seconds\n",
      "2021-11-05 13:58:15.621988: This epoch took 320.513538 s\n",
      "\n",
      "2021-11-05 13:58:15.627050: \n",
      "epoch:  22\n",
      "2021-11-05 14:03:17.047835: train loss : 0.0012\n",
      "2021-11-05 14:03:35.871054: validation loss: 0.0011\n",
      "2021-11-05 14:03:35.880193: Average global foreground Dice: [0.7788]\n",
      "2021-11-05 14:03:35.886921: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 14:03:36.464799: lr: 0.005743\n",
      "2021-11-05 14:03:36.501953: saving checkpoint...\n",
      "2021-11-05 14:03:38.183506: done, saving took 1.71 seconds\n",
      "2021-11-05 14:03:38.218266: This epoch took 322.587059 s\n",
      "\n",
      "2021-11-05 14:03:38.222558: \n",
      "epoch:  23\n",
      "2021-11-05 14:08:41.998364: train loss : 0.0013\n",
      "2021-11-05 14:09:01.945324: validation loss: 0.0011\n",
      "2021-11-05 14:09:01.961423: Average global foreground Dice: [0.7928]\n",
      "2021-11-05 14:09:01.966797: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 14:09:03.280938: lr: 0.005551\n",
      "2021-11-05 14:09:03.319798: saving checkpoint...\n",
      "2021-11-05 14:09:04.427566: done, saving took 1.14 seconds\n",
      "2021-11-05 14:09:04.452395: This epoch took 326.224119 s\n",
      "\n",
      "2021-11-05 14:09:04.457264: \n",
      "epoch:  24\n",
      "2021-11-05 14:14:05.961378: train loss : 0.0012\n",
      "2021-11-05 14:14:24.738206: validation loss: 0.0011\n",
      "2021-11-05 14:14:24.743588: Average global foreground Dice: [0.7734]\n",
      "2021-11-05 14:14:24.748153: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 14:14:25.278912: lr: 0.005359\n",
      "2021-11-05 14:14:25.312552: saving checkpoint...\n",
      "2021-11-05 14:14:26.414129: done, saving took 1.13 seconds\n",
      "2021-11-05 14:14:26.450215: This epoch took 321.988588 s\n",
      "\n",
      "2021-11-05 14:14:26.455172: \n",
      "epoch:  25\n",
      "2021-11-05 14:19:27.850363: train loss : 0.0012\n",
      "2021-11-05 14:19:47.285494: validation loss: 0.0012\n",
      "2021-11-05 14:19:47.292213: Average global foreground Dice: [0.7799]\n",
      "2021-11-05 14:19:47.297764: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 14:19:48.026004: lr: 0.005166\n",
      "2021-11-05 14:19:48.059035: saving checkpoint...\n",
      "2021-11-05 14:19:49.187450: done, saving took 1.16 seconds\n",
      "2021-11-05 14:19:49.216560: This epoch took 322.755368 s\n",
      "\n",
      "2021-11-05 14:19:49.220804: \n",
      "epoch:  26\n",
      "2021-11-05 14:24:51.144916: train loss : 0.0012\n",
      "2021-11-05 14:25:10.740734: validation loss: 0.0011\n",
      "2021-11-05 14:25:10.745631: Average global foreground Dice: [0.7898]\n",
      "2021-11-05 14:25:10.750170: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 14:25:11.322618: lr: 0.004971\n",
      "2021-11-05 14:25:11.356855: saving checkpoint...\n",
      "2021-11-05 14:25:12.465549: done, saving took 1.14 seconds\n",
      "2021-11-05 14:25:12.496460: This epoch took 323.271030 s\n",
      "\n",
      "2021-11-05 14:25:12.503848: \n",
      "epoch:  27\n",
      "2021-11-05 14:30:16.874182: train loss : 0.0012\n",
      "2021-11-05 14:30:36.644374: validation loss: 0.0011\n",
      "2021-11-05 14:30:36.665740: Average global foreground Dice: [0.7891]\n",
      "2021-11-05 14:30:36.670309: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 14:30:38.586909: lr: 0.004776\n",
      "2021-11-05 14:30:38.647014: saving checkpoint...\n",
      "2021-11-05 14:30:39.929724: done, saving took 1.34 seconds\n",
      "2021-11-05 14:30:39.973696: This epoch took 327.460330 s\n",
      "\n",
      "2021-11-05 14:30:39.981997: \n",
      "epoch:  28\n",
      "2021-11-05 14:35:45.499873: train loss : 0.0012\n",
      "2021-11-05 14:36:05.199668: validation loss: 0.0011\n",
      "2021-11-05 14:36:05.244078: Average global foreground Dice: [0.803]\n",
      "2021-11-05 14:36:05.252150: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 14:36:05.937802: lr: 0.004581\n",
      "2021-11-05 14:36:05.972473: saving checkpoint...\n",
      "2021-11-05 14:36:07.012512: done, saving took 1.07 seconds\n",
      "2021-11-05 14:36:07.038241: This epoch took 327.051209 s\n",
      "\n",
      "2021-11-05 14:36:07.044557: \n",
      "epoch:  29\n",
      "2021-11-05 14:41:09.599906: train loss : 0.0012\n",
      "2021-11-05 14:41:27.748310: validation loss: 0.0011\n",
      "2021-11-05 14:41:27.754842: Average global foreground Dice: [0.7872]\n",
      "2021-11-05 14:41:27.759721: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 14:41:28.290441: lr: 0.004384\n",
      "2021-11-05 14:41:28.323981: saving checkpoint...\n",
      "2021-11-05 14:41:30.154508: done, saving took 1.86 seconds\n",
      "2021-11-05 14:41:30.187358: This epoch took 323.138912 s\n",
      "\n",
      "2021-11-05 14:41:30.191611: \n",
      "epoch:  30\n",
      "2021-11-05 14:46:34.950793: train loss : 0.0012\n",
      "2021-11-05 14:46:54.556094: validation loss: 0.0011\n",
      "2021-11-05 14:46:54.584722: Average global foreground Dice: [0.7792]\n",
      "2021-11-05 14:46:54.588928: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 14:46:55.866516: lr: 0.004186\n",
      "2021-11-05 14:46:55.900677: saving checkpoint...\n",
      "2021-11-05 14:46:56.961729: done, saving took 1.09 seconds\n",
      "2021-11-05 14:46:56.988485: This epoch took 326.790438 s\n",
      "\n",
      "2021-11-05 14:46:56.993724: \n",
      "epoch:  31\n",
      "2021-11-05 14:52:01.773832: train loss : 0.0011\n",
      "2021-11-05 14:52:21.547137: validation loss: 0.0010\n",
      "2021-11-05 14:52:21.553285: Average global foreground Dice: [0.7842]\n",
      "2021-11-05 14:52:21.568994: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 14:52:22.765549: lr: 0.003987\n",
      "2021-11-05 14:52:22.858579: saving checkpoint...\n",
      "2021-11-05 14:52:24.067680: done, saving took 1.30 seconds\n",
      "2021-11-05 14:52:24.118143: This epoch took 327.119123 s\n",
      "\n",
      "2021-11-05 14:52:24.124293: \n",
      "epoch:  32\n",
      "2021-11-05 14:57:29.489488: train loss : 0.0012\n",
      "2021-11-05 14:57:49.208353: validation loss: 0.0011\n",
      "2021-11-05 14:57:49.250560: Average global foreground Dice: [0.7771]\n",
      "2021-11-05 14:57:49.256626: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 14:57:51.149776: lr: 0.003787\n",
      "2021-11-05 14:57:51.254202: saving checkpoint...\n",
      "2021-11-05 14:57:52.833294: done, saving took 1.68 seconds\n",
      "2021-11-05 14:57:52.857215: This epoch took 328.728291 s\n",
      "\n",
      "2021-11-05 14:57:52.861621: \n",
      "epoch:  33\n",
      "2021-11-05 15:02:53.663188: train loss : 0.0011\n",
      "2021-11-05 15:03:12.844833: validation loss: 0.0010\n",
      "2021-11-05 15:03:12.851475: Average global foreground Dice: [0.7853]\n",
      "2021-11-05 15:03:12.857692: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 15:03:13.925171: lr: 0.003586\n",
      "2021-11-05 15:03:13.959198: saving checkpoint...\n",
      "2021-11-05 15:03:15.119864: done, saving took 1.19 seconds\n",
      "2021-11-05 15:03:15.160965: This epoch took 322.294998 s\n",
      "\n",
      "2021-11-05 15:03:15.167350: \n",
      "epoch:  34\n",
      "2021-11-05 15:08:20.259979: train loss : 0.0011\n",
      "2021-11-05 15:08:40.157657: validation loss: 0.0011\n",
      "2021-11-05 15:08:40.169811: Average global foreground Dice: [0.8024]\n",
      "2021-11-05 15:08:40.175584: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 15:08:41.837837: lr: 0.003384\n",
      "2021-11-05 15:08:41.949003: saving checkpoint...\n",
      "2021-11-05 15:08:43.882965: done, saving took 2.04 seconds\n",
      "2021-11-05 15:08:43.937413: This epoch took 328.763163 s\n",
      "\n",
      "2021-11-05 15:08:43.943642: \n",
      "epoch:  35\n",
      "2021-11-05 15:13:49.650853: train loss : 0.0011\n",
      "2021-11-05 15:14:09.045450: validation loss: 0.0011\n",
      "2021-11-05 15:14:09.051800: Average global foreground Dice: [0.8004]\n",
      "2021-11-05 15:14:09.057917: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 15:14:09.920154: lr: 0.00318\n",
      "2021-11-05 15:14:09.956882: saving checkpoint...\n",
      "2021-11-05 15:14:10.975009: done, saving took 1.05 seconds\n",
      "2021-11-05 15:14:11.009438: This epoch took 327.061413 s\n",
      "\n",
      "2021-11-05 15:14:11.014335: \n",
      "epoch:  36\n",
      "2021-11-05 15:19:19.268190: train loss : 0.0011\n",
      "2021-11-05 15:19:38.953667: validation loss: 0.0010\n",
      "2021-11-05 15:19:38.963290: Average global foreground Dice: [0.8023]\n",
      "2021-11-05 15:19:38.971349: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 15:19:40.902139: lr: 0.002975\n",
      "2021-11-05 15:19:40.962939: saving checkpoint...\n",
      "2021-11-05 15:19:42.252067: done, saving took 1.34 seconds\n",
      "2021-11-05 15:19:42.302339: This epoch took 331.282708 s\n",
      "\n",
      "2021-11-05 15:19:42.308207: \n",
      "epoch:  37\n",
      "2021-11-05 15:24:46.287559: train loss : 0.0011\n",
      "2021-11-05 15:25:05.211067: validation loss: 0.0010\n",
      "2021-11-05 15:25:05.216539: Average global foreground Dice: [0.7994]\n",
      "2021-11-05 15:25:05.221370: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 15:25:05.738844: lr: 0.002768\n",
      "2021-11-05 15:25:05.795420: saving checkpoint...\n",
      "2021-11-05 15:25:06.766588: done, saving took 1.02 seconds\n",
      "2021-11-05 15:25:06.793963: This epoch took 324.480917 s\n",
      "\n",
      "2021-11-05 15:25:06.800104: \n",
      "epoch:  38\n",
      "2021-11-05 15:30:12.662576: train loss : 0.0011\n",
      "2021-11-05 15:30:32.846991: validation loss: 0.0011\n",
      "2021-11-05 15:30:32.864358: Average global foreground Dice: [0.7977]\n",
      "2021-11-05 15:30:32.871466: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 15:30:35.649138: lr: 0.00256\n",
      "2021-11-05 15:30:35.854166: saving checkpoint...\n",
      "2021-11-05 15:30:38.237193: done, saving took 2.58 seconds\n",
      "2021-11-05 15:30:38.293733: This epoch took 331.487666 s\n",
      "\n",
      "2021-11-05 15:30:38.298229: \n",
      "epoch:  39\n",
      "2021-11-05 15:35:45.992905: train loss : 0.0012\n",
      "2021-11-05 15:36:05.611817: validation loss: 0.0010\n",
      "2021-11-05 15:36:05.646001: Average global foreground Dice: [0.8046]\n",
      "2021-11-05 15:36:05.650435: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 15:36:07.139835: lr: 0.002349\n",
      "2021-11-05 15:36:07.201342: saving checkpoint...\n",
      "2021-11-05 15:36:08.670525: done, saving took 1.53 seconds\n",
      "2021-11-05 15:36:08.697213: This epoch took 330.393261 s\n",
      "\n",
      "2021-11-05 15:36:08.702000: \n",
      "epoch:  40\n",
      "2021-11-05 15:41:19.750316: train loss : 0.0011\n",
      "2021-11-05 15:41:39.803250: validation loss: 0.0010\n",
      "2021-11-05 15:41:39.853837: Average global foreground Dice: [0.8]\n",
      "2021-11-05 15:41:39.859818: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 15:41:42.774390: lr: 0.002137\n",
      "2021-11-05 15:41:42.884049: saving checkpoint...\n",
      "2021-11-05 15:41:45.237129: done, saving took 2.45 seconds\n",
      "2021-11-05 15:41:45.274048: This epoch took 336.567111 s\n",
      "\n",
      "2021-11-05 15:41:45.279293: \n",
      "epoch:  41\n",
      "2021-11-05 15:46:51.277903: train loss : 0.0011\n",
      "2021-11-05 15:47:10.612728: validation loss: 0.0010\n",
      "2021-11-05 15:47:10.618451: Average global foreground Dice: [0.8162]\n",
      "2021-11-05 15:47:10.623153: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 15:47:11.158142: lr: 0.001922\n",
      "2021-11-05 15:47:11.191442: saving checkpoint...\n",
      "2021-11-05 15:47:12.302714: done, saving took 1.14 seconds\n",
      "2021-11-05 15:47:12.326188: This epoch took 327.042225 s\n",
      "\n",
      "2021-11-05 15:47:12.331207: \n",
      "epoch:  42\n",
      "2021-11-05 15:52:17.279501: train loss : 0.0011\n",
      "2021-11-05 15:52:36.252372: validation loss: 0.0010\n",
      "2021-11-05 15:52:36.257817: Average global foreground Dice: [0.8045]\n",
      "2021-11-05 15:52:36.263094: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 15:52:36.762683: lr: 0.001704\n",
      "2021-11-05 15:52:36.795927: saving checkpoint...\n",
      "2021-11-05 15:52:38.065044: done, saving took 1.30 seconds\n",
      "2021-11-05 15:52:38.102363: This epoch took 325.764429 s\n",
      "\n",
      "2021-11-05 15:52:38.111957: \n",
      "epoch:  43\n",
      "2021-11-05 15:57:43.111574: train loss : 0.0011\n",
      "2021-11-05 15:58:02.852101: validation loss: 0.0010\n",
      "2021-11-05 15:58:02.858346: Average global foreground Dice: [0.8151]\n",
      "2021-11-05 15:58:02.863468: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 15:58:03.697351: lr: 0.001483\n",
      "2021-11-05 15:58:03.733832: saving checkpoint...\n",
      "2021-11-05 15:58:04.862234: done, saving took 1.16 seconds\n",
      "2021-11-05 15:58:04.894935: This epoch took 326.774374 s\n",
      "\n",
      "2021-11-05 15:58:04.899258: \n",
      "epoch:  44\n",
      "2021-11-05 16:03:07.620177: train loss : 0.0010\n",
      "2021-11-05 16:03:25.853142: validation loss: 0.0010\n",
      "2021-11-05 16:03:25.859270: Average global foreground Dice: [0.8092]\n",
      "2021-11-05 16:03:25.863983: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 16:03:26.388932: lr: 0.001259\n",
      "2021-11-05 16:03:26.421962: saving checkpoint...\n",
      "2021-11-05 16:03:27.454000: done, saving took 1.06 seconds\n",
      "2021-11-05 16:03:27.493483: This epoch took 322.589906 s\n",
      "\n",
      "2021-11-05 16:03:27.498073: \n",
      "epoch:  45\n",
      "2021-11-05 16:08:33.082255: train loss : 0.0011\n",
      "2021-11-05 16:08:52.862094: validation loss: 0.0009\n",
      "2021-11-05 16:08:52.868115: Average global foreground Dice: [0.8113]\n",
      "2021-11-05 16:08:52.872616: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 16:08:53.482160: lr: 0.00103\n",
      "2021-11-05 16:08:53.546696: saving checkpoint...\n",
      "2021-11-05 16:08:54.759018: done, saving took 1.27 seconds\n",
      "2021-11-05 16:08:54.811081: This epoch took 327.307953 s\n",
      "\n",
      "2021-11-05 16:08:54.815267: \n",
      "epoch:  46\n",
      "2021-11-05 16:14:02.479548: train loss : 0.0011\n",
      "2021-11-05 16:14:22.500796: validation loss: 0.0010\n",
      "2021-11-05 16:14:22.507098: Average global foreground Dice: [0.8122]\n",
      "2021-11-05 16:14:22.512488: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 16:14:25.638815: lr: 0.000795\n",
      "2021-11-05 16:14:25.858258: saving checkpoint...\n",
      "2021-11-05 16:14:27.354822: done, saving took 1.69 seconds\n",
      "2021-11-05 16:14:27.393037: This epoch took 332.572795 s\n",
      "\n",
      "2021-11-05 16:14:27.398230: \n",
      "epoch:  47\n",
      "2021-11-05 16:19:35.398438: train loss : 0.0011\n",
      "2021-11-05 16:19:55.444736: validation loss: 0.0009\n",
      "2021-11-05 16:19:55.452926: Average global foreground Dice: [0.8123]\n",
      "2021-11-05 16:19:55.458616: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 16:19:57.337484: lr: 0.000552\n",
      "2021-11-05 16:19:57.458360: saving checkpoint...\n",
      "2021-11-05 16:25:02.012147: train loss : 0.0011\n",
      "2021-11-05 16:25:20.233607: validation loss: 0.0010\n",
      "2021-11-05 16:25:20.240195: Average global foreground Dice: [0.8117]\n",
      "2021-11-05 16:25:20.246828: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 16:25:20.755942: lr: 0.000296\n",
      "2021-11-05 16:25:20.825925: saving checkpoint...\n",
      "2021-11-05 16:25:21.822666: done, saving took 1.06 seconds\n",
      "2021-11-05 16:25:21.847762: This epoch took 323.181896 s\n",
      "\n",
      "2021-11-05 16:25:21.852993: \n",
      "epoch:  49\n",
      "2021-11-05 16:30:26.917009: train loss : 0.0011\n",
      "2021-11-05 16:30:45.032406: validation loss: 0.0009\n",
      "2021-11-05 16:30:45.038330: Average global foreground Dice: [0.8195]\n",
      "2021-11-05 16:30:45.043461: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 16:30:45.556263: lr: 0.0\n",
      "2021-11-05 16:30:45.561239: saving scheduled checkpoint file...\n",
      "2021-11-05 16:30:45.630890: saving checkpoint...\n",
      "2021-11-05 16:30:46.505064: done, saving took 0.94 seconds\n",
      "2021-11-05 16:30:46.521830: done\n",
      "2021-11-05 16:30:46.555091: saving checkpoint...\n",
      "2021-11-05 16:30:47.514010: done, saving took 0.99 seconds\n",
      "2021-11-05 16:30:47.539301: This epoch took 325.680861 s\n",
      "\n",
      "2021-11-05 16:30:47.572956: saving checkpoint...\n",
      "2021-11-05 16:30:48.364006: done, saving took 0.82 seconds\n",
      "23090567_20160819 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150401 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130213 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120627 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090590_20121212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160706 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090599_20140701 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130225 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090604_20140303 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090615_20140403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090617_20140211 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120406 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160111 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130213 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090631_20130128 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090634_20150409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-05 16:34:17.937973: finished prediction\n",
      "2021-11-05 16:34:17.943272: evaluation of raw predictions\n",
      "2021-11-05 16:34:19.414243: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8189776036373655\n",
      "after:  0.8189776036373655\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CE.nnUNetTrainerV2_Loss_CE'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-05 16:34:29.139266: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-05 16:34:29.152732: The split file contains 5 splits.\n",
      "2021-11-05 16:34:29.156543: Desired fold for training: 2\n",
      "2021-11-05 16:34:29.160695: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-05 16:34:33.492308: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-05 16:34:45.863340: Unable to plot network architecture:\n",
      "2021-11-05 16:34:45.867924: No module named 'hiddenlayer'\n",
      "2021-11-05 16:34:45.874182: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-05 16:34:45.879256: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-05 16:34:45.888543: \n",
      "\n",
      "2021-11-05 16:34:45.893799: \n",
      "epoch:  0\n",
      "2021-11-05 16:40:18.950662: train loss : 0.0465\n",
      "2021-11-05 16:40:38.644305: validation loss: 0.0047\n",
      "2021-11-05 16:40:38.662616: Average global foreground Dice: [0.0]\n",
      "2021-11-05 16:40:38.666947: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 16:40:40.471503: lr: 0.00982\n",
      "2021-11-05 16:40:40.476898: This epoch took 354.539754 s\n",
      "\n",
      "2021-11-05 16:40:40.481681: \n",
      "epoch:  1\n",
      "2021-11-05 16:45:37.856180: train loss : 0.0053\n",
      "2021-11-05 16:45:57.844622: validation loss: 0.0041\n",
      "2021-11-05 16:45:57.857136: Average global foreground Dice: [0.0]\n",
      "2021-11-05 16:45:57.861935: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 16:45:59.971125: lr: 0.009639\n",
      "2021-11-05 16:45:59.975543: This epoch took 319.488818 s\n",
      "\n",
      "2021-11-05 16:45:59.980199: \n",
      "epoch:  2\n",
      "2021-11-05 16:50:52.565792: train loss : 0.0045\n",
      "2021-11-05 16:51:11.459783: validation loss: 0.0038\n",
      "2021-11-05 16:51:11.464914: Average global foreground Dice: [0.0]\n",
      "2021-11-05 16:51:11.469730: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 16:51:12.018740: lr: 0.009458\n",
      "2021-11-05 16:51:12.024499: This epoch took 312.040198 s\n",
      "\n",
      "2021-11-05 16:51:12.029049: \n",
      "epoch:  3\n",
      "2021-11-05 16:56:05.902315: train loss : 0.0043\n",
      "2021-11-05 16:56:25.306400: validation loss: 0.0037\n",
      "2021-11-05 16:56:25.341336: Average global foreground Dice: [0.0]\n",
      "2021-11-05 16:56:25.345695: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 16:56:27.503475: lr: 0.009277\n",
      "2021-11-05 16:56:27.507728: This epoch took 315.474550 s\n",
      "\n",
      "2021-11-05 16:56:27.537228: \n",
      "epoch:  4\n",
      "2021-11-05 17:01:27.178737: train loss : 0.0041\n",
      "2021-11-05 17:01:46.760282: validation loss: 0.0034\n",
      "2021-11-05 17:01:46.766684: Average global foreground Dice: [0.0]\n",
      "2021-11-05 17:01:46.771980: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 17:01:49.439118: lr: 0.009095\n",
      "2021-11-05 17:01:49.444762: This epoch took 321.902707 s\n",
      "\n",
      "2021-11-05 17:01:49.449672: \n",
      "epoch:  5\n",
      "2021-11-05 17:07:16.591698: train loss : 0.0038\n",
      "2021-11-05 17:07:36.352286: validation loss: 0.0031\n",
      "2021-11-05 17:07:36.373149: Average global foreground Dice: [0.0]\n",
      "2021-11-05 17:07:36.377574: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 17:07:38.669483: lr: 0.008913\n",
      "2021-11-05 17:07:38.674939: This epoch took 349.220865 s\n",
      "\n",
      "2021-11-05 17:07:38.679677: \n",
      "epoch:  6\n",
      "2021-11-05 17:12:34.899094: train loss : 0.0032\n",
      "2021-11-05 17:12:54.877340: validation loss: 0.0021\n",
      "2021-11-05 17:12:54.896068: Average global foreground Dice: [0.0284]\n",
      "2021-11-05 17:12:54.900514: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 17:12:57.373419: lr: 0.008731\n",
      "2021-11-05 17:12:57.591119: saving checkpoint...\n",
      "2021-11-05 17:12:59.364193: done, saving took 1.99 seconds\n",
      "2021-11-05 17:12:59.404345: This epoch took 320.719961 s\n",
      "\n",
      "2021-11-05 17:12:59.437183: \n",
      "epoch:  7\n",
      "2021-11-05 17:17:55.160505: train loss : 0.0023\n",
      "2021-11-05 17:18:14.739828: validation loss: 0.0017\n",
      "2021-11-05 17:18:14.745386: Average global foreground Dice: [0.4958]\n",
      "2021-11-05 17:18:14.750244: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 17:18:16.161113: lr: 0.008548\n",
      "2021-11-05 17:18:16.348586: saving checkpoint...\n",
      "2021-11-05 17:18:17.737245: done, saving took 1.57 seconds\n",
      "2021-11-05 17:18:17.785810: This epoch took 318.343714 s\n",
      "\n",
      "2021-11-05 17:18:17.790039: \n",
      "epoch:  8\n",
      "2021-11-05 17:23:17.757016: train loss : 0.0021\n",
      "2021-11-05 17:23:37.749281: validation loss: 0.0016\n",
      "2021-11-05 17:23:37.755203: Average global foreground Dice: [0.5465]\n",
      "2021-11-05 17:23:37.760152: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 17:23:39.938098: lr: 0.008364\n",
      "2021-11-05 17:23:40.244912: saving checkpoint...\n",
      "2021-11-05 17:23:42.237172: done, saving took 2.29 seconds\n",
      "2021-11-05 17:23:42.272111: This epoch took 324.477791 s\n",
      "\n",
      "2021-11-05 17:23:42.276894: \n",
      "epoch:  9\n",
      "2021-11-05 17:28:42.654411: train loss : 0.0019\n",
      "2021-11-05 17:29:02.100196: validation loss: 0.0015\n",
      "2021-11-05 17:29:02.105921: Average global foreground Dice: [0.6763]\n",
      "2021-11-05 17:29:02.110426: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 17:29:03.752257: lr: 0.008181\n",
      "2021-11-05 17:29:03.962211: saving checkpoint...\n",
      "2021-11-05 17:29:05.375688: done, saving took 1.62 seconds\n",
      "2021-11-05 17:29:05.405064: This epoch took 323.123435 s\n",
      "\n",
      "2021-11-05 17:29:05.409818: \n",
      "epoch:  10\n",
      "2021-11-05 17:33:59.765739: train loss : 0.0018\n",
      "2021-11-05 17:34:18.487728: validation loss: 0.0014\n",
      "2021-11-05 17:34:18.492395: Average global foreground Dice: [0.6702]\n",
      "2021-11-05 17:34:18.497228: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 17:34:19.011617: lr: 0.007996\n",
      "2021-11-05 17:34:19.081903: saving checkpoint...\n",
      "2021-11-05 17:34:20.104706: done, saving took 1.09 seconds\n",
      "2021-11-05 17:34:20.131481: This epoch took 314.715982 s\n",
      "\n",
      "2021-11-05 17:34:20.135791: \n",
      "epoch:  11\n",
      "2021-11-05 17:39:18.996701: train loss : 0.0016\n",
      "2021-11-05 17:39:39.841317: validation loss: 0.0014\n",
      "2021-11-05 17:39:39.852473: Average global foreground Dice: [0.6702]\n",
      "2021-11-05 17:39:39.857182: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 17:39:42.299405: lr: 0.007811\n",
      "2021-11-05 17:39:42.383396: saving checkpoint...\n",
      "2021-11-05 17:39:44.137089: done, saving took 1.83 seconds\n",
      "2021-11-05 17:39:44.163732: This epoch took 324.023265 s\n",
      "\n",
      "2021-11-05 17:39:44.168822: \n",
      "epoch:  12\n",
      "2021-11-05 17:44:49.950359: train loss : 0.0016\n",
      "2021-11-05 17:45:08.646374: validation loss: 0.0014\n",
      "2021-11-05 17:45:08.652542: Average global foreground Dice: [0.5954]\n",
      "2021-11-05 17:45:08.657598: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 17:45:09.372414: lr: 0.007626\n",
      "2021-11-05 17:45:09.406198: saving checkpoint...\n",
      "2021-11-05 17:45:10.384524: done, saving took 1.01 seconds\n",
      "2021-11-05 17:45:10.411392: This epoch took 326.238635 s\n",
      "\n",
      "2021-11-05 17:45:10.416640: \n",
      "epoch:  13\n",
      "2021-11-05 17:50:08.942628: train loss : 0.0016\n",
      "2021-11-05 17:50:28.284886: validation loss: 0.0013\n",
      "2021-11-05 17:50:28.290853: Average global foreground Dice: [0.7258]\n",
      "2021-11-05 17:50:28.296201: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 17:50:29.796975: lr: 0.00744\n",
      "2021-11-05 17:50:29.834562: saving checkpoint...\n",
      "2021-11-05 17:50:30.930538: done, saving took 1.13 seconds\n",
      "2021-11-05 17:50:30.957595: This epoch took 320.536010 s\n",
      "\n",
      "2021-11-05 17:50:30.962692: \n",
      "epoch:  14\n",
      "2021-11-05 17:55:28.598559: train loss : 0.0015\n",
      "2021-11-05 17:55:48.288503: validation loss: 0.0013\n",
      "2021-11-05 17:55:48.305498: Average global foreground Dice: [0.7407]\n",
      "2021-11-05 17:55:48.337295: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 17:55:49.856030: lr: 0.007254\n",
      "2021-11-05 17:55:49.908302: saving checkpoint...\n",
      "2021-11-05 17:55:51.405118: done, saving took 1.54 seconds\n",
      "2021-11-05 17:55:51.432263: This epoch took 320.464129 s\n",
      "\n",
      "2021-11-05 17:55:51.436865: \n",
      "epoch:  15\n",
      "2021-11-05 18:00:48.057612: train loss : 0.0015\n",
      "2021-11-05 18:01:07.645372: validation loss: 0.0012\n",
      "2021-11-05 18:01:07.652604: Average global foreground Dice: [0.7364]\n",
      "2021-11-05 18:01:07.661977: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 18:01:09.896210: lr: 0.007067\n",
      "2021-11-05 18:01:09.963399: saving checkpoint...\n",
      "2021-11-05 18:01:11.337328: done, saving took 1.43 seconds\n",
      "2021-11-05 18:01:11.364950: This epoch took 319.923169 s\n",
      "\n",
      "2021-11-05 18:01:11.370157: \n",
      "epoch:  16\n",
      "2021-11-05 18:06:24.265868: train loss : 0.0015\n",
      "2021-11-05 18:06:43.744397: validation loss: 0.0012\n",
      "2021-11-05 18:06:43.761823: Average global foreground Dice: [0.7508]\n",
      "2021-11-05 18:06:43.769911: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 18:06:45.999113: lr: 0.00688\n",
      "2021-11-05 18:06:46.075702: saving checkpoint...\n",
      "2021-11-05 18:06:48.237427: done, saving took 2.23 seconds\n",
      "2021-11-05 18:06:48.283714: This epoch took 336.908849 s\n",
      "\n",
      "2021-11-05 18:06:48.289426: \n",
      "epoch:  17\n",
      "2021-11-05 18:11:41.697390: train loss : 0.0014\n",
      "2021-11-05 18:11:59.534156: validation loss: 0.0012\n",
      "2021-11-05 18:11:59.540181: Average global foreground Dice: [0.7577]\n",
      "2021-11-05 18:11:59.545469: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 18:12:00.040865: lr: 0.006692\n",
      "2021-11-05 18:12:00.073735: saving checkpoint...\n",
      "2021-11-05 18:12:01.183911: done, saving took 1.14 seconds\n",
      "2021-11-05 18:12:01.208201: This epoch took 312.913408 s\n",
      "\n",
      "2021-11-05 18:12:01.213707: \n",
      "epoch:  18\n",
      "2021-11-05 18:16:59.557282: train loss : 0.0014\n",
      "2021-11-05 18:17:19.084753: validation loss: 0.0012\n",
      "2021-11-05 18:17:19.142295: Average global foreground Dice: [0.7532]\n",
      "2021-11-05 18:17:19.146949: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 18:17:21.998283: lr: 0.006504\n",
      "2021-11-05 18:17:22.090360: saving checkpoint...\n",
      "2021-11-05 18:17:24.054967: done, saving took 2.05 seconds\n",
      "2021-11-05 18:17:24.089236: This epoch took 322.870672 s\n",
      "\n",
      "2021-11-05 18:17:24.095401: \n",
      "epoch:  19\n",
      "2021-11-05 18:22:39.849898: train loss : 0.0014\n",
      "2021-11-05 18:22:59.751864: validation loss: 0.0012\n",
      "2021-11-05 18:22:59.773505: Average global foreground Dice: [0.755]\n",
      "2021-11-05 18:22:59.779480: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 18:23:02.057180: lr: 0.006314\n",
      "2021-11-05 18:23:02.256068: saving checkpoint...\n",
      "2021-11-05 18:23:04.165251: done, saving took 2.10 seconds\n",
      "2021-11-05 18:23:04.202278: This epoch took 340.101619 s\n",
      "\n",
      "2021-11-05 18:23:04.207266: \n",
      "epoch:  20\n",
      "2021-11-05 18:28:06.747010: train loss : 0.0014\n",
      "2021-11-05 18:28:25.984580: validation loss: 0.0012\n",
      "2021-11-05 18:28:25.991112: Average global foreground Dice: [0.7647]\n",
      "2021-11-05 18:28:25.997197: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 18:28:28.238155: lr: 0.006125\n",
      "2021-11-05 18:28:28.454307: saving checkpoint...\n",
      "2021-11-05 18:28:30.328597: done, saving took 2.09 seconds\n",
      "2021-11-05 18:28:30.366985: This epoch took 326.129692 s\n",
      "\n",
      "2021-11-05 18:28:30.372040: \n",
      "epoch:  21\n",
      "2021-11-05 18:33:28.180863: train loss : 0.0013\n",
      "2021-11-05 18:33:47.608364: validation loss: 0.0012\n",
      "2021-11-05 18:33:47.665511: Average global foreground Dice: [0.7705]\n",
      "2021-11-05 18:33:47.670532: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 18:33:50.776971: lr: 0.005934\n",
      "2021-11-05 18:33:50.983125: saving checkpoint...\n",
      "2021-11-05 18:33:52.875871: done, saving took 2.09 seconds\n",
      "2021-11-05 18:33:52.944499: This epoch took 322.567554 s\n",
      "\n",
      "2021-11-05 18:33:52.950153: \n",
      "epoch:  22\n",
      "2021-11-05 18:38:38.042167: train loss : 0.0013\n",
      "2021-11-05 18:38:57.601902: validation loss: 0.0011\n",
      "2021-11-05 18:38:57.607227: Average global foreground Dice: [0.7706]\n",
      "2021-11-05 18:38:57.637195: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 18:38:59.896964: lr: 0.005743\n",
      "2021-11-05 18:38:59.989912: saving checkpoint...\n",
      "2021-11-05 18:39:01.549968: done, saving took 1.65 seconds\n",
      "2021-11-05 18:39:01.584242: This epoch took 308.628825 s\n",
      "\n",
      "2021-11-05 18:39:01.588564: \n",
      "epoch:  23\n",
      "2021-11-05 18:43:49.868263: train loss : 0.0013\n",
      "2021-11-05 18:44:08.896151: validation loss: 0.0012\n",
      "2021-11-05 18:44:08.976160: Average global foreground Dice: [0.749]\n",
      "2021-11-05 18:44:08.982250: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 18:44:10.550726: lr: 0.005551\n",
      "2021-11-05 18:44:10.649080: saving checkpoint...\n",
      "2021-11-05 18:44:12.397040: done, saving took 1.84 seconds\n",
      "2021-11-05 18:44:12.448187: This epoch took 310.853382 s\n",
      "\n",
      "2021-11-05 18:44:12.453114: \n",
      "epoch:  24\n",
      "2021-11-05 18:49:01.876255: train loss : 0.0013\n",
      "2021-11-05 18:49:20.745981: validation loss: 0.0011\n",
      "2021-11-05 18:49:20.752307: Average global foreground Dice: [0.7784]\n",
      "2021-11-05 18:49:20.758132: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 18:49:22.880559: lr: 0.005359\n",
      "2021-11-05 18:49:22.951935: saving checkpoint...\n",
      "2021-11-05 18:49:24.654148: done, saving took 1.77 seconds\n",
      "2021-11-05 18:49:24.680721: This epoch took 312.222719 s\n",
      "\n",
      "2021-11-05 18:49:24.685853: \n",
      "epoch:  25\n",
      "2021-11-05 18:54:12.867157: train loss : 0.0013\n",
      "2021-11-05 18:54:32.457745: validation loss: 0.0011\n",
      "2021-11-05 18:54:32.463621: Average global foreground Dice: [0.7759]\n",
      "2021-11-05 18:54:32.468256: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 18:54:35.043201: lr: 0.005166\n",
      "2021-11-05 18:54:35.142481: saving checkpoint...\n",
      "2021-11-05 18:54:37.237540: done, saving took 2.19 seconds\n",
      "2021-11-05 18:54:37.267183: This epoch took 312.576489 s\n",
      "\n",
      "2021-11-05 18:54:37.272710: \n",
      "epoch:  26\n",
      "2021-11-05 18:59:36.364221: train loss : 0.0012\n",
      "2021-11-05 18:59:56.193089: validation loss: 0.0011\n",
      "2021-11-05 18:59:56.198857: Average global foreground Dice: [0.7802]\n",
      "2021-11-05 18:59:56.203773: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 18:59:58.538258: lr: 0.004971\n",
      "2021-11-05 18:59:58.637257: saving checkpoint...\n",
      "2021-11-05 19:00:00.014371: done, saving took 1.47 seconds\n",
      "2021-11-05 19:00:00.037774: This epoch took 322.759728 s\n",
      "\n",
      "2021-11-05 19:00:00.042823: \n",
      "epoch:  27\n",
      "2021-11-05 19:05:02.003597: train loss : 0.0012\n",
      "2021-11-05 19:05:22.191746: validation loss: 0.0011\n",
      "2021-11-05 19:05:22.238015: Average global foreground Dice: [0.7703]\n",
      "2021-11-05 19:05:22.244108: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 19:05:24.740147: lr: 0.004776\n",
      "2021-11-05 19:05:24.839668: saving checkpoint...\n",
      "2021-11-05 19:05:26.547039: done, saving took 1.80 seconds\n",
      "2021-11-05 19:05:26.573869: This epoch took 326.526290 s\n",
      "\n",
      "2021-11-05 19:05:26.578241: \n",
      "epoch:  28\n",
      "2021-11-05 19:10:35.881850: train loss : 0.0013\n",
      "2021-11-05 19:10:55.755676: validation loss: 0.0011\n",
      "2021-11-05 19:10:55.761410: Average global foreground Dice: [0.7663]\n",
      "2021-11-05 19:10:55.767114: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 19:10:57.987231: lr: 0.004581\n",
      "2021-11-05 19:10:58.087157: saving checkpoint...\n",
      "2021-11-05 19:10:59.937168: done, saving took 1.94 seconds\n",
      "2021-11-05 19:10:59.964198: This epoch took 333.380937 s\n",
      "\n",
      "2021-11-05 19:10:59.968478: \n",
      "epoch:  29\n",
      "2021-11-05 19:16:05.450104: train loss : 0.0012\n",
      "2021-11-05 19:16:25.144490: validation loss: 0.0011\n",
      "2021-11-05 19:16:25.156294: Average global foreground Dice: [0.7593]\n",
      "2021-11-05 19:16:25.161522: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 19:16:26.841085: lr: 0.004384\n",
      "2021-11-05 19:16:26.909451: saving checkpoint...\n",
      "2021-11-05 19:16:28.700119: done, saving took 1.84 seconds\n",
      "2021-11-05 19:16:28.747482: This epoch took 328.774357 s\n",
      "\n",
      "2021-11-05 19:16:28.753364: \n",
      "epoch:  30\n",
      "2021-11-05 19:21:28.249723: train loss : 0.0012\n",
      "2021-11-05 19:21:47.061917: validation loss: 0.0011\n",
      "2021-11-05 19:21:47.066855: Average global foreground Dice: [0.7694]\n",
      "2021-11-05 19:21:47.071710: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 19:21:47.560638: lr: 0.004186\n",
      "2021-11-05 19:21:47.593247: saving checkpoint...\n",
      "2021-11-05 19:21:48.548668: done, saving took 0.98 seconds\n",
      "2021-11-05 19:21:48.572272: This epoch took 319.814467 s\n",
      "\n",
      "2021-11-05 19:21:48.576947: \n",
      "epoch:  31\n",
      "2021-11-05 19:26:49.962006: train loss : 0.0012\n",
      "2021-11-05 19:27:10.049930: validation loss: 0.0011\n",
      "2021-11-05 19:27:10.062643: Average global foreground Dice: [0.7811]\n",
      "2021-11-05 19:27:10.067122: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 19:27:11.675729: lr: 0.003987\n",
      "2021-11-05 19:27:11.777094: saving checkpoint...\n",
      "2021-11-05 19:27:13.677669: done, saving took 2.00 seconds\n",
      "2021-11-05 19:27:13.704868: This epoch took 325.122850 s\n",
      "\n",
      "2021-11-05 19:27:13.737063: \n",
      "epoch:  32\n",
      "2021-11-05 19:32:23.164626: train loss : 0.0012\n",
      "2021-11-05 19:32:42.572220: validation loss: 0.0011\n",
      "2021-11-05 19:32:42.601342: Average global foreground Dice: [0.7667]\n",
      "2021-11-05 19:32:42.606732: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 19:32:44.774323: lr: 0.003787\n",
      "2021-11-05 19:32:44.870847: saving checkpoint...\n",
      "2021-11-05 19:32:46.476894: done, saving took 1.70 seconds\n",
      "2021-11-05 19:32:46.505658: This epoch took 332.763249 s\n",
      "\n",
      "2021-11-05 19:32:46.510547: \n",
      "epoch:  33\n",
      "2021-11-05 19:37:49.846134: train loss : 0.0012\n",
      "2021-11-05 19:38:09.746348: validation loss: 0.0011\n",
      "2021-11-05 19:38:09.767667: Average global foreground Dice: [0.7927]\n",
      "2021-11-05 19:38:09.772127: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 19:38:11.553689: lr: 0.003586\n",
      "2021-11-05 19:38:11.606234: saving checkpoint...\n",
      "2021-11-05 19:38:13.022132: done, saving took 1.46 seconds\n",
      "2021-11-05 19:38:13.044522: This epoch took 326.507783 s\n",
      "\n",
      "2021-11-05 19:38:13.049879: \n",
      "epoch:  34\n",
      "2021-11-05 19:43:13.461338: train loss : 0.0012\n",
      "2021-11-05 19:43:32.593014: validation loss: 0.0011\n",
      "2021-11-05 19:43:32.641889: Average global foreground Dice: [0.7773]\n",
      "2021-11-05 19:43:32.647109: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 19:43:33.752348: lr: 0.003384\n",
      "2021-11-05 19:43:33.797119: saving checkpoint...\n",
      "2021-11-05 19:43:34.807578: done, saving took 1.05 seconds\n",
      "2021-11-05 19:43:34.831562: This epoch took 321.776995 s\n",
      "\n",
      "2021-11-05 19:43:34.835982: \n",
      "epoch:  35\n",
      "2021-11-05 19:48:35.366456: train loss : 0.0012\n",
      "2021-11-05 19:48:54.644339: validation loss: 0.0010\n",
      "2021-11-05 19:48:54.664634: Average global foreground Dice: [0.793]\n",
      "2021-11-05 19:48:54.668589: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 19:48:55.802302: lr: 0.00318\n",
      "2021-11-05 19:48:55.838408: saving checkpoint...\n",
      "2021-11-05 19:48:56.917780: done, saving took 1.11 seconds\n",
      "2021-11-05 19:48:56.943714: This epoch took 322.103057 s\n",
      "\n",
      "2021-11-05 19:48:56.948173: \n",
      "epoch:  36\n",
      "2021-11-05 19:53:55.691642: train loss : 0.0012\n",
      "2021-11-05 19:54:13.979319: validation loss: 0.0010\n",
      "2021-11-05 19:54:13.984497: Average global foreground Dice: [0.7755]\n",
      "2021-11-05 19:54:13.988812: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 19:54:14.477343: lr: 0.002975\n",
      "2021-11-05 19:54:14.510408: saving checkpoint...\n",
      "2021-11-05 19:54:15.448933: done, saving took 0.97 seconds\n",
      "2021-11-05 19:54:15.472265: This epoch took 318.519592 s\n",
      "\n",
      "2021-11-05 19:54:15.476831: \n",
      "epoch:  37\n",
      "2021-11-05 19:59:14.666317: train loss : 0.0012\n",
      "2021-11-05 19:59:33.424266: validation loss: 0.0010\n",
      "2021-11-05 19:59:33.429919: Average global foreground Dice: [0.7735]\n",
      "2021-11-05 19:59:33.434458: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 19:59:33.941424: lr: 0.002768\n",
      "2021-11-05 19:59:33.974420: saving checkpoint...\n",
      "2021-11-05 19:59:34.959429: done, saving took 1.01 seconds\n",
      "2021-11-05 19:59:34.984886: This epoch took 319.503155 s\n",
      "\n",
      "2021-11-05 19:59:34.990960: \n",
      "epoch:  38\n",
      "2021-11-05 20:04:33.056643: train loss : 0.0012\n",
      "2021-11-05 20:04:52.550097: validation loss: 0.0011\n",
      "2021-11-05 20:04:52.556093: Average global foreground Dice: [0.7758]\n",
      "2021-11-05 20:04:52.561593: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 20:04:54.189254: lr: 0.00256\n",
      "2021-11-05 20:04:54.352196: saving checkpoint...\n",
      "2021-11-05 20:04:56.151329: done, saving took 1.96 seconds\n",
      "2021-11-05 20:04:56.179085: This epoch took 321.183265 s\n",
      "\n",
      "2021-11-05 20:04:56.185319: \n",
      "epoch:  39\n",
      "2021-11-05 20:09:57.970541: train loss : 0.0011\n",
      "2021-11-05 20:10:17.588362: validation loss: 0.0010\n",
      "2021-11-05 20:10:17.602273: Average global foreground Dice: [0.7853]\n",
      "2021-11-05 20:10:17.607310: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 20:10:19.455185: lr: 0.002349\n",
      "2021-11-05 20:10:19.490732: saving checkpoint...\n",
      "2021-11-05 20:10:20.859661: done, saving took 1.40 seconds\n",
      "2021-11-05 20:10:20.887542: This epoch took 324.696607 s\n",
      "\n",
      "2021-11-05 20:10:20.892154: \n",
      "epoch:  40\n",
      "2021-11-05 20:15:26.846346: train loss : 0.0012\n",
      "2021-11-05 20:15:46.678387: validation loss: 0.0010\n",
      "2021-11-05 20:15:46.686976: Average global foreground Dice: [0.7781]\n",
      "2021-11-05 20:15:46.692076: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 20:15:48.796312: lr: 0.002137\n",
      "2021-11-05 20:15:48.885002: saving checkpoint...\n",
      "2021-11-05 20:15:50.754069: done, saving took 1.95 seconds\n",
      "2021-11-05 20:15:50.794305: This epoch took 329.897286 s\n",
      "\n",
      "2021-11-05 20:15:50.799516: \n",
      "epoch:  41\n",
      "2021-11-05 20:20:52.760531: train loss : 0.0012\n",
      "2021-11-05 20:21:12.442284: validation loss: 0.0010\n",
      "2021-11-05 20:21:12.461212: Average global foreground Dice: [0.7885]\n",
      "2021-11-05 20:21:12.466715: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 20:21:13.938031: lr: 0.001922\n",
      "2021-11-05 20:21:13.977495: saving checkpoint...\n",
      "2021-11-05 20:21:15.093441: done, saving took 1.15 seconds\n",
      "2021-11-05 20:21:15.138077: This epoch took 324.334106 s\n",
      "\n",
      "2021-11-05 20:21:15.143026: \n",
      "epoch:  42\n",
      "2021-11-05 20:26:14.861704: train loss : 0.0012\n",
      "2021-11-05 20:26:34.483021: validation loss: 0.0010\n",
      "2021-11-05 20:26:34.500254: Average global foreground Dice: [0.7821]\n",
      "2021-11-05 20:26:34.508093: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 20:26:35.819462: lr: 0.001704\n",
      "2021-11-05 20:26:35.870546: saving checkpoint...\n",
      "2021-11-05 20:26:36.976082: done, saving took 1.15 seconds\n",
      "2021-11-05 20:26:37.001673: This epoch took 321.853625 s\n",
      "\n",
      "2021-11-05 20:26:37.006438: \n",
      "epoch:  43\n",
      "2021-11-05 20:31:38.950671: train loss : 0.0011\n",
      "2021-11-05 20:31:58.182033: validation loss: 0.0010\n",
      "2021-11-05 20:31:58.187455: Average global foreground Dice: [0.7908]\n",
      "2021-11-05 20:31:58.192866: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 20:31:58.727649: lr: 0.001483\n",
      "2021-11-05 20:31:58.783679: saving checkpoint...\n",
      "2021-11-05 20:31:59.770528: done, saving took 1.04 seconds\n",
      "2021-11-05 20:31:59.799931: This epoch took 322.789135 s\n",
      "\n",
      "2021-11-05 20:31:59.804766: \n",
      "epoch:  44\n",
      "2021-11-05 20:36:58.769307: train loss : 0.0011\n",
      "2021-11-05 20:37:17.548903: validation loss: 0.0011\n",
      "2021-11-05 20:37:17.554405: Average global foreground Dice: [0.7842]\n",
      "2021-11-05 20:37:17.558954: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 20:37:18.042436: lr: 0.001259\n",
      "2021-11-05 20:37:18.107380: saving checkpoint...\n",
      "2021-11-05 20:37:19.066470: done, saving took 1.02 seconds\n",
      "2021-11-05 20:37:19.096634: This epoch took 319.287317 s\n",
      "\n",
      "2021-11-05 20:37:19.101640: \n",
      "epoch:  45\n",
      "2021-11-05 20:42:21.472338: train loss : 0.0011\n",
      "2021-11-05 20:42:40.944618: validation loss: 0.0010\n",
      "2021-11-05 20:42:40.960072: Average global foreground Dice: [0.7913]\n",
      "2021-11-05 20:42:40.964221: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 20:42:42.318528: lr: 0.00103\n",
      "2021-11-05 20:42:42.392760: saving checkpoint...\n",
      "2021-11-05 20:42:43.431762: done, saving took 1.11 seconds\n",
      "2021-11-05 20:42:43.461515: This epoch took 324.355633 s\n",
      "\n",
      "2021-11-05 20:42:43.467184: \n",
      "epoch:  46\n",
      "2021-11-05 20:47:45.997834: train loss : 0.0012\n",
      "2021-11-05 20:48:05.292386: validation loss: 0.0010\n",
      "2021-11-05 20:48:05.304099: Average global foreground Dice: [0.7769]\n",
      "2021-11-05 20:48:05.337115: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 20:48:07.012256: lr: 0.000795\n",
      "2021-11-05 20:48:07.095523: saving checkpoint...\n",
      "2021-11-05 20:48:08.211370: done, saving took 1.19 seconds\n",
      "2021-11-05 20:48:08.238606: This epoch took 324.766621 s\n",
      "\n",
      "2021-11-05 20:48:08.242765: \n",
      "epoch:  47\n",
      "2021-11-05 20:53:08.778679: train loss : 0.0012\n",
      "2021-11-05 20:53:28.098044: validation loss: 0.0010\n",
      "2021-11-05 20:53:28.104685: Average global foreground Dice: [0.7936]\n",
      "2021-11-05 20:53:28.109313: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 20:53:28.882904: lr: 0.000552\n",
      "2021-11-05 20:53:28.951257: saving checkpoint...\n",
      "2021-11-05 20:53:29.981632: done, saving took 1.09 seconds\n",
      "2021-11-05 20:53:30.003646: This epoch took 321.755500 s\n",
      "\n",
      "2021-11-05 20:53:30.007890: \n",
      "epoch:  48\n",
      "2021-11-05 20:58:33.250413: train loss : 0.0011\n",
      "2021-11-05 20:58:52.283566: validation loss: 0.0010\n",
      "2021-11-05 20:58:52.299839: Average global foreground Dice: [0.7768]\n",
      "2021-11-05 20:58:52.305816: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 20:58:54.068036: lr: 0.000296\n",
      "2021-11-05 20:58:54.106663: saving checkpoint...\n",
      "2021-11-05 20:58:55.167559: done, saving took 1.09 seconds\n",
      "2021-11-05 20:58:55.191439: This epoch took 325.179145 s\n",
      "\n",
      "2021-11-05 20:58:55.196067: \n",
      "epoch:  49\n",
      "2021-11-05 21:03:59.259167: train loss : 0.0011\n",
      "2021-11-05 21:04:18.701571: validation loss: 0.0010\n",
      "2021-11-05 21:04:18.707624: Average global foreground Dice: [0.7911]\n",
      "2021-11-05 21:04:18.747247: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 21:04:21.037459: lr: 0.0\n",
      "2021-11-05 21:04:21.042533: saving scheduled checkpoint file...\n",
      "2021-11-05 21:04:21.110466: saving checkpoint...\n",
      "2021-11-05 21:04:22.673679: done, saving took 1.63 seconds\n",
      "2021-11-05 21:04:22.693600: done\n",
      "2021-11-05 21:04:22.753526: saving checkpoint...\n",
      "2021-11-05 21:04:23.920506: done, saving took 1.22 seconds\n",
      "2021-11-05 21:04:23.944263: This epoch took 328.743168 s\n",
      "\n",
      "2021-11-05 21:04:23.978578: saving checkpoint...\n",
      "2021-11-05 21:04:24.808817: done, saving took 0.86 seconds\n",
      "23090566_20141114 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090571_20120517 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131226 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160308 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131025 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090596_20150112 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120619 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090608_20120718 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151210 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121213 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090616_20140331 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090619_20121210 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090629_20120830 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090636_20121018 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150522 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-05 21:07:53.997286: finished prediction\n",
      "2021-11-05 21:07:54.001363: evaluation of raw predictions\n",
      "2021-11-05 21:07:55.489517: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.7860413558093544\n",
      "after:  0.7860413558093544\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CE.nnUNetTrainerV2_Loss_CE'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-05 21:08:05.804523: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-05 21:08:05.818290: The split file contains 5 splits.\n",
      "2021-11-05 21:08:05.822227: Desired fold for training: 3\n",
      "2021-11-05 21:08:05.825875: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-05 21:08:10.168303: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-05 21:08:42.044354: Unable to plot network architecture:\n",
      "2021-11-05 21:08:42.049092: No module named 'hiddenlayer'\n",
      "2021-11-05 21:08:42.053972: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-05 21:08:42.059084: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-05 21:08:42.068180: \n",
      "\n",
      "2021-11-05 21:08:42.073683: \n",
      "epoch:  0\n",
      "2021-11-05 21:14:10.450676: train loss : 0.0262\n",
      "2021-11-05 21:14:28.533519: validation loss: 0.0042\n",
      "2021-11-05 21:14:28.539632: Average global foreground Dice: [0.0]\n",
      "2021-11-05 21:14:28.544342: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 21:14:28.973369: lr: 0.00982\n",
      "2021-11-05 21:14:28.977985: This epoch took 346.899685 s\n",
      "\n",
      "2021-11-05 21:14:28.982979: \n",
      "epoch:  1\n",
      "2021-11-05 21:19:30.639047: train loss : 0.0043\n",
      "2021-11-05 21:19:50.542705: validation loss: 0.0034\n",
      "2021-11-05 21:19:50.548750: Average global foreground Dice: [0.0]\n",
      "2021-11-05 21:19:50.553566: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 21:19:52.876354: lr: 0.009639\n",
      "2021-11-05 21:19:52.882115: This epoch took 323.895138 s\n",
      "\n",
      "2021-11-05 21:19:52.886584: \n",
      "epoch:  2\n",
      "2021-11-05 21:24:57.240704: train loss : 0.0036\n",
      "2021-11-05 21:25:16.973525: validation loss: 0.0027\n",
      "2021-11-05 21:25:16.983635: Average global foreground Dice: [0.0]\n",
      "2021-11-05 21:25:16.989108: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 21:25:19.003048: lr: 0.009458\n",
      "2021-11-05 21:25:19.007989: This epoch took 326.117870 s\n",
      "\n",
      "2021-11-05 21:25:19.041514: \n",
      "epoch:  3\n",
      "2021-11-05 21:30:20.050193: train loss : 0.0030\n",
      "2021-11-05 21:30:39.444916: validation loss: 0.0020\n",
      "2021-11-05 21:30:39.450992: Average global foreground Dice: [0.0208]\n",
      "2021-11-05 21:30:39.455605: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 21:30:40.069465: lr: 0.009277\n",
      "2021-11-05 21:30:40.152467: saving checkpoint...\n",
      "2021-11-05 21:30:41.050016: done, saving took 0.98 seconds\n",
      "2021-11-05 21:30:41.071743: This epoch took 322.025742 s\n",
      "\n",
      "2021-11-05 21:30:41.076171: \n",
      "epoch:  4\n",
      "2021-11-05 21:35:42.186442: train loss : 0.0025\n",
      "2021-11-05 21:36:01.960909: validation loss: 0.0017\n",
      "2021-11-05 21:36:01.970735: Average global foreground Dice: [0.3284]\n",
      "2021-11-05 21:36:01.975289: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 21:36:03.798085: lr: 0.009095\n",
      "2021-11-05 21:36:03.944461: saving checkpoint...\n",
      "2021-11-05 21:36:05.351872: done, saving took 1.55 seconds\n",
      "2021-11-05 21:36:05.378620: This epoch took 324.298574 s\n",
      "\n",
      "2021-11-05 21:36:05.383939: \n",
      "epoch:  5\n",
      "2021-11-05 21:41:04.470877: train loss : 0.0021\n",
      "2021-11-05 21:41:24.198985: validation loss: 0.0016\n",
      "2021-11-05 21:41:24.208281: Average global foreground Dice: [0.5477]\n",
      "2021-11-05 21:41:24.237129: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 21:41:25.996553: lr: 0.008913\n",
      "2021-11-05 21:41:26.142814: saving checkpoint...\n",
      "2021-11-05 21:41:27.730700: done, saving took 1.73 seconds\n",
      "2021-11-05 21:41:27.763422: This epoch took 322.375450 s\n",
      "\n",
      "2021-11-05 21:41:27.767799: \n",
      "epoch:  6\n",
      "2021-11-05 21:46:29.756256: train loss : 0.0020\n",
      "2021-11-05 21:46:49.852010: validation loss: 0.0014\n",
      "2021-11-05 21:46:49.862596: Average global foreground Dice: [0.6253]\n",
      "2021-11-05 21:46:49.867598: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 21:46:52.007405: lr: 0.008731\n",
      "2021-11-05 21:46:52.276258: saving checkpoint...\n",
      "2021-11-05 21:46:54.062567: done, saving took 2.02 seconds\n",
      "2021-11-05 21:46:54.087804: This epoch took 326.314327 s\n",
      "\n",
      "2021-11-05 21:46:54.092803: \n",
      "epoch:  7\n",
      "2021-11-05 21:51:59.850327: train loss : 0.0018\n",
      "2021-11-05 21:52:19.436880: validation loss: 0.0013\n",
      "2021-11-05 21:52:19.442445: Average global foreground Dice: [0.6532]\n",
      "2021-11-05 21:52:19.447042: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 21:52:21.563556: lr: 0.008548\n",
      "2021-11-05 21:52:21.784176: saving checkpoint...\n",
      "2021-11-05 21:52:23.404228: done, saving took 1.84 seconds\n",
      "2021-11-05 21:52:23.442070: This epoch took 329.344816 s\n",
      "\n",
      "2021-11-05 21:52:23.447784: \n",
      "epoch:  8\n",
      "2021-11-05 21:57:24.797997: train loss : 0.0018\n",
      "2021-11-05 21:57:45.076406: validation loss: 0.0014\n",
      "2021-11-05 21:57:45.093754: Average global foreground Dice: [0.6778]\n",
      "2021-11-05 21:57:45.098546: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 21:57:48.537774: lr: 0.008364\n",
      "2021-11-05 21:57:48.762809: saving checkpoint...\n",
      "2021-11-05 21:57:50.398301: done, saving took 1.84 seconds\n",
      "2021-11-05 21:57:50.464045: This epoch took 327.011614 s\n",
      "\n",
      "2021-11-05 21:57:50.468138: \n",
      "epoch:  9\n",
      "2021-11-05 22:02:52.758016: train loss : 0.0016\n",
      "2021-11-05 22:03:11.675463: validation loss: 0.0013\n",
      "2021-11-05 22:03:11.681648: Average global foreground Dice: [0.705]\n",
      "2021-11-05 22:03:11.687115: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 22:03:12.352522: lr: 0.008181\n",
      "2021-11-05 22:03:12.444078: saving checkpoint...\n",
      "2021-11-05 22:03:13.546843: done, saving took 1.19 seconds\n",
      "2021-11-05 22:03:13.577275: This epoch took 323.104363 s\n",
      "\n",
      "2021-11-05 22:03:13.582722: \n",
      "epoch:  10\n",
      "2021-11-05 22:08:13.561833: train loss : 0.0017\n",
      "2021-11-05 22:08:32.294427: validation loss: 0.0013\n",
      "2021-11-05 22:08:32.300648: Average global foreground Dice: [0.7076]\n",
      "2021-11-05 22:08:32.304931: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 22:08:32.800717: lr: 0.007996\n",
      "2021-11-05 22:08:32.834407: saving checkpoint...\n",
      "2021-11-05 22:08:33.995265: done, saving took 1.19 seconds\n",
      "2021-11-05 22:08:34.018012: This epoch took 320.428870 s\n",
      "\n",
      "2021-11-05 22:08:34.023016: \n",
      "epoch:  11\n",
      "2021-11-05 22:13:32.173077: train loss : 0.0015\n",
      "2021-11-05 22:13:51.644329: validation loss: 0.0012\n",
      "2021-11-05 22:13:51.650682: Average global foreground Dice: [0.7007]\n",
      "2021-11-05 22:13:51.656288: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 22:13:52.259465: lr: 0.007811\n",
      "2021-11-05 22:13:52.294437: saving checkpoint...\n",
      "2021-11-05 22:13:53.521934: done, saving took 1.26 seconds\n",
      "2021-11-05 22:13:53.545871: This epoch took 319.518052 s\n",
      "\n",
      "2021-11-05 22:13:53.549706: \n",
      "epoch:  12\n",
      "2021-11-05 22:18:53.651247: train loss : 0.0015\n",
      "2021-11-05 22:19:13.404534: validation loss: 0.0011\n",
      "2021-11-05 22:19:13.437660: Average global foreground Dice: [0.7377]\n",
      "2021-11-05 22:19:13.442161: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 22:19:14.688229: lr: 0.007626\n",
      "2021-11-05 22:19:14.769958: saving checkpoint...\n",
      "2021-11-05 22:19:15.998991: done, saving took 1.31 seconds\n",
      "2021-11-05 22:19:16.022011: This epoch took 322.467277 s\n",
      "\n",
      "2021-11-05 22:19:16.027055: \n",
      "epoch:  13\n",
      "2021-11-05 22:24:16.680990: train loss : 0.0015\n",
      "2021-11-05 22:24:36.089932: validation loss: 0.0012\n",
      "2021-11-05 22:24:36.095550: Average global foreground Dice: [0.746]\n",
      "2021-11-05 22:24:36.100659: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 22:24:36.990222: lr: 0.00744\n",
      "2021-11-05 22:24:37.026170: saving checkpoint...\n",
      "2021-11-05 22:24:38.142298: done, saving took 1.15 seconds\n",
      "2021-11-05 22:24:38.166927: This epoch took 322.134724 s\n",
      "\n",
      "2021-11-05 22:24:38.172128: \n",
      "epoch:  14\n",
      "2021-11-05 22:29:38.178908: train loss : 0.0015\n",
      "2021-11-05 22:29:57.660504: validation loss: 0.0012\n",
      "2021-11-05 22:29:57.685456: Average global foreground Dice: [0.7554]\n",
      "2021-11-05 22:29:57.701212: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 22:29:59.464657: lr: 0.007254\n",
      "2021-11-05 22:29:59.669336: saving checkpoint...\n",
      "2021-11-05 22:30:01.563965: done, saving took 2.09 seconds\n",
      "2021-11-05 22:30:01.589822: This epoch took 323.412778 s\n",
      "\n",
      "2021-11-05 22:30:01.595099: \n",
      "epoch:  15\n",
      "2021-11-05 22:35:00.794252: train loss : 0.0014\n",
      "2021-11-05 22:35:19.912127: validation loss: 0.0011\n",
      "2021-11-05 22:35:19.917903: Average global foreground Dice: [0.7604]\n",
      "2021-11-05 22:35:19.922935: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 22:35:20.415612: lr: 0.007067\n",
      "2021-11-05 22:35:20.487995: saving checkpoint...\n",
      "2021-11-05 22:35:21.689272: done, saving took 1.27 seconds\n",
      "2021-11-05 22:35:21.718617: This epoch took 320.118925 s\n",
      "\n",
      "2021-11-05 22:35:21.723168: \n",
      "epoch:  16\n",
      "2021-11-05 22:40:24.171982: train loss : 0.0014\n",
      "2021-11-05 22:40:43.844874: validation loss: 0.0011\n",
      "2021-11-05 22:40:43.869951: Average global foreground Dice: [0.7342]\n",
      "2021-11-05 22:40:43.876176: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 22:40:45.855383: lr: 0.00688\n",
      "2021-11-05 22:40:45.890454: saving checkpoint...\n",
      "2021-11-05 22:40:47.305147: done, saving took 1.44 seconds\n",
      "2021-11-05 22:40:47.331676: This epoch took 325.603384 s\n",
      "\n",
      "2021-11-05 22:40:47.337020: \n",
      "epoch:  17\n",
      "2021-11-05 22:45:59.160403: train loss : 0.0014\n",
      "2021-11-05 22:46:18.900234: validation loss: 0.0011\n",
      "2021-11-05 22:46:18.937889: Average global foreground Dice: [0.7741]\n",
      "2021-11-05 22:46:18.943476: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 22:46:21.807717: lr: 0.006692\n",
      "2021-11-05 22:46:21.885801: saving checkpoint...\n",
      "2021-11-05 22:46:23.771333: done, saving took 1.93 seconds\n",
      "2021-11-05 22:46:23.804938: This epoch took 336.462567 s\n",
      "\n",
      "2021-11-05 22:46:23.836866: \n",
      "epoch:  18\n",
      "2021-11-05 22:51:35.874549: train loss : 0.0014\n",
      "2021-11-05 22:51:55.744241: validation loss: 0.0011\n",
      "2021-11-05 22:51:55.750460: Average global foreground Dice: [0.7708]\n",
      "2021-11-05 22:51:55.756517: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 22:51:57.003179: lr: 0.006504\n",
      "2021-11-05 22:51:57.139747: saving checkpoint...\n",
      "2021-11-05 22:51:58.681988: done, saving took 1.67 seconds\n",
      "2021-11-05 22:51:58.705601: This epoch took 334.863512 s\n",
      "\n",
      "2021-11-05 22:51:58.710636: \n",
      "epoch:  19\n",
      "2021-11-05 22:57:01.066152: train loss : 0.0013\n",
      "2021-11-05 22:57:21.056257: validation loss: 0.0011\n",
      "2021-11-05 22:57:21.081454: Average global foreground Dice: [0.7642]\n",
      "2021-11-05 22:57:21.087283: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 22:57:23.445218: lr: 0.006314\n",
      "2021-11-05 22:57:23.593339: saving checkpoint...\n",
      "2021-11-05 22:57:25.737126: done, saving took 2.29 seconds\n",
      "2021-11-05 22:57:25.769976: This epoch took 327.054328 s\n",
      "\n",
      "2021-11-05 22:57:25.775034: \n",
      "epoch:  20\n",
      "2021-11-05 23:02:30.066869: train loss : 0.0014\n",
      "2021-11-05 23:02:49.848101: validation loss: 0.0011\n",
      "2021-11-05 23:02:49.881372: Average global foreground Dice: [0.7698]\n",
      "2021-11-05 23:02:49.886593: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 23:02:52.303807: lr: 0.006125\n",
      "2021-11-05 23:02:52.462017: saving checkpoint...\n",
      "2021-11-05 23:02:54.098748: done, saving took 1.76 seconds\n",
      "2021-11-05 23:02:54.159364: This epoch took 328.378892 s\n",
      "\n",
      "2021-11-05 23:02:54.168503: \n",
      "epoch:  21\n",
      "2021-11-05 23:07:58.771192: train loss : 0.0013\n",
      "2021-11-05 23:08:18.144399: validation loss: 0.0011\n",
      "2021-11-05 23:08:18.150990: Average global foreground Dice: [0.7664]\n",
      "2021-11-05 23:08:18.156605: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 23:08:18.979708: lr: 0.005934\n",
      "2021-11-05 23:08:19.047850: saving checkpoint...\n",
      "2021-11-05 23:08:20.082097: done, saving took 1.10 seconds\n",
      "2021-11-05 23:08:20.108814: This epoch took 325.934941 s\n",
      "\n",
      "2021-11-05 23:08:20.113741: \n",
      "epoch:  22\n",
      "2021-11-05 23:13:20.464495: train loss : 0.0013\n",
      "2021-11-05 23:13:40.303987: validation loss: 0.0011\n",
      "2021-11-05 23:13:40.337856: Average global foreground Dice: [0.7681]\n",
      "2021-11-05 23:13:40.343081: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 23:13:41.999249: lr: 0.005743\n",
      "2021-11-05 23:13:42.037817: saving checkpoint...\n",
      "2021-11-05 23:13:43.048890: done, saving took 1.04 seconds\n",
      "2021-11-05 23:13:43.074942: This epoch took 322.956613 s\n",
      "\n",
      "2021-11-05 23:13:43.084225: \n",
      "epoch:  23\n",
      "2021-11-05 23:18:41.957478: train loss : 0.0012\n",
      "2021-11-05 23:19:01.606212: validation loss: 0.0010\n",
      "2021-11-05 23:19:01.657857: Average global foreground Dice: [0.7793]\n",
      "2021-11-05 23:19:01.663175: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 23:19:03.526769: lr: 0.005551\n",
      "2021-11-05 23:19:03.570223: saving checkpoint...\n",
      "2021-11-05 23:19:04.599459: done, saving took 1.06 seconds\n",
      "2021-11-05 23:19:04.623562: This epoch took 321.534364 s\n",
      "\n",
      "2021-11-05 23:19:04.628567: \n",
      "epoch:  24\n",
      "2021-11-05 23:24:05.109234: train loss : 0.0013\n",
      "2021-11-05 23:24:24.344474: validation loss: 0.0011\n",
      "2021-11-05 23:24:24.354487: Average global foreground Dice: [0.7853]\n",
      "2021-11-05 23:24:24.359328: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 23:24:24.851501: lr: 0.005359\n",
      "2021-11-05 23:24:24.885420: saving checkpoint...\n",
      "2021-11-05 23:24:25.832744: done, saving took 0.98 seconds\n",
      "2021-11-05 23:24:25.857170: This epoch took 321.223270 s\n",
      "\n",
      "2021-11-05 23:24:25.862488: \n",
      "epoch:  25\n",
      "2021-11-05 23:29:34.778391: train loss : 0.0013\n",
      "2021-11-05 23:29:54.858961: validation loss: 0.0010\n",
      "2021-11-05 23:29:54.865483: Average global foreground Dice: [0.7788]\n",
      "2021-11-05 23:29:54.870376: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 23:29:57.253573: lr: 0.005166\n",
      "2021-11-05 23:29:57.304928: saving checkpoint...\n",
      "2021-11-05 23:29:58.637103: done, saving took 1.38 seconds\n",
      "2021-11-05 23:29:58.664111: This epoch took 332.797274 s\n",
      "\n",
      "2021-11-05 23:29:58.669159: \n",
      "epoch:  26\n",
      "2021-11-05 23:35:02.358384: train loss : 0.0013\n",
      "2021-11-05 23:35:21.011754: validation loss: 0.0010\n",
      "2021-11-05 23:35:21.018159: Average global foreground Dice: [0.7758]\n",
      "2021-11-05 23:35:21.023430: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 23:35:21.520613: lr: 0.004971\n",
      "2021-11-05 23:35:21.554702: saving checkpoint...\n",
      "2021-11-05 23:35:22.511300: done, saving took 0.98 seconds\n",
      "2021-11-05 23:35:22.533786: This epoch took 323.859511 s\n",
      "\n",
      "2021-11-05 23:35:22.538418: \n",
      "epoch:  27\n",
      "2021-11-05 23:40:25.497258: train loss : 0.0013\n",
      "2021-11-05 23:40:45.744404: validation loss: 0.0010\n",
      "2021-11-05 23:40:45.762609: Average global foreground Dice: [0.7854]\n",
      "2021-11-05 23:40:45.767739: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 23:40:48.301911: lr: 0.004776\n",
      "2021-11-05 23:40:48.395890: saving checkpoint...\n",
      "2021-11-05 23:40:49.851946: done, saving took 1.55 seconds\n",
      "2021-11-05 23:40:49.943840: This epoch took 327.400849 s\n",
      "\n",
      "2021-11-05 23:40:49.949625: \n",
      "epoch:  28\n",
      "2021-11-05 23:45:53.288671: train loss : 0.0012\n",
      "2021-11-05 23:46:12.448416: validation loss: 0.0010\n",
      "2021-11-05 23:46:12.456987: Average global foreground Dice: [0.7867]\n",
      "2021-11-05 23:46:12.463242: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 23:46:14.563745: lr: 0.004581\n",
      "2021-11-05 23:46:14.654217: saving checkpoint...\n",
      "2021-11-05 23:46:15.829175: done, saving took 1.26 seconds\n",
      "2021-11-05 23:46:15.858881: This epoch took 325.904339 s\n",
      "\n",
      "2021-11-05 23:46:15.864547: \n",
      "epoch:  29\n",
      "2021-11-05 23:51:17.017014: train loss : 0.0013\n",
      "2021-11-05 23:51:34.746025: validation loss: 0.0010\n",
      "2021-11-05 23:51:34.751871: Average global foreground Dice: [0.801]\n",
      "2021-11-05 23:51:34.757455: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 23:51:35.267782: lr: 0.004384\n",
      "2021-11-05 23:51:35.340218: saving checkpoint...\n",
      "2021-11-05 23:51:36.320778: done, saving took 1.05 seconds\n",
      "2021-11-05 23:51:36.350300: This epoch took 320.479387 s\n",
      "\n",
      "2021-11-05 23:51:36.354965: \n",
      "epoch:  30\n",
      "2021-11-05 23:56:37.576521: train loss : 0.0012\n",
      "2021-11-05 23:56:56.600211: validation loss: 0.0010\n",
      "2021-11-05 23:56:56.605663: Average global foreground Dice: [0.7974]\n",
      "2021-11-05 23:56:56.610996: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-05 23:56:57.139064: lr: 0.004186\n",
      "2021-11-05 23:56:57.202947: saving checkpoint...\n",
      "2021-11-05 23:56:58.164395: done, saving took 1.02 seconds\n",
      "2021-11-05 23:56:58.195163: This epoch took 321.835741 s\n",
      "\n",
      "2021-11-05 23:56:58.200487: \n",
      "epoch:  31\n",
      "2021-11-06 00:01:58.788767: train loss : 0.0012\n",
      "2021-11-06 00:02:17.419195: validation loss: 0.0010\n",
      "2021-11-06 00:02:17.425256: Average global foreground Dice: [0.7832]\n",
      "2021-11-06 00:02:17.430275: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 00:02:17.934008: lr: 0.003987\n",
      "2021-11-06 00:02:17.997802: saving checkpoint...\n",
      "2021-11-06 00:02:18.991791: done, saving took 1.05 seconds\n",
      "2021-11-06 00:02:19.022631: This epoch took 320.817494 s\n",
      "\n",
      "2021-11-06 00:02:19.028153: \n",
      "epoch:  32\n",
      "2021-11-06 00:07:21.697545: train loss : 0.0012\n",
      "2021-11-06 00:07:41.340122: validation loss: 0.0010\n",
      "2021-11-06 00:07:41.346701: Average global foreground Dice: [0.7984]\n",
      "2021-11-06 00:07:41.351486: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 00:07:41.936731: lr: 0.003787\n",
      "2021-11-06 00:07:42.001163: saving checkpoint...\n",
      "2021-11-06 00:07:42.978392: done, saving took 1.04 seconds\n",
      "2021-11-06 00:07:43.009331: This epoch took 323.975136 s\n",
      "\n",
      "2021-11-06 00:07:43.013991: \n",
      "epoch:  33\n",
      "2021-11-06 00:12:48.750370: train loss : 0.0012\n",
      "2021-11-06 00:13:08.360255: validation loss: 0.0009\n",
      "2021-11-06 00:13:08.365977: Average global foreground Dice: [0.7899]\n",
      "2021-11-06 00:13:08.370884: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 00:13:10.357724: lr: 0.003586\n",
      "2021-11-06 00:13:10.503306: saving checkpoint...\n",
      "2021-11-06 00:13:12.604208: done, saving took 2.24 seconds\n",
      "2021-11-06 00:13:12.659776: This epoch took 329.640933 s\n",
      "\n",
      "2021-11-06 00:13:12.665079: \n",
      "epoch:  34\n",
      "2021-11-06 00:18:19.650457: train loss : 0.0012\n",
      "2021-11-06 00:18:39.439677: validation loss: 0.0010\n",
      "2021-11-06 00:18:39.457185: Average global foreground Dice: [0.8031]\n",
      "2021-11-06 00:18:39.462433: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 00:18:41.379715: lr: 0.003384\n",
      "2021-11-06 00:18:41.475049: saving checkpoint...\n",
      "2021-11-06 00:18:43.290733: done, saving took 1.91 seconds\n",
      "2021-11-06 00:18:43.337283: This epoch took 330.667534 s\n",
      "\n",
      "2021-11-06 00:18:43.341453: \n",
      "epoch:  35\n",
      "2021-11-06 00:23:46.890385: train loss : 0.0012\n",
      "2021-11-06 00:24:06.652231: validation loss: 0.0009\n",
      "2021-11-06 00:24:06.660954: Average global foreground Dice: [0.7928]\n",
      "2021-11-06 00:24:06.666532: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 00:24:07.942775: lr: 0.00318\n",
      "2021-11-06 00:24:07.987100: saving checkpoint...\n",
      "2021-11-06 00:24:09.096916: done, saving took 1.15 seconds\n",
      "2021-11-06 00:24:09.122373: This epoch took 325.776106 s\n",
      "\n",
      "2021-11-06 00:24:09.127830: \n",
      "epoch:  36\n",
      "2021-11-06 00:29:09.802312: train loss : 0.0012\n",
      "2021-11-06 00:29:28.992221: validation loss: 0.0010\n",
      "2021-11-06 00:29:28.999298: Average global foreground Dice: [0.7949]\n",
      "2021-11-06 00:29:29.005231: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 00:29:29.955674: lr: 0.002975\n",
      "2021-11-06 00:29:29.989873: saving checkpoint...\n",
      "2021-11-06 00:29:30.960353: done, saving took 1.00 seconds\n",
      "2021-11-06 00:29:30.984449: This epoch took 321.851398 s\n",
      "\n",
      "2021-11-06 00:29:30.989422: \n",
      "epoch:  37\n",
      "2021-11-06 00:34:35.697177: train loss : 0.0012\n",
      "2021-11-06 00:34:55.845513: validation loss: 0.0010\n",
      "2021-11-06 00:34:55.851574: Average global foreground Dice: [0.7999]\n",
      "2021-11-06 00:34:55.857065: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 00:34:57.860020: lr: 0.002768\n",
      "2021-11-06 00:34:57.941995: saving checkpoint...\n",
      "2021-11-06 00:34:59.681221: done, saving took 1.82 seconds\n",
      "2021-11-06 00:34:59.707256: This epoch took 328.712785 s\n",
      "\n",
      "2021-11-06 00:34:59.737271: \n",
      "epoch:  38\n",
      "2021-11-06 00:40:04.975857: train loss : 0.0012\n",
      "2021-11-06 00:40:24.476278: validation loss: 0.0010\n",
      "2021-11-06 00:40:24.481920: Average global foreground Dice: [0.7941]\n",
      "2021-11-06 00:40:24.486970: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 00:40:25.583362: lr: 0.00256\n",
      "2021-11-06 00:40:25.618094: saving checkpoint...\n",
      "2021-11-06 00:40:26.683355: done, saving took 1.09 seconds\n",
      "2021-11-06 00:40:26.708761: This epoch took 326.965362 s\n",
      "\n",
      "2021-11-06 00:40:26.713831: \n",
      "epoch:  39\n",
      "2021-11-06 00:45:28.898402: train loss : 0.0012\n",
      "2021-11-06 00:45:48.785994: validation loss: 0.0010\n",
      "2021-11-06 00:45:48.796352: Average global foreground Dice: [0.8074]\n",
      "2021-11-06 00:45:48.802157: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 00:45:51.361831: lr: 0.002349\n",
      "2021-11-06 00:45:51.452867: saving checkpoint...\n",
      "2021-11-06 00:45:53.057420: done, saving took 1.69 seconds\n",
      "2021-11-06 00:45:53.084343: This epoch took 326.365133 s\n",
      "\n",
      "2021-11-06 00:45:53.089246: \n",
      "epoch:  40\n",
      "2021-11-06 00:50:57.398309: train loss : 0.0012\n",
      "2021-11-06 00:51:16.992469: validation loss: 0.0010\n",
      "2021-11-06 00:51:17.003330: Average global foreground Dice: [0.7806]\n",
      "2021-11-06 00:51:17.008293: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 00:51:18.876702: lr: 0.002137\n",
      "2021-11-06 00:51:18.912465: saving checkpoint...\n",
      "2021-11-06 00:51:20.058709: done, saving took 1.18 seconds\n",
      "2021-11-06 00:51:20.087409: This epoch took 326.989568 s\n",
      "\n",
      "2021-11-06 00:51:20.093165: \n",
      "epoch:  41\n",
      "2021-11-06 00:56:22.473216: train loss : 0.0012\n",
      "2021-11-06 00:56:41.628269: validation loss: 0.0009\n",
      "2021-11-06 00:56:41.638606: Average global foreground Dice: [0.8042]\n",
      "2021-11-06 00:56:41.645575: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 00:56:42.327358: lr: 0.001922\n",
      "2021-11-06 00:56:42.362191: saving checkpoint...\n",
      "2021-11-06 00:56:43.327574: done, saving took 0.99 seconds\n",
      "2021-11-06 00:56:43.353797: This epoch took 323.255373 s\n",
      "\n",
      "2021-11-06 00:56:43.359499: \n",
      "epoch:  42\n",
      "2021-11-06 01:01:50.602881: train loss : 0.0012\n",
      "2021-11-06 01:02:10.688230: validation loss: 0.0009\n",
      "2021-11-06 01:02:10.744973: Average global foreground Dice: [0.804]\n",
      "2021-11-06 01:02:10.749686: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 01:02:12.737657: lr: 0.001704\n",
      "2021-11-06 01:02:12.790414: saving checkpoint...\n",
      "2021-11-06 01:02:15.437214: done, saving took 2.69 seconds\n",
      "2021-11-06 01:02:15.464647: This epoch took 332.098874 s\n",
      "\n",
      "2021-11-06 01:02:15.469909: \n",
      "epoch:  43\n",
      "2021-11-06 01:07:22.757626: train loss : 0.0012\n",
      "2021-11-06 01:07:42.570297: validation loss: 0.0010\n",
      "2021-11-06 01:07:42.575773: Average global foreground Dice: [0.8087]\n",
      "2021-11-06 01:07:42.579952: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 01:07:44.037770: lr: 0.001483\n",
      "2021-11-06 01:07:44.108326: saving checkpoint...\n",
      "2021-11-06 01:07:45.408649: done, saving took 1.37 seconds\n",
      "2021-11-06 01:07:45.446883: This epoch took 329.972176 s\n",
      "\n",
      "2021-11-06 01:07:45.452310: \n",
      "epoch:  44\n",
      "2021-11-06 01:12:49.400638: train loss : 0.0011\n",
      "2021-11-06 01:13:09.757176: validation loss: 0.0010\n",
      "2021-11-06 01:13:09.763479: Average global foreground Dice: [0.8082]\n",
      "2021-11-06 01:13:09.768169: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 01:13:11.602289: lr: 0.001259\n",
      "2021-11-06 01:13:11.779751: saving checkpoint...\n",
      "2021-11-06 01:13:13.656517: done, saving took 2.05 seconds\n",
      "2021-11-06 01:13:13.692315: This epoch took 328.234306 s\n",
      "\n",
      "2021-11-06 01:13:13.697057: \n",
      "epoch:  45\n",
      "2021-11-06 01:18:15.615426: train loss : 0.0012\n",
      "2021-11-06 01:18:33.403228: validation loss: 0.0009\n",
      "2021-11-06 01:18:33.409027: Average global foreground Dice: [0.7988]\n",
      "2021-11-06 01:18:33.414459: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 01:18:33.948081: lr: 0.00103\n",
      "2021-11-06 01:18:34.011744: saving checkpoint...\n",
      "2021-11-06 01:18:35.053719: done, saving took 1.10 seconds\n",
      "2021-11-06 01:18:35.079152: This epoch took 321.377142 s\n",
      "\n",
      "2021-11-06 01:18:35.084393: \n",
      "epoch:  46\n",
      "2021-11-06 01:23:42.170939: train loss : 0.0011\n",
      "2021-11-06 01:24:02.343344: validation loss: 0.0009\n",
      "2021-11-06 01:24:02.382287: Average global foreground Dice: [0.8049]\n",
      "2021-11-06 01:24:02.387490: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 01:24:04.580413: lr: 0.000795\n",
      "2021-11-06 01:24:04.668581: saving checkpoint...\n",
      "2021-11-06 01:24:06.537243: done, saving took 1.95 seconds\n",
      "2021-11-06 01:24:06.564548: This epoch took 331.473634 s\n",
      "\n",
      "2021-11-06 01:24:06.569671: \n",
      "epoch:  47\n",
      "2021-11-06 01:29:15.194985: train loss : 0.0012\n",
      "2021-11-06 01:29:34.979219: validation loss: 0.0009\n",
      "2021-11-06 01:29:35.001384: Average global foreground Dice: [0.8028]\n",
      "2021-11-06 01:29:35.007124: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 01:29:38.349614: lr: 0.000552\n",
      "2021-11-06 01:29:38.456483: saving checkpoint...\n",
      "2021-11-06 01:29:39.937369: done, saving took 1.58 seconds\n",
      "2021-11-06 01:29:39.963415: This epoch took 333.388986 s\n",
      "\n",
      "2021-11-06 01:29:39.969130: \n",
      "epoch:  48\n",
      "2021-11-06 01:34:48.687933: train loss : 0.0012\n",
      "2021-11-06 01:35:08.841138: validation loss: 0.0009\n",
      "2021-11-06 01:35:08.847022: Average global foreground Dice: [0.8142]\n",
      "2021-11-06 01:35:08.852747: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 01:35:11.137357: lr: 0.000296\n",
      "2021-11-06 01:35:11.193041: saving checkpoint...\n",
      "2021-11-06 01:35:12.937801: done, saving took 1.80 seconds\n",
      "2021-11-06 01:35:12.962582: This epoch took 332.989046 s\n",
      "\n",
      "2021-11-06 01:35:12.968203: \n",
      "epoch:  49\n",
      "2021-11-06 01:40:20.584275: train loss : 0.0012\n",
      "2021-11-06 01:40:40.459224: validation loss: 0.0009\n",
      "2021-11-06 01:40:40.465022: Average global foreground Dice: [0.8157]\n",
      "2021-11-06 01:40:40.474406: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 01:40:43.041368: lr: 0.0\n",
      "2021-11-06 01:40:43.045945: saving scheduled checkpoint file...\n",
      "2021-11-06 01:40:43.105688: saving checkpoint...\n",
      "2021-11-06 01:40:44.638410: done, saving took 1.59 seconds\n",
      "2021-11-06 01:40:44.669256: done\n",
      "2021-11-06 01:40:44.715498: saving checkpoint...\n",
      "2021-11-06 01:40:45.883731: done, saving took 1.21 seconds\n",
      "2021-11-06 01:40:45.918207: This epoch took 332.944081 s\n",
      "\n",
      "2021-11-06 01:40:45.952607: saving checkpoint...\n",
      "2021-11-06 01:40:46.783897: done, saving took 0.86 seconds\n",
      "23090557_20130717 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090560_20160114 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090562_20140206 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141215 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130626 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140124 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121015 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090597_20130227 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130208 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090621_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150105 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130807 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090637_20140401 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131126 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090644_20131216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-06 01:44:15.793962: finished prediction\n",
      "2021-11-06 01:44:15.799042: evaluation of raw predictions\n",
      "2021-11-06 01:44:17.255454: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8151202861736315\n",
      "after:  0.8151202861736315\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CE.nnUNetTrainerV2_Loss_CE'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-06 01:44:27.054741: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-06 01:44:27.070618: The split file contains 5 splits.\n",
      "2021-11-06 01:44:27.075420: Desired fold for training: 4\n",
      "2021-11-06 01:44:27.079082: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-06 01:44:31.440804: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-06 01:44:42.460953: Unable to plot network architecture:\n",
      "2021-11-06 01:44:42.466321: No module named 'hiddenlayer'\n",
      "2021-11-06 01:44:42.471081: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-06 01:44:42.475850: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-06 01:44:42.483230: \n",
      "\n",
      "2021-11-06 01:44:42.487804: \n",
      "epoch:  0\n",
      "2021-11-06 01:50:14.453238: train loss : 0.0320\n",
      "2021-11-06 01:50:34.187136: validation loss: 0.0045\n",
      "2021-11-06 01:50:34.200696: Average global foreground Dice: [0.0]\n",
      "2021-11-06 01:50:34.204771: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 01:50:35.572639: lr: 0.00982\n",
      "2021-11-06 01:50:35.577470: This epoch took 353.076775 s\n",
      "\n",
      "2021-11-06 01:50:35.582633: \n",
      "epoch:  1\n",
      "2021-11-06 01:55:44.439082: train loss : 0.0045\n",
      "2021-11-06 01:56:04.336893: validation loss: 0.0038\n",
      "2021-11-06 01:56:04.343466: Average global foreground Dice: [0.0]\n",
      "2021-11-06 01:56:04.348156: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 01:56:06.539201: lr: 0.009639\n",
      "2021-11-06 01:56:06.543445: This epoch took 330.955424 s\n",
      "\n",
      "2021-11-06 01:56:06.548391: \n",
      "epoch:  2\n",
      "2021-11-06 02:01:12.653395: train loss : 0.0041\n",
      "2021-11-06 02:01:32.683985: validation loss: 0.0034\n",
      "2021-11-06 02:01:32.703285: Average global foreground Dice: [0.0]\n",
      "2021-11-06 02:01:32.708288: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 02:01:34.981545: lr: 0.009458\n",
      "2021-11-06 02:01:34.986238: This epoch took 328.433182 s\n",
      "\n",
      "2021-11-06 02:01:34.990920: \n",
      "epoch:  3\n",
      "2021-11-06 02:06:47.666293: train loss : 0.0032\n",
      "2021-11-06 02:07:07.581641: validation loss: 0.0025\n",
      "2021-11-06 02:07:07.593426: Average global foreground Dice: [0.0167]\n",
      "2021-11-06 02:07:07.597618: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 02:07:10.272032: lr: 0.009277\n",
      "2021-11-06 02:07:10.542831: saving checkpoint...\n",
      "2021-11-06 02:07:12.437303: done, saving took 2.16 seconds\n",
      "2021-11-06 02:07:12.459341: This epoch took 337.463742 s\n",
      "\n",
      "2021-11-06 02:07:12.464583: \n",
      "epoch:  4\n",
      "2021-11-06 02:12:14.685239: train loss : 0.0026\n",
      "2021-11-06 02:12:34.656150: validation loss: 0.0021\n",
      "2021-11-06 02:12:34.660977: Average global foreground Dice: [0.3026]\n",
      "2021-11-06 02:12:34.665918: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 02:12:36.573689: lr: 0.009095\n",
      "2021-11-06 02:12:36.871858: saving checkpoint...\n",
      "2021-11-06 02:12:39.037096: done, saving took 2.46 seconds\n",
      "2021-11-06 02:12:39.091879: This epoch took 326.623003 s\n",
      "\n",
      "2021-11-06 02:12:39.096413: \n",
      "epoch:  5\n",
      "2021-11-06 02:17:40.111188: train loss : 0.0021\n",
      "2021-11-06 02:17:59.142861: validation loss: 0.0019\n",
      "2021-11-06 02:17:59.149058: Average global foreground Dice: [0.4973]\n",
      "2021-11-06 02:17:59.155176: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 02:17:59.749631: lr: 0.008913\n",
      "2021-11-06 02:17:59.834281: saving checkpoint...\n",
      "2021-11-06 02:18:00.868109: done, saving took 1.11 seconds\n",
      "2021-11-06 02:18:00.895823: This epoch took 321.794910 s\n",
      "\n",
      "2021-11-06 02:18:00.900797: \n",
      "epoch:  6\n",
      "2021-11-06 02:22:57.850130: train loss : 0.0019\n",
      "2021-11-06 02:23:16.742840: validation loss: 0.0018\n",
      "2021-11-06 02:23:16.747336: Average global foreground Dice: [0.5606]\n",
      "2021-11-06 02:23:16.752124: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 02:23:17.333880: lr: 0.008731\n",
      "2021-11-06 02:23:17.427665: saving checkpoint...\n",
      "2021-11-06 02:23:18.510778: done, saving took 1.17 seconds\n",
      "2021-11-06 02:23:18.532079: This epoch took 317.626816 s\n",
      "\n",
      "2021-11-06 02:23:18.536027: \n",
      "epoch:  7\n",
      "2021-11-06 02:28:19.197598: train loss : 0.0020\n",
      "2021-11-06 02:28:38.181590: validation loss: 0.0017\n",
      "2021-11-06 02:28:38.187749: Average global foreground Dice: [0.6511]\n",
      "2021-11-06 02:28:38.192141: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 02:28:38.752852: lr: 0.008548\n",
      "2021-11-06 02:28:38.786320: saving checkpoint...\n",
      "2021-11-06 02:28:39.962989: done, saving took 1.21 seconds\n",
      "2021-11-06 02:28:39.989727: This epoch took 321.449145 s\n",
      "\n",
      "2021-11-06 02:28:39.993621: \n",
      "epoch:  8\n",
      "2021-11-06 02:33:39.950738: train loss : 0.0018\n",
      "2021-11-06 02:33:59.899745: validation loss: 0.0017\n",
      "2021-11-06 02:33:59.937447: Average global foreground Dice: [0.616]\n",
      "2021-11-06 02:33:59.942395: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 02:34:03.166305: lr: 0.008364\n",
      "2021-11-06 02:34:03.400072: saving checkpoint...\n",
      "2021-11-06 02:34:06.037174: done, saving took 2.87 seconds\n",
      "2021-11-06 02:34:06.073126: This epoch took 326.074589 s\n",
      "\n",
      "2021-11-06 02:34:06.078145: \n",
      "epoch:  9\n",
      "2021-11-06 02:39:09.564200: train loss : 0.0017\n",
      "2021-11-06 02:39:29.301330: validation loss: 0.0015\n",
      "2021-11-06 02:39:29.308034: Average global foreground Dice: [0.682]\n",
      "2021-11-06 02:39:29.341084: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 02:39:31.569797: lr: 0.008181\n",
      "2021-11-06 02:39:31.645574: saving checkpoint...\n",
      "2021-11-06 02:39:33.537191: done, saving took 1.96 seconds\n",
      "2021-11-06 02:39:33.562932: This epoch took 327.479753 s\n",
      "\n",
      "2021-11-06 02:39:33.568194: \n",
      "epoch:  10\n",
      "2021-11-06 02:44:36.150307: train loss : 0.0016\n",
      "2021-11-06 02:44:55.703802: validation loss: 0.0015\n",
      "2021-11-06 02:44:55.709324: Average global foreground Dice: [0.6632]\n",
      "2021-11-06 02:44:55.714237: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 02:44:56.272798: lr: 0.007996\n",
      "2021-11-06 02:44:56.306764: saving checkpoint...\n",
      "2021-11-06 02:44:57.390692: done, saving took 1.11 seconds\n",
      "2021-11-06 02:44:57.421385: This epoch took 323.848436 s\n",
      "\n",
      "2021-11-06 02:44:57.425614: \n",
      "epoch:  11\n",
      "2021-11-06 02:49:57.008593: train loss : 0.0015\n",
      "2021-11-06 02:50:16.680274: validation loss: 0.0014\n",
      "2021-11-06 02:50:16.686208: Average global foreground Dice: [0.6777]\n",
      "2021-11-06 02:50:16.691847: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 02:50:18.587668: lr: 0.007811\n",
      "2021-11-06 02:50:18.682988: saving checkpoint...\n",
      "2021-11-06 02:50:19.805691: done, saving took 1.21 seconds\n",
      "2021-11-06 02:50:19.844106: This epoch took 322.414357 s\n",
      "\n",
      "2021-11-06 02:50:19.849604: \n",
      "epoch:  12\n",
      "2021-11-06 02:55:21.758988: train loss : 0.0015\n",
      "2021-11-06 02:55:41.677937: validation loss: 0.0014\n",
      "2021-11-06 02:55:41.711352: Average global foreground Dice: [0.7226]\n",
      "2021-11-06 02:55:41.747368: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 02:55:43.637996: lr: 0.007626\n",
      "2021-11-06 02:55:43.786397: saving checkpoint...\n",
      "2021-11-06 02:55:45.837294: done, saving took 2.19 seconds\n",
      "2021-11-06 02:55:45.871389: This epoch took 326.016842 s\n",
      "\n",
      "2021-11-06 02:55:45.876590: \n",
      "epoch:  13\n",
      "2021-11-06 03:00:47.575380: train loss : 0.0015\n",
      "2021-11-06 03:01:07.043708: validation loss: 0.0013\n",
      "2021-11-06 03:01:07.062243: Average global foreground Dice: [0.7388]\n",
      "2021-11-06 03:01:07.066994: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 03:01:08.805284: lr: 0.00744\n",
      "2021-11-06 03:01:08.872977: saving checkpoint...\n",
      "2021-11-06 03:01:10.054815: done, saving took 1.24 seconds\n",
      "2021-11-06 03:01:10.085403: This epoch took 324.203339 s\n",
      "\n",
      "2021-11-06 03:01:10.089869: \n",
      "epoch:  14\n",
      "2021-11-06 03:06:10.375779: train loss : 0.0015\n",
      "2021-11-06 03:06:29.445076: validation loss: 0.0014\n",
      "2021-11-06 03:06:29.452252: Average global foreground Dice: [0.7427]\n",
      "2021-11-06 03:06:29.457113: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 03:06:30.101748: lr: 0.007254\n",
      "2021-11-06 03:06:30.173543: saving checkpoint...\n",
      "2021-11-06 03:06:31.879436: done, saving took 1.77 seconds\n",
      "2021-11-06 03:06:31.912884: This epoch took 321.818062 s\n",
      "\n",
      "2021-11-06 03:06:31.917690: \n",
      "epoch:  15\n",
      "2021-11-06 03:11:31.491181: train loss : 0.0014\n",
      "2021-11-06 03:11:49.590541: validation loss: 0.0013\n",
      "2021-11-06 03:11:49.595442: Average global foreground Dice: [0.7607]\n",
      "2021-11-06 03:11:49.599709: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 03:11:50.113763: lr: 0.007067\n",
      "2021-11-06 03:11:50.146335: saving checkpoint...\n",
      "2021-11-06 03:11:51.097686: done, saving took 0.98 seconds\n",
      "2021-11-06 03:11:51.122129: This epoch took 319.198907 s\n",
      "\n",
      "2021-11-06 03:11:51.129149: \n",
      "epoch:  16\n",
      "2021-11-06 03:16:48.696121: train loss : 0.0013\n",
      "2021-11-06 03:17:07.529015: validation loss: 0.0013\n",
      "2021-11-06 03:17:07.534717: Average global foreground Dice: [0.7368]\n",
      "2021-11-06 03:17:07.539387: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 03:17:08.032475: lr: 0.00688\n",
      "2021-11-06 03:17:08.069216: saving checkpoint...\n",
      "2021-11-06 03:17:09.133156: done, saving took 1.09 seconds\n",
      "2021-11-06 03:17:09.160560: This epoch took 318.026418 s\n",
      "\n",
      "2021-11-06 03:17:09.164764: \n",
      "epoch:  17\n",
      "2021-11-06 03:22:09.250461: train loss : 0.0014\n",
      "2021-11-06 03:22:29.008110: validation loss: 0.0012\n",
      "2021-11-06 03:22:29.056911: Average global foreground Dice: [0.7612]\n",
      "2021-11-06 03:22:29.067078: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 03:22:30.799952: lr: 0.006692\n",
      "2021-11-06 03:22:30.895628: saving checkpoint...\n",
      "2021-11-06 03:22:32.221805: done, saving took 1.42 seconds\n",
      "2021-11-06 03:22:32.247614: This epoch took 323.078230 s\n",
      "\n",
      "2021-11-06 03:22:32.252801: \n",
      "epoch:  18\n",
      "2021-11-06 03:27:34.083292: train loss : 0.0013\n",
      "2021-11-06 03:27:53.239513: validation loss: 0.0012\n",
      "2021-11-06 03:27:53.244705: Average global foreground Dice: [0.773]\n",
      "2021-11-06 03:27:53.249671: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 03:27:53.819052: lr: 0.006504\n",
      "2021-11-06 03:27:53.880837: saving checkpoint...\n",
      "2021-11-06 03:27:54.910067: done, saving took 1.08 seconds\n",
      "2021-11-06 03:27:54.934269: This epoch took 322.676303 s\n",
      "\n",
      "2021-11-06 03:27:54.939346: \n",
      "epoch:  19\n",
      "2021-11-06 03:32:55.944774: train loss : 0.0013\n",
      "2021-11-06 03:33:15.203307: validation loss: 0.0012\n",
      "2021-11-06 03:33:15.242517: Average global foreground Dice: [0.7735]\n",
      "2021-11-06 03:33:15.247524: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 03:33:16.572626: lr: 0.006314\n",
      "2021-11-06 03:33:16.666816: saving checkpoint...\n",
      "2021-11-06 03:33:17.794581: done, saving took 1.22 seconds\n",
      "2021-11-06 03:33:17.825226: This epoch took 322.882127 s\n",
      "\n",
      "2021-11-06 03:33:17.830529: \n",
      "epoch:  20\n",
      "2021-11-06 03:38:18.250677: train loss : 0.0013\n",
      "2021-11-06 03:38:37.749001: validation loss: 0.0012\n",
      "2021-11-06 03:38:37.769598: Average global foreground Dice: [0.7737]\n",
      "2021-11-06 03:38:37.775889: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 03:38:39.372178: lr: 0.006125\n",
      "2021-11-06 03:38:39.414105: saving checkpoint...\n",
      "2021-11-06 03:38:40.447930: done, saving took 1.07 seconds\n",
      "2021-11-06 03:38:40.472268: This epoch took 322.636296 s\n",
      "\n",
      "2021-11-06 03:38:40.477293: \n",
      "epoch:  21\n",
      "2021-11-06 03:43:43.151006: train loss : 0.0013\n",
      "2021-11-06 03:44:03.252730: validation loss: 0.0012\n",
      "2021-11-06 03:44:03.281259: Average global foreground Dice: [0.7872]\n",
      "2021-11-06 03:44:03.288130: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 03:44:05.485954: lr: 0.005934\n",
      "2021-11-06 03:44:05.567828: saving checkpoint...\n",
      "2021-11-06 03:44:07.693048: done, saving took 2.20 seconds\n",
      "2021-11-06 03:44:07.748252: This epoch took 327.265921 s\n",
      "\n",
      "2021-11-06 03:44:07.753709: \n",
      "epoch:  22\n",
      "2021-11-06 03:49:10.757106: train loss : 0.0013\n",
      "2021-11-06 03:49:30.396333: validation loss: 0.0012\n",
      "2021-11-06 03:49:30.402334: Average global foreground Dice: [0.761]\n",
      "2021-11-06 03:49:30.407373: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 03:49:32.206866: lr: 0.005743\n",
      "2021-11-06 03:49:32.254183: saving checkpoint...\n",
      "2021-11-06 03:49:33.260323: done, saving took 1.05 seconds\n",
      "2021-11-06 03:49:33.286829: This epoch took 325.528724 s\n",
      "\n",
      "2021-11-06 03:49:33.292480: \n",
      "epoch:  23\n",
      "2021-11-06 03:54:35.478679: train loss : 0.0012\n",
      "2021-11-06 03:54:54.642041: validation loss: 0.0012\n",
      "2021-11-06 03:54:54.648641: Average global foreground Dice: [0.7697]\n",
      "2021-11-06 03:54:54.653649: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 03:54:55.160649: lr: 0.005551\n",
      "2021-11-06 03:54:55.193676: saving checkpoint...\n",
      "2021-11-06 03:54:56.157347: done, saving took 0.99 seconds\n",
      "2021-11-06 03:54:56.180952: This epoch took 322.883414 s\n",
      "\n",
      "2021-11-06 03:54:56.185860: \n",
      "epoch:  24\n",
      "2021-11-06 03:59:59.875589: train loss : 0.0012\n",
      "2021-11-06 04:00:19.652449: validation loss: 0.0011\n",
      "2021-11-06 04:00:19.663842: Average global foreground Dice: [0.7873]\n",
      "2021-11-06 04:00:19.667875: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 04:00:21.164707: lr: 0.005359\n",
      "2021-11-06 04:00:21.288584: saving checkpoint...\n",
      "2021-11-06 04:00:23.647566: done, saving took 2.48 seconds\n",
      "2021-11-06 04:00:23.683050: This epoch took 327.492712 s\n",
      "\n",
      "2021-11-06 04:00:23.687916: \n",
      "epoch:  25\n",
      "2021-11-06 04:05:30.550146: train loss : 0.0013\n",
      "2021-11-06 04:05:50.910347: validation loss: 0.0011\n",
      "2021-11-06 04:05:50.948990: Average global foreground Dice: [0.786]\n",
      "2021-11-06 04:05:50.953939: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 04:05:53.199723: lr: 0.005166\n",
      "2021-11-06 04:05:53.357507: saving checkpoint...\n",
      "2021-11-06 04:05:54.956552: done, saving took 1.75 seconds\n",
      "2021-11-06 04:05:54.987978: This epoch took 331.294858 s\n",
      "\n",
      "2021-11-06 04:05:54.993403: \n",
      "epoch:  26\n",
      "2021-11-06 04:10:57.850215: train loss : 0.0012\n",
      "2021-11-06 04:11:16.799850: validation loss: 0.0012\n",
      "2021-11-06 04:11:16.805921: Average global foreground Dice: [0.7864]\n",
      "2021-11-06 04:11:16.810795: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 04:11:17.347789: lr: 0.004971\n",
      "2021-11-06 04:11:17.404659: saving checkpoint...\n",
      "2021-11-06 04:11:18.527531: done, saving took 1.18 seconds\n",
      "2021-11-06 04:11:18.560556: This epoch took 323.562434 s\n",
      "\n",
      "2021-11-06 04:11:18.565089: \n",
      "epoch:  27\n",
      "2021-11-06 04:16:20.679443: train loss : 0.0012\n",
      "2021-11-06 04:16:40.261007: validation loss: 0.0011\n",
      "2021-11-06 04:16:40.283027: Average global foreground Dice: [0.7892]\n",
      "2021-11-06 04:16:40.288946: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 04:16:41.918702: lr: 0.004776\n",
      "2021-11-06 04:16:41.969731: saving checkpoint...\n",
      "2021-11-06 04:16:43.126652: done, saving took 1.20 seconds\n",
      "2021-11-06 04:16:43.149579: This epoch took 324.579957 s\n",
      "\n",
      "2021-11-06 04:16:43.154711: \n",
      "epoch:  28\n",
      "2021-11-06 04:21:47.576030: train loss : 0.0012\n",
      "2021-11-06 04:22:07.000161: validation loss: 0.0011\n",
      "2021-11-06 04:22:07.041786: Average global foreground Dice: [0.7921]\n",
      "2021-11-06 04:22:07.046693: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 04:22:09.183560: lr: 0.004581\n",
      "2021-11-06 04:22:09.251156: saving checkpoint...\n",
      "2021-11-06 04:22:10.899567: done, saving took 1.71 seconds\n",
      "2021-11-06 04:22:10.947993: This epoch took 327.788722 s\n",
      "\n",
      "2021-11-06 04:22:10.953135: \n",
      "epoch:  29\n",
      "2021-11-06 04:27:16.739486: train loss : 0.0013\n",
      "2021-11-06 04:27:36.560239: validation loss: 0.0011\n",
      "2021-11-06 04:27:36.566451: Average global foreground Dice: [0.7819]\n",
      "2021-11-06 04:27:36.571276: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 04:27:38.407939: lr: 0.004384\n",
      "2021-11-06 04:27:38.602979: saving checkpoint...\n",
      "2021-11-06 04:27:40.294982: done, saving took 1.86 seconds\n",
      "2021-11-06 04:27:40.357716: This epoch took 329.399683 s\n",
      "\n",
      "2021-11-06 04:27:40.362769: \n",
      "epoch:  30\n",
      "2021-11-06 04:32:44.751142: train loss : 0.0012\n",
      "2021-11-06 04:33:04.293874: validation loss: 0.0011\n",
      "2021-11-06 04:33:04.299608: Average global foreground Dice: [0.7975]\n",
      "2021-11-06 04:33:04.304415: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 04:33:06.054864: lr: 0.004186\n",
      "2021-11-06 04:33:06.163886: saving checkpoint...\n",
      "2021-11-06 04:33:07.411703: done, saving took 1.35 seconds\n",
      "2021-11-06 04:33:07.436325: This epoch took 327.068845 s\n",
      "\n",
      "2021-11-06 04:33:07.441145: \n",
      "epoch:  31\n",
      "2021-11-06 04:38:07.093218: train loss : 0.0012\n",
      "2021-11-06 04:38:25.676227: validation loss: 0.0011\n",
      "2021-11-06 04:38:25.682285: Average global foreground Dice: [0.7879]\n",
      "2021-11-06 04:38:25.686659: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 04:38:26.194982: lr: 0.003987\n",
      "2021-11-06 04:38:26.264534: saving checkpoint...\n",
      "2021-11-06 04:38:27.308057: done, saving took 1.11 seconds\n",
      "2021-11-06 04:38:27.339145: This epoch took 319.892752 s\n",
      "\n",
      "2021-11-06 04:38:27.344169: \n",
      "epoch:  32\n",
      "2021-11-06 04:43:29.979729: train loss : 0.0012\n",
      "2021-11-06 04:43:49.587629: validation loss: 0.0011\n",
      "2021-11-06 04:43:49.637199: Average global foreground Dice: [0.8046]\n",
      "2021-11-06 04:43:49.642327: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 04:43:51.537860: lr: 0.003787\n",
      "2021-11-06 04:43:51.641328: saving checkpoint...\n",
      "2021-11-06 04:43:52.987536: done, saving took 1.44 seconds\n",
      "2021-11-06 04:43:53.020609: This epoch took 325.671552 s\n",
      "\n",
      "2021-11-06 04:43:53.025189: \n",
      "epoch:  33\n",
      "2021-11-06 04:48:55.600818: train loss : 0.0011\n",
      "2021-11-06 04:49:14.648176: validation loss: 0.0011\n",
      "2021-11-06 04:49:14.661957: Average global foreground Dice: [0.7966]\n",
      "2021-11-06 04:49:14.666524: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 04:49:15.760013: lr: 0.003586\n",
      "2021-11-06 04:49:15.794359: saving checkpoint...\n",
      "2021-11-06 04:49:16.831271: done, saving took 1.07 seconds\n",
      "2021-11-06 04:49:16.855049: This epoch took 323.824745 s\n",
      "\n",
      "2021-11-06 04:49:16.860159: \n",
      "epoch:  34\n",
      "2021-11-06 04:54:22.890018: train loss : 0.0012\n",
      "2021-11-06 04:54:43.269241: validation loss: 0.0011\n",
      "2021-11-06 04:54:43.275400: Average global foreground Dice: [0.7945]\n",
      "2021-11-06 04:54:43.280474: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 04:54:44.775693: lr: 0.003384\n",
      "2021-11-06 04:54:44.856058: saving checkpoint...\n",
      "2021-11-06 04:54:46.692242: done, saving took 1.91 seconds\n",
      "2021-11-06 04:54:46.748021: This epoch took 329.883790 s\n",
      "\n",
      "2021-11-06 04:54:46.752565: \n",
      "epoch:  35\n",
      "2021-11-06 04:59:52.462823: train loss : 0.0012\n",
      "2021-11-06 05:00:12.538507: validation loss: 0.0011\n",
      "2021-11-06 05:00:12.553851: Average global foreground Dice: [0.7989]\n",
      "2021-11-06 05:00:12.559029: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 05:00:14.676083: lr: 0.00318\n",
      "2021-11-06 05:00:14.843048: saving checkpoint...\n",
      "2021-11-06 05:00:16.786755: done, saving took 2.11 seconds\n",
      "2021-11-06 05:00:16.848058: This epoch took 330.090356 s\n",
      "\n",
      "2021-11-06 05:00:16.853581: \n",
      "epoch:  36\n",
      "2021-11-06 05:05:22.878190: train loss : 0.0011\n",
      "2021-11-06 05:05:42.799552: validation loss: 0.0011\n",
      "2021-11-06 05:05:42.806207: Average global foreground Dice: [0.8018]\n",
      "2021-11-06 05:05:42.836726: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 05:05:44.986603: lr: 0.002975\n",
      "2021-11-06 05:05:45.183062: saving checkpoint...\n",
      "2021-11-06 05:05:46.986317: done, saving took 1.99 seconds\n",
      "2021-11-06 05:05:47.037153: This epoch took 330.178531 s\n",
      "\n",
      "2021-11-06 05:05:47.042590: \n",
      "epoch:  37\n",
      "2021-11-06 05:10:50.150409: train loss : 0.0011\n",
      "2021-11-06 05:11:09.221234: validation loss: 0.0011\n",
      "2021-11-06 05:11:09.225946: Average global foreground Dice: [0.7689]\n",
      "2021-11-06 05:11:09.230700: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 05:11:09.745713: lr: 0.002768\n",
      "2021-11-06 05:11:09.778480: saving checkpoint...\n",
      "2021-11-06 05:11:10.724725: done, saving took 0.97 seconds\n",
      "2021-11-06 05:11:10.752723: This epoch took 323.704969 s\n",
      "\n",
      "2021-11-06 05:11:10.757658: \n",
      "epoch:  38\n",
      "2021-11-06 05:16:15.808943: train loss : 0.0011\n",
      "2021-11-06 05:16:35.356565: validation loss: 0.0011\n",
      "2021-11-06 05:16:35.363121: Average global foreground Dice: [0.7865]\n",
      "2021-11-06 05:16:35.370899: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 05:16:37.027179: lr: 0.00256\n",
      "2021-11-06 05:16:37.090020: saving checkpoint...\n",
      "2021-11-06 05:16:38.609386: done, saving took 1.57 seconds\n",
      "2021-11-06 05:16:38.646186: This epoch took 327.883661 s\n",
      "\n",
      "2021-11-06 05:16:38.652003: \n",
      "epoch:  39\n",
      "2021-11-06 05:21:45.690180: train loss : 0.0011\n",
      "2021-11-06 05:22:05.092311: validation loss: 0.0011\n",
      "2021-11-06 05:22:05.103083: Average global foreground Dice: [0.7856]\n",
      "2021-11-06 05:22:05.107569: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 05:22:06.812238: lr: 0.002349\n",
      "2021-11-06 05:22:06.858284: saving checkpoint...\n",
      "2021-11-06 05:22:07.974787: done, saving took 1.16 seconds\n",
      "2021-11-06 05:22:07.997069: This epoch took 329.339317 s\n",
      "\n",
      "2021-11-06 05:22:08.002014: \n",
      "epoch:  40\n",
      "2021-11-06 05:27:14.346354: train loss : 0.0011\n",
      "2021-11-06 05:27:33.774576: validation loss: 0.0011\n",
      "2021-11-06 05:27:33.780548: Average global foreground Dice: [0.8109]\n",
      "2021-11-06 05:27:33.786377: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 05:27:35.482368: lr: 0.002137\n",
      "2021-11-06 05:27:35.563720: saving checkpoint...\n",
      "2021-11-06 05:27:36.787949: done, saving took 1.30 seconds\n",
      "2021-11-06 05:27:36.816303: This epoch took 328.809311 s\n",
      "\n",
      "2021-11-06 05:27:36.821026: \n",
      "epoch:  41\n",
      "2021-11-06 05:32:41.674695: train loss : 0.0011\n",
      "2021-11-06 05:33:01.055988: validation loss: 0.0010\n",
      "2021-11-06 05:33:01.063212: Average global foreground Dice: [0.7987]\n",
      "2021-11-06 05:33:01.068829: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 05:33:02.933658: lr: 0.001922\n",
      "2021-11-06 05:33:02.969993: saving checkpoint...\n",
      "2021-11-06 05:33:03.930613: done, saving took 0.99 seconds\n",
      "2021-11-06 05:33:03.955287: This epoch took 327.129100 s\n",
      "\n",
      "2021-11-06 05:33:03.961202: \n",
      "epoch:  42\n",
      "2021-11-06 05:38:07.166645: train loss : 0.0011\n",
      "2021-11-06 05:38:25.710437: validation loss: 0.0011\n",
      "2021-11-06 05:38:25.715995: Average global foreground Dice: [0.8028]\n",
      "2021-11-06 05:38:25.720200: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 05:38:26.224499: lr: 0.001704\n",
      "2021-11-06 05:38:26.258643: saving checkpoint...\n",
      "2021-11-06 05:38:27.218469: done, saving took 0.99 seconds\n",
      "2021-11-06 05:38:27.241900: This epoch took 323.275688 s\n",
      "\n",
      "2021-11-06 05:38:27.246267: \n",
      "epoch:  43\n",
      "2021-11-06 05:43:33.748114: train loss : 0.0010\n",
      "2021-11-06 05:43:52.242792: validation loss: 0.0011\n",
      "2021-11-06 05:43:52.248313: Average global foreground Dice: [0.8087]\n",
      "2021-11-06 05:43:52.252406: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 05:43:52.751231: lr: 0.001483\n",
      "2021-11-06 05:43:52.784513: saving checkpoint...\n",
      "2021-11-06 05:43:53.763426: done, saving took 1.01 seconds\n",
      "2021-11-06 05:43:53.793974: This epoch took 326.542645 s\n",
      "\n",
      "2021-11-06 05:43:53.798141: \n",
      "epoch:  44\n",
      "2021-11-06 05:48:56.822791: train loss : 0.0011\n",
      "2021-11-06 05:49:14.686277: validation loss: 0.0011\n",
      "2021-11-06 05:49:14.693034: Average global foreground Dice: [0.8004]\n",
      "2021-11-06 05:49:14.700691: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 05:49:15.205474: lr: 0.001259\n",
      "2021-11-06 05:49:15.261912: saving checkpoint...\n",
      "2021-11-06 05:49:16.296736: done, saving took 1.09 seconds\n",
      "2021-11-06 05:49:16.329264: This epoch took 322.526356 s\n",
      "\n",
      "2021-11-06 05:49:16.333629: \n",
      "epoch:  45\n",
      "2021-11-06 05:54:18.946164: train loss : 0.0010\n",
      "2021-11-06 05:54:37.807508: validation loss: 0.0010\n",
      "2021-11-06 05:54:37.812723: Average global foreground Dice: [0.8028]\n",
      "2021-11-06 05:54:37.818212: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 05:54:38.306814: lr: 0.00103\n",
      "2021-11-06 05:54:38.340875: saving checkpoint...\n",
      "2021-11-06 05:54:39.301847: done, saving took 0.99 seconds\n",
      "2021-11-06 05:54:39.325844: This epoch took 322.987497 s\n",
      "\n",
      "2021-11-06 05:54:39.330967: \n",
      "epoch:  46\n",
      "2021-11-06 05:59:43.150287: train loss : 0.0010\n",
      "2021-11-06 06:00:02.548469: validation loss: 0.0010\n",
      "2021-11-06 06:00:02.554510: Average global foreground Dice: [0.8108]\n",
      "2021-11-06 06:00:02.560837: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 06:00:04.274956: lr: 0.000795\n",
      "2021-11-06 06:00:04.311118: saving checkpoint...\n",
      "2021-11-06 06:00:05.324002: done, saving took 1.04 seconds\n",
      "2021-11-06 06:00:05.353328: This epoch took 326.017442 s\n",
      "\n",
      "2021-11-06 06:00:05.358130: \n",
      "epoch:  47\n",
      "2021-11-06 06:05:09.795708: train loss : 0.0011\n",
      "2021-11-06 06:05:27.789179: validation loss: 0.0011\n",
      "2021-11-06 06:05:27.795337: Average global foreground Dice: [0.8049]\n",
      "2021-11-06 06:05:27.800794: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 06:05:28.299313: lr: 0.000552\n",
      "2021-11-06 06:05:28.364580: saving checkpoint...\n",
      "2021-11-06 06:05:29.345885: done, saving took 1.04 seconds\n",
      "2021-11-06 06:05:29.374091: This epoch took 324.011110 s\n",
      "\n",
      "2021-11-06 06:05:29.379102: \n",
      "epoch:  48\n",
      "2021-11-06 06:10:35.657488: train loss : 0.0010\n",
      "2021-11-06 06:10:53.585618: validation loss: 0.0011\n",
      "2021-11-06 06:10:53.590362: Average global foreground Dice: [0.7926]\n",
      "2021-11-06 06:10:53.595142: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 06:10:54.099175: lr: 0.000296\n",
      "2021-11-06 06:10:54.159898: saving checkpoint...\n",
      "2021-11-06 06:10:55.111619: done, saving took 1.01 seconds\n",
      "2021-11-06 06:10:55.143054: This epoch took 325.759267 s\n",
      "\n",
      "2021-11-06 06:10:55.147178: \n",
      "epoch:  49\n",
      "2021-11-06 06:16:00.207685: train loss : 0.0010\n",
      "2021-11-06 06:16:19.049153: validation loss: 0.0010\n",
      "2021-11-06 06:16:19.054293: Average global foreground Dice: [0.8171]\n",
      "2021-11-06 06:16:19.059276: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-06 06:16:19.598751: lr: 0.0\n",
      "2021-11-06 06:16:19.604470: saving scheduled checkpoint file...\n",
      "2021-11-06 06:16:19.665699: saving checkpoint...\n",
      "2021-11-06 06:16:20.484330: done, saving took 0.88 seconds\n",
      "2021-11-06 06:16:20.508784: done\n",
      "2021-11-06 06:16:20.585060: saving checkpoint...\n",
      "2021-11-06 06:16:21.543846: done, saving took 1.03 seconds\n",
      "2021-11-06 06:16:21.567148: This epoch took 326.415159 s\n",
      "\n",
      "2021-11-06 06:16:21.601890: saving checkpoint...\n",
      "2021-11-06 06:16:22.438766: done, saving took 0.87 seconds\n",
      "23090558_20120330 (3, 263, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 263, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 7], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090564_20130312 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090568_20121018 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090569_20120607 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120613 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150908 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090593_20120625 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130103 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090600_20121108 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090603_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090607_20120420 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090609_20120510 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160119 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160510 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090646_20120718 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-06 06:19:52.152578: finished prediction\n",
      "2021-11-06 06:19:52.157508: evaluation of raw predictions\n",
      "2021-11-06 06:19:53.603663: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.809053302146021\n",
      "after:  0.8062949659582048\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Model 5 ()\n",
    "\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_CE 555 0\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_CE 555 1\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_CE 555 2\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_CE 555 3\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_CE 555 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-08 03:52:35.365506: Creating new 5-fold cross-validation split...\n",
      "2021-11-08 03:52:35.378733: Desired fold for training: 3\n",
      "2021-11-08 03:52:35.382648: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-08 03:52:44.766221: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-08 03:52:58.678293: Unable to plot network architecture:\n",
      "2021-11-08 03:52:58.707560: No module named 'hiddenlayer'\n",
      "2021-11-08 03:52:58.711996: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-08 03:52:58.716917: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-08 03:52:58.725086: \n",
      "\n",
      "2021-11-08 03:52:58.730774: \n",
      "epoch:  0\n",
      "2021-11-08 03:58:32.889113: train loss : -0.1721\n",
      "2021-11-08 03:58:55.684402: validation loss: -0.5698\n",
      "2021-11-08 03:58:55.689945: Average global foreground Dice: [0.6398]\n",
      "2021-11-08 03:58:55.694155: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 03:58:57.601655: lr: 0.00994\n",
      "2021-11-08 03:58:57.605620: This epoch took 358.830281 s\n",
      "\n",
      "2021-11-08 03:58:57.610201: \n",
      "epoch:  1\n",
      "2021-11-08 04:03:55.492931: train loss : -0.6033\n",
      "2021-11-08 04:04:17.211125: validation loss: -0.6921\n",
      "2021-11-08 04:04:17.216399: Average global foreground Dice: [0.74]\n",
      "2021-11-08 04:04:17.220191: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 04:04:17.869720: lr: 0.00988\n",
      "2021-11-08 04:04:17.951199: saving checkpoint...\n",
      "2021-11-08 04:04:18.818620: done, saving took 0.95 seconds\n",
      "2021-11-08 04:04:18.850868: This epoch took 321.235591 s\n",
      "\n",
      "2021-11-08 04:04:18.855141: \n",
      "epoch:  2\n",
      "2021-11-08 04:09:20.687168: train loss : -0.6846\n",
      "2021-11-08 04:09:42.778752: validation loss: -0.7503\n",
      "2021-11-08 04:09:42.788718: Average global foreground Dice: [0.8032]\n",
      "2021-11-08 04:09:42.793235: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 04:09:45.192911: lr: 0.00982\n",
      "2021-11-08 04:09:45.416854: saving checkpoint...\n",
      "2021-11-08 04:09:47.056587: done, saving took 1.86 seconds\n",
      "2021-11-08 04:09:47.097259: This epoch took 328.238001 s\n",
      "\n",
      "2021-11-08 04:09:47.101775: \n",
      "epoch:  3\n",
      "2021-11-08 04:14:44.573073: train loss : -0.7143\n",
      "2021-11-08 04:15:04.914606: validation loss: -0.7366\n",
      "2021-11-08 04:15:04.920268: Average global foreground Dice: [0.7722]\n",
      "2021-11-08 04:15:04.924272: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 04:15:05.440671: lr: 0.00976\n",
      "2021-11-08 04:15:05.519771: saving checkpoint...\n",
      "2021-11-08 04:15:06.512881: done, saving took 1.07 seconds\n",
      "2021-11-08 04:15:06.542923: This epoch took 319.437136 s\n",
      "\n",
      "2021-11-08 04:15:06.547560: \n",
      "epoch:  4\n",
      "2021-11-08 04:20:05.373075: train loss : -0.7403\n",
      "2021-11-08 04:20:26.605765: validation loss: -0.7785\n",
      "2021-11-08 04:20:26.623738: Average global foreground Dice: [0.8173]\n",
      "2021-11-08 04:20:26.628208: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 04:20:28.861384: lr: 0.009699\n",
      "2021-11-08 04:20:28.981036: saving checkpoint...\n",
      "2021-11-08 04:20:30.222130: done, saving took 1.36 seconds\n",
      "2021-11-08 04:20:30.244748: This epoch took 323.692666 s\n",
      "\n",
      "2021-11-08 04:20:30.249330: \n",
      "epoch:  5\n",
      "2021-11-08 04:25:28.501858: train loss : -0.7527\n",
      "2021-11-08 04:25:47.241529: validation loss: -0.7905\n",
      "2021-11-08 04:25:47.246134: Average global foreground Dice: [0.8286]\n",
      "2021-11-08 04:25:47.250801: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 04:25:47.774114: lr: 0.009639\n",
      "2021-11-08 04:25:47.850614: saving checkpoint...\n",
      "2021-11-08 04:25:48.824859: done, saving took 1.05 seconds\n",
      "2021-11-08 04:25:48.847842: This epoch took 318.593901 s\n",
      "\n",
      "2021-11-08 04:25:48.851357: \n",
      "epoch:  6\n",
      "2021-11-08 04:30:47.165595: train loss : -0.7742\n",
      "2021-11-08 04:31:06.836937: validation loss: -0.8047\n",
      "2021-11-08 04:31:06.842330: Average global foreground Dice: [0.8343]\n",
      "2021-11-08 04:31:06.847061: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 04:31:07.345273: lr: 0.009579\n",
      "2021-11-08 04:31:07.408341: saving checkpoint...\n",
      "2021-11-08 04:31:08.366154: done, saving took 1.02 seconds\n",
      "2021-11-08 04:31:08.389828: This epoch took 319.534006 s\n",
      "\n",
      "2021-11-08 04:31:08.393607: \n",
      "epoch:  7\n",
      "2021-11-08 04:36:05.781437: train loss : -0.7841\n",
      "2021-11-08 04:36:27.664294: validation loss: -0.8137\n",
      "2021-11-08 04:36:27.671481: Average global foreground Dice: [0.8398]\n",
      "2021-11-08 04:36:27.676833: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 04:36:29.192375: lr: 0.009519\n",
      "2021-11-08 04:36:29.297303: saving checkpoint...\n",
      "2021-11-08 04:36:30.394143: done, saving took 1.20 seconds\n",
      "2021-11-08 04:36:30.421941: This epoch took 322.024629 s\n",
      "\n",
      "2021-11-08 04:36:30.425476: \n",
      "epoch:  8\n",
      "2021-11-08 04:41:21.002540: train loss : -0.7928\n",
      "2021-11-08 04:41:39.842913: validation loss: -0.8072\n",
      "2021-11-08 04:41:39.848257: Average global foreground Dice: [0.83]\n",
      "2021-11-08 04:41:39.852443: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 04:41:40.415517: lr: 0.009458\n",
      "2021-11-08 04:41:40.447902: saving checkpoint...\n",
      "2021-11-08 04:41:41.358847: done, saving took 0.94 seconds\n",
      "2021-11-08 04:41:41.381818: This epoch took 310.951802 s\n",
      "\n",
      "2021-11-08 04:41:41.386885: \n",
      "epoch:  9\n",
      "2021-11-08 04:46:34.075758: train loss : -0.7991\n",
      "2021-11-08 04:46:54.773916: validation loss: -0.8024\n",
      "2021-11-08 04:46:54.778111: Average global foreground Dice: [0.8298]\n",
      "2021-11-08 04:46:54.782217: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 04:46:55.369653: lr: 0.009398\n",
      "2021-11-08 04:46:55.403469: saving checkpoint...\n",
      "2021-11-08 04:46:56.479394: done, saving took 1.11 seconds\n",
      "2021-11-08 04:46:56.506300: This epoch took 315.114618 s\n",
      "\n",
      "2021-11-08 04:46:56.510726: \n",
      "epoch:  10\n",
      "2021-11-08 04:51:52.067999: train loss : -0.7971\n",
      "2021-11-08 04:52:11.267708: validation loss: -0.8097\n",
      "2021-11-08 04:52:11.273175: Average global foreground Dice: [0.8396]\n",
      "2021-11-08 04:52:11.278208: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 04:52:11.786952: lr: 0.009338\n",
      "2021-11-08 04:52:11.820426: saving checkpoint...\n",
      "2021-11-08 04:52:12.819948: done, saving took 1.03 seconds\n",
      "2021-11-08 04:52:12.842824: This epoch took 316.327568 s\n",
      "\n",
      "2021-11-08 04:52:12.847101: \n",
      "epoch:  11\n",
      "2021-11-08 04:57:01.990612: train loss : -0.8023\n",
      "2021-11-08 04:57:21.668910: validation loss: -0.8203\n",
      "2021-11-08 04:57:21.673935: Average global foreground Dice: [0.8473]\n",
      "2021-11-08 04:57:21.678643: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 04:57:22.166670: lr: 0.009277\n",
      "2021-11-08 04:57:22.199620: saving checkpoint...\n",
      "2021-11-08 04:57:23.290885: done, saving took 1.12 seconds\n",
      "2021-11-08 04:57:23.316440: This epoch took 310.465045 s\n",
      "\n",
      "2021-11-08 04:57:23.321074: \n",
      "epoch:  12\n",
      "2021-11-08 05:02:21.795989: train loss : -0.8063\n",
      "2021-11-08 05:02:43.215055: validation loss: -0.8312\n",
      "2021-11-08 05:02:43.220386: Average global foreground Dice: [0.8526]\n",
      "2021-11-08 05:02:43.225805: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 05:02:44.019063: lr: 0.009217\n",
      "2021-11-08 05:02:44.078532: saving checkpoint...\n",
      "2021-11-08 05:02:45.071693: done, saving took 1.05 seconds\n",
      "2021-11-08 05:02:45.102072: This epoch took 321.776450 s\n",
      "\n",
      "2021-11-08 05:02:45.106362: \n",
      "epoch:  13\n",
      "2021-11-08 05:07:43.073631: train loss : -0.8015\n",
      "2021-11-08 05:08:04.913058: validation loss: -0.8273\n",
      "2021-11-08 05:08:04.924255: Average global foreground Dice: [0.8483]\n",
      "2021-11-08 05:08:04.928416: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 05:08:06.191731: lr: 0.009156\n",
      "2021-11-08 05:08:06.269411: saving checkpoint...\n",
      "2021-11-08 05:08:07.324697: done, saving took 1.13 seconds\n",
      "2021-11-08 05:08:07.352991: This epoch took 322.241857 s\n",
      "\n",
      "2021-11-08 05:08:07.357337: \n",
      "epoch:  14\n",
      "2021-11-08 05:13:01.689913: train loss : -0.8130\n",
      "2021-11-08 05:13:22.077055: validation loss: -0.8316\n",
      "2021-11-08 05:13:22.082730: Average global foreground Dice: [0.8523]\n",
      "2021-11-08 05:13:22.087459: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 05:13:22.588671: lr: 0.009095\n",
      "2021-11-08 05:13:22.663870: saving checkpoint...\n",
      "2021-11-08 05:13:23.736247: done, saving took 1.14 seconds\n",
      "2021-11-08 05:13:23.765730: This epoch took 316.403657 s\n",
      "\n",
      "2021-11-08 05:13:23.770159: \n",
      "epoch:  15\n",
      "2021-11-08 05:18:21.826009: train loss : -0.8084\n",
      "2021-11-08 05:18:43.687119: validation loss: -0.8258\n",
      "2021-11-08 05:18:43.706791: Average global foreground Dice: [0.8543]\n",
      "2021-11-08 05:18:43.711227: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 05:18:45.074754: lr: 0.009035\n",
      "2021-11-08 05:18:45.109018: saving checkpoint...\n",
      "2021-11-08 05:18:46.241430: done, saving took 1.16 seconds\n",
      "2021-11-08 05:18:46.265185: This epoch took 322.490671 s\n",
      "\n",
      "2021-11-08 05:18:46.269825: \n",
      "epoch:  16\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-08 05:23:37.143314: train loss : -0.8171\n",
      "2021-11-08 05:23:55.109821: validation loss: -0.8337\n",
      "2021-11-08 05:23:55.115296: Average global foreground Dice: [0.8535]\n",
      "2021-11-08 05:23:55.119120: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 05:23:55.651545: lr: 0.008974\n",
      "2021-11-08 05:23:55.684572: saving checkpoint...\n",
      "2021-11-08 05:23:56.627984: done, saving took 0.97 seconds\n",
      "2021-11-08 05:23:56.651018: This epoch took 310.376268 s\n",
      "\n",
      "2021-11-08 05:23:56.656382: \n",
      "epoch:  17\n",
      "2021-11-08 05:28:52.185604: train loss : -0.8110\n",
      "2021-11-08 05:29:12.665181: validation loss: -0.8312\n",
      "2021-11-08 05:29:12.669980: Average global foreground Dice: [0.852]\n",
      "2021-11-08 05:29:12.674936: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 05:29:13.162285: lr: 0.008913\n",
      "2021-11-08 05:29:13.195976: saving checkpoint...\n",
      "2021-11-08 05:29:14.193330: done, saving took 1.03 seconds\n",
      "2021-11-08 05:29:14.217881: This epoch took 317.556687 s\n",
      "\n",
      "2021-11-08 05:29:14.222865: \n",
      "epoch:  18\n",
      "2021-11-08 05:34:08.974375: train loss : -0.8183\n",
      "2021-11-08 05:34:30.831319: validation loss: -0.8379\n",
      "2021-11-08 05:34:30.837266: Average global foreground Dice: [0.8593]\n",
      "2021-11-08 05:34:30.842198: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 05:34:31.698512: lr: 0.008852\n",
      "2021-11-08 05:34:31.761705: saving checkpoint...\n",
      "2021-11-08 05:34:32.790129: done, saving took 1.09 seconds\n",
      "2021-11-08 05:34:32.820688: This epoch took 318.592933 s\n",
      "\n",
      "2021-11-08 05:34:32.825663: \n",
      "epoch:  19\n",
      "2021-11-08 05:39:38.486766: train loss : -0.8200\n",
      "2021-11-08 05:40:00.989879: validation loss: -0.8273\n",
      "2021-11-08 05:40:01.005009: Average global foreground Dice: [0.8415]\n",
      "2021-11-08 05:40:01.009629: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 05:40:03.596946: lr: 0.008792\n",
      "2021-11-08 05:40:03.862212: saving checkpoint...\n",
      "2021-11-08 05:40:05.616050: done, saving took 2.01 seconds\n",
      "2021-11-08 05:40:05.642951: This epoch took 332.813034 s\n",
      "\n",
      "2021-11-08 05:40:05.647684: \n",
      "epoch:  20\n",
      "2021-11-08 05:45:05.184569: train loss : -0.8214\n",
      "2021-11-08 05:45:27.369525: validation loss: -0.8355\n",
      "2021-11-08 05:45:27.388276: Average global foreground Dice: [0.8544]\n",
      "2021-11-08 05:45:27.393189: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 05:45:29.679478: lr: 0.008731\n",
      "2021-11-08 05:45:29.718352: saving checkpoint...\n",
      "2021-11-08 05:45:31.148338: done, saving took 1.46 seconds\n",
      "2021-11-08 05:45:31.171755: This epoch took 325.519719 s\n",
      "\n",
      "2021-11-08 05:45:31.176943: \n",
      "epoch:  21\n",
      "2021-11-08 05:50:30.069232: train loss : -0.8279\n",
      "2021-11-08 05:50:51.195521: validation loss: -0.8393\n",
      "2021-11-08 05:50:51.211936: Average global foreground Dice: [0.858]\n",
      "2021-11-08 05:50:51.216786: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 05:50:53.117015: lr: 0.00867\n",
      "2021-11-08 05:50:53.184033: saving checkpoint...\n",
      "2021-11-08 05:50:54.332384: done, saving took 1.21 seconds\n",
      "2021-11-08 05:50:54.357755: This epoch took 323.176223 s\n",
      "\n",
      "2021-11-08 05:50:54.361596: \n",
      "epoch:  22\n",
      "2021-11-08 05:55:49.766037: train loss : -0.8294\n",
      "2021-11-08 05:56:09.969265: validation loss: -0.8408\n",
      "2021-11-08 05:56:09.974411: Average global foreground Dice: [0.8598]\n",
      "2021-11-08 05:56:09.983361: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 05:56:10.498841: lr: 0.008609\n",
      "2021-11-08 05:56:10.532336: saving checkpoint...\n",
      "2021-11-08 05:56:11.457120: done, saving took 0.95 seconds\n",
      "2021-11-08 05:56:11.483350: This epoch took 317.116984 s\n",
      "\n",
      "2021-11-08 05:56:11.488227: \n",
      "epoch:  23\n",
      "2021-11-08 06:01:08.969496: train loss : -0.8258\n",
      "2021-11-08 06:01:29.108267: validation loss: -0.8303\n",
      "2021-11-08 06:01:29.113606: Average global foreground Dice: [0.8468]\n",
      "2021-11-08 06:01:29.118162: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 06:01:29.610813: lr: 0.008548\n",
      "2021-11-08 06:01:29.644448: saving checkpoint...\n",
      "2021-11-08 06:01:30.677134: done, saving took 1.06 seconds\n",
      "2021-11-08 06:01:30.699267: This epoch took 319.206321 s\n",
      "\n",
      "2021-11-08 06:01:30.703753: \n",
      "epoch:  24\n",
      "2021-11-08 06:06:30.089450: train loss : -0.8248\n",
      "2021-11-08 06:06:51.660936: validation loss: -0.8423\n",
      "2021-11-08 06:06:51.680403: Average global foreground Dice: [0.8595]\n",
      "2021-11-08 06:06:51.685461: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 06:06:53.479328: lr: 0.008487\n",
      "2021-11-08 06:06:53.525699: saving checkpoint...\n",
      "2021-11-08 06:06:55.276559: done, saving took 1.79 seconds\n",
      "2021-11-08 06:06:55.301382: This epoch took 324.593366 s\n",
      "\n",
      "2021-11-08 06:06:55.306028: \n",
      "epoch:  25\n",
      "2021-11-08 06:11:55.580318: train loss : -0.8256\n",
      "2021-11-08 06:12:16.961795: validation loss: -0.8259\n",
      "2021-11-08 06:12:16.968253: Average global foreground Dice: [0.8526]\n",
      "2021-11-08 06:12:16.973432: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 06:12:17.514075: lr: 0.008426\n",
      "2021-11-08 06:12:17.548005: saving checkpoint...\n",
      "2021-11-08 06:12:18.487743: done, saving took 0.97 seconds\n",
      "2021-11-08 06:12:18.510051: This epoch took 323.200294 s\n",
      "\n",
      "2021-11-08 06:12:18.515722: \n",
      "epoch:  26\n",
      "2021-11-08 06:17:15.769062: train loss : -0.8226\n",
      "2021-11-08 06:17:37.986622: validation loss: -0.8211\n",
      "2021-11-08 06:17:37.992395: Average global foreground Dice: [0.8441]\n",
      "2021-11-08 06:17:37.996792: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 06:17:39.964455: lr: 0.008364\n",
      "2021-11-08 06:17:40.020344: saving checkpoint...\n",
      "2021-11-08 06:17:41.745045: done, saving took 1.78 seconds\n",
      "2021-11-08 06:17:41.789163: This epoch took 323.268499 s\n",
      "\n",
      "2021-11-08 06:17:41.794325: \n",
      "epoch:  27\n",
      "2021-11-08 06:22:35.877016: train loss : -0.8335\n",
      "2021-11-08 06:22:55.328982: validation loss: -0.8461\n",
      "2021-11-08 06:22:55.333546: Average global foreground Dice: [0.8699]\n",
      "2021-11-08 06:22:55.337810: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 06:22:55.836336: lr: 0.008303\n",
      "2021-11-08 06:22:55.898973: saving checkpoint...\n",
      "2021-11-08 06:22:56.891120: done, saving took 1.05 seconds\n",
      "2021-11-08 06:22:56.914075: This epoch took 315.105059 s\n",
      "\n",
      "2021-11-08 06:22:56.919071: \n",
      "epoch:  28\n",
      "2021-11-08 06:27:55.597851: train loss : -0.8293\n",
      "2021-11-08 06:28:18.515945: validation loss: -0.8476\n",
      "2021-11-08 06:28:18.560138: Average global foreground Dice: [0.8672]\n",
      "2021-11-08 06:28:18.564689: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 06:28:19.891065: lr: 0.008242\n",
      "2021-11-08 06:28:19.966323: saving checkpoint...\n",
      "2021-11-08 06:28:22.259740: done, saving took 2.36 seconds\n",
      "2021-11-08 06:28:22.286559: This epoch took 325.362879 s\n",
      "\n",
      "2021-11-08 06:28:22.290871: \n",
      "epoch:  29\n",
      "2021-11-08 06:33:22.592259: train loss : -0.8355\n",
      "2021-11-08 06:33:43.978056: validation loss: -0.8396\n",
      "2021-11-08 06:33:44.004363: Average global foreground Dice: [0.8555]\n",
      "2021-11-08 06:33:44.008702: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 06:33:45.300963: lr: 0.008181\n",
      "2021-11-08 06:33:45.342609: saving checkpoint...\n",
      "2021-11-08 06:33:46.483940: done, saving took 1.17 seconds\n",
      "2021-11-08 06:33:46.509571: This epoch took 324.213912 s\n",
      "\n",
      "2021-11-08 06:33:46.513638: \n",
      "epoch:  30\n",
      "2021-11-08 06:38:47.893338: train loss : -0.8314\n",
      "2021-11-08 06:39:09.410528: validation loss: -0.8354\n",
      "2021-11-08 06:39:09.430458: Average global foreground Dice: [0.8561]\n",
      "2021-11-08 06:39:09.459659: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 06:39:10.341967: lr: 0.008119\n",
      "2021-11-08 06:39:10.375931: saving checkpoint...\n",
      "2021-11-08 06:39:11.316983: done, saving took 0.97 seconds\n",
      "2021-11-08 06:39:11.339477: This epoch took 324.821022 s\n",
      "\n",
      "2021-11-08 06:39:11.344373: \n",
      "epoch:  31\n",
      "2021-11-08 06:44:13.822327: train loss : -0.8308\n",
      "2021-11-08 06:44:36.180914: validation loss: -0.8384\n",
      "2021-11-08 06:44:36.192679: Average global foreground Dice: [0.8625]\n",
      "2021-11-08 06:44:36.198746: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 06:44:37.123620: lr: 0.008058\n",
      "2021-11-08 06:44:37.161467: saving checkpoint...\n",
      "2021-11-08 06:44:38.221883: done, saving took 1.09 seconds\n",
      "2021-11-08 06:44:38.248137: This epoch took 326.899210 s\n",
      "\n",
      "2021-11-08 06:44:38.252726: \n",
      "epoch:  32\n",
      "2021-11-08 06:49:37.585367: train loss : -0.8292\n",
      "2021-11-08 06:49:58.965020: validation loss: -0.8358\n",
      "2021-11-08 06:49:58.970677: Average global foreground Dice: [0.85]\n",
      "2021-11-08 06:49:58.975668: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 06:49:59.476997: lr: 0.007996\n",
      "2021-11-08 06:49:59.510395: saving checkpoint...\n",
      "2021-11-08 06:50:00.418511: done, saving took 0.94 seconds\n",
      "2021-11-08 06:50:00.442015: This epoch took 322.184205 s\n",
      "\n",
      "2021-11-08 06:50:00.446113: \n",
      "epoch:  33\n",
      "2021-11-08 06:55:00.485624: train loss : -0.8305\n",
      "2021-11-08 06:55:20.869445: validation loss: -0.8385\n",
      "2021-11-08 06:55:20.874409: Average global foreground Dice: [0.856]\n",
      "2021-11-08 06:55:20.878894: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 06:55:21.392037: lr: 0.007935\n",
      "2021-11-08 06:55:21.425465: saving checkpoint...\n",
      "2021-11-08 06:55:22.385035: done, saving took 0.99 seconds\n",
      "2021-11-08 06:55:22.408520: This epoch took 321.958355 s\n",
      "\n",
      "2021-11-08 06:55:22.412481: \n",
      "epoch:  34\n",
      "2021-11-08 07:00:18.866630: train loss : -0.8376\n",
      "2021-11-08 07:00:40.266685: validation loss: -0.8372\n",
      "2021-11-08 07:00:40.272314: Average global foreground Dice: [0.8523]\n",
      "2021-11-08 07:00:40.279440: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 07:00:41.041402: lr: 0.007873\n",
      "2021-11-08 07:00:41.075017: saving checkpoint...\n",
      "2021-11-08 07:00:41.958895: done, saving took 0.91 seconds\n",
      "2021-11-08 07:00:41.983614: This epoch took 319.566377 s\n",
      "\n",
      "2021-11-08 07:00:41.988384: \n",
      "epoch:  35\n",
      "2021-11-08 07:05:34.273207: train loss : -0.8392\n",
      "2021-11-08 07:05:55.145630: validation loss: -0.8325\n",
      "2021-11-08 07:05:55.150990: Average global foreground Dice: [0.8526]\n",
      "2021-11-08 07:05:55.155814: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 07:05:55.704945: lr: 0.007811\n",
      "2021-11-08 07:05:55.738147: saving checkpoint...\n",
      "2021-11-08 07:05:56.642760: done, saving took 0.93 seconds\n",
      "2021-11-08 07:05:56.664958: This epoch took 314.671876 s\n",
      "\n",
      "2021-11-08 07:05:56.669776: \n",
      "epoch:  36\n",
      "2021-11-08 07:10:55.017460: train loss : -0.8379\n",
      "2021-11-08 07:11:16.420182: validation loss: -0.8469\n",
      "2021-11-08 07:11:16.460119: Average global foreground Dice: [0.8646]\n",
      "2021-11-08 07:11:16.465240: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 07:11:18.171005: lr: 0.00775\n",
      "2021-11-08 07:11:18.205293: saving checkpoint...\n",
      "2021-11-08 07:11:19.156519: done, saving took 0.98 seconds\n",
      "2021-11-08 07:11:19.182409: This epoch took 322.508170 s\n",
      "\n",
      "2021-11-08 07:11:19.187640: \n",
      "epoch:  37\n",
      "2021-11-08 07:16:14.572814: train loss : -0.8336\n",
      "2021-11-08 07:16:33.699198: validation loss: -0.8390\n",
      "2021-11-08 07:16:33.704450: Average global foreground Dice: [0.8567]\n",
      "2021-11-08 07:16:33.709460: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 07:16:34.204435: lr: 0.007688\n",
      "2021-11-08 07:16:34.237695: saving checkpoint...\n",
      "2021-11-08 07:16:35.175262: done, saving took 0.97 seconds\n",
      "2021-11-08 07:16:35.197382: This epoch took 316.005317 s\n",
      "\n",
      "2021-11-08 07:16:35.202056: \n",
      "epoch:  38\n",
      "2021-11-08 07:21:36.593032: train loss : -0.8367\n",
      "2021-11-08 07:21:57.971670: validation loss: -0.8432\n",
      "2021-11-08 07:21:57.984510: Average global foreground Dice: [0.8578]\n",
      "2021-11-08 07:21:57.989331: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 07:21:59.415864: lr: 0.007626\n",
      "2021-11-08 07:21:59.461834: saving checkpoint...\n",
      "2021-11-08 07:22:00.598798: done, saving took 1.18 seconds\n",
      "2021-11-08 07:22:00.624727: This epoch took 325.418301 s\n",
      "\n",
      "2021-11-08 07:22:00.629605: \n",
      "epoch:  39\n",
      "2021-11-08 07:27:00.791268: train loss : -0.8407\n",
      "2021-11-08 07:27:20.646181: validation loss: -0.8430\n",
      "2021-11-08 07:27:20.652040: Average global foreground Dice: [0.8607]\n",
      "2021-11-08 07:27:20.656899: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 07:27:21.152660: lr: 0.007564\n",
      "2021-11-08 07:27:21.185591: saving checkpoint...\n",
      "2021-11-08 07:27:22.186134: done, saving took 1.03 seconds\n",
      "2021-11-08 07:27:22.209301: This epoch took 321.575702 s\n",
      "\n",
      "2021-11-08 07:27:22.213945: \n",
      "epoch:  40\n",
      "2021-11-08 07:32:21.117909: train loss : -0.8421\n",
      "2021-11-08 07:32:41.961367: validation loss: -0.8380\n",
      "2021-11-08 07:32:41.967217: Average global foreground Dice: [0.8577]\n",
      "2021-11-08 07:32:41.972148: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 07:32:42.697139: lr: 0.007502\n",
      "2021-11-08 07:32:42.730993: saving checkpoint...\n",
      "2021-11-08 07:32:43.647140: done, saving took 0.95 seconds\n",
      "2021-11-08 07:32:43.669165: This epoch took 321.450618 s\n",
      "\n",
      "2021-11-08 07:32:43.673728: \n",
      "epoch:  41\n",
      "2021-11-08 07:37:36.138310: train loss : -0.8431\n",
      "2021-11-08 07:37:54.180863: validation loss: -0.8460\n",
      "2021-11-08 07:37:54.186110: Average global foreground Dice: [0.8591]\n",
      "2021-11-08 07:37:54.189768: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 07:37:54.687937: lr: 0.00744\n",
      "2021-11-08 07:37:54.720837: saving checkpoint...\n",
      "2021-11-08 07:37:55.643889: done, saving took 0.95 seconds\n",
      "2021-11-08 07:37:55.666625: This epoch took 311.987963 s\n",
      "\n",
      "2021-11-08 07:37:55.671453: \n",
      "epoch:  42\n",
      "2021-11-08 07:42:54.673648: train loss : -0.8441\n",
      "2021-11-08 07:43:14.776379: validation loss: -0.8450\n",
      "2021-11-08 07:43:14.781425: Average global foreground Dice: [0.8624]\n",
      "2021-11-08 07:43:14.786047: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 07:43:15.328876: lr: 0.007378\n",
      "2021-11-08 07:43:15.363013: saving checkpoint...\n",
      "2021-11-08 07:43:16.310310: done, saving took 0.98 seconds\n",
      "2021-11-08 07:43:16.333631: This epoch took 320.657753 s\n",
      "\n",
      "2021-11-08 07:43:16.338326: \n",
      "epoch:  43\n",
      "2021-11-08 07:48:14.816741: train loss : -0.8352\n",
      "2021-11-08 07:48:36.121355: validation loss: -0.8405\n",
      "2021-11-08 07:48:36.164304: Average global foreground Dice: [0.8601]\n",
      "2021-11-08 07:48:36.169318: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 07:48:37.211466: lr: 0.007316\n",
      "2021-11-08 07:48:37.245951: saving checkpoint...\n",
      "2021-11-08 07:48:38.219548: done, saving took 1.00 seconds\n",
      "2021-11-08 07:48:38.246470: This epoch took 321.902711 s\n",
      "\n",
      "2021-11-08 07:48:38.251398: \n",
      "epoch:  44\n",
      "2021-11-08 07:53:35.885353: train loss : -0.8395\n",
      "2021-11-08 07:53:57.686955: validation loss: -0.8342\n",
      "2021-11-08 07:53:57.705081: Average global foreground Dice: [0.851]\n",
      "2021-11-08 07:53:57.709385: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 07:53:58.836416: lr: 0.007254\n",
      "2021-11-08 07:53:58.841232: This epoch took 320.585299 s\n",
      "\n",
      "2021-11-08 07:53:58.845600: \n",
      "epoch:  45\n",
      "2021-11-08 07:58:57.972773: train loss : -0.8399\n",
      "2021-11-08 07:59:17.394267: validation loss: -0.8399\n",
      "2021-11-08 07:59:17.398744: Average global foreground Dice: [0.8557]\n",
      "2021-11-08 07:59:17.402237: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 07:59:17.885897: lr: 0.007192\n",
      "2021-11-08 07:59:17.890371: This epoch took 319.039774 s\n",
      "\n",
      "2021-11-08 07:59:17.894925: \n",
      "epoch:  46\n",
      "2021-11-08 08:04:10.560538: train loss : -0.8456\n",
      "2021-11-08 08:04:29.002746: validation loss: -0.8470\n",
      "2021-11-08 08:04:29.008426: Average global foreground Dice: [0.8644]\n",
      "2021-11-08 08:04:29.013468: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 08:04:29.504520: lr: 0.00713\n",
      "2021-11-08 08:04:29.545682: saving checkpoint...\n",
      "2021-11-08 08:04:30.609271: done, saving took 1.10 seconds\n",
      "2021-11-08 08:04:30.638544: This epoch took 312.739169 s\n",
      "\n",
      "2021-11-08 08:04:30.642792: \n",
      "epoch:  47\n",
      "2021-11-08 08:09:24.943706: train loss : -0.8450\n",
      "2021-11-08 08:09:43.085671: validation loss: -0.8375\n",
      "2021-11-08 08:09:43.091599: Average global foreground Dice: [0.8588]\n",
      "2021-11-08 08:09:43.096344: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 08:09:43.623310: lr: 0.007067\n",
      "2021-11-08 08:09:43.687550: saving checkpoint...\n",
      "2021-11-08 08:09:44.615858: done, saving took 0.99 seconds\n",
      "2021-11-08 08:09:44.641624: This epoch took 313.994484 s\n",
      "\n",
      "2021-11-08 08:09:44.646661: \n",
      "epoch:  48\n",
      "2021-11-08 08:14:38.073847: train loss : -0.8468\n",
      "2021-11-08 08:14:57.376909: validation loss: -0.8463\n",
      "2021-11-08 08:14:57.382501: Average global foreground Dice: [0.8627]\n",
      "2021-11-08 08:14:57.387047: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 08:14:57.889216: lr: 0.007005\n",
      "2021-11-08 08:14:57.955315: saving checkpoint...\n",
      "2021-11-08 08:14:58.983518: done, saving took 1.09 seconds\n",
      "2021-11-08 08:14:59.005832: This epoch took 314.354573 s\n",
      "\n",
      "2021-11-08 08:14:59.010557: \n",
      "epoch:  49\n",
      "2021-11-08 08:19:51.472818: train loss : -0.8458\n",
      "2021-11-08 08:20:10.745459: validation loss: -0.8452\n",
      "2021-11-08 08:20:10.750927: Average global foreground Dice: [0.8601]\n",
      "2021-11-08 08:20:10.755655: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 08:20:11.244781: lr: 0.006943\n",
      "2021-11-08 08:20:11.250727: saving scheduled checkpoint file...\n",
      "2021-11-08 08:20:11.283831: saving checkpoint...\n",
      "2021-11-08 08:20:12.075943: done, saving took 0.82 seconds\n",
      "2021-11-08 08:20:12.093226: done\n",
      "2021-11-08 08:20:12.125979: saving checkpoint...\n",
      "2021-11-08 08:20:13.055528: done, saving took 0.96 seconds\n",
      "2021-11-08 08:20:13.077996: This epoch took 314.061847 s\n",
      "\n",
      "2021-11-08 08:20:13.082644: \n",
      "epoch:  50\n",
      "2021-11-08 08:25:08.079409: train loss : -0.8513\n",
      "2021-11-08 08:25:28.924147: validation loss: -0.8505\n",
      "2021-11-08 08:25:28.930395: Average global foreground Dice: [0.8658]\n",
      "2021-11-08 08:25:28.959824: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 08:25:30.151361: lr: 0.00688\n",
      "2021-11-08 08:25:30.185611: saving checkpoint...\n",
      "2021-11-08 08:25:31.292470: done, saving took 1.14 seconds\n",
      "2021-11-08 08:25:31.314869: This epoch took 318.227544 s\n",
      "\n",
      "2021-11-08 08:25:31.319707: \n",
      "epoch:  51\n",
      "2021-11-08 08:30:28.259378: train loss : -0.8459\n",
      "2021-11-08 08:30:49.997247: validation loss: -0.8443\n",
      "2021-11-08 08:30:50.002468: Average global foreground Dice: [0.8613]\n",
      "2021-11-08 08:30:50.009030: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 08:30:52.286199: lr: 0.006817\n",
      "2021-11-08 08:30:52.374152: saving checkpoint...\n",
      "2021-11-08 08:30:53.747541: done, saving took 1.46 seconds\n",
      "2021-11-08 08:30:53.774402: This epoch took 322.449532 s\n",
      "\n",
      "2021-11-08 08:30:53.779266: \n",
      "epoch:  52\n",
      "2021-11-08 08:35:54.864658: train loss : -0.8395\n",
      "2021-11-08 08:36:16.859365: validation loss: -0.8386\n",
      "2021-11-08 08:36:16.865036: Average global foreground Dice: [0.8606]\n",
      "2021-11-08 08:36:16.869888: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 08:36:18.879994: lr: 0.006755\n",
      "2021-11-08 08:36:18.987173: saving checkpoint...\n",
      "2021-11-08 08:36:21.022774: done, saving took 2.14 seconds\n",
      "2021-11-08 08:36:21.069819: This epoch took 327.285741 s\n",
      "\n",
      "2021-11-08 08:36:21.074699: \n",
      "epoch:  53\n",
      "2021-11-08 08:41:21.678256: train loss : -0.8443\n",
      "2021-11-08 08:41:43.409863: validation loss: -0.8309\n",
      "2021-11-08 08:41:43.415436: Average global foreground Dice: [0.852]\n",
      "2021-11-08 08:41:43.420473: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 08:41:44.456522: lr: 0.006692\n",
      "2021-11-08 08:41:44.463560: This epoch took 323.383863 s\n",
      "\n",
      "2021-11-08 08:41:44.468171: \n",
      "epoch:  54\n",
      "2021-11-08 08:46:41.573709: train loss : -0.8393\n",
      "2021-11-08 08:47:00.737134: validation loss: -0.8435\n",
      "2021-11-08 08:47:00.741907: Average global foreground Dice: [0.8562]\n",
      "2021-11-08 08:47:00.745712: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 08:47:01.234297: lr: 0.006629\n",
      "2021-11-08 08:47:01.238522: This epoch took 316.766165 s\n",
      "\n",
      "2021-11-08 08:47:01.243758: \n",
      "epoch:  55\n",
      "2021-11-08 08:52:02.025908: train loss : -0.8419\n",
      "2021-11-08 08:52:24.772671: validation loss: -0.8504\n",
      "2021-11-08 08:52:24.778556: Average global foreground Dice: [0.8623]\n",
      "2021-11-08 08:52:24.783462: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 08:52:26.718884: lr: 0.006566\n",
      "2021-11-08 08:52:26.725498: This epoch took 325.477864 s\n",
      "\n",
      "2021-11-08 08:52:26.730159: \n",
      "epoch:  56\n",
      "2021-11-08 08:57:26.879492: train loss : -0.8480\n",
      "2021-11-08 08:57:48.968856: validation loss: -0.8524\n",
      "2021-11-08 08:57:48.988882: Average global foreground Dice: [0.8684]\n",
      "2021-11-08 08:57:48.996027: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 08:57:50.692684: lr: 0.006504\n",
      "2021-11-08 08:57:50.773042: saving checkpoint...\n",
      "2021-11-08 08:57:51.968680: done, saving took 1.27 seconds\n",
      "2021-11-08 08:57:51.995436: This epoch took 325.235876 s\n",
      "\n",
      "2021-11-08 08:57:52.001022: \n",
      "epoch:  57\n",
      "2021-11-08 09:02:47.035698: train loss : -0.8509\n",
      "2021-11-08 09:03:08.287953: validation loss: -0.8417\n",
      "2021-11-08 09:03:08.293534: Average global foreground Dice: [0.8565]\n",
      "2021-11-08 09:03:08.298291: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 09:03:08.886813: lr: 0.006441\n",
      "2021-11-08 09:03:08.891896: This epoch took 316.886886 s\n",
      "\n",
      "2021-11-08 09:03:08.896823: \n",
      "epoch:  58\n",
      "2021-11-08 09:08:01.973429: train loss : -0.8450\n",
      "2021-11-08 09:08:22.992308: validation loss: -0.8401\n",
      "2021-11-08 09:08:23.002538: Average global foreground Dice: [0.8571]\n",
      "2021-11-08 09:08:23.007459: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 09:08:23.809463: lr: 0.006378\n",
      "2021-11-08 09:08:23.814420: This epoch took 314.912817 s\n",
      "\n",
      "2021-11-08 09:08:23.819273: \n",
      "epoch:  59\n",
      "2021-11-08 09:13:17.185760: train loss : -0.8453\n",
      "2021-11-08 09:13:38.474146: validation loss: -0.8476\n",
      "2021-11-08 09:13:38.485131: Average global foreground Dice: [0.8641]\n",
      "2021-11-08 09:13:38.492001: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 09:13:39.491590: lr: 0.006314\n",
      "2021-11-08 09:13:39.531633: saving checkpoint...\n",
      "2021-11-08 09:13:40.627139: done, saving took 1.13 seconds\n",
      "2021-11-08 09:13:40.651482: This epoch took 316.827781 s\n",
      "\n",
      "2021-11-08 09:13:40.656611: \n",
      "epoch:  60\n",
      "2021-11-08 09:18:37.185153: train loss : -0.8505\n",
      "2021-11-08 09:18:57.776916: validation loss: -0.8507\n",
      "2021-11-08 09:18:57.783038: Average global foreground Dice: [0.8685]\n",
      "2021-11-08 09:18:57.787983: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 09:18:58.434735: lr: 0.006251\n",
      "2021-11-08 09:18:58.468755: saving checkpoint...\n",
      "2021-11-08 09:18:59.397102: done, saving took 0.96 seconds\n",
      "2021-11-08 09:18:59.422882: This epoch took 318.761824 s\n",
      "\n",
      "2021-11-08 09:18:59.427557: \n",
      "epoch:  61\n",
      "2021-11-08 09:23:55.343765: train loss : -0.8447\n",
      "2021-11-08 09:24:14.018163: validation loss: -0.8420\n",
      "2021-11-08 09:24:14.023371: Average global foreground Dice: [0.856]\n",
      "2021-11-08 09:24:14.027995: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 09:24:14.559568: lr: 0.006188\n",
      "2021-11-08 09:24:14.563971: This epoch took 315.131180 s\n",
      "\n",
      "2021-11-08 09:24:14.568825: \n",
      "epoch:  62\n",
      "2021-11-08 09:29:12.505561: train loss : -0.8510\n",
      "2021-11-08 09:29:33.429019: validation loss: -0.8482\n",
      "2021-11-08 09:29:33.434282: Average global foreground Dice: [0.865]\n",
      "2021-11-08 09:29:33.438962: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 09:29:34.212925: lr: 0.006125\n",
      "2021-11-08 09:29:34.254053: saving checkpoint...\n",
      "2021-11-08 09:29:35.352036: done, saving took 1.13 seconds\n",
      "2021-11-08 09:29:35.376547: This epoch took 320.802530 s\n",
      "\n",
      "2021-11-08 09:29:35.381921: \n",
      "epoch:  63\n",
      "2021-11-08 09:34:30.780655: train loss : -0.8501\n",
      "2021-11-08 09:34:51.764013: validation loss: -0.8449\n",
      "2021-11-08 09:34:51.780653: Average global foreground Dice: [0.8598]\n",
      "2021-11-08 09:34:51.785536: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 09:34:53.020580: lr: 0.006061\n",
      "2021-11-08 09:34:53.025141: This epoch took 317.638965 s\n",
      "\n",
      "2021-11-08 09:34:53.029852: \n",
      "epoch:  64\n",
      "2021-11-08 09:39:48.525600: train loss : -0.8507\n",
      "2021-11-08 09:40:10.792680: validation loss: -0.8474\n",
      "2021-11-08 09:40:10.801704: Average global foreground Dice: [0.8617]\n",
      "2021-11-08 09:40:10.806615: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 09:40:12.412606: lr: 0.005998\n",
      "2021-11-08 09:40:12.491577: saving checkpoint...\n",
      "2021-11-08 09:40:13.706156: done, saving took 1.29 seconds\n",
      "2021-11-08 09:40:13.732108: This epoch took 320.697986 s\n",
      "\n",
      "2021-11-08 09:40:13.736965: \n",
      "epoch:  65\n",
      "2021-11-08 09:45:14.213072: train loss : -0.8526\n",
      "2021-11-08 09:45:35.236379: validation loss: -0.8443\n",
      "2021-11-08 09:45:35.241145: Average global foreground Dice: [0.8639]\n",
      "2021-11-08 09:45:35.245558: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 09:45:35.741682: lr: 0.005934\n",
      "2021-11-08 09:45:35.774957: saving checkpoint...\n",
      "2021-11-08 09:45:36.774407: done, saving took 1.03 seconds\n",
      "2021-11-08 09:45:36.797122: This epoch took 323.055288 s\n",
      "\n",
      "2021-11-08 09:45:36.801876: \n",
      "epoch:  66\n",
      "2021-11-08 09:50:32.995018: train loss : -0.8486\n",
      "2021-11-08 09:50:50.969980: validation loss: -0.8394\n",
      "2021-11-08 09:50:50.974993: Average global foreground Dice: [0.8572]\n",
      "2021-11-08 09:50:50.979395: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 09:50:51.509124: lr: 0.005871\n",
      "2021-11-08 09:50:51.513428: This epoch took 314.706926 s\n",
      "\n",
      "2021-11-08 09:50:51.518114: \n",
      "epoch:  67\n",
      "2021-11-08 09:55:48.363065: train loss : -0.8520\n",
      "2021-11-08 09:56:07.650337: validation loss: -0.8533\n",
      "2021-11-08 09:56:07.655814: Average global foreground Dice: [0.8714]\n",
      "2021-11-08 09:56:07.660069: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 09:56:08.173348: lr: 0.005807\n",
      "2021-11-08 09:56:08.206003: saving checkpoint...\n",
      "2021-11-08 09:56:09.267182: done, saving took 1.09 seconds\n",
      "2021-11-08 09:56:09.294509: This epoch took 317.771878 s\n",
      "\n",
      "2021-11-08 09:56:09.299049: \n",
      "epoch:  68\n",
      "2021-11-08 10:01:00.389457: train loss : -0.8560\n",
      "2021-11-08 10:01:19.616779: validation loss: -0.8497\n",
      "2021-11-08 10:01:19.622774: Average global foreground Dice: [0.8667]\n",
      "2021-11-08 10:01:19.627485: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 10:01:20.128788: lr: 0.005743\n",
      "2021-11-08 10:01:20.186774: saving checkpoint...\n",
      "2021-11-08 10:01:21.131626: done, saving took 1.00 seconds\n",
      "2021-11-08 10:01:21.153516: This epoch took 311.850451 s\n",
      "\n",
      "2021-11-08 10:01:21.158275: \n",
      "epoch:  69\n",
      "2021-11-08 10:06:19.176822: train loss : -0.8540\n",
      "2021-11-08 10:06:40.994238: validation loss: -0.8431\n",
      "2021-11-08 10:06:41.000416: Average global foreground Dice: [0.8649]\n",
      "2021-11-08 10:06:41.005254: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 10:06:42.582990: lr: 0.005679\n",
      "2021-11-08 10:06:42.618165: saving checkpoint...\n",
      "2021-11-08 10:06:43.839656: done, saving took 1.25 seconds\n",
      "2021-11-08 10:06:43.862366: This epoch took 322.699729 s\n",
      "\n",
      "2021-11-08 10:06:43.867306: \n",
      "epoch:  70\n",
      "2021-11-08 10:11:33.727442: train loss : -0.8549\n",
      "2021-11-08 10:11:51.940784: validation loss: -0.8501\n",
      "2021-11-08 10:11:51.946522: Average global foreground Dice: [0.8701]\n",
      "2021-11-08 10:11:51.951187: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 10:11:52.456764: lr: 0.005615\n",
      "2021-11-08 10:11:52.489516: saving checkpoint...\n",
      "2021-11-08 10:11:53.404321: done, saving took 0.94 seconds\n",
      "2021-11-08 10:11:53.427625: This epoch took 309.555808 s\n",
      "\n",
      "2021-11-08 10:11:53.432739: \n",
      "epoch:  71\n",
      "2021-11-08 10:16:49.773200: train loss : -0.8530\n",
      "2021-11-08 10:17:11.832355: validation loss: -0.8410\n",
      "2021-11-08 10:17:11.868354: Average global foreground Dice: [0.8568]\n",
      "2021-11-08 10:17:11.872960: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 10:17:13.730832: lr: 0.005551\n",
      "2021-11-08 10:17:13.759616: This epoch took 320.322133 s\n",
      "\n",
      "2021-11-08 10:17:13.764502: \n",
      "epoch:  72\n",
      "2021-11-08 10:22:11.785543: train loss : -0.8563\n",
      "2021-11-08 10:22:33.692737: validation loss: -0.8472\n",
      "2021-11-08 10:22:33.712035: Average global foreground Dice: [0.8666]\n",
      "2021-11-08 10:22:33.716722: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 10:22:36.000866: lr: 0.005487\n",
      "2021-11-08 10:22:36.006001: This epoch took 322.236726 s\n",
      "\n",
      "2021-11-08 10:22:36.011090: \n",
      "epoch:  73\n",
      "2021-11-08 10:27:36.176930: train loss : -0.8571\n",
      "2021-11-08 10:27:58.006562: validation loss: -0.8381\n",
      "2021-11-08 10:27:58.020722: Average global foreground Dice: [0.852]\n",
      "2021-11-08 10:27:58.025234: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 10:28:00.570725: lr: 0.005423\n",
      "2021-11-08 10:28:00.582730: This epoch took 324.566832 s\n",
      "\n",
      "2021-11-08 10:28:00.587338: \n",
      "epoch:  74\n",
      "2021-11-08 10:33:03.589792: train loss : -0.8568\n",
      "2021-11-08 10:33:25.381265: validation loss: -0.8469\n",
      "2021-11-08 10:33:25.392330: Average global foreground Dice: [0.8661]\n",
      "2021-11-08 10:33:25.397006: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 10:33:27.421773: lr: 0.005359\n",
      "2021-11-08 10:33:27.429208: This epoch took 326.836089 s\n",
      "\n",
      "2021-11-08 10:33:27.434550: \n",
      "epoch:  75\n",
      "2021-11-08 10:38:21.173178: train loss : -0.8573\n",
      "2021-11-08 10:38:42.596577: validation loss: -0.8438\n",
      "2021-11-08 10:38:42.616171: Average global foreground Dice: [0.8615]\n",
      "2021-11-08 10:38:42.620515: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 10:38:44.597309: lr: 0.005295\n",
      "2021-11-08 10:38:44.602386: This epoch took 317.163668 s\n",
      "\n",
      "2021-11-08 10:38:44.606392: \n",
      "epoch:  76\n",
      "2021-11-08 10:43:46.473086: train loss : -0.8563\n",
      "2021-11-08 10:44:07.536432: validation loss: -0.8459\n",
      "2021-11-08 10:44:07.541701: Average global foreground Dice: [0.8624]\n",
      "2021-11-08 10:44:07.559654: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 10:44:08.435762: lr: 0.00523\n",
      "2021-11-08 10:44:08.440398: This epoch took 323.829645 s\n",
      "\n",
      "2021-11-08 10:44:08.444985: \n",
      "epoch:  77\n",
      "2021-11-08 10:48:58.589113: train loss : -0.8605\n",
      "2021-11-08 10:49:18.161713: validation loss: -0.8433\n",
      "2021-11-08 10:49:18.167201: Average global foreground Dice: [0.8638]\n",
      "2021-11-08 10:49:18.170943: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 10:49:18.683623: lr: 0.005166\n",
      "2021-11-08 10:49:18.688267: This epoch took 310.238632 s\n",
      "\n",
      "2021-11-08 10:49:18.692534: \n",
      "epoch:  78\n",
      "2021-11-08 10:54:16.489879: train loss : -0.8558\n",
      "2021-11-08 10:54:36.899112: validation loss: -0.8363\n",
      "2021-11-08 10:54:36.904303: Average global foreground Dice: [0.8528]\n",
      "2021-11-08 10:54:36.909199: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 10:54:37.404696: lr: 0.005101\n",
      "2021-11-08 10:54:37.409359: This epoch took 318.712593 s\n",
      "\n",
      "2021-11-08 10:54:37.413994: \n",
      "epoch:  79\n",
      "2021-11-08 10:59:35.277411: train loss : -0.8592\n",
      "2021-11-08 10:59:56.687057: validation loss: -0.8371\n",
      "2021-11-08 10:59:56.692512: Average global foreground Dice: [0.8552]\n",
      "2021-11-08 10:59:56.697180: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 10:59:58.774707: lr: 0.005036\n",
      "2021-11-08 10:59:58.779641: This epoch took 321.361217 s\n",
      "\n",
      "2021-11-08 10:59:58.783448: \n",
      "epoch:  80\n",
      "2021-11-08 11:04:57.080422: train loss : -0.8610\n",
      "2021-11-08 11:05:18.720543: validation loss: -0.8516\n",
      "2021-11-08 11:05:18.728816: Average global foreground Dice: [0.8663]\n",
      "2021-11-08 11:05:18.733577: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 11:05:19.452473: lr: 0.004971\n",
      "2021-11-08 11:05:19.456994: This epoch took 320.668678 s\n",
      "\n",
      "2021-11-08 11:05:19.461474: \n",
      "epoch:  81\n",
      "2021-11-08 11:10:10.285797: train loss : -0.8568\n",
      "2021-11-08 11:10:32.522900: validation loss: -0.8451\n",
      "2021-11-08 11:10:32.572289: Average global foreground Dice: [0.8623]\n",
      "2021-11-08 11:10:32.576908: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 11:10:35.360064: lr: 0.004907\n",
      "2021-11-08 11:10:35.365300: This epoch took 315.899164 s\n",
      "\n",
      "2021-11-08 11:10:35.369276: \n",
      "epoch:  82\n",
      "2021-11-08 11:15:31.194157: train loss : -0.8587\n",
      "2021-11-08 11:15:51.099663: validation loss: -0.8548\n",
      "2021-11-08 11:15:51.105132: Average global foreground Dice: [0.8673]\n",
      "2021-11-08 11:15:51.109472: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 11:15:51.620893: lr: 0.004842\n",
      "2021-11-08 11:15:51.626055: This epoch took 316.252316 s\n",
      "\n",
      "2021-11-08 11:15:51.630754: \n",
      "epoch:  83\n",
      "2021-11-08 11:20:46.973068: train loss : -0.8619\n",
      "2021-11-08 11:21:07.568775: validation loss: -0.8550\n",
      "2021-11-08 11:21:07.573899: Average global foreground Dice: [0.868]\n",
      "2021-11-08 11:21:07.578628: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 11:21:08.115411: lr: 0.004776\n",
      "2021-11-08 11:21:08.120217: This epoch took 316.485045 s\n",
      "\n",
      "2021-11-08 11:21:08.124845: \n",
      "epoch:  84\n",
      "2021-11-08 11:26:04.973933: train loss : -0.8598\n",
      "2021-11-08 11:26:25.088205: validation loss: -0.8516\n",
      "2021-11-08 11:26:25.093832: Average global foreground Dice: [0.8675]\n",
      "2021-11-08 11:26:25.098689: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 11:26:25.613407: lr: 0.004711\n",
      "2021-11-08 11:26:25.690674: saving checkpoint...\n",
      "2021-11-08 11:26:26.727428: done, saving took 1.10 seconds\n",
      "2021-11-08 11:26:26.748853: This epoch took 318.619148 s\n",
      "\n",
      "2021-11-08 11:26:26.753403: \n",
      "epoch:  85\n",
      "2021-11-08 11:31:26.205740: train loss : -0.8608\n",
      "2021-11-08 11:31:47.494365: validation loss: -0.8505\n",
      "2021-11-08 11:31:47.500128: Average global foreground Dice: [0.8647]\n",
      "2021-11-08 11:31:47.504816: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 11:31:48.001112: lr: 0.004646\n",
      "2021-11-08 11:31:48.063130: saving checkpoint...\n",
      "2021-11-08 11:31:49.094156: done, saving took 1.09 seconds\n",
      "2021-11-08 11:31:49.116416: This epoch took 322.359267 s\n",
      "\n",
      "2021-11-08 11:31:49.120304: \n",
      "epoch:  86\n",
      "2021-11-08 11:36:46.775167: train loss : -0.8618\n",
      "2021-11-08 11:37:07.664671: validation loss: -0.8490\n",
      "2021-11-08 11:37:07.680674: Average global foreground Dice: [0.8603]\n",
      "2021-11-08 11:37:07.684660: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 11:37:08.686535: lr: 0.004581\n",
      "2021-11-08 11:37:08.691010: This epoch took 319.565864 s\n",
      "\n",
      "2021-11-08 11:37:08.695023: \n",
      "epoch:  87\n",
      "2021-11-08 11:42:06.496793: train loss : -0.8629\n",
      "2021-11-08 11:42:27.610201: validation loss: -0.8533\n",
      "2021-11-08 11:42:27.630567: Average global foreground Dice: [0.8665]\n",
      "2021-11-08 11:42:27.659602: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 11:42:29.794103: lr: 0.004515\n",
      "2021-11-08 11:42:29.901965: saving checkpoint...\n",
      "2021-11-08 11:42:31.235129: done, saving took 1.44 seconds\n",
      "2021-11-08 11:42:31.260702: This epoch took 322.561078 s\n",
      "\n",
      "2021-11-08 11:42:31.265958: \n",
      "epoch:  88\n",
      "2021-11-08 11:47:31.208003: train loss : -0.8636\n",
      "2021-11-08 11:47:51.542454: validation loss: -0.8508\n",
      "2021-11-08 11:47:51.547776: Average global foreground Dice: [0.866]\n",
      "2021-11-08 11:47:51.552634: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 11:47:52.085336: lr: 0.00445\n",
      "2021-11-08 11:47:52.119545: saving checkpoint...\n",
      "2021-11-08 11:47:53.067261: done, saving took 0.98 seconds\n",
      "2021-11-08 11:47:53.089548: This epoch took 321.818793 s\n",
      "\n",
      "2021-11-08 11:47:53.093682: \n",
      "epoch:  89\n",
      "2021-11-08 11:52:42.538195: train loss : -0.8644\n",
      "2021-11-08 11:53:00.900154: validation loss: -0.8505\n",
      "2021-11-08 11:53:00.905310: Average global foreground Dice: [0.8637]\n",
      "2021-11-08 11:53:00.909444: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 11:53:01.423959: lr: 0.004384\n",
      "2021-11-08 11:53:01.456804: saving checkpoint...\n",
      "2021-11-08 11:53:02.421573: done, saving took 0.99 seconds\n",
      "2021-11-08 11:53:02.443675: This epoch took 309.344982 s\n",
      "\n",
      "2021-11-08 11:53:02.448753: \n",
      "epoch:  90\n",
      "2021-11-08 11:57:58.972746: train loss : -0.8636\n",
      "2021-11-08 11:58:17.658719: validation loss: -0.8488\n",
      "2021-11-08 11:58:17.664745: Average global foreground Dice: [0.8636]\n",
      "2021-11-08 11:58:17.669405: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 11:58:18.167291: lr: 0.004318\n",
      "2021-11-08 11:58:18.172968: This epoch took 315.719813 s\n",
      "\n",
      "2021-11-08 11:58:18.177550: \n",
      "epoch:  91\n",
      "2021-11-08 12:03:12.664592: train loss : -0.8664\n",
      "2021-11-08 12:03:32.622422: validation loss: -0.8497\n",
      "2021-11-08 12:03:32.628097: Average global foreground Dice: [0.863]\n",
      "2021-11-08 12:03:32.632858: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 12:03:33.153743: lr: 0.004252\n",
      "2021-11-08 12:03:33.158021: This epoch took 314.975898 s\n",
      "\n",
      "2021-11-08 12:03:33.161784: \n",
      "epoch:  92\n",
      "2021-11-08 12:08:32.029579: train loss : -0.8629\n",
      "2021-11-08 12:08:53.009662: validation loss: -0.8585\n",
      "2021-11-08 12:08:53.025319: Average global foreground Dice: [0.8692]\n",
      "2021-11-08 12:08:53.030686: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 12:08:54.617289: lr: 0.004186\n",
      "2021-11-08 12:08:54.767986: saving checkpoint...\n",
      "2021-11-08 12:08:55.911513: done, saving took 1.29 seconds\n",
      "2021-11-08 12:08:55.937327: This epoch took 322.771052 s\n",
      "\n",
      "2021-11-08 12:08:55.942450: \n",
      "epoch:  93\n",
      "2021-11-08 12:13:52.185702: train loss : -0.8622\n",
      "2021-11-08 12:14:14.804499: validation loss: -0.8501\n",
      "2021-11-08 12:14:14.824736: Average global foreground Dice: [0.8642]\n",
      "2021-11-08 12:14:14.829635: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 12:14:17.000981: lr: 0.00412\n",
      "2021-11-08 12:14:17.204218: saving checkpoint...\n",
      "2021-11-08 12:14:19.199634: done, saving took 2.19 seconds\n",
      "2021-11-08 12:14:19.225738: This epoch took 323.278164 s\n",
      "\n",
      "2021-11-08 12:14:19.230544: \n",
      "epoch:  94\n",
      "2021-11-08 12:19:15.837541: train loss : -0.8640\n",
      "2021-11-08 12:19:34.383266: validation loss: -0.8459\n",
      "2021-11-08 12:19:34.389037: Average global foreground Dice: [0.8641]\n",
      "2021-11-08 12:19:34.393843: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 12:19:34.897364: lr: 0.004054\n",
      "2021-11-08 12:19:34.930940: saving checkpoint...\n",
      "2021-11-08 12:19:35.954143: done, saving took 1.05 seconds\n",
      "2021-11-08 12:19:35.977525: This epoch took 316.717870 s\n",
      "\n",
      "2021-11-08 12:19:35.982853: \n",
      "epoch:  95\n",
      "2021-11-08 12:24:30.489194: train loss : -0.8659\n",
      "2021-11-08 12:24:51.826053: validation loss: -0.8545\n",
      "2021-11-08 12:24:51.831159: Average global foreground Dice: [0.8693]\n",
      "2021-11-08 12:24:51.835661: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 12:24:52.359008: lr: 0.003987\n",
      "2021-11-08 12:24:52.392344: saving checkpoint...\n",
      "2021-11-08 12:24:53.295054: done, saving took 0.93 seconds\n",
      "2021-11-08 12:24:53.320236: This epoch took 317.332875 s\n",
      "\n",
      "2021-11-08 12:24:53.325352: \n",
      "epoch:  96\n",
      "2021-11-08 12:29:48.198257: train loss : -0.8634\n",
      "2021-11-08 12:30:08.928033: validation loss: -0.8645\n",
      "2021-11-08 12:30:08.933480: Average global foreground Dice: [0.8759]\n",
      "2021-11-08 12:30:08.940296: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 12:30:09.475535: lr: 0.003921\n",
      "2021-11-08 12:30:09.509066: saving checkpoint...\n",
      "2021-11-08 12:30:10.439026: done, saving took 0.96 seconds\n",
      "2021-11-08 12:30:10.461792: This epoch took 317.131622 s\n",
      "\n",
      "2021-11-08 12:30:10.466034: \n",
      "epoch:  97\n",
      "2021-11-08 12:35:05.671228: train loss : -0.8650\n",
      "2021-11-08 12:35:23.994486: validation loss: -0.8537\n",
      "2021-11-08 12:35:23.999233: Average global foreground Dice: [0.8721]\n",
      "2021-11-08 12:35:24.003431: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 12:35:24.494680: lr: 0.003854\n",
      "2021-11-08 12:35:24.527949: saving checkpoint...\n",
      "2021-11-08 12:35:25.454497: done, saving took 0.96 seconds\n",
      "2021-11-08 12:35:25.478140: This epoch took 315.006983 s\n",
      "\n",
      "2021-11-08 12:35:25.482556: \n",
      "epoch:  98\n",
      "2021-11-08 12:40:22.985504: train loss : -0.8655\n",
      "2021-11-08 12:40:42.768183: validation loss: -0.8421\n",
      "2021-11-08 12:40:42.773595: Average global foreground Dice: [0.8638]\n",
      "2021-11-08 12:40:42.777630: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 12:40:43.288626: lr: 0.003787\n",
      "2021-11-08 12:40:43.294106: This epoch took 317.806825 s\n",
      "\n",
      "2021-11-08 12:40:43.298435: \n",
      "epoch:  99\n",
      "2021-11-08 12:45:43.590978: train loss : -0.8672\n",
      "2021-11-08 12:46:03.848606: validation loss: -0.8442\n",
      "2021-11-08 12:46:03.854217: Average global foreground Dice: [0.8615]\n",
      "2021-11-08 12:46:03.858558: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 12:46:04.376485: lr: 0.00372\n",
      "2021-11-08 12:46:04.381308: saving scheduled checkpoint file...\n",
      "2021-11-08 12:46:04.414531: saving checkpoint...\n",
      "2021-11-08 12:46:05.497540: done, saving took 1.11 seconds\n",
      "2021-11-08 12:46:05.526677: done\n",
      "2021-11-08 12:46:05.531689: This epoch took 322.228500 s\n",
      "\n",
      "2021-11-08 12:46:05.535357: \n",
      "epoch:  100\n",
      "2021-11-08 12:51:00.077961: train loss : -0.8707\n",
      "2021-11-08 12:51:19.586787: validation loss: -0.8433\n",
      "2021-11-08 12:51:19.592013: Average global foreground Dice: [0.8592]\n",
      "2021-11-08 12:51:19.596780: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 12:51:20.099684: lr: 0.003653\n",
      "2021-11-08 12:51:20.103384: This epoch took 314.563303 s\n",
      "\n",
      "2021-11-08 12:51:20.107797: \n",
      "epoch:  101\n",
      "2021-11-08 12:56:17.896000: train loss : -0.8678\n",
      "2021-11-08 12:56:37.402921: validation loss: -0.8438\n",
      "2021-11-08 12:56:37.407756: Average global foreground Dice: [0.8609]\n",
      "2021-11-08 12:56:37.411473: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 12:56:37.917541: lr: 0.003586\n",
      "2021-11-08 12:56:37.922637: This epoch took 317.810204 s\n",
      "\n",
      "2021-11-08 12:56:37.927290: \n",
      "epoch:  102\n",
      "2021-11-08 13:01:34.073026: train loss : -0.8684\n",
      "2021-11-08 13:01:53.529675: validation loss: -0.8574\n",
      "2021-11-08 13:01:53.534352: Average global foreground Dice: [0.8728]\n",
      "2021-11-08 13:01:53.539459: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 13:01:54.034791: lr: 0.003519\n",
      "2021-11-08 13:01:54.038670: This epoch took 316.107235 s\n",
      "\n",
      "2021-11-08 13:01:54.045321: \n",
      "epoch:  103\n",
      "2021-11-08 13:06:49.585695: train loss : -0.8694\n",
      "2021-11-08 13:07:09.225025: validation loss: -0.8439\n",
      "2021-11-08 13:07:09.229427: Average global foreground Dice: [0.859]\n",
      "2021-11-08 13:07:09.234025: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 13:07:09.749626: lr: 0.003451\n",
      "2021-11-08 13:07:09.754775: This epoch took 315.705088 s\n",
      "\n",
      "2021-11-08 13:07:09.758958: \n",
      "epoch:  104\n",
      "2021-11-08 13:12:07.197972: train loss : -0.8699\n",
      "2021-11-08 13:12:26.925173: validation loss: -0.8501\n",
      "2021-11-08 13:12:26.930389: Average global foreground Dice: [0.8616]\n",
      "2021-11-08 13:12:26.934468: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 13:12:27.443508: lr: 0.003384\n",
      "2021-11-08 13:12:27.449019: This epoch took 317.685264 s\n",
      "\n",
      "2021-11-08 13:12:27.461006: \n",
      "epoch:  105\n",
      "2021-11-08 13:17:27.397964: train loss : -0.8696\n",
      "2021-11-08 13:17:48.906469: validation loss: -0.8514\n",
      "2021-11-08 13:17:48.927562: Average global foreground Dice: [0.8661]\n",
      "2021-11-08 13:17:48.959611: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 13:17:51.006160: lr: 0.003316\n",
      "2021-11-08 13:17:51.013939: This epoch took 323.545127 s\n",
      "\n",
      "2021-11-08 13:17:51.021342: \n",
      "epoch:  106\n",
      "2021-11-08 13:22:51.696676: train loss : -0.8701\n",
      "2021-11-08 13:23:11.172073: validation loss: -0.8504\n",
      "2021-11-08 13:23:11.182166: Average global foreground Dice: [0.8649]\n",
      "2021-11-08 13:23:11.189813: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 13:23:11.687100: lr: 0.003248\n",
      "2021-11-08 13:23:11.694912: This epoch took 320.666808 s\n",
      "\n",
      "2021-11-08 13:23:11.701216: \n",
      "epoch:  107\n",
      "2021-11-08 13:28:10.510695: train loss : -0.8679\n",
      "2021-11-08 13:28:31.818550: validation loss: -0.8498\n",
      "2021-11-08 13:28:31.826842: Average global foreground Dice: [0.8632]\n",
      "2021-11-08 13:28:31.834218: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 13:28:32.336305: lr: 0.00318\n",
      "2021-11-08 13:28:32.343891: This epoch took 320.635243 s\n",
      "\n",
      "2021-11-08 13:28:32.351467: \n",
      "epoch:  108\n",
      "2021-11-08 13:33:29.872763: train loss : -0.8692\n",
      "2021-11-08 13:33:49.068761: validation loss: -0.8516\n",
      "2021-11-08 13:33:49.076899: Average global foreground Dice: [0.8663]\n",
      "2021-11-08 13:33:49.084217: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 13:33:49.584170: lr: 0.003112\n",
      "2021-11-08 13:33:49.591593: This epoch took 317.232972 s\n",
      "\n",
      "2021-11-08 13:33:49.599630: \n",
      "epoch:  109\n",
      "2021-11-08 13:38:47.996939: train loss : -0.8732\n",
      "2021-11-08 13:39:06.968767: validation loss: -0.8513\n",
      "2021-11-08 13:39:06.976237: Average global foreground Dice: [0.8665]\n",
      "2021-11-08 13:39:06.982752: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 13:39:07.478863: lr: 0.003043\n",
      "2021-11-08 13:39:07.486686: This epoch took 317.880722 s\n",
      "\n",
      "2021-11-08 13:39:07.494575: \n",
      "epoch:  110\n",
      "2021-11-08 13:44:01.764199: train loss : -0.8688\n",
      "2021-11-08 13:44:20.574256: validation loss: -0.8477\n",
      "2021-11-08 13:44:20.581748: Average global foreground Dice: [0.8619]\n",
      "2021-11-08 13:44:20.589834: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 13:44:21.105376: lr: 0.002975\n",
      "2021-11-08 13:44:21.113014: This epoch took 313.611251 s\n",
      "\n",
      "2021-11-08 13:44:21.119862: \n",
      "epoch:  111\n",
      "2021-11-08 13:49:21.509819: train loss : -0.8695\n",
      "2021-11-08 13:49:43.219528: validation loss: -0.8464\n",
      "2021-11-08 13:49:43.260194: Average global foreground Dice: [0.8633]\n",
      "2021-11-08 13:49:43.267793: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 13:49:44.892539: lr: 0.002906\n",
      "2021-11-08 13:49:44.901171: This epoch took 323.774997 s\n",
      "\n",
      "2021-11-08 13:49:44.907579: \n",
      "epoch:  112\n",
      "2021-11-08 13:54:59.118051: train loss : -0.8672\n",
      "2021-11-08 13:55:21.124666: validation loss: -0.8573\n",
      "2021-11-08 13:55:21.166382: Average global foreground Dice: [0.8712]\n",
      "2021-11-08 13:55:21.173150: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 13:55:22.586725: lr: 0.002837\n",
      "2021-11-08 13:55:22.595093: This epoch took 337.680189 s\n",
      "\n",
      "2021-11-08 13:55:22.602875: \n",
      "epoch:  113\n",
      "2021-11-08 14:00:23.521508: train loss : -0.8720\n",
      "2021-11-08 14:00:43.977741: validation loss: -0.8512\n",
      "2021-11-08 14:00:43.986170: Average global foreground Dice: [0.8673]\n",
      "2021-11-08 14:00:43.992821: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 14:00:44.495182: lr: 0.002768\n",
      "2021-11-08 14:00:44.503075: This epoch took 321.892168 s\n",
      "\n",
      "2021-11-08 14:00:44.510185: \n",
      "epoch:  114\n",
      "2021-11-08 14:05:44.035264: train loss : -0.8729\n",
      "2021-11-08 14:06:06.691105: validation loss: -0.8562\n",
      "2021-11-08 14:06:06.701011: Average global foreground Dice: [0.8717]\n",
      "2021-11-08 14:06:06.709889: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 14:06:07.333952: lr: 0.002699\n",
      "2021-11-08 14:06:07.341271: This epoch took 322.823180 s\n",
      "\n",
      "2021-11-08 14:06:07.348079: \n",
      "epoch:  115\n",
      "2021-11-08 14:11:08.073656: train loss : -0.8713\n",
      "2021-11-08 14:11:28.070053: validation loss: -0.8423\n",
      "2021-11-08 14:11:28.078554: Average global foreground Dice: [0.8603]\n",
      "2021-11-08 14:11:28.086263: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 14:11:28.595977: lr: 0.002629\n",
      "2021-11-08 14:11:28.604178: This epoch took 321.247828 s\n",
      "\n",
      "2021-11-08 14:11:28.610657: \n",
      "epoch:  116\n",
      "2021-11-08 14:16:32.475734: train loss : -0.8709\n",
      "2021-11-08 14:16:54.509950: validation loss: -0.8566\n",
      "2021-11-08 14:16:54.523512: Average global foreground Dice: [0.8698]\n",
      "2021-11-08 14:16:54.530867: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 14:16:55.757598: lr: 0.00256\n",
      "2021-11-08 14:16:55.767110: This epoch took 327.149017 s\n",
      "\n",
      "2021-11-08 14:16:55.774327: \n",
      "epoch:  117\n",
      "2021-11-08 14:21:55.073767: train loss : -0.8741\n",
      "2021-11-08 14:22:14.682512: validation loss: -0.8519\n",
      "2021-11-08 14:22:14.690130: Average global foreground Dice: [0.8689]\n",
      "2021-11-08 14:22:14.696928: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 14:22:15.216983: lr: 0.00249\n",
      "2021-11-08 14:22:15.224993: This epoch took 319.443934 s\n",
      "\n",
      "2021-11-08 14:22:15.232893: \n",
      "epoch:  118\n",
      "2021-11-08 14:27:15.019884: train loss : -0.8747\n",
      "2021-11-08 14:27:37.076602: validation loss: -0.8541\n",
      "2021-11-08 14:27:37.096320: Average global foreground Dice: [0.8713]\n",
      "2021-11-08 14:27:37.103110: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 14:27:38.777245: lr: 0.00242\n",
      "2021-11-08 14:27:38.813184: saving checkpoint...\n",
      "2021-11-08 14:27:39.972339: done, saving took 1.19 seconds\n",
      "2021-11-08 14:27:40.005590: This epoch took 324.765075 s\n",
      "\n",
      "2021-11-08 14:27:40.013796: \n",
      "epoch:  119\n",
      "2021-11-08 14:32:30.978127: train loss : -0.8766\n",
      "2021-11-08 14:32:50.366220: validation loss: -0.8485\n",
      "2021-11-08 14:32:50.374671: Average global foreground Dice: [0.8645]\n",
      "2021-11-08 14:32:50.382622: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 14:32:50.879904: lr: 0.002349\n",
      "2021-11-08 14:32:50.887880: This epoch took 310.867176 s\n",
      "\n",
      "2021-11-08 14:32:50.894866: \n",
      "epoch:  120\n",
      "2021-11-08 14:37:50.802924: train loss : -0.8719\n",
      "2021-11-08 14:38:12.159246: validation loss: -0.8482\n",
      "2021-11-08 14:38:12.192154: Average global foreground Dice: [0.8673]\n",
      "2021-11-08 14:38:12.199738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 14:38:13.820020: lr: 0.002279\n",
      "2021-11-08 14:38:13.828251: This epoch took 322.926157 s\n",
      "\n",
      "2021-11-08 14:38:13.859631: \n",
      "epoch:  121\n",
      "2021-11-08 14:43:15.385020: train loss : -0.8722\n",
      "2021-11-08 14:43:37.235372: validation loss: -0.8572\n",
      "2021-11-08 14:43:37.287127: Average global foreground Dice: [0.8738]\n",
      "2021-11-08 14:43:37.294243: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 14:43:39.316661: lr: 0.002208\n",
      "2021-11-08 14:43:39.430032: saving checkpoint...\n",
      "2021-11-08 14:43:40.873957: done, saving took 1.55 seconds\n",
      "2021-11-08 14:43:40.903337: This epoch took 327.036766 s\n",
      "\n",
      "2021-11-08 14:43:40.910774: \n",
      "epoch:  122\n",
      "2021-11-08 14:48:35.873087: train loss : -0.8748\n",
      "2021-11-08 14:48:56.071583: validation loss: -0.8524\n",
      "2021-11-08 14:48:56.080262: Average global foreground Dice: [0.8666]\n",
      "2021-11-08 14:48:56.089041: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 14:48:56.640893: lr: 0.002137\n",
      "2021-11-08 14:48:56.647238: This epoch took 315.729244 s\n",
      "\n",
      "2021-11-08 14:48:56.654690: \n",
      "epoch:  123\n",
      "2021-11-08 14:54:05.497202: train loss : -0.8715\n",
      "2021-11-08 14:54:27.494294: validation loss: -0.8474\n",
      "2021-11-08 14:54:27.508536: Average global foreground Dice: [0.865]\n",
      "2021-11-08 14:54:27.515657: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 14:54:29.050863: lr: 0.002065\n",
      "2021-11-08 14:54:29.058797: This epoch took 332.396634 s\n",
      "\n",
      "2021-11-08 14:54:29.065605: \n",
      "epoch:  124\n",
      "2021-11-08 14:59:34.529975: train loss : -0.8730\n",
      "2021-11-08 14:59:56.517310: validation loss: -0.8522\n",
      "2021-11-08 14:59:56.525502: Average global foreground Dice: [0.8657]\n",
      "2021-11-08 14:59:56.559643: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 14:59:57.980006: lr: 0.001994\n",
      "2021-11-08 14:59:57.986696: This epoch took 328.913818 s\n",
      "\n",
      "2021-11-08 14:59:57.994979: \n",
      "epoch:  125\n",
      "2021-11-08 15:04:58.106048: train loss : -0.8744\n",
      "2021-11-08 15:05:19.537674: validation loss: -0.8636\n",
      "2021-11-08 15:05:19.545596: Average global foreground Dice: [0.8744]\n",
      "2021-11-08 15:05:19.553006: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 15:05:20.136799: lr: 0.001922\n",
      "2021-11-08 15:05:20.173624: saving checkpoint...\n",
      "2021-11-08 15:05:21.260176: done, saving took 1.12 seconds\n",
      "2021-11-08 15:05:21.285142: This epoch took 323.282008 s\n",
      "\n",
      "2021-11-08 15:05:21.292602: \n",
      "epoch:  126\n",
      "2021-11-08 15:10:18.336259: train loss : -0.8730\n",
      "2021-11-08 15:10:39.412110: validation loss: -0.8454\n",
      "2021-11-08 15:10:39.421169: Average global foreground Dice: [0.8633]\n",
      "2021-11-08 15:10:39.428706: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 15:10:40.208308: lr: 0.00185\n",
      "2021-11-08 15:10:40.215569: This epoch took 318.915588 s\n",
      "\n",
      "2021-11-08 15:10:40.223552: \n",
      "epoch:  127\n",
      "2021-11-08 15:15:32.937060: train loss : -0.8775\n",
      "2021-11-08 15:15:50.872512: validation loss: -0.8524\n",
      "2021-11-08 15:15:50.880416: Average global foreground Dice: [0.8691]\n",
      "2021-11-08 15:15:50.887935: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 15:15:51.389660: lr: 0.001777\n",
      "2021-11-08 15:15:51.396291: This epoch took 311.165124 s\n",
      "\n",
      "2021-11-08 15:15:51.403407: \n",
      "epoch:  128\n",
      "2021-11-08 15:20:51.321127: train loss : -0.8743\n",
      "2021-11-08 15:21:13.064530: validation loss: -0.8504\n",
      "2021-11-08 15:21:13.084028: Average global foreground Dice: [0.8671]\n",
      "2021-11-08 15:21:13.090823: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 15:21:14.362064: lr: 0.001704\n",
      "2021-11-08 15:21:14.369204: This epoch took 322.958501 s\n",
      "\n",
      "2021-11-08 15:21:14.376913: \n",
      "epoch:  129\n",
      "2021-11-08 15:26:13.464182: train loss : -0.8768\n",
      "2021-11-08 15:26:31.768305: validation loss: -0.8596\n",
      "2021-11-08 15:26:31.775387: Average global foreground Dice: [0.8735]\n",
      "2021-11-08 15:26:31.782732: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 15:26:32.285635: lr: 0.001631\n",
      "2021-11-08 15:26:32.321728: saving checkpoint...\n",
      "2021-11-08 15:26:33.353518: done, saving took 1.06 seconds\n",
      "2021-11-08 15:26:33.384303: This epoch took 319.000125 s\n",
      "\n",
      "2021-11-08 15:26:33.391453: \n",
      "epoch:  130\n",
      "2021-11-08 15:31:33.117167: train loss : -0.8762\n",
      "2021-11-08 15:31:55.571414: validation loss: -0.8457\n",
      "2021-11-08 15:31:55.579934: Average global foreground Dice: [0.8643]\n",
      "2021-11-08 15:31:55.588395: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 15:31:56.419105: lr: 0.001557\n",
      "2021-11-08 15:31:56.426228: This epoch took 323.027886 s\n",
      "\n",
      "2021-11-08 15:31:56.433376: \n",
      "epoch:  131\n",
      "2021-11-08 15:36:53.081417: train loss : -0.8768\n",
      "2021-11-08 15:37:15.081404: validation loss: -0.8581\n",
      "2021-11-08 15:37:15.089864: Average global foreground Dice: [0.8714]\n",
      "2021-11-08 15:37:15.097450: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 15:37:16.041247: lr: 0.001483\n",
      "2021-11-08 15:37:16.115756: saving checkpoint...\n",
      "2021-11-08 15:37:17.360466: done, saving took 1.31 seconds\n",
      "2021-11-08 15:37:17.388407: This epoch took 320.947302 s\n",
      "\n",
      "2021-11-08 15:37:17.394768: \n",
      "epoch:  132\n",
      "2021-11-08 15:42:15.501128: train loss : -0.8759\n",
      "2021-11-08 15:42:36.800975: validation loss: -0.8523\n",
      "2021-11-08 15:42:36.819080: Average global foreground Dice: [0.8693]\n",
      "2021-11-08 15:42:36.827231: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 15:42:38.041864: lr: 0.001409\n",
      "2021-11-08 15:42:38.095005: saving checkpoint...\n",
      "2021-11-08 15:42:39.196820: done, saving took 1.13 seconds\n",
      "2021-11-08 15:42:39.224973: This epoch took 321.822292 s\n",
      "\n",
      "2021-11-08 15:42:39.231473: \n",
      "epoch:  133\n",
      "2021-11-08 15:47:40.460270: train loss : -0.8781\n",
      "2021-11-08 15:48:01.162285: validation loss: -0.8579\n",
      "2021-11-08 15:48:01.169805: Average global foreground Dice: [0.8721]\n",
      "2021-11-08 15:48:01.177082: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 15:48:01.739519: lr: 0.001334\n",
      "2021-11-08 15:48:01.775248: saving checkpoint...\n",
      "2021-11-08 15:48:02.753028: done, saving took 1.01 seconds\n",
      "2021-11-08 15:48:02.778389: This epoch took 323.539844 s\n",
      "\n",
      "2021-11-08 15:48:02.784734: \n",
      "epoch:  134\n",
      "2021-11-08 15:53:04.901073: train loss : -0.8752\n",
      "2021-11-08 15:53:26.629226: validation loss: -0.8593\n",
      "2021-11-08 15:53:26.636900: Average global foreground Dice: [0.8722]\n",
      "2021-11-08 15:53:26.643942: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 15:53:27.665272: lr: 0.001259\n",
      "2021-11-08 15:53:27.701997: saving checkpoint...\n",
      "2021-11-08 15:53:28.685249: done, saving took 1.01 seconds\n",
      "2021-11-08 15:53:28.711313: This epoch took 325.919978 s\n",
      "\n",
      "2021-11-08 15:53:28.718415: \n",
      "epoch:  135\n",
      "2021-11-08 15:58:30.201716: train loss : -0.8803\n",
      "2021-11-08 15:58:50.834260: validation loss: -0.8589\n",
      "2021-11-08 15:58:50.842251: Average global foreground Dice: [0.8744]\n",
      "2021-11-08 15:58:50.848866: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 15:58:51.510825: lr: 0.001183\n",
      "2021-11-08 15:58:51.547263: saving checkpoint...\n",
      "2021-11-08 15:58:52.472866: done, saving took 0.96 seconds\n",
      "2021-11-08 15:58:52.497919: This epoch took 323.772660 s\n",
      "\n",
      "2021-11-08 15:58:52.504854: \n",
      "epoch:  136\n",
      "2021-11-08 16:03:48.870283: train loss : -0.8785\n",
      "2021-11-08 16:04:08.875738: validation loss: -0.8532\n",
      "2021-11-08 16:04:08.884620: Average global foreground Dice: [0.8665]\n",
      "2021-11-08 16:04:08.891126: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 16:04:09.393303: lr: 0.001107\n",
      "2021-11-08 16:04:09.400009: This epoch took 316.888688 s\n",
      "\n",
      "2021-11-08 16:04:09.407680: \n",
      "epoch:  137\n",
      "2021-11-08 16:09:06.659342: train loss : -0.8813\n",
      "2021-11-08 16:09:27.815736: validation loss: -0.8541\n",
      "2021-11-08 16:09:27.826809: Average global foreground Dice: [0.8674]\n",
      "2021-11-08 16:09:27.834560: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 16:09:29.011503: lr: 0.00103\n",
      "2021-11-08 16:09:29.019753: This epoch took 319.605586 s\n",
      "\n",
      "2021-11-08 16:09:29.027157: \n",
      "epoch:  138\n",
      "2021-11-08 16:14:25.777589: train loss : -0.8819\n",
      "2021-11-08 16:14:46.413736: validation loss: -0.8530\n",
      "2021-11-08 16:14:46.424032: Average global foreground Dice: [0.8669]\n",
      "2021-11-08 16:14:46.433910: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 16:14:47.044003: lr: 0.000952\n",
      "2021-11-08 16:14:47.051129: This epoch took 318.017285 s\n",
      "\n",
      "2021-11-08 16:14:47.058059: \n",
      "epoch:  139\n",
      "2021-11-08 16:19:47.177409: train loss : -0.8818\n",
      "2021-11-08 16:20:08.625946: validation loss: -0.8602\n",
      "2021-11-08 16:20:08.667448: Average global foreground Dice: [0.8709]\n",
      "2021-11-08 16:20:08.674167: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 16:20:10.216947: lr: 0.000874\n",
      "2021-11-08 16:20:10.224816: This epoch took 323.160245 s\n",
      "\n",
      "2021-11-08 16:20:10.259633: \n",
      "epoch:  140\n",
      "2021-11-08 16:25:07.772810: train loss : -0.8807\n",
      "2021-11-08 16:25:27.273388: validation loss: -0.8485\n",
      "2021-11-08 16:25:27.282069: Average global foreground Dice: [0.8625]\n",
      "2021-11-08 16:25:27.289853: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 16:25:27.796838: lr: 0.000795\n",
      "2021-11-08 16:25:27.804844: This epoch took 317.538276 s\n",
      "\n",
      "2021-11-08 16:25:27.811452: \n",
      "epoch:  141\n",
      "2021-11-08 16:30:30.782418: train loss : -0.8812\n",
      "2021-11-08 16:30:50.910547: validation loss: -0.8578\n",
      "2021-11-08 16:30:50.919286: Average global foreground Dice: [0.8718]\n",
      "2021-11-08 16:30:50.927332: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 16:30:51.445318: lr: 0.000715\n",
      "2021-11-08 16:30:51.454409: This epoch took 323.635236 s\n",
      "\n",
      "2021-11-08 16:30:51.461092: \n",
      "epoch:  142\n",
      "2021-11-08 16:35:52.593313: train loss : -0.8794\n",
      "2021-11-08 16:36:13.251542: validation loss: -0.8576\n",
      "2021-11-08 16:36:13.259531: Average global foreground Dice: [0.8719]\n",
      "2021-11-08 16:36:13.266451: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 16:36:13.774756: lr: 0.000634\n",
      "2021-11-08 16:36:13.782189: This epoch took 322.313617 s\n",
      "\n",
      "2021-11-08 16:36:13.790613: \n",
      "epoch:  143\n",
      "2021-11-08 16:41:13.001060: train loss : -0.8800\n",
      "2021-11-08 16:41:34.892869: validation loss: -0.8558\n",
      "2021-11-08 16:41:34.923636: Average global foreground Dice: [0.8684]\n",
      "2021-11-08 16:41:34.931860: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 16:41:36.872826: lr: 0.000552\n",
      "2021-11-08 16:41:36.882659: This epoch took 323.085312 s\n",
      "\n",
      "2021-11-08 16:41:36.889398: \n",
      "epoch:  144\n",
      "2021-11-08 16:46:39.693409: train loss : -0.8819\n",
      "2021-11-08 16:47:01.206047: validation loss: -0.8615\n",
      "2021-11-08 16:47:01.219993: Average global foreground Dice: [0.8745]\n",
      "2021-11-08 16:47:01.227413: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 16:47:02.562936: lr: 0.000468\n",
      "2021-11-08 16:47:02.677526: saving checkpoint...\n",
      "2021-11-08 16:47:04.685528: done, saving took 2.11 seconds\n",
      "2021-11-08 16:47:04.717017: This epoch took 327.820320 s\n",
      "\n",
      "2021-11-08 16:47:04.724163: \n",
      "epoch:  145\n",
      "2021-11-08 16:52:08.086537: train loss : -0.8809\n",
      "2021-11-08 16:52:30.804157: validation loss: -0.8550\n",
      "2021-11-08 16:52:30.813226: Average global foreground Dice: [0.868]\n",
      "2021-11-08 16:52:30.821950: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 16:52:33.123887: lr: 0.000383\n",
      "2021-11-08 16:52:33.132745: This epoch took 328.373102 s\n",
      "\n",
      "2021-11-08 16:52:33.166835: \n",
      "epoch:  146\n",
      "2021-11-08 16:57:34.087143: train loss : -0.8809\n",
      "2021-11-08 16:57:56.372567: validation loss: -0.8508\n",
      "2021-11-08 16:57:56.386791: Average global foreground Dice: [0.8688]\n",
      "2021-11-08 16:57:56.398192: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 16:57:59.414777: lr: 0.000296\n",
      "2021-11-08 16:57:59.421863: This epoch took 326.246842 s\n",
      "\n",
      "2021-11-08 16:57:59.429929: \n",
      "epoch:  147\n",
      "2021-11-08 17:03:03.785409: train loss : -0.8806\n",
      "2021-11-08 17:03:25.919050: validation loss: -0.8592\n",
      "2021-11-08 17:03:25.929100: Average global foreground Dice: [0.8743]\n",
      "2021-11-08 17:03:25.959598: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 17:03:27.386590: lr: 0.000205\n",
      "2021-11-08 17:03:27.425257: saving checkpoint...\n",
      "2021-11-08 17:03:28.565025: done, saving took 1.17 seconds\n",
      "2021-11-08 17:03:28.595893: This epoch took 329.136302 s\n",
      "\n",
      "2021-11-08 17:03:28.602710: \n",
      "epoch:  148\n",
      "2021-11-08 17:08:29.685508: train loss : -0.8813\n",
      "2021-11-08 17:08:51.470756: validation loss: -0.8469\n",
      "2021-11-08 17:08:51.492050: Average global foreground Dice: [0.8648]\n",
      "2021-11-08 17:08:51.500129: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 17:08:53.968478: lr: 0.00011\n",
      "2021-11-08 17:08:53.976894: This epoch took 325.366133 s\n",
      "\n",
      "2021-11-08 17:08:53.984002: \n",
      "epoch:  149\n",
      "2021-11-08 17:13:54.388529: train loss : -0.8855\n",
      "2021-11-08 17:14:12.916992: validation loss: -0.8605\n",
      "2021-11-08 17:14:12.924655: Average global foreground Dice: [0.8739]\n",
      "2021-11-08 17:14:12.932816: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 17:14:13.454607: lr: 0.0\n",
      "2021-11-08 17:14:13.462966: saving scheduled checkpoint file...\n",
      "2021-11-08 17:14:13.500325: saving checkpoint...\n",
      "2021-11-08 17:14:14.608664: done, saving took 1.14 seconds\n",
      "2021-11-08 17:14:14.642851: done\n",
      "2021-11-08 17:14:14.651026: This epoch took 320.659162 s\n",
      "\n",
      "2021-11-08 17:14:14.709905: saving checkpoint...\n",
      "2021-11-08 17:14:15.720605: done, saving took 1.06 seconds\n",
      "23090557_20130717 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090560_20160114 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090562_20140206 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141215 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130626 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140124 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121015 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090597_20130227 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130208 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090621_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150105 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130807 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090637_20140401 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131126 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090644_20131216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-08 17:17:39.725049: finished prediction\n",
      "2021-11-08 17:17:39.732754: evaluation of raw predictions\n",
      "2021-11-08 17:17:41.186668: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8661068992694779\n",
      "after:  0.8676951906996675\n",
      "Removing all but the largest foreground region improved results!\n",
      "for_which_classes [1]\n",
      "min_valid_object_sizes None\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[[1]]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-08 17:17:53.324256: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-08 17:17:53.342929: The split file contains 5 splits.\n",
      "2021-11-08 17:17:53.347132: Desired fold for training: 4\n",
      "2021-11-08 17:17:53.352677: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-08 17:17:57.706188: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-08 17:18:23.326216: Unable to plot network architecture:\n",
      "2021-11-08 17:18:23.331357: No module named 'hiddenlayer'\r\n",
      "2021-11-08 17:18:23.364185: \r\n",
      "printing the network instead:\r\n",
      "\r\n",
      "2021-11-08 17:18:23.369663: Generic_UNet(\r\n",
      "  (conv_blocks_localization): ModuleList(\r\n",
      "    (0): Sequential(\r\n",
      "      (0): StackedConvLayers(\r\n",
      "        (blocks): Sequential(\r\n",
      "          (0): ConvDropoutNormNonlin(\r\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (1): StackedConvLayers(\r\n",
      "        (blocks): Sequential(\r\n",
      "          (0): ConvDropoutNormNonlin(\r\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (1): Sequential(\r\n",
      "      (0): StackedConvLayers(\r\n",
      "        (blocks): Sequential(\r\n",
      "          (0): ConvDropoutNormNonlin(\r\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (1): StackedConvLayers(\r\n",
      "        (blocks): Sequential(\r\n",
      "          (0): ConvDropoutNormNonlin(\r\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (2): Sequential(\r\n",
      "      (0): StackedConvLayers(\r\n",
      "        (blocks): Sequential(\r\n",
      "          (0): ConvDropoutNormNonlin(\r\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (1): StackedConvLayers(\r\n",
      "        (blocks): Sequential(\r\n",
      "          (0): ConvDropoutNormNonlin(\r\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (3): Sequential(\r\n",
      "      (0): StackedConvLayers(\r\n",
      "        (blocks): Sequential(\r\n",
      "          (0): ConvDropoutNormNonlin(\r\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (1): StackedConvLayers(\r\n",
      "        (blocks): Sequential(\r\n",
      "          (0): ConvDropoutNormNonlin(\r\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (4): Sequential(\r\n",
      "      (0): StackedConvLayers(\r\n",
      "        (blocks): Sequential(\r\n",
      "          (0): ConvDropoutNormNonlin(\r\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (1): StackedConvLayers(\r\n",
      "        (blocks): Sequential(\r\n",
      "          (0): ConvDropoutNormNonlin(\r\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (conv_blocks_context): ModuleList(\r\n",
      "    (0): StackedConvLayers(\r\n",
      "      (blocks): Sequential(\r\n",
      "        (0): ConvDropoutNormNonlin(\r\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "        )\r\n",
      "        (1): ConvDropoutNormNonlin(\r\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (1): StackedConvLayers(\r\n",
      "      (blocks): Sequential(\r\n",
      "        (0): ConvDropoutNormNonlin(\r\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\r\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "        )\r\n",
      "        (1): ConvDropoutNormNonlin(\r\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (2): StackedConvLayers(\r\n",
      "      (blocks): Sequential(\r\n",
      "        (0): ConvDropoutNormNonlin(\r\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\r\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "        )\r\n",
      "        (1): ConvDropoutNormNonlin(\r\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (3): StackedConvLayers(\r\n",
      "      (blocks): Sequential(\r\n",
      "        (0): ConvDropoutNormNonlin(\r\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\r\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "        )\r\n",
      "        (1): ConvDropoutNormNonlin(\r\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (4): StackedConvLayers(\r\n",
      "      (blocks): Sequential(\r\n",
      "        (0): ConvDropoutNormNonlin(\r\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\r\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "        )\r\n",
      "        (1): ConvDropoutNormNonlin(\r\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (5): Sequential(\r\n",
      "      (0): StackedConvLayers(\r\n",
      "        (blocks): Sequential(\r\n",
      "          (0): ConvDropoutNormNonlin(\r\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\r\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (1): StackedConvLayers(\r\n",
      "        (blocks): Sequential(\r\n",
      "          (0): ConvDropoutNormNonlin(\r\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\r\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\r\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (td): ModuleList()\r\n",
      "  (tu): ModuleList(\r\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\r\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\r\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\r\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\r\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\r\n",
      "  )\r\n",
      "  (seg_outputs): ModuleList(\r\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\r\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\r\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\r\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\r\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\r\n",
      "  )\r\n",
      ")\r\n",
      "2021-11-08 17:18:23.378009: \r\n",
      "\r\n",
      "2021-11-08 17:18:23.382487: \r\n",
      "epoch:  0\r\n",
      "2021-11-08 17:24:00.778302: train loss : -0.2185\n",
      "2021-11-08 17:24:22.769302: validation loss: -0.5622\n",
      "2021-11-08 17:24:22.785366: Average global foreground Dice: [0.633]\n",
      "2021-11-08 17:24:22.792301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 17:24:24.579196: lr: 0.00994\n",
      "2021-11-08 17:24:24.583842: This epoch took 361.196230 s\n",
      "\n",
      "2021-11-08 17:24:24.589985: \n",
      "epoch:  1\n",
      "2021-11-08 17:29:24.984179: train loss : -0.6027\n",
      "2021-11-08 17:29:47.659315: validation loss: -0.6770\n",
      "2021-11-08 17:29:47.665110: Average global foreground Dice: [0.7288]\n",
      "2021-11-08 17:29:47.670185: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 17:29:49.204110: lr: 0.00988\n",
      "2021-11-08 17:29:49.406615: saving checkpoint...\n",
      "2021-11-08 17:29:50.493862: done, saving took 1.29 seconds\n",
      "2021-11-08 17:29:50.515668: This epoch took 325.920642 s\n",
      "\n",
      "2021-11-08 17:29:50.520610: \n",
      "epoch:  2\n",
      "2021-11-08 17:34:47.385103: train loss : -0.6701\n",
      "2021-11-08 17:35:07.598547: validation loss: -0.7386\n",
      "2021-11-08 17:35:07.604706: Average global foreground Dice: [0.7846]\n",
      "2021-11-08 17:35:07.609750: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 17:35:08.130531: lr: 0.00982\n",
      "2021-11-08 17:35:08.213861: saving checkpoint...\n",
      "2021-11-08 17:35:09.235992: done, saving took 1.10 seconds\n",
      "2021-11-08 17:35:09.270211: This epoch took 318.743502 s\n",
      "\n",
      "2021-11-08 17:35:09.274382: \n",
      "epoch:  3\n",
      "2021-11-08 17:40:04.525497: train loss : -0.7220\n",
      "2021-11-08 17:40:26.102282: validation loss: -0.7720\n",
      "2021-11-08 17:40:26.108456: Average global foreground Dice: [0.8019]\n",
      "2021-11-08 17:40:26.114384: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 17:40:26.733538: lr: 0.00976\n",
      "2021-11-08 17:40:26.824873: saving checkpoint...\n",
      "2021-11-08 17:40:27.832923: done, saving took 1.09 seconds\n",
      "2021-11-08 17:40:27.867539: This epoch took 318.589031 s\n",
      "\n",
      "2021-11-08 17:40:27.872744: \n",
      "epoch:  4\n",
      "2021-11-08 17:45:16.639673: train loss : -0.7494\n",
      "2021-11-08 17:45:34.996423: validation loss: -0.7727\n",
      "2021-11-08 17:45:35.001626: Average global foreground Dice: [0.8018]\n",
      "2021-11-08 17:45:35.005826: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 17:45:35.543462: lr: 0.009699\n",
      "2021-11-08 17:45:35.624747: saving checkpoint...\n",
      "2021-11-08 17:45:36.571244: done, saving took 1.02 seconds\n",
      "2021-11-08 17:45:36.603819: This epoch took 308.726096 s\n",
      "\n",
      "2021-11-08 17:45:36.609683: \n",
      "epoch:  5\n",
      "2021-11-08 17:50:33.792045: train loss : -0.7663\n",
      "2021-11-08 17:50:56.359380: validation loss: -0.7836\n",
      "2021-11-08 17:50:56.366767: Average global foreground Dice: [0.8142]\n",
      "2021-11-08 17:50:56.371492: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 17:50:58.910255: lr: 0.009639\n",
      "2021-11-08 17:50:59.129408: saving checkpoint...\n",
      "2021-11-08 17:51:01.052050: done, saving took 2.14 seconds\n",
      "2021-11-08 17:51:01.094386: This epoch took 324.480758 s\n",
      "\n",
      "2021-11-08 17:51:01.099505: \n",
      "epoch:  6\n",
      "2021-11-08 17:55:49.007447: train loss : -0.7769\n",
      "2021-11-08 17:56:07.189326: validation loss: -0.8029\n",
      "2021-11-08 17:56:07.194594: Average global foreground Dice: [0.8287]\n",
      "2021-11-08 17:56:07.199685: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 17:56:07.732416: lr: 0.009579\n",
      "2021-11-08 17:56:07.815074: saving checkpoint...\n",
      "2021-11-08 17:56:08.809378: done, saving took 1.07 seconds\n",
      "2021-11-08 17:56:08.833950: This epoch took 307.729927 s\n",
      "\n",
      "2021-11-08 17:56:08.838958: \n",
      "epoch:  7\n",
      "2021-11-08 18:01:06.173774: train loss : -0.7887\n",
      "2021-11-08 18:01:28.413059: validation loss: -0.8103\n",
      "2021-11-08 18:01:28.431916: Average global foreground Dice: [0.8344]\n",
      "2021-11-08 18:01:28.459605: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 18:01:31.325405: lr: 0.009519\n",
      "2021-11-08 18:01:31.596666: saving checkpoint...\n",
      "2021-11-08 18:01:33.659608: done, saving took 2.33 seconds\n",
      "2021-11-08 18:01:33.701174: This epoch took 324.857071 s\n",
      "\n",
      "2021-11-08 18:01:33.705482: \n",
      "epoch:  8\n",
      "2021-11-08 18:06:25.638793: train loss : -0.7899\n",
      "2021-11-08 18:06:46.630596: validation loss: -0.8155\n",
      "2021-11-08 18:06:46.636006: Average global foreground Dice: [0.8381]\n",
      "2021-11-08 18:06:46.659290: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 18:06:47.271796: lr: 0.009458\n",
      "2021-11-08 18:06:47.305423: saving checkpoint...\n",
      "2021-11-08 18:06:48.349368: done, saving took 1.07 seconds\n",
      "2021-11-08 18:06:48.376200: This epoch took 314.665921 s\n",
      "\n",
      "2021-11-08 18:06:48.381595: \n",
      "epoch:  9\n",
      "2021-11-08 18:11:47.108903: train loss : -0.8014\n",
      "2021-11-08 18:12:08.432917: validation loss: -0.8146\n",
      "2021-11-08 18:12:08.476910: Average global foreground Dice: [0.8419]\n",
      "2021-11-08 18:12:08.480949: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 18:12:10.115387: lr: 0.009398\n",
      "2021-11-08 18:12:10.151131: saving checkpoint...\n",
      "2021-11-08 18:12:11.113539: done, saving took 0.99 seconds\n",
      "2021-11-08 18:12:11.145717: This epoch took 322.759304 s\n",
      "\n",
      "2021-11-08 18:12:11.151495: \n",
      "epoch:  10\n",
      "2021-11-08 18:16:58.695833: train loss : -0.8042\n",
      "2021-11-08 18:17:18.971441: validation loss: -0.8135\n",
      "2021-11-08 18:17:18.977048: Average global foreground Dice: [0.8336]\n",
      "2021-11-08 18:17:18.982024: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 18:17:19.461592: lr: 0.009338\n",
      "2021-11-08 18:17:19.495395: saving checkpoint...\n",
      "2021-11-08 18:17:20.479509: done, saving took 1.01 seconds\n",
      "2021-11-08 18:17:20.503695: This epoch took 309.346786 s\n",
      "\n",
      "2021-11-08 18:17:20.507463: \n",
      "epoch:  11\n",
      "2021-11-08 18:22:22.194041: train loss : -0.8039\n",
      "2021-11-08 18:22:43.392812: validation loss: -0.8136\n",
      "2021-11-08 18:22:43.405104: Average global foreground Dice: [0.829]\n",
      "2021-11-08 18:22:43.412607: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 18:22:45.022877: lr: 0.009277\n",
      "2021-11-08 18:22:45.098475: saving checkpoint...\n",
      "2021-11-08 18:22:46.326337: done, saving took 1.30 seconds\n",
      "2021-11-08 18:22:46.352669: This epoch took 325.840717 s\n",
      "\n",
      "2021-11-08 18:22:46.358496: \n",
      "epoch:  12\n",
      "2021-11-08 18:27:40.172066: train loss : -0.8077\n",
      "2021-11-08 18:27:58.180788: validation loss: -0.8183\n",
      "2021-11-08 18:27:58.186604: Average global foreground Dice: [0.8397]\n",
      "2021-11-08 18:27:58.191551: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 18:27:58.694519: lr: 0.009217\n",
      "2021-11-08 18:27:58.727217: saving checkpoint...\n",
      "2021-11-08 18:27:59.647915: done, saving took 0.95 seconds\n",
      "2021-11-08 18:27:59.670877: This epoch took 313.307004 s\n",
      "\n",
      "2021-11-08 18:27:59.675567: \n",
      "epoch:  13\n",
      "2021-11-08 18:32:48.469370: train loss : -0.8133\n",
      "2021-11-08 18:33:07.618957: validation loss: -0.8157\n",
      "2021-11-08 18:33:07.624513: Average global foreground Dice: [0.8295]\n",
      "2021-11-08 18:33:07.629517: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 18:33:08.118780: lr: 0.009156\n",
      "2021-11-08 18:33:08.151877: saving checkpoint...\n",
      "2021-11-08 18:33:09.070580: done, saving took 0.95 seconds\n",
      "2021-11-08 18:33:09.094867: This epoch took 309.413921 s\n",
      "\n",
      "2021-11-08 18:33:09.099444: \n",
      "epoch:  14\n",
      "2021-11-08 18:38:07.183275: train loss : -0.8157\n",
      "2021-11-08 18:38:29.488215: validation loss: -0.8219\n",
      "2021-11-08 18:38:29.493975: Average global foreground Dice: [0.8386]\n",
      "2021-11-08 18:38:29.498969: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 18:38:31.696006: lr: 0.009095\n",
      "2021-11-08 18:38:31.775697: saving checkpoint...\n",
      "2021-11-08 18:38:33.711511: done, saving took 2.01 seconds\n",
      "2021-11-08 18:38:33.767423: This epoch took 324.663360 s\n",
      "\n",
      "2021-11-08 18:38:33.772748: \n",
      "epoch:  15\n",
      "2021-11-08 18:43:39.193240: train loss : -0.8151\n",
      "2021-11-08 18:44:00.812195: validation loss: -0.8174\n",
      "2021-11-08 18:44:00.822473: Average global foreground Dice: [0.8401]\n",
      "2021-11-08 18:44:00.827612: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 18:44:02.130173: lr: 0.009035\n",
      "2021-11-08 18:44:02.164317: saving checkpoint...\n",
      "2021-11-08 18:44:03.197299: done, saving took 1.06 seconds\n",
      "2021-11-08 18:44:03.222916: This epoch took 329.445353 s\n",
      "\n",
      "2021-11-08 18:44:03.227993: \n",
      "epoch:  16\n",
      "2021-11-08 18:49:14.093791: train loss : -0.8110\n",
      "2021-11-08 18:49:36.484144: validation loss: -0.8275\n",
      "2021-11-08 18:49:36.489400: Average global foreground Dice: [0.8443]\n",
      "2021-11-08 18:49:36.494236: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 18:49:38.798801: lr: 0.008974\n",
      "2021-11-08 18:49:38.879072: saving checkpoint...\n",
      "2021-11-08 18:49:40.787587: done, saving took 1.98 seconds\n",
      "2021-11-08 18:49:40.817492: This epoch took 337.584782 s\n",
      "\n",
      "2021-11-08 18:49:40.822768: \n",
      "epoch:  17\n",
      "2021-11-08 18:54:40.908058: train loss : -0.8148\n",
      "2021-11-08 18:55:03.167943: validation loss: -0.8279\n",
      "2021-11-08 18:55:03.182836: Average global foreground Dice: [0.8466]\n",
      "2021-11-08 18:55:03.187823: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 18:55:04.793585: lr: 0.008913\n",
      "2021-11-08 18:55:04.880669: saving checkpoint...\n",
      "2021-11-08 18:55:06.624925: done, saving took 1.83 seconds\n",
      "2021-11-08 18:55:06.670461: This epoch took 325.842824 s\n",
      "\n",
      "2021-11-08 18:55:06.675139: \n",
      "epoch:  18\n",
      "2021-11-08 19:00:03.072826: train loss : -0.8197\n",
      "2021-11-08 19:00:24.533166: validation loss: -0.8298\n",
      "2021-11-08 19:00:24.577801: Average global foreground Dice: [0.8465]\n",
      "2021-11-08 19:00:24.582493: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 19:00:25.856819: lr: 0.008852\n",
      "2021-11-08 19:00:25.900391: saving checkpoint...\n",
      "2021-11-08 19:00:26.857891: done, saving took 1.00 seconds\n",
      "2021-11-08 19:00:26.882542: This epoch took 320.202693 s\n",
      "\n",
      "2021-11-08 19:00:26.887957: \n",
      "epoch:  19\n",
      "2021-11-08 19:05:23.980753: train loss : -0.8231\n",
      "2021-11-08 19:05:43.722821: validation loss: -0.8270\n",
      "2021-11-08 19:05:43.728554: Average global foreground Dice: [0.8441]\n",
      "2021-11-08 19:05:43.734250: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 19:05:44.267963: lr: 0.008792\n",
      "2021-11-08 19:05:44.300961: saving checkpoint...\n",
      "2021-11-08 19:05:45.269367: done, saving took 1.00 seconds\n",
      "2021-11-08 19:05:45.292605: This epoch took 318.400455 s\n",
      "\n",
      "2021-11-08 19:05:45.297697: \n",
      "epoch:  20\n",
      "2021-11-08 19:10:42.799448: train loss : -0.8247\n",
      "2021-11-08 19:11:04.182641: validation loss: -0.8358\n",
      "2021-11-08 19:11:04.201049: Average global foreground Dice: [0.8409]\n",
      "2021-11-08 19:11:04.205593: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 19:11:05.326766: lr: 0.008731\n",
      "2021-11-08 19:11:05.385774: saving checkpoint...\n",
      "2021-11-08 19:11:06.412220: done, saving took 1.08 seconds\n",
      "2021-11-08 19:11:06.435215: This epoch took 321.132565 s\n",
      "\n",
      "2021-11-08 19:11:06.439137: \n",
      "epoch:  21\n",
      "2021-11-08 19:16:05.417311: train loss : -0.8234\n",
      "2021-11-08 19:16:24.620913: validation loss: -0.8239\n",
      "2021-11-08 19:16:24.625688: Average global foreground Dice: [0.846]\n",
      "2021-11-08 19:16:24.629539: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 19:16:25.121093: lr: 0.00867\n",
      "2021-11-08 19:16:25.154935: saving checkpoint...\n",
      "2021-11-08 19:16:26.058721: done, saving took 0.93 seconds\n",
      "2021-11-08 19:16:26.081503: This epoch took 319.638174 s\n",
      "\n",
      "2021-11-08 19:16:26.085829: \n",
      "epoch:  22\n",
      "2021-11-08 19:21:22.896224: train loss : -0.8298\n",
      "2021-11-08 19:21:44.694930: validation loss: -0.8405\n",
      "2021-11-08 19:21:44.700765: Average global foreground Dice: [0.8612]\n",
      "2021-11-08 19:21:44.705767: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 19:21:46.538223: lr: 0.008609\n",
      "2021-11-08 19:21:46.595596: saving checkpoint...\n",
      "2021-11-08 19:21:47.621674: done, saving took 1.06 seconds\n",
      "2021-11-08 19:21:47.645712: This epoch took 321.555871 s\n",
      "\n",
      "2021-11-08 19:21:47.651388: \n",
      "epoch:  23\n",
      "2021-11-08 19:26:47.973033: train loss : -0.8228\n",
      "2021-11-08 19:27:09.584684: validation loss: -0.8300\n",
      "2021-11-08 19:27:09.590566: Average global foreground Dice: [0.8451]\n",
      "2021-11-08 19:27:09.595425: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 19:27:11.687998: lr: 0.008548\n",
      "2021-11-08 19:27:11.770365: saving checkpoint...\n",
      "2021-11-08 19:27:13.181811: done, saving took 1.49 seconds\n",
      "2021-11-08 19:27:13.209688: This epoch took 325.553599 s\n",
      "\n",
      "2021-11-08 19:27:13.215086: \n",
      "epoch:  24\n",
      "2021-11-08 19:32:10.097696: train loss : -0.8286\n",
      "2021-11-08 19:32:31.293086: validation loss: -0.8270\n",
      "2021-11-08 19:32:31.298844: Average global foreground Dice: [0.8423]\n",
      "2021-11-08 19:32:31.304402: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 19:32:31.810445: lr: 0.008487\n",
      "2021-11-08 19:32:31.844966: saving checkpoint...\n",
      "2021-11-08 19:32:32.905568: done, saving took 1.09 seconds\n",
      "2021-11-08 19:32:32.929719: This epoch took 319.709584 s\n",
      "\n",
      "2021-11-08 19:32:32.934525: \n",
      "epoch:  25\n",
      "2021-11-08 19:37:34.890792: train loss : -0.8285\n",
      "2021-11-08 19:37:57.680394: validation loss: -0.8385\n",
      "2021-11-08 19:37:57.700998: Average global foreground Dice: [0.8533]\n",
      "2021-11-08 19:37:57.705915: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 19:37:59.286317: lr: 0.008426\n",
      "2021-11-08 19:37:59.372275: saving checkpoint...\n",
      "2021-11-08 19:38:00.810016: done, saving took 1.52 seconds\n",
      "2021-11-08 19:38:00.833785: This epoch took 327.894642 s\n",
      "\n",
      "2021-11-08 19:38:00.837670: \n",
      "epoch:  26\n",
      "2021-11-08 19:43:00.137253: train loss : -0.8312\n",
      "2021-11-08 19:43:22.392311: validation loss: -0.8396\n",
      "2021-11-08 19:43:22.417323: Average global foreground Dice: [0.8575]\n",
      "2021-11-08 19:43:22.422507: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 19:43:24.285866: lr: 0.008364\n",
      "2021-11-08 19:43:24.328289: saving checkpoint...\n",
      "2021-11-08 19:43:25.444270: done, saving took 1.15 seconds\n",
      "2021-11-08 19:43:25.477949: This epoch took 324.636536 s\n",
      "\n",
      "2021-11-08 19:43:25.484978: \n",
      "epoch:  27\n",
      "2021-11-08 19:48:23.504450: train loss : -0.8338\n",
      "2021-11-08 19:48:45.564201: validation loss: -0.8310\n",
      "2021-11-08 19:48:45.579564: Average global foreground Dice: [0.8538]\n",
      "2021-11-08 19:48:45.585240: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 19:48:46.327179: lr: 0.008303\n",
      "2021-11-08 19:48:46.383989: saving checkpoint...\n",
      "2021-11-08 19:48:47.392873: done, saving took 1.06 seconds\n",
      "2021-11-08 19:48:47.424181: This epoch took 321.934304 s\n",
      "\n",
      "2021-11-08 19:48:47.428005: \n",
      "epoch:  28\n",
      "2021-11-08 19:53:46.805408: train loss : -0.8339\n",
      "2021-11-08 19:54:07.433135: validation loss: -0.8335\n",
      "2021-11-08 19:54:07.438885: Average global foreground Dice: [0.853]\n",
      "2021-11-08 19:54:07.459590: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 19:54:08.186280: lr: 0.008242\n",
      "2021-11-08 19:54:08.219847: saving checkpoint...\n",
      "2021-11-08 19:54:09.138103: done, saving took 0.95 seconds\n",
      "2021-11-08 19:54:09.163360: This epoch took 321.731508 s\n",
      "\n",
      "2021-11-08 19:54:09.168483: \n",
      "epoch:  29\n",
      "2021-11-08 19:59:08.993934: train loss : -0.8362\n",
      "2021-11-08 19:59:31.333975: validation loss: -0.8360\n",
      "2021-11-08 19:59:31.372399: Average global foreground Dice: [0.8483]\n",
      "2021-11-08 19:59:31.377544: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 19:59:34.224234: lr: 0.008181\n",
      "2021-11-08 19:59:34.307521: saving checkpoint...\n",
      "2021-11-08 19:59:36.027574: done, saving took 1.80 seconds\n",
      "2021-11-08 19:59:36.070529: This epoch took 326.896991 s\n",
      "\n",
      "2021-11-08 19:59:36.075748: \n",
      "epoch:  30\n",
      "2021-11-08 20:04:40.826326: train loss : -0.8349\n",
      "2021-11-08 20:05:02.177157: validation loss: -0.8299\n",
      "2021-11-08 20:05:02.207753: Average global foreground Dice: [0.8474]\n",
      "2021-11-08 20:05:02.213175: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 20:05:04.380495: lr: 0.008119\n",
      "2021-11-08 20:05:04.472036: saving checkpoint...\n",
      "2021-11-08 20:05:05.940463: done, saving took 1.56 seconds\n",
      "2021-11-08 20:05:05.974292: This epoch took 329.893499 s\n",
      "\n",
      "2021-11-08 20:05:05.979546: \n",
      "epoch:  31\n",
      "2021-11-08 20:10:06.381574: train loss : -0.8363\n",
      "2021-11-08 20:10:26.711272: validation loss: -0.8279\n",
      "2021-11-08 20:10:26.717173: Average global foreground Dice: [0.8439]\n",
      "2021-11-08 20:10:26.722223: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 20:10:27.232047: lr: 0.008058\n",
      "2021-11-08 20:10:27.265183: saving checkpoint...\n",
      "2021-11-08 20:10:28.354879: done, saving took 1.12 seconds\n",
      "2021-11-08 20:10:28.380705: This epoch took 322.396281 s\n",
      "\n",
      "2021-11-08 20:10:28.385372: \n",
      "epoch:  32\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-08 20:15:26.513400: train loss : -0.8355\n",
      "2021-11-08 20:15:48.722472: validation loss: -0.8385\n",
      "2021-11-08 20:15:48.773024: Average global foreground Dice: [0.8546]\n",
      "2021-11-08 20:15:48.778535: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 20:15:51.217849: lr: 0.007996\n",
      "2021-11-08 20:15:51.288170: saving checkpoint...\n",
      "2021-11-08 20:15:53.159563: done, saving took 1.94 seconds\n",
      "2021-11-08 20:15:53.192212: This epoch took 324.802010 s\n",
      "\n",
      "2021-11-08 20:15:53.197591: \n",
      "epoch:  33\n",
      "2021-11-08 20:20:55.120821: train loss : -0.8363\n",
      "2021-11-08 20:21:16.680386: validation loss: -0.8432\n",
      "2021-11-08 20:21:16.689084: Average global foreground Dice: [0.8609]\n",
      "2021-11-08 20:21:16.693037: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 20:21:18.860661: lr: 0.007935\n",
      "2021-11-08 20:21:18.921163: saving checkpoint...\n",
      "2021-11-08 20:21:20.301083: done, saving took 1.43 seconds\n",
      "2021-11-08 20:21:20.330144: This epoch took 327.127126 s\n",
      "\n",
      "2021-11-08 20:21:20.335637: \n",
      "epoch:  34\n",
      "2021-11-08 20:26:23.385511: train loss : -0.8405\n",
      "2021-11-08 20:26:45.107964: validation loss: -0.8341\n",
      "2021-11-08 20:26:45.113600: Average global foreground Dice: [0.8449]\n",
      "2021-11-08 20:26:45.117953: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 20:26:47.042133: lr: 0.007873\n",
      "2021-11-08 20:26:47.087685: saving checkpoint...\n",
      "2021-11-08 20:26:48.190871: done, saving took 1.14 seconds\n",
      "2021-11-08 20:26:48.216266: This epoch took 327.875693 s\n",
      "\n",
      "2021-11-08 20:26:48.221094: \n",
      "epoch:  35\n",
      "2021-11-08 20:31:44.773756: train loss : -0.8384\n",
      "2021-11-08 20:32:06.708987: validation loss: -0.8333\n",
      "2021-11-08 20:32:06.716379: Average global foreground Dice: [0.845]\n",
      "2021-11-08 20:32:06.721289: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 20:32:08.614362: lr: 0.007811\n",
      "2021-11-08 20:32:08.678990: saving checkpoint...\n",
      "2021-11-08 20:32:09.768816: done, saving took 1.15 seconds\n",
      "2021-11-08 20:32:09.795168: This epoch took 321.569921 s\n",
      "\n",
      "2021-11-08 20:32:09.799454: \n",
      "epoch:  36\n",
      "2021-11-08 20:37:09.285600: train loss : -0.8412\n",
      "2021-11-08 20:37:29.750901: validation loss: -0.8419\n",
      "2021-11-08 20:37:29.756621: Average global foreground Dice: [0.8555]\n",
      "2021-11-08 20:37:29.763602: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 20:37:30.300201: lr: 0.00775\n",
      "2021-11-08 20:37:30.332763: saving checkpoint...\n",
      "2021-11-08 20:37:31.406317: done, saving took 1.10 seconds\n",
      "2021-11-08 20:37:31.430231: This epoch took 321.625547 s\n",
      "\n",
      "2021-11-08 20:37:31.436104: \n",
      "epoch:  37\n",
      "2021-11-08 20:42:25.780238: train loss : -0.8439\n",
      "2021-11-08 20:42:45.080033: validation loss: -0.8380\n",
      "2021-11-08 20:42:45.085261: Average global foreground Dice: [0.8505]\n",
      "2021-11-08 20:42:45.090062: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 20:42:45.603577: lr: 0.007688\n",
      "2021-11-08 20:42:45.636642: saving checkpoint...\n",
      "2021-11-08 20:42:46.704393: done, saving took 1.10 seconds\n",
      "2021-11-08 20:42:46.727757: This epoch took 315.286633 s\n",
      "\n",
      "2021-11-08 20:42:46.733412: \n",
      "epoch:  38\n",
      "2021-11-08 20:47:44.588873: train loss : -0.8456\n",
      "2021-11-08 20:48:05.335078: validation loss: -0.8464\n",
      "2021-11-08 20:48:05.340604: Average global foreground Dice: [0.8637]\n",
      "2021-11-08 20:48:05.344921: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 20:48:05.861123: lr: 0.007626\n",
      "2021-11-08 20:48:05.894733: saving checkpoint...\n",
      "2021-11-08 20:48:06.931959: done, saving took 1.07 seconds\n",
      "2021-11-08 20:48:06.958602: This epoch took 320.220860 s\n",
      "\n",
      "2021-11-08 20:48:06.963323: \n",
      "epoch:  39\n",
      "2021-11-08 20:53:02.073348: train loss : -0.8436\n",
      "2021-11-08 20:53:22.352726: validation loss: -0.8432\n",
      "2021-11-08 20:53:22.358488: Average global foreground Dice: [0.8607]\n",
      "2021-11-08 20:53:22.363189: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 20:53:22.868720: lr: 0.007564\n",
      "2021-11-08 20:53:22.927767: saving checkpoint...\n",
      "2021-11-08 20:53:24.019907: done, saving took 1.15 seconds\n",
      "2021-11-08 20:53:24.046631: This epoch took 317.078616 s\n",
      "\n",
      "2021-11-08 20:53:24.051221: \n",
      "epoch:  40\n",
      "2021-11-08 20:58:22.385198: train loss : -0.8364\n",
      "2021-11-08 20:58:44.399925: validation loss: -0.8305\n",
      "2021-11-08 20:58:44.405079: Average global foreground Dice: [0.8481]\n",
      "2021-11-08 20:58:44.410099: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 20:58:46.679915: lr: 0.007502\n",
      "2021-11-08 20:58:46.766744: saving checkpoint...\n",
      "2021-11-08 20:58:48.107852: done, saving took 1.42 seconds\n",
      "2021-11-08 20:58:48.135593: This epoch took 324.079629 s\n",
      "\n",
      "2021-11-08 20:58:48.140555: \n",
      "epoch:  41\n",
      "2021-11-08 21:03:48.585072: train loss : -0.8425\n",
      "2021-11-08 21:04:10.280547: validation loss: -0.8363\n",
      "2021-11-08 21:04:10.300952: Average global foreground Dice: [0.8565]\n",
      "2021-11-08 21:04:10.305915: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 21:04:12.460330: lr: 0.00744\n",
      "2021-11-08 21:04:12.500306: saving checkpoint...\n",
      "2021-11-08 21:04:13.529450: done, saving took 1.06 seconds\n",
      "2021-11-08 21:04:13.557331: This epoch took 325.412045 s\n",
      "\n",
      "2021-11-08 21:04:13.562251: \n",
      "epoch:  42\n",
      "2021-11-08 21:09:10.673597: train loss : -0.8472\n",
      "2021-11-08 21:09:31.216038: validation loss: -0.8386\n",
      "2021-11-08 21:09:31.221125: Average global foreground Dice: [0.8529]\n",
      "2021-11-08 21:09:31.226103: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 21:09:31.869060: lr: 0.007378\n",
      "2021-11-08 21:09:31.903169: saving checkpoint...\n",
      "2021-11-08 21:09:32.850005: done, saving took 0.98 seconds\n",
      "2021-11-08 21:09:32.872373: This epoch took 319.304961 s\n",
      "\n",
      "2021-11-08 21:09:32.876625: \n",
      "epoch:  43\n",
      "2021-11-08 21:14:26.783491: train loss : -0.8482\n",
      "2021-11-08 21:14:48.292414: validation loss: -0.8329\n",
      "2021-11-08 21:14:48.297997: Average global foreground Dice: [0.8531]\n",
      "2021-11-08 21:14:48.303116: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 21:14:49.066238: lr: 0.007316\n",
      "2021-11-08 21:14:49.098994: saving checkpoint...\n",
      "2021-11-08 21:14:50.038217: done, saving took 0.97 seconds\n",
      "2021-11-08 21:14:50.064468: This epoch took 317.183232 s\n",
      "\n",
      "2021-11-08 21:14:50.068750: \n",
      "epoch:  44\n",
      "2021-11-08 21:19:52.300989: train loss : -0.8463\n",
      "2021-11-08 21:20:14.521374: validation loss: -0.8219\n",
      "2021-11-08 21:20:14.529171: Average global foreground Dice: [0.8458]\n",
      "2021-11-08 21:20:14.560143: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 21:20:17.086166: lr: 0.007254\n",
      "2021-11-08 21:20:17.090823: This epoch took 327.017568 s\n",
      "\n",
      "2021-11-08 21:20:17.094829: \n",
      "epoch:  45\n",
      "2021-11-08 21:25:25.072706: train loss : -0.8447\n",
      "2021-11-08 21:25:43.837477: validation loss: -0.8334\n",
      "2021-11-08 21:25:43.843111: Average global foreground Dice: [0.8496]\n",
      "2021-11-08 21:25:43.848657: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 21:25:44.332732: lr: 0.007192\n",
      "2021-11-08 21:25:44.337301: This epoch took 327.237704 s\n",
      "\n",
      "2021-11-08 21:25:44.342124: \n",
      "epoch:  46\n",
      "2021-11-08 21:30:41.217695: train loss : -0.8450\n",
      "2021-11-08 21:31:01.612748: validation loss: -0.8417\n",
      "2021-11-08 21:31:01.618165: Average global foreground Dice: [0.8595]\n",
      "2021-11-08 21:31:01.623029: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 21:31:02.109995: lr: 0.00713\n",
      "2021-11-08 21:31:02.155432: saving checkpoint...\n",
      "2021-11-08 21:31:03.065821: done, saving took 0.95 seconds\n",
      "2021-11-08 21:31:03.089212: This epoch took 318.742511 s\n",
      "\n",
      "2021-11-08 21:31:03.093629: \n",
      "epoch:  47\n",
      "2021-11-08 21:36:00.603979: train loss : -0.8484\n",
      "2021-11-08 21:36:21.648948: validation loss: -0.8340\n",
      "2021-11-08 21:36:21.654676: Average global foreground Dice: [0.849]\n",
      "2021-11-08 21:36:21.659357: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 21:36:22.188709: lr: 0.007067\n",
      "2021-11-08 21:36:22.193968: This epoch took 319.096242 s\n",
      "\n",
      "2021-11-08 21:36:22.198611: \n",
      "epoch:  48\n",
      "2021-11-08 21:41:17.949974: train loss : -0.8485\n",
      "2021-11-08 21:41:36.276301: validation loss: -0.8202\n",
      "2021-11-08 21:41:36.280981: Average global foreground Dice: [0.8408]\n",
      "2021-11-08 21:41:36.288283: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 21:41:36.842600: lr: 0.007005\n",
      "2021-11-08 21:41:36.847021: This epoch took 314.644557 s\n",
      "\n",
      "2021-11-08 21:41:36.851729: \n",
      "epoch:  49\n",
      "2021-11-08 21:46:36.081944: train loss : -0.8525\n",
      "2021-11-08 21:46:57.800342: validation loss: -0.8233\n",
      "2021-11-08 21:46:57.806085: Average global foreground Dice: [0.8426]\n",
      "2021-11-08 21:46:57.811286: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 21:46:59.215463: lr: 0.006943\n",
      "2021-11-08 21:46:59.220378: saving scheduled checkpoint file...\n",
      "2021-11-08 21:46:59.259678: saving checkpoint...\n",
      "2021-11-08 21:47:00.090520: done, saving took 0.87 seconds\n",
      "2021-11-08 21:47:00.108554: done\n",
      "2021-11-08 21:47:00.113689: This epoch took 323.257703 s\n",
      "\n",
      "2021-11-08 21:47:00.118926: \n",
      "epoch:  50\n",
      "2021-11-08 21:52:00.481710: train loss : -0.8471\n",
      "2021-11-08 21:52:22.464461: validation loss: -0.8410\n",
      "2021-11-08 21:52:22.473392: Average global foreground Dice: [0.8497]\n",
      "2021-11-08 21:52:22.478789: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 21:52:24.897705: lr: 0.00688\n",
      "2021-11-08 21:52:24.903246: This epoch took 324.779007 s\n",
      "\n",
      "2021-11-08 21:52:24.908508: \n",
      "epoch:  51\n",
      "2021-11-08 21:57:28.595884: train loss : -0.8465\n",
      "2021-11-08 21:57:49.885897: validation loss: -0.8305\n",
      "2021-11-08 21:57:49.904180: Average global foreground Dice: [0.8481]\n",
      "2021-11-08 21:57:49.908308: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 21:57:51.058273: lr: 0.006817\n",
      "2021-11-08 21:57:51.063107: This epoch took 326.149435 s\n",
      "\n",
      "2021-11-08 21:57:51.067699: \n",
      "epoch:  52\n",
      "2021-11-08 22:02:52.673163: train loss : -0.8496\n",
      "2021-11-08 22:03:14.110573: validation loss: -0.8308\n",
      "2021-11-08 22:03:14.128953: Average global foreground Dice: [0.843]\n",
      "2021-11-08 22:03:14.159408: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 22:03:15.502742: lr: 0.006755\n",
      "2021-11-08 22:03:15.507084: This epoch took 324.434063 s\n",
      "\n",
      "2021-11-08 22:03:15.511708: \n",
      "epoch:  53\n",
      "2021-11-08 22:08:09.577445: train loss : -0.8506\n",
      "2021-11-08 22:08:30.145294: validation loss: -0.8393\n",
      "2021-11-08 22:08:30.151184: Average global foreground Dice: [0.8461]\n",
      "2021-11-08 22:08:30.156207: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 22:08:30.768789: lr: 0.006692\n",
      "2021-11-08 22:08:30.773340: This epoch took 315.252709 s\n",
      "\n",
      "2021-11-08 22:08:30.778039: \n",
      "epoch:  54\n",
      "2021-11-08 22:13:27.785409: train loss : -0.8483\n",
      "2021-11-08 22:13:48.769945: validation loss: -0.8326\n",
      "2021-11-08 22:13:48.774878: Average global foreground Dice: [0.8516]\n",
      "2021-11-08 22:13:48.779726: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 22:13:49.310071: lr: 0.006629\n",
      "2021-11-08 22:13:49.313882: This epoch took 318.530929 s\n",
      "\n",
      "2021-11-08 22:13:49.318044: \n",
      "epoch:  55\n",
      "2021-11-08 22:18:50.373886: train loss : -0.8491\n",
      "2021-11-08 22:19:12.806520: validation loss: -0.8385\n",
      "2021-11-08 22:19:12.825449: Average global foreground Dice: [0.8514]\n",
      "2021-11-08 22:19:12.831213: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 22:19:15.110338: lr: 0.006566\n",
      "2021-11-08 22:19:15.114952: This epoch took 325.792193 s\n",
      "\n",
      "2021-11-08 22:19:15.119819: \n",
      "epoch:  56\n",
      "2021-11-08 22:24:11.622008: train loss : -0.8531\n",
      "2021-11-08 22:24:32.322067: validation loss: -0.8316\n",
      "2021-11-08 22:24:32.327026: Average global foreground Dice: [0.8471]\n",
      "2021-11-08 22:24:32.331331: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 22:24:32.847403: lr: 0.006504\n",
      "2021-11-08 22:24:32.852007: This epoch took 317.727628 s\n",
      "\n",
      "2021-11-08 22:24:32.856898: \n",
      "epoch:  57\n",
      "2021-11-08 22:29:32.692993: train loss : -0.8475\n",
      "2021-11-08 22:29:55.725980: validation loss: -0.8371\n",
      "2021-11-08 22:29:55.776747: Average global foreground Dice: [0.8517]\n",
      "2021-11-08 22:29:55.780777: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 22:29:57.531639: lr: 0.006441\n",
      "2021-11-08 22:29:57.537043: This epoch took 324.676060 s\n",
      "\n",
      "2021-11-08 22:29:57.542168: \n",
      "epoch:  58\n",
      "2021-11-08 22:34:47.587211: train loss : -0.8494\n",
      "2021-11-08 22:35:05.773318: validation loss: -0.8311\n",
      "2021-11-08 22:35:05.778648: Average global foreground Dice: [0.8439]\n",
      "2021-11-08 22:35:05.783344: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 22:35:06.299062: lr: 0.006378\n",
      "2021-11-08 22:35:06.303752: This epoch took 308.756666 s\n",
      "\n",
      "2021-11-08 22:35:06.308213: \n",
      "epoch:  59\n",
      "2021-11-08 22:40:05.722134: train loss : -0.8479\n",
      "2021-11-08 22:40:26.596591: validation loss: -0.8392\n",
      "2021-11-08 22:40:26.602282: Average global foreground Dice: [0.8578]\n",
      "2021-11-08 22:40:26.607629: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 22:40:27.651415: lr: 0.006314\n",
      "2021-11-08 22:40:27.656326: This epoch took 321.343827 s\n",
      "\n",
      "2021-11-08 22:40:27.660670: \n",
      "epoch:  60\n",
      "2021-11-08 22:45:28.394289: train loss : -0.8519\n",
      "2021-11-08 22:45:50.901953: validation loss: -0.8322\n",
      "2021-11-08 22:45:50.929266: Average global foreground Dice: [0.8512]\n",
      "2021-11-08 22:45:50.959627: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 22:45:52.302218: lr: 0.006251\n",
      "2021-11-08 22:45:52.307115: This epoch took 324.641561 s\n",
      "\n",
      "2021-11-08 22:45:52.312195: \n",
      "epoch:  61\n",
      "2021-11-08 22:50:53.712023: train loss : -0.8494\n",
      "2021-11-08 22:51:16.931898: validation loss: -0.8444\n",
      "2021-11-08 22:51:16.984739: Average global foreground Dice: [0.8604]\n",
      "2021-11-08 22:51:16.988810: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 22:51:18.493350: lr: 0.006188\n",
      "2021-11-08 22:51:18.573612: saving checkpoint...\n",
      "2021-11-08 22:51:19.900964: done, saving took 1.40 seconds\n",
      "2021-11-08 22:51:19.928413: This epoch took 327.612436 s\n",
      "\n",
      "2021-11-08 22:51:19.933412: \n",
      "epoch:  62\n",
      "2021-11-08 22:56:19.782138: train loss : -0.8554\n",
      "2021-11-08 22:56:39.320454: validation loss: -0.8447\n",
      "2021-11-08 22:56:39.326895: Average global foreground Dice: [0.8584]\n",
      "2021-11-08 22:56:39.331800: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 22:56:39.868330: lr: 0.006125\n",
      "2021-11-08 22:56:39.902464: saving checkpoint...\n",
      "2021-11-08 22:56:40.844987: done, saving took 0.97 seconds\n",
      "2021-11-08 22:56:40.871866: This epoch took 320.933076 s\n",
      "\n",
      "2021-11-08 22:56:40.876071: \n",
      "epoch:  63\n",
      "2021-11-08 23:01:40.573164: train loss : -0.8600\n",
      "2021-11-08 23:01:59.098322: validation loss: -0.8448\n",
      "2021-11-08 23:01:59.103719: Average global foreground Dice: [0.8603]\n",
      "2021-11-08 23:01:59.108484: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 23:01:59.639375: lr: 0.006061\n",
      "2021-11-08 23:01:59.696034: saving checkpoint...\n",
      "2021-11-08 23:02:00.656276: done, saving took 1.01 seconds\n",
      "2021-11-08 23:02:00.680748: This epoch took 319.800468 s\n",
      "\n",
      "2021-11-08 23:02:00.686881: \n",
      "epoch:  64\n",
      "2021-11-08 23:06:59.801642: train loss : -0.8563\n",
      "2021-11-08 23:07:20.784758: validation loss: -0.8272\n",
      "2021-11-08 23:07:20.791065: Average global foreground Dice: [0.8465]\n",
      "2021-11-08 23:07:20.796387: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 23:07:21.367484: lr: 0.005998\n",
      "2021-11-08 23:07:21.373002: This epoch took 320.681203 s\n",
      "\n",
      "2021-11-08 23:07:21.377888: \n",
      "epoch:  65\n",
      "2021-11-08 23:12:16.877868: train loss : -0.8582\n",
      "2021-11-08 23:12:36.882266: validation loss: -0.8456\n",
      "2021-11-08 23:12:36.887902: Average global foreground Dice: [0.8604]\n",
      "2021-11-08 23:12:36.893596: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 23:12:37.407622: lr: 0.005934\n",
      "2021-11-08 23:12:37.471944: saving checkpoint...\n",
      "2021-11-08 23:12:38.604791: done, saving took 1.19 seconds\n",
      "2021-11-08 23:12:38.627279: This epoch took 317.243918 s\n",
      "\n",
      "2021-11-08 23:12:38.631686: \n",
      "epoch:  66\n",
      "2021-11-08 23:17:35.497875: train loss : -0.8595\n",
      "2021-11-08 23:17:56.778167: validation loss: -0.8418\n",
      "2021-11-08 23:17:56.797255: Average global foreground Dice: [0.8569]\n",
      "2021-11-08 23:17:56.802554: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 23:17:58.183354: lr: 0.005871\n",
      "2021-11-08 23:17:58.219001: saving checkpoint...\n",
      "2021-11-08 23:17:59.281849: done, saving took 1.09 seconds\n",
      "2021-11-08 23:17:59.308872: This epoch took 320.672679 s\n",
      "\n",
      "2021-11-08 23:17:59.313980: \n",
      "epoch:  67\n",
      "2021-11-08 23:22:57.181560: train loss : -0.8574\n",
      "2021-11-08 23:23:18.887252: validation loss: -0.8439\n",
      "2021-11-08 23:23:18.894932: Average global foreground Dice: [0.8565]\n",
      "2021-11-08 23:23:18.900086: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 23:23:19.922780: lr: 0.005807\n",
      "2021-11-08 23:23:19.972968: saving checkpoint...\n",
      "2021-11-08 23:23:20.959313: done, saving took 1.03 seconds\n",
      "2021-11-08 23:23:20.981321: This epoch took 321.663001 s\n",
      "\n",
      "2021-11-08 23:23:20.986413: \n",
      "epoch:  68\n",
      "2021-11-08 23:28:20.795432: train loss : -0.8617\n",
      "2021-11-08 23:28:41.413264: validation loss: -0.8446\n",
      "2021-11-08 23:28:41.418158: Average global foreground Dice: [0.8565]\n",
      "2021-11-08 23:28:41.422865: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 23:28:41.957133: lr: 0.005743\n",
      "2021-11-08 23:28:41.990343: saving checkpoint...\n",
      "2021-11-08 23:28:43.001353: done, saving took 1.04 seconds\n",
      "2021-11-08 23:28:43.027358: This epoch took 322.036239 s\n",
      "\n",
      "2021-11-08 23:28:43.032250: \n",
      "epoch:  69\n",
      "2021-11-08 23:33:42.380015: train loss : -0.8561\n",
      "2021-11-08 23:34:04.559541: validation loss: -0.8494\n",
      "2021-11-08 23:34:04.564744: Average global foreground Dice: [0.8609]\n",
      "2021-11-08 23:34:04.569751: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 23:34:06.704713: lr: 0.005679\n",
      "2021-11-08 23:34:06.806342: saving checkpoint...\n",
      "2021-11-08 23:34:08.359145: done, saving took 1.65 seconds\n",
      "2021-11-08 23:34:08.384992: This epoch took 325.347447 s\n",
      "\n",
      "2021-11-08 23:34:08.390146: \n",
      "epoch:  70\n",
      "2021-11-08 23:39:06.297500: train loss : -0.8606\n",
      "2021-11-08 23:39:27.115479: validation loss: -0.8479\n",
      "2021-11-08 23:39:27.121159: Average global foreground Dice: [0.8663]\n",
      "2021-11-08 23:39:27.126350: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 23:39:27.665379: lr: 0.005615\n",
      "2021-11-08 23:39:27.698620: saving checkpoint...\n",
      "2021-11-08 23:39:28.625985: done, saving took 0.96 seconds\n",
      "2021-11-08 23:39:28.650304: This epoch took 320.255490 s\n",
      "\n",
      "2021-11-08 23:39:28.654823: \n",
      "epoch:  71\n",
      "2021-11-08 23:44:22.891400: train loss : -0.8613\n",
      "2021-11-08 23:44:43.532774: validation loss: -0.8431\n",
      "2021-11-08 23:44:43.538105: Average global foreground Dice: [0.8587]\n",
      "2021-11-08 23:44:43.542763: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 23:44:44.051560: lr: 0.005551\n",
      "2021-11-08 23:44:44.084322: saving checkpoint...\n",
      "2021-11-08 23:44:45.100812: done, saving took 1.04 seconds\n",
      "2021-11-08 23:44:45.132053: This epoch took 316.472613 s\n",
      "\n",
      "2021-11-08 23:44:45.136043: \n",
      "epoch:  72\n",
      "2021-11-08 23:49:44.205447: train loss : -0.8606\n",
      "2021-11-08 23:50:06.129095: validation loss: -0.8440\n",
      "2021-11-08 23:50:06.165247: Average global foreground Dice: [0.8564]\n",
      "2021-11-08 23:50:06.169906: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 23:50:08.560727: lr: 0.005487\n",
      "2021-11-08 23:50:08.615385: saving checkpoint...\n",
      "2021-11-08 23:50:09.934588: done, saving took 1.37 seconds\n",
      "2021-11-08 23:50:09.969817: This epoch took 324.829412 s\n",
      "\n",
      "2021-11-08 23:50:09.974214: \n",
      "epoch:  73\n",
      "2021-11-08 23:55:10.694905: train loss : -0.8572\n",
      "2021-11-08 23:55:30.514085: validation loss: -0.8375\n",
      "2021-11-08 23:55:30.520165: Average global foreground Dice: [0.8517]\n",
      "2021-11-08 23:55:30.524700: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-08 23:55:31.067075: lr: 0.005423\n",
      "2021-11-08 23:55:31.072427: This epoch took 321.093689 s\n",
      "\n",
      "2021-11-08 23:55:31.077478: \n",
      "epoch:  74\n",
      "2021-11-09 00:00:29.588654: train loss : -0.8595\n",
      "2021-11-09 00:00:50.224861: validation loss: -0.8203\n",
      "2021-11-09 00:00:50.232246: Average global foreground Dice: [0.8348]\n",
      "2021-11-09 00:00:50.237034: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 00:00:50.742631: lr: 0.005359\n",
      "2021-11-09 00:00:50.747184: This epoch took 319.665784 s\n",
      "\n",
      "2021-11-09 00:00:50.752612: \n",
      "epoch:  75\n",
      "2021-11-09 00:05:47.135050: train loss : -0.8604\n",
      "2021-11-09 00:06:05.854975: validation loss: -0.8365\n",
      "2021-11-09 00:06:05.862011: Average global foreground Dice: [0.8535]\n",
      "2021-11-09 00:06:05.868904: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 00:06:06.376446: lr: 0.005295\n",
      "2021-11-09 00:06:06.381720: This epoch took 315.622053 s\n",
      "\n",
      "2021-11-09 00:06:06.386014: \n",
      "epoch:  76\n",
      "2021-11-09 00:11:03.973362: train loss : -0.8613\n",
      "2021-11-09 00:11:25.277544: validation loss: -0.8534\n",
      "2021-11-09 00:11:25.284176: Average global foreground Dice: [0.8667]\n",
      "2021-11-09 00:11:25.288517: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 00:11:25.924546: lr: 0.00523\n",
      "2021-11-09 00:11:25.929199: This epoch took 319.538680 s\n",
      "\n",
      "2021-11-09 00:11:25.933673: \n",
      "epoch:  77\n",
      "2021-11-09 00:16:21.909369: train loss : -0.8577\n",
      "2021-11-09 00:16:42.188135: validation loss: -0.8342\n",
      "2021-11-09 00:16:42.193869: Average global foreground Dice: [0.8485]\n",
      "2021-11-09 00:16:42.198144: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 00:16:42.758175: lr: 0.005166\n",
      "2021-11-09 00:16:42.763519: This epoch took 316.825574 s\n",
      "\n",
      "2021-11-09 00:16:42.768302: \n",
      "epoch:  78\n",
      "2021-11-09 00:21:41.805382: train loss : -0.8584\n",
      "2021-11-09 00:22:01.015677: validation loss: -0.8441\n",
      "2021-11-09 00:22:01.022238: Average global foreground Dice: [0.8568]\n",
      "2021-11-09 00:22:01.026890: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 00:22:01.561963: lr: 0.005101\n",
      "2021-11-09 00:22:01.566220: This epoch took 318.793112 s\n",
      "\n",
      "2021-11-09 00:22:01.570987: \n",
      "epoch:  79\n",
      "2021-11-09 00:27:02.509208: train loss : -0.8626\n",
      "2021-11-09 00:27:24.694903: validation loss: -0.8532\n",
      "2021-11-09 00:27:24.700809: Average global foreground Dice: [0.8656]\n",
      "2021-11-09 00:27:24.705792: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 00:27:25.893078: lr: 0.005036\n",
      "2021-11-09 00:27:25.897952: This epoch took 324.322027 s\n",
      "\n",
      "2021-11-09 00:27:25.902646: \n",
      "epoch:  80\n",
      "2021-11-09 00:32:23.186028: train loss : -0.8635\n",
      "2021-11-09 00:32:44.694575: validation loss: -0.8325\n",
      "2021-11-09 00:32:44.715179: Average global foreground Dice: [0.8484]\n",
      "2021-11-09 00:32:44.720248: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 00:32:46.202940: lr: 0.004971\n",
      "2021-11-09 00:32:46.211102: This epoch took 320.303702 s\n",
      "\n",
      "2021-11-09 00:32:46.225408: \n",
      "epoch:  81\n",
      "2021-11-09 00:37:47.214889: train loss : -0.8628\n",
      "2021-11-09 00:38:08.783942: validation loss: -0.8444\n",
      "2021-11-09 00:38:08.795621: Average global foreground Dice: [0.8582]\n",
      "2021-11-09 00:38:08.799975: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 00:38:11.130095: lr: 0.004907\n",
      "2021-11-09 00:38:11.159946: This epoch took 324.924913 s\n",
      "\n",
      "2021-11-09 00:38:11.165365: \n",
      "epoch:  82\n",
      "2021-11-09 00:43:10.411754: train loss : -0.8616\n",
      "2021-11-09 00:43:30.564594: validation loss: -0.8422\n",
      "2021-11-09 00:43:30.569945: Average global foreground Dice: [0.8542]\n",
      "2021-11-09 00:43:30.574929: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 00:43:31.083104: lr: 0.004842\n",
      "2021-11-09 00:43:31.088814: This epoch took 319.918596 s\n",
      "\n",
      "2021-11-09 00:43:31.093240: \n",
      "epoch:  83\n",
      "2021-11-09 00:48:26.962225: train loss : -0.8612\n",
      "2021-11-09 00:48:45.509504: validation loss: -0.8360\n",
      "2021-11-09 00:48:45.513969: Average global foreground Dice: [0.8506]\n",
      "2021-11-09 00:48:45.519696: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 00:48:46.057136: lr: 0.004776\n",
      "2021-11-09 00:48:46.061984: This epoch took 314.962240 s\n",
      "\n",
      "2021-11-09 00:48:46.066674: \n",
      "epoch:  84\n",
      "2021-11-09 00:53:39.686057: train loss : -0.8656\n",
      "2021-11-09 00:53:57.695745: validation loss: -0.8356\n",
      "2021-11-09 00:53:57.702375: Average global foreground Dice: [0.854]\n",
      "2021-11-09 00:53:57.707428: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 00:53:58.237855: lr: 0.004711\n",
      "2021-11-09 00:53:58.243380: This epoch took 312.172271 s\n",
      "\n",
      "2021-11-09 00:53:58.247998: \n",
      "epoch:  85\n",
      "2021-11-09 00:58:52.788699: train loss : -0.8654\n",
      "2021-11-09 00:59:13.668564: validation loss: -0.8359\n",
      "2021-11-09 00:59:13.674647: Average global foreground Dice: [0.8539]\n",
      "2021-11-09 00:59:13.679039: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 00:59:14.210734: lr: 0.004646\n",
      "2021-11-09 00:59:14.215403: This epoch took 315.963114 s\n",
      "\n",
      "2021-11-09 00:59:14.220159: \n",
      "epoch:  86\n",
      "2021-11-09 01:04:16.005816: train loss : -0.8645\n",
      "2021-11-09 01:04:38.583033: validation loss: -0.8504\n",
      "2021-11-09 01:04:38.613752: Average global foreground Dice: [0.8619]\n",
      "2021-11-09 01:04:38.618819: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 01:04:41.176583: lr: 0.004581\n",
      "2021-11-09 01:04:41.185603: This epoch took 326.961337 s\n",
      "\n",
      "2021-11-09 01:04:41.192727: \n",
      "epoch:  87\n",
      "2021-11-09 01:09:38.603765: train loss : -0.8649\n",
      "2021-11-09 01:09:59.694229: validation loss: -0.8392\n",
      "2021-11-09 01:09:59.698706: Average global foreground Dice: [0.8572]\n",
      "2021-11-09 01:09:59.703092: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 01:10:00.237675: lr: 0.004515\n",
      "2021-11-09 01:10:00.241940: This epoch took 319.044457 s\n",
      "\n",
      "2021-11-09 01:10:00.246041: \n",
      "epoch:  88\n",
      "2021-11-09 01:15:03.312073: train loss : -0.8642\n",
      "2021-11-09 01:15:26.876518: validation loss: -0.8461\n",
      "2021-11-09 01:15:26.890826: Average global foreground Dice: [0.8615]\n",
      "2021-11-09 01:15:26.897124: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 01:15:28.837803: lr: 0.00445\n",
      "2021-11-09 01:15:29.032498: saving checkpoint...\n",
      "2021-11-09 01:15:30.871748: done, saving took 2.01 seconds\n",
      "2021-11-09 01:15:30.912963: This epoch took 330.662225 s\n",
      "\n",
      "2021-11-09 01:15:30.919811: \n",
      "epoch:  89\n",
      "2021-11-09 01:20:40.173546: train loss : -0.8627\n",
      "2021-11-09 01:21:01.613281: validation loss: -0.8381\n",
      "2021-11-09 01:21:01.625677: Average global foreground Dice: [0.8531]\n",
      "2021-11-09 01:21:01.668145: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 01:21:05.069169: lr: 0.004384\n",
      "2021-11-09 01:21:05.074633: This epoch took 334.150927 s\n",
      "\n",
      "2021-11-09 01:21:05.078759: \n",
      "epoch:  90\n",
      "2021-11-09 01:26:08.932804: train loss : -0.8692\n",
      "2021-11-09 01:26:31.983914: validation loss: -0.8493\n",
      "2021-11-09 01:26:31.990492: Average global foreground Dice: [0.8626]\n",
      "2021-11-09 01:26:31.994988: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 01:26:33.763689: lr: 0.004318\n",
      "2021-11-09 01:26:33.810755: saving checkpoint...\n",
      "2021-11-09 01:26:35.123716: done, saving took 1.35 seconds\n",
      "2021-11-09 01:26:35.160538: This epoch took 330.076518 s\n",
      "\n",
      "2021-11-09 01:26:35.164961: \n",
      "epoch:  91\n",
      "2021-11-09 01:31:30.985418: train loss : -0.8660\n",
      "2021-11-09 01:31:52.492925: validation loss: -0.8374\n",
      "2021-11-09 01:31:52.518903: Average global foreground Dice: [0.8557]\n",
      "2021-11-09 01:31:52.524077: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 01:31:54.021624: lr: 0.004252\n",
      "2021-11-09 01:31:54.027324: This epoch took 318.856722 s\n",
      "\n",
      "2021-11-09 01:31:54.031404: \n",
      "epoch:  92\n",
      "2021-11-09 01:37:05.259426: train loss : -0.8671\n",
      "2021-11-09 01:37:26.995084: validation loss: -0.8449\n",
      "2021-11-09 01:37:27.016725: Average global foreground Dice: [0.8634]\n",
      "2021-11-09 01:37:27.023710: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 01:37:29.476093: lr: 0.004186\n",
      "2021-11-09 01:37:29.576760: saving checkpoint...\n",
      "2021-11-09 01:37:31.579615: done, saving took 2.10 seconds\n",
      "2021-11-09 01:37:31.605843: This epoch took 337.569715 s\n",
      "\n",
      "2021-11-09 01:37:31.610666: \n",
      "epoch:  93\n",
      "2021-11-09 01:43:01.810165: train loss : -0.8679\n",
      "2021-11-09 01:43:24.029670: validation loss: -0.8377\n",
      "2021-11-09 01:43:24.076217: Average global foreground Dice: [0.8605]\n",
      "2021-11-09 01:43:24.081277: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 01:43:27.261142: lr: 0.00412\n",
      "2021-11-09 01:43:27.315459: saving checkpoint...\n",
      "2021-11-09 01:43:29.459687: done, saving took 2.19 seconds\n",
      "2021-11-09 01:43:29.490571: This epoch took 357.875357 s\n",
      "\n",
      "2021-11-09 01:43:29.495597: \n",
      "epoch:  94\n",
      "2021-11-09 01:48:55.117994: train loss : -0.8690\n",
      "2021-11-09 01:49:18.076955: validation loss: -0.8428\n",
      "2021-11-09 01:49:18.092692: Average global foreground Dice: [0.8587]\n",
      "2021-11-09 01:49:18.097422: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 01:49:20.702789: lr: 0.004054\n",
      "2021-11-09 01:49:20.902399: saving checkpoint...\n",
      "2021-11-09 01:49:22.517475: done, saving took 1.81 seconds\n",
      "2021-11-09 01:49:22.578807: This epoch took 353.078003 s\n",
      "\n",
      "2021-11-09 01:49:22.584002: \n",
      "epoch:  95\n",
      "2021-11-09 01:54:30.281114: train loss : -0.8690\n",
      "2021-11-09 01:54:52.470013: validation loss: -0.8443\n",
      "2021-11-09 01:54:52.492567: Average global foreground Dice: [0.8613]\n",
      "2021-11-09 01:54:52.500297: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 01:54:54.324287: lr: 0.003987\n",
      "2021-11-09 01:54:54.520434: saving checkpoint...\n",
      "2021-11-09 01:54:56.296955: done, saving took 1.97 seconds\n",
      "2021-11-09 01:54:56.376728: This epoch took 333.788776 s\n",
      "\n",
      "2021-11-09 01:54:56.381980: \n",
      "epoch:  96\n",
      "2021-11-09 02:00:01.187392: train loss : -0.8697\n",
      "2021-11-09 02:00:23.119753: validation loss: -0.8436\n",
      "2021-11-09 02:00:23.160149: Average global foreground Dice: [0.8584]\n",
      "2021-11-09 02:00:23.165122: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 02:00:25.426265: lr: 0.003921\n",
      "2021-11-09 02:00:25.497817: saving checkpoint...\n",
      "2021-11-09 02:00:27.600456: done, saving took 2.14 seconds\n",
      "2021-11-09 02:00:27.625080: This epoch took 331.238102 s\n",
      "\n",
      "2021-11-09 02:00:27.630468: \n",
      "epoch:  97\n",
      "2021-11-09 02:05:32.193398: train loss : -0.8650\n",
      "2021-11-09 02:05:54.088338: validation loss: -0.8497\n",
      "2021-11-09 02:05:54.094037: Average global foreground Dice: [0.8646]\n",
      "2021-11-09 02:05:54.098497: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 02:05:56.003596: lr: 0.003854\n",
      "2021-11-09 02:05:56.071853: saving checkpoint...\n",
      "2021-11-09 02:05:57.392218: done, saving took 1.38 seconds\n",
      "2021-11-09 02:05:57.419666: This epoch took 329.760000 s\n",
      "\n",
      "2021-11-09 02:05:57.424252: \n",
      "epoch:  98\n",
      "2021-11-09 02:10:52.112034: train loss : -0.8692\n",
      "2021-11-09 02:11:14.408175: validation loss: -0.8488\n",
      "2021-11-09 02:11:14.425001: Average global foreground Dice: [0.8649]\n",
      "2021-11-09 02:11:14.429846: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 02:11:16.126004: lr: 0.003787\n",
      "2021-11-09 02:11:16.205087: saving checkpoint...\n",
      "2021-11-09 02:11:17.727416: done, saving took 1.60 seconds\n",
      "2021-11-09 02:11:17.763771: This epoch took 320.334718 s\n",
      "\n",
      "2021-11-09 02:11:17.768286: \n",
      "epoch:  99\n",
      "2021-11-09 02:16:18.187431: train loss : -0.8681\n",
      "2021-11-09 02:16:40.169774: validation loss: -0.8454\n",
      "2021-11-09 02:16:40.184227: Average global foreground Dice: [0.8595]\n",
      "2021-11-09 02:16:40.188725: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 02:16:41.812896: lr: 0.00372\n",
      "2021-11-09 02:16:41.818257: saving scheduled checkpoint file...\n",
      "2021-11-09 02:16:41.876551: saving checkpoint...\n",
      "2021-11-09 02:16:43.240820: done, saving took 1.42 seconds\n",
      "2021-11-09 02:16:43.295483: done\n",
      "2021-11-09 02:16:43.332416: saving checkpoint...\n",
      "2021-11-09 02:16:44.377927: done, saving took 1.08 seconds\n",
      "2021-11-09 02:16:44.413100: This epoch took 326.640479 s\n",
      "\n",
      "2021-11-09 02:16:44.417544: \n",
      "epoch:  100\n",
      "2021-11-09 02:21:45.203091: train loss : -0.8691\n",
      "2021-11-09 02:22:07.411105: validation loss: -0.8336\n",
      "2021-11-09 02:22:07.425116: Average global foreground Dice: [0.8561]\n",
      "2021-11-09 02:22:07.430161: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 02:22:09.900736: lr: 0.003653\n",
      "2021-11-09 02:22:09.905422: This epoch took 325.483182 s\n",
      "\n",
      "2021-11-09 02:22:09.910007: \n",
      "epoch:  101\n",
      "2021-11-09 02:27:07.672941: train loss : -0.8678\n",
      "2021-11-09 02:27:29.087376: validation loss: -0.8443\n",
      "2021-11-09 02:27:29.105200: Average global foreground Dice: [0.8589]\n",
      "2021-11-09 02:27:29.113032: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 02:27:30.467064: lr: 0.003586\n",
      "2021-11-09 02:27:30.471385: This epoch took 320.555928 s\n",
      "\n",
      "2021-11-09 02:27:30.476320: \n",
      "epoch:  102\n",
      "2021-11-09 02:32:22.777568: train loss : -0.8728\n",
      "2021-11-09 02:32:41.830233: validation loss: -0.8400\n",
      "2021-11-09 02:32:41.835716: Average global foreground Dice: [0.8577]\n",
      "2021-11-09 02:32:41.840139: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 02:32:42.446038: lr: 0.003519\n",
      "2021-11-09 02:32:42.453912: This epoch took 311.972022 s\n",
      "\n",
      "2021-11-09 02:32:42.461424: \n",
      "epoch:  103\n",
      "2021-11-09 02:37:45.001739: train loss : -0.8682\n",
      "2021-11-09 02:38:06.730000: validation loss: -0.8375\n",
      "2021-11-09 02:38:06.760176: Average global foreground Dice: [0.8533]\n",
      "2021-11-09 02:38:06.764379: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 02:38:08.902980: lr: 0.003451\n",
      "2021-11-09 02:38:08.907684: This epoch took 326.437983 s\n",
      "\n",
      "2021-11-09 02:38:08.911892: \n",
      "epoch:  104\n",
      "2021-11-09 02:43:07.700384: train loss : -0.8705\n",
      "2021-11-09 02:43:29.289369: validation loss: -0.8489\n",
      "2021-11-09 02:43:29.296359: Average global foreground Dice: [0.8595]\n",
      "2021-11-09 02:43:29.303389: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 02:43:30.302042: lr: 0.003384\n",
      "2021-11-09 02:43:30.307284: This epoch took 321.390378 s\n",
      "\n",
      "2021-11-09 02:43:30.311975: \n",
      "epoch:  105\n",
      "2021-11-09 02:48:27.591415: train loss : -0.8720\n",
      "2021-11-09 02:48:50.226709: validation loss: -0.8374\n",
      "2021-11-09 02:48:50.265543: Average global foreground Dice: [0.8541]\n",
      "2021-11-09 02:48:50.270250: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 02:48:52.235955: lr: 0.003316\n",
      "2021-11-09 02:48:52.264206: This epoch took 321.947422 s\n",
      "\n",
      "2021-11-09 02:48:52.269446: \n",
      "epoch:  106\n",
      "2021-11-09 02:53:47.751062: train loss : -0.8727\n",
      "2021-11-09 02:54:06.157785: validation loss: -0.8503\n",
      "2021-11-09 02:54:06.167492: Average global foreground Dice: [0.8618]\n",
      "2021-11-09 02:54:06.176142: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 02:54:06.700407: lr: 0.003248\n",
      "2021-11-09 02:54:06.707592: This epoch took 314.432915 s\n",
      "\n",
      "2021-11-09 02:54:06.713837: \n",
      "epoch:  107\n",
      "2021-11-09 02:59:06.655966: train loss : -0.8711\n",
      "2021-11-09 02:59:24.909794: validation loss: -0.8502\n",
      "2021-11-09 02:59:24.918593: Average global foreground Dice: [0.8629]\n",
      "2021-11-09 02:59:24.925808: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 02:59:25.504237: lr: 0.00318\n",
      "2021-11-09 02:59:25.512826: This epoch took 318.791607 s\n",
      "\n",
      "2021-11-09 02:59:25.520303: \n",
      "epoch:  108\n",
      "2021-11-09 03:04:23.912014: train loss : -0.8714\n",
      "2021-11-09 03:04:45.286723: validation loss: -0.8408\n",
      "2021-11-09 03:04:45.294759: Average global foreground Dice: [0.8573]\n",
      "2021-11-09 03:04:45.302992: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 03:04:46.048954: lr: 0.003112\n",
      "2021-11-09 03:04:46.058187: This epoch took 320.530864 s\n",
      "\n",
      "2021-11-09 03:04:46.065755: \n",
      "epoch:  109\n",
      "2021-11-09 03:09:43.984787: train loss : -0.8751\n",
      "2021-11-09 03:10:05.032925: validation loss: -0.8501\n",
      "2021-11-09 03:10:05.040967: Average global foreground Dice: [0.8614]\n",
      "2021-11-09 03:10:05.065650: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 03:10:05.710993: lr: 0.003043\n",
      "2021-11-09 03:10:05.718451: This epoch took 319.645817 s\n",
      "\n",
      "2021-11-09 03:10:05.724984: \n",
      "epoch:  110\n",
      "2021-11-09 03:15:04.577168: train loss : -0.8743\n",
      "2021-11-09 03:15:27.233738: validation loss: -0.8465\n",
      "2021-11-09 03:15:27.281135: Average global foreground Dice: [0.8646]\n",
      "2021-11-09 03:15:27.290368: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 03:15:28.821420: lr: 0.002975\n",
      "2021-11-09 03:15:28.933267: saving checkpoint...\n",
      "2021-11-09 03:15:30.204098: done, saving took 1.37 seconds\n",
      "2021-11-09 03:15:30.261386: This epoch took 324.529538 s\n",
      "\n",
      "2021-11-09 03:15:30.268835: \n",
      "epoch:  111\n",
      "2021-11-09 03:20:27.290872: train loss : -0.8744\n",
      "2021-11-09 03:20:45.510219: validation loss: -0.8420\n",
      "2021-11-09 03:20:45.518180: Average global foreground Dice: [0.8605]\n",
      "2021-11-09 03:20:45.524446: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 03:20:46.072277: lr: 0.002906\n",
      "2021-11-09 03:20:46.141502: saving checkpoint...\n",
      "2021-11-09 03:20:47.225161: done, saving took 1.15 seconds\n",
      "2021-11-09 03:20:47.259869: This epoch took 316.983250 s\n",
      "\n",
      "2021-11-09 03:20:47.266978: \n",
      "epoch:  112\n",
      "2021-11-09 03:25:44.986271: train loss : -0.8734\n",
      "2021-11-09 03:26:06.372857: validation loss: -0.8453\n",
      "2021-11-09 03:26:06.380685: Average global foreground Dice: [0.8629]\n",
      "2021-11-09 03:26:06.387516: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 03:26:07.269813: lr: 0.002837\n",
      "2021-11-09 03:26:07.309004: saving checkpoint...\n",
      "2021-11-09 03:26:08.418519: done, saving took 1.14 seconds\n",
      "2021-11-09 03:26:08.442199: This epoch took 321.168628 s\n",
      "\n",
      "2021-11-09 03:26:08.448809: \n",
      "epoch:  113\n",
      "2021-11-09 03:31:09.279606: train loss : -0.8715\n",
      "2021-11-09 03:31:31.225954: validation loss: -0.8522\n",
      "2021-11-09 03:31:31.266272: Average global foreground Dice: [0.8666]\n",
      "2021-11-09 03:31:31.272688: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 03:31:33.416261: lr: 0.002768\n",
      "2021-11-09 03:31:33.484699: saving checkpoint...\n",
      "2021-11-09 03:31:34.868110: done, saving took 1.45 seconds\n",
      "2021-11-09 03:31:34.898635: This epoch took 326.443101 s\n",
      "\n",
      "2021-11-09 03:31:34.904415: \n",
      "epoch:  114\n",
      "2021-11-09 03:36:35.501036: train loss : -0.8708\n",
      "2021-11-09 03:36:57.675334: validation loss: -0.8422\n",
      "2021-11-09 03:36:57.714890: Average global foreground Dice: [0.8584]\n",
      "2021-11-09 03:36:57.723844: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 03:37:00.284992: lr: 0.002699\n",
      "2021-11-09 03:37:00.291483: This epoch took 325.381016 s\n",
      "\n",
      "2021-11-09 03:37:00.297285: \n",
      "epoch:  115\n",
      "2021-11-09 03:42:01.565092: train loss : -0.8725\n",
      "2021-11-09 03:42:21.085622: validation loss: -0.8321\n",
      "2021-11-09 03:42:21.099247: Average global foreground Dice: [0.8486]\n",
      "2021-11-09 03:42:21.108529: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 03:42:21.632734: lr: 0.002629\n",
      "2021-11-09 03:42:21.639570: This epoch took 321.336019 s\n",
      "\n",
      "2021-11-09 03:42:21.645917: \n",
      "epoch:  116\n",
      "2021-11-09 03:47:17.279900: train loss : -0.8732\n",
      "2021-11-09 03:47:36.988926: validation loss: -0.8481\n",
      "2021-11-09 03:47:36.995276: Average global foreground Dice: [0.864]\n",
      "2021-11-09 03:47:37.001019: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 03:47:37.541235: lr: 0.00256\n",
      "2021-11-09 03:47:37.550338: This epoch took 315.897331 s\n",
      "\n",
      "2021-11-09 03:47:37.556978: \n",
      "epoch:  117\n",
      "2021-11-09 03:52:34.029524: train loss : -0.8765\n",
      "2021-11-09 03:52:52.088724: validation loss: -0.8485\n",
      "2021-11-09 03:52:52.096180: Average global foreground Dice: [0.8609]\n",
      "2021-11-09 03:52:52.102945: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 03:52:52.599072: lr: 0.00249\n",
      "2021-11-09 03:52:52.608392: This epoch took 315.044621 s\n",
      "\n",
      "2021-11-09 03:52:52.614620: \n",
      "epoch:  118\n",
      "2021-11-09 03:57:55.596928: train loss : -0.8739\n",
      "2021-11-09 03:58:17.623766: validation loss: -0.8488\n",
      "2021-11-09 03:58:17.630488: Average global foreground Dice: [0.8618]\n",
      "2021-11-09 03:58:17.659632: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 03:58:18.705915: lr: 0.00242\n",
      "2021-11-09 03:58:18.712619: This epoch took 326.091872 s\n",
      "\n",
      "2021-11-09 03:58:18.720006: \n",
      "epoch:  119\n",
      "2021-11-09 04:03:19.489407: train loss : -0.8767\n",
      "2021-11-09 04:03:39.636484: validation loss: -0.8530\n",
      "2021-11-09 04:03:39.643739: Average global foreground Dice: [0.8681]\n",
      "2021-11-09 04:03:39.650044: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 04:03:40.220411: lr: 0.002349\n",
      "2021-11-09 04:03:40.287507: saving checkpoint...\n",
      "2021-11-09 04:03:41.349711: done, saving took 1.12 seconds\n",
      "2021-11-09 04:03:41.387759: This epoch took 322.661395 s\n",
      "\n",
      "2021-11-09 04:03:41.395416: \n",
      "epoch:  120\n",
      "2021-11-09 04:08:43.385868: train loss : -0.8737\n",
      "2021-11-09 04:09:04.980258: validation loss: -0.8200\n",
      "2021-11-09 04:09:04.995842: Average global foreground Dice: [0.8406]\n",
      "2021-11-09 04:09:05.002054: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 04:09:06.040978: lr: 0.002279\n",
      "2021-11-09 04:09:06.047292: This epoch took 324.645266 s\n",
      "\n",
      "2021-11-09 04:09:06.053888: \n",
      "epoch:  121\n",
      "2021-11-09 04:14:01.606730: train loss : -0.8769\n",
      "2021-11-09 04:14:21.009240: validation loss: -0.8403\n",
      "2021-11-09 04:14:21.016319: Average global foreground Dice: [0.8576]\n",
      "2021-11-09 04:14:21.023085: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 04:14:21.567737: lr: 0.002208\n",
      "2021-11-09 04:14:21.574225: This epoch took 315.513327 s\n",
      "\n",
      "2021-11-09 04:14:21.581724: \n",
      "epoch:  122\n",
      "2021-11-09 04:19:31.885781: train loss : -0.8760\n",
      "2021-11-09 04:19:54.714938: validation loss: -0.8313\n",
      "2021-11-09 04:19:54.790262: Average global foreground Dice: [0.8536]\n",
      "2021-11-09 04:19:54.797726: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 04:19:57.961946: lr: 0.002137\n",
      "2021-11-09 04:19:57.971915: This epoch took 336.383498 s\n",
      "\n",
      "2021-11-09 04:19:57.981795: \n",
      "epoch:  123\n",
      "2021-11-09 04:25:16.878392: train loss : -0.8756\n",
      "2021-11-09 04:25:39.026352: validation loss: -0.8409\n",
      "2021-11-09 04:25:39.065700: Average global foreground Dice: [0.8567]\n",
      "2021-11-09 04:25:39.071501: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 04:25:41.372611: lr: 0.002065\n",
      "2021-11-09 04:25:41.383082: This epoch took 343.390807 s\n",
      "\n",
      "2021-11-09 04:25:41.392691: \n",
      "epoch:  124\n",
      "2021-11-09 04:30:43.067151: train loss : -0.8771\n",
      "2021-11-09 04:31:05.009833: validation loss: -0.8479\n",
      "2021-11-09 04:31:05.026822: Average global foreground Dice: [0.8602]\n",
      "2021-11-09 04:31:05.059608: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 04:31:07.262038: lr: 0.001994\n",
      "2021-11-09 04:31:07.269222: This epoch took 325.866080 s\n",
      "\n",
      "2021-11-09 04:31:07.275253: \n",
      "epoch:  125\n",
      "2021-11-09 04:36:10.119766: train loss : -0.8802\n",
      "2021-11-09 04:36:31.728437: validation loss: -0.8516\n",
      "2021-11-09 04:36:31.766303: Average global foreground Dice: [0.8675]\n",
      "2021-11-09 04:36:31.775041: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 04:36:33.466287: lr: 0.001922\n",
      "2021-11-09 04:36:33.473530: This epoch took 326.191458 s\n",
      "\n",
      "2021-11-09 04:36:33.480735: \n",
      "epoch:  126\n",
      "2021-11-09 04:41:35.398106: train loss : -0.8770\n",
      "2021-11-09 04:41:56.884840: validation loss: -0.8480\n",
      "2021-11-09 04:41:56.891812: Average global foreground Dice: [0.8656]\n",
      "2021-11-09 04:41:56.898837: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 04:41:59.161655: lr: 0.00185\n",
      "2021-11-09 04:41:59.169140: This epoch took 325.681431 s\n",
      "\n",
      "2021-11-09 04:41:59.175520: \n",
      "epoch:  127\n",
      "2021-11-09 04:47:00.373288: train loss : -0.8807\n",
      "2021-11-09 04:47:21.712836: validation loss: -0.8408\n",
      "2021-11-09 04:47:21.723304: Average global foreground Dice: [0.854]\n",
      "2021-11-09 04:47:21.731915: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 04:47:22.749819: lr: 0.001777\n",
      "2021-11-09 04:47:22.762278: This epoch took 323.580024 s\n",
      "\n",
      "2021-11-09 04:47:22.772333: \n",
      "epoch:  128\n",
      "2021-11-09 04:52:21.085746: train loss : -0.8814\n",
      "2021-11-09 04:52:43.080502: validation loss: -0.8359\n",
      "2021-11-09 04:52:43.099129: Average global foreground Dice: [0.8535]\n",
      "2021-11-09 04:52:43.105695: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 04:52:46.561481: lr: 0.001704\n",
      "2021-11-09 04:52:46.567835: This epoch took 323.786889 s\n",
      "\n",
      "2021-11-09 04:52:46.575610: \n",
      "epoch:  129\n",
      "2021-11-09 04:57:46.807984: train loss : -0.8772\n",
      "2021-11-09 04:58:09.008419: validation loss: -0.8465\n",
      "2021-11-09 04:58:09.060165: Average global foreground Dice: [0.8608]\n",
      "2021-11-09 04:58:09.068061: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 04:58:10.128053: lr: 0.001631\n",
      "2021-11-09 04:58:10.135152: This epoch took 323.549902 s\n",
      "\n",
      "2021-11-09 04:58:10.144231: \n",
      "epoch:  130\n",
      "2021-11-09 05:03:09.687590: train loss : -0.8790\n",
      "2021-11-09 05:03:30.095563: validation loss: -0.8481\n",
      "2021-11-09 05:03:30.102989: Average global foreground Dice: [0.8635]\n",
      "2021-11-09 05:03:30.109489: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 05:03:30.666264: lr: 0.001557\n",
      "2021-11-09 05:03:30.673072: This epoch took 320.520809 s\n",
      "\n",
      "2021-11-09 05:03:30.680207: \n",
      "epoch:  131\n",
      "2021-11-09 05:08:27.170603: train loss : -0.8795\n",
      "2021-11-09 05:08:47.460162: validation loss: -0.8470\n",
      "2021-11-09 05:08:47.466371: Average global foreground Dice: [0.8655]\n",
      "2021-11-09 05:08:47.472910: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 05:08:47.990177: lr: 0.001483\n",
      "2021-11-09 05:08:47.997578: This epoch took 317.311027 s\n",
      "\n",
      "2021-11-09 05:08:48.003644: \n",
      "epoch:  132\n",
      "2021-11-09 05:13:51.878671: train loss : -0.8801\n",
      "2021-11-09 05:14:13.699046: validation loss: -0.8411\n",
      "2021-11-09 05:14:13.724854: Average global foreground Dice: [0.8551]\n",
      "2021-11-09 05:14:13.731841: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 05:14:17.091155: lr: 0.001409\n",
      "2021-11-09 05:14:17.097663: This epoch took 329.088299 s\n",
      "\n",
      "2021-11-09 05:14:17.103970: \n",
      "epoch:  133\n",
      "2021-11-09 05:19:21.070272: train loss : -0.8833\n",
      "2021-11-09 05:19:42.685151: validation loss: -0.8417\n",
      "2021-11-09 05:19:42.698760: Average global foreground Dice: [0.8585]\n",
      "2021-11-09 05:19:42.705070: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 05:19:44.091927: lr: 0.001334\n",
      "2021-11-09 05:19:44.104276: This epoch took 326.993119 s\n",
      "\n",
      "2021-11-09 05:19:44.117081: \n",
      "epoch:  134\n",
      "2021-11-09 05:24:48.294997: train loss : -0.8806\n",
      "2021-11-09 05:25:10.996109: validation loss: -0.8450\n",
      "2021-11-09 05:25:11.021927: Average global foreground Dice: [0.8601]\n",
      "2021-11-09 05:25:11.028826: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 05:25:12.920879: lr: 0.001259\n",
      "2021-11-09 05:25:12.927677: This epoch took 328.804240 s\n",
      "\n",
      "2021-11-09 05:25:12.959604: \n",
      "epoch:  135\n",
      "2021-11-09 05:30:16.010602: train loss : -0.8826\n",
      "2021-11-09 05:30:37.914226: validation loss: -0.8505\n",
      "2021-11-09 05:30:37.923553: Average global foreground Dice: [0.8641]\n",
      "2021-11-09 05:30:37.959588: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 05:30:38.859535: lr: 0.001183\n",
      "2021-11-09 05:30:38.866996: This epoch took 325.899676 s\n",
      "\n",
      "2021-11-09 05:30:38.873483: \n",
      "epoch:  136\n",
      "2021-11-09 05:35:34.373288: train loss : -0.8825\n",
      "2021-11-09 05:35:56.303011: validation loss: -0.8492\n",
      "2021-11-09 05:35:56.322011: Average global foreground Dice: [0.8629]\n",
      "2021-11-09 05:35:56.328423: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 05:35:57.850293: lr: 0.001107\n",
      "2021-11-09 05:35:57.856593: This epoch took 318.977250 s\n",
      "\n",
      "2021-11-09 05:35:57.863806: \n",
      "epoch:  137\n",
      "2021-11-09 05:41:09.291973: train loss : -0.8808\n",
      "2021-11-09 05:41:30.699450: validation loss: -0.8377\n",
      "2021-11-09 05:41:30.725679: Average global foreground Dice: [0.8525]\n",
      "2021-11-09 05:41:30.759567: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 05:41:32.260352: lr: 0.00103\n",
      "2021-11-09 05:41:32.269457: This epoch took 334.398383 s\n",
      "\n",
      "2021-11-09 05:41:32.277080: \n",
      "epoch:  138\n",
      "2021-11-09 05:46:45.325358: train loss : -0.8822\n",
      "2021-11-09 05:47:07.561390: validation loss: -0.8452\n",
      "2021-11-09 05:47:07.574588: Average global foreground Dice: [0.8595]\n",
      "2021-11-09 05:47:07.581773: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 05:47:09.860323: lr: 0.000952\n",
      "2021-11-09 05:47:09.867930: This epoch took 337.583336 s\n",
      "\n",
      "2021-11-09 05:47:09.875127: \n",
      "epoch:  139\n",
      "2021-11-09 05:52:19.687930: train loss : -0.8794\n",
      "2021-11-09 05:52:41.898347: validation loss: -0.8441\n",
      "2021-11-09 05:52:41.919719: Average global foreground Dice: [0.8605]\n",
      "2021-11-09 05:52:41.929391: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 05:52:44.399692: lr: 0.000874\n",
      "2021-11-09 05:52:44.406125: This epoch took 334.523812 s\n",
      "\n",
      "2021-11-09 05:52:44.412378: \n",
      "epoch:  140\n",
      "2021-11-09 05:57:45.388682: train loss : -0.8823\n",
      "2021-11-09 05:58:06.659313: validation loss: -0.8470\n",
      "2021-11-09 05:58:06.666353: Average global foreground Dice: [0.8604]\n",
      "2021-11-09 05:58:06.672160: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 05:58:08.833171: lr: 0.000795\n",
      "2021-11-09 05:58:08.838999: This epoch took 324.419479 s\n",
      "\n",
      "2021-11-09 05:58:08.846444: \n",
      "epoch:  141\n",
      "2021-11-09 06:03:06.420704: train loss : -0.8858\n",
      "2021-11-09 06:03:26.058624: validation loss: -0.8411\n",
      "2021-11-09 06:03:26.067102: Average global foreground Dice: [0.8563]\n",
      "2021-11-09 06:03:26.075776: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 06:03:26.595672: lr: 0.000715\n",
      "2021-11-09 06:03:26.604432: This epoch took 317.751508 s\n",
      "\n",
      "2021-11-09 06:03:26.612144: \n",
      "epoch:  142\n",
      "2021-11-09 06:08:25.663168: train loss : -0.8841\n",
      "2021-11-09 06:08:46.710509: validation loss: -0.8502\n",
      "2021-11-09 06:08:46.717070: Average global foreground Dice: [0.8663]\n",
      "2021-11-09 06:08:46.722743: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 06:08:47.346737: lr: 0.000634\n",
      "2021-11-09 06:08:47.353539: This epoch took 320.733249 s\n",
      "\n",
      "2021-11-09 06:08:47.359990: \n",
      "epoch:  143\n",
      "2021-11-09 06:13:43.970561: train loss : -0.8838\n",
      "2021-11-09 06:14:03.035502: validation loss: -0.8477\n",
      "2021-11-09 06:14:03.043883: Average global foreground Dice: [0.8589]\n",
      "2021-11-09 06:14:03.053244: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 06:14:03.566268: lr: 0.000552\n",
      "2021-11-09 06:14:03.572033: This epoch took 316.205619 s\n",
      "\n",
      "2021-11-09 06:14:03.578287: \n",
      "epoch:  144\n",
      "2021-11-09 06:19:06.485678: train loss : -0.8855\n",
      "2021-11-09 06:19:28.116555: validation loss: -0.8509\n",
      "2021-11-09 06:19:28.124476: Average global foreground Dice: [0.8649]\n",
      "2021-11-09 06:19:28.159261: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 06:19:30.061958: lr: 0.000468\n",
      "2021-11-09 06:19:30.069029: This epoch took 326.483523 s\n",
      "\n",
      "2021-11-09 06:19:30.076176: \n",
      "epoch:  145\n",
      "2021-11-09 06:24:28.973123: train loss : -0.8854\n",
      "2021-11-09 06:24:47.449485: validation loss: -0.8509\n",
      "2021-11-09 06:24:47.457188: Average global foreground Dice: [0.8588]\n",
      "2021-11-09 06:24:47.464135: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 06:24:47.994063: lr: 0.000383\n",
      "2021-11-09 06:24:48.002358: This epoch took 317.918610 s\n",
      "\n",
      "2021-11-09 06:24:48.009480: \n",
      "epoch:  146\n",
      "2021-11-09 06:29:46.568361: train loss : -0.8835\n",
      "2021-11-09 06:30:05.948646: validation loss: -0.8487\n",
      "2021-11-09 06:30:05.955441: Average global foreground Dice: [0.8583]\n",
      "2021-11-09 06:30:05.962440: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 06:30:06.487184: lr: 0.000296\n",
      "2021-11-09 06:30:06.496742: This epoch took 318.480885 s\n",
      "\n",
      "2021-11-09 06:30:06.506221: \n",
      "epoch:  147\n",
      "2021-11-09 06:35:00.176974: train loss : -0.8860\n",
      "2021-11-09 06:35:19.527867: validation loss: -0.8421\n",
      "2021-11-09 06:35:19.535737: Average global foreground Dice: [0.856]\n",
      "2021-11-09 06:35:19.542206: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 06:35:20.049138: lr: 0.000205\n",
      "2021-11-09 06:35:20.055461: This epoch took 313.540518 s\n",
      "\n",
      "2021-11-09 06:35:20.061768: \n",
      "epoch:  148\n",
      "2021-11-09 06:40:18.985344: train loss : -0.8864\n",
      "2021-11-09 06:40:41.075709: validation loss: -0.8495\n",
      "2021-11-09 06:40:41.101591: Average global foreground Dice: [0.8624]\n",
      "2021-11-09 06:40:41.108303: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 06:40:42.729246: lr: 0.00011\n",
      "2021-11-09 06:40:42.737164: This epoch took 322.668468 s\n",
      "\n",
      "2021-11-09 06:40:42.759923: \n",
      "epoch:  149\n",
      "2021-11-09 06:45:39.506403: train loss : -0.8856\n",
      "2021-11-09 06:46:00.311452: validation loss: -0.8456\n",
      "2021-11-09 06:46:00.318701: Average global foreground Dice: [0.8595]\n",
      "2021-11-09 06:46:00.324628: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 06:46:00.844348: lr: 0.0\n",
      "2021-11-09 06:46:00.851712: saving scheduled checkpoint file...\n",
      "2021-11-09 06:46:00.886631: saving checkpoint...\n",
      "2021-11-09 06:46:01.968068: done, saving took 1.11 seconds\n",
      "2021-11-09 06:46:02.021545: done\n",
      "2021-11-09 06:46:02.032191: This epoch took 319.265345 s\n",
      "\n",
      "2021-11-09 06:46:02.070681: saving checkpoint...\n",
      "2021-11-09 06:46:02.847812: done, saving took 0.81 seconds\n",
      "23090558_20120330 (3, 263, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 263, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 7], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090564_20130312 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090568_20121018 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090569_20120607 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120613 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150908 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090593_20120625 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130103 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090600_20121108 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090603_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090607_20120420 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090609_20120510 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160119 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160510 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090646_20120718 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-09 06:49:29.812228: finished prediction\n",
      "2021-11-09 06:49:29.818701: evaluation of raw predictions\n",
      "2021-11-09 06:49:31.325085: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8543258202938879\n",
      "after:  0.8543258202938879\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Model 6 (epoch 150)\n",
    "\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 0\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 1\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 2\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 3\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-09 06:56:37.500978: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-09 06:56:37.521390: The split file contains 5 splits.\n",
      "2021-11-09 06:56:37.524716: Desired fold for training: 0\n",
      "2021-11-09 06:56:37.528817: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-09 06:56:41.934675: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-09 06:57:00.202174: Unable to plot network architecture:\n",
      "2021-11-09 06:57:00.206656: No module named 'hiddenlayer'\n",
      "2021-11-09 06:57:00.211711: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-09 06:57:00.216527: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-09 06:57:00.228377: \n",
      "\n",
      "2021-11-09 06:57:00.259676: \n",
      "epoch:  0\n",
      "2021-11-09 07:02:38.575303: train loss : -0.1954\n",
      "2021-11-09 07:03:00.870420: validation loss: -0.5968\n",
      "2021-11-09 07:03:00.896557: Average global foreground Dice: [0.6313]\n",
      "2021-11-09 07:03:00.901417: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 07:03:03.093827: lr: 0.00991\n",
      "2021-11-09 07:03:03.098432: This epoch took 362.834654 s\n",
      "\n",
      "2021-11-09 07:03:03.103088: \n",
      "epoch:  1\n",
      "2021-11-09 07:08:02.973235: train loss : -0.5990\n",
      "2021-11-09 07:08:23.416475: validation loss: -0.6751\n",
      "2021-11-09 07:08:23.427410: Average global foreground Dice: [0.7268]\n",
      "2021-11-09 07:08:23.434264: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 07:08:23.944548: lr: 0.00982\n",
      "2021-11-09 07:08:24.028455: saving checkpoint...\n",
      "2021-11-09 07:08:24.856512: done, saving took 0.91 seconds\n",
      "2021-11-09 07:08:24.883880: This epoch took 321.776045 s\n",
      "\n",
      "2021-11-09 07:08:24.888595: \n",
      "epoch:  2\n",
      "2021-11-09 07:13:21.966970: train loss : -0.6710\n",
      "2021-11-09 07:13:41.523608: validation loss: -0.7443\n",
      "2021-11-09 07:13:41.529331: Average global foreground Dice: [0.7796]\n",
      "2021-11-09 07:13:41.533160: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 07:13:42.074664: lr: 0.00973\n",
      "2021-11-09 07:13:42.147314: saving checkpoint...\n",
      "2021-11-09 07:13:43.265035: done, saving took 1.19 seconds\n",
      "2021-11-09 07:13:43.302953: This epoch took 318.410789 s\n",
      "\n",
      "2021-11-09 07:13:43.309566: \n",
      "epoch:  3\n",
      "2021-11-09 07:18:29.564411: train loss : -0.7010\n",
      "2021-11-09 07:18:48.427844: validation loss: -0.7634\n",
      "2021-11-09 07:18:48.432317: Average global foreground Dice: [0.7877]\n",
      "2021-11-09 07:18:48.436939: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 07:18:48.964857: lr: 0.009639\n",
      "2021-11-09 07:18:49.026642: saving checkpoint...\n",
      "2021-11-09 07:18:50.105479: done, saving took 1.14 seconds\n",
      "2021-11-09 07:18:50.151774: This epoch took 306.835385 s\n",
      "\n",
      "2021-11-09 07:18:50.155995: \n",
      "epoch:  4\n",
      "2021-11-09 07:23:48.593032: train loss : -0.7292\n",
      "2021-11-09 07:24:09.043620: validation loss: -0.7865\n",
      "2021-11-09 07:24:09.048507: Average global foreground Dice: [0.8155]\n",
      "2021-11-09 07:24:09.052863: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 07:24:09.581055: lr: 0.009549\n",
      "2021-11-09 07:24:09.659913: saving checkpoint...\n",
      "2021-11-09 07:24:10.735973: done, saving took 1.15 seconds\n",
      "2021-11-09 07:24:10.779733: This epoch took 320.619140 s\n",
      "\n",
      "2021-11-09 07:24:10.785517: \n",
      "epoch:  5\n",
      "2021-11-09 07:29:09.085043: train loss : -0.7500\n",
      "2021-11-09 07:29:29.731718: validation loss: -0.7947\n",
      "2021-11-09 07:29:29.736038: Average global foreground Dice: [0.8186]\n",
      "2021-11-09 07:29:29.739558: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 07:29:30.264692: lr: 0.009458\n",
      "2021-11-09 07:29:30.331348: saving checkpoint...\n",
      "2021-11-09 07:29:31.468321: done, saving took 1.20 seconds\n",
      "2021-11-09 07:29:31.495843: This epoch took 320.704466 s\n",
      "\n",
      "2021-11-09 07:29:31.500198: \n",
      "epoch:  6\n",
      "2021-11-09 07:34:28.985368: train loss : -0.7603\n",
      "2021-11-09 07:34:51.024161: validation loss: -0.8162\n",
      "2021-11-09 07:34:51.060135: Average global foreground Dice: [0.8366]\n",
      "2021-11-09 07:34:51.064433: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 07:34:53.260244: lr: 0.009368\n",
      "2021-11-09 07:34:53.305552: saving checkpoint...\n",
      "2021-11-09 07:34:55.259983: done, saving took 2.00 seconds\n",
      "2021-11-09 07:34:55.304189: This epoch took 323.799266 s\n",
      "\n",
      "2021-11-09 07:34:55.307844: \n",
      "epoch:  7\n",
      "2021-11-09 07:39:52.282486: train loss : -0.7789\n",
      "2021-11-09 07:40:12.543764: validation loss: -0.8135\n",
      "2021-11-09 07:40:12.549220: Average global foreground Dice: [0.8336]\n",
      "2021-11-09 07:40:12.553225: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 07:40:13.062331: lr: 0.009277\n",
      "2021-11-09 07:40:13.125427: saving checkpoint...\n",
      "2021-11-09 07:40:14.248953: done, saving took 1.18 seconds\n",
      "2021-11-09 07:40:14.297033: This epoch took 318.985501 s\n",
      "\n",
      "2021-11-09 07:40:14.303691: \n",
      "epoch:  8\n",
      "2021-11-09 07:45:11.100892: train loss : -0.7746\n",
      "2021-11-09 07:45:30.251520: validation loss: -0.8088\n",
      "2021-11-09 07:45:30.257011: Average global foreground Dice: [0.8324]\n",
      "2021-11-09 07:45:30.261053: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 07:45:30.758261: lr: 0.009186\n",
      "2021-11-09 07:45:30.828551: saving checkpoint...\n",
      "2021-11-09 07:45:31.956733: done, saving took 1.19 seconds\n",
      "2021-11-09 07:45:31.980868: This epoch took 317.670506 s\n",
      "\n",
      "2021-11-09 07:45:31.985440: \n",
      "epoch:  9\n",
      "2021-11-09 07:50:26.773070: train loss : -0.7854\n",
      "2021-11-09 07:50:47.671199: validation loss: -0.8304\n",
      "2021-11-09 07:50:47.697327: Average global foreground Dice: [0.8516]\n",
      "2021-11-09 07:50:47.704934: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 07:50:49.316971: lr: 0.009095\n",
      "2021-11-09 07:50:49.399438: saving checkpoint...\n",
      "2021-11-09 07:50:50.488244: done, saving took 1.16 seconds\n",
      "2021-11-09 07:50:50.517084: This epoch took 318.526841 s\n",
      "\n",
      "2021-11-09 07:50:50.522082: \n",
      "epoch:  10\n",
      "2021-11-09 07:55:44.786276: train loss : -0.7935\n",
      "2021-11-09 07:56:04.723326: validation loss: -0.8268\n",
      "2021-11-09 07:56:04.728589: Average global foreground Dice: [0.8496]\n",
      "2021-11-09 07:56:04.733474: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 07:56:05.242792: lr: 0.009004\n",
      "2021-11-09 07:56:05.316212: saving checkpoint...\n",
      "2021-11-09 07:56:06.432510: done, saving took 1.18 seconds\n",
      "2021-11-09 07:56:06.469770: This epoch took 315.942698 s\n",
      "\n",
      "2021-11-09 07:56:06.474699: \n",
      "epoch:  11\n",
      "2021-11-09 08:01:06.025960: train loss : -0.7972\n",
      "2021-11-09 08:01:28.588804: validation loss: -0.8261\n",
      "2021-11-09 08:01:28.606768: Average global foreground Dice: [0.8445]\n",
      "2021-11-09 08:01:28.620273: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 08:01:30.727102: lr: 0.008913\n",
      "2021-11-09 08:01:30.916088: saving checkpoint...\n",
      "2021-11-09 08:01:32.400792: done, saving took 1.64 seconds\n",
      "2021-11-09 08:01:32.432430: This epoch took 325.951388 s\n",
      "\n",
      "2021-11-09 08:01:32.440023: \n",
      "epoch:  12\n",
      "2021-11-09 08:06:32.921303: train loss : -0.8016\n",
      "2021-11-09 08:06:55.399928: validation loss: -0.8379\n",
      "2021-11-09 08:06:55.405635: Average global foreground Dice: [0.854]\n",
      "2021-11-09 08:06:55.410729: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 08:06:57.202350: lr: 0.008822\n",
      "2021-11-09 08:06:57.306990: saving checkpoint...\n",
      "2021-11-09 08:06:58.553170: done, saving took 1.35 seconds\n",
      "2021-11-09 08:06:58.603274: This epoch took 326.155753 s\n",
      "\n",
      "2021-11-09 08:06:58.607396: \n",
      "epoch:  13\n",
      "2021-11-09 08:11:56.486083: train loss : -0.8112\n",
      "2021-11-09 08:12:18.886189: validation loss: -0.8297\n",
      "2021-11-09 08:12:18.905207: Average global foreground Dice: [0.8425]\n",
      "2021-11-09 08:12:18.909552: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 08:12:20.664859: lr: 0.008731\n",
      "2021-11-09 08:12:20.820618: saving checkpoint...\n",
      "2021-11-09 08:12:22.294358: done, saving took 1.62 seconds\n",
      "2021-11-09 08:12:22.334534: This epoch took 323.722895 s\n",
      "\n",
      "2021-11-09 08:12:22.339142: \n",
      "epoch:  14\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-09 08:17:19.814344: train loss : -0.8092\n",
      "2021-11-09 08:17:41.415884: validation loss: -0.8256\n",
      "2021-11-09 08:17:41.421262: Average global foreground Dice: [0.8444]\n",
      "2021-11-09 08:17:41.426169: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 08:17:42.620768: lr: 0.008639\n",
      "2021-11-09 08:17:42.654759: saving checkpoint...\n",
      "2021-11-09 08:17:43.869733: done, saving took 1.24 seconds\n",
      "2021-11-09 08:17:43.897808: This epoch took 321.553836 s\n",
      "\n",
      "2021-11-09 08:17:43.902677: \n",
      "epoch:  15\n",
      "2021-11-09 08:22:40.472968: train loss : -0.8064\n",
      "2021-11-09 08:23:03.259320: validation loss: -0.8368\n",
      "2021-11-09 08:23:03.269218: Average global foreground Dice: [0.8535]\n",
      "2021-11-09 08:23:03.274246: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 08:23:05.499316: lr: 0.008548\n",
      "2021-11-09 08:23:05.580723: saving checkpoint...\n",
      "2021-11-09 08:23:07.901984: done, saving took 2.40 seconds\n",
      "2021-11-09 08:23:07.927270: This epoch took 324.019465 s\n",
      "\n",
      "2021-11-09 08:23:07.931866: \n",
      "epoch:  16\n",
      "2021-11-09 08:28:08.992603: train loss : -0.8084\n",
      "2021-11-09 08:28:31.205732: validation loss: -0.8340\n",
      "2021-11-09 08:28:31.220979: Average global foreground Dice: [0.8538]\n",
      "2021-11-09 08:28:31.227703: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 08:28:33.701969: lr: 0.008456\n",
      "2021-11-09 08:28:33.782880: saving checkpoint...\n",
      "2021-11-09 08:28:35.675974: done, saving took 1.97 seconds\n",
      "2021-11-09 08:28:35.713394: This epoch took 327.749110 s\n",
      "\n",
      "2021-11-09 08:28:35.717709: \n",
      "epoch:  17\n",
      "2021-11-09 08:33:32.283330: train loss : -0.8136\n",
      "2021-11-09 08:33:53.895309: validation loss: -0.8318\n",
      "2021-11-09 08:33:53.918979: Average global foreground Dice: [0.851]\n",
      "2021-11-09 08:33:53.925520: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 08:33:55.460285: lr: 0.008364\n",
      "2021-11-09 08:33:55.507048: saving checkpoint...\n",
      "2021-11-09 08:33:57.566498: done, saving took 2.10 seconds\n",
      "2021-11-09 08:33:57.613774: This epoch took 321.891361 s\n",
      "\n",
      "2021-11-09 08:33:57.618023: \n",
      "epoch:  18\n",
      "2021-11-09 08:38:55.504946: train loss : -0.8141\n",
      "2021-11-09 08:39:17.804871: validation loss: -0.8505\n",
      "2021-11-09 08:39:17.824564: Average global foreground Dice: [0.8649]\n",
      "2021-11-09 08:39:17.830090: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 08:39:19.860297: lr: 0.008272\n",
      "2021-11-09 08:39:19.991346: saving checkpoint...\n",
      "2021-11-09 08:39:21.351989: done, saving took 1.49 seconds\n",
      "2021-11-09 08:39:21.382258: This epoch took 323.759485 s\n",
      "\n",
      "2021-11-09 08:39:21.387134: \n",
      "epoch:  19\n",
      "2021-11-09 08:44:15.576035: train loss : -0.8210\n",
      "2021-11-09 08:44:37.999638: validation loss: -0.8436\n",
      "2021-11-09 08:44:38.005430: Average global foreground Dice: [0.8593]\n",
      "2021-11-09 08:44:38.010298: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 08:44:40.308316: lr: 0.008181\n",
      "2021-11-09 08:44:40.379003: saving checkpoint...\n",
      "2021-11-09 08:44:42.286975: done, saving took 1.97 seconds\n",
      "2021-11-09 08:44:42.314059: This epoch took 320.921873 s\n",
      "\n",
      "2021-11-09 08:44:42.318803: \n",
      "epoch:  20\n",
      "2021-11-09 08:49:41.597988: train loss : -0.8135\n",
      "2021-11-09 08:50:02.985335: validation loss: -0.8481\n",
      "2021-11-09 08:50:02.996730: Average global foreground Dice: [0.8628]\n",
      "2021-11-09 08:50:03.001047: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 08:50:04.931031: lr: 0.008088\n",
      "2021-11-09 08:50:05.010601: saving checkpoint...\n",
      "2021-11-09 08:50:06.971148: done, saving took 2.01 seconds\n",
      "2021-11-09 08:50:07.007997: This epoch took 324.684536 s\n",
      "\n",
      "2021-11-09 08:50:07.013055: \n",
      "epoch:  21\n",
      "2021-11-09 08:54:59.748325: train loss : -0.8235\n",
      "2021-11-09 08:55:18.522359: validation loss: -0.8380\n",
      "2021-11-09 08:55:18.527017: Average global foreground Dice: [0.8532]\n",
      "2021-11-09 08:55:18.532315: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 08:55:19.054072: lr: 0.007996\n",
      "2021-11-09 08:55:19.103111: saving checkpoint...\n",
      "2021-11-09 08:55:20.237100: done, saving took 1.18 seconds\n",
      "2021-11-09 08:55:20.292650: This epoch took 313.274543 s\n",
      "\n",
      "2021-11-09 08:55:20.297309: \n",
      "epoch:  22\n",
      "2021-11-09 09:00:17.280728: train loss : -0.8241\n",
      "2021-11-09 09:00:39.590789: validation loss: -0.8355\n",
      "2021-11-09 09:00:39.612287: Average global foreground Dice: [0.8533]\n",
      "2021-11-09 09:00:39.622617: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 09:00:41.245610: lr: 0.007904\n",
      "2021-11-09 09:00:41.327466: saving checkpoint...\n",
      "2021-11-09 09:00:42.533702: done, saving took 1.27 seconds\n",
      "2021-11-09 09:00:42.560081: This epoch took 322.257403 s\n",
      "\n",
      "2021-11-09 09:00:42.565181: \n",
      "epoch:  23\n",
      "2021-11-09 09:05:41.791830: train loss : -0.8287\n",
      "2021-11-09 09:06:02.029792: validation loss: -0.8480\n",
      "2021-11-09 09:06:02.036199: Average global foreground Dice: [0.8607]\n",
      "2021-11-09 09:06:02.045414: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 09:06:02.583317: lr: 0.007811\n",
      "2021-11-09 09:06:02.646205: saving checkpoint...\n",
      "2021-11-09 09:06:03.762967: done, saving took 1.18 seconds\n",
      "2021-11-09 09:06:03.790832: This epoch took 321.220643 s\n",
      "\n",
      "2021-11-09 09:06:03.795552: \n",
      "epoch:  24\n",
      "2021-11-09 09:10:57.384981: train loss : -0.8263\n",
      "2021-11-09 09:11:16.967215: validation loss: -0.8495\n",
      "2021-11-09 09:11:16.974498: Average global foreground Dice: [0.8641]\n",
      "2021-11-09 09:11:16.979064: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 09:11:17.464358: lr: 0.007719\n",
      "2021-11-09 09:11:17.526741: saving checkpoint...\n",
      "2021-11-09 09:11:18.599626: done, saving took 1.13 seconds\n",
      "2021-11-09 09:11:18.630515: This epoch took 314.830750 s\n",
      "\n",
      "2021-11-09 09:11:18.634421: \n",
      "epoch:  25\n",
      "2021-11-09 09:16:15.074388: train loss : -0.8253\n",
      "2021-11-09 09:16:36.465662: validation loss: -0.8472\n",
      "2021-11-09 09:16:36.483943: Average global foreground Dice: [0.8643]\n",
      "2021-11-09 09:16:36.488855: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 09:16:38.052820: lr: 0.007626\n",
      "2021-11-09 09:16:38.125918: saving checkpoint...\n",
      "2021-11-09 09:16:39.245506: done, saving took 1.19 seconds\n",
      "2021-11-09 09:16:39.286196: This epoch took 320.647770 s\n",
      "\n",
      "2021-11-09 09:16:39.292228: \n",
      "epoch:  26\n",
      "2021-11-09 09:21:35.585316: train loss : -0.8325\n",
      "2021-11-09 09:21:57.130531: validation loss: -0.8444\n",
      "2021-11-09 09:21:57.136009: Average global foreground Dice: [0.8604]\n",
      "2021-11-09 09:21:57.140914: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 09:21:57.874583: lr: 0.007533\n",
      "2021-11-09 09:21:57.952818: saving checkpoint...\n",
      "2021-11-09 09:21:59.113793: done, saving took 1.23 seconds\n",
      "2021-11-09 09:21:59.137334: This epoch took 319.839876 s\n",
      "\n",
      "2021-11-09 09:21:59.142395: \n",
      "epoch:  27\n",
      "2021-11-09 09:26:52.181419: train loss : -0.8301\n",
      "2021-11-09 09:27:12.208863: validation loss: -0.8483\n",
      "2021-11-09 09:27:12.213527: Average global foreground Dice: [0.8627]\n",
      "2021-11-09 09:27:12.221699: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 09:27:12.712313: lr: 0.00744\n",
      "2021-11-09 09:27:12.745423: saving checkpoint...\n",
      "2021-11-09 09:27:13.780571: done, saving took 1.06 seconds\n",
      "2021-11-09 09:27:13.805553: This epoch took 314.658395 s\n",
      "\n",
      "2021-11-09 09:27:13.809793: \n",
      "epoch:  28\n",
      "2021-11-09 09:32:07.463887: train loss : -0.8273\n",
      "2021-11-09 09:32:27.312526: validation loss: -0.8397\n",
      "2021-11-09 09:32:27.320604: Average global foreground Dice: [0.855]\n",
      "2021-11-09 09:32:27.327340: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 09:32:27.848223: lr: 0.007347\n",
      "2021-11-09 09:32:27.881552: saving checkpoint...\n",
      "2021-11-09 09:32:28.891805: done, saving took 1.04 seconds\n",
      "2021-11-09 09:32:28.916942: This epoch took 315.103377 s\n",
      "\n",
      "2021-11-09 09:32:28.921706: \n",
      "epoch:  29\n",
      "2021-11-09 09:37:24.797467: train loss : -0.8333\n",
      "2021-11-09 09:37:48.223434: validation loss: -0.8492\n",
      "2021-11-09 09:37:48.229302: Average global foreground Dice: [0.8637]\n",
      "2021-11-09 09:37:48.259621: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 09:37:50.398597: lr: 0.007254\n",
      "2021-11-09 09:37:50.493649: saving checkpoint...\n",
      "2021-11-09 09:37:53.059862: done, saving took 2.66 seconds\n",
      "2021-11-09 09:37:53.101576: This epoch took 324.174845 s\n",
      "\n",
      "2021-11-09 09:37:53.108088: \n",
      "epoch:  30\n",
      "2021-11-09 09:43:01.009363: train loss : -0.8267\n",
      "2021-11-09 09:43:22.323373: validation loss: -0.8470\n",
      "2021-11-09 09:43:22.327578: Average global foreground Dice: [0.8581]\n",
      "2021-11-09 09:43:22.332147: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 09:43:22.886574: lr: 0.007161\n",
      "2021-11-09 09:43:22.921116: saving checkpoint...\n",
      "2021-11-09 09:43:23.859497: done, saving took 0.97 seconds\n",
      "2021-11-09 09:43:23.885256: This epoch took 330.772482 s\n",
      "\n",
      "2021-11-09 09:43:23.890471: \n",
      "epoch:  31\n",
      "2021-11-09 09:48:20.372974: train loss : -0.8300\n",
      "2021-11-09 09:48:40.938566: validation loss: -0.8431\n",
      "2021-11-09 09:48:40.944391: Average global foreground Dice: [0.8578]\n",
      "2021-11-09 09:48:40.948544: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 09:48:41.448628: lr: 0.007067\n",
      "2021-11-09 09:48:41.482457: saving checkpoint...\n",
      "2021-11-09 09:48:42.554347: done, saving took 1.10 seconds\n",
      "2021-11-09 09:48:42.589704: This epoch took 318.694245 s\n",
      "\n",
      "2021-11-09 09:48:42.594926: \n",
      "epoch:  32\n",
      "2021-11-09 09:53:50.285956: train loss : -0.8337\n",
      "2021-11-09 09:54:12.798583: validation loss: -0.8406\n",
      "2021-11-09 09:54:12.805366: Average global foreground Dice: [0.8515]\n",
      "2021-11-09 09:54:12.810488: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 09:54:14.860272: lr: 0.006974\n",
      "2021-11-09 09:54:15.013062: saving checkpoint...\n",
      "2021-11-09 09:54:17.159620: done, saving took 2.29 seconds\n",
      "2021-11-09 09:54:17.189664: This epoch took 334.589627 s\n",
      "\n",
      "2021-11-09 09:54:17.194401: \n",
      "epoch:  33\n",
      "2021-11-09 09:59:14.485540: train loss : -0.8342\n",
      "2021-11-09 09:59:35.242417: validation loss: -0.8335\n",
      "2021-11-09 09:59:35.247695: Average global foreground Dice: [0.8485]\n",
      "2021-11-09 09:59:35.252376: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 09:59:35.778949: lr: 0.00688\n",
      "2021-11-09 09:59:35.842008: saving checkpoint...\n",
      "2021-11-09 09:59:36.978208: done, saving took 1.19 seconds\n",
      "2021-11-09 09:59:37.001510: This epoch took 319.802272 s\n",
      "\n",
      "2021-11-09 09:59:37.006137: \n",
      "epoch:  34\n",
      "2021-11-09 10:04:29.873763: train loss : -0.8365\n",
      "2021-11-09 10:04:48.061815: validation loss: -0.8505\n",
      "2021-11-09 10:04:48.067643: Average global foreground Dice: [0.8645]\n",
      "2021-11-09 10:04:48.072962: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 10:04:48.571332: lr: 0.006786\n",
      "2021-11-09 10:04:48.643909: saving checkpoint...\n",
      "2021-11-09 10:04:49.582090: done, saving took 1.00 seconds\n",
      "2021-11-09 10:04:49.638312: This epoch took 312.627851 s\n",
      "\n",
      "2021-11-09 10:04:49.644503: \n",
      "epoch:  35\n",
      "2021-11-09 10:09:52.174128: train loss : -0.8314\n",
      "2021-11-09 10:10:15.078205: validation loss: -0.8495\n",
      "2021-11-09 10:10:15.083770: Average global foreground Dice: [0.8624]\n",
      "2021-11-09 10:10:15.088868: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 10:10:17.417625: lr: 0.006692\n",
      "2021-11-09 10:10:17.608712: saving checkpoint...\n",
      "2021-11-09 10:10:19.920105: done, saving took 2.50 seconds\n",
      "2021-11-09 10:10:19.970366: This epoch took 330.317565 s\n",
      "\n",
      "2021-11-09 10:10:19.975420: \n",
      "epoch:  36\n",
      "2021-11-09 10:15:15.995873: train loss : -0.8339\n",
      "2021-11-09 10:15:34.683143: validation loss: -0.8462\n",
      "2021-11-09 10:15:34.688710: Average global foreground Dice: [0.8592]\n",
      "2021-11-09 10:15:34.693528: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 10:15:35.187477: lr: 0.006598\n",
      "2021-11-09 10:15:35.251171: saving checkpoint...\n",
      "2021-11-09 10:15:36.325227: done, saving took 1.13 seconds\n",
      "2021-11-09 10:15:36.352119: This epoch took 316.370103 s\n",
      "\n",
      "2021-11-09 10:15:36.356988: \n",
      "epoch:  37\n",
      "2021-11-09 10:20:37.190029: train loss : -0.8348\n",
      "2021-11-09 10:20:58.782595: validation loss: -0.8430\n",
      "2021-11-09 10:20:58.800808: Average global foreground Dice: [0.8588]\n",
      "2021-11-09 10:20:58.804982: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 10:21:00.384241: lr: 0.006504\n",
      "2021-11-09 10:21:00.524796: saving checkpoint...\n",
      "2021-11-09 10:21:02.380023: done, saving took 1.99 seconds\n",
      "2021-11-09 10:21:02.414631: This epoch took 326.053278 s\n",
      "\n",
      "2021-11-09 10:21:02.418744: \n",
      "epoch:  38\n",
      "2021-11-09 10:25:57.265039: train loss : -0.8353\n",
      "2021-11-09 10:26:17.046865: validation loss: -0.8512\n",
      "2021-11-09 10:26:17.051982: Average global foreground Dice: [0.8641]\n",
      "2021-11-09 10:26:17.056042: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 10:26:17.556354: lr: 0.006409\n",
      "2021-11-09 10:26:17.620593: saving checkpoint...\n",
      "2021-11-09 10:26:18.612886: done, saving took 1.05 seconds\n",
      "2021-11-09 10:26:18.647755: This epoch took 316.224392 s\n",
      "\n",
      "2021-11-09 10:26:18.654543: \n",
      "epoch:  39\n",
      "2021-11-09 10:31:07.873172: train loss : -0.8407\n",
      "2021-11-09 10:31:27.138694: validation loss: -0.8475\n",
      "2021-11-09 10:31:27.146288: Average global foreground Dice: [0.8601]\n",
      "2021-11-09 10:31:27.153996: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 10:31:27.685768: lr: 0.006314\n",
      "2021-11-09 10:31:27.717771: saving checkpoint...\n",
      "2021-11-09 10:31:28.672945: done, saving took 0.98 seconds\n",
      "2021-11-09 10:31:28.696502: This epoch took 310.037516 s\n",
      "\n",
      "2021-11-09 10:31:28.700644: \n",
      "epoch:  40\n",
      "2021-11-09 10:36:26.103700: train loss : -0.8389\n",
      "2021-11-09 10:36:48.616337: validation loss: -0.8313\n",
      "2021-11-09 10:36:48.622080: Average global foreground Dice: [0.8411]\n",
      "2021-11-09 10:36:48.626958: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 10:36:50.531700: lr: 0.00622\n",
      "2021-11-09 10:36:50.576042: This epoch took 321.870604 s\n",
      "\n",
      "2021-11-09 10:36:50.580788: \n",
      "epoch:  41\n",
      "2021-11-09 10:41:48.361281: train loss : -0.8370\n",
      "2021-11-09 10:42:10.217045: validation loss: -0.8463\n",
      "2021-11-09 10:42:10.231895: Average global foreground Dice: [0.8595]\n",
      "2021-11-09 10:42:10.263738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 10:42:12.878276: lr: 0.006125\n",
      "2021-11-09 10:42:12.883069: This epoch took 322.297392 s\n",
      "\n",
      "2021-11-09 10:42:12.890547: \n",
      "epoch:  42\n",
      "2021-11-09 10:47:13.700676: train loss : -0.8382\n",
      "2021-11-09 10:47:34.540115: validation loss: -0.8555\n",
      "2021-11-09 10:47:34.546223: Average global foreground Dice: [0.8677]\n",
      "2021-11-09 10:47:34.550880: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 10:47:35.038997: lr: 0.00603\n",
      "2021-11-09 10:47:35.071335: saving checkpoint...\n",
      "2021-11-09 10:47:36.106078: done, saving took 1.06 seconds\n",
      "2021-11-09 10:47:36.128591: This epoch took 323.231044 s\n",
      "\n",
      "2021-11-09 10:47:36.133350: \n",
      "epoch:  43\n",
      "2021-11-09 10:52:30.782256: train loss : -0.8418\n",
      "2021-11-09 10:52:51.990784: validation loss: -0.8466\n",
      "2021-11-09 10:52:51.996359: Average global foreground Dice: [0.8558]\n",
      "2021-11-09 10:52:52.000045: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 10:52:52.549866: lr: 0.005934\n",
      "2021-11-09 10:52:52.584014: saving checkpoint...\n",
      "2021-11-09 10:52:53.583079: done, saving took 1.03 seconds\n",
      "2021-11-09 10:52:53.607272: This epoch took 317.469191 s\n",
      "\n",
      "2021-11-09 10:52:53.611059: \n",
      "epoch:  44\n",
      "2021-11-09 10:57:49.590232: train loss : -0.8369\n",
      "2021-11-09 10:58:10.780020: validation loss: -0.8502\n",
      "2021-11-09 10:58:10.793198: Average global foreground Dice: [0.8603]\n",
      "2021-11-09 10:58:10.797341: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 10:58:12.100997: lr: 0.005839\n",
      "2021-11-09 10:58:12.139318: saving checkpoint...\n",
      "2021-11-09 10:58:13.329338: done, saving took 1.22 seconds\n",
      "2021-11-09 10:58:13.383466: This epoch took 319.768261 s\n",
      "\n",
      "2021-11-09 10:58:13.387892: \n",
      "epoch:  45\n",
      "2021-11-09 11:03:12.585073: train loss : -0.8414\n",
      "2021-11-09 11:03:33.773106: validation loss: -0.8549\n",
      "2021-11-09 11:03:33.785744: Average global foreground Dice: [0.8642]\n",
      "2021-11-09 11:03:33.790588: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 11:03:34.542336: lr: 0.005743\n",
      "2021-11-09 11:03:34.606959: saving checkpoint...\n",
      "2021-11-09 11:03:35.739081: done, saving took 1.19 seconds\n",
      "2021-11-09 11:03:35.768067: This epoch took 322.375399 s\n",
      "\n",
      "2021-11-09 11:03:35.772251: \n",
      "epoch:  46\n",
      "2021-11-09 11:08:32.459629: train loss : -0.8441\n",
      "2021-11-09 11:08:51.124489: validation loss: -0.8407\n",
      "2021-11-09 11:08:51.130625: Average global foreground Dice: [0.8533]\n",
      "2021-11-09 11:08:51.134649: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 11:08:51.631489: lr: 0.005647\n",
      "2021-11-09 11:08:51.639304: This epoch took 315.861351 s\n",
      "\n",
      "2021-11-09 11:08:51.644435: \n",
      "epoch:  47\n",
      "2021-11-09 11:13:43.493555: train loss : -0.8462\n",
      "2021-11-09 11:14:04.002357: validation loss: -0.8454\n",
      "2021-11-09 11:14:04.011221: Average global foreground Dice: [0.8551]\n",
      "2021-11-09 11:14:04.019739: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 11:14:04.604991: lr: 0.005551\n",
      "2021-11-09 11:14:04.609263: This epoch took 312.959974 s\n",
      "\n",
      "2021-11-09 11:14:04.613917: \n",
      "epoch:  48\n",
      "2021-11-09 11:19:03.431994: train loss : -0.8434\n",
      "2021-11-09 11:19:25.730747: validation loss: -0.8408\n",
      "2021-11-09 11:19:25.763041: Average global foreground Dice: [0.8594]\n",
      "2021-11-09 11:19:25.767371: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 11:19:27.562137: lr: 0.005455\n",
      "2021-11-09 11:19:27.567946: This epoch took 322.950033 s\n",
      "\n",
      "2021-11-09 11:19:27.572912: \n",
      "epoch:  49\n",
      "2021-11-09 11:24:29.673425: train loss : -0.8456\n",
      "2021-11-09 11:24:50.570914: validation loss: -0.8474\n",
      "2021-11-09 11:24:50.579032: Average global foreground Dice: [0.857]\n",
      "2021-11-09 11:24:50.583909: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 11:24:51.340561: lr: 0.005359\n",
      "2021-11-09 11:24:51.345765: saving scheduled checkpoint file...\n",
      "2021-11-09 11:24:51.420194: saving checkpoint...\n",
      "2021-11-09 11:24:52.305850: done, saving took 0.95 seconds\n",
      "2021-11-09 11:24:52.344784: done\n",
      "2021-11-09 11:24:52.352709: This epoch took 324.775464 s\n",
      "\n",
      "2021-11-09 11:24:52.357508: \n",
      "epoch:  50\n",
      "2021-11-09 11:29:52.286623: train loss : -0.8461\n",
      "2021-11-09 11:30:13.569969: validation loss: -0.8428\n",
      "2021-11-09 11:30:13.588437: Average global foreground Dice: [0.8567]\n",
      "2021-11-09 11:30:13.592385: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 11:30:15.519512: lr: 0.005262\n",
      "2021-11-09 11:30:15.632303: saving checkpoint...\n",
      "2021-11-09 11:30:16.951644: done, saving took 1.42 seconds\n",
      "2021-11-09 11:30:16.980656: This epoch took 324.619239 s\n",
      "\n",
      "2021-11-09 11:30:16.985498: \n",
      "epoch:  51\n",
      "2021-11-09 11:35:15.504073: train loss : -0.8452\n",
      "2021-11-09 11:35:37.378819: validation loss: -0.8463\n",
      "2021-11-09 11:35:37.384705: Average global foreground Dice: [0.8602]\n",
      "2021-11-09 11:35:37.389702: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 11:35:38.376512: lr: 0.005166\n",
      "2021-11-09 11:35:38.458133: saving checkpoint...\n",
      "2021-11-09 11:35:39.439800: done, saving took 1.06 seconds\n",
      "2021-11-09 11:35:39.487278: This epoch took 322.496237 s\n",
      "\n",
      "2021-11-09 11:35:39.494582: \n",
      "epoch:  52\n",
      "2021-11-09 11:40:41.378591: train loss : -0.8395\n",
      "2021-11-09 11:41:03.094326: validation loss: -0.8522\n",
      "2021-11-09 11:41:03.102997: Average global foreground Dice: [0.8658]\n",
      "2021-11-09 11:41:03.110407: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 11:41:04.080312: lr: 0.005069\n",
      "2021-11-09 11:41:04.148979: saving checkpoint...\n",
      "2021-11-09 11:41:05.235744: done, saving took 1.15 seconds\n",
      "2021-11-09 11:41:05.263065: This epoch took 325.761927 s\n",
      "\n",
      "2021-11-09 11:41:05.269081: \n",
      "epoch:  53\n",
      "2021-11-09 11:46:01.973170: train loss : -0.8490\n",
      "2021-11-09 11:46:22.371216: validation loss: -0.8529\n",
      "2021-11-09 11:46:22.376068: Average global foreground Dice: [0.8629]\n",
      "2021-11-09 11:46:22.380226: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 11:46:22.919886: lr: 0.004971\n",
      "2021-11-09 11:46:22.989147: saving checkpoint...\n",
      "2021-11-09 11:46:24.129195: done, saving took 1.20 seconds\n",
      "2021-11-09 11:46:24.155973: This epoch took 318.881940 s\n",
      "\n",
      "2021-11-09 11:46:24.160819: \n",
      "epoch:  54\n",
      "2021-11-09 11:51:22.016012: train loss : -0.8479\n",
      "2021-11-09 11:51:42.233134: validation loss: -0.8474\n",
      "2021-11-09 11:51:42.243340: Average global foreground Dice: [0.859]\n",
      "2021-11-09 11:51:42.248048: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 11:51:42.729715: lr: 0.004874\n",
      "2021-11-09 11:51:42.762757: saving checkpoint...\n",
      "2021-11-09 11:51:43.919336: done, saving took 1.18 seconds\n",
      "2021-11-09 11:51:43.941404: This epoch took 319.775411 s\n",
      "\n",
      "2021-11-09 11:51:43.946611: \n",
      "epoch:  55\n",
      "2021-11-09 11:56:39.916982: train loss : -0.8469\n",
      "2021-11-09 11:57:01.107866: validation loss: -0.8530\n",
      "2021-11-09 11:57:01.124332: Average global foreground Dice: [0.8634]\n",
      "2021-11-09 11:57:01.128769: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 11:57:02.790926: lr: 0.004776\n",
      "2021-11-09 11:57:02.830184: saving checkpoint...\n",
      "2021-11-09 11:57:03.927379: done, saving took 1.13 seconds\n",
      "2021-11-09 11:57:03.953229: This epoch took 320.002099 s\n",
      "\n",
      "2021-11-09 11:57:03.961700: \n",
      "epoch:  56\n",
      "2021-11-09 12:01:59.589044: train loss : -0.8527\n",
      "2021-11-09 12:02:20.197102: validation loss: -0.8470\n",
      "2021-11-09 12:02:20.202654: Average global foreground Dice: [0.8604]\n",
      "2021-11-09 12:02:20.207235: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 12:02:20.957164: lr: 0.004679\n",
      "2021-11-09 12:02:20.991192: saving checkpoint...\n",
      "2021-11-09 12:02:22.105063: done, saving took 1.14 seconds\n",
      "2021-11-09 12:02:22.139231: This epoch took 318.172646 s\n",
      "\n",
      "2021-11-09 12:02:22.144412: \n",
      "epoch:  57\n",
      "2021-11-09 12:07:21.983693: train loss : -0.8471\n",
      "2021-11-09 12:07:43.494041: validation loss: -0.8540\n",
      "2021-11-09 12:07:43.503749: Average global foreground Dice: [0.8632]\n",
      "2021-11-09 12:07:43.510222: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 12:07:44.229638: lr: 0.004581\n",
      "2021-11-09 12:07:44.262784: saving checkpoint...\n",
      "2021-11-09 12:07:45.398452: done, saving took 1.16 seconds\n",
      "2021-11-09 12:07:45.439330: This epoch took 323.290731 s\n",
      "\n",
      "2021-11-09 12:07:45.447655: \n",
      "epoch:  58\n",
      "2021-11-09 12:12:44.813835: train loss : -0.8526\n",
      "2021-11-09 12:13:06.289719: validation loss: -0.8527\n",
      "2021-11-09 12:13:06.309054: Average global foreground Dice: [0.8622]\n",
      "2021-11-09 12:13:06.313980: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 12:13:07.864137: lr: 0.004482\n",
      "2021-11-09 12:13:07.938223: saving checkpoint...\n",
      "2021-11-09 12:13:09.172167: done, saving took 1.30 seconds\n",
      "2021-11-09 12:13:09.199763: This epoch took 323.742855 s\n",
      "\n",
      "2021-11-09 12:13:09.204637: \n",
      "epoch:  59\n",
      "2021-11-09 12:18:04.572881: train loss : -0.8511\n",
      "2021-11-09 12:18:23.377482: validation loss: -0.8443\n",
      "2021-11-09 12:18:23.382383: Average global foreground Dice: [0.8535]\n",
      "2021-11-09 12:18:23.388118: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 12:18:23.920036: lr: 0.004384\n",
      "2021-11-09 12:18:23.924787: This epoch took 314.715822 s\n",
      "\n",
      "2021-11-09 12:18:23.929595: \n",
      "epoch:  60\n",
      "2021-11-09 12:23:22.283898: train loss : -0.8524\n",
      "2021-11-09 12:23:42.913041: validation loss: -0.8504\n",
      "2021-11-09 12:23:42.918384: Average global foreground Dice: [0.8624]\n",
      "2021-11-09 12:23:42.923259: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 12:23:43.514270: lr: 0.004285\n",
      "2021-11-09 12:23:43.518679: This epoch took 319.584608 s\n",
      "\n",
      "2021-11-09 12:23:43.523402: \n",
      "epoch:  61\n",
      "2021-11-09 12:28:44.679272: train loss : -0.8526\n",
      "2021-11-09 12:29:07.511993: validation loss: -0.8516\n",
      "2021-11-09 12:29:07.563871: Average global foreground Dice: [0.8596]\n",
      "2021-11-09 12:29:07.569018: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 12:29:09.762025: lr: 0.004186\n",
      "2021-11-09 12:29:09.766878: This epoch took 326.238325 s\n",
      "\n",
      "2021-11-09 12:29:09.770520: \n",
      "epoch:  62\n",
      "2021-11-09 12:33:59.731275: train loss : -0.8544\n",
      "2021-11-09 12:34:19.344173: validation loss: -0.8534\n",
      "2021-11-09 12:34:19.349248: Average global foreground Dice: [0.8642]\n",
      "2021-11-09 12:34:19.353357: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 12:34:19.868418: lr: 0.004087\n",
      "2021-11-09 12:34:19.940113: saving checkpoint...\n",
      "2021-11-09 12:34:21.006830: done, saving took 1.13 seconds\n",
      "2021-11-09 12:34:21.045795: This epoch took 311.271188 s\n",
      "\n",
      "2021-11-09 12:34:21.050350: \n",
      "epoch:  63\n",
      "2021-11-09 12:39:18.583351: train loss : -0.8535\n",
      "2021-11-09 12:39:40.831298: validation loss: -0.8478\n",
      "2021-11-09 12:39:40.876190: Average global foreground Dice: [0.8565]\n",
      "2021-11-09 12:39:40.881223: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 12:39:42.483086: lr: 0.003987\n",
      "2021-11-09 12:39:42.487363: This epoch took 321.432035 s\n",
      "\n",
      "2021-11-09 12:39:42.492103: \n",
      "epoch:  64\n",
      "2021-11-09 12:44:40.049980: train loss : -0.8582\n",
      "2021-11-09 12:44:58.253061: validation loss: -0.8559\n",
      "2021-11-09 12:44:58.258016: Average global foreground Dice: [0.8641]\n",
      "2021-11-09 12:44:58.261933: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 12:44:58.772952: lr: 0.003887\n",
      "2021-11-09 12:44:58.844595: saving checkpoint...\n",
      "2021-11-09 12:44:59.987005: done, saving took 1.21 seconds\n",
      "2021-11-09 12:45:00.009809: This epoch took 317.512974 s\n",
      "\n",
      "2021-11-09 12:45:00.014452: \n",
      "epoch:  65\n",
      "2021-11-09 12:49:49.664567: train loss : -0.8552\n",
      "2021-11-09 12:50:09.256440: validation loss: -0.8537\n",
      "2021-11-09 12:50:09.260865: Average global foreground Dice: [0.867]\n",
      "2021-11-09 12:50:09.264807: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 12:50:09.768091: lr: 0.003787\n",
      "2021-11-09 12:50:09.840634: saving checkpoint...\n",
      "2021-11-09 12:50:10.907545: done, saving took 1.14 seconds\n",
      "2021-11-09 12:50:10.929287: This epoch took 310.910357 s\n",
      "\n",
      "2021-11-09 12:50:10.933135: \n",
      "epoch:  66\n",
      "2021-11-09 12:55:11.204038: train loss : -0.8542\n",
      "2021-11-09 12:55:31.768223: validation loss: -0.8513\n",
      "2021-11-09 12:55:31.772905: Average global foreground Dice: [0.8629]\n",
      "2021-11-09 12:55:31.777538: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 12:55:32.303296: lr: 0.003687\n",
      "2021-11-09 12:55:32.366786: saving checkpoint...\n",
      "2021-11-09 12:55:33.469621: done, saving took 1.16 seconds\n",
      "2021-11-09 12:55:33.508788: This epoch took 322.571172 s\n",
      "\n",
      "2021-11-09 12:55:33.513684: \n",
      "epoch:  67\n",
      "2021-11-09 13:00:32.274831: train loss : -0.8504\n",
      "2021-11-09 13:00:54.905616: validation loss: -0.8457\n",
      "2021-11-09 13:00:54.959922: Average global foreground Dice: [0.8593]\n",
      "2021-11-09 13:00:54.964838: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 13:00:56.397175: lr: 0.003586\n",
      "2021-11-09 13:00:56.404114: This epoch took 322.885752 s\n",
      "\n",
      "2021-11-09 13:00:56.412251: \n",
      "epoch:  68\n",
      "2021-11-09 13:05:49.072830: train loss : -0.8602\n",
      "2021-11-09 13:06:07.843329: validation loss: -0.8508\n",
      "2021-11-09 13:06:07.848743: Average global foreground Dice: [0.8646]\n",
      "2021-11-09 13:06:07.853778: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 13:06:08.433233: lr: 0.003485\n",
      "2021-11-09 13:06:08.496348: saving checkpoint...\n",
      "2021-11-09 13:06:09.648548: done, saving took 1.21 seconds\n",
      "2021-11-09 13:06:09.671244: This epoch took 313.251402 s\n",
      "\n",
      "2021-11-09 13:06:09.675709: \n",
      "epoch:  69\n",
      "2021-11-09 13:11:09.801403: train loss : -0.8560\n",
      "2021-11-09 13:11:30.827967: validation loss: -0.8584\n",
      "2021-11-09 13:11:30.833364: Average global foreground Dice: [0.8678]\n",
      "2021-11-09 13:11:30.838068: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 13:11:31.420776: lr: 0.003384\n",
      "2021-11-09 13:11:31.484583: saving checkpoint...\n",
      "2021-11-09 13:11:32.592971: done, saving took 1.17 seconds\n",
      "2021-11-09 13:11:32.620668: This epoch took 322.940216 s\n",
      "\n",
      "2021-11-09 13:11:32.624854: \n",
      "epoch:  70\n",
      "2021-11-09 13:16:28.641558: train loss : -0.8583\n",
      "2021-11-09 13:16:46.772254: validation loss: -0.8466\n",
      "2021-11-09 13:16:46.777313: Average global foreground Dice: [0.8578]\n",
      "2021-11-09 13:16:46.781286: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 13:16:47.339028: lr: 0.003282\n",
      "2021-11-09 13:16:47.343263: This epoch took 314.713538 s\n",
      "\n",
      "2021-11-09 13:16:47.347143: \n",
      "epoch:  71\n",
      "2021-11-09 13:21:42.194147: train loss : -0.8583\n",
      "2021-11-09 13:22:02.892802: validation loss: -0.8468\n",
      "2021-11-09 13:22:02.897957: Average global foreground Dice: [0.8563]\n",
      "2021-11-09 13:22:02.901790: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 13:22:03.427810: lr: 0.00318\n",
      "2021-11-09 13:22:03.432690: This epoch took 316.081424 s\n",
      "\n",
      "2021-11-09 13:22:03.436320: \n",
      "epoch:  72\n",
      "2021-11-09 13:27:03.264808: train loss : -0.8603\n",
      "2021-11-09 13:27:23.513437: validation loss: -0.8538\n",
      "2021-11-09 13:27:23.518759: Average global foreground Dice: [0.8647]\n",
      "2021-11-09 13:27:23.523485: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 13:27:24.058823: lr: 0.003078\n",
      "2021-11-09 13:27:24.063052: This epoch took 320.621927 s\n",
      "\n",
      "2021-11-09 13:27:24.067475: \n",
      "epoch:  73\n",
      "2021-11-09 13:32:16.337805: train loss : -0.8618\n",
      "2021-11-09 13:32:35.820563: validation loss: -0.8487\n",
      "2021-11-09 13:32:35.825944: Average global foreground Dice: [0.8578]\n",
      "2021-11-09 13:32:35.830197: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 13:32:36.373800: lr: 0.002975\n",
      "2021-11-09 13:32:36.379239: This epoch took 312.307867 s\n",
      "\n",
      "2021-11-09 13:32:36.385607: \n",
      "epoch:  74\n",
      "2021-11-09 13:37:34.703105: train loss : -0.8568\n",
      "2021-11-09 13:37:55.613343: validation loss: -0.8414\n",
      "2021-11-09 13:37:55.622973: Average global foreground Dice: [0.854]\n",
      "2021-11-09 13:37:55.628252: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 13:37:56.141463: lr: 0.002872\n",
      "2021-11-09 13:37:56.149453: This epoch took 319.757882 s\n",
      "\n",
      "2021-11-09 13:37:56.154332: \n",
      "epoch:  75\n",
      "2021-11-09 13:42:56.724021: train loss : -0.8640\n",
      "2021-11-09 13:43:17.997160: validation loss: -0.8470\n",
      "2021-11-09 13:43:18.016579: Average global foreground Dice: [0.8575]\n",
      "2021-11-09 13:43:18.021280: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 13:43:19.426742: lr: 0.002768\n",
      "2021-11-09 13:43:19.430697: This epoch took 323.271500 s\n",
      "\n",
      "2021-11-09 13:43:19.434929: \n",
      "epoch:  76\n",
      "2021-11-09 13:48:20.514795: train loss : -0.8557\n",
      "2021-11-09 13:48:42.085330: validation loss: -0.8518\n",
      "2021-11-09 13:48:42.105425: Average global foreground Dice: [0.8608]\n",
      "2021-11-09 13:48:42.109998: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 13:48:44.191746: lr: 0.002664\n",
      "2021-11-09 13:48:44.196888: This epoch took 324.758022 s\n",
      "\n",
      "2021-11-09 13:48:44.201648: \n",
      "epoch:  77\n",
      "2021-11-09 13:53:46.872977: train loss : -0.8610\n",
      "2021-11-09 13:54:06.906954: validation loss: -0.8506\n",
      "2021-11-09 13:54:06.912477: Average global foreground Dice: [0.8619]\n",
      "2021-11-09 13:54:06.917927: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 13:54:07.434560: lr: 0.00256\n",
      "2021-11-09 13:54:07.439331: This epoch took 323.233045 s\n",
      "\n",
      "2021-11-09 13:54:07.445170: \n",
      "epoch:  78\n",
      "2021-11-09 13:59:04.313554: train loss : -0.8632\n",
      "2021-11-09 13:59:22.848993: validation loss: -0.8561\n",
      "2021-11-09 13:59:22.853941: Average global foreground Dice: [0.8657]\n",
      "2021-11-09 13:59:22.858117: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 13:59:23.393342: lr: 0.002455\n",
      "2021-11-09 13:59:23.397629: This epoch took 315.948881 s\n",
      "\n",
      "2021-11-09 13:59:23.403734: \n",
      "epoch:  79\n",
      "2021-11-09 14:04:29.217902: train loss : -0.8635\n",
      "2021-11-09 14:04:51.263132: validation loss: -0.8489\n",
      "2021-11-09 14:04:51.275818: Average global foreground Dice: [0.861]\n",
      "2021-11-09 14:04:51.280673: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 14:04:52.907500: lr: 0.002349\n",
      "2021-11-09 14:04:52.912641: This epoch took 329.505283 s\n",
      "\n",
      "2021-11-09 14:04:52.916562: \n",
      "epoch:  80\n",
      "2021-11-09 14:09:52.180740: train loss : -0.8645\n",
      "2021-11-09 14:10:13.760182: validation loss: -0.8562\n",
      "2021-11-09 14:10:13.764994: Average global foreground Dice: [0.8625]\n",
      "2021-11-09 14:10:13.771135: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 14:10:14.641508: lr: 0.002243\n",
      "2021-11-09 14:10:14.646387: This epoch took 321.725348 s\n",
      "\n",
      "2021-11-09 14:10:14.650504: \n",
      "epoch:  81\n",
      "2021-11-09 14:15:12.696959: train loss : -0.8665\n",
      "2021-11-09 14:15:35.475122: validation loss: -0.8600\n",
      "2021-11-09 14:15:35.480028: Average global foreground Dice: [0.8679]\n",
      "2021-11-09 14:15:35.484023: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 14:15:37.623047: lr: 0.002137\n",
      "2021-11-09 14:15:37.627946: This epoch took 322.973530 s\n",
      "\n",
      "2021-11-09 14:15:37.659193: \n",
      "epoch:  82\n",
      "2021-11-09 14:20:32.074363: train loss : -0.8641\n",
      "2021-11-09 14:20:53.174977: validation loss: -0.8482\n",
      "2021-11-09 14:20:53.180128: Average global foreground Dice: [0.8581]\n",
      "2021-11-09 14:20:53.184796: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 14:20:53.696463: lr: 0.00203\n",
      "2021-11-09 14:20:53.701192: This epoch took 316.034214 s\n",
      "\n",
      "2021-11-09 14:20:53.705733: \n",
      "epoch:  83\n",
      "2021-11-09 14:25:52.873330: train loss : -0.8637\n",
      "2021-11-09 14:26:13.380371: validation loss: -0.8503\n",
      "2021-11-09 14:26:13.385792: Average global foreground Dice: [0.8611]\n",
      "2021-11-09 14:26:13.389981: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 14:26:14.046860: lr: 0.001922\n",
      "2021-11-09 14:26:14.055058: This epoch took 320.344537 s\n",
      "\n",
      "2021-11-09 14:26:14.061585: \n",
      "epoch:  84\n",
      "2021-11-09 14:31:18.064187: train loss : -0.8649\n",
      "2021-11-09 14:31:40.186778: validation loss: -0.8539\n",
      "2021-11-09 14:31:40.203867: Average global foreground Dice: [0.8642]\n",
      "2021-11-09 14:31:40.208813: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 14:31:41.478594: lr: 0.001813\n",
      "2021-11-09 14:31:41.483078: This epoch took 327.414564 s\n",
      "\n",
      "2021-11-09 14:31:41.487875: \n",
      "epoch:  85\n",
      "2021-11-09 14:36:39.572405: train loss : -0.8686\n",
      "2021-11-09 14:37:00.710958: validation loss: -0.8502\n",
      "2021-11-09 14:37:00.715169: Average global foreground Dice: [0.8609]\n",
      "2021-11-09 14:37:00.719908: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 14:37:01.263195: lr: 0.001704\n",
      "2021-11-09 14:37:01.271012: This epoch took 319.778686 s\n",
      "\n",
      "2021-11-09 14:37:01.278736: \n",
      "epoch:  86\n",
      "2021-11-09 14:42:00.292090: train loss : -0.8675\n",
      "2021-11-09 14:42:20.145200: validation loss: -0.8555\n",
      "2021-11-09 14:42:20.149792: Average global foreground Dice: [0.863]\n",
      "2021-11-09 14:42:20.153757: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 14:42:20.671267: lr: 0.001594\n",
      "2021-11-09 14:42:20.676253: This epoch took 319.390563 s\n",
      "\n",
      "2021-11-09 14:42:20.680317: \n",
      "epoch:  87\n",
      "2021-11-09 14:47:16.885511: train loss : -0.8669\n",
      "2021-11-09 14:47:38.585355: validation loss: -0.8536\n",
      "2021-11-09 14:47:38.606137: Average global foreground Dice: [0.8623]\n",
      "2021-11-09 14:47:38.610023: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 14:47:40.133863: lr: 0.001483\n",
      "2021-11-09 14:47:40.164185: This epoch took 319.478961 s\n",
      "\n",
      "2021-11-09 14:47:40.169126: \n",
      "epoch:  88\n",
      "2021-11-09 14:52:37.993129: train loss : -0.8688\n",
      "2021-11-09 14:53:00.285465: validation loss: -0.8517\n",
      "2021-11-09 14:53:00.300901: Average global foreground Dice: [0.8643]\n",
      "2021-11-09 14:53:00.305995: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 14:53:02.120123: lr: 0.001372\n",
      "2021-11-09 14:53:02.367045: saving checkpoint...\n",
      "2021-11-09 14:53:03.652316: done, saving took 1.53 seconds\n",
      "2021-11-09 14:53:03.711062: This epoch took 323.535516 s\n",
      "\n",
      "2021-11-09 14:53:03.716106: \n",
      "epoch:  89\n",
      "2021-11-09 14:58:03.014518: train loss : -0.8671\n",
      "2021-11-09 14:58:24.169738: validation loss: -0.8499\n",
      "2021-11-09 14:58:24.175746: Average global foreground Dice: [0.8597]\n",
      "2021-11-09 14:58:24.179961: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 14:58:24.975651: lr: 0.001259\n",
      "2021-11-09 14:58:24.980170: This epoch took 321.260416 s\n",
      "\n",
      "2021-11-09 14:58:24.984910: \n",
      "epoch:  90\n",
      "2021-11-09 15:03:22.253944: train loss : -0.8674\n",
      "2021-11-09 15:03:40.690274: validation loss: -0.8501\n",
      "2021-11-09 15:03:40.695351: Average global foreground Dice: [0.8574]\n",
      "2021-11-09 15:03:40.699390: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 15:03:41.218005: lr: 0.001145\n",
      "2021-11-09 15:03:41.222759: This epoch took 316.232932 s\n",
      "\n",
      "2021-11-09 15:03:41.226791: \n",
      "epoch:  91\n",
      "2021-11-09 15:08:43.159359: train loss : -0.8703\n",
      "2021-11-09 15:09:03.549788: validation loss: -0.8497\n",
      "2021-11-09 15:09:03.555842: Average global foreground Dice: [0.8618]\n",
      "2021-11-09 15:09:03.560745: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 15:09:04.113057: lr: 0.00103\n",
      "2021-11-09 15:09:04.117641: This epoch took 322.886149 s\n",
      "\n",
      "2021-11-09 15:09:04.121686: \n",
      "epoch:  92\n",
      "2021-11-09 15:14:05.599751: train loss : -0.8698\n",
      "2021-11-09 15:14:27.837880: validation loss: -0.8502\n",
      "2021-11-09 15:14:27.864246: Average global foreground Dice: [0.8598]\n",
      "2021-11-09 15:14:27.868958: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 15:14:28.815387: lr: 0.000913\n",
      "2021-11-09 15:14:28.820381: This epoch took 324.694124 s\n",
      "\n",
      "2021-11-09 15:14:28.825292: \n",
      "epoch:  93\n",
      "2021-11-09 15:19:28.712786: train loss : -0.8701\n",
      "2021-11-09 15:19:47.021707: validation loss: -0.8546\n",
      "2021-11-09 15:19:47.026791: Average global foreground Dice: [0.8639]\n",
      "2021-11-09 15:19:47.030731: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 15:19:47.521488: lr: 0.000795\n",
      "2021-11-09 15:19:47.526505: This epoch took 318.697432 s\n",
      "\n",
      "2021-11-09 15:19:47.531272: \n",
      "epoch:  94\n",
      "2021-11-09 15:24:49.608578: train loss : -0.8707\n",
      "2021-11-09 15:25:12.608633: validation loss: -0.8546\n",
      "2021-11-09 15:25:12.614122: Average global foreground Dice: [0.8634]\n",
      "2021-11-09 15:25:12.619094: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 15:25:14.331094: lr: 0.000675\n",
      "2021-11-09 15:25:14.363030: This epoch took 326.826874 s\n",
      "\n",
      "2021-11-09 15:25:14.367286: \n",
      "epoch:  95\n",
      "2021-11-09 15:30:15.181289: train loss : -0.8723\n",
      "2021-11-09 15:30:37.096404: validation loss: -0.8507\n",
      "2021-11-09 15:30:37.116474: Average global foreground Dice: [0.8582]\n",
      "2021-11-09 15:30:37.121520: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 15:30:38.706882: lr: 0.000552\n",
      "2021-11-09 15:30:38.711344: This epoch took 324.339887 s\n",
      "\n",
      "2021-11-09 15:30:38.716404: \n",
      "epoch:  96\n",
      "2021-11-09 15:35:32.379061: train loss : -0.8749\n",
      "2021-11-09 15:35:52.582162: validation loss: -0.8511\n",
      "2021-11-09 15:35:52.586625: Average global foreground Dice: [0.8581]\n",
      "2021-11-09 15:35:52.590590: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 15:35:53.122567: lr: 0.000426\n",
      "2021-11-09 15:35:53.127711: This epoch took 314.406398 s\n",
      "\n",
      "2021-11-09 15:35:53.131649: \n",
      "epoch:  97\n",
      "2021-11-09 15:40:54.890260: train loss : -0.8731\n",
      "2021-11-09 15:41:16.314588: validation loss: -0.8512\n",
      "2021-11-09 15:41:16.359664: Average global foreground Dice: [0.8603]\n",
      "2021-11-09 15:41:16.364436: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 15:41:17.623925: lr: 0.000296\n",
      "2021-11-09 15:41:17.630436: This epoch took 324.494607 s\n",
      "\n",
      "2021-11-09 15:41:17.634878: \n",
      "epoch:  98\n",
      "2021-11-09 15:46:17.492013: train loss : -0.8724\n",
      "2021-11-09 15:46:39.897171: validation loss: -0.8515\n",
      "2021-11-09 15:46:39.915922: Average global foreground Dice: [0.86]\n",
      "2021-11-09 15:46:39.920350: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 15:46:40.790095: lr: 0.000158\n",
      "2021-11-09 15:46:40.794940: This epoch took 323.135642 s\n",
      "\n",
      "2021-11-09 15:46:40.799629: \n",
      "epoch:  99\n",
      "2021-11-09 15:51:35.801510: train loss : -0.8736\n",
      "2021-11-09 15:51:56.697091: validation loss: -0.8511\n",
      "2021-11-09 15:51:56.702777: Average global foreground Dice: [0.8613]\n",
      "2021-11-09 15:51:56.706549: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 15:51:57.213034: lr: 0.0\n",
      "2021-11-09 15:51:57.217689: saving scheduled checkpoint file...\n",
      "2021-11-09 15:51:57.290552: saving checkpoint...\n",
      "2021-11-09 15:51:58.357444: done, saving took 1.13 seconds\n",
      "2021-11-09 15:51:58.391116: done\n",
      "2021-11-09 15:51:58.396947: This epoch took 317.593204 s\n",
      "\n",
      "2021-11-09 15:51:58.429453: saving checkpoint...\n",
      "2021-11-09 15:51:59.235075: done, saving took 0.83 seconds\n",
      "23090559_20150812 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120330 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090563_20151216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130226 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090584_20120523 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090589_20140219 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090592_20130218 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090614_20120402 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090620_20130617 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090627_20160608 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090628_20150204 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090635_20140710 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090640_20140711 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121227 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-09 15:55:24.043293: finished prediction\n",
      "2021-11-09 15:55:24.048239: evaluation of raw predictions\n",
      "2021-11-09 15:55:25.598822: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8639074931330386\n",
      "after:  0.8639074931330386\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-09 15:55:36.746674: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-09 15:55:36.761292: The split file contains 5 splits.\n",
      "2021-11-09 15:55:36.765455: Desired fold for training: 1\n",
      "2021-11-09 15:55:36.770163: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-09 15:55:41.164378: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-09 15:56:00.486419: Unable to plot network architecture:\n",
      "2021-11-09 15:56:00.500246: No module named 'hiddenlayer'\n",
      "2021-11-09 15:56:00.504363: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-09 15:56:00.508563: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-09 15:56:00.517312: \n",
      "\n",
      "2021-11-09 15:56:00.521349: \n",
      "epoch:  0\n",
      "2021-11-09 16:01:26.385717: train loss : -0.1543\n",
      "2021-11-09 16:01:49.132421: validation loss: -0.5308\n",
      "2021-11-09 16:01:49.176524: Average global foreground Dice: [0.5963]\n",
      "2021-11-09 16:01:49.180878: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 16:01:51.062712: lr: 0.00991\n",
      "2021-11-09 16:01:51.071116: This epoch took 350.545924 s\n",
      "\n",
      "2021-11-09 16:01:51.076084: \n",
      "epoch:  1\n",
      "2021-11-09 16:07:06.115927: train loss : -0.5873\n",
      "2021-11-09 16:07:29.359332: validation loss: -0.6673\n",
      "2021-11-09 16:07:29.365009: Average global foreground Dice: [0.7253]\n",
      "2021-11-09 16:07:29.369758: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 16:07:32.469029: lr: 0.00982\n",
      "2021-11-09 16:07:32.587085: saving checkpoint...\n",
      "2021-11-09 16:07:33.911299: done, saving took 1.44 seconds\n",
      "2021-11-09 16:07:33.930283: This epoch took 342.849410 s\n",
      "\n",
      "2021-11-09 16:07:33.959756: \n",
      "epoch:  2\n",
      "2021-11-09 16:12:33.285881: train loss : -0.6557\n",
      "2021-11-09 16:12:54.686488: validation loss: -0.7308\n",
      "2021-11-09 16:12:54.691314: Average global foreground Dice: [0.768]\n",
      "2021-11-09 16:12:54.696342: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 16:12:55.618293: lr: 0.00973\n",
      "2021-11-09 16:12:55.697116: saving checkpoint...\n",
      "2021-11-09 16:12:56.746960: done, saving took 1.12 seconds\n",
      "2021-11-09 16:12:56.784074: This epoch took 322.820371 s\n",
      "\n",
      "2021-11-09 16:12:56.788178: \n",
      "epoch:  3\n",
      "2021-11-09 16:17:53.893575: train loss : -0.7017\n",
      "2021-11-09 16:18:15.672375: validation loss: -0.7548\n",
      "2021-11-09 16:18:15.679873: Average global foreground Dice: [0.794]\n",
      "2021-11-09 16:18:15.684127: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 16:18:17.502967: lr: 0.009639\n",
      "2021-11-09 16:18:17.585078: saving checkpoint...\n",
      "2021-11-09 16:18:18.669763: done, saving took 1.16 seconds\n",
      "2021-11-09 16:18:18.699112: This epoch took 321.907361 s\n",
      "\n",
      "2021-11-09 16:18:18.703099: \n",
      "epoch:  4\n",
      "2021-11-09 16:23:19.089345: train loss : -0.7264\n",
      "2021-11-09 16:23:41.502153: validation loss: -0.7757\n",
      "2021-11-09 16:23:41.520826: Average global foreground Dice: [0.8065]\n",
      "2021-11-09 16:23:41.524382: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 16:23:43.326570: lr: 0.009549\n",
      "2021-11-09 16:23:43.602835: saving checkpoint...\n",
      "2021-11-09 16:23:45.519714: done, saving took 2.19 seconds\n",
      "2021-11-09 16:23:45.570689: This epoch took 326.863525 s\n",
      "\n",
      "2021-11-09 16:23:45.574236: \n",
      "epoch:  5\n",
      "2021-11-09 16:28:56.701038: train loss : -0.7516\n",
      "2021-11-09 16:29:20.026936: validation loss: -0.7814\n",
      "2021-11-09 16:29:20.075900: Average global foreground Dice: [0.8063]\n",
      "2021-11-09 16:29:20.079929: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 16:29:22.492041: lr: 0.009458\n",
      "2021-11-09 16:29:22.614565: saving checkpoint...\n",
      "2021-11-09 16:29:24.074070: done, saving took 1.58 seconds\n",
      "2021-11-09 16:29:24.101848: This epoch took 338.523712 s\n",
      "\n",
      "2021-11-09 16:29:24.105789: \n",
      "epoch:  6\n",
      "2021-11-09 16:34:22.007434: train loss : -0.7656\n",
      "2021-11-09 16:34:44.587007: validation loss: -0.7978\n",
      "2021-11-09 16:34:44.604450: Average global foreground Dice: [0.8269]\n",
      "2021-11-09 16:34:44.608710: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 16:34:45.739612: lr: 0.009368\n",
      "2021-11-09 16:34:45.806720: saving checkpoint...\n",
      "2021-11-09 16:34:46.991252: done, saving took 1.25 seconds\n",
      "2021-11-09 16:34:47.021157: This epoch took 322.911586 s\n",
      "\n",
      "2021-11-09 16:34:47.026195: \n",
      "epoch:  7\n",
      "2021-11-09 16:39:44.782348: train loss : -0.7801\n",
      "2021-11-09 16:40:06.592360: validation loss: -0.8095\n",
      "2021-11-09 16:40:06.597952: Average global foreground Dice: [0.8299]\n",
      "2021-11-09 16:40:06.601836: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 16:40:07.208409: lr: 0.009277\n",
      "2021-11-09 16:40:07.276624: saving checkpoint...\n",
      "2021-11-09 16:40:08.293442: done, saving took 1.08 seconds\n",
      "2021-11-09 16:40:08.323238: This epoch took 321.292382 s\n",
      "\n",
      "2021-11-09 16:40:08.327528: \n",
      "epoch:  8\n",
      "2021-11-09 16:45:07.880499: train loss : -0.7909\n",
      "2021-11-09 16:45:27.506019: validation loss: -0.8050\n",
      "2021-11-09 16:45:27.511466: Average global foreground Dice: [0.8276]\n",
      "2021-11-09 16:45:27.516351: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 16:45:28.027981: lr: 0.009186\n",
      "2021-11-09 16:45:28.094706: saving checkpoint...\n",
      "2021-11-09 16:45:29.133737: done, saving took 1.10 seconds\n",
      "2021-11-09 16:45:29.160821: This epoch took 320.828532 s\n",
      "\n",
      "2021-11-09 16:45:29.165643: \n",
      "epoch:  9\n",
      "2021-11-09 16:50:22.884111: train loss : -0.7939\n",
      "2021-11-09 16:50:41.716660: validation loss: -0.8125\n",
      "2021-11-09 16:50:41.721488: Average global foreground Dice: [0.8318]\n",
      "2021-11-09 16:50:41.726917: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 16:50:42.217242: lr: 0.009095\n",
      "2021-11-09 16:50:42.250228: saving checkpoint...\n",
      "2021-11-09 16:50:43.202644: done, saving took 0.98 seconds\n",
      "2021-11-09 16:50:43.225662: This epoch took 314.055815 s\n",
      "\n",
      "2021-11-09 16:50:43.232207: \n",
      "epoch:  10\n",
      "2021-11-09 16:55:36.201952: train loss : -0.7964\n",
      "2021-11-09 16:55:56.658669: validation loss: -0.8079\n",
      "2021-11-09 16:55:56.663411: Average global foreground Dice: [0.8316]\n",
      "2021-11-09 16:55:56.667653: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 16:55:57.146620: lr: 0.009004\n",
      "2021-11-09 16:55:57.180362: saving checkpoint...\n",
      "2021-11-09 16:55:58.298071: done, saving took 1.15 seconds\n",
      "2021-11-09 16:55:58.322403: This epoch took 315.085682 s\n",
      "\n",
      "2021-11-09 16:55:58.327585: \n",
      "epoch:  11\n",
      "2021-11-09 17:00:50.889107: train loss : -0.7985\n",
      "2021-11-09 17:01:11.433316: validation loss: -0.8058\n",
      "2021-11-09 17:01:11.439746: Average global foreground Dice: [0.8257]\n",
      "2021-11-09 17:01:11.444129: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 17:01:11.957908: lr: 0.008913\n",
      "2021-11-09 17:01:11.991854: saving checkpoint...\n",
      "2021-11-09 17:01:13.061694: done, saving took 1.10 seconds\n",
      "2021-11-09 17:01:13.083141: This epoch took 314.751309 s\n",
      "\n",
      "2021-11-09 17:01:13.087716: \n",
      "epoch:  12\n",
      "2021-11-09 17:06:09.780672: train loss : -0.8039\n",
      "2021-11-09 17:06:29.237714: validation loss: -0.8129\n",
      "2021-11-09 17:06:29.243611: Average global foreground Dice: [0.8341]\n",
      "2021-11-09 17:06:29.248644: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 17:06:29.740652: lr: 0.008822\n",
      "2021-11-09 17:06:29.775036: saving checkpoint...\n",
      "2021-11-09 17:06:30.777894: done, saving took 1.03 seconds\n",
      "2021-11-09 17:06:30.805074: This epoch took 317.713124 s\n",
      "\n",
      "2021-11-09 17:06:30.810248: \n",
      "epoch:  13\n",
      "2021-11-09 17:11:27.985442: train loss : -0.8065\n",
      "2021-11-09 17:11:49.620535: validation loss: -0.8052\n",
      "2021-11-09 17:11:49.664423: Average global foreground Dice: [0.8251]\n",
      "2021-11-09 17:11:49.668853: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 17:11:50.829624: lr: 0.008731\n",
      "2021-11-09 17:11:50.866759: saving checkpoint...\n",
      "2021-11-09 17:11:52.004462: done, saving took 1.17 seconds\n",
      "2021-11-09 17:11:52.041009: This epoch took 321.225665 s\n",
      "\n",
      "2021-11-09 17:11:52.046751: \n",
      "epoch:  14\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-09 17:16:48.026603: train loss : -0.8064\n",
      "2021-11-09 17:17:10.573117: validation loss: -0.8183\n",
      "2021-11-09 17:17:10.593579: Average global foreground Dice: [0.8369]\n",
      "2021-11-09 17:17:10.599144: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 17:17:12.239180: lr: 0.008639\n",
      "2021-11-09 17:17:12.314657: saving checkpoint...\n",
      "2021-11-09 17:17:13.572115: done, saving took 1.33 seconds\n",
      "2021-11-09 17:17:13.600760: This epoch took 321.548924 s\n",
      "\n",
      "2021-11-09 17:17:13.606349: \n",
      "epoch:  15\n",
      "2021-11-09 17:22:03.120658: train loss : -0.8135\n",
      "2021-11-09 17:22:22.032393: validation loss: -0.8245\n",
      "2021-11-09 17:22:22.038170: Average global foreground Dice: [0.8401]\n",
      "2021-11-09 17:22:22.042738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 17:22:22.535018: lr: 0.008548\n",
      "2021-11-09 17:22:22.568798: saving checkpoint...\n",
      "2021-11-09 17:22:23.501895: done, saving took 0.96 seconds\n",
      "2021-11-09 17:22:23.531413: This epoch took 309.920283 s\n",
      "\n",
      "2021-11-09 17:22:23.537380: \n",
      "epoch:  16\n",
      "2021-11-09 17:27:14.433397: train loss : -0.8193\n",
      "2021-11-09 17:27:33.250291: validation loss: -0.8241\n",
      "2021-11-09 17:27:33.256191: Average global foreground Dice: [0.8406]\n",
      "2021-11-09 17:27:33.261318: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 17:27:33.765361: lr: 0.008456\n",
      "2021-11-09 17:27:33.800144: saving checkpoint...\n",
      "2021-11-09 17:27:34.808117: done, saving took 1.04 seconds\n",
      "2021-11-09 17:27:34.833917: This epoch took 311.290935 s\n",
      "\n",
      "2021-11-09 17:27:34.838335: \n",
      "epoch:  17\n",
      "2021-11-09 17:32:36.277640: train loss : -0.8193\n",
      "2021-11-09 17:32:57.470533: validation loss: -0.8192\n",
      "2021-11-09 17:32:57.484754: Average global foreground Dice: [0.836]\n",
      "2021-11-09 17:32:57.489169: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 17:32:58.860520: lr: 0.008364\n",
      "2021-11-09 17:32:58.900102: saving checkpoint...\n",
      "2021-11-09 17:33:00.247167: done, saving took 1.38 seconds\n",
      "2021-11-09 17:33:00.276371: This epoch took 325.432884 s\n",
      "\n",
      "2021-11-09 17:33:00.281658: \n",
      "epoch:  18\n",
      "2021-11-09 17:37:58.959510: train loss : -0.8218\n",
      "2021-11-09 17:38:19.492353: validation loss: -0.8162\n",
      "2021-11-09 17:38:19.498543: Average global foreground Dice: [0.8318]\n",
      "2021-11-09 17:38:19.506531: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 17:38:20.051834: lr: 0.008272\n",
      "2021-11-09 17:38:20.085183: saving checkpoint...\n",
      "2021-11-09 17:38:21.178549: done, saving took 1.12 seconds\n",
      "2021-11-09 17:38:21.207247: This epoch took 320.920499 s\n",
      "\n",
      "2021-11-09 17:38:21.213284: \n",
      "epoch:  19\n",
      "2021-11-09 17:43:13.276815: train loss : -0.8246\n",
      "2021-11-09 17:43:34.140854: validation loss: -0.8274\n",
      "2021-11-09 17:43:34.146835: Average global foreground Dice: [0.8374]\n",
      "2021-11-09 17:43:34.152833: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 17:43:34.691771: lr: 0.008181\n",
      "2021-11-09 17:43:34.725756: saving checkpoint...\n",
      "2021-11-09 17:43:35.776067: done, saving took 1.08 seconds\n",
      "2021-11-09 17:43:35.799927: This epoch took 314.581799 s\n",
      "\n",
      "2021-11-09 17:43:35.805442: \n",
      "epoch:  20\n",
      "2021-11-09 17:48:27.389638: train loss : -0.8217\n",
      "2021-11-09 17:48:46.468727: validation loss: -0.8224\n",
      "2021-11-09 17:48:46.473653: Average global foreground Dice: [0.8366]\n",
      "2021-11-09 17:48:46.477681: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 17:48:46.974982: lr: 0.008088\n",
      "2021-11-09 17:48:47.008411: saving checkpoint...\n",
      "2021-11-09 17:48:48.059664: done, saving took 1.08 seconds\n",
      "2021-11-09 17:48:48.084596: This epoch took 312.273638 s\n",
      "\n",
      "2021-11-09 17:48:48.089566: \n",
      "epoch:  21\n",
      "2021-11-09 17:53:53.886036: train loss : -0.8270\n",
      "2021-11-09 17:54:12.799079: validation loss: -0.8358\n",
      "2021-11-09 17:54:12.805007: Average global foreground Dice: [0.8465]\n",
      "2021-11-09 17:54:12.809480: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 17:54:13.344859: lr: 0.007996\n",
      "2021-11-09 17:54:13.378929: saving checkpoint...\n",
      "2021-11-09 17:54:14.406653: done, saving took 1.06 seconds\n",
      "2021-11-09 17:54:14.433373: This epoch took 326.339142 s\n",
      "\n",
      "2021-11-09 17:54:14.438643: \n",
      "epoch:  22\n",
      "2021-11-09 17:59:07.487298: train loss : -0.8291\n",
      "2021-11-09 17:59:29.021163: validation loss: -0.8268\n",
      "2021-11-09 17:59:29.028675: Average global foreground Dice: [0.8425]\n",
      "2021-11-09 17:59:29.059757: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 17:59:31.900929: lr: 0.007904\n",
      "2021-11-09 17:59:31.983953: saving checkpoint...\n",
      "2021-11-09 17:59:33.389032: done, saving took 1.48 seconds\n",
      "2021-11-09 17:59:33.417748: This epoch took 318.974735 s\n",
      "\n",
      "2021-11-09 17:59:33.423164: \n",
      "epoch:  23\n",
      "2021-11-09 18:04:29.364416: train loss : -0.8262\n",
      "2021-11-09 18:04:49.780700: validation loss: -0.8389\n",
      "2021-11-09 18:04:49.786123: Average global foreground Dice: [0.8513]\n",
      "2021-11-09 18:04:49.791279: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 18:04:50.531573: lr: 0.007811\n",
      "2021-11-09 18:04:50.565714: saving checkpoint...\n",
      "2021-11-09 18:04:51.575412: done, saving took 1.04 seconds\n",
      "2021-11-09 18:04:51.602467: This epoch took 318.173921 s\n",
      "\n",
      "2021-11-09 18:04:51.608175: \n",
      "epoch:  24\n",
      "2021-11-09 18:09:40.990621: train loss : -0.8313\n",
      "2021-11-09 18:09:59.034310: validation loss: -0.8278\n",
      "2021-11-09 18:09:59.039741: Average global foreground Dice: [0.8397]\n",
      "2021-11-09 18:09:59.046522: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 18:09:59.529123: lr: 0.007719\n",
      "2021-11-09 18:09:59.561956: saving checkpoint...\n",
      "2021-11-09 18:10:00.639649: done, saving took 1.11 seconds\n",
      "2021-11-09 18:10:00.674431: This epoch took 309.061154 s\n",
      "\n",
      "2021-11-09 18:10:00.679533: \n",
      "epoch:  25\n",
      "2021-11-09 18:14:59.470474: train loss : -0.8277\n",
      "2021-11-09 18:15:20.534423: validation loss: -0.8343\n",
      "2021-11-09 18:15:20.539503: Average global foreground Dice: [0.8456]\n",
      "2021-11-09 18:15:20.544665: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 18:15:21.079978: lr: 0.007626\n",
      "2021-11-09 18:15:21.113983: saving checkpoint...\n",
      "2021-11-09 18:15:22.215638: done, saving took 1.13 seconds\n",
      "2021-11-09 18:15:22.240002: This epoch took 321.555553 s\n",
      "\n",
      "2021-11-09 18:15:22.245111: \n",
      "epoch:  26\n",
      "2021-11-09 18:20:30.695232: train loss : -0.8286\n",
      "2021-11-09 18:20:52.215605: validation loss: -0.8188\n",
      "2021-11-09 18:20:52.221600: Average global foreground Dice: [0.8317]\n",
      "2021-11-09 18:20:52.225958: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 18:20:53.614034: lr: 0.007533\n",
      "2021-11-09 18:20:53.689685: saving checkpoint...\n",
      "2021-11-09 18:20:55.824052: done, saving took 2.20 seconds\n",
      "2021-11-09 18:20:55.869990: This epoch took 333.619828 s\n",
      "\n",
      "2021-11-09 18:20:55.875340: \n",
      "epoch:  27\n",
      "2021-11-09 18:25:53.189193: train loss : -0.8321\n",
      "2021-11-09 18:26:14.960055: validation loss: -0.8321\n",
      "2021-11-09 18:26:14.969180: Average global foreground Dice: [0.8465]\n",
      "2021-11-09 18:26:14.974370: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 18:26:16.231717: lr: 0.00744\n",
      "2021-11-09 18:26:16.321623: saving checkpoint...\n",
      "2021-11-09 18:26:17.881415: done, saving took 1.62 seconds\n",
      "2021-11-09 18:26:17.907163: This epoch took 322.026605 s\n",
      "\n",
      "2021-11-09 18:26:17.912205: \n",
      "epoch:  28\n",
      "2021-11-09 18:31:15.471053: train loss : -0.8344\n",
      "2021-11-09 18:31:34.319539: validation loss: -0.8292\n",
      "2021-11-09 18:31:34.325036: Average global foreground Dice: [0.8376]\n",
      "2021-11-09 18:31:34.329799: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 18:31:34.843363: lr: 0.007347\n",
      "2021-11-09 18:31:34.875915: saving checkpoint...\n",
      "2021-11-09 18:31:35.986747: done, saving took 1.14 seconds\n",
      "2021-11-09 18:31:36.010566: This epoch took 318.094433 s\n",
      "\n",
      "2021-11-09 18:31:36.014337: \n",
      "epoch:  29\n",
      "2021-11-09 18:36:28.690226: train loss : -0.8393\n",
      "2021-11-09 18:36:47.460522: validation loss: -0.8376\n",
      "2021-11-09 18:36:47.465862: Average global foreground Dice: [0.8517]\n",
      "2021-11-09 18:36:47.476086: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 18:36:47.962764: lr: 0.007254\n",
      "2021-11-09 18:36:47.995904: saving checkpoint...\n",
      "2021-11-09 18:36:48.979800: done, saving took 1.01 seconds\n",
      "2021-11-09 18:36:49.002311: This epoch took 312.983675 s\n",
      "\n",
      "2021-11-09 18:36:49.006531: \n",
      "epoch:  30\n",
      "2021-11-09 18:41:44.723954: train loss : -0.8333\n",
      "2021-11-09 18:42:07.179738: validation loss: -0.8361\n",
      "2021-11-09 18:42:07.193593: Average global foreground Dice: [0.8498]\n",
      "2021-11-09 18:42:07.198865: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 18:42:08.582001: lr: 0.007161\n",
      "2021-11-09 18:42:08.677476: saving checkpoint...\n",
      "2021-11-09 18:42:10.359920: done, saving took 1.77 seconds\n",
      "2021-11-09 18:42:10.386700: This epoch took 321.375347 s\n",
      "\n",
      "2021-11-09 18:42:10.391505: \n",
      "epoch:  31\n",
      "2021-11-09 18:47:11.401036: train loss : -0.8348\n",
      "2021-11-09 18:47:32.470126: validation loss: -0.8323\n",
      "2021-11-09 18:47:32.475554: Average global foreground Dice: [0.8482]\n",
      "2021-11-09 18:47:32.480690: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 18:47:33.177703: lr: 0.007067\n",
      "2021-11-09 18:47:33.211992: saving checkpoint...\n",
      "2021-11-09 18:47:34.245477: done, saving took 1.06 seconds\n",
      "2021-11-09 18:47:34.268933: This epoch took 323.873493 s\n",
      "\n",
      "2021-11-09 18:47:34.272527: \n",
      "epoch:  32\n",
      "2021-11-09 18:52:32.364269: train loss : -0.8382\n",
      "2021-11-09 18:52:51.386515: validation loss: -0.8341\n",
      "2021-11-09 18:52:51.391824: Average global foreground Dice: [0.8464]\n",
      "2021-11-09 18:52:51.396892: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 18:52:51.888326: lr: 0.006974\n",
      "2021-11-09 18:52:51.922858: saving checkpoint...\n",
      "2021-11-09 18:52:52.979182: done, saving took 1.09 seconds\n",
      "2021-11-09 18:52:53.003705: This epoch took 318.725721 s\n",
      "\n",
      "2021-11-09 18:52:53.007812: \n",
      "epoch:  33\n",
      "2021-11-09 18:57:49.533118: train loss : -0.8395\n",
      "2021-11-09 18:58:08.738383: validation loss: -0.8293\n",
      "2021-11-09 18:58:08.743064: Average global foreground Dice: [0.842]\n",
      "2021-11-09 18:58:08.748622: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 18:58:09.277432: lr: 0.00688\n",
      "2021-11-09 18:58:09.310675: saving checkpoint...\n",
      "2021-11-09 18:58:10.315027: done, saving took 1.03 seconds\n",
      "2021-11-09 18:58:10.336997: This epoch took 317.324951 s\n",
      "\n",
      "2021-11-09 18:58:10.340917: \n",
      "epoch:  34\n",
      "2021-11-09 19:03:01.802101: train loss : -0.8403\n",
      "2021-11-09 19:03:20.701330: validation loss: -0.8261\n",
      "2021-11-09 19:03:20.707446: Average global foreground Dice: [0.8424]\n",
      "2021-11-09 19:03:20.712281: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 19:03:21.200682: lr: 0.006786\n",
      "2021-11-09 19:03:21.233126: saving checkpoint...\n",
      "2021-11-09 19:03:22.306129: done, saving took 1.10 seconds\n",
      "2021-11-09 19:03:22.329707: This epoch took 311.985124 s\n",
      "\n",
      "2021-11-09 19:03:22.334810: \n",
      "epoch:  35\n",
      "2021-11-09 19:08:24.582606: train loss : -0.8372\n",
      "2021-11-09 19:08:46.307907: validation loss: -0.8255\n",
      "2021-11-09 19:08:46.324808: Average global foreground Dice: [0.8363]\n",
      "2021-11-09 19:08:46.329794: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 19:08:48.169665: lr: 0.006692\n",
      "2021-11-09 19:08:48.228035: saving checkpoint...\n",
      "2021-11-09 19:08:49.961147: done, saving took 1.79 seconds\n",
      "2021-11-09 19:08:49.986989: This epoch took 327.637583 s\n",
      "\n",
      "2021-11-09 19:08:49.992075: \n",
      "epoch:  36\n",
      "2021-11-09 19:13:48.276855: train loss : -0.8447\n",
      "2021-11-09 19:14:09.020965: validation loss: -0.8373\n",
      "2021-11-09 19:14:09.025607: Average global foreground Dice: [0.8519]\n",
      "2021-11-09 19:14:09.029655: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 19:14:09.546942: lr: 0.006598\n",
      "2021-11-09 19:14:09.580749: saving checkpoint...\n",
      "2021-11-09 19:14:10.751228: done, saving took 1.20 seconds\n",
      "2021-11-09 19:14:10.775661: This epoch took 320.777845 s\n",
      "\n",
      "2021-11-09 19:14:10.780567: \n",
      "epoch:  37\n",
      "2021-11-09 19:19:03.578050: train loss : -0.8428\n",
      "2021-11-09 19:19:24.085663: validation loss: -0.8328\n",
      "2021-11-09 19:19:24.092700: Average global foreground Dice: [0.8418]\n",
      "2021-11-09 19:19:24.097558: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 19:19:24.588352: lr: 0.006504\n",
      "2021-11-09 19:19:24.621956: saving checkpoint...\n",
      "2021-11-09 19:19:25.650358: done, saving took 1.06 seconds\n",
      "2021-11-09 19:19:25.677694: This epoch took 314.893159 s\n",
      "\n",
      "2021-11-09 19:19:25.681566: \n",
      "epoch:  38\n",
      "2021-11-09 19:24:23.014340: train loss : -0.8445\n",
      "2021-11-09 19:24:41.171064: validation loss: -0.8357\n",
      "2021-11-09 19:24:41.175993: Average global foreground Dice: [0.8475]\n",
      "2021-11-09 19:24:41.180792: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 19:24:41.665986: lr: 0.006409\n",
      "2021-11-09 19:24:41.699833: saving checkpoint...\n",
      "2021-11-09 19:24:42.675770: done, saving took 1.00 seconds\n",
      "2021-11-09 19:24:42.697034: This epoch took 317.010790 s\n",
      "\n",
      "2021-11-09 19:24:42.701475: \n",
      "epoch:  39\n",
      "2021-11-09 19:29:41.495999: train loss : -0.8481\n",
      "2021-11-09 19:30:02.594748: validation loss: -0.8469\n",
      "2021-11-09 19:30:02.612673: Average global foreground Dice: [0.858]\n",
      "2021-11-09 19:30:02.617517: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 19:30:03.729156: lr: 0.006314\n",
      "2021-11-09 19:30:03.762681: saving checkpoint...\n",
      "2021-11-09 19:30:04.704509: done, saving took 0.97 seconds\n",
      "2021-11-09 19:30:04.727104: This epoch took 322.020738 s\n",
      "\n",
      "2021-11-09 19:30:04.731756: \n",
      "epoch:  40\n",
      "2021-11-09 19:35:04.902907: train loss : -0.8483\n",
      "2021-11-09 19:35:27.089578: validation loss: -0.8329\n",
      "2021-11-09 19:35:27.103774: Average global foreground Dice: [0.8418]\n",
      "2021-11-09 19:35:27.108267: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 19:35:29.325544: lr: 0.00622\n",
      "2021-11-09 19:35:29.391585: saving checkpoint...\n",
      "2021-11-09 19:35:31.659624: done, saving took 2.33 seconds\n",
      "2021-11-09 19:35:31.687836: This epoch took 326.951846 s\n",
      "\n",
      "2021-11-09 19:35:31.693383: \n",
      "epoch:  41\n",
      "2021-11-09 19:40:31.285453: train loss : -0.8450\n",
      "2021-11-09 19:40:52.464814: validation loss: -0.8432\n",
      "2021-11-09 19:40:52.484381: Average global foreground Dice: [0.8556]\n",
      "2021-11-09 19:40:52.489505: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 19:40:53.913977: lr: 0.006125\n",
      "2021-11-09 19:40:53.974313: saving checkpoint...\n",
      "2021-11-09 19:40:54.984333: done, saving took 1.07 seconds\n",
      "2021-11-09 19:40:55.007483: This epoch took 323.308923 s\n",
      "\n",
      "2021-11-09 19:40:55.012845: \n",
      "epoch:  42\n",
      "2021-11-09 19:45:50.201616: train loss : -0.8478\n",
      "2021-11-09 19:46:11.431766: validation loss: -0.8409\n",
      "2021-11-09 19:46:11.472238: Average global foreground Dice: [0.8497]\n",
      "2021-11-09 19:46:11.476965: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 19:46:13.412453: lr: 0.00603\n",
      "2021-11-09 19:46:13.484034: saving checkpoint...\n",
      "2021-11-09 19:46:14.575055: done, saving took 1.16 seconds\n",
      "2021-11-09 19:46:14.599210: This epoch took 319.582481 s\n",
      "\n",
      "2021-11-09 19:46:14.604025: \n",
      "epoch:  43\n",
      "2021-11-09 19:51:15.476818: train loss : -0.8410\n",
      "2021-11-09 19:51:38.026481: validation loss: -0.8264\n",
      "2021-11-09 19:51:38.073233: Average global foreground Dice: [0.8353]\n",
      "2021-11-09 19:51:38.077429: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 19:51:40.098218: lr: 0.005934\n",
      "2021-11-09 19:51:40.103215: This epoch took 325.494561 s\n",
      "\n",
      "2021-11-09 19:51:40.108024: \n",
      "epoch:  44\n",
      "2021-11-09 19:56:35.774940: train loss : -0.8431\n",
      "2021-11-09 19:56:55.268646: validation loss: -0.8402\n",
      "2021-11-09 19:56:55.273611: Average global foreground Dice: [0.8498]\n",
      "2021-11-09 19:56:55.278316: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 19:56:55.761069: lr: 0.005839\n",
      "2021-11-09 19:56:55.794808: saving checkpoint...\n",
      "2021-11-09 19:56:56.833046: done, saving took 1.07 seconds\n",
      "2021-11-09 19:56:56.856305: This epoch took 316.743326 s\n",
      "\n",
      "2021-11-09 19:56:56.861389: \n",
      "epoch:  45\n",
      "2021-11-09 20:01:48.972970: train loss : -0.8471\n",
      "2021-11-09 20:02:07.822547: validation loss: -0.8306\n",
      "2021-11-09 20:02:07.826612: Average global foreground Dice: [0.8375]\n",
      "2021-11-09 20:02:07.830597: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 20:02:08.318921: lr: 0.005743\n",
      "2021-11-09 20:02:08.323900: This epoch took 311.457549 s\n",
      "\n",
      "2021-11-09 20:02:08.327571: \n",
      "epoch:  46\n",
      "2021-11-09 20:07:01.136567: train loss : -0.8484\n",
      "2021-11-09 20:07:20.230372: validation loss: -0.8360\n",
      "2021-11-09 20:07:20.235094: Average global foreground Dice: [0.8456]\n",
      "2021-11-09 20:07:20.240110: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 20:07:20.727259: lr: 0.005647\n",
      "2021-11-09 20:07:20.732820: This epoch took 312.400451 s\n",
      "\n",
      "2021-11-09 20:07:20.736868: \n",
      "epoch:  47\n",
      "2021-11-09 20:12:20.197916: train loss : -0.8486\n",
      "2021-11-09 20:12:42.493004: validation loss: -0.8311\n",
      "2021-11-09 20:12:42.504556: Average global foreground Dice: [0.844]\n",
      "2021-11-09 20:12:42.508614: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 20:12:43.578218: lr: 0.005551\n",
      "2021-11-09 20:12:43.583958: This epoch took 322.842927 s\n",
      "\n",
      "2021-11-09 20:12:43.589208: \n",
      "epoch:  48\n",
      "2021-11-09 20:17:33.101291: train loss : -0.8516\n",
      "2021-11-09 20:17:51.069907: validation loss: -0.8417\n",
      "2021-11-09 20:17:51.075604: Average global foreground Dice: [0.8483]\n",
      "2021-11-09 20:17:51.080470: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 20:17:51.569520: lr: 0.005455\n",
      "2021-11-09 20:17:51.602785: saving checkpoint...\n",
      "2021-11-09 20:17:52.674973: done, saving took 1.10 seconds\n",
      "2021-11-09 20:17:52.697663: This epoch took 309.104027 s\n",
      "\n",
      "2021-11-09 20:17:52.702097: \n",
      "epoch:  49\n",
      "2021-11-09 20:22:51.573681: train loss : -0.8506\n",
      "2021-11-09 20:23:14.008751: validation loss: -0.8415\n",
      "2021-11-09 20:23:14.014535: Average global foreground Dice: [0.8524]\n",
      "2021-11-09 20:23:14.019199: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 20:23:15.803969: lr: 0.005359\n",
      "2021-11-09 20:23:15.809574: saving scheduled checkpoint file...\n",
      "2021-11-09 20:23:15.876070: saving checkpoint...\n",
      "2021-11-09 20:23:17.280742: done, saving took 1.47 seconds\n",
      "2021-11-09 20:23:17.299812: done\n",
      "2021-11-09 20:23:17.337695: saving checkpoint...\n",
      "2021-11-09 20:23:18.404144: done, saving took 1.10 seconds\n",
      "2021-11-09 20:23:18.428457: This epoch took 325.722898 s\n",
      "\n",
      "2021-11-09 20:23:18.433239: \n",
      "epoch:  50\n",
      "2021-11-09 20:28:18.376859: train loss : -0.8500\n",
      "2021-11-09 20:28:38.522639: validation loss: -0.8390\n",
      "2021-11-09 20:28:38.528038: Average global foreground Dice: [0.8501]\n",
      "2021-11-09 20:28:38.539846: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 20:28:39.029793: lr: 0.005262\n",
      "2021-11-09 20:28:39.063701: saving checkpoint...\n",
      "2021-11-09 20:28:40.221400: done, saving took 1.19 seconds\n",
      "2021-11-09 20:28:40.245831: This epoch took 321.806386 s\n",
      "\n",
      "2021-11-09 20:28:40.249792: \n",
      "epoch:  51\n",
      "2021-11-09 20:33:35.974317: train loss : -0.8529\n",
      "2021-11-09 20:33:54.322480: validation loss: -0.8381\n",
      "2021-11-09 20:33:54.327078: Average global foreground Dice: [0.849]\n",
      "2021-11-09 20:33:54.331970: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 20:33:54.832897: lr: 0.005166\n",
      "2021-11-09 20:33:54.867143: saving checkpoint...\n",
      "2021-11-09 20:33:55.931019: done, saving took 1.09 seconds\n",
      "2021-11-09 20:33:55.956205: This epoch took 315.701760 s\n",
      "\n",
      "2021-11-09 20:33:55.960763: \n",
      "epoch:  52\n",
      "2021-11-09 20:38:54.293656: train loss : -0.8508\n",
      "2021-11-09 20:39:16.399656: validation loss: -0.8375\n",
      "2021-11-09 20:39:16.404306: Average global foreground Dice: [0.847]\n",
      "2021-11-09 20:39:16.408967: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 20:39:18.699949: lr: 0.005069\n",
      "2021-11-09 20:39:18.775123: saving checkpoint...\n",
      "2021-11-09 20:39:20.660188: done, saving took 1.96 seconds\n",
      "2021-11-09 20:39:20.686644: This epoch took 324.721075 s\n",
      "\n",
      "2021-11-09 20:39:20.692017: \n",
      "epoch:  53\n",
      "2021-11-09 20:44:17.673218: train loss : -0.8529\n",
      "2021-11-09 20:44:37.256900: validation loss: -0.8380\n",
      "2021-11-09 20:44:37.262106: Average global foreground Dice: [0.8534]\n",
      "2021-11-09 20:44:37.266361: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 20:44:37.749436: lr: 0.004971\n",
      "2021-11-09 20:44:37.782503: saving checkpoint...\n",
      "2021-11-09 20:44:38.794734: done, saving took 1.04 seconds\n",
      "2021-11-09 20:44:38.817726: This epoch took 318.120826 s\n",
      "\n",
      "2021-11-09 20:44:38.822378: \n",
      "epoch:  54\n",
      "2021-11-09 20:49:37.885810: train loss : -0.8513\n",
      "2021-11-09 20:49:58.062769: validation loss: -0.8408\n",
      "2021-11-09 20:49:58.068953: Average global foreground Dice: [0.8496]\n",
      "2021-11-09 20:49:58.073491: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 20:49:58.584982: lr: 0.004874\n",
      "2021-11-09 20:49:58.619354: saving checkpoint...\n",
      "2021-11-09 20:49:59.568612: done, saving took 0.98 seconds\n",
      "2021-11-09 20:49:59.593325: This epoch took 320.764822 s\n",
      "\n",
      "2021-11-09 20:49:59.597478: \n",
      "epoch:  55\n",
      "2021-11-09 20:55:00.932326: train loss : -0.8515\n",
      "2021-11-09 20:55:22.411090: validation loss: -0.8364\n",
      "2021-11-09 20:55:22.424358: Average global foreground Dice: [0.8465]\n",
      "2021-11-09 20:55:22.428600: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 20:55:24.078916: lr: 0.004776\n",
      "2021-11-09 20:55:24.119071: saving checkpoint...\n",
      "2021-11-09 20:55:25.222224: done, saving took 1.14 seconds\n",
      "2021-11-09 20:55:25.248449: This epoch took 325.646161 s\n",
      "\n",
      "2021-11-09 20:55:25.253011: \n",
      "epoch:  56\n",
      "2021-11-09 21:00:18.281718: train loss : -0.8531\n",
      "2021-11-09 21:00:39.809160: validation loss: -0.8346\n",
      "2021-11-09 21:00:39.816903: Average global foreground Dice: [0.844]\n",
      "2021-11-09 21:00:39.822645: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 21:00:40.440795: lr: 0.004679\n",
      "2021-11-09 21:00:40.448689: This epoch took 315.189634 s\n",
      "\n",
      "2021-11-09 21:00:40.454071: \n",
      "epoch:  57\n",
      "2021-11-09 21:05:38.723643: train loss : -0.8563\n",
      "2021-11-09 21:05:57.868076: validation loss: -0.8357\n",
      "2021-11-09 21:05:57.874141: Average global foreground Dice: [0.8438]\n",
      "2021-11-09 21:05:57.878850: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 21:05:58.388276: lr: 0.004581\n",
      "2021-11-09 21:05:58.392384: This epoch took 317.933019 s\n",
      "\n",
      "2021-11-09 21:05:58.396993: \n",
      "epoch:  58\n",
      "2021-11-09 21:10:58.685474: train loss : -0.8566\n",
      "2021-11-09 21:11:20.698931: validation loss: -0.8383\n",
      "2021-11-09 21:11:20.714237: Average global foreground Dice: [0.8504]\n",
      "2021-11-09 21:11:20.719007: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 21:11:22.661974: lr: 0.004482\n",
      "2021-11-09 21:11:22.666600: This epoch took 324.264599 s\n",
      "\n",
      "2021-11-09 21:11:22.671304: \n",
      "epoch:  59\n",
      "2021-11-09 21:16:19.472792: train loss : -0.8579\n",
      "2021-11-09 21:16:39.189126: validation loss: -0.8314\n",
      "2021-11-09 21:16:39.195128: Average global foreground Dice: [0.8442]\n",
      "2021-11-09 21:16:39.200057: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 21:16:39.701663: lr: 0.004384\n",
      "2021-11-09 21:16:39.706517: This epoch took 317.030237 s\n",
      "\n",
      "2021-11-09 21:16:39.710963: \n",
      "epoch:  60\n",
      "2021-11-09 21:21:39.779733: train loss : -0.8543\n",
      "2021-11-09 21:21:59.254897: validation loss: -0.8458\n",
      "2021-11-09 21:21:59.259666: Average global foreground Dice: [0.8569]\n",
      "2021-11-09 21:21:59.263530: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 21:21:59.776769: lr: 0.004285\n",
      "2021-11-09 21:21:59.810662: saving checkpoint...\n",
      "2021-11-09 21:22:00.869150: done, saving took 1.09 seconds\n",
      "2021-11-09 21:22:00.894717: This epoch took 321.179109 s\n",
      "\n",
      "2021-11-09 21:22:00.899081: \n",
      "epoch:  61\n",
      "2021-11-09 21:26:58.298346: train loss : -0.8586\n",
      "2021-11-09 21:27:18.450008: validation loss: -0.8345\n",
      "2021-11-09 21:27:18.455196: Average global foreground Dice: [0.8439]\n",
      "2021-11-09 21:27:18.460618: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 21:27:18.957865: lr: 0.004186\n",
      "2021-11-09 21:27:18.963213: This epoch took 318.059733 s\n",
      "\n",
      "2021-11-09 21:27:18.968266: \n",
      "epoch:  62\n",
      "2021-11-09 21:32:17.000332: train loss : -0.8583\n",
      "2021-11-09 21:32:37.622755: validation loss: -0.8425\n",
      "2021-11-09 21:32:37.627756: Average global foreground Dice: [0.8537]\n",
      "2021-11-09 21:32:37.635050: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 21:32:38.289749: lr: 0.004087\n",
      "2021-11-09 21:32:38.322632: saving checkpoint...\n",
      "2021-11-09 21:32:39.290395: done, saving took 1.00 seconds\n",
      "2021-11-09 21:32:39.313423: This epoch took 320.341095 s\n",
      "\n",
      "2021-11-09 21:32:39.317644: \n",
      "epoch:  63\n",
      "2021-11-09 21:37:34.517227: train loss : -0.8539\n",
      "2021-11-09 21:37:55.520946: validation loss: -0.8497\n",
      "2021-11-09 21:37:55.527388: Average global foreground Dice: [0.8621]\n",
      "2021-11-09 21:37:55.532626: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 21:37:56.731452: lr: 0.003987\n",
      "2021-11-09 21:37:56.771585: saving checkpoint...\n",
      "2021-11-09 21:37:57.812671: done, saving took 1.08 seconds\n",
      "2021-11-09 21:37:57.836096: This epoch took 318.513323 s\n",
      "\n",
      "2021-11-09 21:37:57.840944: \n",
      "epoch:  64\n",
      "2021-11-09 21:42:54.985604: train loss : -0.8607\n",
      "2021-11-09 21:43:15.042800: validation loss: -0.8406\n",
      "2021-11-09 21:43:15.047958: Average global foreground Dice: [0.8517]\n",
      "2021-11-09 21:43:15.053015: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 21:43:15.550921: lr: 0.003887\n",
      "2021-11-09 21:43:15.584497: saving checkpoint...\n",
      "2021-11-09 21:43:16.614518: done, saving took 1.06 seconds\n",
      "2021-11-09 21:43:16.642849: This epoch took 318.797641 s\n",
      "\n",
      "2021-11-09 21:43:16.647907: \n",
      "epoch:  65\n",
      "2021-11-09 21:48:11.785635: train loss : -0.8630\n",
      "2021-11-09 21:48:32.642040: validation loss: -0.8501\n",
      "2021-11-09 21:48:32.647443: Average global foreground Dice: [0.8592]\n",
      "2021-11-09 21:48:32.651619: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 21:48:33.238194: lr: 0.003787\n",
      "2021-11-09 21:48:33.302559: saving checkpoint...\n",
      "2021-11-09 21:48:34.338658: done, saving took 1.10 seconds\n",
      "2021-11-09 21:48:34.359945: This epoch took 317.706679 s\n",
      "\n",
      "2021-11-09 21:48:34.364267: \n",
      "epoch:  66\n",
      "2021-11-09 21:53:32.300017: train loss : -0.8590\n",
      "2021-11-09 21:53:53.913029: validation loss: -0.8388\n",
      "2021-11-09 21:53:53.926080: Average global foreground Dice: [0.8477]\n",
      "2021-11-09 21:53:53.959616: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 21:53:55.711280: lr: 0.003687\n",
      "2021-11-09 21:53:55.716732: This epoch took 321.347068 s\n",
      "\n",
      "2021-11-09 21:53:55.721653: \n",
      "epoch:  67\n",
      "2021-11-09 21:58:52.889477: train loss : -0.8649\n",
      "2021-11-09 21:59:14.517083: validation loss: -0.8415\n",
      "2021-11-09 21:59:14.563704: Average global foreground Dice: [0.8483]\n",
      "2021-11-09 21:59:14.568872: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 21:59:16.401621: lr: 0.003586\n",
      "2021-11-09 21:59:16.407104: This epoch took 320.680551 s\n",
      "\n",
      "2021-11-09 21:59:16.411100: \n",
      "epoch:  68\n",
      "2021-11-09 22:04:20.479643: train loss : -0.8613\n",
      "2021-11-09 22:04:42.493089: validation loss: -0.8455\n",
      "2021-11-09 22:04:42.517667: Average global foreground Dice: [0.8533]\n",
      "2021-11-09 22:04:42.522656: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 22:04:45.260361: lr: 0.003485\n",
      "2021-11-09 22:04:45.265433: This epoch took 328.849778 s\n",
      "\n",
      "2021-11-09 22:04:45.270137: \n",
      "epoch:  69\n",
      "2021-11-09 22:09:43.877010: train loss : -0.8642\n",
      "2021-11-09 22:10:04.194999: validation loss: -0.8452\n",
      "2021-11-09 22:10:04.199470: Average global foreground Dice: [0.8555]\n",
      "2021-11-09 22:10:04.204067: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 22:10:04.699285: lr: 0.003384\n",
      "2021-11-09 22:10:04.732545: saving checkpoint...\n",
      "2021-11-09 22:10:05.866612: done, saving took 1.16 seconds\n",
      "2021-11-09 22:10:05.890204: This epoch took 320.615150 s\n",
      "\n",
      "2021-11-09 22:10:05.895232: \n",
      "epoch:  70\n",
      "2021-11-09 22:15:06.723153: train loss : -0.8618\n",
      "2021-11-09 22:15:27.830021: validation loss: -0.8361\n",
      "2021-11-09 22:15:27.864404: Average global foreground Dice: [0.8442]\n",
      "2021-11-09 22:15:27.869555: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 22:15:29.524132: lr: 0.003282\n",
      "2021-11-09 22:15:29.529104: This epoch took 323.629682 s\n",
      "\n",
      "2021-11-09 22:15:29.559618: \n",
      "epoch:  71\n",
      "2021-11-09 22:20:27.073460: train loss : -0.8688\n",
      "2021-11-09 22:20:46.000864: validation loss: -0.8467\n",
      "2021-11-09 22:20:46.006949: Average global foreground Dice: [0.8561]\n",
      "2021-11-09 22:20:46.011610: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 22:20:46.512525: lr: 0.00318\n",
      "2021-11-09 22:20:46.516991: This epoch took 316.953326 s\n",
      "\n",
      "2021-11-09 22:20:46.521761: \n",
      "epoch:  72\n",
      "2021-11-09 22:25:45.709685: train loss : -0.8643\n",
      "2021-11-09 22:26:06.233096: validation loss: -0.8428\n",
      "2021-11-09 22:26:06.238640: Average global foreground Dice: [0.8526]\n",
      "2021-11-09 22:26:06.244017: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 22:26:06.753376: lr: 0.003078\n",
      "2021-11-09 22:26:06.787246: saving checkpoint...\n",
      "2021-11-09 22:26:07.881611: done, saving took 1.12 seconds\n",
      "2021-11-09 22:26:07.910593: This epoch took 321.384395 s\n",
      "\n",
      "2021-11-09 22:26:07.915820: \n",
      "epoch:  73\n",
      "2021-11-09 22:31:14.180863: train loss : -0.8675\n",
      "2021-11-09 22:31:37.030025: validation loss: -0.8507\n",
      "2021-11-09 22:31:37.080114: Average global foreground Dice: [0.8615]\n",
      "2021-11-09 22:31:37.097478: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 22:31:40.420563: lr: 0.002975\n",
      "2021-11-09 22:31:40.485054: saving checkpoint...\n",
      "2021-11-09 22:31:42.020430: done, saving took 1.59 seconds\n",
      "2021-11-09 22:31:42.070428: This epoch took 334.149965 s\n",
      "\n",
      "2021-11-09 22:31:42.075462: \n",
      "epoch:  74\n",
      "2021-11-09 22:36:40.885425: train loss : -0.8624\n",
      "2021-11-09 22:37:03.663428: validation loss: -0.8396\n",
      "2021-11-09 22:37:03.672394: Average global foreground Dice: [0.8479]\n",
      "2021-11-09 22:37:03.677645: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 22:37:05.287765: lr: 0.002872\n",
      "2021-11-09 22:37:05.292932: This epoch took 323.212509 s\n",
      "\n",
      "2021-11-09 22:37:05.297837: \n",
      "epoch:  75\n",
      "2021-11-09 22:42:03.972627: train loss : -0.8641\n",
      "2021-11-09 22:42:24.821596: validation loss: -0.8414\n",
      "2021-11-09 22:42:24.827982: Average global foreground Dice: [0.8497]\n",
      "2021-11-09 22:42:24.833051: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 22:42:25.567421: lr: 0.002768\n",
      "2021-11-09 22:42:25.572658: This epoch took 320.270024 s\n",
      "\n",
      "2021-11-09 22:42:25.576474: \n",
      "epoch:  76\n",
      "2021-11-09 22:47:21.271983: train loss : -0.8635\n",
      "2021-11-09 22:47:41.126972: validation loss: -0.8443\n",
      "2021-11-09 22:47:41.133402: Average global foreground Dice: [0.8543]\n",
      "2021-11-09 22:47:41.137764: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 22:47:41.647403: lr: 0.002664\n",
      "2021-11-09 22:47:41.652881: This epoch took 316.072264 s\n",
      "\n",
      "2021-11-09 22:47:41.657133: \n",
      "epoch:  77\n",
      "2021-11-09 22:52:33.429142: train loss : -0.8667\n",
      "2021-11-09 22:52:54.810042: validation loss: -0.8435\n",
      "2021-11-09 22:52:54.828473: Average global foreground Dice: [0.8492]\n",
      "2021-11-09 22:52:54.859763: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 22:52:55.787034: lr: 0.00256\n",
      "2021-11-09 22:52:55.791561: This epoch took 314.129794 s\n",
      "\n",
      "2021-11-09 22:52:55.796600: \n",
      "epoch:  78\n",
      "2021-11-09 22:57:43.598681: train loss : -0.8692\n",
      "2021-11-09 22:58:01.698569: validation loss: -0.8543\n",
      "2021-11-09 22:58:01.704091: Average global foreground Dice: [0.8643]\n",
      "2021-11-09 22:58:01.708825: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 22:58:02.206010: lr: 0.002455\n",
      "2021-11-09 22:58:02.240901: saving checkpoint...\n",
      "2021-11-09 22:58:03.289352: done, saving took 1.08 seconds\n",
      "2021-11-09 22:58:03.315805: This epoch took 307.513723 s\n",
      "\n",
      "2021-11-09 22:58:03.320478: \n",
      "epoch:  79\n",
      "2021-11-09 23:02:57.572788: train loss : -0.8698\n",
      "2021-11-09 23:03:17.504607: validation loss: -0.8478\n",
      "2021-11-09 23:03:17.509121: Average global foreground Dice: [0.8532]\n",
      "2021-11-09 23:03:17.512980: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 23:03:18.020916: lr: 0.002349\n",
      "2021-11-09 23:03:18.071681: saving checkpoint...\n",
      "2021-11-09 23:03:18.983896: done, saving took 0.96 seconds\n",
      "2021-11-09 23:03:19.011424: This epoch took 315.686235 s\n",
      "\n",
      "2021-11-09 23:03:19.016209: \n",
      "epoch:  80\n",
      "2021-11-09 23:08:16.921834: train loss : -0.8690\n",
      "2021-11-09 23:08:40.677094: validation loss: -0.8450\n",
      "2021-11-09 23:08:40.683439: Average global foreground Dice: [0.8533]\n",
      "2021-11-09 23:08:40.688560: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 23:08:43.860189: lr: 0.002243\n",
      "2021-11-09 23:08:43.919829: saving checkpoint...\n",
      "2021-11-09 23:08:45.718248: done, saving took 1.85 seconds\n",
      "2021-11-09 23:08:45.770248: This epoch took 326.749021 s\n",
      "\n",
      "2021-11-09 23:08:45.776304: \n",
      "epoch:  81\n",
      "2021-11-09 23:13:45.086119: train loss : -0.8672\n",
      "2021-11-09 23:14:06.267946: validation loss: -0.8479\n",
      "2021-11-09 23:14:06.272812: Average global foreground Dice: [0.8575]\n",
      "2021-11-09 23:14:06.277563: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 23:14:08.618248: lr: 0.002137\n",
      "2021-11-09 23:14:08.703323: saving checkpoint...\n",
      "2021-11-09 23:14:10.036496: done, saving took 1.41 seconds\n",
      "2021-11-09 23:14:10.070020: This epoch took 324.288948 s\n",
      "\n",
      "2021-11-09 23:14:10.075044: \n",
      "epoch:  82\n",
      "2021-11-09 23:19:09.789290: train loss : -0.8676\n",
      "2021-11-09 23:19:29.923281: validation loss: -0.8394\n",
      "2021-11-09 23:19:29.929081: Average global foreground Dice: [0.8459]\n",
      "2021-11-09 23:19:29.934738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 23:19:30.430068: lr: 0.00203\n",
      "2021-11-09 23:19:30.434265: This epoch took 320.354175 s\n",
      "\n",
      "2021-11-09 23:19:30.440821: \n",
      "epoch:  83\n",
      "2021-11-09 23:24:29.785440: train loss : -0.8700\n",
      "2021-11-09 23:24:52.033036: validation loss: -0.8438\n",
      "2021-11-09 23:24:52.072320: Average global foreground Dice: [0.8546]\n",
      "2021-11-09 23:24:52.077145: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 23:24:54.319562: lr: 0.001922\n",
      "2021-11-09 23:24:54.324078: This epoch took 323.877697 s\n",
      "\n",
      "2021-11-09 23:24:54.327873: \n",
      "epoch:  84\n",
      "2021-11-09 23:29:50.405076: train loss : -0.8694\n",
      "2021-11-09 23:30:11.474207: validation loss: -0.8445\n",
      "2021-11-09 23:30:11.480216: Average global foreground Dice: [0.8524]\n",
      "2021-11-09 23:30:11.484255: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 23:30:11.984101: lr: 0.001813\n",
      "2021-11-09 23:30:11.988921: This epoch took 317.629710 s\n",
      "\n",
      "2021-11-09 23:30:11.993770: \n",
      "epoch:  85\n",
      "2021-11-09 23:35:13.284855: train loss : -0.8701\n",
      "2021-11-09 23:35:35.879377: validation loss: -0.8464\n",
      "2021-11-09 23:35:35.892540: Average global foreground Dice: [0.8546]\n",
      "2021-11-09 23:35:35.896864: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 23:35:37.407558: lr: 0.001704\n",
      "2021-11-09 23:35:37.412358: This epoch took 325.414199 s\n",
      "\n",
      "2021-11-09 23:35:37.417359: \n",
      "epoch:  86\n",
      "2021-11-09 23:40:44.064085: train loss : -0.8677\n",
      "2021-11-09 23:41:05.121674: validation loss: -0.8380\n",
      "2021-11-09 23:41:05.160147: Average global foreground Dice: [0.8463]\n",
      "2021-11-09 23:41:05.164991: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 23:41:06.691144: lr: 0.001594\n",
      "2021-11-09 23:41:06.695670: This epoch took 329.273342 s\n",
      "\n",
      "2021-11-09 23:41:06.700785: \n",
      "epoch:  87\n",
      "2021-11-09 23:46:00.473004: train loss : -0.8710\n",
      "2021-11-09 23:46:19.675820: validation loss: -0.8436\n",
      "2021-11-09 23:46:19.680788: Average global foreground Dice: [0.8552]\n",
      "2021-11-09 23:46:19.685574: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 23:46:20.207695: lr: 0.001483\n",
      "2021-11-09 23:46:20.212202: This epoch took 313.507043 s\n",
      "\n",
      "2021-11-09 23:46:20.216807: \n",
      "epoch:  88\n",
      "2021-11-09 23:51:19.003229: train loss : -0.8727\n",
      "2021-11-09 23:51:40.380605: validation loss: -0.8449\n",
      "2021-11-09 23:51:40.386227: Average global foreground Dice: [0.854]\n",
      "2021-11-09 23:51:40.390908: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 23:51:41.023600: lr: 0.001372\n",
      "2021-11-09 23:51:41.027468: This epoch took 320.805603 s\n",
      "\n",
      "2021-11-09 23:51:41.032199: \n",
      "epoch:  89\n",
      "2021-11-09 23:56:32.533367: train loss : -0.8743\n",
      "2021-11-09 23:56:50.901635: validation loss: -0.8372\n",
      "2021-11-09 23:56:50.907351: Average global foreground Dice: [0.8455]\n",
      "2021-11-09 23:56:50.911932: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-09 23:56:51.421697: lr: 0.001259\n",
      "2021-11-09 23:56:51.426611: This epoch took 310.389724 s\n",
      "\n",
      "2021-11-09 23:56:51.430664: \n",
      "epoch:  90\n",
      "2021-11-10 00:01:48.585700: train loss : -0.8717\n",
      "2021-11-10 00:02:11.091703: validation loss: -0.8406\n",
      "2021-11-10 00:02:11.112818: Average global foreground Dice: [0.8496]\n",
      "2021-11-10 00:02:11.118398: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 00:02:13.392050: lr: 0.001145\n",
      "2021-11-10 00:02:13.396803: This epoch took 321.961171 s\n",
      "\n",
      "2021-11-10 00:02:13.401310: \n",
      "epoch:  91\n",
      "2021-11-10 00:07:07.794495: train loss : -0.8745\n",
      "2021-11-10 00:07:27.030270: validation loss: -0.8366\n",
      "2021-11-10 00:07:27.035957: Average global foreground Dice: [0.8444]\n",
      "2021-11-10 00:07:27.040745: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 00:07:27.532487: lr: 0.00103\n",
      "2021-11-10 00:07:27.537683: This epoch took 314.131909 s\n",
      "\n",
      "2021-11-10 00:07:27.541777: \n",
      "epoch:  92\n",
      "2021-11-10 00:12:26.797158: train loss : -0.8745\n",
      "2021-11-10 00:12:48.594740: validation loss: -0.8495\n",
      "2021-11-10 00:12:48.600693: Average global foreground Dice: [0.8578]\n",
      "2021-11-10 00:12:48.604356: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 00:12:49.472634: lr: 0.000913\n",
      "2021-11-10 00:12:49.477126: This epoch took 321.930681 s\n",
      "\n",
      "2021-11-10 00:12:49.480889: \n",
      "epoch:  93\n",
      "2021-11-10 00:17:50.099654: train loss : -0.8737\n",
      "2021-11-10 00:18:10.662988: validation loss: -0.8457\n",
      "2021-11-10 00:18:10.667740: Average global foreground Dice: [0.8531]\n",
      "2021-11-10 00:18:10.672582: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 00:18:11.170080: lr: 0.000795\n",
      "2021-11-10 00:18:11.181335: This epoch took 321.695182 s\n",
      "\n",
      "2021-11-10 00:18:11.185564: \n",
      "epoch:  94\n",
      "2021-11-10 00:23:25.972943: train loss : -0.8747\n",
      "2021-11-10 00:23:47.681856: validation loss: -0.8457\n",
      "2021-11-10 00:23:47.696721: Average global foreground Dice: [0.8548]\n",
      "2021-11-10 00:23:47.701717: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 00:23:49.095025: lr: 0.000675\n",
      "2021-11-10 00:23:49.099015: This epoch took 337.909795 s\n",
      "\n",
      "2021-11-10 00:23:49.103772: \n",
      "epoch:  95\n",
      "2021-11-10 00:28:46.864576: train loss : -0.8751\n",
      "2021-11-10 00:29:06.745333: validation loss: -0.8434\n",
      "2021-11-10 00:29:06.749792: Average global foreground Dice: [0.8512]\n",
      "2021-11-10 00:29:06.754115: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 00:29:07.275645: lr: 0.000552\n",
      "2021-11-10 00:29:07.279752: This epoch took 318.172056 s\n",
      "\n",
      "2021-11-10 00:29:07.283851: \n",
      "epoch:  96\n",
      "2021-11-10 00:34:08.595874: train loss : -0.8757\n",
      "2021-11-10 00:34:29.616213: validation loss: -0.8462\n",
      "2021-11-10 00:34:29.621532: Average global foreground Dice: [0.8533]\n",
      "2021-11-10 00:34:29.626218: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 00:34:30.134054: lr: 0.000426\n",
      "2021-11-10 00:34:30.138237: This epoch took 322.850175 s\n",
      "\n",
      "2021-11-10 00:34:30.142554: \n",
      "epoch:  97\n",
      "2021-11-10 00:39:24.274072: train loss : -0.8764\n",
      "2021-11-10 00:39:45.905324: validation loss: -0.8413\n",
      "2021-11-10 00:39:45.920738: Average global foreground Dice: [0.8498]\n",
      "2021-11-10 00:39:45.925776: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 00:39:46.967470: lr: 0.000296\n",
      "2021-11-10 00:39:46.971390: This epoch took 316.824059 s\n",
      "\n",
      "2021-11-10 00:39:46.975455: \n",
      "epoch:  98\n",
      "2021-11-10 00:44:46.134917: train loss : -0.8758\n",
      "2021-11-10 00:45:06.599277: validation loss: -0.8480\n",
      "2021-11-10 00:45:06.618975: Average global foreground Dice: [0.8545]\n",
      "2021-11-10 00:45:06.623641: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 00:45:08.633009: lr: 0.000158\n",
      "2021-11-10 00:45:08.663499: This epoch took 321.683207 s\n",
      "\n",
      "2021-11-10 00:45:08.667581: \n",
      "epoch:  99\n",
      "2021-11-10 00:50:08.716945: train loss : -0.8749\n",
      "2021-11-10 00:50:30.425469: validation loss: -0.8490\n",
      "2021-11-10 00:50:30.432067: Average global foreground Dice: [0.8531]\n",
      "2021-11-10 00:50:30.463760: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 00:50:32.509266: lr: 0.0\n",
      "2021-11-10 00:50:32.513855: saving scheduled checkpoint file...\n",
      "2021-11-10 00:50:32.606257: saving checkpoint...\n",
      "2021-11-10 00:50:34.124918: done, saving took 1.61 seconds\n",
      "2021-11-10 00:50:34.181424: done\n",
      "2021-11-10 00:50:34.187006: This epoch took 325.515026 s\n",
      "\n",
      "2021-11-10 00:50:34.262545: saving checkpoint...\n",
      "2021-11-10 00:50:35.468123: done, saving took 1.28 seconds\n",
      "23090567_20160819 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150401 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130213 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120627 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090590_20121212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160706 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090599_20140701 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130225 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090604_20140303 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090615_20140403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090617_20140211 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120406 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160111 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130213 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090631_20130128 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090634_20150409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-10 00:54:00.213036: finished prediction\n",
      "2021-11-10 00:54:00.217888: evaluation of raw predictions\n",
      "2021-11-10 00:54:01.984409: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8551531705260019\n",
      "after:  0.8551531705260019\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-10 00:54:11.580192: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-10 00:54:11.595017: The split file contains 5 splits.\n",
      "2021-11-10 00:54:11.598989: Desired fold for training: 2\n",
      "2021-11-10 00:54:11.603134: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-10 00:54:15.959174: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-10 00:54:43.123319: Unable to plot network architecture:\n",
      "2021-11-10 00:54:43.127220: No module named 'hiddenlayer'\n",
      "2021-11-10 00:54:43.131408: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-10 00:54:43.162681: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-10 00:54:43.200632: \n",
      "\n",
      "2021-11-10 00:54:43.206806: \n",
      "epoch:  0\n",
      "2021-11-10 01:00:08.081639: train loss : -0.1986\n",
      "2021-11-10 01:00:31.020381: validation loss: -0.5867\n",
      "2021-11-10 01:00:31.063121: Average global foreground Dice: [0.6536]\n",
      "2021-11-10 01:00:31.068123: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 01:00:32.811747: lr: 0.00991\n",
      "2021-11-10 01:00:32.817014: This epoch took 349.605343 s\n",
      "\n",
      "2021-11-10 01:00:32.820926: \n",
      "epoch:  1\n",
      "2021-11-10 01:05:29.592628: train loss : -0.6311\n",
      "2021-11-10 01:05:50.615574: validation loss: -0.6894\n",
      "2021-11-10 01:05:50.620926: Average global foreground Dice: [0.7318]\n",
      "2021-11-10 01:05:50.625859: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 01:05:51.164279: lr: 0.00982\n",
      "2021-11-10 01:05:51.246374: saving checkpoint...\n",
      "2021-11-10 01:05:52.075687: done, saving took 0.91 seconds\n",
      "2021-11-10 01:05:52.109560: This epoch took 319.284990 s\n",
      "\n",
      "2021-11-10 01:05:52.113595: \n",
      "epoch:  2\n",
      "2021-11-10 01:11:01.890335: train loss : -0.6852\n",
      "2021-11-10 01:11:24.399970: validation loss: -0.7054\n",
      "2021-11-10 01:11:24.405647: Average global foreground Dice: [0.7506]\n",
      "2021-11-10 01:11:24.410438: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 01:11:26.461191: lr: 0.00973\n",
      "2021-11-10 01:11:26.676558: saving checkpoint...\n",
      "2021-11-10 01:11:29.159594: done, saving took 2.69 seconds\n",
      "2021-11-10 01:11:29.204541: This epoch took 337.087123 s\n",
      "\n",
      "2021-11-10 01:11:29.208908: \n",
      "epoch:  3\n",
      "2021-11-10 01:16:25.896699: train loss : -0.7284\n",
      "2021-11-10 01:16:46.963115: validation loss: -0.7369\n",
      "2021-11-10 01:16:47.000614: Average global foreground Dice: [0.7836]\n",
      "2021-11-10 01:16:47.004961: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 01:16:49.360534: lr: 0.009639\n",
      "2021-11-10 01:16:49.507252: saving checkpoint...\n",
      "2021-11-10 01:16:51.124112: done, saving took 1.75 seconds\n",
      "2021-11-10 01:16:51.160459: This epoch took 321.946860 s\n",
      "\n",
      "2021-11-10 01:16:51.164816: \n",
      "epoch:  4\n",
      "2021-11-10 01:21:48.672885: train loss : -0.7528\n",
      "2021-11-10 01:22:10.789848: validation loss: -0.7608\n",
      "2021-11-10 01:22:10.808023: Average global foreground Dice: [0.7949]\n",
      "2021-11-10 01:22:10.813190: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 01:22:13.321704: lr: 0.009549\n",
      "2021-11-10 01:22:13.417947: saving checkpoint...\n",
      "2021-11-10 01:22:14.838685: done, saving took 1.51 seconds\n",
      "2021-11-10 01:22:14.876867: This epoch took 323.708338 s\n",
      "\n",
      "2021-11-10 01:22:14.880979: \n",
      "epoch:  5\n",
      "2021-11-10 01:27:10.876952: train loss : -0.7602\n",
      "2021-11-10 01:27:29.727381: validation loss: -0.7757\n",
      "2021-11-10 01:27:29.731573: Average global foreground Dice: [0.8064]\n",
      "2021-11-10 01:27:29.735304: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 01:27:30.266880: lr: 0.009458\n",
      "2021-11-10 01:27:30.331741: saving checkpoint...\n",
      "2021-11-10 01:27:31.396508: done, saving took 1.12 seconds\n",
      "2021-11-10 01:27:31.429489: This epoch took 316.544424 s\n",
      "\n",
      "2021-11-10 01:27:31.433373: \n",
      "epoch:  6\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-10 01:32:29.581453: train loss : -0.7795\n",
      "2021-11-10 01:32:53.011622: validation loss: -0.7872\n",
      "2021-11-10 01:32:53.026054: Average global foreground Dice: [0.8159]\n",
      "2021-11-10 01:32:53.030344: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 01:32:55.408800: lr: 0.009368\n",
      "2021-11-10 01:32:55.595189: saving checkpoint...\n",
      "2021-11-10 01:32:57.035296: done, saving took 1.62 seconds\n",
      "2021-11-10 01:32:57.066030: This epoch took 325.629134 s\n",
      "\n",
      "2021-11-10 01:32:57.070629: \n",
      "epoch:  7\n",
      "2021-11-10 01:37:53.987655: train loss : -0.7880\n",
      "2021-11-10 01:38:15.323211: validation loss: -0.7693\n",
      "2021-11-10 01:38:15.328288: Average global foreground Dice: [0.8038]\n",
      "2021-11-10 01:38:15.359355: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 01:38:16.074008: lr: 0.009277\n",
      "2021-11-10 01:38:16.139884: saving checkpoint...\n",
      "2021-11-10 01:38:17.433090: done, saving took 1.35 seconds\n",
      "2021-11-10 01:38:17.458224: This epoch took 320.381638 s\n",
      "\n",
      "2021-11-10 01:38:17.462654: \n",
      "epoch:  8\n",
      "2021-11-10 01:43:12.267345: train loss : -0.7963\n",
      "2021-11-10 01:43:33.061911: validation loss: -0.7771\n",
      "2021-11-10 01:43:33.066804: Average global foreground Dice: [0.81]\n",
      "2021-11-10 01:43:33.071524: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 01:43:33.653236: lr: 0.009186\n",
      "2021-11-10 01:43:33.686736: saving checkpoint...\n",
      "2021-11-10 01:43:34.737455: done, saving took 1.08 seconds\n",
      "2021-11-10 01:43:34.760721: This epoch took 317.294277 s\n",
      "\n",
      "2021-11-10 01:43:34.764705: \n",
      "epoch:  9\n",
      "2021-11-10 01:48:31.285349: train loss : -0.7931\n",
      "2021-11-10 01:48:52.513070: validation loss: -0.8068\n",
      "2021-11-10 01:48:52.560106: Average global foreground Dice: [0.8293]\n",
      "2021-11-10 01:48:52.567189: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 01:48:55.193167: lr: 0.009095\n",
      "2021-11-10 01:48:55.271724: saving checkpoint...\n",
      "2021-11-10 01:48:56.621245: done, saving took 1.42 seconds\n",
      "2021-11-10 01:48:56.659163: This epoch took 321.889666 s\n",
      "\n",
      "2021-11-10 01:48:56.664589: \n",
      "epoch:  10\n",
      "2021-11-10 01:53:53.176948: train loss : -0.8052\n",
      "2021-11-10 01:54:13.157028: validation loss: -0.8145\n",
      "2021-11-10 01:54:13.164410: Average global foreground Dice: [0.8371]\n",
      "2021-11-10 01:54:13.170414: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 01:54:13.720677: lr: 0.009004\n",
      "2021-11-10 01:54:13.757816: saving checkpoint...\n",
      "2021-11-10 01:54:14.855031: done, saving took 1.13 seconds\n",
      "2021-11-10 01:54:14.896404: This epoch took 318.227812 s\n",
      "\n",
      "2021-11-10 01:54:14.900390: \n",
      "epoch:  11\n",
      "2021-11-10 01:59:21.134938: train loss : -0.8103\n",
      "2021-11-10 01:59:43.593381: validation loss: -0.8111\n",
      "2021-11-10 01:59:43.615098: Average global foreground Dice: [0.8347]\n",
      "2021-11-10 01:59:43.625701: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 01:59:46.160317: lr: 0.008913\n",
      "2021-11-10 01:59:46.207663: saving checkpoint...\n",
      "2021-11-10 01:59:48.193843: done, saving took 2.03 seconds\n",
      "2021-11-10 01:59:48.229167: This epoch took 333.324948 s\n",
      "\n",
      "2021-11-10 01:59:48.259614: \n",
      "epoch:  12\n",
      "2021-11-10 02:04:45.968014: train loss : -0.8135\n",
      "2021-11-10 02:05:07.486558: validation loss: -0.8032\n",
      "2021-11-10 02:05:07.504797: Average global foreground Dice: [0.8313]\n",
      "2021-11-10 02:05:07.509201: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 02:05:08.992935: lr: 0.008822\n",
      "2021-11-10 02:05:09.072547: saving checkpoint...\n",
      "2021-11-10 02:05:10.477394: done, saving took 1.48 seconds\n",
      "2021-11-10 02:05:10.517894: This epoch took 322.253043 s\n",
      "\n",
      "2021-11-10 02:05:10.524839: \n",
      "epoch:  13\n",
      "2021-11-10 02:10:07.788912: train loss : -0.8153\n",
      "2021-11-10 02:10:29.973708: validation loss: -0.7953\n",
      "2021-11-10 02:10:29.984452: Average global foreground Dice: [0.828]\n",
      "2021-11-10 02:10:29.989316: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 02:10:32.460275: lr: 0.008731\n",
      "2021-11-10 02:10:32.618211: saving checkpoint...\n",
      "2021-11-10 02:10:34.421347: done, saving took 1.95 seconds\n",
      "2021-11-10 02:10:34.478958: This epoch took 323.946299 s\n",
      "\n",
      "2021-11-10 02:10:34.483798: \n",
      "epoch:  14\n",
      "2021-11-10 02:15:30.285598: train loss : -0.8184\n",
      "2021-11-10 02:15:51.624299: validation loss: -0.7941\n",
      "2021-11-10 02:15:51.665124: Average global foreground Dice: [0.8223]\n",
      "2021-11-10 02:15:51.670737: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 02:15:53.030669: lr: 0.008639\n",
      "2021-11-10 02:15:53.094342: saving checkpoint...\n",
      "2021-11-10 02:15:54.295326: done, saving took 1.26 seconds\n",
      "2021-11-10 02:15:54.321252: This epoch took 319.832899 s\n",
      "\n",
      "2021-11-10 02:15:54.327155: \n",
      "epoch:  15\n",
      "2021-11-10 02:20:50.613302: train loss : -0.8214\n",
      "2021-11-10 02:21:13.326404: validation loss: -0.8102\n",
      "2021-11-10 02:21:13.360290: Average global foreground Dice: [0.8365]\n",
      "2021-11-10 02:21:13.384026: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 02:21:16.120956: lr: 0.008548\n",
      "2021-11-10 02:21:16.205012: saving checkpoint...\n",
      "2021-11-10 02:21:17.975525: done, saving took 1.85 seconds\n",
      "2021-11-10 02:21:18.012025: This epoch took 323.680198 s\n",
      "\n",
      "2021-11-10 02:21:18.016974: \n",
      "epoch:  16\n",
      "2021-11-10 02:26:11.559492: train loss : -0.8247\n",
      "2021-11-10 02:26:32.705802: validation loss: -0.8042\n",
      "2021-11-10 02:26:32.729785: Average global foreground Dice: [0.8304]\n",
      "2021-11-10 02:26:32.759609: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 02:26:35.003092: lr: 0.008456\n",
      "2021-11-10 02:26:35.081089: saving checkpoint...\n",
      "2021-11-10 02:26:36.520178: done, saving took 1.51 seconds\n",
      "2021-11-10 02:26:36.562481: This epoch took 318.540548 s\n",
      "\n",
      "2021-11-10 02:26:36.567234: \n",
      "epoch:  17\n",
      "2021-11-10 02:31:31.264025: train loss : -0.8226\n",
      "2021-11-10 02:31:52.071101: validation loss: -0.8186\n",
      "2021-11-10 02:31:52.076368: Average global foreground Dice: [0.8421]\n",
      "2021-11-10 02:31:52.081019: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 02:31:52.711826: lr: 0.008364\n",
      "2021-11-10 02:31:52.745715: saving checkpoint...\n",
      "2021-11-10 02:31:53.782096: done, saving took 1.07 seconds\n",
      "2021-11-10 02:31:53.813421: This epoch took 317.240237 s\n",
      "\n",
      "2021-11-10 02:31:53.817202: \n",
      "epoch:  18\n",
      "2021-11-10 02:36:47.486002: train loss : -0.8246\n",
      "2021-11-10 02:37:08.517445: validation loss: -0.7989\n",
      "2021-11-10 02:37:08.560060: Average global foreground Dice: [0.8261]\n",
      "2021-11-10 02:37:08.566246: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 02:37:10.885650: lr: 0.008272\n",
      "2021-11-10 02:37:10.924248: saving checkpoint...\n",
      "2021-11-10 02:37:12.081891: done, saving took 1.19 seconds\n",
      "2021-11-10 02:37:12.116079: This epoch took 318.293694 s\n",
      "\n",
      "2021-11-10 02:37:12.121065: \n",
      "epoch:  19\n",
      "2021-11-10 02:42:03.137355: train loss : -0.8289\n",
      "2021-11-10 02:42:23.916158: validation loss: -0.8081\n",
      "2021-11-10 02:42:23.921833: Average global foreground Dice: [0.8336]\n",
      "2021-11-10 02:42:23.926427: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 02:42:24.468336: lr: 0.008181\n",
      "2021-11-10 02:42:24.502094: saving checkpoint...\n",
      "2021-11-10 02:42:25.595239: done, saving took 1.12 seconds\n",
      "2021-11-10 02:42:25.631444: This epoch took 313.505903 s\n",
      "\n",
      "2021-11-10 02:42:25.636546: \n",
      "epoch:  20\n",
      "2021-11-10 02:47:18.289287: train loss : -0.8190\n",
      "2021-11-10 02:47:38.511275: validation loss: -0.8221\n",
      "2021-11-10 02:47:38.516576: Average global foreground Dice: [0.8438]\n",
      "2021-11-10 02:47:38.521571: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 02:47:39.104349: lr: 0.008088\n",
      "2021-11-10 02:47:39.138964: saving checkpoint...\n",
      "2021-11-10 02:47:40.299688: done, saving took 1.19 seconds\n",
      "2021-11-10 02:47:40.323717: This epoch took 314.683235 s\n",
      "\n",
      "2021-11-10 02:47:40.328196: \n",
      "epoch:  21\n",
      "2021-11-10 02:52:38.113055: train loss : -0.8232\n",
      "2021-11-10 02:52:59.416568: validation loss: -0.8116\n",
      "2021-11-10 02:52:59.422130: Average global foreground Dice: [0.8338]\n",
      "2021-11-10 02:52:59.426922: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 02:53:00.892630: lr: 0.007996\n",
      "2021-11-10 02:53:00.975255: saving checkpoint...\n",
      "2021-11-10 02:53:02.356137: done, saving took 1.46 seconds\n",
      "2021-11-10 02:53:02.378880: This epoch took 322.046351 s\n",
      "\n",
      "2021-11-10 02:53:02.383499: \n",
      "epoch:  22\n",
      "2021-11-10 02:57:55.214643: train loss : -0.8296\n",
      "2021-11-10 02:58:14.100476: validation loss: -0.8187\n",
      "2021-11-10 02:58:14.104974: Average global foreground Dice: [0.8406]\n",
      "2021-11-10 02:58:14.109413: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 02:58:14.632128: lr: 0.007904\n",
      "2021-11-10 02:58:14.665548: saving checkpoint...\n",
      "2021-11-10 02:58:15.808987: done, saving took 1.17 seconds\n",
      "2021-11-10 02:58:15.833696: This epoch took 313.445446 s\n",
      "\n",
      "2021-11-10 02:58:15.837792: \n",
      "epoch:  23\n",
      "2021-11-10 03:03:11.899461: train loss : -0.8286\n",
      "2021-11-10 03:03:33.328215: validation loss: -0.8056\n",
      "2021-11-10 03:03:33.360189: Average global foreground Dice: [0.8294]\n",
      "2021-11-10 03:03:33.368828: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 03:03:34.660883: lr: 0.007811\n",
      "2021-11-10 03:03:34.695333: saving checkpoint...\n",
      "2021-11-10 03:03:35.915865: done, saving took 1.25 seconds\n",
      "2021-11-10 03:03:35.941107: This epoch took 320.098485 s\n",
      "\n",
      "2021-11-10 03:03:35.947434: \n",
      "epoch:  24\n",
      "2021-11-10 03:08:27.273382: train loss : -0.8326\n",
      "2021-11-10 03:08:47.315470: validation loss: -0.8223\n",
      "2021-11-10 03:08:47.320417: Average global foreground Dice: [0.8389]\n",
      "2021-11-10 03:08:47.325111: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 03:08:47.850407: lr: 0.007719\n",
      "2021-11-10 03:08:47.883546: saving checkpoint...\n",
      "2021-11-10 03:08:48.997868: done, saving took 1.14 seconds\n",
      "2021-11-10 03:08:49.029874: This epoch took 313.075657 s\n",
      "\n",
      "2021-11-10 03:08:49.033805: \n",
      "epoch:  25\n",
      "2021-11-10 03:13:46.173496: train loss : -0.8355\n",
      "2021-11-10 03:14:06.859365: validation loss: -0.8240\n",
      "2021-11-10 03:14:06.865195: Average global foreground Dice: [0.8412]\n",
      "2021-11-10 03:14:06.871233: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 03:14:07.531949: lr: 0.007626\n",
      "2021-11-10 03:14:07.567116: saving checkpoint...\n",
      "2021-11-10 03:14:08.732709: done, saving took 1.20 seconds\n",
      "2021-11-10 03:14:08.789057: This epoch took 319.750806 s\n",
      "\n",
      "2021-11-10 03:14:08.795854: \n",
      "epoch:  26\n",
      "2021-11-10 03:19:06.164881: train loss : -0.8359\n",
      "2021-11-10 03:19:27.728551: validation loss: -0.8248\n",
      "2021-11-10 03:19:27.760065: Average global foreground Dice: [0.8469]\n",
      "2021-11-10 03:19:27.765109: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 03:19:28.684805: lr: 0.007533\n",
      "2021-11-10 03:19:28.749845: saving checkpoint...\n",
      "2021-11-10 03:19:30.103901: done, saving took 1.41 seconds\n",
      "2021-11-10 03:19:30.128783: This epoch took 321.325913 s\n",
      "\n",
      "2021-11-10 03:19:30.133356: \n",
      "epoch:  27\n",
      "2021-11-10 03:24:25.121571: train loss : -0.8447\n",
      "2021-11-10 03:24:44.784555: validation loss: -0.8214\n",
      "2021-11-10 03:24:44.790528: Average global foreground Dice: [0.8439]\n",
      "2021-11-10 03:24:44.794535: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 03:24:45.310185: lr: 0.00744\n",
      "2021-11-10 03:24:45.343117: saving checkpoint...\n",
      "2021-11-10 03:24:46.416891: done, saving took 1.10 seconds\n",
      "2021-11-10 03:24:46.440110: This epoch took 316.301839 s\n",
      "\n",
      "2021-11-10 03:24:46.444035: \n",
      "epoch:  28\n",
      "2021-11-10 03:29:38.130235: train loss : -0.8420\n",
      "2021-11-10 03:29:58.453688: validation loss: -0.8263\n",
      "2021-11-10 03:29:58.458696: Average global foreground Dice: [0.846]\n",
      "2021-11-10 03:29:58.462481: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 03:29:58.973606: lr: 0.007347\n",
      "2021-11-10 03:29:59.006820: saving checkpoint...\n",
      "2021-11-10 03:30:00.067868: done, saving took 1.09 seconds\n",
      "2021-11-10 03:30:00.098237: This epoch took 313.649432 s\n",
      "\n",
      "2021-11-10 03:30:00.102781: \n",
      "epoch:  29\n",
      "2021-11-10 03:34:55.699978: train loss : -0.8398\n",
      "2021-11-10 03:35:17.788939: validation loss: -0.8130\n",
      "2021-11-10 03:35:17.800126: Average global foreground Dice: [0.8369]\n",
      "2021-11-10 03:35:17.806543: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 03:35:19.884032: lr: 0.007254\n",
      "2021-11-10 03:35:19.961601: saving checkpoint...\n",
      "2021-11-10 03:35:21.911022: done, saving took 2.02 seconds\n",
      "2021-11-10 03:35:21.935349: This epoch took 321.827854 s\n",
      "\n",
      "2021-11-10 03:35:21.940247: \n",
      "epoch:  30\n",
      "2021-11-10 03:40:11.288171: train loss : -0.8405\n",
      "2021-11-10 03:40:32.220249: validation loss: -0.8282\n",
      "2021-11-10 03:40:32.225593: Average global foreground Dice: [0.844]\n",
      "2021-11-10 03:40:32.230330: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 03:40:32.790600: lr: 0.007161\n",
      "2021-11-10 03:40:32.823619: saving checkpoint...\n",
      "2021-11-10 03:40:34.177540: done, saving took 1.38 seconds\n",
      "2021-11-10 03:40:34.200958: This epoch took 312.255985 s\n",
      "\n",
      "2021-11-10 03:40:34.205845: \n",
      "epoch:  31\n",
      "2021-11-10 03:45:31.585341: train loss : -0.8461\n",
      "2021-11-10 03:45:52.804272: validation loss: -0.8303\n",
      "2021-11-10 03:45:52.820417: Average global foreground Dice: [0.8466]\n",
      "2021-11-10 03:45:52.824858: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 03:45:54.615000: lr: 0.007067\n",
      "2021-11-10 03:45:54.683007: saving checkpoint...\n",
      "2021-11-10 03:45:56.679900: done, saving took 2.06 seconds\n",
      "2021-11-10 03:45:56.721728: This epoch took 322.511073 s\n",
      "\n",
      "2021-11-10 03:45:56.729954: \n",
      "epoch:  32\n",
      "2021-11-10 03:50:51.773212: train loss : -0.8438\n",
      "2021-11-10 03:51:12.435467: validation loss: -0.8120\n",
      "2021-11-10 03:51:12.444968: Average global foreground Dice: [0.8351]\n",
      "2021-11-10 03:51:12.449813: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 03:51:12.972296: lr: 0.006974\n",
      "2021-11-10 03:51:13.005275: saving checkpoint...\n",
      "2021-11-10 03:51:14.109061: done, saving took 1.13 seconds\n",
      "2021-11-10 03:51:14.132132: This epoch took 317.372518 s\n",
      "\n",
      "2021-11-10 03:51:14.136565: \n",
      "epoch:  33\n",
      "2021-11-10 03:56:10.688307: train loss : -0.8460\n",
      "2021-11-10 03:56:32.899966: validation loss: -0.8283\n",
      "2021-11-10 03:56:32.905547: Average global foreground Dice: [0.8441]\n",
      "2021-11-10 03:56:32.917287: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 03:56:35.324261: lr: 0.00688\n",
      "2021-11-10 03:56:35.425843: saving checkpoint...\n",
      "2021-11-10 03:56:37.564240: done, saving took 2.23 seconds\n",
      "2021-11-10 03:56:37.590132: This epoch took 323.449226 s\n",
      "\n",
      "2021-11-10 03:56:37.593983: \n",
      "epoch:  34\n",
      "2021-11-10 04:01:39.000636: train loss : -0.8430\n",
      "2021-11-10 04:02:00.775650: validation loss: -0.8272\n",
      "2021-11-10 04:02:00.797834: Average global foreground Dice: [0.8465]\n",
      "2021-11-10 04:02:00.803599: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 04:02:02.123071: lr: 0.006786\n",
      "2021-11-10 04:02:02.194636: saving checkpoint...\n",
      "2021-11-10 04:02:03.380166: done, saving took 1.25 seconds\n",
      "2021-11-10 04:02:03.418704: This epoch took 325.819930 s\n",
      "\n",
      "2021-11-10 04:02:03.426880: \n",
      "epoch:  35\n",
      "2021-11-10 04:06:52.284389: train loss : -0.8452\n",
      "2021-11-10 04:07:12.603171: validation loss: -0.8249\n",
      "2021-11-10 04:07:12.608107: Average global foreground Dice: [0.8395]\n",
      "2021-11-10 04:07:12.612466: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 04:07:13.159401: lr: 0.006692\n",
      "2021-11-10 04:07:13.217301: saving checkpoint...\n",
      "2021-11-10 04:07:14.424766: done, saving took 1.26 seconds\n",
      "2021-11-10 04:07:14.459235: This epoch took 311.023850 s\n",
      "\n",
      "2021-11-10 04:07:14.463759: \n",
      "epoch:  36\n",
      "2021-11-10 04:12:12.945238: train loss : -0.8450\n",
      "2021-11-10 04:12:31.095752: validation loss: -0.8114\n",
      "2021-11-10 04:12:31.102093: Average global foreground Dice: [0.8303]\n",
      "2021-11-10 04:12:31.106386: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 04:12:31.648400: lr: 0.006598\n",
      "2021-11-10 04:12:31.652580: This epoch took 317.184141 s\n",
      "\n",
      "2021-11-10 04:12:31.657010: \n",
      "epoch:  37\n",
      "2021-11-10 04:17:27.472692: train loss : -0.8495\n",
      "2021-11-10 04:17:46.828770: validation loss: -0.8235\n",
      "2021-11-10 04:17:46.833333: Average global foreground Dice: [0.8438]\n",
      "2021-11-10 04:17:46.837471: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 04:17:47.371031: lr: 0.006504\n",
      "2021-11-10 04:17:47.430304: saving checkpoint...\n",
      "2021-11-10 04:17:48.760506: done, saving took 1.38 seconds\n",
      "2021-11-10 04:17:48.782700: This epoch took 317.121293 s\n",
      "\n",
      "2021-11-10 04:17:48.786633: \n",
      "epoch:  38\n",
      "2021-11-10 04:22:46.172880: train loss : -0.8464\n",
      "2021-11-10 04:23:08.372720: validation loss: -0.8368\n",
      "2021-11-10 04:23:08.384402: Average global foreground Dice: [0.8541]\n",
      "2021-11-10 04:23:08.389357: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 04:23:09.960302: lr: 0.006409\n",
      "2021-11-10 04:23:10.009449: saving checkpoint...\n",
      "2021-11-10 04:23:11.567948: done, saving took 1.60 seconds\n",
      "2021-11-10 04:23:11.611246: This epoch took 322.819686 s\n",
      "\n",
      "2021-11-10 04:23:11.617416: \n",
      "epoch:  39\n",
      "2021-11-10 04:28:07.011882: train loss : -0.8460\n",
      "2021-11-10 04:28:26.635446: validation loss: -0.8288\n",
      "2021-11-10 04:28:26.640216: Average global foreground Dice: [0.8466]\n",
      "2021-11-10 04:28:26.644369: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 04:28:27.190193: lr: 0.006314\n",
      "2021-11-10 04:28:27.251461: saving checkpoint...\n",
      "2021-11-10 04:28:28.328999: done, saving took 1.13 seconds\n",
      "2021-11-10 04:28:28.352011: This epoch took 316.728410 s\n",
      "\n",
      "2021-11-10 04:28:28.356233: \n",
      "epoch:  40\n",
      "2021-11-10 04:33:25.193432: train loss : -0.8506\n",
      "2021-11-10 04:33:45.672734: validation loss: -0.8228\n",
      "2021-11-10 04:33:45.680002: Average global foreground Dice: [0.842]\n",
      "2021-11-10 04:33:45.686422: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 04:33:46.535316: lr: 0.00622\n",
      "2021-11-10 04:33:46.600689: saving checkpoint...\n",
      "2021-11-10 04:33:47.702630: done, saving took 1.16 seconds\n",
      "2021-11-10 04:33:47.738443: This epoch took 319.378107 s\n",
      "\n",
      "2021-11-10 04:33:47.743150: \n",
      "epoch:  41\n",
      "2021-11-10 04:38:40.086767: train loss : -0.8450\n",
      "2021-11-10 04:39:01.799799: validation loss: -0.8030\n",
      "2021-11-10 04:39:01.813165: Average global foreground Dice: [0.8214]\n",
      "2021-11-10 04:39:01.818674: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 04:39:02.597831: lr: 0.006125\n",
      "2021-11-10 04:39:02.602229: This epoch took 314.854617 s\n",
      "\n",
      "2021-11-10 04:39:02.606972: \n",
      "epoch:  42\n",
      "2021-11-10 04:43:55.894107: train loss : -0.8508\n",
      "2021-11-10 04:44:18.276461: validation loss: -0.8335\n",
      "2021-11-10 04:44:18.287436: Average global foreground Dice: [0.8496]\n",
      "2021-11-10 04:44:18.294654: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 04:44:19.909223: lr: 0.00603\n",
      "2021-11-10 04:44:19.913514: This epoch took 317.301862 s\n",
      "\n",
      "2021-11-10 04:44:19.917178: \n",
      "epoch:  43\n",
      "2021-11-10 04:49:18.999675: train loss : -0.8502\n",
      "2021-11-10 04:49:40.193424: validation loss: -0.8323\n",
      "2021-11-10 04:49:40.198237: Average global foreground Dice: [0.848]\n",
      "2021-11-10 04:49:40.202954: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 04:49:40.798761: lr: 0.005934\n",
      "2021-11-10 04:49:40.870206: saving checkpoint...\n",
      "2021-11-10 04:49:42.015269: done, saving took 1.21 seconds\n",
      "2021-11-10 04:49:42.054159: This epoch took 322.132213 s\n",
      "\n",
      "2021-11-10 04:49:42.058503: \n",
      "epoch:  44\n",
      "2021-11-10 04:54:39.099998: train loss : -0.8531\n",
      "2021-11-10 04:55:01.599376: validation loss: -0.8016\n",
      "2021-11-10 04:55:01.605042: Average global foreground Dice: [0.823]\n",
      "2021-11-10 04:55:01.610021: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 04:55:03.612016: lr: 0.005839\n",
      "2021-11-10 04:55:03.616688: This epoch took 321.554239 s\n",
      "\n",
      "2021-11-10 04:55:03.621311: \n",
      "epoch:  45\n",
      "2021-11-10 05:00:04.664487: train loss : -0.8514\n",
      "2021-11-10 05:00:23.492838: validation loss: -0.8325\n",
      "2021-11-10 05:00:23.500337: Average global foreground Dice: [0.8489]\n",
      "2021-11-10 05:00:23.509176: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 05:00:24.058666: lr: 0.005743\n",
      "2021-11-10 05:00:24.063824: This epoch took 320.438061 s\n",
      "\n",
      "2021-11-10 05:00:24.067990: \n",
      "epoch:  46\n",
      "2021-11-10 05:05:22.081830: train loss : -0.8520\n",
      "2021-11-10 05:05:43.759401: validation loss: -0.8265\n",
      "2021-11-10 05:05:43.764305: Average global foreground Dice: [0.8442]\n",
      "2021-11-10 05:05:43.768945: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 05:05:44.473698: lr: 0.005647\n",
      "2021-11-10 05:05:44.537087: saving checkpoint...\n",
      "2021-11-10 05:05:45.679214: done, saving took 1.20 seconds\n",
      "2021-11-10 05:05:45.720865: This epoch took 321.648497 s\n",
      "\n",
      "2021-11-10 05:05:45.725901: \n",
      "epoch:  47\n",
      "2021-11-10 05:10:43.850975: train loss : -0.8552\n",
      "2021-11-10 05:11:03.364336: validation loss: -0.8322\n",
      "2021-11-10 05:11:03.371125: Average global foreground Dice: [0.8463]\n",
      "2021-11-10 05:11:03.376556: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 05:11:03.907163: lr: 0.005551\n",
      "2021-11-10 05:11:03.970717: saving checkpoint...\n",
      "2021-11-10 05:11:05.082986: done, saving took 1.17 seconds\n",
      "2021-11-10 05:11:05.105341: This epoch took 319.374678 s\n",
      "\n",
      "2021-11-10 05:11:05.109130: \n",
      "epoch:  48\n",
      "2021-11-10 05:16:04.766180: train loss : -0.8514\n",
      "2021-11-10 05:16:26.022849: validation loss: -0.8194\n",
      "2021-11-10 05:16:26.060135: Average global foreground Dice: [0.8397]\n",
      "2021-11-10 05:16:26.068093: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 05:16:27.623029: lr: 0.005455\n",
      "2021-11-10 05:16:27.627671: This epoch took 322.513753 s\n",
      "\n",
      "2021-11-10 05:16:27.632252: \n",
      "epoch:  49\n",
      "2021-11-10 05:21:23.516081: train loss : -0.8560\n",
      "2021-11-10 05:21:45.600551: validation loss: -0.8207\n",
      "2021-11-10 05:21:45.606074: Average global foreground Dice: [0.841]\n",
      "2021-11-10 05:21:45.609911: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 05:21:46.438865: lr: 0.005359\n",
      "2021-11-10 05:21:46.442726: saving scheduled checkpoint file...\n",
      "2021-11-10 05:21:46.507318: saving checkpoint...\n",
      "2021-11-10 05:21:47.411536: done, saving took 0.96 seconds\n",
      "2021-11-10 05:21:47.439128: done\n",
      "2021-11-10 05:21:47.509426: saving checkpoint...\n",
      "2021-11-10 05:21:48.617749: done, saving took 1.17 seconds\n",
      "2021-11-10 05:21:48.646971: This epoch took 321.009894 s\n",
      "\n",
      "2021-11-10 05:21:48.651811: \n",
      "epoch:  50\n",
      "2021-11-10 05:26:41.416001: train loss : -0.8540\n",
      "2021-11-10 05:27:01.030404: validation loss: -0.8390\n",
      "2021-11-10 05:27:01.035511: Average global foreground Dice: [0.8532]\n",
      "2021-11-10 05:27:01.040056: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 05:27:01.585210: lr: 0.005262\n",
      "2021-11-10 05:27:01.649480: saving checkpoint...\n",
      "2021-11-10 05:27:02.742392: done, saving took 1.15 seconds\n",
      "2021-11-10 05:27:02.769315: This epoch took 314.113428 s\n",
      "\n",
      "2021-11-10 05:27:02.774015: \n",
      "epoch:  51\n",
      "2021-11-10 05:31:59.733811: train loss : -0.8539\n",
      "2021-11-10 05:32:19.733891: validation loss: -0.8416\n",
      "2021-11-10 05:32:19.739554: Average global foreground Dice: [0.8547]\n",
      "2021-11-10 05:32:19.744167: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 05:32:20.272811: lr: 0.005166\n",
      "2021-11-10 05:32:20.334595: saving checkpoint...\n",
      "2021-11-10 05:32:21.484682: done, saving took 1.21 seconds\n",
      "2021-11-10 05:32:21.521070: This epoch took 318.743186 s\n",
      "\n",
      "2021-11-10 05:32:21.525669: \n",
      "epoch:  52\n",
      "2021-11-10 05:37:23.513858: train loss : -0.8577\n",
      "2021-11-10 05:37:45.785898: validation loss: -0.8312\n",
      "2021-11-10 05:37:45.796081: Average global foreground Dice: [0.8481]\n",
      "2021-11-10 05:37:45.800876: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 05:37:47.304780: lr: 0.005069\n",
      "2021-11-10 05:37:47.527119: saving checkpoint...\n",
      "2021-11-10 05:37:50.029806: done, saving took 2.72 seconds\n",
      "2021-11-10 05:37:50.061321: This epoch took 328.531192 s\n",
      "\n",
      "2021-11-10 05:37:50.065116: \n",
      "epoch:  53\n",
      "2021-11-10 05:42:49.895625: train loss : -0.8553\n",
      "2021-11-10 05:43:09.381009: validation loss: -0.8356\n",
      "2021-11-10 05:43:09.389018: Average global foreground Dice: [0.8517]\n",
      "2021-11-10 05:43:09.396118: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 05:43:09.926176: lr: 0.004971\n",
      "2021-11-10 05:43:09.959871: saving checkpoint...\n",
      "2021-11-10 05:43:11.083017: done, saving took 1.15 seconds\n",
      "2021-11-10 05:43:11.113121: This epoch took 321.043042 s\n",
      "\n",
      "2021-11-10 05:43:11.121369: \n",
      "epoch:  54\n",
      "2021-11-10 05:48:10.786703: train loss : -0.8565\n",
      "2021-11-10 05:48:31.778275: validation loss: -0.8281\n",
      "2021-11-10 05:48:31.783752: Average global foreground Dice: [0.8408]\n",
      "2021-11-10 05:48:31.788047: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 05:48:34.216917: lr: 0.004874\n",
      "2021-11-10 05:48:34.221480: This epoch took 323.093864 s\n",
      "\n",
      "2021-11-10 05:48:34.226383: \n",
      "epoch:  55\n",
      "2021-11-10 05:53:25.780966: train loss : -0.8592\n",
      "2021-11-10 05:53:45.421452: validation loss: -0.8236\n",
      "2021-11-10 05:53:45.426239: Average global foreground Dice: [0.8392]\n",
      "2021-11-10 05:53:45.430920: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 05:53:45.965650: lr: 0.004776\n",
      "2021-11-10 05:53:45.975014: This epoch took 311.743884 s\n",
      "\n",
      "2021-11-10 05:53:45.982849: \n",
      "epoch:  56\n",
      "2021-11-10 05:58:42.291451: train loss : -0.8590\n",
      "2021-11-10 05:59:03.284394: validation loss: -0.8262\n",
      "2021-11-10 05:59:03.306095: Average global foreground Dice: [0.8459]\n",
      "2021-11-10 05:59:03.313615: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 05:59:05.246606: lr: 0.004679\n",
      "2021-11-10 05:59:05.263361: This epoch took 319.269976 s\n",
      "\n",
      "2021-11-10 05:59:05.268440: \n",
      "epoch:  57\n",
      "2021-11-10 06:04:05.785316: train loss : -0.8580\n",
      "2021-11-10 06:04:27.294876: validation loss: -0.8203\n",
      "2021-11-10 06:04:27.305561: Average global foreground Dice: [0.837]\n",
      "2021-11-10 06:04:27.312934: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 06:04:29.060207: lr: 0.004581\n",
      "2021-11-10 06:04:29.066459: This epoch took 323.793507 s\n",
      "\n",
      "2021-11-10 06:04:29.072258: \n",
      "epoch:  58\n",
      "2021-11-10 06:09:27.925401: train loss : -0.8582\n",
      "2021-11-10 06:09:48.027196: validation loss: -0.8335\n",
      "2021-11-10 06:09:48.032773: Average global foreground Dice: [0.8468]\n",
      "2021-11-10 06:09:48.037188: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 06:09:48.571525: lr: 0.004482\n",
      "2021-11-10 06:09:48.576681: This epoch took 319.499461 s\n",
      "\n",
      "2021-11-10 06:09:48.581036: \n",
      "epoch:  59\n",
      "2021-11-10 06:14:46.300278: train loss : -0.8606\n",
      "2021-11-10 06:15:08.893712: validation loss: -0.8387\n",
      "2021-11-10 06:15:08.904418: Average global foreground Dice: [0.8527]\n",
      "2021-11-10 06:15:08.909354: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 06:15:10.470328: lr: 0.004384\n",
      "2021-11-10 06:15:10.611012: saving checkpoint...\n",
      "2021-11-10 06:15:11.942762: done, saving took 1.46 seconds\n",
      "2021-11-10 06:15:12.013884: This epoch took 323.427918 s\n",
      "\n",
      "2021-11-10 06:15:12.018159: \n",
      "epoch:  60\n",
      "2021-11-10 06:20:08.521358: train loss : -0.8605\n",
      "2021-11-10 06:20:27.929820: validation loss: -0.8421\n",
      "2021-11-10 06:20:27.933668: Average global foreground Dice: [0.8523]\n",
      "2021-11-10 06:20:27.938251: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 06:20:28.492195: lr: 0.004285\n",
      "2021-11-10 06:20:28.554033: saving checkpoint...\n",
      "2021-11-10 06:20:29.674570: done, saving took 1.18 seconds\n",
      "2021-11-10 06:20:29.711930: This epoch took 317.689058 s\n",
      "\n",
      "2021-11-10 06:20:29.715851: \n",
      "epoch:  61\n",
      "2021-11-10 06:25:24.508873: train loss : -0.8606\n",
      "2021-11-10 06:25:43.235969: validation loss: -0.8316\n",
      "2021-11-10 06:25:43.241120: Average global foreground Dice: [0.8427]\n",
      "2021-11-10 06:25:43.245813: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 06:25:43.778317: lr: 0.004186\n",
      "2021-11-10 06:25:43.783123: This epoch took 314.063563 s\n",
      "\n",
      "2021-11-10 06:25:43.787658: \n",
      "epoch:  62\n",
      "2021-11-10 06:30:41.082453: train loss : -0.8602\n",
      "2021-11-10 06:31:01.995265: validation loss: -0.8314\n",
      "2021-11-10 06:31:02.006950: Average global foreground Dice: [0.8455]\n",
      "2021-11-10 06:31:02.016016: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 06:31:02.621706: lr: 0.004087\n",
      "2021-11-10 06:31:02.626572: This epoch took 318.832772 s\n",
      "\n",
      "2021-11-10 06:31:02.630101: \n",
      "epoch:  63\n",
      "2021-11-10 06:36:03.803089: train loss : -0.8621\n",
      "2021-11-10 06:36:24.992504: validation loss: -0.8342\n",
      "2021-11-10 06:36:24.997737: Average global foreground Dice: [0.8488]\n",
      "2021-11-10 06:36:25.002470: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 06:36:25.553977: lr: 0.003987\n",
      "2021-11-10 06:36:25.616708: saving checkpoint...\n",
      "2021-11-10 06:36:26.771530: done, saving took 1.21 seconds\n",
      "2021-11-10 06:36:26.806529: This epoch took 324.172427 s\n",
      "\n",
      "2021-11-10 06:36:26.811916: \n",
      "epoch:  64\n",
      "2021-11-10 06:41:27.574069: train loss : -0.8586\n",
      "2021-11-10 06:41:50.528401: validation loss: -0.8262\n",
      "2021-11-10 06:41:50.564098: Average global foreground Dice: [0.8457]\n",
      "2021-11-10 06:41:50.568502: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 06:41:52.311055: lr: 0.003887\n",
      "2021-11-10 06:41:52.468953: saving checkpoint...\n",
      "2021-11-10 06:41:53.682102: done, saving took 1.37 seconds\n",
      "2021-11-10 06:41:53.707858: This epoch took 326.891299 s\n",
      "\n",
      "2021-11-10 06:41:53.712684: \n",
      "epoch:  65\n",
      "2021-11-10 06:46:52.088401: train loss : -0.8586\n",
      "2021-11-10 06:47:12.310481: validation loss: -0.8256\n",
      "2021-11-10 06:47:12.315932: Average global foreground Dice: [0.8408]\n",
      "2021-11-10 06:47:12.319550: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 06:47:12.836371: lr: 0.003787\n",
      "2021-11-10 06:47:12.841127: This epoch took 319.124604 s\n",
      "\n",
      "2021-11-10 06:47:12.846158: \n",
      "epoch:  66\n",
      "2021-11-10 06:52:13.016001: train loss : -0.8629\n",
      "2021-11-10 06:52:34.322312: validation loss: -0.8373\n",
      "2021-11-10 06:52:34.327613: Average global foreground Dice: [0.852]\n",
      "2021-11-10 06:52:34.331720: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 06:52:35.725385: lr: 0.003687\n",
      "2021-11-10 06:52:35.793869: saving checkpoint...\n",
      "2021-11-10 06:52:36.989256: done, saving took 1.26 seconds\n",
      "2021-11-10 06:52:37.031889: This epoch took 324.181178 s\n",
      "\n",
      "2021-11-10 06:52:37.037559: \n",
      "epoch:  67\n",
      "2021-11-10 06:57:28.665020: train loss : -0.8645\n",
      "2021-11-10 06:57:47.308734: validation loss: -0.8377\n",
      "2021-11-10 06:57:47.313257: Average global foreground Dice: [0.8535]\n",
      "2021-11-10 06:57:47.317279: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 06:57:47.848835: lr: 0.003586\n",
      "2021-11-10 06:57:47.884049: saving checkpoint...\n",
      "2021-11-10 06:57:48.998490: done, saving took 1.14 seconds\n",
      "2021-11-10 06:57:49.021408: This epoch took 311.977360 s\n",
      "\n",
      "2021-11-10 06:57:49.025442: \n",
      "epoch:  68\n",
      "2021-11-10 07:02:46.977726: train loss : -0.8666\n",
      "2021-11-10 07:03:08.933287: validation loss: -0.8252\n",
      "2021-11-10 07:03:08.976791: Average global foreground Dice: [0.8411]\n",
      "2021-11-10 07:03:08.980871: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 07:03:11.402644: lr: 0.003485\n",
      "2021-11-10 07:03:11.406796: This epoch took 322.376971 s\n",
      "\n",
      "2021-11-10 07:03:11.411820: \n",
      "epoch:  69\n",
      "2021-11-10 07:08:12.281937: train loss : -0.8647\n",
      "2021-11-10 07:08:33.587100: validation loss: -0.8281\n",
      "2021-11-10 07:08:33.592355: Average global foreground Dice: [0.846]\n",
      "2021-11-10 07:08:33.597445: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 07:08:34.854044: lr: 0.003384\n",
      "2021-11-10 07:08:34.863400: This epoch took 323.446632 s\n",
      "\n",
      "2021-11-10 07:08:34.867754: \n",
      "epoch:  70\n",
      "2021-11-10 07:13:45.482425: train loss : -0.8619\n",
      "2021-11-10 07:14:07.119139: validation loss: -0.8258\n",
      "2021-11-10 07:14:07.123977: Average global foreground Dice: [0.841]\n",
      "2021-11-10 07:14:07.128978: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 07:14:09.284860: lr: 0.003282\n",
      "2021-11-10 07:14:09.289533: This epoch took 334.417669 s\n",
      "\n",
      "2021-11-10 07:14:09.293231: \n",
      "epoch:  71\n",
      "2021-11-10 07:19:00.899538: train loss : -0.8655\n",
      "2021-11-10 07:19:21.652140: validation loss: -0.8223\n",
      "2021-11-10 07:19:21.660429: Average global foreground Dice: [0.8407]\n",
      "2021-11-10 07:19:21.667253: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 07:19:22.222010: lr: 0.00318\n",
      "2021-11-10 07:19:22.226091: This epoch took 312.929193 s\n",
      "\n",
      "2021-11-10 07:19:22.232279: \n",
      "epoch:  72\n",
      "2021-11-10 07:24:21.997219: train loss : -0.8668\n",
      "2021-11-10 07:24:42.040976: validation loss: -0.8214\n",
      "2021-11-10 07:24:42.046102: Average global foreground Dice: [0.8411]\n",
      "2021-11-10 07:24:42.050988: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 07:24:42.605619: lr: 0.003078\n",
      "2021-11-10 07:24:42.609848: This epoch took 320.373747 s\n",
      "\n",
      "2021-11-10 07:24:42.614045: \n",
      "epoch:  73\n",
      "2021-11-10 07:29:40.697343: train loss : -0.8663\n",
      "2021-11-10 07:30:01.177560: validation loss: -0.8140\n",
      "2021-11-10 07:30:01.182960: Average global foreground Dice: [0.8345]\n",
      "2021-11-10 07:30:01.187679: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 07:30:01.725474: lr: 0.002975\n",
      "2021-11-10 07:30:01.731501: This epoch took 319.113075 s\n",
      "\n",
      "2021-11-10 07:30:01.736380: \n",
      "epoch:  74\n",
      "2021-11-10 07:34:59.209096: train loss : -0.8678\n",
      "2021-11-10 07:35:19.658468: validation loss: -0.8333\n",
      "2021-11-10 07:35:19.663345: Average global foreground Dice: [0.8477]\n",
      "2021-11-10 07:35:19.667566: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 07:35:20.209348: lr: 0.002872\n",
      "2021-11-10 07:35:20.213816: This epoch took 318.472722 s\n",
      "\n",
      "2021-11-10 07:35:20.220796: \n",
      "epoch:  75\n",
      "2021-11-10 07:40:22.321795: train loss : -0.8657\n",
      "2021-11-10 07:40:44.220218: validation loss: -0.8228\n",
      "2021-11-10 07:40:44.227461: Average global foreground Dice: [0.8407]\n",
      "2021-11-10 07:40:44.259260: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 07:40:47.172136: lr: 0.002768\n",
      "2021-11-10 07:40:47.177050: This epoch took 326.951491 s\n",
      "\n",
      "2021-11-10 07:40:47.181478: \n",
      "epoch:  76\n",
      "2021-11-10 07:45:50.873610: train loss : -0.8688\n",
      "2021-11-10 07:46:12.814298: validation loss: -0.8428\n",
      "2021-11-10 07:46:12.820832: Average global foreground Dice: [0.8562]\n",
      "2021-11-10 07:46:12.825366: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 07:46:14.526860: lr: 0.002664\n",
      "2021-11-10 07:46:14.532007: This epoch took 327.345879 s\n",
      "\n",
      "2021-11-10 07:46:14.559706: \n",
      "epoch:  77\n",
      "2021-11-10 07:51:15.778757: train loss : -0.8713\n",
      "2021-11-10 07:51:38.228634: validation loss: -0.8344\n",
      "2021-11-10 07:51:38.260350: Average global foreground Dice: [0.8505]\n",
      "2021-11-10 07:51:38.264237: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 07:51:39.760410: lr: 0.00256\n",
      "2021-11-10 07:51:39.765072: This epoch took 325.200282 s\n",
      "\n",
      "2021-11-10 07:51:39.773040: \n",
      "epoch:  78\n",
      "2021-11-10 07:56:40.373791: train loss : -0.8676\n",
      "2021-11-10 07:57:00.373179: validation loss: -0.8154\n",
      "2021-11-10 07:57:00.378646: Average global foreground Dice: [0.831]\n",
      "2021-11-10 07:57:00.383416: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 07:57:00.979428: lr: 0.002455\n",
      "2021-11-10 07:57:00.983756: This epoch took 321.205878 s\n",
      "\n",
      "2021-11-10 07:57:00.988038: \n",
      "epoch:  79\n",
      "2021-11-10 08:01:58.803941: train loss : -0.8711\n",
      "2021-11-10 08:02:18.015210: validation loss: -0.8353\n",
      "2021-11-10 08:02:18.021357: Average global foreground Dice: [0.8472]\n",
      "2021-11-10 08:02:18.025647: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 08:02:18.618451: lr: 0.002349\n",
      "2021-11-10 08:02:18.623309: This epoch took 317.629237 s\n",
      "\n",
      "2021-11-10 08:02:18.628014: \n",
      "epoch:  80\n",
      "2021-11-10 08:07:17.673622: train loss : -0.8700\n",
      "2021-11-10 08:07:39.896498: validation loss: -0.8338\n",
      "2021-11-10 08:07:39.919459: Average global foreground Dice: [0.8457]\n",
      "2021-11-10 08:07:39.923703: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 08:07:41.967571: lr: 0.002243\n",
      "2021-11-10 08:07:41.972155: This epoch took 323.339916 s\n",
      "\n",
      "2021-11-10 08:07:41.976650: \n",
      "epoch:  81\n",
      "2021-11-10 08:12:41.674774: train loss : -0.8721\n",
      "2021-11-10 08:13:02.706082: validation loss: -0.8278\n",
      "2021-11-10 08:13:02.713185: Average global foreground Dice: [0.8435]\n",
      "2021-11-10 08:13:02.717003: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 08:13:03.280329: lr: 0.002137\n",
      "2021-11-10 08:13:03.285222: This epoch took 321.304303 s\n",
      "\n",
      "2021-11-10 08:13:03.289342: \n",
      "epoch:  82\n",
      "2021-11-10 08:17:58.401749: train loss : -0.8730\n",
      "2021-11-10 08:18:19.234596: validation loss: -0.8208\n",
      "2021-11-10 08:18:19.240860: Average global foreground Dice: [0.8388]\n",
      "2021-11-10 08:18:19.245617: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 08:18:19.788944: lr: 0.00203\n",
      "2021-11-10 08:18:19.793032: This epoch took 316.499196 s\n",
      "\n",
      "2021-11-10 08:18:19.797388: \n",
      "epoch:  83\n",
      "2021-11-10 08:23:16.805686: train loss : -0.8723\n",
      "2021-11-10 08:23:38.908977: validation loss: -0.8431\n",
      "2021-11-10 08:23:38.922488: Average global foreground Dice: [0.8533]\n",
      "2021-11-10 08:23:38.928436: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 08:23:40.860230: lr: 0.001922\n",
      "2021-11-10 08:23:40.865215: This epoch took 321.063431 s\n",
      "\n",
      "2021-11-10 08:23:40.869938: \n",
      "epoch:  84\n",
      "2021-11-10 08:28:37.977469: train loss : -0.8719\n",
      "2021-11-10 08:28:56.136605: validation loss: -0.8263\n",
      "2021-11-10 08:28:56.140639: Average global foreground Dice: [0.842]\n",
      "2021-11-10 08:28:56.146941: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 08:28:56.698508: lr: 0.001813\n",
      "2021-11-10 08:28:56.705011: This epoch took 315.830063 s\n",
      "\n",
      "2021-11-10 08:28:56.713334: \n",
      "epoch:  85\n",
      "2021-11-10 08:33:57.573152: train loss : -0.8727\n",
      "2021-11-10 08:34:19.383290: validation loss: -0.8400\n",
      "2021-11-10 08:34:19.401693: Average global foreground Dice: [0.8517]\n",
      "2021-11-10 08:34:19.405990: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 08:34:20.930210: lr: 0.001704\n",
      "2021-11-10 08:34:20.935631: This epoch took 324.214939 s\n",
      "\n",
      "2021-11-10 08:34:20.959709: \n",
      "epoch:  86\n",
      "2021-11-10 08:39:18.170090: train loss : -0.8715\n",
      "2021-11-10 08:39:39.114683: validation loss: -0.8356\n",
      "2021-11-10 08:39:39.119590: Average global foreground Dice: [0.8509]\n",
      "2021-11-10 08:39:39.124519: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 08:39:39.671263: lr: 0.001594\n",
      "2021-11-10 08:39:39.676152: This epoch took 318.710606 s\n",
      "\n",
      "2021-11-10 08:39:39.680700: \n",
      "epoch:  87\n",
      "2021-11-10 08:44:38.394834: train loss : -0.8699\n",
      "2021-11-10 08:44:59.246897: validation loss: -0.8388\n",
      "2021-11-10 08:44:59.255588: Average global foreground Dice: [0.8517]\n",
      "2021-11-10 08:44:59.260486: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 08:44:59.801449: lr: 0.001483\n",
      "2021-11-10 08:44:59.864237: saving checkpoint...\n",
      "2021-11-10 08:45:00.987507: done, saving took 1.18 seconds\n",
      "2021-11-10 08:45:01.031686: This epoch took 321.346677 s\n",
      "\n",
      "2021-11-10 08:45:01.036164: \n",
      "epoch:  88\n",
      "2021-11-10 08:50:01.494054: train loss : -0.8738\n",
      "2021-11-10 08:50:23.288440: validation loss: -0.8329\n",
      "2021-11-10 08:50:23.294268: Average global foreground Dice: [0.8455]\n",
      "2021-11-10 08:50:23.298355: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 08:50:24.291315: lr: 0.001372\n",
      "2021-11-10 08:50:24.295379: This epoch took 323.255311 s\n",
      "\n",
      "2021-11-10 08:50:24.299981: \n",
      "epoch:  89\n",
      "2021-11-10 08:55:24.892287: train loss : -0.8718\n",
      "2021-11-10 08:55:46.109936: validation loss: -0.8297\n",
      "2021-11-10 08:55:46.127588: Average global foreground Dice: [0.8389]\n",
      "2021-11-10 08:55:46.159231: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 08:55:47.405155: lr: 0.001259\n",
      "2021-11-10 08:55:47.410503: This epoch took 323.105987 s\n",
      "\n",
      "2021-11-10 08:55:47.415065: \n",
      "epoch:  90\n",
      "2021-11-10 09:00:54.305865: train loss : -0.8752\n",
      "2021-11-10 09:01:16.530549: validation loss: -0.8362\n",
      "2021-11-10 09:01:16.563150: Average global foreground Dice: [0.8502]\n",
      "2021-11-10 09:01:16.567449: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 09:01:18.902933: lr: 0.001145\n",
      "2021-11-10 09:01:18.909494: This epoch took 331.489550 s\n",
      "\n",
      "2021-11-10 09:01:18.914373: \n",
      "epoch:  91\n",
      "2021-11-10 09:06:18.972648: train loss : -0.8733\n",
      "2021-11-10 09:06:38.612336: validation loss: -0.8274\n",
      "2021-11-10 09:06:38.616951: Average global foreground Dice: [0.8414]\n",
      "2021-11-10 09:06:38.621416: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 09:06:39.171656: lr: 0.00103\n",
      "2021-11-10 09:06:39.175700: This epoch took 320.256512 s\n",
      "\n",
      "2021-11-10 09:06:39.179806: \n",
      "epoch:  92\n",
      "2021-11-10 09:11:37.587097: train loss : -0.8762\n",
      "2021-11-10 09:11:57.206820: validation loss: -0.8251\n",
      "2021-11-10 09:11:57.212506: Average global foreground Dice: [0.8397]\n",
      "2021-11-10 09:11:57.217171: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 09:11:57.742069: lr: 0.000913\n",
      "2021-11-10 09:11:57.747810: This epoch took 318.563541 s\n",
      "\n",
      "2021-11-10 09:11:57.754485: \n",
      "epoch:  93\n",
      "2021-11-10 09:16:54.274210: train loss : -0.8757\n",
      "2021-11-10 09:17:14.301141: validation loss: -0.8277\n",
      "2021-11-10 09:17:14.305676: Average global foreground Dice: [0.8423]\n",
      "2021-11-10 09:17:14.310114: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 09:17:14.849442: lr: 0.000795\n",
      "2021-11-10 09:17:14.854413: This epoch took 317.093177 s\n",
      "\n",
      "2021-11-10 09:17:14.859192: \n",
      "epoch:  94\n",
      "2021-11-10 09:22:09.696430: train loss : -0.8768\n",
      "2021-11-10 09:22:27.797422: validation loss: -0.8303\n",
      "2021-11-10 09:22:27.803345: Average global foreground Dice: [0.8389]\n",
      "2021-11-10 09:22:27.808123: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 09:22:28.354923: lr: 0.000675\n",
      "2021-11-10 09:22:28.359542: This epoch took 313.495704 s\n",
      "\n",
      "2021-11-10 09:22:28.364063: \n",
      "epoch:  95\n",
      "2021-11-10 09:27:30.488282: train loss : -0.8762\n",
      "2021-11-10 09:27:53.113041: validation loss: -0.8351\n",
      "2021-11-10 09:27:53.163646: Average global foreground Dice: [0.851]\n",
      "2021-11-10 09:27:53.168747: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 09:27:54.809676: lr: 0.000552\n",
      "2021-11-10 09:27:54.814515: This epoch took 326.445628 s\n",
      "\n",
      "2021-11-10 09:27:54.819245: \n",
      "epoch:  96\n",
      "2021-11-10 09:33:04.284573: train loss : -0.8760\n",
      "2021-11-10 09:33:26.673083: validation loss: -0.8384\n",
      "2021-11-10 09:33:26.695702: Average global foreground Dice: [0.8502]\n",
      "2021-11-10 09:33:26.700495: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 09:33:28.301437: lr: 0.000426\n",
      "2021-11-10 09:33:28.306407: This epoch took 333.483263 s\n",
      "\n",
      "2021-11-10 09:33:28.310591: \n",
      "epoch:  97\n",
      "2021-11-10 09:38:28.297520: train loss : -0.8764\n",
      "2021-11-10 09:38:48.202614: validation loss: -0.8345\n",
      "2021-11-10 09:38:48.210596: Average global foreground Dice: [0.85]\n",
      "2021-11-10 09:38:48.217648: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 09:38:48.740202: lr: 0.000296\n",
      "2021-11-10 09:38:48.744629: This epoch took 320.430306 s\n",
      "\n",
      "2021-11-10 09:38:48.748852: \n",
      "epoch:  98\n",
      "2021-11-10 09:43:49.485887: train loss : -0.8741\n",
      "2021-11-10 09:44:11.025304: validation loss: -0.8363\n",
      "2021-11-10 09:44:11.030519: Average global foreground Dice: [0.848]\n",
      "2021-11-10 09:44:11.034629: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 09:44:11.602621: lr: 0.000158\n",
      "2021-11-10 09:44:11.607747: This epoch took 322.855110 s\n",
      "\n",
      "2021-11-10 09:44:11.611843: \n",
      "epoch:  99\n",
      "2021-11-10 09:49:11.085452: train loss : -0.8786\n",
      "2021-11-10 09:49:32.687491: validation loss: -0.8248\n",
      "2021-11-10 09:49:32.704223: Average global foreground Dice: [0.8401]\n",
      "2021-11-10 09:49:32.708874: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 09:49:34.560184: lr: 0.0\n",
      "2021-11-10 09:49:34.565150: saving scheduled checkpoint file...\n",
      "2021-11-10 09:49:34.761986: saving checkpoint...\n",
      "2021-11-10 09:49:36.363805: done, saving took 1.79 seconds\n",
      "2021-11-10 09:49:36.397132: done\n",
      "2021-11-10 09:49:36.401564: This epoch took 324.785826 s\n",
      "\n",
      "2021-11-10 09:49:36.485526: saving checkpoint...\n",
      "2021-11-10 09:49:37.637225: done, saving took 1.23 seconds\n",
      "23090566_20141114 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090571_20120517 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131226 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160308 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131025 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090596_20150112 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120619 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090608_20120718 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151210 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121213 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090616_20140331 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090619_20121210 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090629_20120830 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090636_20121018 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150522 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-10 09:53:02.230968: finished prediction\n",
      "2021-11-10 09:53:02.235745: evaluation of raw predictions\n",
      "2021-11-10 09:53:03.908789: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8420065076857624\n",
      "after:  0.8420065076857624\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-10 09:53:17.490911: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-10 09:53:17.507384: The split file contains 5 splits.\n",
      "2021-11-10 09:53:17.513680: Desired fold for training: 3\n",
      "2021-11-10 09:53:17.521139: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-10 09:53:21.905412: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-10 09:53:31.008756: Unable to plot network architecture:\n",
      "2021-11-10 09:53:31.015427: No module named 'hiddenlayer'\n",
      "2021-11-10 09:53:31.021088: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-10 09:53:31.025733: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-10 09:53:31.061083: \n",
      "\n",
      "2021-11-10 09:53:31.065100: \n",
      "epoch:  0\n",
      "2021-11-10 09:59:13.786423: train loss : -0.2268\n",
      "2021-11-10 09:59:36.339559: validation loss: -0.6081\n",
      "2021-11-10 09:59:36.363027: Average global foreground Dice: [0.6774]\n",
      "2021-11-10 09:59:36.367265: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 09:59:38.308420: lr: 0.00991\n",
      "2021-11-10 09:59:38.312633: This epoch took 367.243933 s\n",
      "\n",
      "2021-11-10 09:59:38.317266: \n",
      "epoch:  1\n",
      "2021-11-10 10:04:37.796785: train loss : -0.6329\n",
      "2021-11-10 10:04:59.979432: validation loss: -0.7126\n",
      "2021-11-10 10:04:59.984876: Average global foreground Dice: [0.7597]\n",
      "2021-11-10 10:04:59.989440: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 10:05:01.640790: lr: 0.00982\n",
      "2021-11-10 10:05:01.743517: saving checkpoint...\n",
      "2021-11-10 10:05:02.769210: done, saving took 1.12 seconds\n",
      "2021-11-10 10:05:02.789383: This epoch took 324.468261 s\n",
      "\n",
      "2021-11-10 10:05:02.794016: \n",
      "epoch:  2\n",
      "2021-11-10 10:10:01.123518: train loss : -0.6925\n",
      "2021-11-10 10:10:22.686216: validation loss: -0.7466\n",
      "2021-11-10 10:10:22.691540: Average global foreground Dice: [0.787]\n",
      "2021-11-10 10:10:22.696259: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 10:10:23.830226: lr: 0.00973\n",
      "2021-11-10 10:10:23.966513: saving checkpoint...\n",
      "2021-11-10 10:10:25.123240: done, saving took 1.29 seconds\n",
      "2021-11-10 10:10:25.175447: This epoch took 322.377824 s\n",
      "\n",
      "2021-11-10 10:10:25.183343: \n",
      "epoch:  3\n",
      "2021-11-10 10:15:25.100521: train loss : -0.7320\n",
      "2021-11-10 10:15:47.472751: validation loss: -0.7585\n",
      "2021-11-10 10:15:47.484384: Average global foreground Dice: [0.7885]\n",
      "2021-11-10 10:15:47.488991: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 10:15:49.960394: lr: 0.009639\n",
      "2021-11-10 10:15:50.193152: saving checkpoint...\n",
      "2021-11-10 10:15:52.581395: done, saving took 2.61 seconds\n",
      "2021-11-10 10:15:52.604383: This epoch took 327.416672 s\n",
      "\n",
      "2021-11-10 10:15:52.608480: \n",
      "epoch:  4\n",
      "2021-11-10 10:20:49.182339: train loss : -0.7467\n",
      "2021-11-10 10:21:08.625360: validation loss: -0.7809\n",
      "2021-11-10 10:21:08.633190: Average global foreground Dice: [0.8118]\n",
      "2021-11-10 10:21:08.637238: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 10:21:09.141196: lr: 0.009549\n",
      "2021-11-10 10:21:09.214148: saving checkpoint...\n",
      "2021-11-10 10:21:10.275829: done, saving took 1.13 seconds\n",
      "2021-11-10 10:21:10.305999: This epoch took 317.691973 s\n",
      "\n",
      "2021-11-10 10:21:10.310833: \n",
      "epoch:  5\n",
      "2021-11-10 10:25:59.737849: train loss : -0.7724\n",
      "2021-11-10 10:26:21.700907: validation loss: -0.7902\n",
      "2021-11-10 10:26:21.706052: Average global foreground Dice: [0.8209]\n",
      "2021-11-10 10:26:21.710635: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 10:26:22.278977: lr: 0.009458\n",
      "2021-11-10 10:26:22.362595: saving checkpoint...\n",
      "2021-11-10 10:26:23.470123: done, saving took 1.18 seconds\n",
      "2021-11-10 10:26:23.512792: This epoch took 313.197146 s\n",
      "\n",
      "2021-11-10 10:26:23.516697: \n",
      "epoch:  6\n",
      "2021-11-10 10:31:18.288872: train loss : -0.7808\n",
      "2021-11-10 10:31:37.218893: validation loss: -0.7996\n",
      "2021-11-10 10:31:37.223251: Average global foreground Dice: [0.8325]\n",
      "2021-11-10 10:31:37.227024: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 10:31:37.783407: lr: 0.009368\n",
      "2021-11-10 10:31:37.863573: saving checkpoint...\n",
      "2021-11-10 10:31:38.942200: done, saving took 1.15 seconds\n",
      "2021-11-10 10:31:38.973157: This epoch took 315.452549 s\n",
      "\n",
      "2021-11-10 10:31:38.977680: \n",
      "epoch:  7\n",
      "2021-11-10 10:36:30.264404: train loss : -0.7907\n",
      "2021-11-10 10:36:50.479215: validation loss: -0.7977\n",
      "2021-11-10 10:36:50.483881: Average global foreground Dice: [0.8239]\n",
      "2021-11-10 10:36:50.488885: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 10:36:51.137255: lr: 0.009277\n",
      "2021-11-10 10:36:51.214312: saving checkpoint...\n",
      "2021-11-10 10:36:52.346508: done, saving took 1.21 seconds\n",
      "2021-11-10 10:36:52.402494: This epoch took 313.421358 s\n",
      "\n",
      "2021-11-10 10:36:52.407903: \n",
      "epoch:  8\n",
      "2021-11-10 10:41:45.373929: train loss : -0.7929\n",
      "2021-11-10 10:42:07.179810: validation loss: -0.8197\n",
      "2021-11-10 10:42:07.185934: Average global foreground Dice: [0.846]\n",
      "2021-11-10 10:42:07.190465: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 10:42:08.692812: lr: 0.009186\n",
      "2021-11-10 10:42:08.726700: saving checkpoint...\n",
      "2021-11-10 10:42:09.752838: done, saving took 1.06 seconds\n",
      "2021-11-10 10:42:09.778581: This epoch took 317.366908 s\n",
      "\n",
      "2021-11-10 10:42:09.782876: \n",
      "epoch:  9\n",
      "2021-11-10 10:47:21.617193: train loss : -0.7988\n",
      "2021-11-10 10:47:43.110811: validation loss: -0.8181\n",
      "2021-11-10 10:47:43.115855: Average global foreground Dice: [0.8443]\n",
      "2021-11-10 10:47:43.121110: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 10:47:45.260446: lr: 0.009095\n",
      "2021-11-10 10:47:45.308748: saving checkpoint...\n",
      "2021-11-10 10:47:47.120944: done, saving took 1.86 seconds\n",
      "2021-11-10 10:47:47.180002: This epoch took 337.392937 s\n",
      "\n",
      "2021-11-10 10:47:47.185114: \n",
      "epoch:  10\n",
      "2021-11-10 10:52:46.272879: train loss : -0.8054\n",
      "2021-11-10 10:53:05.977413: validation loss: -0.8328\n",
      "2021-11-10 10:53:05.983351: Average global foreground Dice: [0.8534]\n",
      "2021-11-10 10:53:05.987882: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 10:53:06.549582: lr: 0.009004\n",
      "2021-11-10 10:53:06.582673: saving checkpoint...\n",
      "2021-11-10 10:53:07.644105: done, saving took 1.09 seconds\n",
      "2021-11-10 10:53:07.665514: This epoch took 320.475596 s\n",
      "\n",
      "2021-11-10 10:53:07.669894: \n",
      "epoch:  11\n",
      "2021-11-10 10:58:05.535572: train loss : -0.8034\n",
      "2021-11-10 10:58:27.085497: validation loss: -0.8287\n",
      "2021-11-10 10:58:27.103342: Average global foreground Dice: [0.8517]\n",
      "2021-11-10 10:58:27.107383: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 10:58:28.880131: lr: 0.008913\n",
      "2021-11-10 10:58:29.016091: saving checkpoint...\n",
      "2021-11-10 10:58:30.432687: done, saving took 1.55 seconds\n",
      "2021-11-10 10:58:30.469589: This epoch took 322.795640 s\n",
      "\n",
      "2021-11-10 10:58:30.474519: \n",
      "epoch:  12\n",
      "2021-11-10 11:03:30.780063: train loss : -0.8112\n",
      "2021-11-10 11:03:52.903049: validation loss: -0.8249\n",
      "2021-11-10 11:03:52.910449: Average global foreground Dice: [0.847]\n",
      "2021-11-10 11:03:52.917726: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 11:03:55.668471: lr: 0.008822\n",
      "2021-11-10 11:03:55.820514: saving checkpoint...\n",
      "2021-11-10 11:03:58.098012: done, saving took 2.43 seconds\n",
      "2021-11-10 11:03:58.159575: This epoch took 327.680043 s\n",
      "\n",
      "2021-11-10 11:03:58.164581: \n",
      "epoch:  13\n",
      "2021-11-10 11:08:54.681380: train loss : -0.8101\n",
      "2021-11-10 11:09:16.201878: validation loss: -0.8209\n",
      "2021-11-10 11:09:16.220797: Average global foreground Dice: [0.8453]\n",
      "2021-11-10 11:09:16.225294: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 11:09:19.001336: lr: 0.008731\n",
      "2021-11-10 11:09:19.161439: saving checkpoint...\n",
      "2021-11-10 11:09:21.186965: done, saving took 2.18 seconds\n",
      "2021-11-10 11:09:21.220978: This epoch took 323.052555 s\n",
      "\n",
      "2021-11-10 11:09:21.225980: \n",
      "epoch:  14\n",
      "2021-11-10 11:14:15.171439: train loss : -0.8147\n",
      "2021-11-10 11:14:37.320925: validation loss: -0.8314\n",
      "2021-11-10 11:14:37.363264: Average global foreground Dice: [0.8538]\n",
      "2021-11-10 11:14:37.368072: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 11:14:39.118116: lr: 0.008639\n",
      "2021-11-10 11:14:39.185947: saving checkpoint...\n",
      "2021-11-10 11:14:40.342526: done, saving took 1.22 seconds\n",
      "2021-11-10 11:14:40.374645: This epoch took 319.143917 s\n",
      "\n",
      "2021-11-10 11:14:40.379381: \n",
      "epoch:  15\n",
      "2021-11-10 11:19:42.181134: train loss : -0.8140\n",
      "2021-11-10 11:20:03.770544: validation loss: -0.8044\n",
      "2021-11-10 11:20:03.781147: Average global foreground Dice: [0.8276]\n",
      "2021-11-10 11:20:03.785700: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 11:20:04.852274: lr: 0.008548\n",
      "2021-11-10 11:20:04.924522: saving checkpoint...\n",
      "2021-11-10 11:20:06.040881: done, saving took 1.18 seconds\n",
      "2021-11-10 11:20:06.065705: This epoch took 325.681789 s\n",
      "\n",
      "2021-11-10 11:20:06.069864: \n",
      "epoch:  16\n",
      "2021-11-10 11:25:01.185392: train loss : -0.8130\n",
      "2021-11-10 11:25:21.799971: validation loss: -0.8319\n",
      "2021-11-10 11:25:21.805480: Average global foreground Dice: [0.8513]\n",
      "2021-11-10 11:25:21.809443: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 11:25:22.312545: lr: 0.008456\n",
      "2021-11-10 11:25:22.409248: saving checkpoint...\n",
      "2021-11-10 11:25:23.429210: done, saving took 1.11 seconds\n",
      "2021-11-10 11:25:23.461260: This epoch took 317.386734 s\n",
      "\n",
      "2021-11-10 11:25:23.465930: \n",
      "epoch:  17\n",
      "2021-11-10 11:30:20.964559: train loss : -0.8177\n",
      "2021-11-10 11:30:39.980253: validation loss: -0.8331\n",
      "2021-11-10 11:30:39.986210: Average global foreground Dice: [0.8494]\n",
      "2021-11-10 11:30:39.990807: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 11:30:40.555393: lr: 0.008364\n",
      "2021-11-10 11:30:40.629558: saving checkpoint...\n",
      "2021-11-10 11:30:41.758716: done, saving took 1.20 seconds\n",
      "2021-11-10 11:30:41.784694: This epoch took 318.314925 s\n",
      "\n",
      "2021-11-10 11:30:41.789447: \n",
      "epoch:  18\n",
      "2021-11-10 11:35:43.422722: train loss : -0.8211\n",
      "2021-11-10 11:36:04.764088: validation loss: -0.8258\n",
      "2021-11-10 11:36:04.773425: Average global foreground Dice: [0.8476]\n",
      "2021-11-10 11:36:04.780305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 11:36:06.260641: lr: 0.008272\n",
      "2021-11-10 11:36:06.432245: saving checkpoint...\n",
      "2021-11-10 11:36:07.711886: done, saving took 1.44 seconds\n",
      "2021-11-10 11:36:07.744314: This epoch took 325.949530 s\n",
      "\n",
      "2021-11-10 11:36:07.749182: \n",
      "epoch:  19\n",
      "2021-11-10 11:41:06.496022: train loss : -0.8197\n",
      "2021-11-10 11:41:27.602934: validation loss: -0.8285\n",
      "2021-11-10 11:41:27.608041: Average global foreground Dice: [0.8449]\n",
      "2021-11-10 11:41:27.612604: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 11:41:28.488551: lr: 0.008181\n",
      "2021-11-10 11:41:28.556975: saving checkpoint...\n",
      "2021-11-10 11:41:29.638806: done, saving took 1.14 seconds\n",
      "2021-11-10 11:41:29.669595: This epoch took 321.914138 s\n",
      "\n",
      "2021-11-10 11:41:29.673816: \n",
      "epoch:  20\n",
      "2021-11-10 11:46:27.287034: train loss : -0.8278\n",
      "2021-11-10 11:46:49.213653: validation loss: -0.8329\n",
      "2021-11-10 11:46:49.219406: Average global foreground Dice: [0.8533]\n",
      "2021-11-10 11:46:49.223372: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 11:46:51.050970: lr: 0.008088\n",
      "2021-11-10 11:46:51.091118: saving checkpoint...\n",
      "2021-11-10 11:46:52.891855: done, saving took 1.84 seconds\n",
      "2021-11-10 11:46:52.931137: This epoch took 323.252770 s\n",
      "\n",
      "2021-11-10 11:46:52.935901: \n",
      "epoch:  21\n",
      "2021-11-10 11:51:51.507987: train loss : -0.8256\n",
      "2021-11-10 11:52:13.983576: validation loss: -0.8224\n",
      "2021-11-10 11:52:13.999580: Average global foreground Dice: [0.8457]\n",
      "2021-11-10 11:52:14.004370: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 11:52:15.345838: lr: 0.007996\n",
      "2021-11-10 11:52:15.396655: saving checkpoint...\n",
      "2021-11-10 11:52:16.589146: done, saving took 1.22 seconds\n",
      "2021-11-10 11:52:16.613393: This epoch took 323.670140 s\n",
      "\n",
      "2021-11-10 11:52:16.617819: \n",
      "epoch:  22\n",
      "2021-11-10 11:57:14.759704: train loss : -0.8246\n",
      "2021-11-10 11:57:35.989214: validation loss: -0.8337\n",
      "2021-11-10 11:57:35.994893: Average global foreground Dice: [0.8549]\n",
      "2021-11-10 11:57:35.999873: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 11:57:37.709121: lr: 0.007904\n",
      "2021-11-10 11:57:37.770988: saving checkpoint...\n",
      "2021-11-10 11:57:38.919547: done, saving took 1.21 seconds\n",
      "2021-11-10 11:57:38.948601: This epoch took 322.326601 s\n",
      "\n",
      "2021-11-10 11:57:38.953495: \n",
      "epoch:  23\n",
      "2021-11-10 12:02:40.591412: train loss : -0.8247\n",
      "2021-11-10 12:03:03.276148: validation loss: -0.8277\n",
      "2021-11-10 12:03:03.281299: Average global foreground Dice: [0.8455]\n",
      "2021-11-10 12:03:03.285876: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 12:03:06.260313: lr: 0.007811\n",
      "2021-11-10 12:03:06.369147: saving checkpoint...\n",
      "2021-11-10 12:03:08.822825: done, saving took 2.56 seconds\n",
      "2021-11-10 12:03:08.870440: This epoch took 329.912506 s\n",
      "\n",
      "2021-11-10 12:03:08.874960: \n",
      "epoch:  24\n",
      "2021-11-10 12:08:10.133924: train loss : -0.8281\n",
      "2021-11-10 12:08:29.471344: validation loss: -0.8385\n",
      "2021-11-10 12:08:29.475474: Average global foreground Dice: [0.8568]\n",
      "2021-11-10 12:08:29.480299: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 12:08:30.019953: lr: 0.007719\n",
      "2021-11-10 12:08:30.081850: saving checkpoint...\n",
      "2021-11-10 12:08:31.147125: done, saving took 1.12 seconds\n",
      "2021-11-10 12:08:31.189243: This epoch took 322.310021 s\n",
      "\n",
      "2021-11-10 12:08:31.193741: \n",
      "epoch:  25\n",
      "2021-11-10 12:13:22.684278: train loss : -0.8344\n",
      "2021-11-10 12:13:43.129747: validation loss: -0.8401\n",
      "2021-11-10 12:13:43.134825: Average global foreground Dice: [0.8625]\n",
      "2021-11-10 12:13:43.139301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 12:13:43.678885: lr: 0.007626\n",
      "2021-11-10 12:13:43.738352: saving checkpoint...\n",
      "2021-11-10 12:13:44.798563: done, saving took 1.11 seconds\n",
      "2021-11-10 12:13:44.825577: This epoch took 313.626918 s\n",
      "\n",
      "2021-11-10 12:13:44.830095: \n",
      "epoch:  26\n",
      "2021-11-10 12:18:41.874766: train loss : -0.8265\n",
      "2021-11-10 12:19:02.597015: validation loss: -0.8364\n",
      "2021-11-10 12:19:02.602208: Average global foreground Dice: [0.8496]\n",
      "2021-11-10 12:19:02.607161: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 12:19:03.142841: lr: 0.007533\n",
      "2021-11-10 12:19:03.205740: saving checkpoint...\n",
      "2021-11-10 12:19:04.254650: done, saving took 1.11 seconds\n",
      "2021-11-10 12:19:04.275705: This epoch took 319.441225 s\n",
      "\n",
      "2021-11-10 12:19:04.279597: \n",
      "epoch:  27\n",
      "2021-11-10 12:24:04.385638: train loss : -0.8294\n",
      "2021-11-10 12:24:25.582902: validation loss: -0.8446\n",
      "2021-11-10 12:24:25.588599: Average global foreground Dice: [0.862]\n",
      "2021-11-10 12:24:25.593125: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 12:24:26.965189: lr: 0.00744\n",
      "2021-11-10 12:24:26.998423: saving checkpoint...\n",
      "2021-11-10 12:24:28.151386: done, saving took 1.18 seconds\n",
      "2021-11-10 12:24:28.180871: This epoch took 323.897125 s\n",
      "\n",
      "2021-11-10 12:24:28.185198: \n",
      "epoch:  28\n",
      "2021-11-10 12:29:26.893121: train loss : -0.8331\n",
      "2021-11-10 12:29:48.020976: validation loss: -0.8424\n",
      "2021-11-10 12:29:48.028281: Average global foreground Dice: [0.8627]\n",
      "2021-11-10 12:29:48.035767: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 12:29:48.858864: lr: 0.007347\n",
      "2021-11-10 12:29:48.894425: saving checkpoint...\n",
      "2021-11-10 12:29:49.936644: done, saving took 1.07 seconds\n",
      "2021-11-10 12:29:49.958347: This epoch took 321.768703 s\n",
      "\n",
      "2021-11-10 12:29:49.963089: \n",
      "epoch:  29\n",
      "2021-11-10 12:34:49.375131: train loss : -0.8332\n",
      "2021-11-10 12:35:08.465149: validation loss: -0.8516\n",
      "2021-11-10 12:35:08.470634: Average global foreground Dice: [0.8725]\n",
      "2021-11-10 12:35:08.474839: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 12:35:08.988999: lr: 0.007254\n",
      "2021-11-10 12:35:09.022432: saving checkpoint...\n",
      "2021-11-10 12:35:10.080888: done, saving took 1.09 seconds\n",
      "2021-11-10 12:35:10.103192: This epoch took 320.135907 s\n",
      "\n",
      "2021-11-10 12:35:10.109449: \n",
      "epoch:  30\n",
      "2021-11-10 12:40:10.090190: train loss : -0.8341\n",
      "2021-11-10 12:40:30.420071: validation loss: -0.8459\n",
      "2021-11-10 12:40:30.425513: Average global foreground Dice: [0.8684]\n",
      "2021-11-10 12:40:30.430545: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 12:40:30.936463: lr: 0.007161\n",
      "2021-11-10 12:40:30.969905: saving checkpoint...\n",
      "2021-11-10 12:40:32.013566: done, saving took 1.07 seconds\n",
      "2021-11-10 12:40:32.036384: This epoch took 321.921995 s\n",
      "\n",
      "2021-11-10 12:40:32.041001: \n",
      "epoch:  31\n",
      "2021-11-10 12:45:27.796330: train loss : -0.8343\n",
      "2021-11-10 12:45:47.588979: validation loss: -0.8428\n",
      "2021-11-10 12:45:47.593748: Average global foreground Dice: [0.8558]\n",
      "2021-11-10 12:45:47.597659: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 12:45:48.110394: lr: 0.007067\n",
      "2021-11-10 12:45:48.143765: saving checkpoint...\n",
      "2021-11-10 12:45:49.183823: done, saving took 1.07 seconds\n",
      "2021-11-10 12:45:49.205237: This epoch took 317.159558 s\n",
      "\n",
      "2021-11-10 12:45:49.209443: \n",
      "epoch:  32\n",
      "2021-11-10 12:50:40.377943: train loss : -0.8395\n",
      "2021-11-10 12:51:00.093450: validation loss: -0.8507\n",
      "2021-11-10 12:51:00.098946: Average global foreground Dice: [0.8677]\n",
      "2021-11-10 12:51:00.103732: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 12:51:00.616006: lr: 0.006974\n",
      "2021-11-10 12:51:00.649341: saving checkpoint...\n",
      "2021-11-10 12:51:01.824841: done, saving took 1.20 seconds\n",
      "2021-11-10 12:51:01.864547: This epoch took 312.651184 s\n",
      "\n",
      "2021-11-10 12:51:01.869283: \n",
      "epoch:  33\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-10 12:56:02.691375: train loss : -0.8362\n",
      "2021-11-10 12:56:23.683709: validation loss: -0.8421\n",
      "2021-11-10 12:56:23.690163: Average global foreground Dice: [0.8611]\n",
      "2021-11-10 12:56:23.694522: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 12:56:24.628882: lr: 0.00688\n",
      "2021-11-10 12:56:24.666438: saving checkpoint...\n",
      "2021-11-10 12:56:25.619671: done, saving took 0.98 seconds\n",
      "2021-11-10 12:56:25.644970: This epoch took 323.770967 s\n",
      "\n",
      "2021-11-10 12:56:25.649619: \n",
      "epoch:  34\n",
      "2021-11-10 13:01:22.164621: train loss : -0.8402\n",
      "2021-11-10 13:01:44.306343: validation loss: -0.8423\n",
      "2021-11-10 13:01:44.324186: Average global foreground Dice: [0.8586]\n",
      "2021-11-10 13:01:44.329113: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 13:01:45.418726: lr: 0.006786\n",
      "2021-11-10 13:01:45.454411: saving checkpoint...\n",
      "2021-11-10 13:01:46.513970: done, saving took 1.09 seconds\n",
      "2021-11-10 13:01:46.560698: This epoch took 320.906760 s\n",
      "\n",
      "2021-11-10 13:01:46.565268: \n",
      "epoch:  35\n",
      "2021-11-10 13:06:41.873151: train loss : -0.8368\n",
      "2021-11-10 13:07:01.670370: validation loss: -0.8422\n",
      "2021-11-10 13:07:01.676469: Average global foreground Dice: [0.8621]\n",
      "2021-11-10 13:07:01.681267: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 13:07:02.195918: lr: 0.006692\n",
      "2021-11-10 13:07:02.228881: saving checkpoint...\n",
      "2021-11-10 13:07:03.325206: done, saving took 1.12 seconds\n",
      "2021-11-10 13:07:03.356671: This epoch took 316.786958 s\n",
      "\n",
      "2021-11-10 13:07:03.361429: \n",
      "epoch:  36\n",
      "2021-11-10 13:12:03.489189: train loss : -0.8350\n",
      "2021-11-10 13:12:24.966959: validation loss: -0.8272\n",
      "2021-11-10 13:12:24.983537: Average global foreground Dice: [0.85]\n",
      "2021-11-10 13:12:24.989036: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 13:12:26.216625: lr: 0.006598\n",
      "2021-11-10 13:12:26.221064: This epoch took 322.852791 s\n",
      "\n",
      "2021-11-10 13:12:26.225514: \n",
      "epoch:  37\n",
      "2021-11-10 13:17:20.573420: train loss : -0.8389\n",
      "2021-11-10 13:17:40.572446: validation loss: -0.8458\n",
      "2021-11-10 13:17:40.577861: Average global foreground Dice: [0.8602]\n",
      "2021-11-10 13:17:40.586197: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 13:17:41.157248: lr: 0.006504\n",
      "2021-11-10 13:17:41.224222: saving checkpoint...\n",
      "2021-11-10 13:17:42.441094: done, saving took 1.28 seconds\n",
      "2021-11-10 13:17:42.463610: This epoch took 316.233652 s\n",
      "\n",
      "2021-11-10 13:17:42.468156: \n",
      "epoch:  38\n",
      "2021-11-10 13:22:36.674546: train loss : -0.8357\n",
      "2021-11-10 13:22:55.799463: validation loss: -0.8189\n",
      "2021-11-10 13:22:55.804075: Average global foreground Dice: [0.8408]\n",
      "2021-11-10 13:22:55.808090: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 13:22:56.496965: lr: 0.006409\n",
      "2021-11-10 13:22:56.501326: This epoch took 314.029153 s\n",
      "\n",
      "2021-11-10 13:22:56.505783: \n",
      "epoch:  39\n",
      "2021-11-10 13:27:55.793200: train loss : -0.8365\n",
      "2021-11-10 13:28:17.896840: validation loss: -0.8508\n",
      "2021-11-10 13:28:17.908686: Average global foreground Dice: [0.8664]\n",
      "2021-11-10 13:28:17.913815: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 13:28:20.517356: lr: 0.006314\n",
      "2021-11-10 13:28:20.622052: saving checkpoint...\n",
      "2021-11-10 13:28:22.668734: done, saving took 2.15 seconds\n",
      "2021-11-10 13:28:22.702685: This epoch took 326.190388 s\n",
      "\n",
      "2021-11-10 13:28:22.707441: \n",
      "epoch:  40\n",
      "2021-11-10 13:33:22.173056: train loss : -0.8423\n",
      "2021-11-10 13:33:41.577805: validation loss: -0.8459\n",
      "2021-11-10 13:33:41.582392: Average global foreground Dice: [0.8621]\n",
      "2021-11-10 13:33:41.587922: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 13:33:42.160469: lr: 0.00622\n",
      "2021-11-10 13:33:42.193659: saving checkpoint...\n",
      "2021-11-10 13:33:43.283642: done, saving took 1.12 seconds\n",
      "2021-11-10 13:33:43.314073: This epoch took 320.601747 s\n",
      "\n",
      "2021-11-10 13:33:43.321059: \n",
      "epoch:  41\n",
      "2021-11-10 13:38:45.304081: train loss : -0.8351\n",
      "2021-11-10 13:39:07.564388: validation loss: -0.8375\n",
      "2021-11-10 13:39:07.579072: Average global foreground Dice: [0.859]\n",
      "2021-11-10 13:39:07.583645: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 13:39:10.160459: lr: 0.006125\n",
      "2021-11-10 13:39:10.218673: saving checkpoint...\n",
      "2021-11-10 13:39:12.392492: done, saving took 2.23 seconds\n",
      "2021-11-10 13:39:12.417317: This epoch took 329.089375 s\n",
      "\n",
      "2021-11-10 13:39:12.421881: \n",
      "epoch:  42\n",
      "2021-11-10 13:44:12.801320: train loss : -0.8384\n",
      "2021-11-10 13:44:32.945843: validation loss: -0.8414\n",
      "2021-11-10 13:44:32.950418: Average global foreground Dice: [0.8577]\n",
      "2021-11-10 13:44:32.955861: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 13:44:33.481961: lr: 0.00603\n",
      "2021-11-10 13:44:33.546514: saving checkpoint...\n",
      "2021-11-10 13:44:34.710776: done, saving took 1.22 seconds\n",
      "2021-11-10 13:44:34.744576: This epoch took 322.318030 s\n",
      "\n",
      "2021-11-10 13:44:34.749201: \n",
      "epoch:  43\n",
      "2021-11-10 13:49:30.779894: train loss : -0.8465\n",
      "2021-11-10 13:49:50.637204: validation loss: -0.8408\n",
      "2021-11-10 13:49:50.641946: Average global foreground Dice: [0.8584]\n",
      "2021-11-10 13:49:50.646865: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 13:49:51.174799: lr: 0.005934\n",
      "2021-11-10 13:49:51.241909: saving checkpoint...\n",
      "2021-11-10 13:49:52.315362: done, saving took 1.14 seconds\n",
      "2021-11-10 13:49:52.347411: This epoch took 317.594126 s\n",
      "\n",
      "2021-11-10 13:49:52.352240: \n",
      "epoch:  44\n",
      "2021-11-10 13:54:51.713422: train loss : -0.8442\n",
      "2021-11-10 13:55:11.587461: validation loss: -0.8382\n",
      "2021-11-10 13:55:11.592710: Average global foreground Dice: [0.8536]\n",
      "2021-11-10 13:55:11.597208: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 13:55:12.114243: lr: 0.005839\n",
      "2021-11-10 13:55:12.123661: This epoch took 319.767502 s\n",
      "\n",
      "2021-11-10 13:55:12.128105: \n",
      "epoch:  45\n",
      "2021-11-10 14:00:07.480938: train loss : -0.8458\n",
      "2021-11-10 14:00:29.224905: validation loss: -0.8435\n",
      "2021-11-10 14:00:29.264718: Average global foreground Dice: [0.8617]\n",
      "2021-11-10 14:00:29.269903: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 14:00:31.118894: lr: 0.005743\n",
      "2021-11-10 14:00:31.192773: saving checkpoint...\n",
      "2021-11-10 14:00:32.514562: done, saving took 1.39 seconds\n",
      "2021-11-10 14:00:32.546317: This epoch took 320.413426 s\n",
      "\n",
      "2021-11-10 14:00:32.551292: \n",
      "epoch:  46\n",
      "2021-11-10 14:05:33.280870: train loss : -0.8448\n",
      "2021-11-10 14:05:53.613489: validation loss: -0.8456\n",
      "2021-11-10 14:05:53.621377: Average global foreground Dice: [0.8615]\n",
      "2021-11-10 14:05:53.629140: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 14:05:54.161981: lr: 0.005647\n",
      "2021-11-10 14:05:54.195640: saving checkpoint...\n",
      "2021-11-10 14:05:55.317967: done, saving took 1.15 seconds\n",
      "2021-11-10 14:05:55.352617: This epoch took 322.796418 s\n",
      "\n",
      "2021-11-10 14:05:55.359471: \n",
      "epoch:  47\n",
      "2021-11-10 14:10:52.102755: train loss : -0.8486\n",
      "2021-11-10 14:11:12.581769: validation loss: -0.8505\n",
      "2021-11-10 14:11:12.587865: Average global foreground Dice: [0.8668]\n",
      "2021-11-10 14:11:12.592683: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 14:11:13.229529: lr: 0.005551\n",
      "2021-11-10 14:11:13.263827: saving checkpoint...\n",
      "2021-11-10 14:11:14.389883: done, saving took 1.15 seconds\n",
      "2021-11-10 14:11:14.416720: This epoch took 319.049398 s\n",
      "\n",
      "2021-11-10 14:11:14.421708: \n",
      "epoch:  48\n",
      "2021-11-10 14:16:12.785563: train loss : -0.8459\n",
      "2021-11-10 14:16:34.335985: validation loss: -0.8330\n",
      "2021-11-10 14:16:34.341960: Average global foreground Dice: [0.8527]\n",
      "2021-11-10 14:16:34.346652: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 14:16:34.968042: lr: 0.005455\n",
      "2021-11-10 14:16:34.974303: This epoch took 320.548886 s\n",
      "\n",
      "2021-11-10 14:16:34.981039: \n",
      "epoch:  49\n",
      "2021-11-10 14:21:31.001583: train loss : -0.8477\n",
      "2021-11-10 14:21:49.998364: validation loss: -0.8526\n",
      "2021-11-10 14:21:50.004136: Average global foreground Dice: [0.867]\n",
      "2021-11-10 14:21:50.008970: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 14:21:50.517101: lr: 0.005359\n",
      "2021-11-10 14:21:50.521379: saving scheduled checkpoint file...\n",
      "2021-11-10 14:21:50.563600: saving checkpoint...\n",
      "2021-11-10 14:21:51.407283: done, saving took 0.88 seconds\n",
      "2021-11-10 14:21:51.423519: done\n",
      "2021-11-10 14:21:51.456949: saving checkpoint...\n",
      "2021-11-10 14:21:52.561250: done, saving took 1.13 seconds\n",
      "2021-11-10 14:21:52.585282: This epoch took 317.599337 s\n",
      "\n",
      "2021-11-10 14:21:52.590168: \n",
      "epoch:  50\n",
      "2021-11-10 14:26:46.892625: train loss : -0.8473\n",
      "2021-11-10 14:27:07.761539: validation loss: -0.8395\n",
      "2021-11-10 14:27:07.771008: Average global foreground Dice: [0.8544]\n",
      "2021-11-10 14:27:07.778382: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 14:27:08.301154: lr: 0.005262\n",
      "2021-11-10 14:27:08.306354: This epoch took 315.710702 s\n",
      "\n",
      "2021-11-10 14:27:08.311299: \n",
      "epoch:  51\n",
      "2021-11-10 14:32:01.185972: train loss : -0.8475\n",
      "2021-11-10 14:32:22.387580: validation loss: -0.8451\n",
      "2021-11-10 14:32:22.392577: Average global foreground Dice: [0.8633]\n",
      "2021-11-10 14:32:22.397142: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 14:32:22.964457: lr: 0.005166\n",
      "2021-11-10 14:32:23.031446: saving checkpoint...\n",
      "2021-11-10 14:32:24.185114: done, saving took 1.22 seconds\n",
      "2021-11-10 14:32:24.207252: This epoch took 315.891094 s\n",
      "\n",
      "2021-11-10 14:32:24.211627: \n",
      "epoch:  52\n",
      "2021-11-10 14:37:23.268227: train loss : -0.8468\n",
      "2021-11-10 14:37:45.120324: validation loss: -0.8482\n",
      "2021-11-10 14:37:45.125991: Average global foreground Dice: [0.8623]\n",
      "2021-11-10 14:37:45.131063: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 14:37:46.896014: lr: 0.005069\n",
      "2021-11-10 14:37:46.970474: saving checkpoint...\n",
      "2021-11-10 14:37:48.258122: done, saving took 1.36 seconds\n",
      "2021-11-10 14:37:48.283862: This epoch took 324.067801 s\n",
      "\n",
      "2021-11-10 14:37:48.288605: \n",
      "epoch:  53\n",
      "2021-11-10 14:42:46.686134: train loss : -0.8493\n",
      "2021-11-10 14:43:08.070136: validation loss: -0.8376\n",
      "2021-11-10 14:43:08.080056: Average global foreground Dice: [0.8582]\n",
      "2021-11-10 14:43:08.085019: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 14:43:09.360583: lr: 0.004971\n",
      "2021-11-10 14:43:09.366264: This epoch took 321.072735 s\n",
      "\n",
      "2021-11-10 14:43:09.370978: \n",
      "epoch:  54\n",
      "2021-11-10 14:48:09.463279: train loss : -0.8491\n",
      "2021-11-10 14:48:30.520209: validation loss: -0.8521\n",
      "2021-11-10 14:48:30.565197: Average global foreground Dice: [0.8685]\n",
      "2021-11-10 14:48:30.571730: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 14:48:32.126580: lr: 0.004874\n",
      "2021-11-10 14:48:32.213805: saving checkpoint...\n",
      "2021-11-10 14:48:33.849871: done, saving took 1.69 seconds\n",
      "2021-11-10 14:48:33.881771: This epoch took 324.506438 s\n",
      "\n",
      "2021-11-10 14:48:33.887528: \n",
      "epoch:  55\n",
      "2021-11-10 14:53:32.873156: train loss : -0.8499\n",
      "2021-11-10 14:53:54.610495: validation loss: -0.8444\n",
      "2021-11-10 14:53:54.620528: Average global foreground Dice: [0.8632]\n",
      "2021-11-10 14:53:54.625103: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 14:53:56.160302: lr: 0.004776\n",
      "2021-11-10 14:53:56.324263: saving checkpoint...\n",
      "2021-11-10 14:53:57.752686: done, saving took 1.59 seconds\n",
      "2021-11-10 14:53:57.783666: This epoch took 323.892086 s\n",
      "\n",
      "2021-11-10 14:53:57.788870: \n",
      "epoch:  56\n",
      "2021-11-10 14:58:49.490655: train loss : -0.8556\n",
      "2021-11-10 14:59:10.165196: validation loss: -0.8489\n",
      "2021-11-10 14:59:10.174427: Average global foreground Dice: [0.8683]\n",
      "2021-11-10 14:59:10.181208: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 14:59:10.876810: lr: 0.004679\n",
      "2021-11-10 14:59:10.955668: saving checkpoint...\n",
      "2021-11-10 14:59:12.118384: done, saving took 1.23 seconds\n",
      "2021-11-10 14:59:12.141839: This epoch took 314.348115 s\n",
      "\n",
      "2021-11-10 14:59:12.146378: \n",
      "epoch:  57\n",
      "2021-11-10 15:04:03.873463: train loss : -0.8541\n",
      "2021-11-10 15:04:23.234460: validation loss: -0.8387\n",
      "2021-11-10 15:04:23.240383: Average global foreground Dice: [0.8557]\n",
      "2021-11-10 15:04:23.245384: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 15:04:23.793597: lr: 0.004581\n",
      "2021-11-10 15:04:23.798336: This epoch took 311.647756 s\n",
      "\n",
      "2021-11-10 15:04:23.803039: \n",
      "epoch:  58\n",
      "2021-11-10 15:09:21.764629: train loss : -0.8524\n",
      "2021-11-10 15:09:43.475896: validation loss: -0.8415\n",
      "2021-11-10 15:09:43.481653: Average global foreground Dice: [0.8573]\n",
      "2021-11-10 15:09:43.487179: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 15:09:44.274170: lr: 0.004482\n",
      "2021-11-10 15:09:44.278995: This epoch took 320.470973 s\n",
      "\n",
      "2021-11-10 15:09:44.284155: \n",
      "epoch:  59\n",
      "2021-11-10 15:14:40.169069: train loss : -0.8534\n",
      "2021-11-10 15:14:59.519763: validation loss: -0.8356\n",
      "2021-11-10 15:14:59.524846: Average global foreground Dice: [0.8495]\n",
      "2021-11-10 15:14:59.529501: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 15:15:00.042768: lr: 0.004384\n",
      "2021-11-10 15:15:00.047236: This epoch took 315.758548 s\n",
      "\n",
      "2021-11-10 15:15:00.051893: \n",
      "epoch:  60\n",
      "2021-11-10 15:19:51.493509: train loss : -0.8507\n",
      "2021-11-10 15:20:12.025912: validation loss: -0.8474\n",
      "2021-11-10 15:20:12.031245: Average global foreground Dice: [0.8655]\n",
      "2021-11-10 15:20:12.035490: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 15:20:12.554383: lr: 0.004285\n",
      "2021-11-10 15:20:12.559248: This epoch took 312.499698 s\n",
      "\n",
      "2021-11-10 15:20:12.563910: \n",
      "epoch:  61\n",
      "2021-11-10 15:25:10.282098: train loss : -0.8548\n",
      "2021-11-10 15:25:31.820450: validation loss: -0.8541\n",
      "2021-11-10 15:25:31.826302: Average global foreground Dice: [0.8681]\n",
      "2021-11-10 15:25:31.831438: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 15:25:33.360310: lr: 0.004186\n",
      "2021-11-10 15:25:33.365191: This epoch took 320.797208 s\n",
      "\n",
      "2021-11-10 15:25:33.369037: \n",
      "epoch:  62\n",
      "2021-11-10 15:30:29.916656: train loss : -0.8570\n",
      "2021-11-10 15:30:48.235874: validation loss: -0.8372\n",
      "2021-11-10 15:30:48.243551: Average global foreground Dice: [0.8569]\n",
      "2021-11-10 15:30:48.247915: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 15:30:48.785107: lr: 0.004087\n",
      "2021-11-10 15:30:48.789173: This epoch took 315.414967 s\n",
      "\n",
      "2021-11-10 15:30:48.794380: \n",
      "epoch:  63\n",
      "2021-11-10 15:35:50.787421: train loss : -0.8547\n",
      "2021-11-10 15:36:12.831297: validation loss: -0.8450\n",
      "2021-11-10 15:36:12.864003: Average global foreground Dice: [0.8618]\n",
      "2021-11-10 15:36:12.867721: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 15:36:15.022379: lr: 0.003987\n",
      "2021-11-10 15:36:15.026870: This epoch took 326.227897 s\n",
      "\n",
      "2021-11-10 15:36:15.031512: \n",
      "epoch:  64\n",
      "2021-11-10 15:41:18.481865: train loss : -0.8554\n",
      "2021-11-10 15:41:39.891615: validation loss: -0.8433\n",
      "2021-11-10 15:41:39.897841: Average global foreground Dice: [0.8586]\n",
      "2021-11-10 15:41:39.902272: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 15:41:40.831675: lr: 0.003887\n",
      "2021-11-10 15:41:40.836615: This epoch took 325.773590 s\n",
      "\n",
      "2021-11-10 15:41:40.841246: \n",
      "epoch:  65\n",
      "2021-11-10 15:46:39.069284: train loss : -0.8581\n",
      "2021-11-10 15:47:00.331325: validation loss: -0.8362\n",
      "2021-11-10 15:47:00.364448: Average global foreground Dice: [0.8511]\n",
      "2021-11-10 15:47:00.369544: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 15:47:00.988030: lr: 0.003787\n",
      "2021-11-10 15:47:00.993005: This epoch took 320.147213 s\n",
      "\n",
      "2021-11-10 15:47:00.996960: \n",
      "epoch:  66\n",
      "2021-11-10 15:52:02.615233: train loss : -0.8552\n",
      "2021-11-10 15:52:24.879393: validation loss: -0.8457\n",
      "2021-11-10 15:52:24.884634: Average global foreground Dice: [0.8612]\n",
      "2021-11-10 15:52:24.894098: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 15:52:28.061475: lr: 0.003687\n",
      "2021-11-10 15:52:28.066706: This epoch took 327.065374 s\n",
      "\n",
      "2021-11-10 15:52:28.071439: \n",
      "epoch:  67\n",
      "2021-11-10 15:57:27.863761: train loss : -0.8576\n",
      "2021-11-10 15:57:46.296466: validation loss: -0.8439\n",
      "2021-11-10 15:57:46.300750: Average global foreground Dice: [0.8598]\n",
      "2021-11-10 15:57:46.306647: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 15:57:46.830313: lr: 0.003586\n",
      "2021-11-10 15:57:46.835208: This epoch took 318.758603 s\n",
      "\n",
      "2021-11-10 15:57:46.839426: \n",
      "epoch:  68\n",
      "2021-11-10 16:02:44.074061: train loss : -0.8585\n",
      "2021-11-10 16:03:03.262336: validation loss: -0.8437\n",
      "2021-11-10 16:03:03.267255: Average global foreground Dice: [0.86]\n",
      "2021-11-10 16:03:03.273453: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 16:03:03.783487: lr: 0.003485\n",
      "2021-11-10 16:03:03.788289: This epoch took 316.944882 s\n",
      "\n",
      "2021-11-10 16:03:03.793474: \n",
      "epoch:  69\n",
      "2021-11-10 16:07:59.072987: train loss : -0.8596\n",
      "2021-11-10 16:08:20.587654: validation loss: -0.8431\n",
      "2021-11-10 16:08:20.604213: Average global foreground Dice: [0.8628]\n",
      "2021-11-10 16:08:20.612220: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 16:08:22.397122: lr: 0.003384\n",
      "2021-11-10 16:08:22.401808: This epoch took 318.600107 s\n",
      "\n",
      "2021-11-10 16:08:22.407587: \n",
      "epoch:  70\n",
      "2021-11-10 16:13:23.115283: train loss : -0.8595\n",
      "2021-11-10 16:13:45.592766: validation loss: -0.8445\n",
      "2021-11-10 16:13:45.602078: Average global foreground Dice: [0.8606]\n",
      "2021-11-10 16:13:45.610725: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 16:13:46.459098: lr: 0.003282\n",
      "2021-11-10 16:13:46.463318: This epoch took 324.047706 s\n",
      "\n",
      "2021-11-10 16:13:46.468609: \n",
      "epoch:  71\n",
      "2021-11-10 16:18:42.612014: train loss : -0.8640\n",
      "2021-11-10 16:19:02.800273: validation loss: -0.8475\n",
      "2021-11-10 16:19:02.805713: Average global foreground Dice: [0.8667]\n",
      "2021-11-10 16:19:02.810145: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 16:19:03.331761: lr: 0.00318\n",
      "2021-11-10 16:19:03.335588: This epoch took 316.863292 s\n",
      "\n",
      "2021-11-10 16:19:03.340277: \n",
      "epoch:  72\n",
      "2021-11-10 16:24:03.763795: train loss : -0.8599\n",
      "2021-11-10 16:24:25.186572: validation loss: -0.8459\n",
      "2021-11-10 16:24:25.212570: Average global foreground Dice: [0.8615]\n",
      "2021-11-10 16:24:25.216844: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 16:24:26.826795: lr: 0.003078\n",
      "2021-11-10 16:24:26.830840: This epoch took 323.486142 s\n",
      "\n",
      "2021-11-10 16:24:26.834959: \n",
      "epoch:  73\n",
      "2021-11-10 16:29:22.419436: train loss : -0.8589\n",
      "2021-11-10 16:29:41.985620: validation loss: -0.8487\n",
      "2021-11-10 16:29:41.991590: Average global foreground Dice: [0.8659]\n",
      "2021-11-10 16:29:41.996167: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 16:29:42.533290: lr: 0.002975\n",
      "2021-11-10 16:29:42.569540: saving checkpoint...\n",
      "2021-11-10 16:29:43.627221: done, saving took 1.09 seconds\n",
      "2021-11-10 16:29:43.663177: This epoch took 316.823845 s\n",
      "\n",
      "2021-11-10 16:29:43.667667: \n",
      "epoch:  74\n",
      "2021-11-10 16:34:47.422756: train loss : -0.8622\n",
      "2021-11-10 16:35:09.176592: validation loss: -0.8473\n",
      "2021-11-10 16:35:09.182311: Average global foreground Dice: [0.865]\n",
      "2021-11-10 16:35:09.186584: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 16:35:10.660529: lr: 0.002872\n",
      "2021-11-10 16:35:10.808932: saving checkpoint...\n",
      "2021-11-10 16:35:12.485004: done, saving took 1.82 seconds\n",
      "2021-11-10 16:35:12.520904: This epoch took 328.848748 s\n",
      "\n",
      "2021-11-10 16:35:12.525976: \n",
      "epoch:  75\n",
      "2021-11-10 16:40:07.864542: train loss : -0.8652\n",
      "2021-11-10 16:40:27.149462: validation loss: -0.8424\n",
      "2021-11-10 16:40:27.153744: Average global foreground Dice: [0.8594]\n",
      "2021-11-10 16:40:27.158742: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 16:40:27.696754: lr: 0.002768\n",
      "2021-11-10 16:40:27.700728: This epoch took 315.170041 s\n",
      "\n",
      "2021-11-10 16:40:27.705431: \n",
      "epoch:  76\n",
      "2021-11-10 16:45:20.472655: train loss : -0.8634\n",
      "2021-11-10 16:45:40.359180: validation loss: -0.8439\n",
      "2021-11-10 16:45:40.367338: Average global foreground Dice: [0.8621]\n",
      "2021-11-10 16:45:40.373340: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 16:45:40.935621: lr: 0.002664\n",
      "2021-11-10 16:45:40.940531: This epoch took 313.230397 s\n",
      "\n",
      "2021-11-10 16:45:40.944773: \n",
      "epoch:  77\n",
      "2021-11-10 16:50:40.275390: train loss : -0.8646\n",
      "2021-11-10 16:51:01.441533: validation loss: -0.8515\n",
      "2021-11-10 16:51:01.448225: Average global foreground Dice: [0.8672]\n",
      "2021-11-10 16:51:01.452612: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 16:51:01.993858: lr: 0.00256\n",
      "2021-11-10 16:51:02.074825: saving checkpoint...\n",
      "2021-11-10 16:51:03.193458: done, saving took 1.19 seconds\n",
      "2021-11-10 16:51:03.220312: This epoch took 322.270999 s\n",
      "\n",
      "2021-11-10 16:51:03.224805: \n",
      "epoch:  78\n",
      "2021-11-10 16:55:57.763408: train loss : -0.8636\n",
      "2021-11-10 16:56:16.948979: validation loss: -0.8447\n",
      "2021-11-10 16:56:16.953509: Average global foreground Dice: [0.863]\n",
      "2021-11-10 16:56:16.957966: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 16:56:17.463669: lr: 0.002455\n",
      "2021-11-10 16:56:17.496567: saving checkpoint...\n",
      "2021-11-10 16:56:18.497695: done, saving took 1.03 seconds\n",
      "2021-11-10 16:56:18.519418: This epoch took 315.289969 s\n",
      "\n",
      "2021-11-10 16:56:18.524159: \n",
      "epoch:  79\n",
      "2021-11-10 17:01:13.979470: train loss : -0.8655\n",
      "2021-11-10 17:01:32.568060: validation loss: -0.8489\n",
      "2021-11-10 17:01:32.573129: Average global foreground Dice: [0.8658]\n",
      "2021-11-10 17:01:32.577932: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 17:01:33.113611: lr: 0.002349\n",
      "2021-11-10 17:01:33.148989: saving checkpoint...\n",
      "2021-11-10 17:01:34.192700: done, saving took 1.07 seconds\n",
      "2021-11-10 17:01:34.214936: This epoch took 315.686846 s\n",
      "\n",
      "2021-11-10 17:01:34.220370: \n",
      "epoch:  80\n",
      "2021-11-10 17:06:32.367238: train loss : -0.8646\n",
      "2021-11-10 17:06:52.788609: validation loss: -0.8294\n",
      "2021-11-10 17:06:52.795210: Average global foreground Dice: [0.8494]\n",
      "2021-11-10 17:06:52.799960: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 17:06:53.345922: lr: 0.002243\n",
      "2021-11-10 17:06:53.351365: This epoch took 319.127388 s\n",
      "\n",
      "2021-11-10 17:06:53.356375: \n",
      "epoch:  81\n",
      "2021-11-10 17:11:46.110470: train loss : -0.8677\n",
      "2021-11-10 17:12:04.694903: validation loss: -0.8408\n",
      "2021-11-10 17:12:04.700045: Average global foreground Dice: [0.8576]\n",
      "2021-11-10 17:12:04.704555: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 17:12:05.259317: lr: 0.002137\n",
      "2021-11-10 17:12:05.272167: This epoch took 311.910805 s\n",
      "\n",
      "2021-11-10 17:12:05.283995: \n",
      "epoch:  82\n",
      "2021-11-10 17:16:56.772916: train loss : -0.8672\n",
      "2021-11-10 17:17:17.126585: validation loss: -0.8442\n",
      "2021-11-10 17:17:17.131307: Average global foreground Dice: [0.8585]\n",
      "2021-11-10 17:17:17.136518: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 17:17:17.677330: lr: 0.00203\n",
      "2021-11-10 17:17:17.681681: This epoch took 312.385406 s\n",
      "\n",
      "2021-11-10 17:17:17.686797: \n",
      "epoch:  83\n",
      "2021-11-10 17:22:13.554157: train loss : -0.8699\n",
      "2021-11-10 17:22:32.107890: validation loss: -0.8475\n",
      "2021-11-10 17:22:32.116318: Average global foreground Dice: [0.8645]\n",
      "2021-11-10 17:22:32.121834: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 17:22:32.676962: lr: 0.001922\n",
      "2021-11-10 17:22:32.688046: This epoch took 314.995896 s\n",
      "\n",
      "2021-11-10 17:22:32.699252: \n",
      "epoch:  84\n",
      "2021-11-10 17:27:45.471993: train loss : -0.8671\n",
      "2021-11-10 17:28:07.492789: validation loss: -0.8438\n",
      "2021-11-10 17:28:07.498969: Average global foreground Dice: [0.8611]\n",
      "2021-11-10 17:28:07.505329: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 17:28:08.950986: lr: 0.001813\n",
      "2021-11-10 17:28:08.956268: This epoch took 336.246737 s\n",
      "\n",
      "2021-11-10 17:28:08.963007: \n",
      "epoch:  85\n",
      "2021-11-10 17:33:03.598818: train loss : -0.8706\n",
      "2021-11-10 17:33:25.094417: validation loss: -0.8526\n",
      "2021-11-10 17:33:25.101050: Average global foreground Dice: [0.8658]\n",
      "2021-11-10 17:33:25.107152: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 17:33:25.752813: lr: 0.001704\n",
      "2021-11-10 17:33:25.762086: This epoch took 316.793863 s\n",
      "\n",
      "2021-11-10 17:33:25.772712: \n",
      "epoch:  86\n",
      "2021-11-10 17:38:25.885871: train loss : -0.8726\n",
      "2021-11-10 17:38:47.626613: validation loss: -0.8384\n",
      "2021-11-10 17:38:47.632135: Average global foreground Dice: [0.8566]\n",
      "2021-11-10 17:38:47.636262: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 17:38:48.191808: lr: 0.001594\n",
      "2021-11-10 17:38:48.199334: This epoch took 322.416853 s\n",
      "\n",
      "2021-11-10 17:38:48.204800: \n",
      "epoch:  87\n",
      "2021-11-10 17:43:55.202157: train loss : -0.8676\n",
      "2021-11-10 17:44:16.626321: validation loss: -0.8481\n",
      "2021-11-10 17:44:16.660075: Average global foreground Dice: [0.8649]\n",
      "2021-11-10 17:44:16.665285: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 17:44:17.872389: lr: 0.001483\n",
      "2021-11-10 17:44:17.883614: This epoch took 329.670858 s\n",
      "\n",
      "2021-11-10 17:44:17.894053: \n",
      "epoch:  88\n",
      "2021-11-10 17:49:17.096992: train loss : -0.8708\n",
      "2021-11-10 17:49:39.010576: validation loss: -0.8421\n",
      "2021-11-10 17:49:39.025887: Average global foreground Dice: [0.8608]\n",
      "2021-11-10 17:49:39.031095: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 17:49:40.659625: lr: 0.001372\n",
      "2021-11-10 17:49:40.665313: This epoch took 322.761376 s\n",
      "\n",
      "2021-11-10 17:49:40.670237: \n",
      "epoch:  89\n",
      "2021-11-10 17:54:41.881588: train loss : -0.8699\n",
      "2021-11-10 17:55:01.790869: validation loss: -0.8467\n",
      "2021-11-10 17:55:01.796502: Average global foreground Dice: [0.8652]\n",
      "2021-11-10 17:55:01.805317: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 17:55:02.369690: lr: 0.001259\n",
      "2021-11-10 17:55:02.382054: This epoch took 321.704289 s\n",
      "\n",
      "2021-11-10 17:55:02.393482: \n",
      "epoch:  90\n",
      "2021-11-10 18:00:04.203916: train loss : -0.8702\n",
      "2021-11-10 18:00:25.786666: validation loss: -0.8468\n",
      "2021-11-10 18:00:25.815460: Average global foreground Dice: [0.8669]\n",
      "2021-11-10 18:00:25.821567: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 18:00:27.743030: lr: 0.001145\n",
      "2021-11-10 18:00:27.748194: This epoch took 325.343812 s\n",
      "\n",
      "2021-11-10 18:00:27.763693: \n",
      "epoch:  91\n",
      "2021-11-10 18:05:20.372822: train loss : -0.8685\n",
      "2021-11-10 18:05:39.386613: validation loss: -0.8495\n",
      "2021-11-10 18:05:39.392376: Average global foreground Dice: [0.8651]\n",
      "2021-11-10 18:05:39.397357: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 18:05:39.944705: lr: 0.00103\n",
      "2021-11-10 18:05:40.014012: saving checkpoint...\n",
      "2021-11-10 18:05:41.203241: done, saving took 1.25 seconds\n",
      "2021-11-10 18:05:41.241190: This epoch took 313.472089 s\n",
      "\n",
      "2021-11-10 18:05:41.246573: \n",
      "epoch:  92\n",
      "2021-11-10 18:10:38.201517: train loss : -0.8718\n",
      "2021-11-10 18:10:58.538019: validation loss: -0.8441\n",
      "2021-11-10 18:10:58.551447: Average global foreground Dice: [0.8605]\n",
      "2021-11-10 18:10:58.564215: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 18:10:59.105632: lr: 0.000913\n",
      "2021-11-10 18:10:59.110559: This epoch took 317.858693 s\n",
      "\n",
      "2021-11-10 18:10:59.115195: \n",
      "epoch:  93\n",
      "2021-11-10 18:15:58.011800: train loss : -0.8731\n",
      "2021-11-10 18:16:19.479069: validation loss: -0.8436\n",
      "2021-11-10 18:16:19.485328: Average global foreground Dice: [0.8612]\n",
      "2021-11-10 18:16:19.490055: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 18:16:21.121343: lr: 0.000795\n",
      "2021-11-10 18:16:21.128658: This epoch took 322.008322 s\n",
      "\n",
      "2021-11-10 18:16:21.133472: \n",
      "epoch:  94\n",
      "2021-11-10 18:21:16.701393: train loss : -0.8722\n",
      "2021-11-10 18:21:36.290278: validation loss: -0.8456\n",
      "2021-11-10 18:21:36.298957: Average global foreground Dice: [0.8617]\n",
      "2021-11-10 18:21:36.303981: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 18:21:36.988457: lr: 0.000675\n",
      "2021-11-10 18:21:36.993750: This epoch took 315.855300 s\n",
      "\n",
      "2021-11-10 18:21:36.998384: \n",
      "epoch:  95\n",
      "2021-11-10 18:26:33.000279: train loss : -0.8741\n",
      "2021-11-10 18:26:51.703742: validation loss: -0.8529\n",
      "2021-11-10 18:26:51.708852: Average global foreground Dice: [0.8692]\n",
      "2021-11-10 18:26:51.713924: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 18:26:52.262991: lr: 0.000552\n",
      "2021-11-10 18:26:52.335443: saving checkpoint...\n",
      "2021-11-10 18:26:53.576219: done, saving took 1.30 seconds\n",
      "2021-11-10 18:26:53.622565: This epoch took 316.619308 s\n",
      "\n",
      "2021-11-10 18:26:53.630734: \n",
      "epoch:  96\n",
      "2021-11-10 18:31:49.538754: train loss : -0.8746\n",
      "2021-11-10 18:32:08.915078: validation loss: -0.8484\n",
      "2021-11-10 18:32:08.920907: Average global foreground Dice: [0.8613]\n",
      "2021-11-10 18:32:08.925758: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 18:32:09.448504: lr: 0.000426\n",
      "2021-11-10 18:32:09.455351: This epoch took 315.819599 s\n",
      "\n",
      "2021-11-10 18:32:09.459732: \n",
      "epoch:  97\n",
      "2021-11-10 18:37:04.081468: train loss : -0.8749\n",
      "2021-11-10 18:37:24.065922: validation loss: -0.8463\n",
      "2021-11-10 18:37:24.071113: Average global foreground Dice: [0.8606]\n",
      "2021-11-10 18:37:24.075674: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 18:37:24.637871: lr: 0.000296\n",
      "2021-11-10 18:37:24.642624: This epoch took 315.178522 s\n",
      "\n",
      "2021-11-10 18:37:24.646603: \n",
      "epoch:  98\n",
      "2021-11-10 18:42:26.480923: train loss : -0.8727\n",
      "2021-11-10 18:42:48.907616: validation loss: -0.8529\n",
      "2021-11-10 18:42:48.924601: Average global foreground Dice: [0.8702]\n",
      "2021-11-10 18:42:48.930158: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 18:42:50.760298: lr: 0.000158\n",
      "2021-11-10 18:42:50.965343: saving checkpoint...\n",
      "2021-11-10 18:42:53.072080: done, saving took 2.31 seconds\n",
      "2021-11-10 18:42:53.105970: This epoch took 328.455057 s\n",
      "\n",
      "2021-11-10 18:42:53.110867: \n",
      "epoch:  99\n",
      "2021-11-10 18:47:54.580996: train loss : -0.8751\n",
      "2021-11-10 18:48:16.597193: validation loss: -0.8421\n",
      "2021-11-10 18:48:16.615540: Average global foreground Dice: [0.8596]\n",
      "2021-11-10 18:48:16.620204: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 18:48:17.971429: lr: 0.0\n",
      "2021-11-10 18:48:17.976109: saving scheduled checkpoint file...\n",
      "2021-11-10 18:48:18.009660: saving checkpoint...\n",
      "2021-11-10 18:48:19.211895: done, saving took 1.23 seconds\n",
      "2021-11-10 18:48:19.252748: done\n",
      "2021-11-10 18:48:19.257706: This epoch took 326.143093 s\n",
      "\n",
      "2021-11-10 18:48:19.295561: saving checkpoint...\n",
      "2021-11-10 18:48:20.277834: done, saving took 1.01 seconds\n",
      "23090557_20130717 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090560_20160114 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090562_20140206 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141215 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130626 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140124 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121015 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090597_20130227 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130208 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090621_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150105 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130807 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090637_20140401 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131126 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090644_20131216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-10 18:51:44.902657: finished prediction\n",
      "2021-11-10 18:51:44.907372: evaluation of raw predictions\n",
      "2021-11-10 18:51:46.653880: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8623335462836286\n",
      "after:  0.8639118129382377\n",
      "Removing all but the largest foreground region improved results!\n",
      "for_which_classes [1]\n",
      "min_valid_object_sizes None\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[[1]]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-10 18:51:57.084354: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-10 18:51:57.108277: The split file contains 5 splits.\n",
      "2021-11-10 18:51:57.115544: Desired fold for training: 4\n",
      "2021-11-10 18:51:57.123587: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-10 18:52:01.467057: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-10 18:52:19.828255: Unable to plot network architecture:\n",
      "2021-11-10 18:52:19.833626: No module named 'hiddenlayer'\n",
      "2021-11-10 18:52:19.859698: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-10 18:52:19.864798: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-10 18:52:19.880079: \n",
      "\n",
      "2021-11-10 18:52:19.885001: \n",
      "epoch:  0\n",
      "2021-11-10 18:57:55.616143: train loss : -0.2080\n",
      "2021-11-10 18:58:17.796420: validation loss: -0.5160\n",
      "2021-11-10 18:58:17.804592: Average global foreground Dice: [0.5881]\n",
      "2021-11-10 18:58:17.808674: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 18:58:18.902435: lr: 0.00991\n",
      "2021-11-10 18:58:18.906592: This epoch took 359.016618 s\n",
      "\n",
      "2021-11-10 18:58:18.910555: \n",
      "epoch:  1\n",
      "2021-11-10 19:03:19.973657: train loss : -0.6094\n",
      "2021-11-10 19:03:41.976948: validation loss: -0.6528\n",
      "2021-11-10 19:03:41.992682: Average global foreground Dice: [0.6932]\n",
      "2021-11-10 19:03:41.996538: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 19:03:44.069866: lr: 0.00982\n",
      "2021-11-10 19:03:44.296555: saving checkpoint...\n",
      "2021-11-10 19:03:45.907381: done, saving took 1.83 seconds\n",
      "2021-11-10 19:03:45.940336: This epoch took 327.025820 s\n",
      "\n",
      "2021-11-10 19:03:45.945256: \n",
      "epoch:  2\n",
      "2021-11-10 19:08:44.799561: train loss : -0.6833\n",
      "2021-11-10 19:09:06.370809: validation loss: -0.7363\n",
      "2021-11-10 19:09:06.374875: Average global foreground Dice: [0.7846]\n",
      "2021-11-10 19:09:06.379649: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 19:09:06.905645: lr: 0.00973\n",
      "2021-11-10 19:09:06.980640: saving checkpoint...\n",
      "2021-11-10 19:09:08.138154: done, saving took 1.23 seconds\n",
      "2021-11-10 19:09:08.164351: This epoch took 322.214906 s\n",
      "\n",
      "2021-11-10 19:09:08.169011: \n",
      "epoch:  3\n",
      "2021-11-10 19:14:07.513869: train loss : -0.7058\n",
      "2021-11-10 19:14:29.034579: validation loss: -0.7502\n",
      "2021-11-10 19:14:29.069793: Average global foreground Dice: [0.7936]\n",
      "2021-11-10 19:14:29.073635: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 19:14:30.209330: lr: 0.009639\n",
      "2021-11-10 19:14:30.310149: saving checkpoint...\n",
      "2021-11-10 19:14:31.449392: done, saving took 1.23 seconds\n",
      "2021-11-10 19:14:31.476831: This epoch took 323.302415 s\n",
      "\n",
      "2021-11-10 19:14:31.481330: \n",
      "epoch:  4\n",
      "2021-11-10 19:19:28.393576: train loss : -0.7415\n",
      "2021-11-10 19:19:49.627432: validation loss: -0.7776\n",
      "2021-11-10 19:19:49.676051: Average global foreground Dice: [0.8169]\n",
      "2021-11-10 19:19:49.681324: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 19:19:51.893467: lr: 0.009549\n",
      "2021-11-10 19:19:52.124700: saving checkpoint...\n",
      "2021-11-10 19:19:53.452961: done, saving took 1.55 seconds\n",
      "2021-11-10 19:19:53.496697: This epoch took 322.010652 s\n",
      "\n",
      "2021-11-10 19:19:53.502025: \n",
      "epoch:  5\n",
      "2021-11-10 19:24:51.187643: train loss : -0.7698\n",
      "2021-11-10 19:25:11.405911: validation loss: -0.7947\n",
      "2021-11-10 19:25:11.410733: Average global foreground Dice: [0.8286]\n",
      "2021-11-10 19:25:11.414604: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 19:25:11.935900: lr: 0.009458\n",
      "2021-11-10 19:25:12.017763: saving checkpoint...\n",
      "2021-11-10 19:25:13.178550: done, saving took 1.24 seconds\n",
      "2021-11-10 19:25:13.210295: This epoch took 319.703305 s\n",
      "\n",
      "2021-11-10 19:25:13.214570: \n",
      "epoch:  6\n",
      "2021-11-10 19:30:10.785254: train loss : -0.7775\n",
      "2021-11-10 19:30:31.942899: validation loss: -0.7997\n",
      "2021-11-10 19:30:31.963977: Average global foreground Dice: [0.8341]\n",
      "2021-11-10 19:30:31.969086: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 19:30:32.571537: lr: 0.009368\n",
      "2021-11-10 19:30:32.604825: saving checkpoint...\n",
      "2021-11-10 19:30:33.646778: done, saving took 1.07 seconds\n",
      "2021-11-10 19:30:33.683864: This epoch took 320.465916 s\n",
      "\n",
      "2021-11-10 19:30:33.690738: \n",
      "epoch:  7\n",
      "2021-11-10 19:35:23.347482: train loss : -0.7891\n",
      "2021-11-10 19:35:41.343705: validation loss: -0.8043\n",
      "2021-11-10 19:35:41.348001: Average global foreground Dice: [0.8371]\n",
      "2021-11-10 19:35:41.352242: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 19:35:41.852833: lr: 0.009277\n",
      "2021-11-10 19:35:41.919155: saving checkpoint...\n",
      "2021-11-10 19:35:43.123922: done, saving took 1.27 seconds\n",
      "2021-11-10 19:35:43.164276: This epoch took 309.466134 s\n",
      "\n",
      "2021-11-10 19:35:43.168924: \n",
      "epoch:  8\n",
      "2021-11-10 19:40:39.189718: train loss : -0.7956\n",
      "2021-11-10 19:40:58.765192: validation loss: -0.8002\n",
      "2021-11-10 19:40:58.770349: Average global foreground Dice: [0.8232]\n",
      "2021-11-10 19:40:58.774564: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 19:40:59.338760: lr: 0.009186\n",
      "2021-11-10 19:40:59.409850: saving checkpoint...\n",
      "2021-11-10 19:41:00.614476: done, saving took 1.27 seconds\n",
      "2021-11-10 19:41:00.642713: This epoch took 317.469178 s\n",
      "\n",
      "2021-11-10 19:41:00.647291: \n",
      "epoch:  9\n",
      "2021-11-10 19:46:01.924357: train loss : -0.7966\n",
      "2021-11-10 19:46:24.718584: validation loss: -0.8160\n",
      "2021-11-10 19:46:24.734493: Average global foreground Dice: [0.8364]\n",
      "2021-11-10 19:46:24.763990: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 19:46:26.988306: lr: 0.009095\n",
      "2021-11-10 19:46:27.071323: saving checkpoint...\n",
      "2021-11-10 19:46:29.759545: done, saving took 2.77 seconds\n",
      "2021-11-10 19:46:29.786592: This epoch took 329.134607 s\n",
      "\n",
      "2021-11-10 19:46:29.791400: \n",
      "epoch:  10\n",
      "2021-11-10 19:51:32.604625: train loss : -0.7981\n",
      "2021-11-10 19:51:55.002682: validation loss: -0.8158\n",
      "2021-11-10 19:51:55.028384: Average global foreground Dice: [0.8374]\n",
      "2021-11-10 19:51:55.059722: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 19:51:57.480903: lr: 0.009004\n",
      "2021-11-10 19:51:57.564016: saving checkpoint...\n",
      "2021-11-10 19:51:59.666080: done, saving took 2.18 seconds\n",
      "2021-11-10 19:51:59.691505: This epoch took 329.895822 s\n",
      "\n",
      "2021-11-10 19:51:59.696743: \n",
      "epoch:  11\n",
      "2021-11-10 19:57:00.301916: train loss : -0.8040\n",
      "2021-11-10 19:57:19.790356: validation loss: -0.8180\n",
      "2021-11-10 19:57:19.795531: Average global foreground Dice: [0.8462]\n",
      "2021-11-10 19:57:19.799807: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 19:57:20.294205: lr: 0.008913\n",
      "2021-11-10 19:57:20.345836: saving checkpoint...\n",
      "2021-11-10 19:57:21.494632: done, saving took 1.19 seconds\n",
      "2021-11-10 19:57:21.519877: This epoch took 321.815917 s\n",
      "\n",
      "2021-11-10 19:57:21.524379: \n",
      "epoch:  12\n",
      "2021-11-10 20:02:17.173209: train loss : -0.8123\n",
      "2021-11-10 20:02:36.362226: validation loss: -0.8252\n",
      "2021-11-10 20:02:36.366853: Average global foreground Dice: [0.8471]\n",
      "2021-11-10 20:02:36.371033: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 20:02:36.855473: lr: 0.008822\n",
      "2021-11-10 20:02:36.918266: saving checkpoint...\n",
      "2021-11-10 20:02:38.180035: done, saving took 1.32 seconds\n",
      "2021-11-10 20:02:38.209761: This epoch took 316.680532 s\n",
      "\n",
      "2021-11-10 20:02:38.214269: \n",
      "epoch:  13\n",
      "2021-11-10 20:07:33.215336: train loss : -0.8107\n",
      "2021-11-10 20:07:54.502687: validation loss: -0.8152\n",
      "2021-11-10 20:07:54.508282: Average global foreground Dice: [0.8376]\n",
      "2021-11-10 20:07:54.512822: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 20:07:55.116111: lr: 0.008731\n",
      "2021-11-10 20:07:55.206153: saving checkpoint...\n",
      "2021-11-10 20:07:56.361798: done, saving took 1.24 seconds\n",
      "2021-11-10 20:07:56.399440: This epoch took 318.180658 s\n",
      "\n",
      "2021-11-10 20:07:56.405323: \n",
      "epoch:  14\n",
      "2021-11-10 20:12:54.685714: train loss : -0.8137\n",
      "2021-11-10 20:13:16.160187: validation loss: -0.8277\n",
      "2021-11-10 20:13:16.167180: Average global foreground Dice: [0.8482]\n",
      "2021-11-10 20:13:16.175617: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 20:13:17.009683: lr: 0.008639\n",
      "2021-11-10 20:13:17.080296: saving checkpoint...\n",
      "2021-11-10 20:13:18.207644: done, saving took 1.19 seconds\n",
      "2021-11-10 20:13:18.243458: This epoch took 321.830843 s\n",
      "\n",
      "2021-11-10 20:13:18.247648: \n",
      "epoch:  15\n",
      "2021-11-10 20:18:15.774415: train loss : -0.8207\n",
      "2021-11-10 20:18:35.123327: validation loss: -0.8263\n",
      "2021-11-10 20:18:35.128441: Average global foreground Dice: [0.8488]\n",
      "2021-11-10 20:18:35.133032: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 20:18:35.629339: lr: 0.008548\n",
      "2021-11-10 20:18:35.662366: saving checkpoint...\n",
      "2021-11-10 20:18:36.738609: done, saving took 1.10 seconds\n",
      "2021-11-10 20:18:36.769748: This epoch took 318.517915 s\n",
      "\n",
      "2021-11-10 20:18:36.773751: \n",
      "epoch:  16\n",
      "2021-11-10 20:23:39.981736: train loss : -0.8115\n",
      "2021-11-10 20:24:02.905023: validation loss: -0.8267\n",
      "2021-11-10 20:24:02.919185: Average global foreground Dice: [0.8402]\n",
      "2021-11-10 20:24:02.923576: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 20:24:05.212317: lr: 0.008456\n",
      "2021-11-10 20:24:05.287817: saving checkpoint...\n",
      "2021-11-10 20:24:07.617019: done, saving took 2.40 seconds\n",
      "2021-11-10 20:24:07.671560: This epoch took 330.893642 s\n",
      "\n",
      "2021-11-10 20:24:07.676533: \n",
      "epoch:  17\n",
      "2021-11-10 20:29:10.068693: train loss : -0.8170\n",
      "2021-11-10 20:29:30.415816: validation loss: -0.8212\n",
      "2021-11-10 20:29:30.420503: Average global foreground Dice: [0.8378]\n",
      "2021-11-10 20:29:30.425143: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 20:29:30.927190: lr: 0.008364\n",
      "2021-11-10 20:29:30.959799: saving checkpoint...\n",
      "2021-11-10 20:29:32.058178: done, saving took 1.13 seconds\n",
      "2021-11-10 20:29:32.093215: This epoch took 324.411900 s\n",
      "\n",
      "2021-11-10 20:29:32.098411: \n",
      "epoch:  18\n",
      "2021-11-10 20:34:29.583612: train loss : -0.8178\n",
      "2021-11-10 20:34:50.918942: validation loss: -0.8293\n",
      "2021-11-10 20:34:50.925303: Average global foreground Dice: [0.8474]\n",
      "2021-11-10 20:34:50.931499: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 20:34:52.528872: lr: 0.008272\n",
      "2021-11-10 20:34:52.603636: saving checkpoint...\n",
      "2021-11-10 20:34:53.857616: done, saving took 1.32 seconds\n",
      "2021-11-10 20:34:53.899216: This epoch took 321.795978 s\n",
      "\n",
      "2021-11-10 20:34:53.904076: \n",
      "epoch:  19\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-10 20:39:54.289211: train loss : -0.8178\n",
      "2021-11-10 20:40:15.583513: validation loss: -0.8320\n",
      "2021-11-10 20:40:15.590472: Average global foreground Dice: [0.8526]\n",
      "2021-11-10 20:40:15.595704: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 20:40:16.281503: lr: 0.008181\n",
      "2021-11-10 20:40:16.362305: saving checkpoint...\n",
      "2021-11-10 20:40:17.438277: done, saving took 1.15 seconds\n",
      "2021-11-10 20:40:17.480878: This epoch took 323.572723 s\n",
      "\n",
      "2021-11-10 20:40:17.489191: \n",
      "epoch:  20\n",
      "2021-11-10 20:45:12.585532: train loss : -0.8233\n",
      "2021-11-10 20:45:33.930488: validation loss: -0.8230\n",
      "2021-11-10 20:45:33.964868: Average global foreground Dice: [0.8409]\n",
      "2021-11-10 20:45:33.968853: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 20:45:34.944635: lr: 0.008088\n",
      "2021-11-10 20:45:35.013642: saving checkpoint...\n",
      "2021-11-10 20:45:36.122967: done, saving took 1.17 seconds\n",
      "2021-11-10 20:45:36.178021: This epoch took 318.680701 s\n",
      "\n",
      "2021-11-10 20:45:36.182785: \n",
      "epoch:  21\n",
      "2021-11-10 20:50:31.214068: train loss : -0.8222\n",
      "2021-11-10 20:50:49.139758: validation loss: -0.8258\n",
      "2021-11-10 20:50:49.144522: Average global foreground Dice: [0.8469]\n",
      "2021-11-10 20:50:49.148825: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 20:50:49.642550: lr: 0.007996\n",
      "2021-11-10 20:50:49.676047: saving checkpoint...\n",
      "2021-11-10 20:50:50.787491: done, saving took 1.14 seconds\n",
      "2021-11-10 20:50:50.818625: This epoch took 314.631354 s\n",
      "\n",
      "2021-11-10 20:50:50.823308: \n",
      "epoch:  22\n",
      "2021-11-10 20:55:44.421300: train loss : -0.8288\n",
      "2021-11-10 20:56:02.892812: validation loss: -0.8262\n",
      "2021-11-10 20:56:02.898278: Average global foreground Dice: [0.8477]\n",
      "2021-11-10 20:56:02.902997: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 20:56:03.400689: lr: 0.007904\n",
      "2021-11-10 20:56:03.433821: saving checkpoint...\n",
      "2021-11-10 20:56:04.494065: done, saving took 1.09 seconds\n",
      "2021-11-10 20:56:04.526935: This epoch took 313.699076 s\n",
      "\n",
      "2021-11-10 20:56:04.531819: \n",
      "epoch:  23\n",
      "2021-11-10 21:01:03.012282: train loss : -0.8259\n",
      "2021-11-10 21:01:21.037184: validation loss: -0.8308\n",
      "2021-11-10 21:01:21.042811: Average global foreground Dice: [0.8497]\n",
      "2021-11-10 21:01:21.047018: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 21:01:21.541826: lr: 0.007811\n",
      "2021-11-10 21:01:21.574210: saving checkpoint...\n",
      "2021-11-10 21:01:22.603235: done, saving took 1.06 seconds\n",
      "2021-11-10 21:01:22.640649: This epoch took 318.103839 s\n",
      "\n",
      "2021-11-10 21:01:22.647742: \n",
      "epoch:  24\n",
      "2021-11-10 21:06:19.286087: train loss : -0.8336\n",
      "2021-11-10 21:06:40.184687: validation loss: -0.8167\n",
      "2021-11-10 21:06:40.190505: Average global foreground Dice: [0.8349]\n",
      "2021-11-10 21:06:40.195032: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 21:06:41.278957: lr: 0.007719\n",
      "2021-11-10 21:06:41.313280: saving checkpoint...\n",
      "2021-11-10 21:06:42.500117: done, saving took 1.22 seconds\n",
      "2021-11-10 21:06:42.548227: This epoch took 319.895961 s\n",
      "\n",
      "2021-11-10 21:06:42.555898: \n",
      "epoch:  25\n",
      "2021-11-10 21:11:42.997735: train loss : -0.8263\n",
      "2021-11-10 21:12:04.690625: validation loss: -0.8406\n",
      "2021-11-10 21:12:04.705099: Average global foreground Dice: [0.8579]\n",
      "2021-11-10 21:12:04.709405: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 21:12:06.219298: lr: 0.007626\n",
      "2021-11-10 21:12:06.310503: saving checkpoint...\n",
      "2021-11-10 21:12:07.494232: done, saving took 1.27 seconds\n",
      "2021-11-10 21:12:07.538417: This epoch took 324.974526 s\n",
      "\n",
      "2021-11-10 21:12:07.542641: \n",
      "epoch:  26\n",
      "2021-11-10 21:17:06.073259: train loss : -0.8283\n",
      "2021-11-10 21:17:27.276186: validation loss: -0.8295\n",
      "2021-11-10 21:17:27.281208: Average global foreground Dice: [0.8509]\n",
      "2021-11-10 21:17:27.285889: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 21:17:27.835974: lr: 0.007533\n",
      "2021-11-10 21:17:27.894547: saving checkpoint...\n",
      "2021-11-10 21:17:29.052675: done, saving took 1.21 seconds\n",
      "2021-11-10 21:17:29.098763: This epoch took 321.551272 s\n",
      "\n",
      "2021-11-10 21:17:29.103281: \n",
      "epoch:  27\n",
      "2021-11-10 21:22:27.468079: train loss : -0.8324\n",
      "2021-11-10 21:22:50.105942: validation loss: -0.8323\n",
      "2021-11-10 21:22:50.112408: Average global foreground Dice: [0.8495]\n",
      "2021-11-10 21:22:50.118661: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 21:22:51.592556: lr: 0.00744\n",
      "2021-11-10 21:22:51.669925: saving checkpoint...\n",
      "2021-11-10 21:22:53.507889: done, saving took 1.91 seconds\n",
      "2021-11-10 21:22:53.550184: This epoch took 324.442164 s\n",
      "\n",
      "2021-11-10 21:22:53.555736: \n",
      "epoch:  28\n",
      "2021-11-10 21:27:53.900045: train loss : -0.8375\n",
      "2021-11-10 21:28:15.676745: validation loss: -0.8306\n",
      "2021-11-10 21:28:15.684035: Average global foreground Dice: [0.8444]\n",
      "2021-11-10 21:28:15.688873: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 21:28:17.506754: lr: 0.007347\n",
      "2021-11-10 21:28:17.575520: saving checkpoint...\n",
      "2021-11-10 21:28:18.825806: done, saving took 1.31 seconds\n",
      "2021-11-10 21:28:18.860472: This epoch took 325.300580 s\n",
      "\n",
      "2021-11-10 21:28:18.866405: \n",
      "epoch:  29\n",
      "2021-11-10 21:33:17.873093: train loss : -0.8289\n",
      "2021-11-10 21:33:39.294961: validation loss: -0.8384\n",
      "2021-11-10 21:33:39.304327: Average global foreground Dice: [0.8524]\n",
      "2021-11-10 21:33:39.308817: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 21:33:40.632653: lr: 0.007254\n",
      "2021-11-10 21:33:40.672678: saving checkpoint...\n",
      "2021-11-10 21:33:41.832984: done, saving took 1.19 seconds\n",
      "2021-11-10 21:33:41.873112: This epoch took 323.001547 s\n",
      "\n",
      "2021-11-10 21:33:41.877269: \n",
      "epoch:  30\n",
      "2021-11-10 21:38:38.172986: train loss : -0.8378\n",
      "2021-11-10 21:39:00.372531: validation loss: -0.8377\n",
      "2021-11-10 21:39:00.393859: Average global foreground Dice: [0.8581]\n",
      "2021-11-10 21:39:00.399255: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 21:39:01.730271: lr: 0.007161\n",
      "2021-11-10 21:39:01.804475: saving checkpoint...\n",
      "2021-11-10 21:39:03.133504: done, saving took 1.40 seconds\n",
      "2021-11-10 21:39:03.167861: This epoch took 321.285098 s\n",
      "\n",
      "2021-11-10 21:39:03.173695: \n",
      "epoch:  31\n",
      "2021-11-10 21:43:57.606994: train loss : -0.8369\n",
      "2021-11-10 21:44:17.941738: validation loss: -0.8411\n",
      "2021-11-10 21:44:17.946808: Average global foreground Dice: [0.8625]\n",
      "2021-11-10 21:44:17.951817: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 21:44:18.482881: lr: 0.007067\n",
      "2021-11-10 21:44:18.548855: saving checkpoint...\n",
      "2021-11-10 21:44:19.679260: done, saving took 1.19 seconds\n",
      "2021-11-10 21:44:19.720170: This epoch took 316.541745 s\n",
      "\n",
      "2021-11-10 21:44:19.724885: \n",
      "epoch:  32\n",
      "2021-11-10 21:49:19.574131: train loss : -0.8367\n",
      "2021-11-10 21:49:40.785046: validation loss: -0.8339\n",
      "2021-11-10 21:49:40.804282: Average global foreground Dice: [0.8574]\n",
      "2021-11-10 21:49:40.808793: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 21:49:42.318986: lr: 0.006974\n",
      "2021-11-10 21:49:42.379520: saving checkpoint...\n",
      "2021-11-10 21:49:43.674027: done, saving took 1.35 seconds\n",
      "2021-11-10 21:49:43.725738: This epoch took 323.996672 s\n",
      "\n",
      "2021-11-10 21:49:43.730783: \n",
      "epoch:  33\n",
      "2021-11-10 21:54:43.985482: train loss : -0.8328\n",
      "2021-11-10 21:55:06.464753: validation loss: -0.8311\n",
      "2021-11-10 21:55:06.479349: Average global foreground Dice: [0.8489]\n",
      "2021-11-10 21:55:06.484345: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 21:55:08.660450: lr: 0.00688\n",
      "2021-11-10 21:55:08.709776: saving checkpoint...\n",
      "2021-11-10 21:55:11.039179: done, saving took 2.37 seconds\n",
      "2021-11-10 21:55:11.092819: This epoch took 327.352939 s\n",
      "\n",
      "2021-11-10 21:55:11.097873: \n",
      "epoch:  34\n",
      "2021-11-10 22:00:11.996022: train loss : -0.8363\n",
      "2021-11-10 22:00:33.306281: validation loss: -0.8325\n",
      "2021-11-10 22:00:33.324433: Average global foreground Dice: [0.8522]\n",
      "2021-11-10 22:00:33.328533: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 22:00:34.912104: lr: 0.006786\n",
      "2021-11-10 22:00:34.949626: saving checkpoint...\n",
      "2021-11-10 22:00:36.154195: done, saving took 1.24 seconds\n",
      "2021-11-10 22:00:36.190787: This epoch took 325.088583 s\n",
      "\n",
      "2021-11-10 22:00:36.195446: \n",
      "epoch:  35\n",
      "2021-11-10 22:05:35.885589: train loss : -0.8400\n",
      "2021-11-10 22:05:56.997607: validation loss: -0.8208\n",
      "2021-11-10 22:05:57.003572: Average global foreground Dice: [0.8446]\n",
      "2021-11-10 22:05:57.008528: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 22:05:58.503574: lr: 0.006692\n",
      "2021-11-10 22:05:58.541317: saving checkpoint...\n",
      "2021-11-10 22:05:59.810477: done, saving took 1.30 seconds\n",
      "2021-11-10 22:05:59.853727: This epoch took 323.653585 s\n",
      "\n",
      "2021-11-10 22:05:59.858809: \n",
      "epoch:  36\n",
      "2021-11-10 22:10:59.264289: train loss : -0.8407\n",
      "2021-11-10 22:11:19.947925: validation loss: -0.8424\n",
      "2021-11-10 22:11:19.954711: Average global foreground Dice: [0.8592]\n",
      "2021-11-10 22:11:19.959443: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 22:11:20.525832: lr: 0.006598\n",
      "2021-11-10 22:11:20.590459: saving checkpoint...\n",
      "2021-11-10 22:11:21.714478: done, saving took 1.18 seconds\n",
      "2021-11-10 22:11:21.753450: This epoch took 321.889610 s\n",
      "\n",
      "2021-11-10 22:11:21.758044: \n",
      "epoch:  37\n",
      "2021-11-10 22:16:20.895922: train loss : -0.8428\n",
      "2021-11-10 22:16:41.571608: validation loss: -0.8404\n",
      "2021-11-10 22:16:41.576682: Average global foreground Dice: [0.859]\n",
      "2021-11-10 22:16:41.581954: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 22:16:42.151677: lr: 0.006504\n",
      "2021-11-10 22:16:42.209017: saving checkpoint...\n",
      "2021-11-10 22:16:43.351108: done, saving took 1.19 seconds\n",
      "2021-11-10 22:16:43.391218: This epoch took 321.628463 s\n",
      "\n",
      "2021-11-10 22:16:43.395442: \n",
      "epoch:  38\n",
      "2021-11-10 22:21:44.998360: train loss : -0.8403\n",
      "2021-11-10 22:22:04.190676: validation loss: -0.8357\n",
      "2021-11-10 22:22:04.195550: Average global foreground Dice: [0.8537]\n",
      "2021-11-10 22:22:04.200946: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 22:22:04.734967: lr: 0.006409\n",
      "2021-11-10 22:22:04.793465: saving checkpoint...\n",
      "2021-11-10 22:22:05.963974: done, saving took 1.22 seconds\n",
      "2021-11-10 22:22:06.018063: This epoch took 322.618298 s\n",
      "\n",
      "2021-11-10 22:22:06.024595: \n",
      "epoch:  39\n",
      "2021-11-10 22:27:05.128594: train loss : -0.8429\n",
      "2021-11-10 22:27:26.721219: validation loss: -0.8275\n",
      "2021-11-10 22:27:26.726802: Average global foreground Dice: [0.8403]\n",
      "2021-11-10 22:27:26.759555: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 22:27:28.403264: lr: 0.006314\n",
      "2021-11-10 22:27:28.407685: This epoch took 322.376793 s\n",
      "\n",
      "2021-11-10 22:27:28.412017: \n",
      "epoch:  40\n",
      "2021-11-10 22:32:27.072974: train loss : -0.8414\n",
      "2021-11-10 22:32:47.051595: validation loss: -0.8361\n",
      "2021-11-10 22:32:47.056305: Average global foreground Dice: [0.8509]\n",
      "2021-11-10 22:32:47.060459: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 22:32:47.626424: lr: 0.00622\n",
      "2021-11-10 22:32:47.631804: This epoch took 319.214892 s\n",
      "\n",
      "2021-11-10 22:32:47.638258: \n",
      "epoch:  41\n",
      "2021-11-10 22:37:47.785469: train loss : -0.8459\n",
      "2021-11-10 22:38:09.582828: validation loss: -0.8309\n",
      "2021-11-10 22:38:09.601648: Average global foreground Dice: [0.8458]\n",
      "2021-11-10 22:38:09.606799: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 22:38:11.774608: lr: 0.006125\n",
      "2021-11-10 22:38:11.780044: This epoch took 324.137344 s\n",
      "\n",
      "2021-11-10 22:38:11.783750: \n",
      "epoch:  42\n",
      "2021-11-10 22:43:07.773094: train loss : -0.8475\n",
      "2021-11-10 22:43:30.290466: validation loss: -0.8312\n",
      "2021-11-10 22:43:30.304304: Average global foreground Dice: [0.8475]\n",
      "2021-11-10 22:43:30.312270: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 22:43:32.504911: lr: 0.00603\n",
      "2021-11-10 22:43:32.676041: saving checkpoint...\n",
      "2021-11-10 22:43:34.286333: done, saving took 1.78 seconds\n",
      "2021-11-10 22:43:34.323857: This epoch took 322.535443 s\n",
      "\n",
      "2021-11-10 22:43:34.329267: \n",
      "epoch:  43\n",
      "2021-11-10 22:48:36.333528: train loss : -0.8394\n",
      "2021-11-10 22:48:57.628645: validation loss: -0.8473\n",
      "2021-11-10 22:48:57.634652: Average global foreground Dice: [0.8624]\n",
      "2021-11-10 22:48:57.638763: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 22:48:58.165503: lr: 0.005934\n",
      "2021-11-10 22:48:58.231268: saving checkpoint...\n",
      "2021-11-10 22:48:59.326887: done, saving took 1.16 seconds\n",
      "2021-11-10 22:48:59.364436: This epoch took 325.023546 s\n",
      "\n",
      "2021-11-10 22:48:59.369087: \n",
      "epoch:  44\n",
      "2021-11-10 22:53:57.921474: train loss : -0.8450\n",
      "2021-11-10 22:54:19.689101: validation loss: -0.8268\n",
      "2021-11-10 22:54:19.694514: Average global foreground Dice: [0.8458]\n",
      "2021-11-10 22:54:19.699301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 22:54:20.610497: lr: 0.005839\n",
      "2021-11-10 22:54:20.615536: This epoch took 321.241921 s\n",
      "\n",
      "2021-11-10 22:54:20.620752: \n",
      "epoch:  45\n",
      "2021-11-10 22:59:21.401592: train loss : -0.8454\n",
      "2021-11-10 22:59:43.308362: validation loss: -0.8291\n",
      "2021-11-10 22:59:43.324155: Average global foreground Dice: [0.8482]\n",
      "2021-11-10 22:59:43.329033: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 22:59:44.941705: lr: 0.005743\n",
      "2021-11-10 22:59:44.946625: This epoch took 324.320450 s\n",
      "\n",
      "2021-11-10 22:59:44.951251: \n",
      "epoch:  46\n",
      "2021-11-10 23:04:40.404479: train loss : -0.8494\n",
      "2021-11-10 23:04:58.554049: validation loss: -0.8291\n",
      "2021-11-10 23:04:58.559106: Average global foreground Dice: [0.849]\n",
      "2021-11-10 23:04:58.563636: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 23:04:59.089889: lr: 0.005647\n",
      "2021-11-10 23:04:59.095037: This epoch took 314.139608 s\n",
      "\n",
      "2021-11-10 23:04:59.099816: \n",
      "epoch:  47\n",
      "2021-11-10 23:09:57.577392: train loss : -0.8424\n",
      "2021-11-10 23:10:17.618846: validation loss: -0.8151\n",
      "2021-11-10 23:10:17.625356: Average global foreground Dice: [0.8346]\n",
      "2021-11-10 23:10:17.631831: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 23:10:18.132650: lr: 0.005551\n",
      "2021-11-10 23:10:18.136537: This epoch took 319.032433 s\n",
      "\n",
      "2021-11-10 23:10:18.140110: \n",
      "epoch:  48\n",
      "2021-11-10 23:15:18.580691: train loss : -0.8470\n",
      "2021-11-10 23:15:37.722735: validation loss: -0.8407\n",
      "2021-11-10 23:15:37.728778: Average global foreground Dice: [0.8587]\n",
      "2021-11-10 23:15:37.733294: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 23:15:38.237260: lr: 0.005455\n",
      "2021-11-10 23:15:38.240980: This epoch took 320.095722 s\n",
      "\n",
      "2021-11-10 23:15:38.245709: \n",
      "epoch:  49\n",
      "2021-11-10 23:20:38.294777: train loss : -0.8444\n",
      "2021-11-10 23:21:00.165172: validation loss: -0.8271\n",
      "2021-11-10 23:21:00.186474: Average global foreground Dice: [0.8454]\n",
      "2021-11-10 23:21:00.192024: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 23:21:02.390809: lr: 0.005359\n",
      "2021-11-10 23:21:02.395476: saving scheduled checkpoint file...\n",
      "2021-11-10 23:21:02.507859: saving checkpoint...\n",
      "2021-11-10 23:21:03.659650: done, saving took 1.26 seconds\n",
      "2021-11-10 23:21:03.689153: done\n",
      "2021-11-10 23:21:03.693538: This epoch took 325.443817 s\n",
      "\n",
      "2021-11-10 23:21:03.698102: \n",
      "epoch:  50\n",
      "2021-11-10 23:26:04.985783: train loss : -0.8523\n",
      "2021-11-10 23:26:23.673669: validation loss: -0.8397\n",
      "2021-11-10 23:26:23.680573: Average global foreground Dice: [0.8529]\n",
      "2021-11-10 23:26:23.684963: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 23:26:24.189163: lr: 0.005262\n",
      "2021-11-10 23:26:24.254373: saving checkpoint...\n",
      "2021-11-10 23:26:25.394585: done, saving took 1.20 seconds\n",
      "2021-11-10 23:26:25.445832: This epoch took 321.743318 s\n",
      "\n",
      "2021-11-10 23:26:25.450482: \n",
      "epoch:  51\n",
      "2021-11-10 23:31:22.580572: train loss : -0.8521\n",
      "2021-11-10 23:31:42.739067: validation loss: -0.8347\n",
      "2021-11-10 23:31:42.744239: Average global foreground Dice: [0.8531]\n",
      "2021-11-10 23:31:42.749302: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 23:31:43.297685: lr: 0.005166\n",
      "2021-11-10 23:31:43.330581: saving checkpoint...\n",
      "2021-11-10 23:31:44.384338: done, saving took 1.08 seconds\n",
      "2021-11-10 23:31:44.424218: This epoch took 318.969042 s\n",
      "\n",
      "2021-11-10 23:31:44.428288: \n",
      "epoch:  52\n",
      "2021-11-10 23:36:45.875960: train loss : -0.8501\n",
      "2021-11-10 23:37:06.936051: validation loss: -0.8387\n",
      "2021-11-10 23:37:06.941356: Average global foreground Dice: [0.8525]\n",
      "2021-11-10 23:37:06.945192: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 23:37:07.623894: lr: 0.005069\n",
      "2021-11-10 23:37:07.709902: saving checkpoint...\n",
      "2021-11-10 23:37:08.718552: done, saving took 1.09 seconds\n",
      "2021-11-10 23:37:08.741266: This epoch took 324.308594 s\n",
      "\n",
      "2021-11-10 23:37:08.747016: \n",
      "epoch:  53\n",
      "2021-11-10 23:42:09.101255: train loss : -0.8473\n",
      "2021-11-10 23:42:32.061242: validation loss: -0.8372\n",
      "2021-11-10 23:42:32.071384: Average global foreground Dice: [0.8584]\n",
      "2021-11-10 23:42:32.076993: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 23:42:34.262731: lr: 0.004971\n",
      "2021-11-10 23:42:34.382553: saving checkpoint...\n",
      "2021-11-10 23:42:35.575470: done, saving took 1.31 seconds\n",
      "2021-11-10 23:42:35.619929: This epoch took 326.865366 s\n",
      "\n",
      "2021-11-10 23:42:35.629245: \n",
      "epoch:  54\n",
      "2021-11-10 23:47:33.789227: train loss : -0.8515\n",
      "2021-11-10 23:47:53.990440: validation loss: -0.8406\n",
      "2021-11-10 23:47:53.996626: Average global foreground Dice: [0.8544]\n",
      "2021-11-10 23:47:54.000915: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 23:47:54.549184: lr: 0.004874\n",
      "2021-11-10 23:47:54.615629: saving checkpoint...\n",
      "2021-11-10 23:47:55.703026: done, saving took 1.15 seconds\n",
      "2021-11-10 23:47:55.729721: This epoch took 320.095538 s\n",
      "\n",
      "2021-11-10 23:47:55.734633: \n",
      "epoch:  55\n",
      "2021-11-10 23:52:53.921258: train loss : -0.8529\n",
      "2021-11-10 23:53:14.344096: validation loss: -0.8385\n",
      "2021-11-10 23:53:14.349289: Average global foreground Dice: [0.8552]\n",
      "2021-11-10 23:53:14.353333: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 23:53:14.911106: lr: 0.004776\n",
      "2021-11-10 23:53:14.944556: saving checkpoint...\n",
      "2021-11-10 23:53:16.036307: done, saving took 1.12 seconds\n",
      "2021-11-10 23:53:16.069091: This epoch took 320.330218 s\n",
      "\n",
      "2021-11-10 23:53:16.073180: \n",
      "epoch:  56\n",
      "2021-11-10 23:58:18.981624: train loss : -0.8545\n",
      "2021-11-10 23:58:40.586286: validation loss: -0.8412\n",
      "2021-11-10 23:58:40.604520: Average global foreground Dice: [0.8553]\n",
      "2021-11-10 23:58:40.609387: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-10 23:58:42.731166: lr: 0.004679\n",
      "2021-11-10 23:58:42.817501: saving checkpoint...\n",
      "2021-11-10 23:58:44.470675: done, saving took 1.71 seconds\n",
      "2021-11-10 23:58:44.506447: This epoch took 328.428398 s\n",
      "\n",
      "2021-11-10 23:58:44.511388: \n",
      "epoch:  57\n",
      "2021-11-11 00:03:49.678110: train loss : -0.8568\n",
      "2021-11-11 00:04:09.693663: validation loss: -0.8413\n",
      "2021-11-11 00:04:09.717552: Average global foreground Dice: [0.8559]\n",
      "2021-11-11 00:04:09.722390: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 00:04:11.293225: lr: 0.004581\n",
      "2021-11-11 00:04:11.331499: saving checkpoint...\n",
      "2021-11-11 00:04:12.554290: done, saving took 1.25 seconds\n",
      "2021-11-11 00:04:12.580703: This epoch took 328.064963 s\n",
      "\n",
      "2021-11-11 00:04:12.584895: \n",
      "epoch:  58\n",
      "2021-11-11 00:09:16.493122: train loss : -0.8555\n",
      "2021-11-11 00:09:38.890348: validation loss: -0.8415\n",
      "2021-11-11 00:09:38.908298: Average global foreground Dice: [0.8592]\n",
      "2021-11-11 00:09:38.913175: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 00:09:40.430265: lr: 0.004482\n",
      "2021-11-11 00:09:40.525392: saving checkpoint...\n",
      "2021-11-11 00:09:42.490739: done, saving took 2.03 seconds\n",
      "2021-11-11 00:09:42.525349: This epoch took 329.936167 s\n",
      "\n",
      "2021-11-11 00:09:42.530057: \n",
      "epoch:  59\n",
      "2021-11-11 00:14:45.091164: train loss : -0.8549\n",
      "2021-11-11 00:15:06.394283: validation loss: -0.8384\n",
      "2021-11-11 00:15:06.413703: Average global foreground Dice: [0.8491]\n",
      "2021-11-11 00:15:06.421458: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 00:15:07.402703: lr: 0.004384\n",
      "2021-11-11 00:15:07.407488: This epoch took 324.847949 s\n",
      "\n",
      "2021-11-11 00:15:07.412440: \n",
      "epoch:  60\n",
      "2021-11-11 00:20:07.685777: train loss : -0.8560\n",
      "2021-11-11 00:20:30.034250: validation loss: -0.8381\n",
      "2021-11-11 00:20:30.079261: Average global foreground Dice: [0.8526]\n",
      "2021-11-11 00:20:30.084273: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 00:20:32.107864: lr: 0.004285\n",
      "2021-11-11 00:20:32.112497: This epoch took 324.695004 s\n",
      "\n",
      "2021-11-11 00:20:32.117076: \n",
      "epoch:  61\n",
      "2021-11-11 00:25:28.409766: train loss : -0.8555\n",
      "2021-11-11 00:25:47.614507: validation loss: -0.8376\n",
      "2021-11-11 00:25:47.619625: Average global foreground Dice: [0.853]\n",
      "2021-11-11 00:25:47.624525: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 00:25:48.180429: lr: 0.004186\n",
      "2021-11-11 00:25:48.184725: This epoch took 316.062190 s\n",
      "\n",
      "2021-11-11 00:25:48.189338: \n",
      "epoch:  62\n",
      "2021-11-11 00:30:48.896668: train loss : -0.8579\n",
      "2021-11-11 00:31:10.526789: validation loss: -0.8295\n",
      "2021-11-11 00:31:10.564698: Average global foreground Dice: [0.8408]\n",
      "2021-11-11 00:31:10.568707: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 00:31:12.570299: lr: 0.004087\n",
      "2021-11-11 00:31:12.578069: This epoch took 324.384326 s\n",
      "\n",
      "2021-11-11 00:31:12.585060: \n",
      "epoch:  63\n",
      "2021-11-11 00:36:05.904147: train loss : -0.8568\n",
      "2021-11-11 00:36:26.129510: validation loss: -0.8327\n",
      "2021-11-11 00:36:26.134985: Average global foreground Dice: [0.848]\n",
      "2021-11-11 00:36:26.140184: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 00:36:26.662690: lr: 0.003987\n",
      "2021-11-11 00:36:26.666916: This epoch took 314.076495 s\n",
      "\n",
      "2021-11-11 00:36:26.671491: \n",
      "epoch:  64\n",
      "2021-11-11 00:41:18.561929: train loss : -0.8593\n",
      "2021-11-11 00:41:36.540376: validation loss: -0.8394\n",
      "2021-11-11 00:41:36.545227: Average global foreground Dice: [0.8528]\n",
      "2021-11-11 00:41:36.549700: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 00:41:37.103610: lr: 0.003887\n",
      "2021-11-11 00:41:37.108445: This epoch took 310.432812 s\n",
      "\n",
      "2021-11-11 00:41:37.112585: \n",
      "epoch:  65\n",
      "2021-11-11 00:46:34.673078: train loss : -0.8572\n",
      "2021-11-11 00:46:55.826913: validation loss: -0.8399\n",
      "2021-11-11 00:46:55.832673: Average global foreground Dice: [0.8508]\n",
      "2021-11-11 00:46:55.837375: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 00:46:56.631510: lr: 0.003787\n",
      "2021-11-11 00:46:56.635431: This epoch took 319.518354 s\n",
      "\n",
      "2021-11-11 00:46:56.639219: \n",
      "epoch:  66\n",
      "2021-11-11 00:51:56.105044: train loss : -0.8611\n",
      "2021-11-11 00:52:15.926057: validation loss: -0.8503\n",
      "2021-11-11 00:52:15.931538: Average global foreground Dice: [0.8621]\n",
      "2021-11-11 00:52:15.935749: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 00:52:16.470652: lr: 0.003687\n",
      "2021-11-11 00:52:16.475317: This epoch took 319.831587 s\n",
      "\n",
      "2021-11-11 00:52:16.479083: \n",
      "epoch:  67\n",
      "2021-11-11 00:57:18.214033: train loss : -0.8549\n",
      "2021-11-11 00:57:39.712850: validation loss: -0.8460\n",
      "2021-11-11 00:57:39.764111: Average global foreground Dice: [0.8591]\n",
      "2021-11-11 00:57:39.768027: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 00:57:41.206803: lr: 0.003586\n",
      "2021-11-11 00:57:41.303602: saving checkpoint...\n",
      "2021-11-11 00:57:42.510270: done, saving took 1.30 seconds\n",
      "2021-11-11 00:57:42.551930: This epoch took 326.067734 s\n",
      "\n",
      "2021-11-11 00:57:42.556999: \n",
      "epoch:  68\n",
      "2021-11-11 01:02:42.700387: train loss : -0.8585\n",
      "2021-11-11 01:03:04.013022: validation loss: -0.8461\n",
      "2021-11-11 01:03:04.018813: Average global foreground Dice: [0.8602]\n",
      "2021-11-11 01:03:04.023465: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 01:03:04.694789: lr: 0.003485\n",
      "2021-11-11 01:03:04.764293: saving checkpoint...\n",
      "2021-11-11 01:03:05.931602: done, saving took 1.23 seconds\n",
      "2021-11-11 01:03:05.972957: This epoch took 323.411802 s\n",
      "\n",
      "2021-11-11 01:03:05.977474: \n",
      "epoch:  69\n",
      "2021-11-11 01:08:27.495454: train loss : -0.8533\n",
      "2021-11-11 01:08:48.998542: validation loss: -0.8426\n",
      "2021-11-11 01:08:49.021298: Average global foreground Dice: [0.8603]\n",
      "2021-11-11 01:08:49.028537: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 01:08:50.802578: lr: 0.003384\n",
      "2021-11-11 01:08:50.839140: saving checkpoint...\n",
      "2021-11-11 01:08:52.080664: done, saving took 1.27 seconds\n",
      "2021-11-11 01:08:52.118436: This epoch took 346.137348 s\n",
      "\n",
      "2021-11-11 01:08:52.123214: \n",
      "epoch:  70\n",
      "2021-11-11 01:13:51.389499: train loss : -0.8584\n",
      "2021-11-11 01:14:13.013217: validation loss: -0.8338\n",
      "2021-11-11 01:14:13.018889: Average global foreground Dice: [0.8483]\n",
      "2021-11-11 01:14:13.023448: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 01:14:13.681184: lr: 0.003282\n",
      "2021-11-11 01:14:13.686250: This epoch took 321.559018 s\n",
      "\n",
      "2021-11-11 01:14:13.691025: \n",
      "epoch:  71\n",
      "2021-11-11 01:19:14.665513: train loss : -0.8621\n",
      "2021-11-11 01:19:37.625444: validation loss: -0.8372\n",
      "2021-11-11 01:19:37.630512: Average global foreground Dice: [0.8508]\n",
      "2021-11-11 01:19:37.663415: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 01:19:39.475852: lr: 0.00318\n",
      "2021-11-11 01:19:39.483651: This epoch took 325.788385 s\n",
      "\n",
      "2021-11-11 01:19:39.488697: \n",
      "epoch:  72\n",
      "2021-11-11 01:24:43.009663: train loss : -0.8638\n",
      "2021-11-11 01:25:06.024111: validation loss: -0.8382\n",
      "2021-11-11 01:25:06.030272: Average global foreground Dice: [0.8515]\n",
      "2021-11-11 01:25:06.059598: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 01:25:08.598032: lr: 0.003078\n",
      "2021-11-11 01:25:08.602644: This epoch took 329.107827 s\n",
      "\n",
      "2021-11-11 01:25:08.607987: \n",
      "epoch:  73\n",
      "2021-11-11 01:30:12.084945: train loss : -0.8614\n",
      "2021-11-11 01:30:32.775359: validation loss: -0.8428\n",
      "2021-11-11 01:30:32.780712: Average global foreground Dice: [0.8577]\n",
      "2021-11-11 01:30:32.784852: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 01:30:33.517968: lr: 0.002975\n",
      "2021-11-11 01:30:33.522547: This epoch took 324.909698 s\n",
      "\n",
      "2021-11-11 01:30:33.527143: \n",
      "epoch:  74\n",
      "2021-11-11 01:35:36.629015: train loss : -0.8624\n",
      "2021-11-11 01:35:58.603712: validation loss: -0.8315\n",
      "2021-11-11 01:35:58.609333: Average global foreground Dice: [0.8466]\n",
      "2021-11-11 01:35:58.614008: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 01:35:59.416494: lr: 0.002872\n",
      "2021-11-11 01:35:59.425678: This epoch took 325.894311 s\n",
      "\n",
      "2021-11-11 01:35:59.433140: \n",
      "epoch:  75\n",
      "2021-11-11 01:41:07.173692: train loss : -0.8606\n",
      "2021-11-11 01:41:29.124681: validation loss: -0.8325\n",
      "2021-11-11 01:41:29.160267: Average global foreground Dice: [0.8522]\n",
      "2021-11-11 01:41:29.164372: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 01:41:31.670641: lr: 0.002768\n",
      "2021-11-11 01:41:31.675990: This epoch took 332.235161 s\n",
      "\n",
      "2021-11-11 01:41:31.683310: \n",
      "epoch:  76\n",
      "2021-11-11 01:46:33.421902: train loss : -0.8633\n",
      "2021-11-11 01:46:54.581347: validation loss: -0.8368\n",
      "2021-11-11 01:46:54.587008: Average global foreground Dice: [0.8502]\n",
      "2021-11-11 01:46:54.591166: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 01:46:55.184839: lr: 0.002664\n",
      "2021-11-11 01:46:55.189152: This epoch took 323.498535 s\n",
      "\n",
      "2021-11-11 01:46:55.193664: \n",
      "epoch:  77\n",
      "2021-11-11 01:51:58.485044: train loss : -0.8625\n",
      "2021-11-11 01:52:20.369696: validation loss: -0.8357\n",
      "2021-11-11 01:52:20.395662: Average global foreground Dice: [0.8513]\n",
      "2021-11-11 01:52:20.400300: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 01:52:22.662231: lr: 0.00256\n",
      "2021-11-11 01:52:22.666796: This epoch took 327.469106 s\n",
      "\n",
      "2021-11-11 01:52:22.671206: \n",
      "epoch:  78\n",
      "2021-11-11 01:57:23.577044: train loss : -0.8596\n",
      "2021-11-11 01:57:43.686153: validation loss: -0.8403\n",
      "2021-11-11 01:57:43.691520: Average global foreground Dice: [0.8556]\n",
      "2021-11-11 01:57:43.695886: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 01:57:44.212374: lr: 0.002455\n",
      "2021-11-11 01:57:44.217291: This epoch took 321.541079 s\n",
      "\n",
      "2021-11-11 01:57:44.221975: \n",
      "epoch:  79\n",
      "2021-11-11 02:02:45.980518: train loss : -0.8643\n",
      "2021-11-11 02:03:06.745477: validation loss: -0.8536\n",
      "2021-11-11 02:03:06.750705: Average global foreground Dice: [0.8661]\n",
      "2021-11-11 02:03:06.755466: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 02:03:07.287570: lr: 0.002349\n",
      "2021-11-11 02:03:07.291805: This epoch took 323.065195 s\n",
      "\n",
      "2021-11-11 02:03:07.296475: \n",
      "epoch:  80\n",
      "2021-11-11 02:08:07.717686: train loss : -0.8652\n",
      "2021-11-11 02:08:29.959337: validation loss: -0.8348\n",
      "2021-11-11 02:08:29.965625: Average global foreground Dice: [0.8491]\n",
      "2021-11-11 02:08:29.969919: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 02:08:31.960342: lr: 0.002243\n",
      "2021-11-11 02:08:31.965362: This epoch took 324.664878 s\n",
      "\n",
      "2021-11-11 02:08:31.970005: \n",
      "epoch:  81\n",
      "2021-11-11 02:13:29.705659: train loss : -0.8674\n",
      "2021-11-11 02:13:50.842589: validation loss: -0.8488\n",
      "2021-11-11 02:13:50.848090: Average global foreground Dice: [0.8608]\n",
      "2021-11-11 02:13:50.852587: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 02:13:51.499016: lr: 0.002137\n",
      "2021-11-11 02:13:51.565297: saving checkpoint...\n",
      "2021-11-11 02:13:52.678891: done, saving took 1.18 seconds\n",
      "2021-11-11 02:13:52.734303: This epoch took 320.760349 s\n",
      "\n",
      "2021-11-11 02:13:52.740145: \n",
      "epoch:  82\n",
      "2021-11-11 02:18:55.505783: train loss : -0.8665\n",
      "2021-11-11 02:19:18.289906: validation loss: -0.8419\n",
      "2021-11-11 02:19:18.308335: Average global foreground Dice: [0.8549]\n",
      "2021-11-11 02:19:18.317163: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 02:19:20.660420: lr: 0.00203\n",
      "2021-11-11 02:19:20.815663: saving checkpoint...\n",
      "2021-11-11 02:19:22.728022: done, saving took 2.06 seconds\n",
      "2021-11-11 02:19:22.778093: This epoch took 330.032918 s\n",
      "\n",
      "2021-11-11 02:19:22.784938: \n",
      "epoch:  83\n",
      "2021-11-11 02:24:21.979539: train loss : -0.8683\n",
      "2021-11-11 02:24:42.561038: validation loss: -0.8330\n",
      "2021-11-11 02:24:42.566326: Average global foreground Dice: [0.8506]\n",
      "2021-11-11 02:24:42.571205: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 02:24:43.086134: lr: 0.001922\n",
      "2021-11-11 02:24:43.091051: This epoch took 320.301299 s\n",
      "\n",
      "2021-11-11 02:24:43.096293: \n",
      "epoch:  84\n",
      "2021-11-11 02:29:42.972911: train loss : -0.8682\n",
      "2021-11-11 02:30:02.621952: validation loss: -0.8414\n",
      "2021-11-11 02:30:02.628528: Average global foreground Dice: [0.8564]\n",
      "2021-11-11 02:30:02.632571: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 02:30:03.178582: lr: 0.001813\n",
      "2021-11-11 02:30:03.182928: This epoch took 320.080340 s\n",
      "\n",
      "2021-11-11 02:30:03.188170: \n",
      "epoch:  85\n",
      "2021-11-11 02:35:03.672693: train loss : -0.8672\n",
      "2021-11-11 02:35:25.459292: validation loss: -0.8444\n",
      "2021-11-11 02:35:25.467336: Average global foreground Dice: [0.8565]\n",
      "2021-11-11 02:35:25.474692: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 02:35:27.320321: lr: 0.001704\n",
      "2021-11-11 02:35:27.476274: saving checkpoint...\n",
      "2021-11-11 02:35:28.907659: done, saving took 1.58 seconds\n",
      "2021-11-11 02:35:28.952296: This epoch took 325.760367 s\n",
      "\n",
      "2021-11-11 02:35:28.956702: \n",
      "epoch:  86\n",
      "2021-11-11 02:40:29.097660: train loss : -0.8696\n",
      "2021-11-11 02:40:51.299693: validation loss: -0.8431\n",
      "2021-11-11 02:40:51.305516: Average global foreground Dice: [0.8538]\n",
      "2021-11-11 02:40:51.310199: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 02:40:53.619662: lr: 0.001594\n",
      "2021-11-11 02:40:53.624091: This epoch took 324.663203 s\n",
      "\n",
      "2021-11-11 02:40:53.628494: \n",
      "epoch:  87\n",
      "2021-11-11 02:45:58.395520: train loss : -0.8683\n",
      "2021-11-11 02:46:19.481953: validation loss: -0.8415\n",
      "2021-11-11 02:46:19.487087: Average global foreground Dice: [0.8593]\n",
      "2021-11-11 02:46:19.490915: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 02:46:20.064943: lr: 0.001483\n",
      "2021-11-11 02:46:20.130543: saving checkpoint...\n",
      "2021-11-11 02:46:21.203169: done, saving took 1.13 seconds\n",
      "2021-11-11 02:46:21.239949: This epoch took 327.580129 s\n",
      "\n",
      "2021-11-11 02:46:21.244977: \n",
      "epoch:  88\n",
      "2021-11-11 02:51:23.568958: train loss : -0.8698\n",
      "2021-11-11 02:51:43.127869: validation loss: -0.8401\n",
      "2021-11-11 02:51:43.134406: Average global foreground Dice: [0.8545]\n",
      "2021-11-11 02:51:43.139502: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 02:51:43.660794: lr: 0.001372\n",
      "2021-11-11 02:51:43.665427: This epoch took 322.415389 s\n",
      "\n",
      "2021-11-11 02:51:43.670158: \n",
      "epoch:  89\n",
      "2021-11-11 02:56:50.118058: train loss : -0.8687\n",
      "2021-11-11 02:57:12.087904: validation loss: -0.8415\n",
      "2021-11-11 02:57:12.092813: Average global foreground Dice: [0.8544]\n",
      "2021-11-11 02:57:12.096722: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 02:57:14.507533: lr: 0.001259\n",
      "2021-11-11 02:57:14.516626: This epoch took 330.841757 s\n",
      "\n",
      "2021-11-11 02:57:14.521204: \n",
      "epoch:  90\n",
      "2021-11-11 03:02:17.105014: train loss : -0.8706\n",
      "2021-11-11 03:02:39.228884: validation loss: -0.8460\n",
      "2021-11-11 03:02:39.264843: Average global foreground Dice: [0.8611]\n",
      "2021-11-11 03:02:39.270109: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 03:02:41.546211: lr: 0.001145\n",
      "2021-11-11 03:02:41.637154: saving checkpoint...\n",
      "2021-11-11 03:02:42.915433: done, saving took 1.35 seconds\n",
      "2021-11-11 03:02:42.950719: This epoch took 328.425217 s\n",
      "\n",
      "2021-11-11 03:02:42.954766: \n",
      "epoch:  91\n",
      "2021-11-11 03:07:40.402391: train loss : -0.8711\n",
      "2021-11-11 03:08:01.992034: validation loss: -0.8417\n",
      "2021-11-11 03:08:02.000330: Average global foreground Dice: [0.8563]\n",
      "2021-11-11 03:08:02.007954: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 03:08:02.616927: lr: 0.00103\n",
      "2021-11-11 03:08:02.650861: saving checkpoint...\n",
      "2021-11-11 03:08:03.760038: done, saving took 1.14 seconds\n",
      "2021-11-11 03:08:03.793663: This epoch took 320.833956 s\n",
      "\n",
      "2021-11-11 03:08:03.798481: \n",
      "epoch:  92\n",
      "2021-11-11 03:13:03.803377: train loss : -0.8703\n",
      "2021-11-11 03:13:26.199957: validation loss: -0.8416\n",
      "2021-11-11 03:13:26.206126: Average global foreground Dice: [0.8577]\n",
      "2021-11-11 03:13:26.211286: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 03:13:27.662352: lr: 0.000913\n",
      "2021-11-11 03:13:27.712601: saving checkpoint...\n",
      "2021-11-11 03:13:29.147303: done, saving took 1.48 seconds\n",
      "2021-11-11 03:13:29.178328: This epoch took 325.375157 s\n",
      "\n",
      "2021-11-11 03:13:29.183495: \n",
      "epoch:  93\n",
      "2021-11-11 03:18:28.184976: train loss : -0.8688\n",
      "2021-11-11 03:18:49.472447: validation loss: -0.8458\n",
      "2021-11-11 03:18:49.483941: Average global foreground Dice: [0.8616]\n",
      "2021-11-11 03:18:49.488623: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 03:18:50.712787: lr: 0.000795\n",
      "2021-11-11 03:18:50.746744: saving checkpoint...\n",
      "2021-11-11 03:18:51.802429: done, saving took 1.08 seconds\n",
      "2021-11-11 03:18:51.827482: This epoch took 322.638491 s\n",
      "\n",
      "2021-11-11 03:18:51.833147: \n",
      "epoch:  94\n",
      "2021-11-11 03:23:51.898074: train loss : -0.8693\n",
      "2021-11-11 03:24:13.184878: validation loss: -0.8411\n",
      "2021-11-11 03:24:13.213978: Average global foreground Dice: [0.855]\n",
      "2021-11-11 03:24:13.220320: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 03:24:15.760786: lr: 0.000675\n",
      "2021-11-11 03:24:15.765584: This epoch took 323.928041 s\n",
      "\n",
      "2021-11-11 03:24:15.769737: \n",
      "epoch:  95\n",
      "2021-11-11 03:29:13.989328: train loss : -0.8747\n",
      "2021-11-11 03:29:34.823150: validation loss: -0.8560\n",
      "2021-11-11 03:29:34.828432: Average global foreground Dice: [0.8691]\n",
      "2021-11-11 03:29:34.832836: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 03:29:35.355568: lr: 0.000552\n",
      "2021-11-11 03:29:35.389928: saving checkpoint...\n",
      "2021-11-11 03:29:36.469720: done, saving took 1.11 seconds\n",
      "2021-11-11 03:29:36.495816: This epoch took 320.721041 s\n",
      "\n",
      "2021-11-11 03:29:36.500879: \n",
      "epoch:  96\n",
      "2021-11-11 03:34:38.896892: train loss : -0.8688\n",
      "2021-11-11 03:35:01.466042: validation loss: -0.8335\n",
      "2021-11-11 03:35:01.471823: Average global foreground Dice: [0.8489]\n",
      "2021-11-11 03:35:01.476581: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 03:35:03.720612: lr: 0.000426\n",
      "2021-11-11 03:35:03.724768: This epoch took 327.220210 s\n",
      "\n",
      "2021-11-11 03:35:03.729403: \n",
      "epoch:  97\n",
      "2021-11-11 03:40:05.118582: train loss : -0.8727\n",
      "2021-11-11 03:40:26.196227: validation loss: -0.8488\n",
      "2021-11-11 03:40:26.201515: Average global foreground Dice: [0.8613]\n",
      "2021-11-11 03:40:26.206282: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 03:40:26.743124: lr: 0.000296\n",
      "2021-11-11 03:40:26.749197: This epoch took 322.989624 s\n",
      "\n",
      "2021-11-11 03:40:26.753721: \n",
      "epoch:  98\n",
      "2021-11-11 03:45:23.348175: train loss : -0.8727\n",
      "2021-11-11 03:45:41.545614: validation loss: -0.8556\n",
      "2021-11-11 03:45:41.550929: Average global foreground Dice: [0.8695]\n",
      "2021-11-11 03:45:41.555325: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 03:45:42.185572: lr: 0.000158\n",
      "2021-11-11 03:45:42.221663: saving checkpoint...\n",
      "2021-11-11 03:45:43.306964: done, saving took 1.11 seconds\n",
      "2021-11-11 03:45:43.338049: This epoch took 316.580544 s\n",
      "\n",
      "2021-11-11 03:45:43.342302: \n",
      "epoch:  99\n",
      "2021-11-11 03:50:40.730278: train loss : -0.8728\n",
      "2021-11-11 03:51:01.764581: validation loss: -0.8472\n",
      "2021-11-11 03:51:01.769632: Average global foreground Dice: [0.8608]\n",
      "2021-11-11 03:51:01.776605: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 03:51:02.333603: lr: 0.0\n",
      "2021-11-11 03:51:02.338358: saving scheduled checkpoint file...\n",
      "2021-11-11 03:51:02.371017: saving checkpoint...\n",
      "2021-11-11 03:51:03.464599: done, saving took 1.12 seconds\n",
      "2021-11-11 03:51:03.507334: done\n",
      "2021-11-11 03:51:03.540503: saving checkpoint...\n",
      "2021-11-11 03:51:04.643324: done, saving took 1.13 seconds\n",
      "2021-11-11 03:51:04.673196: This epoch took 321.327323 s\n",
      "\n",
      "2021-11-11 03:51:04.706895: saving checkpoint...\n",
      "2021-11-11 03:51:05.540586: done, saving took 0.86 seconds\n",
      "23090558_20120330 (3, 263, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 263, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 7], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090564_20130312 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090568_20121018 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090569_20120607 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120613 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150908 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090593_20120625 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130103 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090600_20121108 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090603_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090607_20120420 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090609_20120510 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160119 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160510 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090646_20120718 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-11 03:54:29.917624: finished prediction\n",
      "2021-11-11 03:54:29.923599: evaluation of raw predictions\n",
      "2021-11-11 03:54:31.414841: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8547516698774074\n",
      "after:  0.8547516698774074\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Model 7 (epoch 100)\n",
    "\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_CEGDL 555 0\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_CEGDL 555 1\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_CEGDL 555 2\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_CEGDL 555 3\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_Loss_CEGDL 555 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-11 05:10:26.295338: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-11 05:10:26.309657: The split file contains 5 splits.\n",
      "2021-11-11 05:10:26.314455: Desired fold for training: 0\n",
      "2021-11-11 05:10:26.319017: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-11 05:10:37.513331: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-11 05:10:49.906997: Unable to plot network architecture:\n",
      "2021-11-11 05:10:49.911939: No module named 'hiddenlayer'\n",
      "2021-11-11 05:10:49.915942: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-11 05:10:49.921116: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-11 05:10:49.962393: \n",
      "\n",
      "2021-11-11 05:10:49.970658: \n",
      "epoch:  0\n",
      "2021-11-11 05:14:04.476293: train loss : -0.2121\n",
      "2021-11-11 05:14:18.779876: validation loss: -0.5536\n",
      "2021-11-11 05:14:18.784966: Average global foreground Dice: [0.729]\n",
      "2021-11-11 05:14:18.790572: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 05:14:19.458379: lr: 0.009549\n",
      "2021-11-11 05:14:19.462763: This epoch took 209.487647 s\n",
      "\n",
      "2021-11-11 05:14:19.466355: \n",
      "epoch:  1\n",
      "2021-11-11 05:17:25.933062: train loss : -0.6377\n",
      "2021-11-11 05:17:40.010856: validation loss: -0.7225\n",
      "2021-11-11 05:17:40.016821: Average global foreground Dice: [0.7981]\n",
      "2021-11-11 05:17:40.021569: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 05:17:40.651599: lr: 0.009095\n",
      "2021-11-11 05:17:40.685802: saving checkpoint...\n",
      "2021-11-11 05:17:41.212481: done, saving took 0.56 seconds\n",
      "2021-11-11 05:17:41.234047: This epoch took 201.763272 s\n",
      "\n",
      "2021-11-11 05:17:41.238066: \n",
      "epoch:  2\n",
      "2021-11-11 05:20:48.840443: train loss : -0.7490\n",
      "2021-11-11 05:21:02.957022: validation loss: -0.7957\n",
      "2021-11-11 05:21:02.961294: Average global foreground Dice: [0.8212]\n",
      "2021-11-11 05:21:02.965194: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 05:21:03.519699: lr: 0.008639\n",
      "2021-11-11 05:21:03.542643: saving checkpoint...\n",
      "2021-11-11 05:21:04.162848: done, saving took 0.64 seconds\n",
      "2021-11-11 05:21:04.193164: This epoch took 202.950515 s\n",
      "\n",
      "2021-11-11 05:21:04.197467: \n",
      "epoch:  3\n",
      "2021-11-11 05:24:11.750252: train loss : -0.7929\n",
      "2021-11-11 05:24:25.830619: validation loss: -0.8155\n",
      "2021-11-11 05:24:25.835882: Average global foreground Dice: [0.8336]\n",
      "2021-11-11 05:24:25.839543: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 05:24:26.402390: lr: 0.008181\n",
      "2021-11-11 05:24:26.425908: saving checkpoint...\n",
      "2021-11-11 05:24:27.065648: done, saving took 0.66 seconds\n",
      "2021-11-11 05:24:27.096533: This epoch took 202.895000 s\n",
      "\n",
      "2021-11-11 05:24:27.100434: \n",
      "epoch:  4\n",
      "2021-11-11 05:27:34.643836: train loss : -0.8073\n",
      "2021-11-11 05:27:48.697742: validation loss: -0.8233\n",
      "2021-11-11 05:27:48.705713: Average global foreground Dice: [0.8403]\n",
      "2021-11-11 05:27:48.712023: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 05:27:49.229283: lr: 0.007719\n",
      "2021-11-11 05:27:49.257809: saving checkpoint...\n",
      "2021-11-11 05:27:49.851539: done, saving took 0.61 seconds\n",
      "2021-11-11 05:27:49.888914: This epoch took 202.784070 s\n",
      "\n",
      "2021-11-11 05:27:49.893761: \n",
      "epoch:  5\n",
      "2021-11-11 05:30:57.418082: train loss : -0.8169\n",
      "2021-11-11 05:31:11.489739: validation loss: -0.8239\n",
      "2021-11-11 05:31:11.494538: Average global foreground Dice: [0.8394]\n",
      "2021-11-11 05:31:11.498489: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 05:31:12.056829: lr: 0.007254\n",
      "2021-11-11 05:31:12.094447: saving checkpoint...\n",
      "2021-11-11 05:31:12.775117: done, saving took 0.71 seconds\n",
      "2021-11-11 05:31:12.804678: This epoch took 202.904469 s\n",
      "\n",
      "2021-11-11 05:31:12.809365: \n",
      "epoch:  6\n",
      "2021-11-11 05:34:20.256039: train loss : -0.8241\n",
      "2021-11-11 05:34:34.293357: validation loss: -0.8267\n",
      "2021-11-11 05:34:34.297609: Average global foreground Dice: [0.8442]\n",
      "2021-11-11 05:34:34.301458: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 05:34:34.916329: lr: 0.006786\n",
      "2021-11-11 05:34:34.940007: saving checkpoint...\n",
      "2021-11-11 05:34:35.600769: done, saving took 0.68 seconds\n",
      "2021-11-11 05:34:35.632512: This epoch took 202.818475 s\n",
      "\n",
      "2021-11-11 05:34:35.637421: \n",
      "epoch:  7\n",
      "2021-11-11 05:37:43.170983: train loss : -0.8299\n",
      "2021-11-11 05:37:57.224717: validation loss: -0.8321\n",
      "2021-11-11 05:37:57.229326: Average global foreground Dice: [0.8486]\n",
      "2021-11-11 05:37:57.233476: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 05:37:57.744346: lr: 0.006314\n",
      "2021-11-11 05:37:57.771207: saving checkpoint...\n",
      "2021-11-11 05:37:58.411807: done, saving took 0.66 seconds\n",
      "2021-11-11 05:37:58.432971: This epoch took 202.791250 s\n",
      "\n",
      "2021-11-11 05:37:58.437485: \n",
      "epoch:  8\n",
      "2021-11-11 05:41:05.985465: train loss : -0.8359\n",
      "2021-11-11 05:41:20.065263: validation loss: -0.8317\n",
      "2021-11-11 05:41:20.069546: Average global foreground Dice: [0.8476]\n",
      "2021-11-11 05:41:20.073187: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 05:41:20.590840: lr: 0.005839\n",
      "2021-11-11 05:41:20.613996: saving checkpoint...\n",
      "2021-11-11 05:41:21.286648: done, saving took 0.69 seconds\n",
      "2021-11-11 05:41:21.317918: This epoch took 202.875788 s\n",
      "\n",
      "2021-11-11 05:41:21.322128: \n",
      "epoch:  9\n",
      "2021-11-11 05:44:28.874089: train loss : -0.8405\n",
      "2021-11-11 05:44:42.949318: validation loss: -0.8334\n",
      "2021-11-11 05:44:42.954266: Average global foreground Dice: [0.8484]\n",
      "2021-11-11 05:44:42.959254: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 05:44:43.509908: lr: 0.005359\n",
      "2021-11-11 05:44:43.533799: saving checkpoint...\n",
      "2021-11-11 05:44:44.173305: done, saving took 0.66 seconds\n",
      "2021-11-11 05:44:44.206376: This epoch took 202.878869 s\n",
      "\n",
      "2021-11-11 05:44:44.210884: \n",
      "epoch:  10\n",
      "2021-11-11 05:47:51.755886: train loss : -0.8427\n",
      "2021-11-11 05:48:05.796261: validation loss: -0.8236\n",
      "2021-11-11 05:48:05.800939: Average global foreground Dice: [0.8384]\n",
      "2021-11-11 05:48:05.808281: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 05:48:06.335030: lr: 0.004874\n",
      "2021-11-11 05:48:06.358479: saving checkpoint...\n",
      "2021-11-11 05:48:07.016392: done, saving took 0.68 seconds\n",
      "2021-11-11 05:48:07.072198: This epoch took 202.856261 s\n",
      "\n",
      "2021-11-11 05:48:07.076514: \n",
      "epoch:  11\n",
      "2021-11-11 05:51:14.643761: train loss : -0.8482\n",
      "2021-11-11 05:51:28.725886: validation loss: -0.8269\n",
      "2021-11-11 05:51:28.732676: Average global foreground Dice: [0.8438]\n",
      "2021-11-11 05:51:28.740544: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 05:51:29.332252: lr: 0.004384\n",
      "2021-11-11 05:51:29.355752: saving checkpoint...\n",
      "2021-11-11 05:51:30.023506: done, saving took 0.69 seconds\n",
      "2021-11-11 05:51:30.053796: This epoch took 202.972634 s\n",
      "\n",
      "2021-11-11 05:51:30.058156: \n",
      "epoch:  12\n",
      "2021-11-11 05:54:37.637250: train loss : -0.8506\n",
      "2021-11-11 05:54:51.717050: validation loss: -0.8308\n",
      "2021-11-11 05:54:51.722978: Average global foreground Dice: [0.8445]\n",
      "2021-11-11 05:54:51.727718: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 05:54:52.275482: lr: 0.003887\n",
      "2021-11-11 05:54:52.299238: saving checkpoint...\n",
      "2021-11-11 05:54:52.949886: done, saving took 0.67 seconds\n",
      "2021-11-11 05:54:52.971270: This epoch took 202.908511 s\n",
      "\n",
      "2021-11-11 05:54:52.975144: \n",
      "epoch:  13\n",
      "2021-11-11 05:58:00.521441: train loss : -0.8541\n",
      "2021-11-11 05:58:14.618300: validation loss: -0.8393\n",
      "2021-11-11 05:58:14.622812: Average global foreground Dice: [0.8518]\n",
      "2021-11-11 05:58:14.627819: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 05:58:15.141283: lr: 0.003384\n",
      "2021-11-11 05:58:15.168085: saving checkpoint...\n",
      "2021-11-11 05:58:15.825876: done, saving took 0.68 seconds\n",
      "2021-11-11 05:58:15.855759: This epoch took 202.875990 s\n",
      "\n",
      "2021-11-11 05:58:15.859420: \n",
      "epoch:  14\n",
      "2021-11-11 06:01:23.399117: train loss : -0.8577\n",
      "2021-11-11 06:01:37.484332: validation loss: -0.8344\n",
      "2021-11-11 06:01:37.489076: Average global foreground Dice: [0.8481]\n",
      "2021-11-11 06:01:37.494406: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 06:01:38.056808: lr: 0.002872\n",
      "2021-11-11 06:01:38.080694: saving checkpoint...\n",
      "2021-11-11 06:01:38.754582: done, saving took 0.69 seconds\n",
      "2021-11-11 06:01:38.782972: This epoch took 202.919384 s\n",
      "\n",
      "2021-11-11 06:01:38.787674: \n",
      "epoch:  15\n",
      "2021-11-11 06:04:46.370699: train loss : -0.8591\n",
      "2021-11-11 06:05:00.474549: validation loss: -0.8366\n",
      "2021-11-11 06:05:00.479660: Average global foreground Dice: [0.8498]\n",
      "2021-11-11 06:05:00.484202: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 06:05:01.039712: lr: 0.002349\n",
      "2021-11-11 06:05:01.064155: saving checkpoint...\n",
      "2021-11-11 06:05:01.715969: done, saving took 0.67 seconds\n",
      "2021-11-11 06:05:01.760383: This epoch took 202.968619 s\n",
      "\n",
      "2021-11-11 06:05:01.769423: \n",
      "epoch:  16\n",
      "2021-11-11 06:08:09.416661: train loss : -0.8629\n",
      "2021-11-11 06:08:23.495351: validation loss: -0.8289\n",
      "2021-11-11 06:08:23.499837: Average global foreground Dice: [0.8432]\n",
      "2021-11-11 06:08:23.503547: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 06:08:24.112961: lr: 0.001813\n",
      "2021-11-11 06:08:24.136267: saving checkpoint...\n",
      "2021-11-11 06:08:24.705215: done, saving took 0.59 seconds\n",
      "2021-11-11 06:08:24.731495: This epoch took 202.953002 s\n",
      "\n",
      "2021-11-11 06:08:24.740769: \n",
      "epoch:  17\n",
      "2021-11-11 06:11:32.361620: train loss : -0.8659\n",
      "2021-11-11 06:11:46.452766: validation loss: -0.8280\n",
      "2021-11-11 06:11:46.458647: Average global foreground Dice: [0.8414]\n",
      "2021-11-11 06:11:46.463205: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 06:11:46.968690: lr: 0.001259\n",
      "2021-11-11 06:11:46.991896: saving checkpoint...\n",
      "2021-11-11 06:11:47.711529: done, saving took 0.74 seconds\n",
      "2021-11-11 06:11:47.734907: This epoch took 202.987266 s\n",
      "\n",
      "2021-11-11 06:11:47.739912: \n",
      "epoch:  18\n",
      "2021-11-11 06:14:55.341253: train loss : -0.8676\n",
      "2021-11-11 06:15:09.437099: validation loss: -0.8324\n",
      "2021-11-11 06:15:09.442192: Average global foreground Dice: [0.8458]\n",
      "2021-11-11 06:15:09.446326: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 06:15:09.981990: lr: 0.000675\n",
      "2021-11-11 06:15:10.006186: saving checkpoint...\n",
      "2021-11-11 06:15:10.665553: done, saving took 0.68 seconds\n",
      "2021-11-11 06:15:10.694006: This epoch took 202.949858 s\n",
      "\n",
      "2021-11-11 06:15:10.698845: \n",
      "epoch:  19\n",
      "2021-11-11 06:18:18.341437: train loss : -0.8703\n",
      "2021-11-11 06:18:32.421680: validation loss: -0.8327\n",
      "2021-11-11 06:18:32.427131: Average global foreground Dice: [0.8468]\n",
      "2021-11-11 06:18:32.433055: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 06:18:33.064803: lr: 0.0\n",
      "2021-11-11 06:18:33.088604: saving checkpoint...\n",
      "2021-11-11 06:18:33.740217: done, saving took 0.67 seconds\n",
      "2021-11-11 06:18:33.766935: This epoch took 203.064173 s\n",
      "\n",
      "2021-11-11 06:18:33.789994: saving checkpoint...\n",
      "2021-11-11 06:18:34.319436: done, saving took 0.55 seconds\n",
      "23090559_20150812 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120330 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090563_20151216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130226 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090584_20120523 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090589_20140219 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090592_20130218 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090614_20120402 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090620_20130617 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090627_20160608 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090628_20150204 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090635_20140710 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090640_20140711 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121227 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-11 06:20:33.203921: finished prediction\n",
      "2021-11-11 06:20:33.208380: evaluation of raw predictions\n",
      "2021-11-11 06:20:34.837177: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.838086705568324\n",
      "after:  0.8381897207699107\n",
      "Removing all but the largest foreground region improved results!\n",
      "for_which_classes [1]\n",
      "min_valid_object_sizes None\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[[1]]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-11 06:20:44.601166: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-11 06:20:44.614156: The split file contains 5 splits.\n",
      "2021-11-11 06:20:44.618648: Desired fold for training: 1\n",
      "2021-11-11 06:20:44.623138: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-11 06:20:48.935743: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-11 06:20:59.502368: Unable to plot network architecture:\n",
      "2021-11-11 06:20:59.506753: No module named 'hiddenlayer'\n",
      "2021-11-11 06:20:59.511469: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-11 06:20:59.515829: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-11 06:20:59.525061: \n",
      "\n",
      "2021-11-11 06:20:59.530858: \n",
      "epoch:  0\n",
      "2021-11-11 06:24:17.013449: train loss : -0.3450\n",
      "2021-11-11 06:24:30.546576: validation loss: -0.6919\n",
      "2021-11-11 06:24:30.550851: Average global foreground Dice: [0.715]\n",
      "2021-11-11 06:24:30.555044: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 06:24:30.996651: lr: 0.009549\n",
      "2021-11-11 06:24:31.001145: This epoch took 211.441477 s\n",
      "\n",
      "2021-11-11 06:24:31.005443: \n",
      "epoch:  1\n",
      "2021-11-11 06:27:30.402017: train loss : -0.7270\n",
      "2021-11-11 06:27:43.927813: validation loss: -0.7794\n",
      "2021-11-11 06:27:43.932137: Average global foreground Dice: [0.798]\n",
      "2021-11-11 06:27:43.936153: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 06:27:44.602425: lr: 0.009095\n",
      "2021-11-11 06:27:44.645536: saving checkpoint...\n",
      "2021-11-11 06:27:45.190657: done, saving took 0.58 seconds\n",
      "2021-11-11 06:27:45.216969: This epoch took 194.205858 s\n",
      "\n",
      "2021-11-11 06:27:45.220728: \n",
      "epoch:  2\n",
      "2021-11-11 06:30:44.458327: train loss : -0.7798\n",
      "2021-11-11 06:30:58.033036: validation loss: -0.7992\n",
      "2021-11-11 06:30:58.038559: Average global foreground Dice: [0.8124]\n",
      "2021-11-11 06:30:58.042490: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 06:30:58.660163: lr: 0.008639\n",
      "2021-11-11 06:30:58.703674: saving checkpoint...\n",
      "2021-11-11 06:30:59.365472: done, saving took 0.70 seconds\n",
      "2021-11-11 06:30:59.388572: This epoch took 194.163259 s\n",
      "\n",
      "2021-11-11 06:30:59.392641: \n",
      "epoch:  3\n",
      "2021-11-11 06:33:58.477499: train loss : -0.8007\n",
      "2021-11-11 06:34:12.062585: validation loss: -0.8118\n",
      "2021-11-11 06:34:12.068299: Average global foreground Dice: [0.8255]\n",
      "2021-11-11 06:34:12.072269: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 06:34:12.637210: lr: 0.008181\n",
      "2021-11-11 06:34:12.660408: saving checkpoint...\n",
      "2021-11-11 06:34:13.293208: done, saving took 0.65 seconds\n",
      "2021-11-11 06:34:13.318328: This epoch took 193.922205 s\n",
      "\n",
      "2021-11-11 06:34:13.322599: \n",
      "epoch:  4\n",
      "2021-11-11 06:37:12.458521: train loss : -0.8109\n",
      "2021-11-11 06:37:25.998983: validation loss: -0.8074\n",
      "2021-11-11 06:37:26.006170: Average global foreground Dice: [0.8169]\n",
      "2021-11-11 06:37:26.009992: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 06:37:26.585911: lr: 0.007719\n",
      "2021-11-11 06:37:26.626177: saving checkpoint...\n",
      "2021-11-11 06:37:27.284533: done, saving took 0.69 seconds\n",
      "2021-11-11 06:37:27.317463: This epoch took 193.990418 s\n",
      "\n",
      "2021-11-11 06:37:27.321621: \n",
      "epoch:  5\n",
      "2021-11-11 06:40:26.592660: train loss : -0.8219\n",
      "2021-11-11 06:40:40.074835: validation loss: -0.8218\n",
      "2021-11-11 06:40:40.079473: Average global foreground Dice: [0.8341]\n",
      "2021-11-11 06:40:40.083904: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 06:40:40.629848: lr: 0.007254\n",
      "2021-11-11 06:40:40.667860: saving checkpoint...\n",
      "2021-11-11 06:40:41.252718: done, saving took 0.62 seconds\n",
      "2021-11-11 06:40:41.277949: This epoch took 193.952142 s\n",
      "\n",
      "2021-11-11 06:40:41.282155: \n",
      "epoch:  6\n",
      "2021-11-11 06:43:40.356954: train loss : -0.8286\n",
      "2021-11-11 06:43:53.856321: validation loss: -0.8141\n",
      "2021-11-11 06:43:53.861871: Average global foreground Dice: [0.8253]\n",
      "2021-11-11 06:43:53.866202: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 06:43:54.461804: lr: 0.006786\n",
      "2021-11-11 06:43:54.500632: saving checkpoint...\n",
      "2021-11-11 06:43:55.121867: done, saving took 0.66 seconds\n",
      "2021-11-11 06:43:55.150813: This epoch took 193.864100 s\n",
      "\n",
      "2021-11-11 06:43:55.154545: \n",
      "epoch:  7\n",
      "2021-11-11 06:46:54.067248: train loss : -0.8333\n",
      "2021-11-11 06:47:07.565455: validation loss: -0.8236\n",
      "2021-11-11 06:47:07.570930: Average global foreground Dice: [0.837]\n",
      "2021-11-11 06:47:07.575402: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 06:47:08.073535: lr: 0.006314\n",
      "2021-11-11 06:47:08.096224: saving checkpoint...\n",
      "2021-11-11 06:47:08.783583: done, saving took 0.71 seconds\n",
      "2021-11-11 06:47:08.806212: This epoch took 193.647749 s\n",
      "\n",
      "2021-11-11 06:47:08.810542: \n",
      "epoch:  8\n",
      "2021-11-11 06:50:08.296156: train loss : -0.8374\n",
      "2021-11-11 06:50:21.797546: validation loss: -0.8189\n",
      "2021-11-11 06:50:21.803259: Average global foreground Dice: [0.8306]\n",
      "2021-11-11 06:50:21.807881: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 06:50:22.308501: lr: 0.005839\n",
      "2021-11-11 06:50:22.331805: saving checkpoint...\n",
      "2021-11-11 06:50:22.980815: done, saving took 0.67 seconds\n",
      "2021-11-11 06:50:23.003984: This epoch took 194.189506 s\n",
      "\n",
      "2021-11-11 06:50:23.007739: \n",
      "epoch:  9\n",
      "2021-11-11 06:53:22.620668: train loss : -0.8415\n",
      "2021-11-11 06:53:36.185926: validation loss: -0.8249\n",
      "2021-11-11 06:53:36.190797: Average global foreground Dice: [0.8371]\n",
      "2021-11-11 06:53:36.195656: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 06:53:36.775695: lr: 0.005359\n",
      "2021-11-11 06:53:36.800025: saving checkpoint...\n",
      "2021-11-11 06:53:37.461614: done, saving took 0.68 seconds\n",
      "2021-11-11 06:53:37.483428: This epoch took 194.471274 s\n",
      "\n",
      "2021-11-11 06:53:37.487661: \n",
      "epoch:  10\n",
      "2021-11-11 06:56:37.132999: train loss : -0.8466\n",
      "2021-11-11 06:56:50.628381: validation loss: -0.8277\n",
      "2021-11-11 06:56:50.635231: Average global foreground Dice: [0.8402]\n",
      "2021-11-11 06:56:50.640320: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 06:56:51.199275: lr: 0.004874\n",
      "2021-11-11 06:56:51.222516: saving checkpoint...\n",
      "2021-11-11 06:56:51.873122: done, saving took 0.67 seconds\n",
      "2021-11-11 06:56:51.893923: This epoch took 194.401753 s\n",
      "\n",
      "2021-11-11 06:56:51.898576: \n",
      "epoch:  11\n",
      "2021-11-11 06:59:51.485037: train loss : -0.8495\n",
      "2021-11-11 07:00:04.991474: validation loss: -0.8287\n",
      "2021-11-11 07:00:04.996303: Average global foreground Dice: [0.8396]\n",
      "2021-11-11 07:00:05.000598: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 07:00:05.628500: lr: 0.004384\n",
      "2021-11-11 07:00:05.652036: saving checkpoint...\n",
      "2021-11-11 07:00:06.741807: done, saving took 1.11 seconds\n",
      "2021-11-11 07:00:06.766291: This epoch took 194.862928 s\n",
      "\n",
      "2021-11-11 07:00:06.771329: \n",
      "epoch:  12\n",
      "2021-11-11 07:03:06.388248: train loss : -0.8523\n",
      "2021-11-11 07:03:19.887667: validation loss: -0.8259\n",
      "2021-11-11 07:03:19.894277: Average global foreground Dice: [0.8371]\n",
      "2021-11-11 07:03:19.898314: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 07:03:20.442671: lr: 0.003887\n",
      "2021-11-11 07:03:20.466088: saving checkpoint...\n",
      "2021-11-11 07:03:21.134527: done, saving took 0.69 seconds\n",
      "2021-11-11 07:03:21.161670: This epoch took 194.385474 s\n",
      "\n",
      "2021-11-11 07:03:21.166310: \n",
      "epoch:  13\n",
      "2021-11-11 07:06:20.682931: train loss : -0.8553\n",
      "2021-11-11 07:06:34.179398: validation loss: -0.8312\n",
      "2021-11-11 07:06:34.184166: Average global foreground Dice: [0.8405]\n",
      "2021-11-11 07:06:34.188712: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 07:06:34.680182: lr: 0.003384\n",
      "2021-11-11 07:06:34.703248: saving checkpoint...\n",
      "2021-11-11 07:06:35.407632: done, saving took 0.72 seconds\n",
      "2021-11-11 07:06:35.430983: This epoch took 194.260327 s\n",
      "\n",
      "2021-11-11 07:06:35.435957: \n",
      "epoch:  14\n",
      "2021-11-11 07:09:35.113951: train loss : -0.8567\n",
      "2021-11-11 07:09:48.602839: validation loss: -0.8301\n",
      "2021-11-11 07:09:48.611048: Average global foreground Dice: [0.8423]\n",
      "2021-11-11 07:09:48.615704: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 07:09:49.175266: lr: 0.002872\n",
      "2021-11-11 07:09:49.198869: saving checkpoint...\n",
      "2021-11-11 07:09:49.878977: done, saving took 0.70 seconds\n",
      "2021-11-11 07:09:49.913421: This epoch took 194.471692 s\n",
      "\n",
      "2021-11-11 07:09:49.917861: \n",
      "epoch:  15\n",
      "2021-11-11 07:12:49.594613: train loss : -0.8597\n",
      "2021-11-11 07:13:03.101830: validation loss: -0.8314\n",
      "2021-11-11 07:13:03.107732: Average global foreground Dice: [0.8427]\n",
      "2021-11-11 07:13:03.112871: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 07:13:03.608191: lr: 0.002349\n",
      "2021-11-11 07:13:03.630533: saving checkpoint...\n",
      "2021-11-11 07:13:04.302679: done, saving took 0.69 seconds\n",
      "2021-11-11 07:13:04.325005: This epoch took 194.402479 s\n",
      "\n",
      "2021-11-11 07:13:04.329075: \n",
      "epoch:  16\n",
      "2021-11-11 07:16:04.280978: train loss : -0.8621\n",
      "2021-11-11 07:16:17.826649: validation loss: -0.8320\n",
      "2021-11-11 07:16:17.831671: Average global foreground Dice: [0.8421]\n",
      "2021-11-11 07:16:17.836520: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 07:16:18.456460: lr: 0.001813\n",
      "2021-11-11 07:16:18.479718: saving checkpoint...\n",
      "2021-11-11 07:16:19.168110: done, saving took 0.71 seconds\n",
      "2021-11-11 07:16:19.189406: This epoch took 194.856340 s\n",
      "\n",
      "2021-11-11 07:16:19.194529: \n",
      "epoch:  17\n",
      "2021-11-11 07:19:19.131126: train loss : -0.8641\n",
      "2021-11-11 07:19:32.659576: validation loss: -0.8324\n",
      "2021-11-11 07:19:32.664675: Average global foreground Dice: [0.8423]\n",
      "2021-11-11 07:19:32.668444: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 07:19:33.245419: lr: 0.001259\n",
      "2021-11-11 07:19:33.269559: saving checkpoint...\n",
      "2021-11-11 07:19:33.954367: done, saving took 0.70 seconds\n",
      "2021-11-11 07:19:33.986666: This epoch took 194.787621 s\n",
      "\n",
      "2021-11-11 07:19:33.990680: \n",
      "epoch:  18\n",
      "2021-11-11 07:22:33.936220: train loss : -0.8667\n",
      "2021-11-11 07:22:47.448460: validation loss: -0.8268\n",
      "2021-11-11 07:22:47.453486: Average global foreground Dice: [0.8369]\n",
      "2021-11-11 07:22:47.458519: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 07:22:47.962047: lr: 0.000675\n",
      "2021-11-11 07:22:47.985830: saving checkpoint...\n",
      "2021-11-11 07:22:48.639249: done, saving took 0.67 seconds\n",
      "2021-11-11 07:22:48.664688: This epoch took 194.668055 s\n",
      "\n",
      "2021-11-11 07:22:48.669405: \n",
      "epoch:  19\n",
      "2021-11-11 07:25:48.637836: train loss : -0.8697\n",
      "2021-11-11 07:26:02.153781: validation loss: -0.8328\n",
      "2021-11-11 07:26:02.158697: Average global foreground Dice: [0.8417]\n",
      "2021-11-11 07:26:02.163139: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 07:26:02.674812: lr: 0.0\n",
      "2021-11-11 07:26:02.698008: saving checkpoint...\n",
      "2021-11-11 07:26:03.355676: done, saving took 0.68 seconds\n",
      "2021-11-11 07:26:03.377947: This epoch took 194.703973 s\n",
      "\n",
      "2021-11-11 07:26:03.401045: saving checkpoint...\n",
      "2021-11-11 07:26:03.910952: done, saving took 0.53 seconds\n",
      "23090567_20160819 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150401 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130213 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120627 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090590_20121212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160706 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090599_20140701 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130225 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090604_20140303 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090615_20140403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090617_20140211 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120406 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160111 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130213 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090631_20130128 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090634_20150409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-11 07:28:01.762457: finished prediction\n",
      "2021-11-11 07:28:01.767102: evaluation of raw predictions\n",
      "2021-11-11 07:28:03.218598: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8378068618265448\n",
      "after:  0.8379703897813566\n",
      "Removing all but the largest foreground region improved results!\n",
      "for_which_classes [1]\n",
      "min_valid_object_sizes None\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[[1]]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-11 07:28:13.094558: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-11 07:28:13.109041: The split file contains 5 splits.\n",
      "2021-11-11 07:28:13.113582: Desired fold for training: 2\n",
      "2021-11-11 07:28:13.117496: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-11 07:28:17.271122: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-11 07:28:27.573588: Unable to plot network architecture:\n",
      "2021-11-11 07:28:27.579028: No module named 'hiddenlayer'\n",
      "2021-11-11 07:28:27.584005: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-11 07:28:27.588145: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-11 07:28:27.596568: \n",
      "\n",
      "2021-11-11 07:28:27.600923: \n",
      "epoch:  0\n",
      "2021-11-11 07:31:45.370416: train loss : -0.3506\n",
      "2021-11-11 07:31:59.073912: validation loss: -0.7136\n",
      "2021-11-11 07:31:59.078207: Average global foreground Dice: [0.7462]\n",
      "2021-11-11 07:31:59.081833: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 07:31:59.511568: lr: 0.009549\n",
      "2021-11-11 07:31:59.516827: This epoch took 211.911700 s\n",
      "\n",
      "2021-11-11 07:31:59.521598: \n",
      "epoch:  1\n",
      "2021-11-11 07:34:59.316463: train loss : -0.7337\n",
      "2021-11-11 07:35:13.007101: validation loss: -0.7709\n",
      "2021-11-11 07:35:13.011683: Average global foreground Dice: [0.7968]\n",
      "2021-11-11 07:35:13.015371: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 07:35:13.569599: lr: 0.009095\n",
      "2021-11-11 07:35:13.604872: saving checkpoint...\n",
      "2021-11-11 07:35:14.150819: done, saving took 0.58 seconds\n",
      "2021-11-11 07:35:14.167292: This epoch took 194.641154 s\n",
      "\n",
      "2021-11-11 07:35:14.171975: \n",
      "epoch:  2\n",
      "2021-11-11 07:38:13.652514: train loss : -0.7850\n",
      "2021-11-11 07:38:27.329511: validation loss: -0.8080\n",
      "2021-11-11 07:38:27.335084: Average global foreground Dice: [0.8259]\n",
      "2021-11-11 07:38:27.339500: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 07:38:27.900917: lr: 0.008639\n",
      "2021-11-11 07:38:27.947889: saving checkpoint...\n",
      "2021-11-11 07:38:28.605608: done, saving took 0.70 seconds\n",
      "2021-11-11 07:38:28.628783: This epoch took 194.451974 s\n",
      "\n",
      "2021-11-11 07:38:28.632676: \n",
      "epoch:  3\n",
      "2021-11-11 07:41:29.210203: train loss : -0.8067\n",
      "2021-11-11 07:41:42.996596: validation loss: -0.8074\n",
      "2021-11-11 07:41:43.001398: Average global foreground Dice: [0.8261]\n",
      "2021-11-11 07:41:43.005037: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 07:41:43.581560: lr: 0.008181\n",
      "2021-11-11 07:41:43.626519: saving checkpoint...\n",
      "2021-11-11 07:41:44.271905: done, saving took 0.69 seconds\n",
      "2021-11-11 07:41:44.305655: This epoch took 195.669139 s\n",
      "\n",
      "2021-11-11 07:41:44.309990: \n",
      "epoch:  4\n",
      "2021-11-11 07:44:44.943051: train loss : -0.8180\n",
      "2021-11-11 07:44:58.694909: validation loss: -0.8129\n",
      "2021-11-11 07:44:58.700467: Average global foreground Dice: [0.8299]\n",
      "2021-11-11 07:44:58.705858: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 07:44:59.230872: lr: 0.007719\n",
      "2021-11-11 07:44:59.253417: saving checkpoint...\n",
      "2021-11-11 07:44:59.835874: done, saving took 0.60 seconds\n",
      "2021-11-11 07:44:59.862385: This epoch took 195.548952 s\n",
      "\n",
      "2021-11-11 07:44:59.867048: \n",
      "epoch:  5\n",
      "2021-11-11 07:48:00.707246: train loss : -0.8261\n",
      "2021-11-11 07:48:14.502540: validation loss: -0.8194\n",
      "2021-11-11 07:48:14.507150: Average global foreground Dice: [0.8331]\n",
      "2021-11-11 07:48:14.511296: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 07:48:15.069664: lr: 0.007254\n",
      "2021-11-11 07:48:15.097453: saving checkpoint...\n",
      "2021-11-11 07:48:15.758870: done, saving took 0.68 seconds\n",
      "2021-11-11 07:48:15.779473: This epoch took 195.907996 s\n",
      "\n",
      "2021-11-11 07:48:15.784015: \n",
      "epoch:  6\n",
      "2021-11-11 07:51:16.529924: train loss : -0.8319\n",
      "2021-11-11 07:51:30.311616: validation loss: -0.8211\n",
      "2021-11-11 07:51:30.316146: Average global foreground Dice: [0.8354]\n",
      "2021-11-11 07:51:30.320883: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 07:51:30.884100: lr: 0.006786\n",
      "2021-11-11 07:51:30.907158: saving checkpoint...\n",
      "2021-11-11 07:51:31.538392: done, saving took 0.65 seconds\n",
      "2021-11-11 07:51:31.562160: This epoch took 195.774720 s\n",
      "\n",
      "2021-11-11 07:51:31.566812: \n",
      "epoch:  7\n",
      "2021-11-11 07:54:32.306297: train loss : -0.8356\n",
      "2021-11-11 07:54:46.096156: validation loss: -0.8163\n",
      "2021-11-11 07:54:46.100688: Average global foreground Dice: [0.8297]\n",
      "2021-11-11 07:54:46.104846: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 07:54:46.654491: lr: 0.006314\n",
      "2021-11-11 07:54:46.677408: saving checkpoint...\n",
      "2021-11-11 07:54:47.319108: done, saving took 0.66 seconds\n",
      "2021-11-11 07:54:47.346437: This epoch took 195.776156 s\n",
      "\n",
      "2021-11-11 07:54:47.349904: \n",
      "epoch:  8\n",
      "2021-11-11 07:57:48.509789: train loss : -0.8401\n",
      "2021-11-11 07:58:02.305504: validation loss: -0.8213\n",
      "2021-11-11 07:58:02.310181: Average global foreground Dice: [0.8348]\n",
      "2021-11-11 07:58:02.313710: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 07:58:02.826587: lr: 0.005839\n",
      "2021-11-11 07:58:02.850475: saving checkpoint...\n",
      "2021-11-11 07:58:03.504045: done, saving took 0.67 seconds\n",
      "2021-11-11 07:58:03.537095: This epoch took 196.183440 s\n",
      "\n",
      "2021-11-11 07:58:03.540984: \n",
      "epoch:  9\n",
      "2021-11-11 08:01:04.996735: train loss : -0.8449\n",
      "2021-11-11 08:01:18.770790: validation loss: -0.8225\n",
      "2021-11-11 08:01:18.776915: Average global foreground Dice: [0.8359]\n",
      "2021-11-11 08:01:18.780878: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 08:01:19.307384: lr: 0.005359\n",
      "2021-11-11 08:01:19.331903: saving checkpoint...\n",
      "2021-11-11 08:01:19.966514: done, saving took 0.65 seconds\n",
      "2021-11-11 08:01:19.994956: This epoch took 196.447446 s\n",
      "\n",
      "2021-11-11 08:01:19.999988: \n",
      "epoch:  10\n",
      "2021-11-11 08:04:21.322016: train loss : -0.8487\n",
      "2021-11-11 08:04:35.116938: validation loss: -0.8212\n",
      "2021-11-11 08:04:35.122971: Average global foreground Dice: [0.8337]\n",
      "2021-11-11 08:04:35.127853: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 08:04:35.666394: lr: 0.004874\n",
      "2021-11-11 08:04:35.690248: saving checkpoint...\n",
      "2021-11-11 08:04:36.354889: done, saving took 0.68 seconds\n",
      "2021-11-11 08:04:36.385323: This epoch took 196.380684 s\n",
      "\n",
      "2021-11-11 08:04:36.390073: \n",
      "epoch:  11\n",
      "2021-11-11 08:07:37.687472: train loss : -0.8521\n",
      "2021-11-11 08:07:51.441743: validation loss: -0.8242\n",
      "2021-11-11 08:07:51.447357: Average global foreground Dice: [0.8375]\n",
      "2021-11-11 08:07:51.451824: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 08:07:52.008169: lr: 0.004384\n",
      "2021-11-11 08:07:52.031040: saving checkpoint...\n",
      "2021-11-11 08:07:52.792869: done, saving took 0.78 seconds\n",
      "2021-11-11 08:07:52.831146: This epoch took 196.436536 s\n",
      "\n",
      "2021-11-11 08:07:52.835632: \n",
      "epoch:  12\n",
      "2021-11-11 08:10:54.280979: train loss : -0.8551\n",
      "2021-11-11 08:11:08.072784: validation loss: -0.8244\n",
      "2021-11-11 08:11:08.079030: Average global foreground Dice: [0.8369]\n",
      "2021-11-11 08:11:08.085622: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 08:11:08.591713: lr: 0.003887\n",
      "2021-11-11 08:11:08.615037: saving checkpoint...\n",
      "2021-11-11 08:11:09.257773: done, saving took 0.66 seconds\n",
      "2021-11-11 08:11:09.283489: This epoch took 196.443651 s\n",
      "\n",
      "2021-11-11 08:11:09.288152: \n",
      "epoch:  13\n",
      "2021-11-11 08:14:10.846368: train loss : -0.8580\n",
      "2021-11-11 08:14:24.661335: validation loss: -0.8223\n",
      "2021-11-11 08:14:24.666649: Average global foreground Dice: [0.8356]\n",
      "2021-11-11 08:14:24.671490: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 08:14:25.238694: lr: 0.003384\n",
      "2021-11-11 08:14:25.262468: saving checkpoint...\n",
      "2021-11-11 08:14:25.895593: done, saving took 0.65 seconds\n",
      "2021-11-11 08:14:25.929084: This epoch took 196.635856 s\n",
      "\n",
      "2021-11-11 08:14:25.933338: \n",
      "epoch:  14\n",
      "2021-11-11 08:17:27.465790: train loss : -0.8607\n",
      "2021-11-11 08:17:41.241200: validation loss: -0.8232\n",
      "2021-11-11 08:17:41.246154: Average global foreground Dice: [0.8351]\n",
      "2021-11-11 08:17:41.251001: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 08:17:41.805567: lr: 0.002872\n",
      "2021-11-11 08:17:41.829449: saving checkpoint...\n",
      "2021-11-11 08:17:42.548340: done, saving took 0.74 seconds\n",
      "2021-11-11 08:17:42.576411: This epoch took 196.639097 s\n",
      "\n",
      "2021-11-11 08:17:42.581287: \n",
      "epoch:  15\n",
      "2021-11-11 08:20:43.969573: train loss : -0.8631\n",
      "2021-11-11 08:20:57.768738: validation loss: -0.8244\n",
      "2021-11-11 08:20:57.775321: Average global foreground Dice: [0.838]\n",
      "2021-11-11 08:20:57.779622: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 08:20:58.320536: lr: 0.002349\n",
      "2021-11-11 08:20:58.343996: saving checkpoint...\n",
      "2021-11-11 08:20:58.980978: done, saving took 0.66 seconds\n",
      "2021-11-11 08:20:59.003585: This epoch took 196.418130 s\n",
      "\n",
      "2021-11-11 08:20:59.007669: \n",
      "epoch:  16\n",
      "2021-11-11 08:24:01.048540: train loss : -0.8666\n",
      "2021-11-11 08:24:14.837938: validation loss: -0.8302\n",
      "2021-11-11 08:24:14.842072: Average global foreground Dice: [0.8427]\n",
      "2021-11-11 08:24:14.846054: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 08:24:15.393167: lr: 0.001813\n",
      "2021-11-11 08:24:15.417566: saving checkpoint...\n",
      "2021-11-11 08:24:16.144320: done, saving took 0.75 seconds\n",
      "2021-11-11 08:24:16.175050: This epoch took 197.162712 s\n",
      "\n",
      "2021-11-11 08:24:16.178742: \n",
      "epoch:  17\n",
      "2021-11-11 08:27:18.333523: train loss : -0.8677\n",
      "2021-11-11 08:27:32.147193: validation loss: -0.8233\n",
      "2021-11-11 08:27:32.152673: Average global foreground Dice: [0.8353]\n",
      "2021-11-11 08:27:32.156747: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 08:27:32.732825: lr: 0.001259\n",
      "2021-11-11 08:27:32.756221: saving checkpoint...\n",
      "2021-11-11 08:27:33.446366: done, saving took 0.71 seconds\n",
      "2021-11-11 08:27:33.466704: This epoch took 197.283749 s\n",
      "\n",
      "2021-11-11 08:27:33.471026: \n",
      "epoch:  18\n",
      "2021-11-11 08:30:35.410822: train loss : -0.8712\n",
      "2021-11-11 08:30:49.228894: validation loss: -0.8257\n",
      "2021-11-11 08:30:49.233888: Average global foreground Dice: [0.8374]\n",
      "2021-11-11 08:30:49.238280: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 08:30:49.784277: lr: 0.000675\n",
      "2021-11-11 08:30:49.808368: saving checkpoint...\n",
      "2021-11-11 08:30:50.440603: done, saving took 0.65 seconds\n",
      "2021-11-11 08:30:50.468835: This epoch took 196.992987 s\n",
      "\n",
      "2021-11-11 08:30:50.473321: \n",
      "epoch:  19\n",
      "2021-11-11 08:33:52.588184: train loss : -0.8721\n",
      "2021-11-11 08:34:06.383929: validation loss: -0.8250\n",
      "2021-11-11 08:34:06.388508: Average global foreground Dice: [0.836]\n",
      "2021-11-11 08:34:06.392385: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 08:34:06.967542: lr: 0.0\n",
      "2021-11-11 08:34:06.990513: saving checkpoint...\n",
      "2021-11-11 08:34:07.623788: done, saving took 0.65 seconds\n",
      "2021-11-11 08:34:07.654998: This epoch took 197.177010 s\n",
      "\n",
      "2021-11-11 08:34:07.678497: saving checkpoint...\n",
      "2021-11-11 08:34:08.224639: done, saving took 0.57 seconds\n",
      "23090566_20141114 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090571_20120517 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131226 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160308 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131025 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090596_20150112 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120619 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090608_20120718 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151210 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121213 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090616_20140331 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090619_20121210 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090629_20120830 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090636_20121018 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150522 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-11 08:36:09.022834: finished prediction\n",
      "2021-11-11 08:36:09.027897: evaluation of raw predictions\n",
      "2021-11-11 08:36:10.518779: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8265648848897827\n",
      "after:  0.8264410283314049\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-11 08:36:20.039049: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-11 08:36:20.052261: The split file contains 5 splits.\n",
      "2021-11-11 08:36:20.055568: Desired fold for training: 3\n",
      "2021-11-11 08:36:20.060534: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-11 08:36:24.250299: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-11 08:36:33.766151: Unable to plot network architecture:\n",
      "2021-11-11 08:36:33.772126: No module named 'hiddenlayer'\n",
      "2021-11-11 08:36:33.779637: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-11 08:36:33.785229: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-11 08:36:33.793407: \n",
      "\n",
      "2021-11-11 08:36:33.798836: \n",
      "epoch:  0\n",
      "2021-11-11 08:39:51.794229: train loss : -0.3505\n",
      "2021-11-11 08:40:05.494015: validation loss: -0.7211\n",
      "2021-11-11 08:40:05.498727: Average global foreground Dice: [0.7444]\n",
      "2021-11-11 08:40:05.503164: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 08:40:05.942174: lr: 0.009549\n",
      "2021-11-11 08:40:05.946514: This epoch took 212.083503 s\n",
      "\n",
      "2021-11-11 08:40:05.950367: \n",
      "epoch:  1\n",
      "2021-11-11 08:43:05.868923: train loss : -0.7326\n",
      "2021-11-11 08:43:19.547247: validation loss: -0.7972\n",
      "2021-11-11 08:43:19.552606: Average global foreground Dice: [0.8185]\n",
      "2021-11-11 08:43:19.557230: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 08:43:20.187853: lr: 0.009095\n",
      "2021-11-11 08:43:20.228825: saving checkpoint...\n",
      "2021-11-11 08:43:20.780383: done, saving took 0.59 seconds\n",
      "2021-11-11 08:43:20.798516: This epoch took 194.843414 s\n",
      "\n",
      "2021-11-11 08:43:20.803005: \n",
      "epoch:  2\n",
      "2021-11-11 08:46:20.291940: train loss : -0.7790\n",
      "2021-11-11 08:46:33.991660: validation loss: -0.8099\n",
      "2021-11-11 08:46:33.996291: Average global foreground Dice: [0.8256]\n",
      "2021-11-11 08:46:33.999738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 08:46:34.510888: lr: 0.008639\n",
      "2021-11-11 08:46:34.545019: saving checkpoint...\n",
      "2021-11-11 08:46:35.175261: done, saving took 0.66 seconds\n",
      "2021-11-11 08:46:35.196338: This epoch took 194.388882 s\n",
      "\n",
      "2021-11-11 08:46:35.200194: \n",
      "epoch:  3\n",
      "2021-11-11 08:49:35.856599: train loss : -0.8002\n",
      "2021-11-11 08:49:49.637846: validation loss: -0.8178\n",
      "2021-11-11 08:49:49.642670: Average global foreground Dice: [0.8328]\n",
      "2021-11-11 08:49:49.646520: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 08:49:50.176479: lr: 0.008181\n",
      "2021-11-11 08:49:50.202468: saving checkpoint...\n",
      "2021-11-11 08:49:50.885730: done, saving took 0.71 seconds\n",
      "2021-11-11 08:49:50.909204: This epoch took 195.705691 s\n",
      "\n",
      "2021-11-11 08:49:50.913599: \n",
      "epoch:  4\n",
      "2021-11-11 08:52:51.656733: train loss : -0.8139\n",
      "2021-11-11 08:53:05.417939: validation loss: -0.8221\n",
      "2021-11-11 08:53:05.423325: Average global foreground Dice: [0.8365]\n",
      "2021-11-11 08:53:05.427888: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 08:53:05.996270: lr: 0.007719\n",
      "2021-11-11 08:53:06.021260: saving checkpoint...\n",
      "2021-11-11 08:53:06.651075: done, saving took 0.65 seconds\n",
      "2021-11-11 08:53:06.676062: This epoch took 195.757748 s\n",
      "\n",
      "2021-11-11 08:53:06.680405: \n",
      "epoch:  5\n",
      "2021-11-11 08:56:07.489947: train loss : -0.8216\n",
      "2021-11-11 08:56:21.280344: validation loss: -0.8272\n",
      "2021-11-11 08:56:21.285297: Average global foreground Dice: [0.8387]\n",
      "2021-11-11 08:56:21.289392: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 08:56:21.857491: lr: 0.007254\n",
      "2021-11-11 08:56:21.880820: saving checkpoint...\n",
      "2021-11-11 08:56:22.546718: done, saving took 0.68 seconds\n",
      "2021-11-11 08:56:22.580902: This epoch took 195.895523 s\n",
      "\n",
      "2021-11-11 08:56:22.585676: \n",
      "epoch:  6\n",
      "2021-11-11 08:59:23.545396: train loss : -0.8280\n",
      "2021-11-11 08:59:37.345605: validation loss: -0.8330\n",
      "2021-11-11 08:59:37.350523: Average global foreground Dice: [0.8451]\n",
      "2021-11-11 08:59:37.354716: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 08:59:37.920882: lr: 0.006786\n",
      "2021-11-11 08:59:37.943748: saving checkpoint...\n",
      "2021-11-11 08:59:38.637012: done, saving took 0.71 seconds\n",
      "2021-11-11 08:59:38.658664: This epoch took 196.068783 s\n",
      "\n",
      "2021-11-11 08:59:38.662566: \n",
      "epoch:  7\n",
      "2021-11-11 09:02:39.457114: train loss : -0.8331\n",
      "2021-11-11 09:02:53.227225: validation loss: -0.8318\n",
      "2021-11-11 09:02:53.232667: Average global foreground Dice: [0.846]\n",
      "2021-11-11 09:02:53.237553: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 09:02:53.735446: lr: 0.006314\n",
      "2021-11-11 09:02:53.763040: saving checkpoint...\n",
      "2021-11-11 09:02:54.409229: done, saving took 0.67 seconds\n",
      "2021-11-11 09:02:54.433085: This epoch took 195.766974 s\n",
      "\n",
      "2021-11-11 09:02:54.437211: \n",
      "epoch:  8\n",
      "2021-11-11 09:05:55.738784: train loss : -0.8374\n",
      "2021-11-11 09:06:09.490891: validation loss: -0.8328\n",
      "2021-11-11 09:06:09.496021: Average global foreground Dice: [0.8439]\n",
      "2021-11-11 09:06:09.500834: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 09:06:10.043676: lr: 0.005839\n",
      "2021-11-11 09:06:10.067073: saving checkpoint...\n",
      "2021-11-11 09:06:10.700267: done, saving took 0.65 seconds\n",
      "2021-11-11 09:06:10.723268: This epoch took 196.282031 s\n",
      "\n",
      "2021-11-11 09:06:10.727505: \n",
      "epoch:  9\n",
      "2021-11-11 09:09:12.022825: train loss : -0.8409\n",
      "2021-11-11 09:09:25.839869: validation loss: -0.8308\n",
      "2021-11-11 09:09:25.844844: Average global foreground Dice: [0.8426]\n",
      "2021-11-11 09:09:25.848871: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 09:09:26.376121: lr: 0.005359\n",
      "2021-11-11 09:09:26.399464: saving checkpoint...\n",
      "2021-11-11 09:09:27.033228: done, saving took 0.65 seconds\n",
      "2021-11-11 09:09:27.055215: This epoch took 196.322924 s\n",
      "\n",
      "2021-11-11 09:09:27.059561: \n",
      "epoch:  10\n",
      "2021-11-11 09:12:28.533499: train loss : -0.8462\n",
      "2021-11-11 09:12:42.312696: validation loss: -0.8332\n",
      "2021-11-11 09:12:42.317871: Average global foreground Dice: [0.8446]\n",
      "2021-11-11 09:12:42.322527: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 09:12:42.858227: lr: 0.004874\n",
      "2021-11-11 09:12:42.882033: saving checkpoint...\n",
      "2021-11-11 09:12:43.514462: done, saving took 0.65 seconds\n",
      "2021-11-11 09:12:43.536456: This epoch took 196.472417 s\n",
      "\n",
      "2021-11-11 09:12:43.539996: \n",
      "epoch:  11\n",
      "2021-11-11 09:15:44.892309: train loss : -0.8495\n",
      "2021-11-11 09:15:58.670120: validation loss: -0.8366\n",
      "2021-11-11 09:15:58.674922: Average global foreground Dice: [0.8464]\n",
      "2021-11-11 09:15:58.678667: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 09:15:59.243434: lr: 0.004384\n",
      "2021-11-11 09:15:59.266303: saving checkpoint...\n",
      "2021-11-11 09:15:59.958790: done, saving took 0.71 seconds\n",
      "2021-11-11 09:15:59.990747: This epoch took 196.446246 s\n",
      "\n",
      "2021-11-11 09:15:59.995447: \n",
      "epoch:  12\n",
      "2021-11-11 09:19:01.507410: train loss : -0.8522\n",
      "2021-11-11 09:19:15.298559: validation loss: -0.8357\n",
      "2021-11-11 09:19:15.303744: Average global foreground Dice: [0.8475]\n",
      "2021-11-11 09:19:15.308791: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 09:19:15.855136: lr: 0.003887\n",
      "2021-11-11 09:19:15.879043: saving checkpoint...\n",
      "2021-11-11 09:19:16.509860: done, saving took 0.65 seconds\n",
      "2021-11-11 09:19:16.540505: This epoch took 196.540832 s\n",
      "\n",
      "2021-11-11 09:19:16.545008: \n",
      "epoch:  13\n",
      "2021-11-11 09:22:17.949653: train loss : -0.8552\n",
      "2021-11-11 09:22:31.761848: validation loss: -0.8353\n",
      "2021-11-11 09:22:31.766201: Average global foreground Dice: [0.846]\n",
      "2021-11-11 09:22:31.770751: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 09:22:32.344319: lr: 0.003384\n",
      "2021-11-11 09:22:32.369037: saving checkpoint...\n",
      "2021-11-11 09:22:32.984773: done, saving took 0.63 seconds\n",
      "2021-11-11 09:22:33.017060: This epoch took 196.467635 s\n",
      "\n",
      "2021-11-11 09:22:33.021003: \n",
      "epoch:  14\n",
      "2021-11-11 09:25:34.440260: train loss : -0.8579\n",
      "2021-11-11 09:25:48.234466: validation loss: -0.8396\n",
      "2021-11-11 09:25:48.238935: Average global foreground Dice: [0.8498]\n",
      "2021-11-11 09:25:48.243650: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 09:25:48.774511: lr: 0.002872\n",
      "2021-11-11 09:25:48.798043: saving checkpoint...\n",
      "2021-11-11 09:25:49.439753: done, saving took 0.66 seconds\n",
      "2021-11-11 09:25:49.472524: This epoch took 196.446939 s\n",
      "\n",
      "2021-11-11 09:25:49.476820: \n",
      "epoch:  15\n",
      "2021-11-11 09:28:50.834044: train loss : -0.8602\n",
      "2021-11-11 09:29:04.644881: validation loss: -0.8342\n",
      "2021-11-11 09:29:04.650049: Average global foreground Dice: [0.8439]\n",
      "2021-11-11 09:29:04.653703: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 09:29:05.191508: lr: 0.002349\n",
      "2021-11-11 09:29:05.215206: saving checkpoint...\n",
      "2021-11-11 09:29:05.805938: done, saving took 0.61 seconds\n",
      "2021-11-11 09:29:05.840967: This epoch took 196.360631 s\n",
      "\n",
      "2021-11-11 09:29:05.845616: \n",
      "epoch:  16\n",
      "2021-11-11 09:32:07.806277: train loss : -0.8626\n",
      "2021-11-11 09:32:21.592413: validation loss: -0.8388\n",
      "2021-11-11 09:32:21.597388: Average global foreground Dice: [0.8481]\n",
      "2021-11-11 09:32:21.602211: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 09:32:22.147673: lr: 0.001813\n",
      "2021-11-11 09:32:22.171413: saving checkpoint...\n",
      "2021-11-11 09:32:22.867195: done, saving took 0.71 seconds\n",
      "2021-11-11 09:32:22.896377: This epoch took 197.046079 s\n",
      "\n",
      "2021-11-11 09:32:22.901754: \n",
      "epoch:  17\n",
      "2021-11-11 09:35:24.961515: train loss : -0.8651\n",
      "2021-11-11 09:35:38.761482: validation loss: -0.8396\n",
      "2021-11-11 09:35:38.766937: Average global foreground Dice: [0.8495]\n",
      "2021-11-11 09:35:38.771665: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 09:35:39.337759: lr: 0.001259\n",
      "2021-11-11 09:35:39.361069: saving checkpoint...\n",
      "2021-11-11 09:35:39.977900: done, saving took 0.64 seconds\n",
      "2021-11-11 09:35:40.000525: This epoch took 197.094088 s\n",
      "\n",
      "2021-11-11 09:35:40.005371: \n",
      "epoch:  18\n",
      "2021-11-11 09:38:41.954882: train loss : -0.8677\n",
      "2021-11-11 09:38:55.759843: validation loss: -0.8395\n",
      "2021-11-11 09:38:55.766727: Average global foreground Dice: [0.8496]\n",
      "2021-11-11 09:38:55.771085: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 09:38:56.326626: lr: 0.000675\n",
      "2021-11-11 09:38:56.350672: saving checkpoint...\n",
      "2021-11-11 09:38:56.989415: done, saving took 0.66 seconds\n",
      "2021-11-11 09:38:57.011339: This epoch took 197.001042 s\n",
      "\n",
      "2021-11-11 09:38:57.015496: \n",
      "epoch:  19\n",
      "2021-11-11 09:41:59.077659: train loss : -0.8694\n",
      "2021-11-11 09:42:12.882680: validation loss: -0.8424\n",
      "2021-11-11 09:42:12.888435: Average global foreground Dice: [0.852]\n",
      "2021-11-11 09:42:12.893574: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 09:42:13.449070: lr: 0.0\n",
      "2021-11-11 09:42:13.472069: saving checkpoint...\n",
      "2021-11-11 09:42:14.099756: done, saving took 0.65 seconds\n",
      "2021-11-11 09:42:14.121040: This epoch took 197.101225 s\n",
      "\n",
      "2021-11-11 09:42:14.144860: saving checkpoint...\n",
      "2021-11-11 09:42:14.656393: done, saving took 0.53 seconds\n",
      "23090557_20130717 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090560_20160114 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090562_20140206 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141215 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130626 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140124 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121015 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090597_20130227 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130208 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090621_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150105 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130807 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090637_20140401 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131126 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090644_20131216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-11 09:44:08.913683: finished prediction\n",
      "2021-11-11 09:44:08.918738: evaluation of raw predictions\n",
      "2021-11-11 09:44:10.436328: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8376967296569788\n",
      "after:  0.8399926958038051\n",
      "Removing all but the largest foreground region improved results!\n",
      "for_which_classes [1]\n",
      "min_valid_object_sizes None\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[[1]]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-11 09:44:20.039541: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-11 09:44:20.054375: The split file contains 5 splits.\n",
      "2021-11-11 09:44:20.058636: Desired fold for training: 4\n",
      "2021-11-11 09:44:20.062388: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-11 09:44:24.217781: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-11 09:44:37.507411: Unable to plot network architecture:\n",
      "2021-11-11 09:44:37.518600: No module named 'hiddenlayer'\n",
      "2021-11-11 09:44:37.522983: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-11 09:44:37.527227: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-11 09:44:37.560869: \n",
      "\n",
      "2021-11-11 09:44:37.566310: \n",
      "epoch:  0\n",
      "2021-11-11 09:47:54.804703: train loss : -0.3188\n",
      "2021-11-11 09:48:08.584030: validation loss: -0.6585\n",
      "2021-11-11 09:48:08.588377: Average global foreground Dice: [0.7269]\n",
      "2021-11-11 09:48:08.593360: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 09:48:09.063996: lr: 0.009549\n",
      "2021-11-11 09:48:09.067619: This epoch took 211.496924 s\n",
      "\n",
      "2021-11-11 09:48:09.071592: \n",
      "epoch:  1\n",
      "2021-11-11 09:51:08.485269: train loss : -0.6863\n",
      "2021-11-11 09:51:22.177531: validation loss: -0.7258\n",
      "2021-11-11 09:51:22.182997: Average global foreground Dice: [0.7926]\n",
      "2021-11-11 09:51:22.188174: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 09:51:22.757779: lr: 0.009095\n",
      "2021-11-11 09:51:22.799253: saving checkpoint...\n",
      "2021-11-11 09:51:23.359457: done, saving took 0.60 seconds\n",
      "2021-11-11 09:51:23.380916: This epoch took 194.305075 s\n",
      "\n",
      "2021-11-11 09:51:23.384767: \n",
      "epoch:  2\n",
      "2021-11-11 09:54:22.834330: train loss : -0.7606\n",
      "2021-11-11 09:54:36.534607: validation loss: -0.7958\n",
      "2021-11-11 09:54:36.540134: Average global foreground Dice: [0.8146]\n",
      "2021-11-11 09:54:36.544237: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 09:54:37.076452: lr: 0.008639\n",
      "2021-11-11 09:54:37.114263: saving checkpoint...\n",
      "2021-11-11 09:54:37.748042: done, saving took 0.67 seconds\n",
      "2021-11-11 09:54:37.774460: This epoch took 194.386271 s\n",
      "\n",
      "2021-11-11 09:54:37.779048: \n",
      "epoch:  3\n",
      "2021-11-11 09:57:36.916437: train loss : -0.7985\n",
      "2021-11-11 09:57:50.574741: validation loss: -0.8059\n",
      "2021-11-11 09:57:50.579522: Average global foreground Dice: [0.8192]\n",
      "2021-11-11 09:57:50.583853: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 09:57:51.091105: lr: 0.008181\n",
      "2021-11-11 09:57:51.120994: saving checkpoint...\n",
      "2021-11-11 09:57:51.772474: done, saving took 0.68 seconds\n",
      "2021-11-11 09:57:51.805650: This epoch took 194.022351 s\n",
      "\n",
      "2021-11-11 09:57:51.809872: \n",
      "epoch:  4\n",
      "2021-11-11 10:00:51.880028: train loss : -0.8141\n",
      "2021-11-11 10:01:05.652577: validation loss: -0.8100\n",
      "2021-11-11 10:01:05.657217: Average global foreground Dice: [0.8246]\n",
      "2021-11-11 10:01:05.660831: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 10:01:06.209958: lr: 0.007719\n",
      "2021-11-11 10:01:06.240943: saving checkpoint...\n",
      "2021-11-11 10:01:06.903305: done, saving took 0.69 seconds\n",
      "2021-11-11 10:01:06.937269: This epoch took 195.123830 s\n",
      "\n",
      "2021-11-11 10:01:06.941664: \n",
      "epoch:  5\n",
      "2021-11-11 10:04:07.346892: train loss : -0.8231\n",
      "2021-11-11 10:04:21.103677: validation loss: -0.8177\n",
      "2021-11-11 10:04:21.108092: Average global foreground Dice: [0.8296]\n",
      "2021-11-11 10:04:21.112525: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 10:04:21.630767: lr: 0.007254\n",
      "2021-11-11 10:04:21.663460: saving checkpoint...\n",
      "2021-11-11 10:04:22.314079: done, saving took 0.68 seconds\n",
      "2021-11-11 10:04:22.338887: This epoch took 195.392983 s\n",
      "\n",
      "2021-11-11 10:04:22.342894: \n",
      "epoch:  6\n",
      "2021-11-11 10:07:22.617291: train loss : -0.8298\n",
      "2021-11-11 10:07:36.360355: validation loss: -0.8255\n",
      "2021-11-11 10:07:36.365172: Average global foreground Dice: [0.8389]\n",
      "2021-11-11 10:07:36.369919: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 10:07:37.022469: lr: 0.006786\n",
      "2021-11-11 10:07:37.060199: saving checkpoint...\n",
      "2021-11-11 10:07:37.706728: done, saving took 0.68 seconds\n",
      "2021-11-11 10:07:37.738226: This epoch took 195.390715 s\n",
      "\n",
      "2021-11-11 10:07:37.742584: \n",
      "epoch:  7\n",
      "2021-11-11 10:10:38.170347: train loss : -0.8347\n",
      "2021-11-11 10:10:51.930759: validation loss: -0.8193\n",
      "2021-11-11 10:10:51.935464: Average global foreground Dice: [0.8325]\n",
      "2021-11-11 10:10:51.939167: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 10:10:52.502904: lr: 0.006314\n",
      "2021-11-11 10:10:52.540887: saving checkpoint...\n",
      "2021-11-11 10:10:53.180355: done, saving took 0.67 seconds\n",
      "2021-11-11 10:10:53.214185: This epoch took 195.467700 s\n",
      "\n",
      "2021-11-11 10:10:53.218127: \n",
      "epoch:  8\n",
      "2021-11-11 10:13:53.994816: train loss : -0.8374\n",
      "2021-11-11 10:14:07.778303: validation loss: -0.8244\n",
      "2021-11-11 10:14:07.783439: Average global foreground Dice: [0.8352]\n",
      "2021-11-11 10:14:07.788148: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 10:14:08.381448: lr: 0.005839\n",
      "2021-11-11 10:14:08.404526: saving checkpoint...\n",
      "2021-11-11 10:14:09.095504: done, saving took 0.71 seconds\n",
      "2021-11-11 10:14:09.124655: This epoch took 195.902572 s\n",
      "\n",
      "2021-11-11 10:14:09.128170: \n",
      "epoch:  9\n",
      "2021-11-11 10:17:09.952458: train loss : -0.8425\n",
      "2021-11-11 10:17:23.725371: validation loss: -0.8245\n",
      "2021-11-11 10:17:23.730924: Average global foreground Dice: [0.8375]\n",
      "2021-11-11 10:17:23.734972: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 10:17:24.273377: lr: 0.005359\n",
      "2021-11-11 10:17:24.296189: saving checkpoint...\n",
      "2021-11-11 10:17:24.947822: done, saving took 0.67 seconds\n",
      "2021-11-11 10:17:24.977960: This epoch took 195.844808 s\n",
      "\n",
      "2021-11-11 10:17:24.982600: \n",
      "epoch:  10\n",
      "2021-11-11 10:20:26.011891: train loss : -0.8453\n",
      "2021-11-11 10:20:39.793080: validation loss: -0.8310\n",
      "2021-11-11 10:20:39.798434: Average global foreground Dice: [0.8434]\n",
      "2021-11-11 10:20:39.802669: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 10:20:40.369604: lr: 0.004874\n",
      "2021-11-11 10:20:40.393377: saving checkpoint...\n",
      "2021-11-11 10:20:40.988789: done, saving took 0.61 seconds\n",
      "2021-11-11 10:20:41.017793: This epoch took 196.030429 s\n",
      "\n",
      "2021-11-11 10:20:41.022109: \n",
      "epoch:  11\n",
      "2021-11-11 10:23:41.978596: train loss : -0.8494\n",
      "2021-11-11 10:23:55.745295: validation loss: -0.8355\n",
      "2021-11-11 10:23:55.750878: Average global foreground Dice: [0.8468]\n",
      "2021-11-11 10:23:55.755609: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 10:23:56.332264: lr: 0.004384\n",
      "2021-11-11 10:23:56.355270: saving checkpoint...\n",
      "2021-11-11 10:23:56.989096: done, saving took 0.65 seconds\n",
      "2021-11-11 10:23:57.026357: This epoch took 195.999587 s\n",
      "\n",
      "2021-11-11 10:23:57.030019: \n",
      "epoch:  12\n",
      "2021-11-11 10:26:57.728416: train loss : -0.8526\n",
      "2021-11-11 10:27:11.476400: validation loss: -0.8270\n",
      "2021-11-11 10:27:11.481355: Average global foreground Dice: [0.8387]\n",
      "2021-11-11 10:27:11.485713: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 10:27:12.039541: lr: 0.003887\n",
      "2021-11-11 10:27:12.072697: saving checkpoint...\n",
      "2021-11-11 10:27:12.730485: done, saving took 0.69 seconds\n",
      "2021-11-11 10:27:12.752750: This epoch took 195.719054 s\n",
      "\n",
      "2021-11-11 10:27:12.756897: \n",
      "epoch:  13\n",
      "2021-11-11 10:30:13.472352: train loss : -0.8547\n",
      "2021-11-11 10:30:27.251471: validation loss: -0.8321\n",
      "2021-11-11 10:30:27.258006: Average global foreground Dice: [0.8421]\n",
      "2021-11-11 10:30:27.262392: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 10:30:27.810366: lr: 0.003384\n",
      "2021-11-11 10:30:27.843851: saving checkpoint...\n",
      "2021-11-11 10:30:28.495139: done, saving took 0.68 seconds\n",
      "2021-11-11 10:30:28.528057: This epoch took 195.766453 s\n",
      "\n",
      "2021-11-11 10:30:28.532833: \n",
      "epoch:  14\n",
      "2021-11-11 10:33:29.363805: train loss : -0.8577\n",
      "2021-11-11 10:33:43.130914: validation loss: -0.8319\n",
      "2021-11-11 10:33:43.136652: Average global foreground Dice: [0.8426]\n",
      "2021-11-11 10:33:43.142253: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 10:33:43.651585: lr: 0.002872\n",
      "2021-11-11 10:33:43.685996: saving checkpoint...\n",
      "2021-11-11 10:33:44.342627: done, saving took 0.69 seconds\n",
      "2021-11-11 10:33:44.375423: This epoch took 195.837639 s\n",
      "\n",
      "2021-11-11 10:33:44.379576: \n",
      "epoch:  15\n",
      "2021-11-11 10:36:45.227295: train loss : -0.8598\n",
      "2021-11-11 10:36:58.999678: validation loss: -0.8338\n",
      "2021-11-11 10:36:59.005629: Average global foreground Dice: [0.8433]\n",
      "2021-11-11 10:36:59.009805: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 10:36:59.564704: lr: 0.002349\n",
      "2021-11-11 10:36:59.599200: saving checkpoint...\n",
      "2021-11-11 10:37:00.229042: done, saving took 0.66 seconds\n",
      "2021-11-11 10:37:00.258096: This epoch took 195.874363 s\n",
      "\n",
      "2021-11-11 10:37:00.263228: \n",
      "epoch:  16\n",
      "2021-11-11 10:40:01.541645: train loss : -0.8618\n",
      "2021-11-11 10:40:15.295170: validation loss: -0.8395\n",
      "2021-11-11 10:40:15.300048: Average global foreground Dice: [0.8494]\n",
      "2021-11-11 10:40:15.304869: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 10:40:15.869577: lr: 0.001813\n",
      "2021-11-11 10:40:15.892692: saving checkpoint...\n",
      "2021-11-11 10:40:16.518875: done, saving took 0.64 seconds\n",
      "2021-11-11 10:40:16.546020: This epoch took 196.278139 s\n",
      "\n",
      "2021-11-11 10:40:16.550842: \n",
      "epoch:  17\n",
      "2021-11-11 10:43:17.752734: train loss : -0.8656\n",
      "2021-11-11 10:43:31.520779: validation loss: -0.8379\n",
      "2021-11-11 10:43:31.525111: Average global foreground Dice: [0.8483]\n",
      "2021-11-11 10:43:31.529176: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 10:43:32.078842: lr: 0.001259\n",
      "2021-11-11 10:43:32.102559: saving checkpoint...\n",
      "2021-11-11 10:43:32.716867: done, saving took 0.63 seconds\n",
      "2021-11-11 10:43:32.746084: This epoch took 196.190612 s\n",
      "\n",
      "2021-11-11 10:43:32.749675: \n",
      "epoch:  18\n",
      "2021-11-11 10:46:34.147197: train loss : -0.8683\n",
      "2021-11-11 10:46:47.908993: validation loss: -0.8370\n",
      "2021-11-11 10:46:47.914134: Average global foreground Dice: [0.847]\n",
      "2021-11-11 10:46:47.919060: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 10:46:48.446160: lr: 0.000675\n",
      "2021-11-11 10:46:48.472324: saving checkpoint...\n",
      "2021-11-11 10:46:49.112412: done, saving took 0.66 seconds\n",
      "2021-11-11 10:46:49.143000: This epoch took 196.388344 s\n",
      "\n",
      "2021-11-11 10:46:49.148555: \n",
      "epoch:  19\n",
      "2021-11-11 10:49:50.517067: train loss : -0.8695\n",
      "2021-11-11 10:50:04.262943: validation loss: -0.8377\n",
      "2021-11-11 10:50:04.268067: Average global foreground Dice: [0.8478]\n",
      "2021-11-11 10:50:04.272809: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 10:50:04.804027: lr: 0.0\n",
      "2021-11-11 10:50:04.827251: saving checkpoint...\n",
      "2021-11-11 10:50:05.483204: done, saving took 0.67 seconds\n",
      "2021-11-11 10:50:05.516177: This epoch took 196.362943 s\n",
      "\n",
      "2021-11-11 10:50:05.539945: saving checkpoint...\n",
      "2021-11-11 10:50:06.033741: done, saving took 0.51 seconds\n",
      "23090558_20120330 (3, 263, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090564_20130312 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090568_20121018 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090569_20120607 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120613 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150908 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090593_20120625 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130103 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090600_20121108 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090603_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090607_20120420 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090609_20120510 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160119 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160510 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090646_20120718 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-11 10:52:02.247344: finished prediction\n",
      "2021-11-11 10:52:02.253999: evaluation of raw predictions\n",
      "2021-11-11 10:52:03.704973: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8317533007525237\n",
      "after:  0.824449113372206\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Model 8 (epoch 20)\n",
    "\n",
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_CEGDL 555 0 --cuda_device 0\n",
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_CEGDL 555 1 --cuda_device 0\n",
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_CEGDL 555 2 --cuda_device 0\n",
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_CEGDL 555 3 --cuda_device 0\n",
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_CEGDL 555 4 --cuda_device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_DiceTopK10.nnUNetTrainerV2_Loss_DiceTopK10'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-11 10:52:13.319699: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-11 10:52:13.332848: The split file contains 5 splits.\n",
      "2021-11-11 10:52:13.336771: Desired fold for training: 0\n",
      "2021-11-11 10:52:13.341165: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-11 10:52:17.514271: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-11 10:52:27.312337: Unable to plot network architecture:\n",
      "2021-11-11 10:52:27.316867: No module named 'hiddenlayer'\n",
      "2021-11-11 10:52:27.320843: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-11 10:52:27.324744: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-11 10:52:27.332383: \n",
      "\n",
      "2021-11-11 10:52:27.363312: \n",
      "epoch:  0\n",
      "2021-11-11 10:55:57.959281: train loss : -0.2539\n",
      "2021-11-11 10:56:13.886333: validation loss: -0.6698\n",
      "2021-11-11 10:56:13.891316: Average global foreground Dice: [0.7415]\n",
      "2021-11-11 10:56:13.895157: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 10:56:14.384619: lr: 0.009549\n",
      "2021-11-11 10:56:14.389221: This epoch took 227.021626 s\n",
      "\n",
      "2021-11-11 10:56:14.393807: \n",
      "epoch:  1\n",
      "2021-11-11 10:59:27.503562: train loss : -0.6978\n",
      "2021-11-11 10:59:43.419136: validation loss: -0.7720\n",
      "2021-11-11 10:59:43.426724: Average global foreground Dice: [0.8193]\n",
      "2021-11-11 10:59:43.431112: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 10:59:44.024370: lr: 0.009095\n",
      "2021-11-11 10:59:44.066547: saving checkpoint...\n",
      "2021-11-11 10:59:44.623961: done, saving took 0.60 seconds\n",
      "2021-11-11 10:59:44.652725: This epoch took 210.255421 s\n",
      "\n",
      "2021-11-11 10:59:44.656610: \n",
      "epoch:  2\n",
      "2021-11-11 11:02:57.647605: train loss : -0.7568\n",
      "2021-11-11 11:03:13.548246: validation loss: -0.7930\n",
      "2021-11-11 11:03:13.552826: Average global foreground Dice: [0.8368]\n",
      "2021-11-11 11:03:13.556563: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 11:03:14.080682: lr: 0.008639\n",
      "2021-11-11 11:03:14.116581: saving checkpoint...\n",
      "2021-11-11 11:03:14.797858: done, saving took 0.71 seconds\n",
      "2021-11-11 11:03:14.828559: This epoch took 210.167962 s\n",
      "\n",
      "2021-11-11 11:03:14.833166: \n",
      "epoch:  3\n",
      "2021-11-11 11:06:27.680991: train loss : -0.7803\n",
      "2021-11-11 11:06:43.586128: validation loss: -0.7933\n",
      "2021-11-11 11:06:43.595612: Average global foreground Dice: [0.8342]\n",
      "2021-11-11 11:06:43.599147: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 11:06:44.127012: lr: 0.008181\n",
      "2021-11-11 11:06:44.149471: saving checkpoint...\n",
      "2021-11-11 11:06:44.817276: done, saving took 0.69 seconds\n",
      "2021-11-11 11:06:44.850886: This epoch took 210.013836 s\n",
      "\n",
      "2021-11-11 11:06:44.854843: \n",
      "epoch:  4\n",
      "2021-11-11 11:09:57.715820: train loss : -0.7983\n",
      "2021-11-11 11:10:13.650542: validation loss: -0.8006\n",
      "2021-11-11 11:10:13.655771: Average global foreground Dice: [0.8391]\n",
      "2021-11-11 11:10:13.660663: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 11:10:14.204436: lr: 0.007719\n",
      "2021-11-11 11:10:14.244173: saving checkpoint...\n",
      "2021-11-11 11:10:14.882001: done, saving took 0.67 seconds\n",
      "2021-11-11 11:10:14.905962: This epoch took 210.046723 s\n",
      "\n",
      "2021-11-11 11:10:14.910197: \n",
      "epoch:  5\n",
      "2021-11-11 11:13:27.735619: train loss : -0.8060\n",
      "2021-11-11 11:13:43.653076: validation loss: -0.8084\n",
      "2021-11-11 11:13:43.658453: Average global foreground Dice: [0.8441]\n",
      "2021-11-11 11:13:43.662798: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 11:13:44.206320: lr: 0.007254\n",
      "2021-11-11 11:13:44.229606: saving checkpoint...\n",
      "2021-11-11 11:13:44.866585: done, saving took 0.66 seconds\n",
      "2021-11-11 11:13:44.896696: This epoch took 209.981712 s\n",
      "\n",
      "2021-11-11 11:13:44.900397: \n",
      "epoch:  6\n",
      "2021-11-11 11:16:57.729994: train loss : -0.8109\n",
      "2021-11-11 11:17:13.630603: validation loss: -0.8124\n",
      "2021-11-11 11:17:13.635421: Average global foreground Dice: [0.8489]\n",
      "2021-11-11 11:17:13.639456: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 11:17:14.178787: lr: 0.006786\n",
      "2021-11-11 11:17:14.201799: saving checkpoint...\n",
      "2021-11-11 11:17:14.918331: done, saving took 0.74 seconds\n",
      "2021-11-11 11:17:14.942391: This epoch took 210.037182 s\n",
      "\n",
      "2021-11-11 11:17:14.946861: \n",
      "epoch:  7\n",
      "2021-11-11 11:20:27.809422: train loss : -0.8182\n",
      "2021-11-11 11:20:43.709030: validation loss: -0.8041\n",
      "2021-11-11 11:20:43.714072: Average global foreground Dice: [0.8435]\n",
      "2021-11-11 11:20:43.718407: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 11:20:44.222310: lr: 0.006314\n",
      "2021-11-11 11:20:44.245408: saving checkpoint...\n",
      "2021-11-11 11:20:44.878856: done, saving took 0.65 seconds\n",
      "2021-11-11 11:20:44.904743: This epoch took 209.953875 s\n",
      "\n",
      "2021-11-11 11:20:44.909059: \n",
      "epoch:  8\n",
      "2021-11-11 11:23:57.832019: train loss : -0.8229\n",
      "2021-11-11 11:24:13.737455: validation loss: -0.8224\n",
      "2021-11-11 11:24:13.741723: Average global foreground Dice: [0.8553]\n",
      "2021-11-11 11:24:13.745689: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 11:24:14.286779: lr: 0.005839\n",
      "2021-11-11 11:24:14.309120: saving checkpoint...\n",
      "2021-11-11 11:24:14.928739: done, saving took 0.64 seconds\n",
      "2021-11-11 11:24:14.955591: This epoch took 210.042222 s\n",
      "\n",
      "2021-11-11 11:24:14.959587: \n",
      "epoch:  9\n",
      "2021-11-11 11:27:27.846588: train loss : -0.8303\n",
      "2021-11-11 11:27:43.766366: validation loss: -0.8074\n",
      "2021-11-11 11:27:43.771750: Average global foreground Dice: [0.845]\n",
      "2021-11-11 11:27:43.777090: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 11:27:44.297139: lr: 0.005359\n",
      "2021-11-11 11:27:44.336092: saving checkpoint...\n",
      "2021-11-11 11:27:45.024215: done, saving took 0.72 seconds\n",
      "2021-11-11 11:27:45.049820: This epoch took 210.085760 s\n",
      "\n",
      "2021-11-11 11:27:45.054730: \n",
      "epoch:  10\n",
      "2021-11-11 11:30:57.946863: train loss : -0.8341\n",
      "2021-11-11 11:31:13.864188: validation loss: -0.8074\n",
      "2021-11-11 11:31:13.870185: Average global foreground Dice: [0.8428]\n",
      "2021-11-11 11:31:13.874761: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 11:31:14.426791: lr: 0.004874\n",
      "2021-11-11 11:31:14.466308: saving checkpoint...\n",
      "2021-11-11 11:31:15.110311: done, saving took 0.68 seconds\n",
      "2021-11-11 11:31:15.144469: This epoch took 210.085335 s\n",
      "\n",
      "2021-11-11 11:31:15.148600: \n",
      "epoch:  11\n",
      "2021-11-11 11:34:28.055501: train loss : -0.8351\n",
      "2021-11-11 11:34:43.955888: validation loss: -0.8025\n",
      "2021-11-11 11:34:43.961169: Average global foreground Dice: [0.8391]\n",
      "2021-11-11 11:34:43.965691: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 11:34:44.505215: lr: 0.004384\n",
      "2021-11-11 11:34:44.527825: saving checkpoint...\n",
      "2021-11-11 11:34:45.160898: done, saving took 0.65 seconds\n",
      "2021-11-11 11:34:45.191808: This epoch took 210.039087 s\n",
      "\n",
      "2021-11-11 11:34:45.195804: \n",
      "epoch:  12\n",
      "2021-11-11 11:37:58.060888: train loss : -0.8395\n",
      "2021-11-11 11:38:13.985713: validation loss: -0.8091\n",
      "2021-11-11 11:38:13.991016: Average global foreground Dice: [0.8457]\n",
      "2021-11-11 11:38:13.995305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 11:38:14.570559: lr: 0.003887\n",
      "2021-11-11 11:38:14.606087: saving checkpoint...\n",
      "2021-11-11 11:38:15.225363: done, saving took 0.65 seconds\n",
      "2021-11-11 11:38:15.255507: This epoch took 210.055127 s\n",
      "\n",
      "2021-11-11 11:38:15.259999: \n",
      "epoch:  13\n",
      "2021-11-11 11:41:28.159764: train loss : -0.8421\n",
      "2021-11-11 11:41:44.085726: validation loss: -0.8081\n",
      "2021-11-11 11:41:44.091083: Average global foreground Dice: [0.8441]\n",
      "2021-11-11 11:41:44.094561: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 11:41:44.597185: lr: 0.003384\n",
      "2021-11-11 11:41:44.620446: saving checkpoint...\n",
      "2021-11-11 11:41:45.274034: done, saving took 0.67 seconds\n",
      "2021-11-11 11:41:45.295960: This epoch took 210.030668 s\n",
      "\n",
      "2021-11-11 11:41:45.300446: \n",
      "epoch:  14\n",
      "2021-11-11 11:44:58.190465: train loss : -0.8457\n",
      "2021-11-11 11:45:14.119007: validation loss: -0.8022\n",
      "2021-11-11 11:45:14.124739: Average global foreground Dice: [0.8395]\n",
      "2021-11-11 11:45:14.129149: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 11:45:14.701072: lr: 0.002872\n",
      "2021-11-11 11:45:14.736455: saving checkpoint...\n",
      "2021-11-11 11:45:15.332843: done, saving took 0.63 seconds\n",
      "2021-11-11 11:45:15.355877: This epoch took 210.050910 s\n",
      "\n",
      "2021-11-11 11:45:15.359759: \n",
      "epoch:  15\n",
      "2021-11-11 11:48:28.251489: train loss : -0.8494\n",
      "2021-11-11 11:48:44.173776: validation loss: -0.8042\n",
      "2021-11-11 11:48:44.179555: Average global foreground Dice: [0.8413]\n",
      "2021-11-11 11:48:44.184100: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 11:48:44.697041: lr: 0.002349\n",
      "2021-11-11 11:48:44.732401: saving checkpoint...\n",
      "2021-11-11 11:48:45.416956: done, saving took 0.72 seconds\n",
      "2021-11-11 11:48:45.444775: This epoch took 210.080321 s\n",
      "\n",
      "2021-11-11 11:48:45.449460: \n",
      "epoch:  16\n",
      "2021-11-11 11:51:58.756206: train loss : -0.8514\n",
      "2021-11-11 11:52:14.698190: validation loss: -0.8078\n",
      "2021-11-11 11:52:14.702987: Average global foreground Dice: [0.8453]\n",
      "2021-11-11 11:52:14.707833: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 11:52:15.255391: lr: 0.001813\n",
      "2021-11-11 11:52:15.278790: saving checkpoint...\n",
      "2021-11-11 11:52:15.916776: done, saving took 0.66 seconds\n",
      "2021-11-11 11:52:15.941481: This epoch took 210.487338 s\n",
      "\n",
      "2021-11-11 11:52:15.945572: \n",
      "epoch:  17\n",
      "2021-11-11 11:55:29.062570: train loss : -0.8546\n",
      "2021-11-11 11:55:44.972360: validation loss: -0.8076\n",
      "2021-11-11 11:55:44.977380: Average global foreground Dice: [0.8426]\n",
      "2021-11-11 11:55:44.982269: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 11:55:45.563868: lr: 0.001259\n",
      "2021-11-11 11:55:45.592159: saving checkpoint...\n",
      "2021-11-11 11:55:46.244941: done, saving took 0.68 seconds\n",
      "2021-11-11 11:55:46.270170: This epoch took 210.320194 s\n",
      "\n",
      "2021-11-11 11:55:46.274903: \n",
      "epoch:  18\n",
      "2021-11-11 11:58:59.463516: train loss : -0.8572\n",
      "2021-11-11 11:59:15.367088: validation loss: -0.8105\n",
      "2021-11-11 11:59:15.372745: Average global foreground Dice: [0.8458]\n",
      "2021-11-11 11:59:15.377119: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 11:59:15.890191: lr: 0.000675\n",
      "2021-11-11 11:59:15.913405: saving checkpoint...\n",
      "2021-11-11 11:59:16.531188: done, saving took 0.64 seconds\n",
      "2021-11-11 11:59:16.565488: This epoch took 210.287050 s\n",
      "\n",
      "2021-11-11 11:59:16.569989: \n",
      "epoch:  19\n",
      "2021-11-11 12:02:29.892054: train loss : -0.8594\n",
      "2021-11-11 12:02:45.808882: validation loss: -0.8043\n",
      "2021-11-11 12:02:45.813908: Average global foreground Dice: [0.8418]\n",
      "2021-11-11 12:02:45.818129: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 12:02:46.345285: lr: 0.0\n",
      "2021-11-11 12:02:46.368389: saving checkpoint...\n",
      "2021-11-11 12:02:47.010727: done, saving took 0.66 seconds\n",
      "2021-11-11 12:02:47.033127: This epoch took 210.458543 s\n",
      "\n",
      "2021-11-11 12:02:47.055937: saving checkpoint...\n",
      "2021-11-11 12:02:47.571043: done, saving took 0.53 seconds\n",
      "23090559_20150812 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120330 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090563_20151216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130226 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090584_20120523 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090589_20140219 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090592_20130218 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090614_20120402 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090620_20130617 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090627_20160608 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090628_20150204 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090635_20140710 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090640_20140711 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121227 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-11 12:04:45.815070: finished prediction\n",
      "2021-11-11 12:04:45.820237: evaluation of raw predictions\n",
      "2021-11-11 12:04:47.381964: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.834260413266904\n",
      "after:  0.8338661535808829\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_DiceTopK10.nnUNetTrainerV2_Loss_DiceTopK10'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-11 12:04:56.509379: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-11 12:04:56.526241: The split file contains 5 splits.\n",
      "2021-11-11 12:04:56.530049: Desired fold for training: 1\n",
      "2021-11-11 12:04:56.534619: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-11 12:05:00.741880: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-11 12:05:09.962521: Unable to plot network architecture:\n",
      "2021-11-11 12:05:09.966875: No module named 'hiddenlayer'\n",
      "2021-11-11 12:05:09.971488: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-11 12:05:09.975593: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-11 12:05:09.982626: \n",
      "\n",
      "2021-11-11 12:05:09.986762: \n",
      "epoch:  0\n",
      "2021-11-11 12:08:40.518656: train loss : -0.2109\n",
      "2021-11-11 12:08:56.393398: validation loss: -0.6395\n",
      "2021-11-11 12:08:56.397620: Average global foreground Dice: [0.7093]\n",
      "2021-11-11 12:08:56.402437: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 12:08:56.819702: lr: 0.009549\n",
      "2021-11-11 12:08:56.824390: This epoch took 226.832981 s\n",
      "\n",
      "2021-11-11 12:08:56.828818: \n",
      "epoch:  1\n",
      "2021-11-11 12:12:09.695845: train loss : -0.6837\n",
      "2021-11-11 12:12:25.604103: validation loss: -0.7376\n",
      "2021-11-11 12:12:25.608803: Average global foreground Dice: [0.7881]\n",
      "2021-11-11 12:12:25.613431: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 12:12:26.221956: lr: 0.009095\n",
      "2021-11-11 12:12:26.266964: saving checkpoint...\n",
      "2021-11-11 12:12:26.769022: done, saving took 0.54 seconds\n",
      "2021-11-11 12:12:26.785689: This epoch took 209.952537 s\n",
      "\n",
      "2021-11-11 12:12:26.789362: \n",
      "epoch:  2\n",
      "2021-11-11 12:15:39.644432: train loss : -0.7548\n",
      "2021-11-11 12:15:55.548415: validation loss: -0.7783\n",
      "2021-11-11 12:15:55.552808: Average global foreground Dice: [0.8191]\n",
      "2021-11-11 12:15:55.557329: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 12:15:56.056008: lr: 0.008639\n",
      "2021-11-11 12:15:56.091002: saving checkpoint...\n",
      "2021-11-11 12:15:56.751613: done, saving took 0.69 seconds\n",
      "2021-11-11 12:15:56.773624: This epoch took 209.980911 s\n",
      "\n",
      "2021-11-11 12:15:56.777697: \n",
      "epoch:  3\n",
      "2021-11-11 12:19:09.587361: train loss : -0.7808\n",
      "2021-11-11 12:19:25.485427: validation loss: -0.7847\n",
      "2021-11-11 12:19:25.490779: Average global foreground Dice: [0.8214]\n",
      "2021-11-11 12:19:25.495403: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 12:19:26.007981: lr: 0.008181\n",
      "2021-11-11 12:19:26.049296: saving checkpoint...\n",
      "2021-11-11 12:19:26.683768: done, saving took 0.67 seconds\n",
      "2021-11-11 12:19:26.704870: This epoch took 209.923248 s\n",
      "\n",
      "2021-11-11 12:19:26.710063: \n",
      "epoch:  4\n",
      "2021-11-11 12:22:39.552626: train loss : -0.7972\n",
      "2021-11-11 12:22:55.433331: validation loss: -0.7896\n",
      "2021-11-11 12:22:55.437454: Average global foreground Dice: [0.8228]\n",
      "2021-11-11 12:22:55.441423: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 12:22:55.998109: lr: 0.007719\n",
      "2021-11-11 12:22:56.038956: saving checkpoint...\n",
      "2021-11-11 12:22:56.645641: done, saving took 0.64 seconds\n",
      "2021-11-11 12:22:56.669238: This epoch took 209.955347 s\n",
      "\n",
      "2021-11-11 12:22:56.672897: \n",
      "epoch:  5\n",
      "2021-11-11 12:26:09.497669: train loss : -0.8065\n",
      "2021-11-11 12:26:25.383701: validation loss: -0.7900\n",
      "2021-11-11 12:26:25.388679: Average global foreground Dice: [0.8298]\n",
      "2021-11-11 12:26:25.392731: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 12:26:25.894757: lr: 0.007254\n",
      "2021-11-11 12:26:25.928924: saving checkpoint...\n",
      "2021-11-11 12:26:26.568612: done, saving took 0.67 seconds\n",
      "2021-11-11 12:26:26.591462: This epoch took 209.914825 s\n",
      "\n",
      "2021-11-11 12:26:26.596263: \n",
      "epoch:  6\n",
      "2021-11-11 12:29:39.442712: train loss : -0.8118\n",
      "2021-11-11 12:29:55.340193: validation loss: -0.7993\n",
      "2021-11-11 12:29:55.345156: Average global foreground Dice: [0.833]\n",
      "2021-11-11 12:29:55.349170: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 12:29:55.918194: lr: 0.006786\n",
      "2021-11-11 12:29:55.950287: saving checkpoint...\n",
      "2021-11-11 12:29:56.578083: done, saving took 0.66 seconds\n",
      "2021-11-11 12:29:56.600402: This epoch took 209.999136 s\n",
      "\n",
      "2021-11-11 12:29:56.604752: \n",
      "epoch:  7\n",
      "2021-11-11 12:33:09.447182: train loss : -0.8204\n",
      "2021-11-11 12:33:25.318871: validation loss: -0.8030\n",
      "2021-11-11 12:33:25.324016: Average global foreground Dice: [0.8362]\n",
      "2021-11-11 12:33:25.328344: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 12:33:25.834999: lr: 0.006314\n",
      "2021-11-11 12:33:25.877116: saving checkpoint...\n",
      "2021-11-11 12:33:26.529939: done, saving took 0.69 seconds\n",
      "2021-11-11 12:33:26.551275: This epoch took 209.942771 s\n",
      "\n",
      "2021-11-11 12:33:26.554951: \n",
      "epoch:  8\n",
      "2021-11-11 12:36:39.409301: train loss : -0.8249\n",
      "2021-11-11 12:36:55.290700: validation loss: -0.7982\n",
      "2021-11-11 12:36:55.294916: Average global foreground Dice: [0.8292]\n",
      "2021-11-11 12:36:55.298670: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 12:36:55.792359: lr: 0.005839\n",
      "2021-11-11 12:36:55.815816: saving checkpoint...\n",
      "2021-11-11 12:36:56.444263: done, saving took 0.65 seconds\n",
      "2021-11-11 12:36:56.466228: This epoch took 209.906054 s\n",
      "\n",
      "2021-11-11 12:36:56.470221: \n",
      "epoch:  9\n",
      "2021-11-11 12:40:09.342134: train loss : -0.8283\n",
      "2021-11-11 12:40:25.229571: validation loss: -0.8051\n",
      "2021-11-11 12:40:25.235193: Average global foreground Dice: [0.8364]\n",
      "2021-11-11 12:40:25.239277: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 12:40:25.727134: lr: 0.005359\n",
      "2021-11-11 12:40:25.750035: saving checkpoint...\n",
      "2021-11-11 12:40:26.398804: done, saving took 0.67 seconds\n",
      "2021-11-11 12:40:26.421249: This epoch took 209.946414 s\n",
      "\n",
      "2021-11-11 12:40:26.425940: \n",
      "epoch:  10\n",
      "2021-11-11 12:43:39.257859: train loss : -0.8323\n",
      "2021-11-11 12:43:55.136709: validation loss: -0.8057\n",
      "2021-11-11 12:43:55.142404: Average global foreground Dice: [0.8368]\n",
      "2021-11-11 12:43:55.146859: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 12:43:55.641998: lr: 0.004874\n",
      "2021-11-11 12:43:55.664948: saving checkpoint...\n",
      "2021-11-11 12:43:56.295556: done, saving took 0.65 seconds\n",
      "2021-11-11 12:43:56.316894: This epoch took 209.886776 s\n",
      "\n",
      "2021-11-11 12:43:56.321357: \n",
      "epoch:  11\n",
      "2021-11-11 12:47:09.238186: train loss : -0.8359\n",
      "2021-11-11 12:47:25.106755: validation loss: -0.7996\n",
      "2021-11-11 12:47:25.111398: Average global foreground Dice: [0.833]\n",
      "2021-11-11 12:47:25.116575: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 12:47:25.717129: lr: 0.004384\n",
      "2021-11-11 12:47:25.739561: saving checkpoint...\n",
      "2021-11-11 12:47:26.376154: done, saving took 0.65 seconds\n",
      "2021-11-11 12:47:26.398412: This epoch took 210.072673 s\n",
      "\n",
      "2021-11-11 12:47:26.402437: \n",
      "epoch:  12\n",
      "2021-11-11 12:50:39.328355: train loss : -0.8386\n",
      "2021-11-11 12:50:55.224138: validation loss: -0.8101\n",
      "2021-11-11 12:50:55.229083: Average global foreground Dice: [0.8402]\n",
      "2021-11-11 12:50:55.233796: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 12:50:55.738961: lr: 0.003887\n",
      "2021-11-11 12:50:55.762658: saving checkpoint...\n",
      "2021-11-11 12:50:56.370403: done, saving took 0.63 seconds\n",
      "2021-11-11 12:50:56.394130: This epoch took 209.986984 s\n",
      "\n",
      "2021-11-11 12:50:56.399227: \n",
      "epoch:  13\n",
      "2021-11-11 12:54:09.253120: train loss : -0.8415\n",
      "2021-11-11 12:54:25.127472: validation loss: -0.7992\n",
      "2021-11-11 12:54:25.132226: Average global foreground Dice: [0.8322]\n",
      "2021-11-11 12:54:25.136979: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 12:54:25.627620: lr: 0.003384\n",
      "2021-11-11 12:54:25.663278: saving checkpoint...\n",
      "2021-11-11 12:54:26.253918: done, saving took 0.62 seconds\n",
      "2021-11-11 12:54:26.274762: This epoch took 209.870684 s\n",
      "\n",
      "2021-11-11 12:54:26.278930: \n",
      "epoch:  14\n",
      "2021-11-11 12:57:39.160232: train loss : -0.8452\n",
      "2021-11-11 12:57:55.038241: validation loss: -0.8018\n",
      "2021-11-11 12:57:55.042788: Average global foreground Dice: [0.8363]\n",
      "2021-11-11 12:57:55.047551: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 12:57:55.562872: lr: 0.002872\n",
      "2021-11-11 12:57:55.586712: saving checkpoint...\n",
      "2021-11-11 12:57:56.206951: done, saving took 0.64 seconds\n",
      "2021-11-11 12:57:56.229819: This epoch took 209.946155 s\n",
      "\n",
      "2021-11-11 12:57:56.233934: \n",
      "epoch:  15\n",
      "2021-11-11 13:01:09.114151: train loss : -0.8468\n",
      "2021-11-11 13:01:24.983153: validation loss: -0.8080\n",
      "2021-11-11 13:01:24.988014: Average global foreground Dice: [0.8386]\n",
      "2021-11-11 13:01:24.992189: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 13:01:25.493495: lr: 0.002349\n",
      "2021-11-11 13:01:25.517005: saving checkpoint...\n",
      "2021-11-11 13:01:26.152194: done, saving took 0.65 seconds\n",
      "2021-11-11 13:01:26.174672: This epoch took 209.936733 s\n",
      "\n",
      "2021-11-11 13:01:26.178802: \n",
      "epoch:  16\n",
      "2021-11-11 13:04:39.135154: train loss : -0.8514\n",
      "2021-11-11 13:04:55.017316: validation loss: -0.8072\n",
      "2021-11-11 13:04:55.023079: Average global foreground Dice: [0.8376]\n",
      "2021-11-11 13:04:55.027378: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 13:04:55.538217: lr: 0.001813\n",
      "2021-11-11 13:04:55.562493: saving checkpoint...\n",
      "2021-11-11 13:04:56.256227: done, saving took 0.71 seconds\n",
      "2021-11-11 13:04:56.279157: This epoch took 210.095767 s\n",
      "\n",
      "2021-11-11 13:04:56.283972: \n",
      "epoch:  17\n",
      "2021-11-11 13:08:09.246187: train loss : -0.8540\n",
      "2021-11-11 13:08:25.130618: validation loss: -0.8106\n",
      "2021-11-11 13:08:25.135623: Average global foreground Dice: [0.842]\n",
      "2021-11-11 13:08:25.140013: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 13:08:25.651936: lr: 0.001259\n",
      "2021-11-11 13:08:25.675540: saving checkpoint...\n",
      "2021-11-11 13:08:26.368666: done, saving took 0.71 seconds\n",
      "2021-11-11 13:08:26.391105: This epoch took 210.102203 s\n",
      "\n",
      "2021-11-11 13:08:26.395467: \n",
      "epoch:  18\n",
      "2021-11-11 13:11:39.315825: train loss : -0.8562\n",
      "2021-11-11 13:11:55.189715: validation loss: -0.8057\n",
      "2021-11-11 13:11:55.194941: Average global foreground Dice: [0.8367]\n",
      "2021-11-11 13:11:55.199562: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 13:11:55.754897: lr: 0.000675\n",
      "2021-11-11 13:11:55.778454: saving checkpoint...\n",
      "2021-11-11 13:11:56.396999: done, saving took 0.64 seconds\n",
      "2021-11-11 13:11:56.420163: This epoch took 210.019059 s\n",
      "\n",
      "2021-11-11 13:11:56.425211: \n",
      "epoch:  19\n",
      "2021-11-11 13:15:09.345138: train loss : -0.8590\n",
      "2021-11-11 13:15:25.221954: validation loss: -0.8088\n",
      "2021-11-11 13:15:25.228625: Average global foreground Dice: [0.8393]\n",
      "2021-11-11 13:15:25.233673: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 13:15:25.735620: lr: 0.0\n",
      "2021-11-11 13:15:25.758086: saving checkpoint...\n",
      "2021-11-11 13:15:26.400183: done, saving took 0.66 seconds\n",
      "2021-11-11 13:15:26.423136: This epoch took 209.994046 s\n",
      "\n",
      "2021-11-11 13:15:26.446579: saving checkpoint...\n",
      "2021-11-11 13:15:26.947282: done, saving took 0.52 seconds\n",
      "23090567_20160819 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150401 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130213 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120627 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090590_20121212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160706 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090599_20140701 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130225 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090604_20140303 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090615_20140403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090617_20140211 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120406 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160111 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130213 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090631_20130128 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090634_20150409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-11 13:17:24.591617: finished prediction\n",
      "2021-11-11 13:17:24.596430: evaluation of raw predictions\n",
      "2021-11-11 13:17:26.077452: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8346843474961883\n",
      "after:  0.8346295053484456\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_DiceTopK10.nnUNetTrainerV2_Loss_DiceTopK10'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-11 13:17:35.545634: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-11 13:17:35.559916: The split file contains 5 splits.\n",
      "2021-11-11 13:17:35.564221: Desired fold for training: 2\n",
      "2021-11-11 13:17:35.568023: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-11 13:17:39.759174: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-11 13:17:49.727553: Unable to plot network architecture:\n",
      "2021-11-11 13:17:49.766736: No module named 'hiddenlayer'\n",
      "2021-11-11 13:17:49.771416: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-11 13:17:49.775593: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-11 13:17:49.784163: \n",
      "\n",
      "2021-11-11 13:17:49.788387: \n",
      "epoch:  0\n",
      "2021-11-11 13:21:21.983118: train loss : -0.1706\n",
      "2021-11-11 13:21:38.209276: validation loss: -0.6327\n",
      "2021-11-11 13:21:38.213651: Average global foreground Dice: [0.6989]\n",
      "2021-11-11 13:21:38.218452: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 13:21:38.630810: lr: 0.009549\n",
      "2021-11-11 13:21:38.635207: This epoch took 228.842577 s\n",
      "\n",
      "2021-11-11 13:21:38.639117: \n",
      "epoch:  1\n",
      "2021-11-11 13:24:52.292745: train loss : -0.6760\n",
      "2021-11-11 13:25:08.507557: validation loss: -0.7441\n",
      "2021-11-11 13:25:08.512485: Average global foreground Dice: [0.7895]\n",
      "2021-11-11 13:25:08.517167: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 13:25:09.116533: lr: 0.009095\n",
      "2021-11-11 13:25:09.151688: saving checkpoint...\n",
      "2021-11-11 13:25:09.679189: done, saving took 0.56 seconds\n",
      "2021-11-11 13:25:09.695006: This epoch took 211.051726 s\n",
      "\n",
      "2021-11-11 13:25:09.698714: \n",
      "epoch:  2\n",
      "2021-11-11 13:28:24.423995: train loss : -0.7565\n",
      "2021-11-11 13:28:40.651082: validation loss: -0.7747\n",
      "2021-11-11 13:28:40.655689: Average global foreground Dice: [0.8132]\n",
      "2021-11-11 13:28:40.660661: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 13:28:41.218153: lr: 0.008639\n",
      "2021-11-11 13:28:41.263561: saving checkpoint...\n",
      "2021-11-11 13:28:41.921261: done, saving took 0.70 seconds\n",
      "2021-11-11 13:28:41.953075: This epoch took 212.250531 s\n",
      "\n",
      "2021-11-11 13:28:41.957438: \n",
      "epoch:  3\n",
      "2021-11-11 13:31:56.895545: train loss : -0.7834\n",
      "2021-11-11 13:32:13.136584: validation loss: -0.7810\n",
      "2021-11-11 13:32:13.141972: Average global foreground Dice: [0.8184]\n",
      "2021-11-11 13:32:13.146479: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 13:32:13.688327: lr: 0.008181\n",
      "2021-11-11 13:32:13.734379: saving checkpoint...\n",
      "2021-11-11 13:32:14.392450: done, saving took 0.70 seconds\n",
      "2021-11-11 13:32:14.413919: This epoch took 212.452358 s\n",
      "\n",
      "2021-11-11 13:32:14.418594: \n",
      "epoch:  4\n",
      "2021-11-11 13:35:29.592144: train loss : -0.7980\n",
      "2021-11-11 13:35:45.836230: validation loss: -0.7956\n",
      "2021-11-11 13:35:45.841355: Average global foreground Dice: [0.8312]\n",
      "2021-11-11 13:35:45.846037: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 13:35:46.356297: lr: 0.007719\n",
      "2021-11-11 13:35:46.378366: saving checkpoint...\n",
      "2021-11-11 13:35:47.066612: done, saving took 0.71 seconds\n",
      "2021-11-11 13:35:47.095111: This epoch took 212.673007 s\n",
      "\n",
      "2021-11-11 13:35:47.098737: \n",
      "epoch:  5\n",
      "2021-11-11 13:39:02.186541: train loss : -0.8093\n",
      "2021-11-11 13:39:18.426028: validation loss: -0.7936\n",
      "2021-11-11 13:39:18.430869: Average global foreground Dice: [0.8258]\n",
      "2021-11-11 13:39:18.434502: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 13:39:18.926961: lr: 0.007254\n",
      "2021-11-11 13:39:18.949909: saving checkpoint...\n",
      "2021-11-11 13:39:19.588365: done, saving took 0.66 seconds\n",
      "2021-11-11 13:39:19.614515: This epoch took 212.511751 s\n",
      "\n",
      "2021-11-11 13:39:19.618006: \n",
      "epoch:  6\n",
      "2021-11-11 13:42:34.864345: train loss : -0.8162\n",
      "2021-11-11 13:42:51.119608: validation loss: -0.7962\n",
      "2021-11-11 13:42:51.125050: Average global foreground Dice: [0.8306]\n",
      "2021-11-11 13:42:51.129216: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 13:42:51.709307: lr: 0.006786\n",
      "2021-11-11 13:42:51.732330: saving checkpoint...\n",
      "2021-11-11 13:42:52.388362: done, saving took 0.67 seconds\n",
      "2021-11-11 13:42:52.413080: This epoch took 212.790591 s\n",
      "\n",
      "2021-11-11 13:42:52.417046: \n",
      "epoch:  7\n",
      "2021-11-11 13:46:07.782770: train loss : -0.8221\n",
      "2021-11-11 13:46:24.017215: validation loss: -0.7948\n",
      "2021-11-11 13:46:24.022773: Average global foreground Dice: [0.8287]\n",
      "2021-11-11 13:46:24.027460: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 13:46:24.566279: lr: 0.006314\n",
      "2021-11-11 13:46:24.588718: saving checkpoint...\n",
      "2021-11-11 13:46:25.250811: done, saving took 0.68 seconds\n",
      "2021-11-11 13:46:25.270887: This epoch took 212.850259 s\n",
      "\n",
      "2021-11-11 13:46:25.275084: \n",
      "epoch:  8\n",
      "2021-11-11 13:49:41.229576: train loss : -0.8297\n",
      "2021-11-11 13:49:57.506215: validation loss: -0.7986\n",
      "2021-11-11 13:49:57.511959: Average global foreground Dice: [0.8294]\n",
      "2021-11-11 13:49:57.515809: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 13:49:58.855996: lr: 0.005839\n",
      "2021-11-11 13:49:58.879686: saving checkpoint...\n",
      "2021-11-11 13:49:59.460405: done, saving took 0.60 seconds\n",
      "2021-11-11 13:49:59.483554: This epoch took 214.204451 s\n",
      "\n",
      "2021-11-11 13:49:59.487090: \n",
      "epoch:  9\n",
      "2021-11-11 13:53:15.291195: train loss : -0.8304\n",
      "2021-11-11 13:53:31.577089: validation loss: -0.7982\n",
      "2021-11-11 13:53:31.581709: Average global foreground Dice: [0.8317]\n",
      "2021-11-11 13:53:31.585838: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 13:53:32.087798: lr: 0.005359\n",
      "2021-11-11 13:53:32.110817: saving checkpoint...\n",
      "2021-11-11 13:53:32.673249: done, saving took 0.58 seconds\n",
      "2021-11-11 13:53:32.695855: This epoch took 213.203936 s\n",
      "\n",
      "2021-11-11 13:53:32.700542: \n",
      "epoch:  10\n",
      "2021-11-11 13:56:48.496056: train loss : -0.8373\n",
      "2021-11-11 13:57:04.753493: validation loss: -0.8043\n",
      "2021-11-11 13:57:04.758967: Average global foreground Dice: [0.8359]\n",
      "2021-11-11 13:57:04.763492: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 13:57:05.258670: lr: 0.004874\n",
      "2021-11-11 13:57:05.283265: saving checkpoint...\n",
      "2021-11-11 13:57:05.940644: done, saving took 0.68 seconds\n",
      "2021-11-11 13:57:05.964789: This epoch took 213.259813 s\n",
      "\n",
      "2021-11-11 13:57:05.970185: \n",
      "epoch:  11\n",
      "2021-11-11 14:00:21.865203: train loss : -0.8410\n",
      "2021-11-11 14:00:38.100610: validation loss: -0.7960\n",
      "2021-11-11 14:00:38.106056: Average global foreground Dice: [0.8278]\n",
      "2021-11-11 14:00:38.110699: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 14:00:38.674857: lr: 0.004384\n",
      "2021-11-11 14:00:38.697480: saving checkpoint...\n",
      "2021-11-11 14:00:39.300799: done, saving took 0.62 seconds\n",
      "2021-11-11 14:00:39.325469: This epoch took 213.348955 s\n",
      "\n",
      "2021-11-11 14:00:39.329016: \n",
      "epoch:  12\n",
      "2021-11-11 14:03:55.199005: train loss : -0.8441\n",
      "2021-11-11 14:04:11.472770: validation loss: -0.8030\n",
      "2021-11-11 14:04:11.477901: Average global foreground Dice: [0.8351]\n",
      "2021-11-11 14:04:11.481903: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 14:04:11.983365: lr: 0.003887\n",
      "2021-11-11 14:04:12.007526: saving checkpoint...\n",
      "2021-11-11 14:04:12.651418: done, saving took 0.66 seconds\n",
      "2021-11-11 14:04:12.672264: This epoch took 213.338704 s\n",
      "\n",
      "2021-11-11 14:04:12.676340: \n",
      "epoch:  13\n",
      "2021-11-11 14:07:28.778589: train loss : -0.8471\n",
      "2021-11-11 14:07:45.207933: validation loss: -0.7998\n",
      "2021-11-11 14:07:45.213717: Average global foreground Dice: [0.8316]\n",
      "2021-11-11 14:07:45.218231: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 14:07:45.757681: lr: 0.003384\n",
      "2021-11-11 14:07:45.780876: saving checkpoint...\n",
      "2021-11-11 14:07:46.566847: done, saving took 0.80 seconds\n",
      "2021-11-11 14:07:46.589497: This epoch took 213.908527 s\n",
      "\n",
      "2021-11-11 14:07:46.593934: \n",
      "epoch:  14\n",
      "2021-11-11 14:11:02.395669: train loss : -0.8501\n",
      "2021-11-11 14:11:18.684480: validation loss: -0.8055\n",
      "2021-11-11 14:11:18.689755: Average global foreground Dice: [0.8355]\n",
      "2021-11-11 14:11:18.693918: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 14:11:19.197880: lr: 0.002872\n",
      "2021-11-11 14:11:19.225047: saving checkpoint...\n",
      "2021-11-11 14:11:19.919076: done, saving took 0.72 seconds\n",
      "2021-11-11 14:11:19.940748: This epoch took 213.342961 s\n",
      "\n",
      "2021-11-11 14:11:19.945568: \n",
      "epoch:  15\n",
      "2021-11-11 14:14:35.637126: train loss : -0.8526\n",
      "2021-11-11 14:14:51.868030: validation loss: -0.8002\n",
      "2021-11-11 14:14:51.872720: Average global foreground Dice: [0.8322]\n",
      "2021-11-11 14:14:51.877410: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 14:14:52.420495: lr: 0.002349\n",
      "2021-11-11 14:14:52.443383: saving checkpoint...\n",
      "2021-11-11 14:14:53.083051: done, saving took 0.66 seconds\n",
      "2021-11-11 14:14:53.107800: This epoch took 213.157897 s\n",
      "\n",
      "2021-11-11 14:14:53.112760: \n",
      "epoch:  16\n",
      "2021-11-11 14:18:09.448077: train loss : -0.8561\n",
      "2021-11-11 14:18:25.701717: validation loss: -0.8054\n",
      "2021-11-11 14:18:25.706640: Average global foreground Dice: [0.8373]\n",
      "2021-11-11 14:18:25.711083: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 14:18:26.271664: lr: 0.001813\n",
      "2021-11-11 14:18:26.294833: saving checkpoint...\n",
      "2021-11-11 14:18:26.873426: done, saving took 0.60 seconds\n",
      "2021-11-11 14:18:26.897355: This epoch took 213.780785 s\n",
      "\n",
      "2021-11-11 14:18:26.901775: \n",
      "epoch:  17\n",
      "2021-11-11 14:21:43.483040: train loss : -0.8578\n",
      "2021-11-11 14:21:59.725379: validation loss: -0.8053\n",
      "2021-11-11 14:21:59.730404: Average global foreground Dice: [0.836]\n",
      "2021-11-11 14:21:59.734443: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 14:22:00.238867: lr: 0.001259\n",
      "2021-11-11 14:22:00.261801: saving checkpoint...\n",
      "2021-11-11 14:22:00.892441: done, saving took 0.65 seconds\n",
      "2021-11-11 14:22:00.915852: This epoch took 214.009664 s\n",
      "\n",
      "2021-11-11 14:22:00.920405: \n",
      "epoch:  18\n",
      "2021-11-11 14:25:17.216979: train loss : -0.8592\n",
      "2021-11-11 14:25:33.454409: validation loss: -0.7989\n",
      "2021-11-11 14:25:33.459596: Average global foreground Dice: [0.8317]\n",
      "2021-11-11 14:25:33.463681: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 14:25:34.002480: lr: 0.000675\n",
      "2021-11-11 14:25:34.025568: saving checkpoint...\n",
      "2021-11-11 14:25:34.599206: done, saving took 0.59 seconds\n",
      "2021-11-11 14:25:34.621601: This epoch took 213.696494 s\n",
      "\n",
      "2021-11-11 14:25:34.627013: \n",
      "epoch:  19\n",
      "2021-11-11 14:28:51.007150: train loss : -0.8630\n",
      "2021-11-11 14:29:07.277639: validation loss: -0.8056\n",
      "2021-11-11 14:29:07.282657: Average global foreground Dice: [0.8366]\n",
      "2021-11-11 14:29:07.286582: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 14:29:07.795923: lr: 0.0\n",
      "2021-11-11 14:29:07.819180: saving checkpoint...\n",
      "2021-11-11 14:29:08.415715: done, saving took 0.62 seconds\n",
      "2021-11-11 14:29:08.437024: This epoch took 213.806627 s\n",
      "\n",
      "2021-11-11 14:29:08.461012: saving checkpoint...\n",
      "2021-11-11 14:29:08.993371: done, saving took 0.55 seconds\n",
      "23090566_20141114 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090571_20120517 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131226 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160308 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131025 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090596_20150112 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120619 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090608_20120718 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151210 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121213 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090616_20140331 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090619_20121210 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090629_20120830 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090636_20121018 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150522 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-11 14:31:03.634754: finished prediction\n",
      "2021-11-11 14:31:03.638676: evaluation of raw predictions\n",
      "2021-11-11 14:31:05.213576: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8217492910116486\n",
      "after:  0.8215115989490049\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_DiceTopK10.nnUNetTrainerV2_Loss_DiceTopK10'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-11 14:31:16.464246: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-11 14:31:16.476776: The split file contains 5 splits.\n",
      "2021-11-11 14:31:16.480542: Desired fold for training: 3\n",
      "2021-11-11 14:31:16.484899: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-11 14:31:20.670918: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-11 14:31:31.166607: Unable to plot network architecture:\n",
      "2021-11-11 14:31:31.171398: No module named 'hiddenlayer'\n",
      "2021-11-11 14:31:31.179699: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-11 14:31:31.183289: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-11 14:31:31.205615: \n",
      "\n",
      "2021-11-11 14:31:31.209168: \n",
      "epoch:  0\n",
      "2021-11-11 14:35:03.112665: train loss : -0.2854\n",
      "2021-11-11 14:35:19.328302: validation loss: -0.6681\n",
      "2021-11-11 14:35:19.332364: Average global foreground Dice: [0.7298]\n",
      "2021-11-11 14:35:19.336714: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 14:35:19.764174: lr: 0.009549\n",
      "2021-11-11 14:35:19.768377: This epoch took 228.555078 s\n",
      "\n",
      "2021-11-11 14:35:19.772390: \n",
      "epoch:  1\n",
      "2021-11-11 14:38:33.367709: train loss : -0.7029\n",
      "2021-11-11 14:38:49.602719: validation loss: -0.7628\n",
      "2021-11-11 14:38:49.606822: Average global foreground Dice: [0.8061]\n",
      "2021-11-11 14:38:49.613192: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 14:38:50.196111: lr: 0.009095\n",
      "2021-11-11 14:38:50.241082: saving checkpoint...\n",
      "2021-11-11 14:38:50.734221: done, saving took 0.53 seconds\n",
      "2021-11-11 14:38:50.749893: This epoch took 210.973529 s\n",
      "\n",
      "2021-11-11 14:38:50.754155: \n",
      "epoch:  2\n",
      "2021-11-11 14:42:05.807190: train loss : -0.7603\n",
      "2021-11-11 14:42:22.042787: validation loss: -0.7958\n",
      "2021-11-11 14:42:22.047526: Average global foreground Dice: [0.8324]\n",
      "2021-11-11 14:42:22.051047: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 14:42:22.559753: lr: 0.008639\n",
      "2021-11-11 14:42:22.593202: saving checkpoint...\n",
      "2021-11-11 14:42:23.149468: done, saving took 0.59 seconds\n",
      "2021-11-11 14:42:23.174221: This epoch took 212.416443 s\n",
      "\n",
      "2021-11-11 14:42:23.177813: \n",
      "epoch:  3\n",
      "2021-11-11 14:45:38.144734: train loss : -0.7850\n",
      "2021-11-11 14:45:54.369009: validation loss: -0.7946\n",
      "2021-11-11 14:45:54.374231: Average global foreground Dice: [0.8292]\n",
      "2021-11-11 14:45:54.379029: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 14:45:54.878652: lr: 0.008181\n",
      "2021-11-11 14:45:54.912891: saving checkpoint...\n",
      "2021-11-11 14:45:55.576647: done, saving took 0.69 seconds\n",
      "2021-11-11 14:45:55.597821: This epoch took 212.416628 s\n",
      "\n",
      "2021-11-11 14:45:55.601387: \n",
      "epoch:  4\n",
      "2021-11-11 14:49:10.655821: train loss : -0.7970\n",
      "2021-11-11 14:49:26.884132: validation loss: -0.8036\n",
      "2021-11-11 14:49:26.888729: Average global foreground Dice: [0.8357]\n",
      "2021-11-11 14:49:26.892224: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 14:49:27.390906: lr: 0.007719\n",
      "2021-11-11 14:49:27.413269: saving checkpoint...\n",
      "2021-11-11 14:49:28.009825: done, saving took 0.62 seconds\n",
      "2021-11-11 14:49:28.034720: This epoch took 212.429463 s\n",
      "\n",
      "2021-11-11 14:49:28.039270: \n",
      "epoch:  5\n",
      "2021-11-11 14:52:43.044603: train loss : -0.8070\n",
      "2021-11-11 14:52:59.289803: validation loss: -0.7979\n",
      "2021-11-11 14:52:59.294138: Average global foreground Dice: [0.8314]\n",
      "2021-11-11 14:52:59.299340: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 14:52:59.802501: lr: 0.007254\n",
      "2021-11-11 14:52:59.825564: saving checkpoint...\n",
      "2021-11-11 14:53:00.502548: done, saving took 0.70 seconds\n",
      "2021-11-11 14:53:00.523764: This epoch took 212.479586 s\n",
      "\n",
      "2021-11-11 14:53:00.528346: \n",
      "epoch:  6\n",
      "2021-11-11 14:56:15.546538: train loss : -0.8164\n",
      "2021-11-11 14:56:31.768028: validation loss: -0.8132\n",
      "2021-11-11 14:56:31.774639: Average global foreground Dice: [0.844]\n",
      "2021-11-11 14:56:31.779292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 14:56:32.357921: lr: 0.006786\n",
      "2021-11-11 14:56:32.389848: saving checkpoint...\n",
      "2021-11-11 14:56:33.024559: done, saving took 0.66 seconds\n",
      "2021-11-11 14:56:33.046401: This epoch took 212.514105 s\n",
      "\n",
      "2021-11-11 14:56:33.050946: \n",
      "epoch:  7\n",
      "2021-11-11 14:59:48.019759: train loss : -0.8218\n",
      "2021-11-11 15:00:04.251256: validation loss: -0.8146\n",
      "2021-11-11 15:00:04.256377: Average global foreground Dice: [0.8445]\n",
      "2021-11-11 15:00:04.261611: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 15:00:04.761712: lr: 0.006314\n",
      "2021-11-11 15:00:04.784912: saving checkpoint...\n",
      "2021-11-11 15:00:05.464061: done, saving took 0.70 seconds\n",
      "2021-11-11 15:00:05.487644: This epoch took 212.432377 s\n",
      "\n",
      "2021-11-11 15:00:05.491432: \n",
      "epoch:  8\n",
      "2021-11-11 15:03:20.926946: train loss : -0.8267\n",
      "2021-11-11 15:03:37.193401: validation loss: -0.8139\n",
      "2021-11-11 15:03:37.198158: Average global foreground Dice: [0.8429]\n",
      "2021-11-11 15:03:37.202763: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 15:03:37.695633: lr: 0.005839\n",
      "2021-11-11 15:03:37.718814: saving checkpoint...\n",
      "2021-11-11 15:03:38.309987: done, saving took 0.61 seconds\n",
      "2021-11-11 15:03:38.333102: This epoch took 212.837611 s\n",
      "\n",
      "2021-11-11 15:03:38.336999: \n",
      "epoch:  9\n",
      "2021-11-11 15:06:53.661049: train loss : -0.8312\n",
      "2021-11-11 15:07:09.902463: validation loss: -0.8118\n",
      "2021-11-11 15:07:09.907247: Average global foreground Dice: [0.8409]\n",
      "2021-11-11 15:07:09.912191: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 15:07:10.411888: lr: 0.005359\n",
      "2021-11-11 15:07:10.434680: saving checkpoint...\n",
      "2021-11-11 15:07:11.035182: done, saving took 0.62 seconds\n",
      "2021-11-11 15:07:11.062551: This epoch took 212.720538 s\n",
      "\n",
      "2021-11-11 15:07:11.067796: \n",
      "epoch:  10\n",
      "2021-11-11 15:10:26.512791: train loss : -0.8349\n",
      "2021-11-11 15:10:42.736070: validation loss: -0.8151\n",
      "2021-11-11 15:10:42.741674: Average global foreground Dice: [0.8442]\n",
      "2021-11-11 15:10:42.746610: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 15:10:43.241373: lr: 0.004874\n",
      "2021-11-11 15:10:43.264682: saving checkpoint...\n",
      "2021-11-11 15:10:44.243064: done, saving took 1.00 seconds\n",
      "2021-11-11 15:10:44.266364: This epoch took 213.194502 s\n",
      "\n",
      "2021-11-11 15:10:44.271579: \n",
      "epoch:  11\n",
      "2021-11-11 15:13:59.639607: train loss : -0.8394\n",
      "2021-11-11 15:14:15.881239: validation loss: -0.8164\n",
      "2021-11-11 15:14:15.886609: Average global foreground Dice: [0.8446]\n",
      "2021-11-11 15:14:15.891652: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 15:14:16.505864: lr: 0.004384\n",
      "2021-11-11 15:14:16.537807: saving checkpoint...\n",
      "2021-11-11 15:14:17.178272: done, saving took 0.67 seconds\n",
      "2021-11-11 15:14:17.200661: This epoch took 212.924236 s\n",
      "\n",
      "2021-11-11 15:14:17.204956: \n",
      "epoch:  12\n",
      "2021-11-11 15:17:32.551466: train loss : -0.8420\n",
      "2021-11-11 15:17:48.789946: validation loss: -0.8169\n",
      "2021-11-11 15:17:48.795433: Average global foreground Dice: [0.8456]\n",
      "2021-11-11 15:17:48.800318: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 15:17:49.319553: lr: 0.003887\n",
      "2021-11-11 15:17:49.345284: saving checkpoint...\n",
      "2021-11-11 15:17:50.023614: done, saving took 0.70 seconds\n",
      "2021-11-11 15:17:50.044617: This epoch took 212.834869 s\n",
      "\n",
      "2021-11-11 15:17:50.048209: \n",
      "epoch:  13\n",
      "2021-11-11 15:21:05.385361: train loss : -0.8454\n",
      "2021-11-11 15:21:22.811236: validation loss: -0.8130\n",
      "2021-11-11 15:21:22.815950: Average global foreground Dice: [0.8416]\n",
      "2021-11-11 15:21:22.820882: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 15:21:23.314449: lr: 0.003384\n",
      "2021-11-11 15:21:23.337927: saving checkpoint...\n",
      "2021-11-11 15:21:24.006649: done, saving took 0.69 seconds\n",
      "2021-11-11 15:21:24.029007: This epoch took 213.976145 s\n",
      "\n",
      "2021-11-11 15:21:24.033890: \n",
      "epoch:  14\n",
      "2021-11-11 15:24:39.381708: train loss : -0.8485\n",
      "2021-11-11 15:24:55.634689: validation loss: -0.8170\n",
      "2021-11-11 15:24:55.640681: Average global foreground Dice: [0.8446]\n",
      "2021-11-11 15:24:55.645243: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 15:24:56.178033: lr: 0.002872\n",
      "2021-11-11 15:24:56.201162: saving checkpoint...\n",
      "2021-11-11 15:24:56.902225: done, saving took 0.72 seconds\n",
      "2021-11-11 15:24:56.925205: This epoch took 212.886778 s\n",
      "\n",
      "2021-11-11 15:24:56.929707: \n",
      "epoch:  15\n",
      "2021-11-11 15:28:12.448127: train loss : -0.8506\n",
      "2021-11-11 15:28:28.699268: validation loss: -0.8109\n",
      "2021-11-11 15:28:28.703598: Average global foreground Dice: [0.8396]\n",
      "2021-11-11 15:28:28.708361: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 15:28:29.216918: lr: 0.002349\n",
      "2021-11-11 15:28:29.239811: saving checkpoint...\n",
      "2021-11-11 15:28:29.909927: done, saving took 0.69 seconds\n",
      "2021-11-11 15:28:29.931632: This epoch took 212.997590 s\n",
      "\n",
      "2021-11-11 15:28:29.935976: \n",
      "epoch:  16\n",
      "2021-11-11 15:31:45.829005: train loss : -0.8543\n",
      "2021-11-11 15:32:02.048544: validation loss: -0.8184\n",
      "2021-11-11 15:32:02.054160: Average global foreground Dice: [0.8454]\n",
      "2021-11-11 15:32:02.058945: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 15:32:02.670030: lr: 0.001813\n",
      "2021-11-11 15:32:02.701455: saving checkpoint...\n",
      "2021-11-11 15:32:03.291665: done, saving took 0.62 seconds\n",
      "2021-11-11 15:32:03.314466: This epoch took 213.374151 s\n",
      "\n",
      "2021-11-11 15:32:03.319252: \n",
      "epoch:  17\n",
      "2021-11-11 15:35:19.412326: train loss : -0.8562\n",
      "2021-11-11 15:35:35.624592: validation loss: -0.8149\n",
      "2021-11-11 15:35:35.630305: Average global foreground Dice: [0.8421]\n",
      "2021-11-11 15:35:35.635763: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 15:35:36.128052: lr: 0.001259\n",
      "2021-11-11 15:35:36.151941: saving checkpoint...\n",
      "2021-11-11 15:35:36.714145: done, saving took 0.58 seconds\n",
      "2021-11-11 15:35:36.735704: This epoch took 213.410543 s\n",
      "\n",
      "2021-11-11 15:35:36.740169: \n",
      "epoch:  18\n",
      "2021-11-11 15:38:52.697706: train loss : -0.8586\n",
      "2021-11-11 15:39:08.942648: validation loss: -0.8147\n",
      "2021-11-11 15:39:08.948010: Average global foreground Dice: [0.8438]\n",
      "2021-11-11 15:39:08.952260: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 15:39:09.509511: lr: 0.000675\n",
      "2021-11-11 15:39:09.532309: saving checkpoint...\n",
      "2021-11-11 15:39:10.104373: done, saving took 0.59 seconds\n",
      "2021-11-11 15:39:10.126048: This epoch took 213.381287 s\n",
      "\n",
      "2021-11-11 15:39:10.130152: \n",
      "epoch:  19\n",
      "2021-11-11 15:42:26.144373: train loss : -0.8614\n",
      "2021-11-11 15:42:42.370142: validation loss: -0.8169\n",
      "2021-11-11 15:42:42.375393: Average global foreground Dice: [0.8447]\n",
      "2021-11-11 15:42:42.380461: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 15:42:42.889639: lr: 0.0\n",
      "2021-11-11 15:42:42.913186: saving checkpoint...\n",
      "2021-11-11 15:42:43.495677: done, saving took 0.60 seconds\n",
      "2021-11-11 15:42:43.517924: This epoch took 213.383130 s\n",
      "\n",
      "2021-11-11 15:42:43.541812: saving checkpoint...\n",
      "2021-11-11 15:42:44.071498: done, saving took 0.55 seconds\n",
      "23090557_20130717 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090560_20160114 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090562_20140206 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141215 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130626 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140124 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121015 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090597_20130227 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130208 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090621_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150105 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130807 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090637_20140401 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131126 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090644_20131216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-11 15:44:36.961958: finished prediction\n",
      "2021-11-11 15:44:36.965999: evaluation of raw predictions\n",
      "2021-11-11 15:44:38.398916: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8320261744877199\n",
      "after:  0.8313701175650141\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_DiceTopK10.nnUNetTrainerV2_Loss_DiceTopK10'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-11 15:44:47.409606: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-11 15:44:47.423196: The split file contains 5 splits.\n",
      "2021-11-11 15:44:47.427034: Desired fold for training: 4\n",
      "2021-11-11 15:44:47.430504: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-11 15:44:51.628953: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-11 15:45:00.002884: Unable to plot network architecture:\n",
      "2021-11-11 15:45:00.007856: No module named 'hiddenlayer'\n",
      "2021-11-11 15:45:00.012252: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-11 15:45:00.016806: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-11 15:45:00.025207: \n",
      "\n",
      "2021-11-11 15:45:00.028935: \n",
      "epoch:  0\n",
      "2021-11-11 15:48:31.519315: train loss : -0.1882\n",
      "2021-11-11 15:48:47.355813: validation loss: -0.6109\n",
      "2021-11-11 15:48:47.361137: Average global foreground Dice: [0.6968]\n",
      "2021-11-11 15:48:47.364642: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 15:48:47.776813: lr: 0.009549\n",
      "2021-11-11 15:48:47.781614: This epoch took 227.722063 s\n",
      "\n",
      "2021-11-11 15:48:47.785156: \n",
      "epoch:  1\n",
      "2021-11-11 15:52:00.474748: train loss : -0.6652\n",
      "2021-11-11 15:52:16.301589: validation loss: -0.7390\n",
      "2021-11-11 15:52:16.306561: Average global foreground Dice: [0.7867]\n",
      "2021-11-11 15:52:16.311225: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 15:52:16.881101: lr: 0.009095\n",
      "2021-11-11 15:52:16.919985: saving checkpoint...\n",
      "2021-11-11 15:52:17.449208: done, saving took 0.56 seconds\n",
      "2021-11-11 15:52:17.468415: This epoch took 209.678524 s\n",
      "\n",
      "2021-11-11 15:52:17.474342: \n",
      "epoch:  2\n",
      "2021-11-11 15:55:30.417107: train loss : -0.7417\n",
      "2021-11-11 15:55:46.338368: validation loss: -0.7642\n",
      "2021-11-11 15:55:46.343017: Average global foreground Dice: [0.8056]\n",
      "2021-11-11 15:55:46.346551: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 15:55:46.857788: lr: 0.008639\n",
      "2021-11-11 15:55:46.892757: saving checkpoint...\n",
      "2021-11-11 15:55:47.470171: done, saving took 0.61 seconds\n",
      "2021-11-11 15:55:47.491831: This epoch took 210.013052 s\n",
      "\n",
      "2021-11-11 15:55:47.496115: \n",
      "epoch:  3\n",
      "2021-11-11 15:59:00.442250: train loss : -0.7739\n",
      "2021-11-11 15:59:16.365158: validation loss: -0.7779\n",
      "2021-11-11 15:59:16.369400: Average global foreground Dice: [0.8162]\n",
      "2021-11-11 15:59:16.373107: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 15:59:16.990181: lr: 0.008181\n",
      "2021-11-11 15:59:17.022416: saving checkpoint...\n",
      "2021-11-11 15:59:17.617587: done, saving took 0.62 seconds\n",
      "2021-11-11 15:59:17.641681: This epoch took 210.142370 s\n",
      "\n",
      "2021-11-11 15:59:17.645152: \n",
      "epoch:  4\n",
      "2021-11-11 16:02:30.504373: train loss : -0.7907\n",
      "2021-11-11 16:02:46.453904: validation loss: -0.7923\n",
      "2021-11-11 16:02:46.458552: Average global foreground Dice: [0.828]\n",
      "2021-11-11 16:02:46.462182: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 16:02:46.981272: lr: 0.007719\n",
      "2021-11-11 16:02:47.004315: saving checkpoint...\n",
      "2021-11-11 16:02:47.635984: done, saving took 0.65 seconds\n",
      "2021-11-11 16:02:47.656707: This epoch took 210.008164 s\n",
      "\n",
      "2021-11-11 16:02:47.660599: \n",
      "epoch:  5\n",
      "2021-11-11 16:06:00.608916: train loss : -0.8014\n",
      "2021-11-11 16:06:16.569804: validation loss: -0.7993\n",
      "2021-11-11 16:06:16.574897: Average global foreground Dice: [0.8324]\n",
      "2021-11-11 16:06:16.579425: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 16:06:17.083173: lr: 0.007254\n",
      "2021-11-11 16:06:17.106397: saving checkpoint...\n",
      "2021-11-11 16:06:17.659209: done, saving took 0.57 seconds\n",
      "2021-11-11 16:06:17.681336: This epoch took 210.016962 s\n",
      "\n",
      "2021-11-11 16:06:17.684896: \n",
      "epoch:  6\n",
      "2021-11-11 16:09:30.584262: train loss : -0.8109\n",
      "2021-11-11 16:09:46.521573: validation loss: -0.8085\n",
      "2021-11-11 16:09:46.526089: Average global foreground Dice: [0.839]\n",
      "2021-11-11 16:09:46.530741: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 16:09:47.086826: lr: 0.006786\n",
      "2021-11-11 16:09:47.109459: saving checkpoint...\n",
      "2021-11-11 16:09:47.741646: done, saving took 0.65 seconds\n",
      "2021-11-11 16:09:47.764336: This epoch took 210.074777 s\n",
      "\n",
      "2021-11-11 16:09:47.768383: \n",
      "epoch:  7\n",
      "2021-11-11 16:13:00.653514: train loss : -0.8182\n",
      "2021-11-11 16:13:16.612510: validation loss: -0.8094\n",
      "2021-11-11 16:13:16.616610: Average global foreground Dice: [0.841]\n",
      "2021-11-11 16:13:16.621426: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 16:13:17.145917: lr: 0.006314\n",
      "2021-11-11 16:13:17.168693: saving checkpoint...\n",
      "2021-11-11 16:13:17.855843: done, saving took 0.71 seconds\n",
      "2021-11-11 16:13:17.879473: This epoch took 210.107334 s\n",
      "\n",
      "2021-11-11 16:13:17.883007: \n",
      "epoch:  8\n",
      "2021-11-11 16:16:31.044341: train loss : -0.8234\n",
      "2021-11-11 16:16:47.007093: validation loss: -0.8048\n",
      "2021-11-11 16:16:47.012217: Average global foreground Dice: [0.8358]\n",
      "2021-11-11 16:16:47.016427: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 16:16:47.525741: lr: 0.005839\n",
      "2021-11-11 16:16:47.549702: saving checkpoint...\n",
      "2021-11-11 16:16:48.099525: done, saving took 0.57 seconds\n",
      "2021-11-11 16:16:48.121534: This epoch took 210.233450 s\n",
      "\n",
      "2021-11-11 16:16:48.125043: \n",
      "epoch:  9\n",
      "2021-11-11 16:20:01.533253: train loss : -0.8284\n",
      "2021-11-11 16:20:17.492712: validation loss: -0.8077\n",
      "2021-11-11 16:20:17.498899: Average global foreground Dice: [0.8399]\n",
      "2021-11-11 16:20:17.503741: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 16:20:18.045462: lr: 0.005359\n",
      "2021-11-11 16:20:18.068622: saving checkpoint...\n",
      "2021-11-11 16:20:18.687216: done, saving took 0.64 seconds\n",
      "2021-11-11 16:20:18.711323: This epoch took 210.581726 s\n",
      "\n",
      "2021-11-11 16:20:18.715548: \n",
      "epoch:  10\n",
      "2021-11-11 16:23:31.741584: train loss : -0.8341\n",
      "2021-11-11 16:23:47.717422: validation loss: -0.8046\n",
      "2021-11-11 16:23:47.722395: Average global foreground Dice: [0.8385]\n",
      "2021-11-11 16:23:47.726831: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 16:23:48.221243: lr: 0.004874\n",
      "2021-11-11 16:23:48.244401: saving checkpoint...\n",
      "2021-11-11 16:23:48.802790: done, saving took 0.58 seconds\n",
      "2021-11-11 16:23:48.825569: This epoch took 210.105712 s\n",
      "\n",
      "2021-11-11 16:23:48.830199: \n",
      "epoch:  11\n",
      "2021-11-11 16:27:02.240932: train loss : -0.8359\n",
      "2021-11-11 16:27:18.177486: validation loss: -0.8094\n",
      "2021-11-11 16:27:18.182899: Average global foreground Dice: [0.843]\n",
      "2021-11-11 16:27:18.187482: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 16:27:18.745526: lr: 0.004384\n",
      "2021-11-11 16:27:18.768553: saving checkpoint...\n",
      "2021-11-11 16:27:19.333891: done, saving took 0.58 seconds\n",
      "2021-11-11 16:27:19.356690: This epoch took 210.522371 s\n",
      "\n",
      "2021-11-11 16:27:19.361092: \n",
      "epoch:  12\n",
      "2021-11-11 16:30:32.498942: train loss : -0.8398\n",
      "2021-11-11 16:30:48.460459: validation loss: -0.8124\n",
      "2021-11-11 16:30:48.465265: Average global foreground Dice: [0.8431]\n",
      "2021-11-11 16:30:48.471096: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 16:30:48.967762: lr: 0.003887\n",
      "2021-11-11 16:30:48.990341: saving checkpoint...\n",
      "2021-11-11 16:30:49.572542: done, saving took 0.60 seconds\n",
      "2021-11-11 16:30:49.595690: This epoch took 210.230803 s\n",
      "\n",
      "2021-11-11 16:30:49.600430: \n",
      "epoch:  13\n",
      "2021-11-11 16:34:02.786276: train loss : -0.8428\n",
      "2021-11-11 16:34:18.695744: validation loss: -0.8150\n",
      "2021-11-11 16:34:18.700809: Average global foreground Dice: [0.8456]\n",
      "2021-11-11 16:34:18.705629: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 16:34:19.200949: lr: 0.003384\n",
      "2021-11-11 16:34:19.224614: saving checkpoint...\n",
      "2021-11-11 16:34:19.801370: done, saving took 0.60 seconds\n",
      "2021-11-11 16:34:19.822797: This epoch took 210.217571 s\n",
      "\n",
      "2021-11-11 16:34:19.827593: \n",
      "epoch:  14\n",
      "2021-11-11 16:37:32.991231: train loss : -0.8464\n",
      "2021-11-11 16:37:48.928838: validation loss: -0.8203\n",
      "2021-11-11 16:37:48.934368: Average global foreground Dice: [0.8495]\n",
      "2021-11-11 16:37:48.938959: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 16:37:49.475237: lr: 0.002872\n",
      "2021-11-11 16:37:49.498581: saving checkpoint...\n",
      "2021-11-11 16:37:50.055985: done, saving took 0.58 seconds\n",
      "2021-11-11 16:37:50.079708: This epoch took 210.248487 s\n",
      "\n",
      "2021-11-11 16:37:50.084183: \n",
      "epoch:  15\n",
      "2021-11-11 16:41:03.272860: train loss : -0.8508\n",
      "2021-11-11 16:41:19.201416: validation loss: -0.8105\n",
      "2021-11-11 16:41:19.205818: Average global foreground Dice: [0.8412]\n",
      "2021-11-11 16:41:19.209850: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 16:41:19.716304: lr: 0.002349\n",
      "2021-11-11 16:41:19.739533: saving checkpoint...\n",
      "2021-11-11 16:41:21.117159: done, saving took 1.40 seconds\n",
      "2021-11-11 16:41:21.138529: This epoch took 211.049874 s\n",
      "\n",
      "2021-11-11 16:41:21.142917: \n",
      "epoch:  16\n",
      "2021-11-11 16:44:35.118485: train loss : -0.8526\n",
      "2021-11-11 16:44:51.043020: validation loss: -0.8078\n",
      "2021-11-11 16:44:51.047636: Average global foreground Dice: [0.8398]\n",
      "2021-11-11 16:44:51.052172: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 16:44:51.614260: lr: 0.001813\n",
      "2021-11-11 16:44:51.637289: saving checkpoint...\n",
      "2021-11-11 16:44:52.216990: done, saving took 0.60 seconds\n",
      "2021-11-11 16:44:52.240505: This epoch took 211.093651 s\n",
      "\n",
      "2021-11-11 16:44:52.245282: \n",
      "epoch:  17\n",
      "2021-11-11 16:48:06.153265: train loss : -0.8553\n",
      "2021-11-11 16:48:22.130166: validation loss: -0.8190\n",
      "2021-11-11 16:48:22.134258: Average global foreground Dice: [0.8482]\n",
      "2021-11-11 16:48:22.139084: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 16:48:22.657993: lr: 0.001259\n",
      "2021-11-11 16:48:22.680907: saving checkpoint...\n",
      "2021-11-11 16:48:23.259834: done, saving took 0.60 seconds\n",
      "2021-11-11 16:48:23.282973: This epoch took 211.032705 s\n",
      "\n",
      "2021-11-11 16:48:23.287041: \n",
      "epoch:  18\n",
      "2021-11-11 16:51:37.176364: train loss : -0.8575\n",
      "2021-11-11 16:51:53.127774: validation loss: -0.8113\n",
      "2021-11-11 16:51:53.132544: Average global foreground Dice: [0.8426]\n",
      "2021-11-11 16:51:53.136657: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 16:51:53.629482: lr: 0.000675\n",
      "2021-11-11 16:51:53.652591: saving checkpoint...\n",
      "2021-11-11 16:51:54.254179: done, saving took 0.62 seconds\n",
      "2021-11-11 16:51:54.277327: This epoch took 210.986421 s\n",
      "\n",
      "2021-11-11 16:51:54.282126: \n",
      "epoch:  19\n",
      "2021-11-11 16:55:08.131332: train loss : -0.8596\n",
      "2021-11-11 16:55:24.058165: validation loss: -0.8140\n",
      "2021-11-11 16:55:24.064383: Average global foreground Dice: [0.8432]\n",
      "2021-11-11 16:55:24.068487: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 16:55:24.614652: lr: 0.0\n",
      "2021-11-11 16:55:24.637169: saving checkpoint...\n",
      "2021-11-11 16:55:25.331883: done, saving took 0.71 seconds\n",
      "2021-11-11 16:55:25.355033: This epoch took 211.068738 s\n",
      "\n",
      "2021-11-11 16:55:25.378533: saving checkpoint...\n",
      "2021-11-11 16:55:25.893151: done, saving took 0.53 seconds\n",
      "23090558_20120330 (3, 263, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090564_20130312 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090568_20121018 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090569_20120607 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120613 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150908 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090593_20120625 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130103 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090600_20121108 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090603_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090607_20120420 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090609_20120510 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160119 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160510 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090646_20120718 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-11 16:57:21.032382: finished prediction\n",
      "2021-11-11 16:57:21.037137: evaluation of raw predictions\n",
      "2021-11-11 16:57:22.480094: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8266748245199651\n",
      "after:  0.8192172236379196\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Model 9 (epoch 20)\n",
    "\n",
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_DiceTopK10 555 0 --cuda_device 0\n",
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_DiceTopK10 555 1 --cuda_device 0\n",
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_DiceTopK10 555 2 --cuda_device 0\n",
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_DiceTopK10 555 3 --cuda_device 0\n",
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_DiceTopK10 555 4 --cuda_device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-11 16:57:31.588540: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-11 16:57:31.601399: The split file contains 5 splits.\n",
      "2021-11-11 16:57:31.605297: Desired fold for training: 0\n",
      "2021-11-11 16:57:31.609297: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-11 16:57:35.777957: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-11 16:57:46.963824: Unable to plot network architecture:\n",
      "2021-11-11 16:57:46.968361: No module named 'hiddenlayer'\n",
      "2021-11-11 16:57:46.973015: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-11 16:57:46.977959: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-11 16:57:46.989506: \n",
      "\n",
      "2021-11-11 16:57:46.993879: \n",
      "epoch:  0\n",
      "2021-11-11 17:01:04.697186: train loss : -0.2882\n",
      "2021-11-11 17:01:18.419217: validation loss: -0.6712\n",
      "2021-11-11 17:01:18.427771: Average global foreground Dice: [0.7473]\n",
      "2021-11-11 17:01:18.432394: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:01:18.862604: lr: 0.009775\n",
      "2021-11-11 17:01:18.867247: This epoch took 211.868125 s\n",
      "\n",
      "2021-11-11 17:01:18.871264: \n",
      "epoch:  1\n",
      "2021-11-11 17:04:19.318702: train loss : -0.6740\n",
      "2021-11-11 17:04:33.037773: validation loss: -0.7492\n",
      "2021-11-11 17:04:33.043819: Average global foreground Dice: [0.8139]\n",
      "2021-11-11 17:04:33.056201: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:04:33.586029: lr: 0.009549\n",
      "2021-11-11 17:04:33.635231: saving checkpoint...\n",
      "2021-11-11 17:04:34.169633: done, saving took 0.58 seconds\n",
      "2021-11-11 17:04:34.187221: This epoch took 195.311895 s\n",
      "\n",
      "2021-11-11 17:04:34.191607: \n",
      "epoch:  2\n",
      "2021-11-11 17:07:34.457400: train loss : -0.7648\n",
      "2021-11-11 17:07:48.173109: validation loss: -0.8053\n",
      "2021-11-11 17:07:48.177768: Average global foreground Dice: [0.8275]\n",
      "2021-11-11 17:07:48.182284: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:07:48.707722: lr: 0.009322\n",
      "2021-11-11 17:07:48.742836: saving checkpoint...\n",
      "2021-11-11 17:07:49.325830: done, saving took 0.61 seconds\n",
      "2021-11-11 17:07:49.350000: This epoch took 195.154071 s\n",
      "\n",
      "2021-11-11 17:07:49.354301: \n",
      "epoch:  3\n",
      "2021-11-11 17:10:49.465963: train loss : -0.7980\n",
      "2021-11-11 17:11:03.173856: validation loss: -0.8280\n",
      "2021-11-11 17:11:03.180664: Average global foreground Dice: [0.8462]\n",
      "2021-11-11 17:11:03.185883: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:11:03.723608: lr: 0.009095\n",
      "2021-11-11 17:11:03.746102: saving checkpoint...\n",
      "2021-11-11 17:11:04.360811: done, saving took 0.63 seconds\n",
      "2021-11-11 17:11:04.386111: This epoch took 195.027081 s\n",
      "\n",
      "2021-11-11 17:11:04.390954: \n",
      "epoch:  4\n",
      "2021-11-11 17:14:04.297253: train loss : -0.8128\n",
      "2021-11-11 17:14:18.021116: validation loss: -0.8264\n",
      "2021-11-11 17:14:18.027267: Average global foreground Dice: [0.8448]\n",
      "2021-11-11 17:14:18.031107: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:14:18.544088: lr: 0.008868\n",
      "2021-11-11 17:14:18.568797: saving checkpoint...\n",
      "2021-11-11 17:14:19.155404: done, saving took 0.61 seconds\n",
      "2021-11-11 17:14:19.180410: This epoch took 194.785076 s\n",
      "\n",
      "2021-11-11 17:14:19.185313: \n",
      "epoch:  5\n",
      "2021-11-11 17:17:19.337478: train loss : -0.8216\n",
      "2021-11-11 17:17:33.068509: validation loss: -0.8264\n",
      "2021-11-11 17:17:33.073684: Average global foreground Dice: [0.8417]\n",
      "2021-11-11 17:17:33.078224: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:17:33.575666: lr: 0.008639\n",
      "2021-11-11 17:17:33.598436: saving checkpoint...\n",
      "2021-11-11 17:17:34.180614: done, saving took 0.60 seconds\n",
      "2021-11-11 17:17:34.205381: This epoch took 195.015967 s\n",
      "\n",
      "2021-11-11 17:17:34.209991: \n",
      "epoch:  6\n",
      "2021-11-11 17:20:34.212397: train loss : -0.8272\n",
      "2021-11-11 17:20:47.942559: validation loss: -0.8233\n",
      "2021-11-11 17:20:47.948646: Average global foreground Dice: [0.8417]\n",
      "2021-11-11 17:20:47.953107: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:20:48.536958: lr: 0.00841\n",
      "2021-11-11 17:20:48.560822: saving checkpoint...\n",
      "2021-11-11 17:20:49.200656: done, saving took 0.66 seconds\n",
      "2021-11-11 17:20:49.231262: This epoch took 195.016737 s\n",
      "\n",
      "2021-11-11 17:20:49.236516: \n",
      "epoch:  7\n",
      "2021-11-11 17:23:49.326813: train loss : -0.8296\n",
      "2021-11-11 17:24:03.059927: validation loss: -0.8316\n",
      "2021-11-11 17:24:03.065009: Average global foreground Dice: [0.8468]\n",
      "2021-11-11 17:24:03.069587: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:24:03.560638: lr: 0.008181\n",
      "2021-11-11 17:24:03.590703: saving checkpoint...\n",
      "2021-11-11 17:24:04.197977: done, saving took 0.63 seconds\n",
      "2021-11-11 17:24:04.223698: This epoch took 194.981887 s\n",
      "\n",
      "2021-11-11 17:24:04.228194: \n",
      "epoch:  8\n",
      "2021-11-11 17:27:04.636129: train loss : -0.8368\n",
      "2021-11-11 17:27:18.377953: validation loss: -0.8346\n",
      "2021-11-11 17:27:18.383816: Average global foreground Dice: [0.8494]\n",
      "2021-11-11 17:27:18.388523: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:27:18.928723: lr: 0.00795\n",
      "2021-11-11 17:27:18.952388: saving checkpoint...\n",
      "2021-11-11 17:27:19.565823: done, saving took 0.63 seconds\n",
      "2021-11-11 17:27:19.588660: This epoch took 195.355047 s\n",
      "\n",
      "2021-11-11 17:27:19.593466: \n",
      "epoch:  9\n",
      "2021-11-11 17:30:19.931148: train loss : -0.8409\n",
      "2021-11-11 17:30:33.632900: validation loss: -0.8405\n",
      "2021-11-11 17:30:33.638619: Average global foreground Dice: [0.8541]\n",
      "2021-11-11 17:30:33.644235: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:30:34.133197: lr: 0.007719\n",
      "2021-11-11 17:30:34.157066: saving checkpoint...\n",
      "2021-11-11 17:30:34.737342: done, saving took 0.60 seconds\n",
      "2021-11-11 17:30:34.763114: This epoch took 195.164311 s\n",
      "\n",
      "2021-11-11 17:30:34.769046: \n",
      "epoch:  10\n",
      "2021-11-11 17:33:35.021717: train loss : -0.8446\n",
      "2021-11-11 17:33:48.765605: validation loss: -0.8385\n",
      "2021-11-11 17:33:48.770779: Average global foreground Dice: [0.8537]\n",
      "2021-11-11 17:33:48.775662: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:33:49.262849: lr: 0.007487\n",
      "2021-11-11 17:33:49.286225: saving checkpoint...\n",
      "2021-11-11 17:33:49.904562: done, saving took 0.64 seconds\n",
      "2021-11-11 17:33:49.929474: This epoch took 195.155457 s\n",
      "\n",
      "2021-11-11 17:33:49.934400: \n",
      "epoch:  11\n",
      "2021-11-11 17:36:50.163946: train loss : -0.8468\n",
      "2021-11-11 17:37:03.877078: validation loss: -0.8341\n",
      "2021-11-11 17:37:03.883238: Average global foreground Dice: [0.8486]\n",
      "2021-11-11 17:37:03.889402: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:37:04.486795: lr: 0.007254\n",
      "2021-11-11 17:37:04.510734: saving checkpoint...\n",
      "2021-11-11 17:37:05.096699: done, saving took 0.61 seconds\n",
      "2021-11-11 17:37:05.124349: This epoch took 195.185353 s\n",
      "\n",
      "2021-11-11 17:37:05.129903: \n",
      "epoch:  12\n",
      "2021-11-11 17:40:05.373264: train loss : -0.8504\n",
      "2021-11-11 17:40:19.104931: validation loss: -0.8407\n",
      "2021-11-11 17:40:19.110634: Average global foreground Dice: [0.8556]\n",
      "2021-11-11 17:40:19.115977: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:40:19.609347: lr: 0.007021\n",
      "2021-11-11 17:40:19.633186: saving checkpoint...\n",
      "2021-11-11 17:40:20.206044: done, saving took 0.59 seconds\n",
      "2021-11-11 17:40:20.234925: This epoch took 195.100764 s\n",
      "\n",
      "2021-11-11 17:40:20.239728: \n",
      "epoch:  13\n",
      "2021-11-11 17:43:20.448007: train loss : -0.8537\n",
      "2021-11-11 17:43:34.159685: validation loss: -0.8454\n",
      "2021-11-11 17:43:34.164829: Average global foreground Dice: [0.8578]\n",
      "2021-11-11 17:43:34.169714: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:43:34.702669: lr: 0.006786\n",
      "2021-11-11 17:43:34.740197: saving checkpoint...\n",
      "2021-11-11 17:43:35.402542: done, saving took 0.69 seconds\n",
      "2021-11-11 17:43:35.434551: This epoch took 195.189574 s\n",
      "\n",
      "2021-11-11 17:43:35.440105: \n",
      "epoch:  14\n",
      "2021-11-11 17:46:35.667339: train loss : -0.8522\n",
      "2021-11-11 17:46:49.409857: validation loss: -0.8392\n",
      "2021-11-11 17:46:49.414971: Average global foreground Dice: [0.8516]\n",
      "2021-11-11 17:46:49.420052: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:46:49.963537: lr: 0.006551\n",
      "2021-11-11 17:46:49.994970: saving checkpoint...\n",
      "2021-11-11 17:46:50.573199: done, saving took 0.60 seconds\n",
      "2021-11-11 17:46:50.597687: This epoch took 195.152736 s\n",
      "\n",
      "2021-11-11 17:46:50.602301: \n",
      "epoch:  15\n",
      "2021-11-11 17:49:50.789977: train loss : -0.8562\n",
      "2021-11-11 17:50:04.531530: validation loss: -0.8297\n",
      "2021-11-11 17:50:04.536711: Average global foreground Dice: [0.8425]\n",
      "2021-11-11 17:50:04.541703: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:50:05.064512: lr: 0.006314\n",
      "2021-11-11 17:50:05.095332: saving checkpoint...\n",
      "2021-11-11 17:50:05.697968: done, saving took 0.62 seconds\n",
      "2021-11-11 17:50:05.722687: This epoch took 195.116221 s\n",
      "\n",
      "2021-11-11 17:50:05.728033: \n",
      "epoch:  16\n",
      "2021-11-11 17:53:06.346884: train loss : -0.8592\n",
      "2021-11-11 17:53:20.083838: validation loss: -0.8359\n",
      "2021-11-11 17:53:20.089141: Average global foreground Dice: [0.8488]\n",
      "2021-11-11 17:53:20.093938: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:53:20.660470: lr: 0.006077\n",
      "2021-11-11 17:53:20.701727: saving checkpoint...\n",
      "2021-11-11 17:53:21.329441: done, saving took 0.66 seconds\n",
      "2021-11-11 17:53:21.365110: This epoch took 195.632218 s\n",
      "\n",
      "2021-11-11 17:53:21.370202: \n",
      "epoch:  17\n",
      "2021-11-11 17:56:21.989748: train loss : -0.8610\n",
      "2021-11-11 17:56:35.743422: validation loss: -0.8437\n",
      "2021-11-11 17:56:35.748495: Average global foreground Dice: [0.8561]\n",
      "2021-11-11 17:56:35.753403: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:56:36.326670: lr: 0.005839\n",
      "2021-11-11 17:56:36.364286: saving checkpoint...\n",
      "2021-11-11 17:56:36.954132: done, saving took 0.62 seconds\n",
      "2021-11-11 17:56:36.983762: This epoch took 195.604795 s\n",
      "\n",
      "2021-11-11 17:56:36.988684: \n",
      "epoch:  18\n",
      "2021-11-11 17:59:37.606069: train loss : -0.8634\n",
      "2021-11-11 17:59:51.345467: validation loss: -0.8374\n",
      "2021-11-11 17:59:51.350840: Average global foreground Dice: [0.8504]\n",
      "2021-11-11 17:59:51.354776: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 17:59:51.911414: lr: 0.005599\n",
      "2021-11-11 17:59:51.935131: saving checkpoint...\n",
      "2021-11-11 17:59:52.511618: done, saving took 0.60 seconds\n",
      "2021-11-11 17:59:52.534726: This epoch took 195.540961 s\n",
      "\n",
      "2021-11-11 17:59:52.538816: \n",
      "epoch:  19\n",
      "2021-11-11 18:02:53.237063: train loss : -0.8650\n",
      "2021-11-11 18:03:06.968642: validation loss: -0.8373\n",
      "2021-11-11 18:03:06.973332: Average global foreground Dice: [0.8506]\n",
      "2021-11-11 18:03:06.978027: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 18:03:07.509673: lr: 0.005359\n",
      "2021-11-11 18:03:07.546316: saving checkpoint...\n",
      "2021-11-11 18:03:08.182931: done, saving took 0.67 seconds\n",
      "2021-11-11 18:03:08.210689: This epoch took 195.667809 s\n",
      "\n",
      "2021-11-11 18:03:08.215493: \n",
      "epoch:  20\n",
      "2021-11-11 18:06:08.864980: train loss : -0.8667\n",
      "2021-11-11 18:06:22.609358: validation loss: -0.8311\n",
      "2021-11-11 18:06:22.614926: Average global foreground Dice: [0.8437]\n",
      "2021-11-11 18:06:22.619522: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 18:06:23.131597: lr: 0.005117\n",
      "2021-11-11 18:06:23.168555: saving checkpoint...\n",
      "2021-11-11 18:06:23.791192: done, saving took 0.65 seconds\n",
      "2021-11-11 18:06:23.831868: This epoch took 195.611898 s\n",
      "\n",
      "2021-11-11 18:06:23.836727: \n",
      "epoch:  21\n",
      "2021-11-11 18:09:24.483602: train loss : -0.8683\n",
      "2021-11-11 18:09:38.215890: validation loss: -0.8358\n",
      "2021-11-11 18:09:38.221851: Average global foreground Dice: [0.8493]\n",
      "2021-11-11 18:09:38.226416: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 18:09:38.783496: lr: 0.004874\n",
      "2021-11-11 18:09:38.819296: saving checkpoint...\n",
      "2021-11-11 18:09:39.383728: done, saving took 0.60 seconds\n",
      "2021-11-11 18:09:39.415149: This epoch took 195.573002 s\n",
      "\n",
      "2021-11-11 18:09:39.419725: \n",
      "epoch:  22\n",
      "2021-11-11 18:12:40.116374: train loss : -0.8698\n",
      "2021-11-11 18:12:53.866922: validation loss: -0.8288\n",
      "2021-11-11 18:12:53.872261: Average global foreground Dice: [0.8413]\n",
      "2021-11-11 18:12:53.876533: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 18:12:54.384488: lr: 0.00463\n",
      "2021-11-11 18:12:54.421644: saving checkpoint...\n",
      "2021-11-11 18:12:55.045789: done, saving took 0.66 seconds\n",
      "2021-11-11 18:12:55.068508: This epoch took 195.644365 s\n",
      "\n",
      "2021-11-11 18:12:55.072670: \n",
      "epoch:  23\n",
      "2021-11-11 18:15:55.796971: train loss : -0.8718\n",
      "2021-11-11 18:16:09.518338: validation loss: -0.8340\n",
      "2021-11-11 18:16:09.523243: Average global foreground Dice: [0.8467]\n",
      "2021-11-11 18:16:09.527942: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 18:16:10.077020: lr: 0.004384\n",
      "2021-11-11 18:16:10.114156: saving checkpoint...\n",
      "2021-11-11 18:16:10.715845: done, saving took 0.63 seconds\n",
      "2021-11-11 18:16:10.739241: This epoch took 195.662016 s\n",
      "\n",
      "2021-11-11 18:16:10.744121: \n",
      "epoch:  24\n",
      "2021-11-11 18:19:11.866523: train loss : -0.8717\n",
      "2021-11-11 18:19:25.598524: validation loss: -0.8335\n",
      "2021-11-11 18:19:25.603623: Average global foreground Dice: [0.8463]\n",
      "2021-11-11 18:19:25.608422: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 18:19:26.132103: lr: 0.004136\n",
      "2021-11-11 18:19:26.155728: saving checkpoint...\n",
      "2021-11-11 18:19:26.771811: done, saving took 0.63 seconds\n",
      "2021-11-11 18:19:26.795556: This epoch took 196.047333 s\n",
      "\n",
      "2021-11-11 18:19:26.799898: \n",
      "epoch:  25\n",
      "2021-11-11 18:22:27.824313: train loss : -0.8735\n",
      "2021-11-11 18:22:41.539175: validation loss: -0.8370\n",
      "2021-11-11 18:22:41.544810: Average global foreground Dice: [0.8489]\n",
      "2021-11-11 18:22:41.550034: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 18:22:42.072879: lr: 0.003887\n",
      "2021-11-11 18:22:42.097991: saving checkpoint...\n",
      "2021-11-11 18:22:42.706029: done, saving took 0.63 seconds\n",
      "2021-11-11 18:22:42.729618: This epoch took 195.924021 s\n",
      "\n",
      "2021-11-11 18:22:42.733867: \n",
      "epoch:  26\n",
      "2021-11-11 18:25:43.780405: train loss : -0.8742\n",
      "2021-11-11 18:25:57.502438: validation loss: -0.8344\n",
      "2021-11-11 18:25:57.508796: Average global foreground Dice: [0.8464]\n",
      "2021-11-11 18:25:57.513708: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 18:25:58.087639: lr: 0.003637\n",
      "2021-11-11 18:25:58.124998: saving checkpoint...\n",
      "2021-11-11 18:25:58.710998: done, saving took 0.62 seconds\n",
      "2021-11-11 18:25:58.737418: This epoch took 195.996378 s\n",
      "\n",
      "2021-11-11 18:25:58.741994: \n",
      "epoch:  27\n",
      "2021-11-11 18:28:59.847536: train loss : -0.8773\n",
      "2021-11-11 18:29:13.580711: validation loss: -0.8391\n",
      "2021-11-11 18:29:13.585972: Average global foreground Dice: [0.8504]\n",
      "2021-11-11 18:29:13.590795: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 18:29:14.103620: lr: 0.003384\n",
      "2021-11-11 18:29:14.127834: saving checkpoint...\n",
      "2021-11-11 18:29:14.724359: done, saving took 0.62 seconds\n",
      "2021-11-11 18:29:14.750885: This epoch took 196.003817 s\n",
      "\n",
      "2021-11-11 18:29:14.755370: \n",
      "epoch:  28\n",
      "2021-11-11 18:32:16.008653: train loss : -0.8782\n",
      "2021-11-11 18:32:29.722524: validation loss: -0.8360\n",
      "2021-11-11 18:32:29.728264: Average global foreground Dice: [0.8482]\n",
      "2021-11-11 18:32:29.733183: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 18:32:30.284693: lr: 0.003129\n",
      "2021-11-11 18:32:30.322293: saving checkpoint...\n",
      "2021-11-11 18:32:30.892913: done, saving took 0.60 seconds\n",
      "2021-11-11 18:32:30.919064: This epoch took 196.159243 s\n",
      "\n",
      "2021-11-11 18:32:30.924154: \n",
      "epoch:  29\n",
      "2021-11-11 18:35:32.331396: train loss : -0.8795\n",
      "2021-11-11 18:35:46.087467: validation loss: -0.8397\n",
      "2021-11-11 18:35:46.093003: Average global foreground Dice: [0.85]\n",
      "2021-11-11 18:35:46.097957: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 18:35:46.606366: lr: 0.002872\n",
      "2021-11-11 18:35:46.647987: saving checkpoint...\n",
      "2021-11-11 18:35:47.244168: done, saving took 0.63 seconds\n",
      "2021-11-11 18:35:47.269130: This epoch took 196.340343 s\n",
      "\n",
      "2021-11-11 18:35:47.274146: \n",
      "epoch:  30\n",
      "2021-11-11 18:38:48.514926: train loss : -0.8807\n",
      "2021-11-11 18:39:02.253866: validation loss: -0.8391\n",
      "2021-11-11 18:39:02.261317: Average global foreground Dice: [0.85]\n",
      "2021-11-11 18:39:02.265180: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 18:39:02.809187: lr: 0.002612\n",
      "2021-11-11 18:39:02.831615: saving checkpoint...\n",
      "2021-11-11 18:39:03.421645: done, saving took 0.61 seconds\n",
      "2021-11-11 18:39:03.443956: This epoch took 196.165735 s\n",
      "\n",
      "2021-11-11 18:39:03.447681: \n",
      "epoch:  31\n",
      "2021-11-11 18:42:04.729302: train loss : -0.8814\n",
      "2021-11-11 18:42:18.459507: validation loss: -0.8351\n",
      "2021-11-11 18:42:18.464498: Average global foreground Dice: [0.8474]\n",
      "2021-11-11 18:42:18.469190: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 18:42:19.086271: lr: 0.002349\n",
      "2021-11-11 18:42:19.120467: saving checkpoint...\n",
      "2021-11-11 18:42:19.738818: done, saving took 0.65 seconds\n",
      "2021-11-11 18:42:19.764405: This epoch took 196.312039 s\n",
      "\n",
      "2021-11-11 18:42:19.768649: \n",
      "epoch:  32\n",
      "2021-11-11 18:45:21.692420: train loss : -0.8830\n",
      "2021-11-11 18:45:35.466502: validation loss: -0.8323\n",
      "2021-11-11 18:45:35.472861: Average global foreground Dice: [0.8457]\n",
      "2021-11-11 18:45:35.477837: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 18:45:35.990010: lr: 0.002083\n",
      "2021-11-11 18:45:36.022695: saving checkpoint...\n",
      "2021-11-11 18:45:36.643206: done, saving took 0.65 seconds\n",
      "2021-11-11 18:45:36.669751: This epoch took 196.895057 s\n",
      "\n",
      "2021-11-11 18:45:36.674029: \n",
      "epoch:  33\n",
      "2021-11-11 18:48:38.400713: train loss : -0.8846\n",
      "2021-11-11 18:48:52.139849: validation loss: -0.8374\n",
      "2021-11-11 18:48:52.145337: Average global foreground Dice: [0.8489]\n",
      "2021-11-11 18:48:52.149902: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 18:48:52.719263: lr: 0.001813\n",
      "2021-11-11 18:48:52.744147: saving checkpoint...\n",
      "2021-11-11 18:48:53.344845: done, saving took 0.62 seconds\n",
      "2021-11-11 18:48:53.367946: This epoch took 196.689285 s\n",
      "\n",
      "2021-11-11 18:48:53.372410: \n",
      "epoch:  34\n",
      "2021-11-11 18:51:55.064785: train loss : -0.8855\n",
      "2021-11-11 18:52:08.789552: validation loss: -0.8347\n",
      "2021-11-11 18:52:08.795597: Average global foreground Dice: [0.847]\n",
      "2021-11-11 18:52:08.800105: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 18:52:09.343111: lr: 0.001539\n",
      "2021-11-11 18:52:09.367136: saving checkpoint...\n",
      "2021-11-11 18:52:10.071343: done, saving took 0.72 seconds\n",
      "2021-11-11 18:52:10.097487: This epoch took 196.718211 s\n",
      "\n",
      "2021-11-11 18:52:10.103288: \n",
      "epoch:  35\n",
      "2021-11-11 18:55:11.793246: train loss : -0.8864\n",
      "2021-11-11 18:55:25.539209: validation loss: -0.8338\n",
      "2021-11-11 18:55:25.545846: Average global foreground Dice: [0.8465]\n",
      "2021-11-11 18:55:25.551005: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 18:55:26.057902: lr: 0.001259\n",
      "2021-11-11 18:55:26.080977: saving checkpoint...\n",
      "2021-11-11 18:55:26.663891: done, saving took 0.60 seconds\n",
      "2021-11-11 18:55:26.685789: This epoch took 196.577893 s\n",
      "\n",
      "2021-11-11 18:55:26.689721: \n",
      "epoch:  36\n",
      "2021-11-11 18:58:28.283758: train loss : -0.8871\n",
      "2021-11-11 18:58:42.036973: validation loss: -0.8360\n",
      "2021-11-11 18:58:42.041627: Average global foreground Dice: [0.8472]\n",
      "2021-11-11 18:58:42.045828: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 18:58:42.614577: lr: 0.000972\n",
      "2021-11-11 18:58:42.637882: saving checkpoint...\n",
      "2021-11-11 18:58:43.261047: done, saving took 0.64 seconds\n",
      "2021-11-11 18:58:43.283710: This epoch took 196.589417 s\n",
      "\n",
      "2021-11-11 18:58:43.288793: \n",
      "epoch:  37\n",
      "2021-11-11 19:01:44.878092: train loss : -0.8883\n",
      "2021-11-11 19:01:58.628778: validation loss: -0.8338\n",
      "2021-11-11 19:01:58.633947: Average global foreground Dice: [0.8456]\n",
      "2021-11-11 19:01:58.638812: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 19:01:59.180016: lr: 0.000675\n",
      "2021-11-11 19:01:59.202677: saving checkpoint...\n",
      "2021-11-11 19:01:59.766878: done, saving took 0.58 seconds\n",
      "2021-11-11 19:01:59.788635: This epoch took 196.492667 s\n",
      "\n",
      "2021-11-11 19:01:59.792296: \n",
      "epoch:  38\n",
      "2021-11-11 19:05:01.569719: train loss : -0.8901\n",
      "2021-11-11 19:05:15.313445: validation loss: -0.8334\n",
      "2021-11-11 19:05:15.319360: Average global foreground Dice: [0.8457]\n",
      "2021-11-11 19:05:15.323213: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 19:05:15.822437: lr: 0.000362\n",
      "2021-11-11 19:05:15.846539: saving checkpoint...\n",
      "2021-11-11 19:05:16.451169: done, saving took 0.62 seconds\n",
      "2021-11-11 19:05:16.473078: This epoch took 196.676738 s\n",
      "\n",
      "2021-11-11 19:05:16.477663: \n",
      "epoch:  39\n",
      "2021-11-11 19:08:18.198102: train loss : -0.8904\n",
      "2021-11-11 19:08:31.932622: validation loss: -0.8334\n",
      "2021-11-11 19:08:31.937901: Average global foreground Dice: [0.8454]\n",
      "2021-11-11 19:08:31.942555: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 19:08:32.474468: lr: 0.0\n",
      "2021-11-11 19:08:32.481085: This epoch took 195.998629 s\n",
      "\n",
      "2021-11-11 19:08:32.508546: saving checkpoint...\n",
      "2021-11-11 19:08:33.056479: done, saving took 0.57 seconds\n",
      "23090559_20150812 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120330 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090563_20151216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130226 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090584_20120523 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090589_20140219 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090592_20130218 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090614_20120402 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090620_20130617 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090627_20160608 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090628_20150204 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090635_20140710 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090640_20140711 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121227 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-11 19:10:33.179507: finished prediction\n",
      "2021-11-11 19:10:33.184302: evaluation of raw predictions\n",
      "2021-11-11 19:10:34.971556: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.837010836511804\n",
      "after:  0.8373180869164867\n",
      "Removing all but the largest foreground region improved results!\n",
      "for_which_classes [1]\n",
      "min_valid_object_sizes None\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[[1]]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-11 19:10:44.209486: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-11 19:10:44.223109: The split file contains 5 splits.\n",
      "2021-11-11 19:10:44.227600: Desired fold for training: 1\n",
      "2021-11-11 19:10:44.231322: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-11 19:10:48.421169: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-11 19:10:59.923056: Unable to plot network architecture:\n",
      "2021-11-11 19:10:59.927888: No module named 'hiddenlayer'\n",
      "2021-11-11 19:10:59.959595: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-11 19:10:59.965263: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-11 19:10:59.973855: \n",
      "\n",
      "2021-11-11 19:10:59.978592: \n",
      "epoch:  0\n",
      "2021-11-11 19:14:15.396726: train loss : -0.2339\n",
      "2021-11-11 19:14:28.842963: validation loss: -0.6401\n",
      "2021-11-11 19:14:28.848470: Average global foreground Dice: [0.7175]\n",
      "2021-11-11 19:14:28.852448: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 19:14:29.303547: lr: 0.009775\n",
      "2021-11-11 19:14:29.307910: This epoch took 209.325032 s\n",
      "\n",
      "2021-11-11 19:14:29.312444: \n",
      "epoch:  1\n",
      "2021-11-11 19:17:27.981405: train loss : -0.6702\n",
      "2021-11-11 19:17:41.421756: validation loss: -0.7220\n",
      "2021-11-11 19:17:41.426449: Average global foreground Dice: [0.7867]\n",
      "2021-11-11 19:17:41.430461: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 19:17:42.040708: lr: 0.009549\n",
      "2021-11-11 19:17:42.086601: saving checkpoint...\n",
      "2021-11-11 19:17:42.610323: done, saving took 0.56 seconds\n",
      "2021-11-11 19:17:42.635350: This epoch took 193.318115 s\n",
      "\n",
      "2021-11-11 19:17:42.640284: \n",
      "epoch:  2\n",
      "2021-11-11 19:20:40.932494: train loss : -0.7613\n",
      "2021-11-11 19:20:54.390016: validation loss: -0.7910\n",
      "2021-11-11 19:20:54.395599: Average global foreground Dice: [0.8065]\n",
      "2021-11-11 19:20:54.399924: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 19:20:54.916731: lr: 0.009322\n",
      "2021-11-11 19:20:54.949150: saving checkpoint...\n",
      "2021-11-11 19:20:55.533413: done, saving took 0.61 seconds\n",
      "2021-11-11 19:20:55.555800: This epoch took 192.911227 s\n",
      "\n",
      "2021-11-11 19:20:55.559648: \n",
      "epoch:  3\n",
      "2021-11-11 19:23:53.763377: train loss : -0.7989\n",
      "2021-11-11 19:24:07.207570: validation loss: -0.8071\n",
      "2021-11-11 19:24:07.213177: Average global foreground Dice: [0.8229]\n",
      "2021-11-11 19:24:07.217406: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 19:24:07.751966: lr: 0.009095\n",
      "2021-11-11 19:24:07.774278: saving checkpoint...\n",
      "2021-11-11 19:24:08.375153: done, saving took 0.62 seconds\n",
      "2021-11-11 19:24:08.395926: This epoch took 192.832089 s\n",
      "\n",
      "2021-11-11 19:24:08.399906: \n",
      "epoch:  4\n",
      "2021-11-11 19:27:06.513757: train loss : -0.8144\n",
      "2021-11-11 19:27:19.986684: validation loss: -0.8146\n",
      "2021-11-11 19:27:19.992759: Average global foreground Dice: [0.8266]\n",
      "2021-11-11 19:27:19.996843: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 19:27:20.508085: lr: 0.008868\n",
      "2021-11-11 19:27:20.541271: saving checkpoint...\n",
      "2021-11-11 19:27:21.170538: done, saving took 0.66 seconds\n",
      "2021-11-11 19:27:21.193272: This epoch took 192.789265 s\n",
      "\n",
      "2021-11-11 19:27:21.197257: \n",
      "epoch:  5\n",
      "2021-11-11 19:30:19.255547: train loss : -0.8232\n",
      "2021-11-11 19:30:32.690847: validation loss: -0.8148\n",
      "2021-11-11 19:30:32.696308: Average global foreground Dice: [0.8288]\n",
      "2021-11-11 19:30:32.700873: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 19:30:33.250668: lr: 0.008639\n",
      "2021-11-11 19:30:33.274312: saving checkpoint...\n",
      "2021-11-11 19:30:33.895361: done, saving took 0.64 seconds\n",
      "2021-11-11 19:30:33.919060: This epoch took 192.717170 s\n",
      "\n",
      "2021-11-11 19:30:33.923292: \n",
      "epoch:  6\n",
      "2021-11-11 19:33:32.107325: train loss : -0.8282\n",
      "2021-11-11 19:33:45.545172: validation loss: -0.8167\n",
      "2021-11-11 19:33:45.550397: Average global foreground Dice: [0.83]\n",
      "2021-11-11 19:33:45.555322: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 19:33:46.173837: lr: 0.00841\n",
      "2021-11-11 19:33:46.206808: saving checkpoint...\n",
      "2021-11-11 19:33:46.796723: done, saving took 0.62 seconds\n",
      "2021-11-11 19:33:46.821162: This epoch took 192.893182 s\n",
      "\n",
      "2021-11-11 19:33:46.825004: \n",
      "epoch:  7\n",
      "2021-11-11 19:36:44.728959: train loss : -0.8339\n",
      "2021-11-11 19:36:58.188842: validation loss: -0.8281\n",
      "2021-11-11 19:36:58.194058: Average global foreground Dice: [0.8416]\n",
      "2021-11-11 19:36:58.198934: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 19:36:58.696473: lr: 0.008181\n",
      "2021-11-11 19:36:58.719514: saving checkpoint...\n",
      "2021-11-11 19:36:59.289521: done, saving took 0.59 seconds\n",
      "2021-11-11 19:36:59.311234: This epoch took 192.481781 s\n",
      "\n",
      "2021-11-11 19:36:59.314917: \n",
      "epoch:  8\n",
      "2021-11-11 19:39:57.761517: train loss : -0.8373\n",
      "2021-11-11 19:40:11.218711: validation loss: -0.8180\n",
      "2021-11-11 19:40:11.223493: Average global foreground Dice: [0.8321]\n",
      "2021-11-11 19:40:11.227900: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 19:40:11.763670: lr: 0.00795\n",
      "2021-11-11 19:40:11.797674: saving checkpoint...\n",
      "2021-11-11 19:40:12.387160: done, saving took 0.62 seconds\n",
      "2021-11-11 19:40:12.409490: This epoch took 193.089932 s\n",
      "\n",
      "2021-11-11 19:40:12.413246: \n",
      "epoch:  9\n",
      "2021-11-11 19:43:11.052236: train loss : -0.8435\n",
      "2021-11-11 19:43:24.495251: validation loss: -0.8242\n",
      "2021-11-11 19:43:24.500849: Average global foreground Dice: [0.836]\n",
      "2021-11-11 19:43:24.505732: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 19:43:25.041293: lr: 0.007719\n",
      "2021-11-11 19:43:25.072583: saving checkpoint...\n",
      "2021-11-11 19:43:25.667595: done, saving took 0.62 seconds\n",
      "2021-11-11 19:43:25.688912: This epoch took 193.271001 s\n",
      "\n",
      "2021-11-11 19:43:25.693270: \n",
      "epoch:  10\n",
      "2021-11-11 19:46:24.361836: train loss : -0.8463\n",
      "2021-11-11 19:46:37.790880: validation loss: -0.8229\n",
      "2021-11-11 19:46:37.795702: Average global foreground Dice: [0.8345]\n",
      "2021-11-11 19:46:37.800304: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 19:46:38.312143: lr: 0.007487\n",
      "2021-11-11 19:46:38.335529: saving checkpoint...\n",
      "2021-11-11 19:46:38.913557: done, saving took 0.60 seconds\n",
      "2021-11-11 19:46:38.936558: This epoch took 193.238629 s\n",
      "\n",
      "2021-11-11 19:46:38.940809: \n",
      "epoch:  11\n",
      "2021-11-11 19:49:37.638400: train loss : -0.8481\n",
      "2021-11-11 19:49:51.095067: validation loss: -0.8180\n",
      "2021-11-11 19:49:51.100954: Average global foreground Dice: [0.8288]\n",
      "2021-11-11 19:49:51.105510: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 19:49:51.661277: lr: 0.007254\n",
      "2021-11-11 19:49:51.683720: saving checkpoint...\n",
      "2021-11-11 19:49:52.386606: done, saving took 0.72 seconds\n",
      "2021-11-11 19:49:52.421680: This epoch took 193.476343 s\n",
      "\n",
      "2021-11-11 19:49:52.426344: \n",
      "epoch:  12\n",
      "2021-11-11 19:52:51.075393: train loss : -0.8515\n",
      "2021-11-11 19:53:04.500313: validation loss: -0.8291\n",
      "2021-11-11 19:53:04.505518: Average global foreground Dice: [0.842]\n",
      "2021-11-11 19:53:04.510110: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 19:53:05.055256: lr: 0.007021\n",
      "2021-11-11 19:53:05.089685: saving checkpoint...\n",
      "2021-11-11 19:53:05.749105: done, saving took 0.69 seconds\n",
      "2021-11-11 19:53:05.771317: This epoch took 193.340933 s\n",
      "\n",
      "2021-11-11 19:53:05.775578: \n",
      "epoch:  13\n",
      "2021-11-11 19:56:04.417438: train loss : -0.8531\n",
      "2021-11-11 19:56:17.882833: validation loss: -0.8269\n",
      "2021-11-11 19:56:17.888110: Average global foreground Dice: [0.8394]\n",
      "2021-11-11 19:56:17.892252: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 19:56:18.402483: lr: 0.006786\n",
      "2021-11-11 19:56:18.425941: saving checkpoint...\n",
      "2021-11-11 19:56:19.186663: done, saving took 0.78 seconds\n",
      "2021-11-11 19:56:19.208982: This epoch took 193.429011 s\n",
      "\n",
      "2021-11-11 19:56:19.213459: \n",
      "epoch:  14\n",
      "2021-11-11 19:59:17.804310: train loss : -0.8562\n",
      "2021-11-11 19:59:31.236344: validation loss: -0.8195\n",
      "2021-11-11 19:59:31.241474: Average global foreground Dice: [0.8293]\n",
      "2021-11-11 19:59:31.245624: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 19:59:31.738713: lr: 0.006551\n",
      "2021-11-11 19:59:31.762599: saving checkpoint...\n",
      "2021-11-11 19:59:32.359969: done, saving took 0.62 seconds\n",
      "2021-11-11 19:59:32.381272: This epoch took 193.163434 s\n",
      "\n",
      "2021-11-11 19:59:32.385777: \n",
      "epoch:  15\n",
      "2021-11-11 20:02:31.064235: train loss : -0.8583\n",
      "2021-11-11 20:02:44.514538: validation loss: -0.8302\n",
      "2021-11-11 20:02:44.519843: Average global foreground Dice: [0.8416]\n",
      "2021-11-11 20:02:44.524941: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 20:02:45.083304: lr: 0.006314\n",
      "2021-11-11 20:02:45.106320: saving checkpoint...\n",
      "2021-11-11 20:02:45.733534: done, saving took 0.65 seconds\n",
      "2021-11-11 20:02:45.755386: This epoch took 193.365483 s\n",
      "\n",
      "2021-11-11 20:02:45.759290: \n",
      "epoch:  16\n",
      "2021-11-11 20:05:44.906720: train loss : -0.8597\n",
      "2021-11-11 20:05:58.353253: validation loss: -0.8321\n",
      "2021-11-11 20:05:58.358486: Average global foreground Dice: [0.8414]\n",
      "2021-11-11 20:05:58.362884: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 20:05:58.899078: lr: 0.006077\n",
      "2021-11-11 20:05:58.921592: saving checkpoint...\n",
      "2021-11-11 20:05:59.509696: done, saving took 0.61 seconds\n",
      "2021-11-11 20:05:59.530449: This epoch took 193.766854 s\n",
      "\n",
      "2021-11-11 20:05:59.535026: \n",
      "epoch:  17\n",
      "2021-11-11 20:08:58.693392: train loss : -0.8615\n",
      "2021-11-11 20:09:12.127669: validation loss: -0.8304\n",
      "2021-11-11 20:09:12.132745: Average global foreground Dice: [0.841]\n",
      "2021-11-11 20:09:12.137212: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 20:09:12.709053: lr: 0.005839\n",
      "2021-11-11 20:09:12.742714: saving checkpoint...\n",
      "2021-11-11 20:09:13.346343: done, saving took 0.63 seconds\n",
      "2021-11-11 20:09:13.370115: This epoch took 193.830462 s\n",
      "\n",
      "2021-11-11 20:09:13.375057: \n",
      "epoch:  18\n",
      "2021-11-11 20:12:12.458503: train loss : -0.8637\n",
      "2021-11-11 20:12:25.926542: validation loss: -0.8360\n",
      "2021-11-11 20:12:25.931190: Average global foreground Dice: [0.8455]\n",
      "2021-11-11 20:12:25.935204: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 20:12:26.473909: lr: 0.005599\n",
      "2021-11-11 20:12:26.507845: saving checkpoint...\n",
      "2021-11-11 20:12:27.094944: done, saving took 0.62 seconds\n",
      "2021-11-11 20:12:27.118589: This epoch took 193.738674 s\n",
      "\n",
      "2021-11-11 20:12:27.123390: \n",
      "epoch:  19\n",
      "2021-11-11 20:15:26.266831: train loss : -0.8660\n",
      "2021-11-11 20:15:39.717257: validation loss: -0.8284\n",
      "2021-11-11 20:15:39.722653: Average global foreground Dice: [0.8404]\n",
      "2021-11-11 20:15:39.727299: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 20:15:40.230227: lr: 0.005359\n",
      "2021-11-11 20:15:40.253488: saving checkpoint...\n",
      "2021-11-11 20:15:40.883776: done, saving took 0.65 seconds\n",
      "2021-11-11 20:15:40.905314: This epoch took 193.777456 s\n",
      "\n",
      "2021-11-11 20:15:40.909400: \n",
      "epoch:  20\n",
      "2021-11-11 20:18:40.049582: train loss : -0.8682\n",
      "2021-11-11 20:18:53.499319: validation loss: -0.8347\n",
      "2021-11-11 20:18:53.504802: Average global foreground Dice: [0.8444]\n",
      "2021-11-11 20:18:53.508798: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 20:18:54.026832: lr: 0.005117\n",
      "2021-11-11 20:18:54.050228: saving checkpoint...\n",
      "2021-11-11 20:18:54.714395: done, saving took 0.68 seconds\n",
      "2021-11-11 20:18:54.746858: This epoch took 193.832628 s\n",
      "\n",
      "2021-11-11 20:18:54.750702: \n",
      "epoch:  21\n",
      "2021-11-11 20:21:53.859566: train loss : -0.8692\n",
      "2021-11-11 20:22:07.311982: validation loss: -0.8220\n",
      "2021-11-11 20:22:07.316437: Average global foreground Dice: [0.835]\n",
      "2021-11-11 20:22:07.321669: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 20:22:07.820439: lr: 0.004874\n",
      "2021-11-11 20:22:07.844517: saving checkpoint...\n",
      "2021-11-11 20:22:08.425009: done, saving took 0.60 seconds\n",
      "2021-11-11 20:22:08.448359: This epoch took 193.693758 s\n",
      "\n",
      "2021-11-11 20:22:08.452439: \n",
      "epoch:  22\n",
      "2021-11-11 20:25:07.770921: train loss : -0.8712\n",
      "2021-11-11 20:25:21.242778: validation loss: -0.8272\n",
      "2021-11-11 20:25:21.247978: Average global foreground Dice: [0.8398]\n",
      "2021-11-11 20:25:21.252838: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 20:25:21.813341: lr: 0.00463\n",
      "2021-11-11 20:25:21.856828: saving checkpoint...\n",
      "2021-11-11 20:25:22.437606: done, saving took 0.61 seconds\n",
      "2021-11-11 20:25:22.458809: This epoch took 194.002198 s\n",
      "\n",
      "2021-11-11 20:25:22.463670: \n",
      "epoch:  23\n",
      "2021-11-11 20:28:21.748259: train loss : -0.8724\n",
      "2021-11-11 20:28:35.217865: validation loss: -0.8363\n",
      "2021-11-11 20:28:35.223098: Average global foreground Dice: [0.8463]\n",
      "2021-11-11 20:28:35.228103: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 20:28:35.793220: lr: 0.004384\n",
      "2021-11-11 20:28:35.816563: saving checkpoint...\n",
      "2021-11-11 20:28:36.492271: done, saving took 0.69 seconds\n",
      "2021-11-11 20:28:36.526650: This epoch took 194.058561 s\n",
      "\n",
      "2021-11-11 20:28:36.530812: \n",
      "epoch:  24\n",
      "2021-11-11 20:31:36.051033: train loss : -0.8737\n",
      "2021-11-11 20:31:49.513397: validation loss: -0.8367\n",
      "2021-11-11 20:31:49.518863: Average global foreground Dice: [0.8477]\n",
      "2021-11-11 20:31:49.523230: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 20:31:50.103877: lr: 0.004136\n",
      "2021-11-11 20:31:50.126656: saving checkpoint...\n",
      "2021-11-11 20:31:50.758390: done, saving took 0.65 seconds\n",
      "2021-11-11 20:31:50.780110: This epoch took 194.245669 s\n",
      "\n",
      "2021-11-11 20:31:50.784789: \n",
      "epoch:  25\n",
      "2021-11-11 20:34:50.248010: train loss : -0.8760\n",
      "2021-11-11 20:35:03.712004: validation loss: -0.8345\n",
      "2021-11-11 20:35:03.717030: Average global foreground Dice: [0.8454]\n",
      "2021-11-11 20:35:03.723282: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 20:35:04.250797: lr: 0.003887\n",
      "2021-11-11 20:35:04.274177: saving checkpoint...\n",
      "2021-11-11 20:35:04.884994: done, saving took 0.63 seconds\n",
      "2021-11-11 20:35:04.908630: This epoch took 194.120107 s\n",
      "\n",
      "2021-11-11 20:35:04.912290: \n",
      "epoch:  26\n",
      "2021-11-11 20:38:04.518705: train loss : -0.8742\n",
      "2021-11-11 20:38:17.978069: validation loss: -0.8298\n",
      "2021-11-11 20:38:17.983822: Average global foreground Dice: [0.8417]\n",
      "2021-11-11 20:38:17.988863: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 20:38:18.553277: lr: 0.003637\n",
      "2021-11-11 20:38:18.576805: saving checkpoint...\n",
      "2021-11-11 20:38:19.158347: done, saving took 0.60 seconds\n",
      "2021-11-11 20:38:19.192964: This epoch took 194.276315 s\n",
      "\n",
      "2021-11-11 20:38:19.197343: \n",
      "epoch:  27\n",
      "2021-11-11 20:41:18.799829: train loss : -0.8781\n",
      "2021-11-11 20:41:32.249929: validation loss: -0.8301\n",
      "2021-11-11 20:41:32.254811: Average global foreground Dice: [0.8395]\n",
      "2021-11-11 20:41:32.258889: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 20:41:32.846886: lr: 0.003384\n",
      "2021-11-11 20:41:32.869967: saving checkpoint...\n",
      "2021-11-11 20:41:33.430057: done, saving took 0.58 seconds\n",
      "2021-11-11 20:41:33.452045: This epoch took 194.250036 s\n",
      "\n",
      "2021-11-11 20:41:33.456771: \n",
      "epoch:  28\n",
      "2021-11-11 20:44:32.946955: train loss : -0.8798\n",
      "2021-11-11 20:44:46.392610: validation loss: -0.8289\n",
      "2021-11-11 20:44:46.398121: Average global foreground Dice: [0.8396]\n",
      "2021-11-11 20:44:46.405258: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 20:44:46.959232: lr: 0.003129\n",
      "2021-11-11 20:44:46.982975: saving checkpoint...\n",
      "2021-11-11 20:44:47.560339: done, saving took 0.60 seconds\n",
      "2021-11-11 20:44:47.586643: This epoch took 194.125364 s\n",
      "\n",
      "2021-11-11 20:44:47.591501: \n",
      "epoch:  29\n",
      "2021-11-11 20:47:47.109878: train loss : -0.8805\n",
      "2021-11-11 20:48:00.556053: validation loss: -0.8354\n",
      "2021-11-11 20:48:00.560721: Average global foreground Dice: [0.8449]\n",
      "2021-11-11 20:48:00.564847: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 20:48:01.088369: lr: 0.002872\n",
      "2021-11-11 20:48:01.111686: saving checkpoint...\n",
      "2021-11-11 20:48:01.759994: done, saving took 0.67 seconds\n",
      "2021-11-11 20:48:01.788525: This epoch took 194.192657 s\n",
      "\n",
      "2021-11-11 20:48:01.793394: \n",
      "epoch:  30\n",
      "2021-11-11 20:51:01.394085: train loss : -0.8816\n",
      "2021-11-11 20:51:14.827086: validation loss: -0.8266\n",
      "2021-11-11 20:51:14.832394: Average global foreground Dice: [0.8389]\n",
      "2021-11-11 20:51:14.836930: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 20:51:15.386258: lr: 0.002612\n",
      "2021-11-11 20:51:15.409110: saving checkpoint...\n",
      "2021-11-11 20:51:16.097115: done, saving took 0.71 seconds\n",
      "2021-11-11 20:51:16.129721: This epoch took 194.332069 s\n",
      "\n",
      "2021-11-11 20:51:16.134632: \n",
      "epoch:  31\n",
      "2021-11-11 20:54:15.680082: train loss : -0.8838\n",
      "2021-11-11 20:54:29.116705: validation loss: -0.8234\n",
      "2021-11-11 20:54:29.121505: Average global foreground Dice: [0.8335]\n",
      "2021-11-11 20:54:29.126138: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 20:54:29.671750: lr: 0.002349\n",
      "2021-11-11 20:54:29.676643: This epoch took 193.538010 s\n",
      "\n",
      "2021-11-11 20:54:29.681149: \n",
      "epoch:  32\n",
      "2021-11-11 20:57:29.597749: train loss : -0.8834\n",
      "2021-11-11 20:57:43.051774: validation loss: -0.8295\n",
      "2021-11-11 20:57:43.056316: Average global foreground Dice: [0.8419]\n",
      "2021-11-11 20:57:43.060806: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 20:57:43.676650: lr: 0.002083\n",
      "2021-11-11 20:57:43.700087: saving checkpoint...\n",
      "2021-11-11 20:57:44.337657: done, saving took 0.66 seconds\n",
      "2021-11-11 20:57:44.360429: This epoch took 194.674814 s\n",
      "\n",
      "2021-11-11 20:57:44.365196: \n",
      "epoch:  33\n",
      "2021-11-11 21:00:44.296805: train loss : -0.8853\n",
      "2021-11-11 21:00:57.777225: validation loss: -0.8329\n",
      "2021-11-11 21:00:57.782797: Average global foreground Dice: [0.8427]\n",
      "2021-11-11 21:00:57.787693: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 21:00:58.305032: lr: 0.001813\n",
      "2021-11-11 21:00:58.329185: saving checkpoint...\n",
      "2021-11-11 21:00:59.006531: done, saving took 0.70 seconds\n",
      "2021-11-11 21:00:59.031589: This epoch took 194.662674 s\n",
      "\n",
      "2021-11-11 21:00:59.035142: \n",
      "epoch:  34\n",
      "2021-11-11 21:03:58.875767: train loss : -0.8864\n",
      "2021-11-11 21:04:12.324844: validation loss: -0.8343\n",
      "2021-11-11 21:04:12.330299: Average global foreground Dice: [0.8444]\n",
      "2021-11-11 21:04:12.334345: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 21:04:12.875159: lr: 0.001539\n",
      "2021-11-11 21:04:12.898106: saving checkpoint...\n",
      "2021-11-11 21:04:13.510075: done, saving took 0.63 seconds\n",
      "2021-11-11 21:04:13.535863: This epoch took 194.496418 s\n",
      "\n",
      "2021-11-11 21:04:13.539766: \n",
      "epoch:  35\n",
      "2021-11-11 21:07:13.402451: train loss : -0.8882\n",
      "2021-11-11 21:07:26.835311: validation loss: -0.8336\n",
      "2021-11-11 21:07:26.841664: Average global foreground Dice: [0.8435]\n",
      "2021-11-11 21:07:26.846379: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 21:07:27.390937: lr: 0.001259\n",
      "2021-11-11 21:07:27.414912: saving checkpoint...\n",
      "2021-11-11 21:07:28.011386: done, saving took 0.62 seconds\n",
      "2021-11-11 21:07:28.033948: This epoch took 194.489645 s\n",
      "\n",
      "2021-11-11 21:07:28.038638: \n",
      "epoch:  36\n",
      "2021-11-11 21:10:27.834473: train loss : -0.8893\n",
      "2021-11-11 21:10:41.298759: validation loss: -0.8344\n",
      "2021-11-11 21:10:41.304205: Average global foreground Dice: [0.8447]\n",
      "2021-11-11 21:10:41.308408: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 21:10:41.834853: lr: 0.000972\n",
      "2021-11-11 21:10:41.861623: saving checkpoint...\n",
      "2021-11-11 21:10:42.555746: done, saving took 0.71 seconds\n",
      "2021-11-11 21:10:42.585494: This epoch took 194.542083 s\n",
      "\n",
      "2021-11-11 21:10:42.590151: \n",
      "epoch:  37\n",
      "2021-11-11 21:13:42.478744: train loss : -0.8896\n",
      "2021-11-11 21:13:55.947004: validation loss: -0.8328\n",
      "2021-11-11 21:13:55.952393: Average global foreground Dice: [0.8432]\n",
      "2021-11-11 21:13:55.957108: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 21:13:56.546602: lr: 0.000675\n",
      "2021-11-11 21:13:56.569914: saving checkpoint...\n",
      "2021-11-11 21:13:57.204007: done, saving took 0.65 seconds\n",
      "2021-11-11 21:13:57.229807: This epoch took 194.635518 s\n",
      "\n",
      "2021-11-11 21:13:57.234678: \n",
      "epoch:  38\n",
      "2021-11-11 21:16:57.054057: train loss : -0.8909\n",
      "2021-11-11 21:17:10.489716: validation loss: -0.8309\n",
      "2021-11-11 21:17:10.496899: Average global foreground Dice: [0.8414]\n",
      "2021-11-11 21:17:10.501523: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 21:17:11.015220: lr: 0.000362\n",
      "2021-11-11 21:17:11.038834: saving checkpoint...\n",
      "2021-11-11 21:17:11.616381: done, saving took 0.60 seconds\n",
      "2021-11-11 21:17:11.637904: This epoch took 194.399280 s\n",
      "\n",
      "2021-11-11 21:17:11.642872: \n",
      "epoch:  39\n",
      "2021-11-11 21:20:11.540851: train loss : -0.8922\n",
      "2021-11-11 21:20:24.999517: validation loss: -0.8322\n",
      "2021-11-11 21:20:25.004302: Average global foreground Dice: [0.8431]\n",
      "2021-11-11 21:20:25.010918: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 21:20:25.547145: lr: 0.0\n",
      "2021-11-11 21:20:25.571047: saving checkpoint...\n",
      "2021-11-11 21:20:26.143641: done, saving took 0.59 seconds\n",
      "2021-11-11 21:20:26.170710: This epoch took 194.523954 s\n",
      "\n",
      "2021-11-11 21:20:26.193018: saving checkpoint...\n",
      "2021-11-11 21:20:26.701410: done, saving took 0.53 seconds\n",
      "23090567_20160819 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150401 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130213 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120627 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090590_20121212 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160706 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090599_20140701 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130225 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090604_20140303 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090615_20140403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090617_20140211 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120406 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160111 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130213 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090631_20130128 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090634_20150409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-11 21:22:24.045210: finished prediction\n",
      "2021-11-11 21:22:24.049363: evaluation of raw predictions\n",
      "2021-11-11 21:22:25.521256: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8414973744924925\n",
      "after:  0.84178313149226\n",
      "Removing all but the largest foreground region improved results!\n",
      "for_which_classes [1]\n",
      "min_valid_object_sizes None\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[[1]]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-11 21:22:35.082950: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-11 21:22:35.096620: The split file contains 5 splits.\n",
      "2021-11-11 21:22:35.101284: Desired fold for training: 2\n",
      "2021-11-11 21:22:35.105153: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-11 21:22:39.276119: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-11 21:22:51.024625: Unable to plot network architecture:\n",
      "2021-11-11 21:22:51.028558: No module named 'hiddenlayer'\n",
      "2021-11-11 21:22:51.059522: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-11 21:22:51.063184: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-11 21:22:51.070765: \n",
      "\n",
      "2021-11-11 21:22:51.075095: \n",
      "epoch:  0\n",
      "2021-11-11 21:26:07.222457: train loss : -0.2747\n",
      "2021-11-11 21:26:20.663680: validation loss: -0.6277\n",
      "2021-11-11 21:26:20.668113: Average global foreground Dice: [0.696]\n",
      "2021-11-11 21:26:20.673655: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 21:26:21.105928: lr: 0.009775\n",
      "2021-11-11 21:26:21.110535: This epoch took 210.030968 s\n",
      "\n",
      "2021-11-11 21:26:21.114355: \n",
      "epoch:  1\n",
      "2021-11-11 21:29:19.755677: train loss : -0.6766\n",
      "2021-11-11 21:29:33.210608: validation loss: -0.7524\n",
      "2021-11-11 21:29:33.215925: Average global foreground Dice: [0.7901]\n",
      "2021-11-11 21:29:33.220468: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 21:29:33.800055: lr: 0.009549\n",
      "2021-11-11 21:29:33.844235: saving checkpoint...\n",
      "2021-11-11 21:29:34.365880: done, saving took 0.56 seconds\n",
      "2021-11-11 21:29:34.381030: This epoch took 193.262998 s\n",
      "\n",
      "2021-11-11 21:29:34.384298: \n",
      "epoch:  2\n",
      "2021-11-11 21:32:32.679273: train loss : -0.7782\n",
      "2021-11-11 21:32:46.108071: validation loss: -0.7969\n",
      "2021-11-11 21:32:46.113118: Average global foreground Dice: [0.8162]\n",
      "2021-11-11 21:32:46.117771: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 21:32:46.625044: lr: 0.009322\n",
      "2021-11-11 21:32:46.658599: saving checkpoint...\n",
      "2021-11-11 21:32:47.254362: done, saving took 0.63 seconds\n",
      "2021-11-11 21:32:47.280762: This epoch took 192.892356 s\n",
      "\n",
      "2021-11-11 21:32:47.285132: \n",
      "epoch:  3\n",
      "2021-11-11 21:35:45.418319: train loss : -0.8047\n",
      "2021-11-11 21:35:58.867430: validation loss: -0.8064\n",
      "2021-11-11 21:35:58.871927: Average global foreground Dice: [0.8221]\n",
      "2021-11-11 21:35:58.875906: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 21:35:59.423126: lr: 0.009095\n",
      "2021-11-11 21:35:59.456903: saving checkpoint...\n",
      "2021-11-11 21:36:00.134319: done, saving took 0.71 seconds\n",
      "2021-11-11 21:36:00.157896: This epoch took 192.869414 s\n",
      "\n",
      "2021-11-11 21:36:00.161999: \n",
      "epoch:  4\n",
      "2021-11-11 21:38:58.180011: train loss : -0.8191\n",
      "2021-11-11 21:39:11.617795: validation loss: -0.8073\n",
      "2021-11-11 21:39:11.622798: Average global foreground Dice: [0.8248]\n",
      "2021-11-11 21:39:11.626859: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 21:39:12.147720: lr: 0.008868\n",
      "2021-11-11 21:39:12.188965: saving checkpoint...\n",
      "2021-11-11 21:39:12.727950: done, saving took 0.58 seconds\n",
      "2021-11-11 21:39:12.754124: This epoch took 192.587334 s\n",
      "\n",
      "2021-11-11 21:39:12.758132: \n",
      "epoch:  5\n",
      "2021-11-11 21:42:10.904418: train loss : -0.8274\n",
      "2021-11-11 21:42:24.354830: validation loss: -0.8106\n",
      "2021-11-11 21:42:24.358933: Average global foreground Dice: [0.8254]\n",
      "2021-11-11 21:42:24.363773: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 21:42:24.887989: lr: 0.008639\n",
      "2021-11-11 21:42:24.929506: saving checkpoint...\n",
      "2021-11-11 21:42:25.518964: done, saving took 0.63 seconds\n",
      "2021-11-11 21:42:25.547171: This epoch took 192.785300 s\n",
      "\n",
      "2021-11-11 21:42:25.551974: \n",
      "epoch:  6\n",
      "2021-11-11 21:45:23.616929: train loss : -0.8321\n",
      "2021-11-11 21:45:37.042601: validation loss: -0.8165\n",
      "2021-11-11 21:45:37.047679: Average global foreground Dice: [0.8279]\n",
      "2021-11-11 21:45:37.051636: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 21:45:37.666219: lr: 0.00841\n",
      "2021-11-11 21:45:37.706170: saving checkpoint...\n",
      "2021-11-11 21:45:38.280422: done, saving took 0.61 seconds\n",
      "2021-11-11 21:45:38.303404: This epoch took 192.747940 s\n",
      "\n",
      "2021-11-11 21:45:38.307336: \n",
      "epoch:  7\n",
      "2021-11-11 21:48:36.511251: train loss : -0.8378\n",
      "2021-11-11 21:48:49.965169: validation loss: -0.8196\n",
      "2021-11-11 21:48:49.969910: Average global foreground Dice: [0.8352]\n",
      "2021-11-11 21:48:49.974212: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 21:48:50.503334: lr: 0.008181\n",
      "2021-11-11 21:48:50.543920: saving checkpoint...\n",
      "2021-11-11 21:48:51.232372: done, saving took 0.72 seconds\n",
      "2021-11-11 21:48:51.260003: This epoch took 192.949334 s\n",
      "\n",
      "2021-11-11 21:48:51.264543: \n",
      "epoch:  8\n",
      "2021-11-11 21:51:49.896777: train loss : -0.8417\n",
      "2021-11-11 21:52:03.362791: validation loss: -0.8225\n",
      "2021-11-11 21:52:03.368387: Average global foreground Dice: [0.8358]\n",
      "2021-11-11 21:52:03.372488: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 21:52:03.954919: lr: 0.00795\n",
      "2021-11-11 21:52:03.994426: saving checkpoint...\n",
      "2021-11-11 21:52:04.642741: done, saving took 0.68 seconds\n",
      "2021-11-11 21:52:04.679822: This epoch took 193.411450 s\n",
      "\n",
      "2021-11-11 21:52:04.683960: \n",
      "epoch:  9\n",
      "2021-11-11 21:55:03.417413: train loss : -0.8478\n",
      "2021-11-11 21:55:16.893799: validation loss: -0.8231\n",
      "2021-11-11 21:55:16.898502: Average global foreground Dice: [0.8372]\n",
      "2021-11-11 21:55:16.902915: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 21:55:17.416145: lr: 0.007719\n",
      "2021-11-11 21:55:17.455225: saving checkpoint...\n",
      "2021-11-11 21:55:18.067549: done, saving took 0.65 seconds\n",
      "2021-11-11 21:55:18.094583: This epoch took 193.405270 s\n",
      "\n",
      "2021-11-11 21:55:18.099056: \n",
      "epoch:  10\n",
      "2021-11-11 21:58:16.840224: train loss : -0.8506\n",
      "2021-11-11 21:58:30.299531: validation loss: -0.8234\n",
      "2021-11-11 21:58:30.304499: Average global foreground Dice: [0.8357]\n",
      "2021-11-11 21:58:30.308083: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 21:58:30.813159: lr: 0.007487\n",
      "2021-11-11 21:58:30.836322: saving checkpoint...\n",
      "2021-11-11 21:58:31.498457: done, saving took 0.68 seconds\n",
      "2021-11-11 21:58:31.528710: This epoch took 193.424812 s\n",
      "\n",
      "2021-11-11 21:58:31.533172: \n",
      "epoch:  11\n",
      "2021-11-11 22:01:30.275087: train loss : -0.8509\n",
      "2021-11-11 22:01:43.765260: validation loss: -0.8208\n",
      "2021-11-11 22:01:43.769890: Average global foreground Dice: [0.8352]\n",
      "2021-11-11 22:01:43.774411: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:01:44.355065: lr: 0.007254\n",
      "2021-11-11 22:01:44.386889: saving checkpoint...\n",
      "2021-11-11 22:01:44.957656: done, saving took 0.60 seconds\n",
      "2021-11-11 22:01:44.985674: This epoch took 193.448497 s\n",
      "\n",
      "2021-11-11 22:01:44.989633: \n",
      "epoch:  12\n",
      "2021-11-11 22:04:43.790529: train loss : -0.8552\n",
      "2021-11-11 22:04:57.271499: validation loss: -0.8268\n",
      "2021-11-11 22:04:57.276247: Average global foreground Dice: [0.8399]\n",
      "2021-11-11 22:04:57.280179: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:04:57.792324: lr: 0.007021\n",
      "2021-11-11 22:04:57.816645: saving checkpoint...\n",
      "2021-11-11 22:04:58.411902: done, saving took 0.61 seconds\n",
      "2021-11-11 22:04:58.441312: This epoch took 193.447614 s\n",
      "\n",
      "2021-11-11 22:04:58.445567: \n",
      "epoch:  13\n",
      "2021-11-11 22:07:57.259511: train loss : -0.8576\n",
      "2021-11-11 22:08:10.750767: validation loss: -0.8248\n",
      "2021-11-11 22:08:10.756620: Average global foreground Dice: [0.8363]\n",
      "2021-11-11 22:08:10.760591: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:08:11.321384: lr: 0.006786\n",
      "2021-11-11 22:08:11.360521: saving checkpoint...\n",
      "2021-11-11 22:08:11.925148: done, saving took 0.60 seconds\n",
      "2021-11-11 22:08:11.951084: This epoch took 193.501626 s\n",
      "\n",
      "2021-11-11 22:08:11.955353: \n",
      "epoch:  14\n",
      "2021-11-11 22:11:10.876922: train loss : -0.8602\n",
      "2021-11-11 22:11:24.361246: validation loss: -0.8233\n",
      "2021-11-11 22:11:24.366739: Average global foreground Dice: [0.8373]\n",
      "2021-11-11 22:11:24.371107: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:11:24.886432: lr: 0.006551\n",
      "2021-11-11 22:11:24.909507: saving checkpoint...\n",
      "2021-11-11 22:11:25.559452: done, saving took 0.67 seconds\n",
      "2021-11-11 22:11:25.590773: This epoch took 193.631542 s\n",
      "\n",
      "2021-11-11 22:11:25.594763: \n",
      "epoch:  15\n",
      "2021-11-11 22:14:24.599242: train loss : -0.8632\n",
      "2021-11-11 22:14:38.058811: validation loss: -0.8216\n",
      "2021-11-11 22:14:38.064043: Average global foreground Dice: [0.8343]\n",
      "2021-11-11 22:14:38.068556: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:14:38.589062: lr: 0.006314\n",
      "2021-11-11 22:14:38.612289: saving checkpoint...\n",
      "2021-11-11 22:14:39.182754: done, saving took 0.59 seconds\n",
      "2021-11-11 22:14:39.212550: This epoch took 193.613641 s\n",
      "\n",
      "2021-11-11 22:14:39.216984: \n",
      "epoch:  16\n",
      "2021-11-11 22:17:38.458949: train loss : -0.8642\n",
      "2021-11-11 22:17:51.929644: validation loss: -0.8244\n",
      "2021-11-11 22:17:51.934618: Average global foreground Dice: [0.8363]\n",
      "2021-11-11 22:17:51.939399: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:17:52.459558: lr: 0.006077\n",
      "2021-11-11 22:17:52.482462: saving checkpoint...\n",
      "2021-11-11 22:17:53.237902: done, saving took 0.77 seconds\n",
      "2021-11-11 22:17:53.275618: This epoch took 194.054074 s\n",
      "\n",
      "2021-11-11 22:17:53.282714: \n",
      "epoch:  17\n",
      "2021-11-11 22:20:52.534863: train loss : -0.8658\n",
      "2021-11-11 22:21:06.012577: validation loss: -0.8229\n",
      "2021-11-11 22:21:06.017637: Average global foreground Dice: [0.8351]\n",
      "2021-11-11 22:21:06.022638: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:21:06.570066: lr: 0.005839\n",
      "2021-11-11 22:21:06.604164: saving checkpoint...\n",
      "2021-11-11 22:21:07.179456: done, saving took 0.60 seconds\n",
      "2021-11-11 22:21:07.200029: This epoch took 193.912553 s\n",
      "\n",
      "2021-11-11 22:21:07.204615: \n",
      "epoch:  18\n",
      "2021-11-11 22:24:06.420755: train loss : -0.8680\n",
      "2021-11-11 22:24:19.880289: validation loss: -0.8206\n",
      "2021-11-11 22:24:19.886253: Average global foreground Dice: [0.8334]\n",
      "2021-11-11 22:24:19.890897: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:24:20.443253: lr: 0.005599\n",
      "2021-11-11 22:24:20.477765: saving checkpoint...\n",
      "2021-11-11 22:24:21.061524: done, saving took 0.61 seconds\n",
      "2021-11-11 22:24:21.084591: This epoch took 193.874857 s\n",
      "\n",
      "2021-11-11 22:24:21.089104: \n",
      "epoch:  19\n",
      "2021-11-11 22:27:20.407587: train loss : -0.8694\n",
      "2021-11-11 22:27:33.874532: validation loss: -0.8237\n",
      "2021-11-11 22:27:33.880479: Average global foreground Dice: [0.8364]\n",
      "2021-11-11 22:27:33.884772: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:27:34.399620: lr: 0.005359\n",
      "2021-11-11 22:27:34.435963: saving checkpoint...\n",
      "2021-11-11 22:27:35.124641: done, saving took 0.72 seconds\n",
      "2021-11-11 22:27:35.159570: This epoch took 194.066711 s\n",
      "\n",
      "2021-11-11 22:27:35.164388: \n",
      "epoch:  20\n",
      "2021-11-11 22:30:34.522757: train loss : -0.8704\n",
      "2021-11-11 22:30:47.996173: validation loss: -0.8275\n",
      "2021-11-11 22:30:48.002060: Average global foreground Dice: [0.84]\n",
      "2021-11-11 22:30:48.006763: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:30:48.529925: lr: 0.005117\n",
      "2021-11-11 22:30:48.552900: saving checkpoint...\n",
      "2021-11-11 22:30:49.220648: done, saving took 0.69 seconds\n",
      "2021-11-11 22:30:49.253525: This epoch took 194.084635 s\n",
      "\n",
      "2021-11-11 22:30:49.257539: \n",
      "epoch:  21\n",
      "2021-11-11 22:33:48.587074: train loss : -0.8713\n",
      "2021-11-11 22:34:02.053179: validation loss: -0.8247\n",
      "2021-11-11 22:34:02.058741: Average global foreground Dice: [0.8375]\n",
      "2021-11-11 22:34:02.063546: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:34:02.584850: lr: 0.004874\n",
      "2021-11-11 22:34:02.608482: saving checkpoint...\n",
      "2021-11-11 22:34:03.200926: done, saving took 0.61 seconds\n",
      "2021-11-11 22:34:03.233393: This epoch took 193.970719 s\n",
      "\n",
      "2021-11-11 22:34:03.237721: \n",
      "epoch:  22\n",
      "2021-11-11 22:37:02.617535: train loss : -0.8735\n",
      "2021-11-11 22:37:16.086790: validation loss: -0.8282\n",
      "2021-11-11 22:37:16.092181: Average global foreground Dice: [0.8412]\n",
      "2021-11-11 22:37:16.097528: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:37:16.697694: lr: 0.00463\n",
      "2021-11-11 22:37:16.733882: saving checkpoint...\n",
      "2021-11-11 22:37:17.406933: done, saving took 0.69 seconds\n",
      "2021-11-11 22:37:17.443384: This epoch took 194.201399 s\n",
      "\n",
      "2021-11-11 22:37:17.447809: \n",
      "epoch:  23\n",
      "2021-11-11 22:40:16.753264: train loss : -0.8758\n",
      "2021-11-11 22:40:30.220277: validation loss: -0.8233\n",
      "2021-11-11 22:40:30.225375: Average global foreground Dice: [0.8351]\n",
      "2021-11-11 22:40:30.229832: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:40:30.739663: lr: 0.004384\n",
      "2021-11-11 22:40:30.762804: saving checkpoint...\n",
      "2021-11-11 22:40:31.375589: done, saving took 0.63 seconds\n",
      "2021-11-11 22:40:31.404115: This epoch took 193.951677 s\n",
      "\n",
      "2021-11-11 22:40:31.409337: \n",
      "epoch:  24\n",
      "2021-11-11 22:43:31.065543: train loss : -0.8770\n",
      "2021-11-11 22:43:44.540637: validation loss: -0.8249\n",
      "2021-11-11 22:43:44.545903: Average global foreground Dice: [0.8382]\n",
      "2021-11-11 22:43:44.549987: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:43:45.044617: lr: 0.004136\n",
      "2021-11-11 22:43:45.067669: saving checkpoint...\n",
      "2021-11-11 22:43:45.660463: done, saving took 0.61 seconds\n",
      "2021-11-11 22:43:45.687389: This epoch took 194.273755 s\n",
      "\n",
      "2021-11-11 22:43:45.692298: \n",
      "epoch:  25\n",
      "2021-11-11 22:46:45.409308: train loss : -0.8781\n",
      "2021-11-11 22:46:58.885441: validation loss: -0.8223\n",
      "2021-11-11 22:46:58.890638: Average global foreground Dice: [0.835]\n",
      "2021-11-11 22:46:58.895751: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:46:59.404788: lr: 0.003887\n",
      "2021-11-11 22:46:59.442080: saving checkpoint...\n",
      "2021-11-11 22:47:00.098335: done, saving took 0.69 seconds\n",
      "2021-11-11 22:47:00.128978: This epoch took 194.431982 s\n",
      "\n",
      "2021-11-11 22:47:00.133704: \n",
      "epoch:  26\n",
      "2021-11-11 22:49:59.760695: train loss : -0.8794\n",
      "2021-11-11 22:50:13.226653: validation loss: -0.8240\n",
      "2021-11-11 22:50:13.231498: Average global foreground Dice: [0.8359]\n",
      "2021-11-11 22:50:13.235981: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:50:13.780463: lr: 0.003637\n",
      "2021-11-11 22:50:13.811762: saving checkpoint...\n",
      "2021-11-11 22:50:14.407120: done, saving took 0.62 seconds\n",
      "2021-11-11 22:50:14.428919: This epoch took 194.290328 s\n",
      "\n",
      "2021-11-11 22:50:14.433408: \n",
      "epoch:  27\n",
      "2021-11-11 22:53:14.128355: train loss : -0.8806\n",
      "2021-11-11 22:53:27.599846: validation loss: -0.8257\n",
      "2021-11-11 22:53:27.605151: Average global foreground Dice: [0.838]\n",
      "2021-11-11 22:53:27.609294: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:53:28.109969: lr: 0.003384\n",
      "2021-11-11 22:53:28.133052: saving checkpoint...\n",
      "2021-11-11 22:53:28.762458: done, saving took 0.65 seconds\n",
      "2021-11-11 22:53:28.784977: This epoch took 194.347637 s\n",
      "\n",
      "2021-11-11 22:53:28.788614: \n",
      "epoch:  28\n",
      "2021-11-11 22:56:28.401251: train loss : -0.8827\n",
      "2021-11-11 22:56:41.862280: validation loss: -0.8268\n",
      "2021-11-11 22:56:41.867549: Average global foreground Dice: [0.8396]\n",
      "2021-11-11 22:56:41.871794: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:56:42.386388: lr: 0.003129\n",
      "2021-11-11 22:56:42.428300: saving checkpoint...\n",
      "2021-11-11 22:56:43.110519: done, saving took 0.72 seconds\n",
      "2021-11-11 22:56:43.140336: This epoch took 194.347091 s\n",
      "\n",
      "2021-11-11 22:56:43.146940: \n",
      "epoch:  29\n",
      "2021-11-11 22:59:42.779062: train loss : -0.8832\n",
      "2021-11-11 22:59:56.242122: validation loss: -0.8231\n",
      "2021-11-11 22:59:56.247135: Average global foreground Dice: [0.8351]\n",
      "2021-11-11 22:59:56.252313: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 22:59:56.822713: lr: 0.002872\n",
      "2021-11-11 22:59:56.856614: saving checkpoint...\n",
      "2021-11-11 22:59:57.551515: done, saving took 0.72 seconds\n",
      "2021-11-11 22:59:57.577513: This epoch took 194.426831 s\n",
      "\n",
      "2021-11-11 22:59:57.582516: \n",
      "epoch:  30\n",
      "2021-11-11 23:02:57.179339: train loss : -0.8852\n",
      "2021-11-11 23:03:10.630967: validation loss: -0.8237\n",
      "2021-11-11 23:03:10.635717: Average global foreground Dice: [0.8365]\n",
      "2021-11-11 23:03:10.640142: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 23:03:11.192058: lr: 0.002612\n",
      "2021-11-11 23:03:11.232942: saving checkpoint...\n",
      "2021-11-11 23:03:11.947272: done, saving took 0.75 seconds\n",
      "2021-11-11 23:03:11.977936: This epoch took 194.390299 s\n",
      "\n",
      "2021-11-11 23:03:11.982945: \n",
      "epoch:  31\n",
      "2021-11-11 23:06:11.586592: train loss : -0.8863\n",
      "2021-11-11 23:06:25.029136: validation loss: -0.8273\n",
      "2021-11-11 23:06:25.034295: Average global foreground Dice: [0.8385]\n",
      "2021-11-11 23:06:25.039269: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 23:06:25.538102: lr: 0.002349\n",
      "2021-11-11 23:06:25.561063: saving checkpoint...\n",
      "2021-11-11 23:06:26.403702: done, saving took 0.86 seconds\n",
      "2021-11-11 23:06:26.427452: This epoch took 194.440629 s\n",
      "\n",
      "2021-11-11 23:06:26.431768: \n",
      "epoch:  32\n",
      "2021-11-11 23:09:26.336692: train loss : -0.8877\n",
      "2021-11-11 23:09:39.783243: validation loss: -0.8220\n",
      "2021-11-11 23:09:39.787995: Average global foreground Dice: [0.8335]\n",
      "2021-11-11 23:09:39.792223: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 23:09:40.312533: lr: 0.002083\n",
      "2021-11-11 23:09:40.335460: saving checkpoint...\n",
      "2021-11-11 23:09:41.056438: done, saving took 0.74 seconds\n",
      "2021-11-11 23:09:41.077386: This epoch took 194.641198 s\n",
      "\n",
      "2021-11-11 23:09:41.082295: \n",
      "epoch:  33\n",
      "2021-11-11 23:12:41.051409: train loss : -0.8893\n",
      "2021-11-11 23:12:54.723279: validation loss: -0.8262\n",
      "2021-11-11 23:12:54.728871: Average global foreground Dice: [0.8378]\n",
      "2021-11-11 23:12:54.733865: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 23:12:55.343421: lr: 0.001813\n",
      "2021-11-11 23:12:55.366381: saving checkpoint...\n",
      "2021-11-11 23:12:55.988746: done, saving took 0.64 seconds\n",
      "2021-11-11 23:12:56.012168: This epoch took 194.925757 s\n",
      "\n",
      "2021-11-11 23:12:56.016755: \n",
      "epoch:  34\n",
      "2021-11-11 23:15:56.024557: train loss : -0.8897\n",
      "2021-11-11 23:16:09.494148: validation loss: -0.8258\n",
      "2021-11-11 23:16:09.498462: Average global foreground Dice: [0.8359]\n",
      "2021-11-11 23:16:09.503385: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 23:16:10.007500: lr: 0.001539\n",
      "2021-11-11 23:16:10.042446: saving checkpoint...\n",
      "2021-11-11 23:16:10.627814: done, saving took 0.62 seconds\n",
      "2021-11-11 23:16:10.650264: This epoch took 194.629806 s\n",
      "\n",
      "2021-11-11 23:16:10.654742: \n",
      "epoch:  35\n",
      "2021-11-11 23:19:10.678082: train loss : -0.8907\n",
      "2021-11-11 23:19:24.155332: validation loss: -0.8251\n",
      "2021-11-11 23:19:24.160146: Average global foreground Dice: [0.8358]\n",
      "2021-11-11 23:19:24.164628: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 23:19:24.682579: lr: 0.001259\n",
      "2021-11-11 23:19:24.717344: saving checkpoint...\n",
      "2021-11-11 23:19:25.391502: done, saving took 0.70 seconds\n",
      "2021-11-11 23:19:25.415409: This epoch took 194.756196 s\n",
      "\n",
      "2021-11-11 23:19:25.419834: \n",
      "epoch:  36\n",
      "2021-11-11 23:22:25.484736: train loss : -0.8915\n",
      "2021-11-11 23:22:38.939614: validation loss: -0.8276\n",
      "2021-11-11 23:22:38.945180: Average global foreground Dice: [0.839]\n",
      "2021-11-11 23:22:38.949513: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 23:22:39.477287: lr: 0.000972\n",
      "2021-11-11 23:22:39.517924: saving checkpoint...\n",
      "2021-11-11 23:22:40.066656: done, saving took 0.59 seconds\n",
      "2021-11-11 23:22:40.093521: This epoch took 194.669065 s\n",
      "\n",
      "2021-11-11 23:22:40.098183: \n",
      "epoch:  37\n",
      "2021-11-11 23:25:40.168652: train loss : -0.8925\n",
      "2021-11-11 23:25:53.650016: validation loss: -0.8269\n",
      "2021-11-11 23:25:53.655298: Average global foreground Dice: [0.8374]\n",
      "2021-11-11 23:25:53.659996: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 23:25:54.193228: lr: 0.000675\n",
      "2021-11-11 23:25:54.235313: saving checkpoint...\n",
      "2021-11-11 23:25:54.905804: done, saving took 0.71 seconds\n",
      "2021-11-11 23:25:54.930173: This epoch took 194.827639 s\n",
      "\n",
      "2021-11-11 23:25:54.934358: \n",
      "epoch:  38\n",
      "2021-11-11 23:28:54.886276: train loss : -0.8927\n",
      "2021-11-11 23:29:08.353679: validation loss: -0.8249\n",
      "2021-11-11 23:29:08.364422: Average global foreground Dice: [0.8354]\n",
      "2021-11-11 23:29:08.368226: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 23:29:08.957336: lr: 0.000362\n",
      "2021-11-11 23:29:08.998654: saving checkpoint...\n",
      "2021-11-11 23:29:09.677359: done, saving took 0.72 seconds\n",
      "2021-11-11 23:29:09.700151: This epoch took 194.759106 s\n",
      "\n",
      "2021-11-11 23:29:09.704258: \n",
      "epoch:  39\n",
      "2021-11-11 23:32:09.742720: train loss : -0.8952\n",
      "2021-11-11 23:32:23.199156: validation loss: -0.8214\n",
      "2021-11-11 23:32:23.204470: Average global foreground Dice: [0.8329]\n",
      "2021-11-11 23:32:23.209149: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 23:32:23.728859: lr: 0.0\n",
      "2021-11-11 23:32:23.733161: This epoch took 194.023827 s\n",
      "\n",
      "2021-11-11 23:32:23.768204: saving checkpoint...\n",
      "2021-11-11 23:32:24.333673: done, saving took 0.60 seconds\n",
      "23090566_20141114 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090571_20120517 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131226 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160308 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131025 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090596_20150112 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120619 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090608_20120718 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151210 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121213 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090616_20140331 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090619_20121210 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090629_20120830 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090636_20121018 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150522 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-11 23:34:19.229950: finished prediction\n",
      "2021-11-11 23:34:19.233938: evaluation of raw predictions\n",
      "2021-11-11 23:34:20.837855: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8241783505332343\n",
      "after:  0.8241064429407606\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-11 23:34:32.162807: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-11 23:34:32.178317: The split file contains 5 splits.\n",
      "2021-11-11 23:34:32.182374: Desired fold for training: 3\n",
      "2021-11-11 23:34:32.186208: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-11 23:34:36.327902: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-11 23:34:44.717220: Unable to plot network architecture:\n",
      "2021-11-11 23:34:44.721635: No module named 'hiddenlayer'\n",
      "2021-11-11 23:34:44.727177: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-11 23:34:44.759477: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-11 23:34:44.772535: \n",
      "\n",
      "2021-11-11 23:34:44.777278: \n",
      "epoch:  0\n",
      "2021-11-11 23:38:03.444905: train loss : -0.2148\n",
      "2021-11-11 23:38:17.181508: validation loss: -0.6039\n",
      "2021-11-11 23:38:17.186417: Average global foreground Dice: [0.6788]\n",
      "2021-11-11 23:38:17.190226: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 23:38:17.663012: lr: 0.009775\n",
      "2021-11-11 23:38:17.667263: This epoch took 212.884652 s\n",
      "\n",
      "2021-11-11 23:38:17.671715: \n",
      "epoch:  1\n",
      "2021-11-11 23:41:17.207692: train loss : -0.6528\n",
      "2021-11-11 23:41:30.892242: validation loss: -0.7345\n",
      "2021-11-11 23:41:30.897644: Average global foreground Dice: [0.8038]\n",
      "2021-11-11 23:41:30.901660: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 23:41:31.411604: lr: 0.009549\n",
      "2021-11-11 23:41:31.453038: saving checkpoint...\n",
      "2021-11-11 23:41:31.978826: done, saving took 0.56 seconds\n",
      "2021-11-11 23:41:31.997550: This epoch took 194.321589 s\n",
      "\n",
      "2021-11-11 23:41:32.001694: \n",
      "epoch:  2\n",
      "2021-11-11 23:44:31.170529: train loss : -0.7452\n",
      "2021-11-11 23:44:44.866867: validation loss: -0.8057\n",
      "2021-11-11 23:44:44.871947: Average global foreground Dice: [0.8289]\n",
      "2021-11-11 23:44:44.876400: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 23:44:45.399706: lr: 0.009322\n",
      "2021-11-11 23:44:45.433619: saving checkpoint...\n",
      "2021-11-11 23:44:46.108248: done, saving took 0.70 seconds\n",
      "2021-11-11 23:44:46.139073: This epoch took 194.133154 s\n",
      "\n",
      "2021-11-11 23:44:46.143159: \n",
      "epoch:  3\n",
      "2021-11-11 23:47:46.371845: train loss : -0.7917\n",
      "2021-11-11 23:48:00.138907: validation loss: -0.8127\n",
      "2021-11-11 23:48:00.143213: Average global foreground Dice: [0.8306]\n",
      "2021-11-11 23:48:00.148149: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 23:48:00.678633: lr: 0.009095\n",
      "2021-11-11 23:48:00.710899: saving checkpoint...\n",
      "2021-11-11 23:48:01.340587: done, saving took 0.66 seconds\n",
      "2021-11-11 23:48:01.361617: This epoch took 195.214800 s\n",
      "\n",
      "2021-11-11 23:48:01.365575: \n",
      "epoch:  4\n",
      "2021-11-11 23:51:01.502304: train loss : -0.8092\n",
      "2021-11-11 23:51:15.270156: validation loss: -0.8257\n",
      "2021-11-11 23:51:15.275299: Average global foreground Dice: [0.8407]\n",
      "2021-11-11 23:51:15.279852: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 23:51:15.805341: lr: 0.008868\n",
      "2021-11-11 23:51:15.840096: saving checkpoint...\n",
      "2021-11-11 23:51:16.478245: done, saving took 0.67 seconds\n",
      "2021-11-11 23:51:16.503535: This epoch took 195.134613 s\n",
      "\n",
      "2021-11-11 23:51:16.507706: \n",
      "epoch:  5\n",
      "2021-11-11 23:54:16.605818: train loss : -0.8186\n",
      "2021-11-11 23:54:30.379727: validation loss: -0.8309\n",
      "2021-11-11 23:54:30.383991: Average global foreground Dice: [0.8445]\n",
      "2021-11-11 23:54:30.388369: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 23:54:30.913110: lr: 0.008639\n",
      "2021-11-11 23:54:30.944587: saving checkpoint...\n",
      "2021-11-11 23:54:31.607666: done, saving took 0.69 seconds\n",
      "2021-11-11 23:54:31.629517: This epoch took 195.117095 s\n",
      "\n",
      "2021-11-11 23:54:31.634169: \n",
      "epoch:  6\n",
      "2021-11-11 23:57:31.662101: train loss : -0.8239\n",
      "2021-11-11 23:57:45.432949: validation loss: -0.8246\n",
      "2021-11-11 23:57:45.437120: Average global foreground Dice: [0.8385]\n",
      "2021-11-11 23:57:45.441087: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-11 23:57:46.045296: lr: 0.00841\n",
      "2021-11-11 23:57:46.068882: saving checkpoint...\n",
      "2021-11-11 23:57:46.701914: done, saving took 0.65 seconds\n",
      "2021-11-11 23:57:46.732210: This epoch took 195.094324 s\n",
      "\n",
      "2021-11-11 23:57:46.736109: \n",
      "epoch:  7\n",
      "2021-11-12 00:00:46.820676: train loss : -0.8305\n",
      "2021-11-12 00:01:00.589329: validation loss: -0.8347\n",
      "2021-11-12 00:01:00.593757: Average global foreground Dice: [0.8464]\n",
      "2021-11-12 00:01:00.597985: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:01:01.169233: lr: 0.008181\n",
      "2021-11-12 00:01:01.191979: saving checkpoint...\n",
      "2021-11-12 00:01:01.864862: done, saving took 0.69 seconds\n",
      "2021-11-12 00:01:01.901872: This epoch took 195.162258 s\n",
      "\n",
      "2021-11-12 00:01:01.906535: \n",
      "epoch:  8\n",
      "2021-11-12 00:04:02.347289: train loss : -0.8347\n",
      "2021-11-12 00:04:16.123179: validation loss: -0.8256\n",
      "2021-11-12 00:04:16.128800: Average global foreground Dice: [0.8381]\n",
      "2021-11-12 00:04:16.132477: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:04:16.715108: lr: 0.00795\n",
      "2021-11-12 00:04:16.751459: saving checkpoint...\n",
      "2021-11-12 00:04:17.402150: done, saving took 0.68 seconds\n",
      "2021-11-12 00:04:17.436240: This epoch took 195.524920 s\n",
      "\n",
      "2021-11-12 00:04:17.440796: \n",
      "epoch:  9\n",
      "2021-11-12 00:07:17.998969: train loss : -0.8368\n",
      "2021-11-12 00:07:31.782408: validation loss: -0.8326\n",
      "2021-11-12 00:07:31.788160: Average global foreground Dice: [0.8428]\n",
      "2021-11-12 00:07:31.794299: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:07:32.328646: lr: 0.007719\n",
      "2021-11-12 00:07:32.365159: saving checkpoint...\n",
      "2021-11-12 00:07:33.032577: done, saving took 0.70 seconds\n",
      "2021-11-12 00:07:33.069983: This epoch took 195.621921 s\n",
      "\n",
      "2021-11-12 00:07:33.075847: \n",
      "epoch:  10\n",
      "2021-11-12 00:10:33.830899: train loss : -0.8412\n",
      "2021-11-12 00:10:47.610109: validation loss: -0.8327\n",
      "2021-11-12 00:10:47.615215: Average global foreground Dice: [0.8433]\n",
      "2021-11-12 00:10:47.619807: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:10:48.138069: lr: 0.007487\n",
      "2021-11-12 00:10:48.161130: saving checkpoint...\n",
      "2021-11-12 00:10:48.847687: done, saving took 0.71 seconds\n",
      "2021-11-12 00:10:48.878757: This epoch took 195.799257 s\n",
      "\n",
      "2021-11-12 00:10:48.883219: \n",
      "epoch:  11\n",
      "2021-11-12 00:13:49.631371: train loss : -0.8440\n",
      "2021-11-12 00:14:03.398449: validation loss: -0.8398\n",
      "2021-11-12 00:14:03.404694: Average global foreground Dice: [0.8501]\n",
      "2021-11-12 00:14:03.409437: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:14:03.987064: lr: 0.007254\n",
      "2021-11-12 00:14:04.010908: saving checkpoint...\n",
      "2021-11-12 00:14:04.764656: done, saving took 0.77 seconds\n",
      "2021-11-12 00:14:04.803500: This epoch took 195.916687 s\n",
      "\n",
      "2021-11-12 00:14:04.807663: \n",
      "epoch:  12\n",
      "2021-11-12 00:17:05.648370: train loss : -0.8481\n",
      "2021-11-12 00:17:19.417660: validation loss: -0.8397\n",
      "2021-11-12 00:17:19.422954: Average global foreground Dice: [0.8487]\n",
      "2021-11-12 00:17:19.426944: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:17:19.958607: lr: 0.007021\n",
      "2021-11-12 00:17:19.982054: saving checkpoint...\n",
      "2021-11-12 00:17:20.642740: done, saving took 0.68 seconds\n",
      "2021-11-12 00:17:20.675799: This epoch took 195.861446 s\n",
      "\n",
      "2021-11-12 00:17:20.680350: \n",
      "epoch:  13\n",
      "2021-11-12 00:20:21.582376: train loss : -0.8497\n",
      "2021-11-12 00:20:35.347522: validation loss: -0.8354\n",
      "2021-11-12 00:20:35.352087: Average global foreground Dice: [0.8468]\n",
      "2021-11-12 00:20:35.357326: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:20:35.913837: lr: 0.006786\n",
      "2021-11-12 00:20:35.937226: saving checkpoint...\n",
      "2021-11-12 00:20:36.600521: done, saving took 0.68 seconds\n",
      "2021-11-12 00:20:36.631240: This epoch took 195.947278 s\n",
      "\n",
      "2021-11-12 00:20:36.635496: \n",
      "epoch:  14\n",
      "2021-11-12 00:23:37.451744: train loss : -0.8522\n",
      "2021-11-12 00:23:51.222621: validation loss: -0.8382\n",
      "2021-11-12 00:23:51.227867: Average global foreground Dice: [0.8476]\n",
      "2021-11-12 00:23:51.232892: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:23:51.793889: lr: 0.006551\n",
      "2021-11-12 00:23:51.828872: saving checkpoint...\n",
      "2021-11-12 00:23:52.492359: done, saving took 0.69 seconds\n",
      "2021-11-12 00:23:52.524929: This epoch took 195.885278 s\n",
      "\n",
      "2021-11-12 00:23:52.529401: \n",
      "epoch:  15\n",
      "2021-11-12 00:26:53.678085: train loss : -0.8546\n",
      "2021-11-12 00:27:07.456408: validation loss: -0.8344\n",
      "2021-11-12 00:27:07.461119: Average global foreground Dice: [0.8445]\n",
      "2021-11-12 00:27:07.466948: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:27:08.003662: lr: 0.006314\n",
      "2021-11-12 00:27:08.038948: saving checkpoint...\n",
      "2021-11-12 00:27:08.709176: done, saving took 0.70 seconds\n",
      "2021-11-12 00:27:08.743081: This epoch took 196.209192 s\n",
      "\n",
      "2021-11-12 00:27:08.747331: \n",
      "epoch:  16\n",
      "2021-11-12 00:30:10.190268: train loss : -0.8562\n",
      "2021-11-12 00:30:23.951194: validation loss: -0.8386\n",
      "2021-11-12 00:30:23.956085: Average global foreground Dice: [0.8493]\n",
      "2021-11-12 00:30:23.960269: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:30:24.525541: lr: 0.006077\n",
      "2021-11-12 00:30:24.548570: saving checkpoint...\n",
      "2021-11-12 00:30:25.361433: done, saving took 0.83 seconds\n",
      "2021-11-12 00:30:25.394467: This epoch took 196.643496 s\n",
      "\n",
      "2021-11-12 00:30:25.399222: \n",
      "epoch:  17\n",
      "2021-11-12 00:33:26.906036: train loss : -0.8598\n",
      "2021-11-12 00:33:40.683925: validation loss: -0.8426\n",
      "2021-11-12 00:33:40.689058: Average global foreground Dice: [0.8511]\n",
      "2021-11-12 00:33:40.694336: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:33:41.212495: lr: 0.005839\n",
      "2021-11-12 00:33:41.235535: saving checkpoint...\n",
      "2021-11-12 00:33:41.913789: done, saving took 0.70 seconds\n",
      "2021-11-12 00:33:41.946461: This epoch took 196.543070 s\n",
      "\n",
      "2021-11-12 00:33:41.950288: \n",
      "epoch:  18\n",
      "2021-11-12 00:36:43.406328: train loss : -0.8597\n",
      "2021-11-12 00:36:57.180438: validation loss: -0.8328\n",
      "2021-11-12 00:36:57.185824: Average global foreground Dice: [0.8438]\n",
      "2021-11-12 00:36:57.190778: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:36:57.743490: lr: 0.005599\n",
      "2021-11-12 00:36:57.771661: saving checkpoint...\n",
      "2021-11-12 00:36:58.473416: done, saving took 0.72 seconds\n",
      "2021-11-12 00:36:58.501688: This epoch took 196.547500 s\n",
      "\n",
      "2021-11-12 00:36:58.506277: \n",
      "epoch:  19\n",
      "2021-11-12 00:40:00.018537: train loss : -0.8626\n",
      "2021-11-12 00:40:13.783853: validation loss: -0.8378\n",
      "2021-11-12 00:40:13.792338: Average global foreground Dice: [0.8476]\n",
      "2021-11-12 00:40:13.796721: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:40:14.325577: lr: 0.005359\n",
      "2021-11-12 00:40:14.348884: saving checkpoint...\n",
      "2021-11-12 00:40:15.031391: done, saving took 0.70 seconds\n",
      "2021-11-12 00:40:15.061787: This epoch took 196.550594 s\n",
      "\n",
      "2021-11-12 00:40:15.066176: \n",
      "epoch:  20\n",
      "2021-11-12 00:43:16.586595: train loss : -0.8631\n",
      "2021-11-12 00:43:30.352221: validation loss: -0.8398\n",
      "2021-11-12 00:43:30.357139: Average global foreground Dice: [0.8467]\n",
      "2021-11-12 00:43:30.361643: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:43:30.908981: lr: 0.005117\n",
      "2021-11-12 00:43:30.932528: saving checkpoint...\n",
      "2021-11-12 00:43:31.654525: done, saving took 0.74 seconds\n",
      "2021-11-12 00:43:31.694118: This epoch took 196.623701 s\n",
      "\n",
      "2021-11-12 00:43:31.698763: \n",
      "epoch:  21\n",
      "2021-11-12 00:46:33.310498: train loss : -0.8660\n",
      "2021-11-12 00:46:47.100491: validation loss: -0.8411\n",
      "2021-11-12 00:46:47.105015: Average global foreground Dice: [0.8497]\n",
      "2021-11-12 00:46:47.108782: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:46:47.630548: lr: 0.004874\n",
      "2021-11-12 00:46:47.654529: saving checkpoint...\n",
      "2021-11-12 00:46:48.400983: done, saving took 0.77 seconds\n",
      "2021-11-12 00:46:48.434560: This epoch took 196.731210 s\n",
      "\n",
      "2021-11-12 00:46:48.438945: \n",
      "epoch:  22\n",
      "2021-11-12 00:49:50.405727: train loss : -0.8675\n",
      "2021-11-12 00:50:04.179620: validation loss: -0.8423\n",
      "2021-11-12 00:50:04.184942: Average global foreground Dice: [0.8532]\n",
      "2021-11-12 00:50:04.190295: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:50:04.712976: lr: 0.00463\n",
      "2021-11-12 00:50:04.737154: saving checkpoint...\n",
      "2021-11-12 00:50:05.430344: done, saving took 0.71 seconds\n",
      "2021-11-12 00:50:05.461741: This epoch took 197.018300 s\n",
      "\n",
      "2021-11-12 00:50:05.466256: \n",
      "epoch:  23\n",
      "2021-11-12 00:53:07.248288: train loss : -0.8690\n",
      "2021-11-12 00:53:21.039204: validation loss: -0.8382\n",
      "2021-11-12 00:53:21.046247: Average global foreground Dice: [0.8479]\n",
      "2021-11-12 00:53:21.050290: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:53:21.635849: lr: 0.004384\n",
      "2021-11-12 00:53:21.659052: saving checkpoint...\n",
      "2021-11-12 00:53:22.324069: done, saving took 0.68 seconds\n",
      "2021-11-12 00:53:22.359210: This epoch took 196.888768 s\n",
      "\n",
      "2021-11-12 00:53:22.363592: \n",
      "epoch:  24\n",
      "2021-11-12 00:56:24.338483: train loss : -0.8710\n",
      "2021-11-12 00:56:38.143525: validation loss: -0.8430\n",
      "2021-11-12 00:56:38.149649: Average global foreground Dice: [0.8515]\n",
      "2021-11-12 00:56:38.153481: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:56:38.686822: lr: 0.004136\n",
      "2021-11-12 00:56:38.722749: saving checkpoint...\n",
      "2021-11-12 00:56:39.415841: done, saving took 0.72 seconds\n",
      "2021-11-12 00:56:39.449066: This epoch took 197.080959 s\n",
      "\n",
      "2021-11-12 00:56:39.453714: \n",
      "epoch:  25\n",
      "2021-11-12 00:59:41.767749: train loss : -0.8728\n",
      "2021-11-12 00:59:55.564389: validation loss: -0.8423\n",
      "2021-11-12 00:59:55.569156: Average global foreground Dice: [0.8506]\n",
      "2021-11-12 00:59:55.574023: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 00:59:56.124794: lr: 0.003887\n",
      "2021-11-12 00:59:56.161526: saving checkpoint...\n",
      "2021-11-12 00:59:56.858940: done, saving took 0.73 seconds\n",
      "2021-11-12 00:59:56.888567: This epoch took 197.428435 s\n",
      "\n",
      "2021-11-12 00:59:56.893152: \n",
      "epoch:  26\n",
      "2021-11-12 01:02:58.962840: train loss : -0.8732\n",
      "2021-11-12 01:03:12.745790: validation loss: -0.8429\n",
      "2021-11-12 01:03:12.751073: Average global foreground Dice: [0.8522]\n",
      "2021-11-12 01:03:12.755269: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 01:03:13.267043: lr: 0.003637\n",
      "2021-11-12 01:03:13.290015: saving checkpoint...\n",
      "2021-11-12 01:03:13.960582: done, saving took 0.69 seconds\n",
      "2021-11-12 01:03:13.982730: This epoch took 197.085639 s\n",
      "\n",
      "2021-11-12 01:03:13.987474: \n",
      "epoch:  27\n",
      "2021-11-12 01:06:16.033497: train loss : -0.8763\n",
      "2021-11-12 01:06:29.828185: validation loss: -0.8445\n",
      "2021-11-12 01:06:29.833842: Average global foreground Dice: [0.8536]\n",
      "2021-11-12 01:06:29.837915: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 01:06:30.420428: lr: 0.003384\n",
      "2021-11-12 01:06:30.444531: saving checkpoint...\n",
      "2021-11-12 01:06:31.140540: done, saving took 0.72 seconds\n",
      "2021-11-12 01:06:31.163400: This epoch took 197.172028 s\n",
      "\n",
      "2021-11-12 01:06:31.168061: \n",
      "epoch:  28\n",
      "2021-11-12 01:09:33.305964: train loss : -0.8768\n",
      "2021-11-12 01:09:47.099774: validation loss: -0.8422\n",
      "2021-11-12 01:09:47.104537: Average global foreground Dice: [0.8497]\n",
      "2021-11-12 01:09:47.109535: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 01:09:47.635861: lr: 0.003129\n",
      "2021-11-12 01:09:47.661104: saving checkpoint...\n",
      "2021-11-12 01:09:48.335932: done, saving took 0.70 seconds\n",
      "2021-11-12 01:09:48.359776: This epoch took 197.187890 s\n",
      "\n",
      "2021-11-12 01:09:48.364292: \n",
      "epoch:  29\n",
      "2021-11-12 01:12:50.612117: train loss : -0.8770\n",
      "2021-11-12 01:13:04.385720: validation loss: -0.8397\n",
      "2021-11-12 01:13:04.391229: Average global foreground Dice: [0.8497]\n",
      "2021-11-12 01:13:04.396001: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 01:13:04.933764: lr: 0.002872\n",
      "2021-11-12 01:13:04.956672: saving checkpoint...\n",
      "2021-11-12 01:13:05.647362: done, saving took 0.71 seconds\n",
      "2021-11-12 01:13:05.679291: This epoch took 197.310181 s\n",
      "\n",
      "2021-11-12 01:13:05.683944: \n",
      "epoch:  30\n",
      "2021-11-12 01:16:07.928283: train loss : -0.8793\n",
      "2021-11-12 01:16:21.694002: validation loss: -0.8422\n",
      "2021-11-12 01:16:21.698752: Average global foreground Dice: [0.8506]\n",
      "2021-11-12 01:16:21.702981: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 01:16:22.266349: lr: 0.002612\n",
      "2021-11-12 01:16:22.288853: saving checkpoint...\n",
      "2021-11-12 01:16:22.950746: done, saving took 0.68 seconds\n",
      "2021-11-12 01:16:22.986870: This epoch took 197.299117 s\n",
      "\n",
      "2021-11-12 01:16:22.993643: \n",
      "epoch:  31\n",
      "2021-11-12 01:19:25.282487: train loss : -0.8802\n",
      "2021-11-12 01:19:39.059653: validation loss: -0.8378\n",
      "2021-11-12 01:19:39.064806: Average global foreground Dice: [0.8469]\n",
      "2021-11-12 01:19:39.069079: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 01:19:39.612407: lr: 0.002349\n",
      "2021-11-12 01:19:39.635590: saving checkpoint...\n",
      "2021-11-12 01:19:40.302180: done, saving took 0.69 seconds\n",
      "2021-11-12 01:19:40.330610: This epoch took 197.332593 s\n",
      "\n",
      "2021-11-12 01:19:40.335133: \n",
      "epoch:  32\n",
      "2021-11-12 01:22:42.831174: train loss : -0.8823\n",
      "2021-11-12 01:22:56.645112: validation loss: -0.8379\n",
      "2021-11-12 01:22:56.650150: Average global foreground Dice: [0.8462]\n",
      "2021-11-12 01:22:56.654584: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 01:22:57.279070: lr: 0.002083\n",
      "2021-11-12 01:22:57.302266: saving checkpoint...\n",
      "2021-11-12 01:22:57.976703: done, saving took 0.69 seconds\n",
      "2021-11-12 01:22:58.011157: This epoch took 197.671407 s\n",
      "\n",
      "2021-11-12 01:22:58.015588: \n",
      "epoch:  33\n",
      "2021-11-12 01:26:00.503908: train loss : -0.8823\n",
      "2021-11-12 01:26:14.300308: validation loss: -0.8409\n",
      "2021-11-12 01:26:14.305803: Average global foreground Dice: [0.8503]\n",
      "2021-11-12 01:26:14.310623: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 01:26:14.822268: lr: 0.001813\n",
      "2021-11-12 01:26:14.845832: saving checkpoint...\n",
      "2021-11-12 01:26:15.487558: done, saving took 0.66 seconds\n",
      "2021-11-12 01:26:15.509378: This epoch took 197.489048 s\n",
      "\n",
      "2021-11-12 01:26:15.513433: \n",
      "epoch:  34\n",
      "2021-11-12 01:29:18.014302: train loss : -0.8847\n",
      "2021-11-12 01:29:31.797600: validation loss: -0.8400\n",
      "2021-11-12 01:29:31.803885: Average global foreground Dice: [0.8478]\n",
      "2021-11-12 01:29:31.808820: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 01:29:32.357713: lr: 0.001539\n",
      "2021-11-12 01:29:32.381431: saving checkpoint...\n",
      "2021-11-12 01:29:33.007215: done, saving took 0.64 seconds\n",
      "2021-11-12 01:29:33.030040: This epoch took 197.511664 s\n",
      "\n",
      "2021-11-12 01:29:33.034352: \n",
      "epoch:  35\n",
      "2021-11-12 01:32:35.542611: train loss : -0.8862\n",
      "2021-11-12 01:32:49.333066: validation loss: -0.8364\n",
      "2021-11-12 01:32:49.338009: Average global foreground Dice: [0.8444]\n",
      "2021-11-12 01:32:49.343212: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 01:32:49.879741: lr: 0.001259\n",
      "2021-11-12 01:32:49.903127: saving checkpoint...\n",
      "2021-11-12 01:32:50.591771: done, saving took 0.71 seconds\n",
      "2021-11-12 01:32:50.620985: This epoch took 197.582931 s\n",
      "\n",
      "2021-11-12 01:32:50.625436: \n",
      "epoch:  36\n",
      "2021-11-12 01:35:53.158227: train loss : -0.8866\n",
      "2021-11-12 01:36:06.933759: validation loss: -0.8404\n",
      "2021-11-12 01:36:06.939647: Average global foreground Dice: [0.8488]\n",
      "2021-11-12 01:36:06.944716: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 01:36:07.480175: lr: 0.000972\n",
      "2021-11-12 01:36:07.503899: saving checkpoint...\n",
      "2021-11-12 01:36:08.184140: done, saving took 0.70 seconds\n",
      "2021-11-12 01:36:08.217288: This epoch took 197.586576 s\n",
      "\n",
      "2021-11-12 01:36:08.221764: \n",
      "epoch:  37\n",
      "2021-11-12 01:39:10.670280: train loss : -0.8882\n",
      "2021-11-12 01:39:24.456205: validation loss: -0.8405\n",
      "2021-11-12 01:39:24.461467: Average global foreground Dice: [0.8485]\n",
      "2021-11-12 01:39:24.465972: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 01:39:25.044085: lr: 0.000675\n",
      "2021-11-12 01:39:25.067200: saving checkpoint...\n",
      "2021-11-12 01:39:25.728508: done, saving took 0.68 seconds\n",
      "2021-11-12 01:39:25.750648: This epoch took 197.523248 s\n",
      "\n",
      "2021-11-12 01:39:25.755458: \n",
      "epoch:  38\n",
      "2021-11-12 01:42:28.201341: train loss : -0.8883\n",
      "2021-11-12 01:42:41.960241: validation loss: -0.8406\n",
      "2021-11-12 01:42:41.966328: Average global foreground Dice: [0.8489]\n",
      "2021-11-12 01:42:41.971300: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 01:42:42.525447: lr: 0.000362\n",
      "2021-11-12 01:42:42.548492: saving checkpoint...\n",
      "2021-11-12 01:42:43.230258: done, saving took 0.70 seconds\n",
      "2021-11-12 01:42:43.251535: This epoch took 197.491591 s\n",
      "\n",
      "2021-11-12 01:42:43.256248: \n",
      "epoch:  39\n",
      "2021-11-12 01:45:45.745535: train loss : -0.8894\n",
      "2021-11-12 01:45:59.513303: validation loss: -0.8398\n",
      "2021-11-12 01:45:59.519746: Average global foreground Dice: [0.8465]\n",
      "2021-11-12 01:45:59.524352: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 01:46:00.039281: lr: 0.0\n",
      "2021-11-12 01:46:00.063315: saving checkpoint...\n",
      "2021-11-12 01:46:00.736633: done, saving took 0.69 seconds\n",
      "2021-11-12 01:46:00.758415: This epoch took 197.498030 s\n",
      "\n",
      "2021-11-12 01:46:00.782075: saving checkpoint...\n",
      "2021-11-12 01:46:01.277384: done, saving took 0.51 seconds\n",
      "23090557_20130717 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090560_20160114 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090562_20140206 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141215 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130626 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140124 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121015 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090597_20130227 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130208 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090621_20130409 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150105 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130807 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120403 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090637_20140401 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131126 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090644_20131216 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-12 01:47:55.598633: finished prediction\n",
      "2021-11-12 01:47:55.603121: evaluation of raw predictions\n",
      "2021-11-12 01:47:57.087074: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8351750692815085\n",
      "after:  0.8378648829824653\n",
      "Removing all but the largest foreground region improved results!\n",
      "for_which_classes [1]\n",
      "min_valid_object_sizes None\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[[1]]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CEGDL.nnUNetTrainerV2_Loss_CEGDL'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-11-12 01:48:06.891292: Using splits from existing split file: /tf/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-11-12 01:48:06.904457: The split file contains 5 splits.\n",
      "2021-11-12 01:48:06.908391: Desired fold for training: 4\n",
      "2021-11-12 01:48:06.912424: This split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-12 01:48:11.116229: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-12 01:48:20.483045: Unable to plot network architecture:\n",
      "2021-11-12 01:48:20.487375: No module named 'hiddenlayer'\n",
      "2021-11-12 01:48:20.491100: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-12 01:48:20.494806: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-12 01:48:20.502559: \n",
      "\n",
      "2021-11-12 01:48:20.507055: \n",
      "epoch:  0\n",
      "2021-11-12 01:51:39.168725: train loss : -0.2520\n",
      "2021-11-12 01:51:53.083178: validation loss: -0.6144\n",
      "2021-11-12 01:51:53.089347: Average global foreground Dice: [0.6841]\n",
      "2021-11-12 01:51:53.094513: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 01:51:53.525187: lr: 0.009775\n",
      "2021-11-12 01:51:53.529059: This epoch took 213.017348 s\n",
      "\n",
      "2021-11-12 01:51:53.533055: \n",
      "epoch:  1\n",
      "2021-11-12 01:54:54.275664: train loss : -0.6668\n",
      "2021-11-12 01:55:08.100114: validation loss: -0.7166\n",
      "2021-11-12 01:55:08.104743: Average global foreground Dice: [0.7906]\n",
      "2021-11-12 01:55:08.109858: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 01:55:08.718847: lr: 0.009549\n",
      "2021-11-12 01:55:08.760885: saving checkpoint...\n",
      "2021-11-12 01:55:09.307910: done, saving took 0.58 seconds\n",
      "2021-11-12 01:55:09.328797: This epoch took 195.790960 s\n",
      "\n",
      "2021-11-12 01:55:09.332302: \n",
      "epoch:  2\n",
      "2021-11-12 01:58:10.268285: train loss : -0.7561\n",
      "2021-11-12 01:58:24.069038: validation loss: -0.7914\n",
      "2021-11-12 01:58:24.073490: Average global foreground Dice: [0.8107]\n",
      "2021-11-12 01:58:24.077104: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 01:58:24.645897: lr: 0.009322\n",
      "2021-11-12 01:58:24.686112: saving checkpoint...\n",
      "2021-11-12 01:58:25.295280: done, saving took 0.64 seconds\n",
      "2021-11-12 01:58:25.316823: This epoch took 195.980948 s\n",
      "\n",
      "2021-11-12 01:58:25.321260: \n",
      "epoch:  3\n",
      "2021-11-12 02:01:26.273323: train loss : -0.7934\n",
      "2021-11-12 02:01:40.112771: validation loss: -0.8153\n",
      "2021-11-12 02:01:40.117214: Average global foreground Dice: [0.8312]\n",
      "2021-11-12 02:01:40.121495: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 02:01:40.671162: lr: 0.009095\n",
      "2021-11-12 02:01:40.693732: saving checkpoint...\n",
      "2021-11-12 02:01:41.338224: done, saving took 0.66 seconds\n",
      "2021-11-12 02:01:41.371310: This epoch took 196.045597 s\n",
      "\n",
      "2021-11-12 02:01:41.376309: \n",
      "epoch:  4\n",
      "2021-11-12 02:04:41.510398: train loss : -0.8068\n",
      "2021-11-12 02:04:55.327094: validation loss: -0.8197\n",
      "2021-11-12 02:04:55.331527: Average global foreground Dice: [0.8348]\n",
      "2021-11-12 02:04:55.335513: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 02:04:55.896040: lr: 0.008868\n",
      "2021-11-12 02:04:55.932762: saving checkpoint...\n",
      "2021-11-12 02:04:56.592375: done, saving took 0.69 seconds\n",
      "2021-11-12 02:04:56.626655: This epoch took 195.246566 s\n",
      "\n",
      "2021-11-12 02:04:56.631511: \n",
      "epoch:  5\n",
      "2021-11-12 02:07:58.574982: train loss : -0.8171\n",
      "2021-11-12 02:08:12.539942: validation loss: -0.8249\n",
      "2021-11-12 02:08:12.543977: Average global foreground Dice: [0.8395]\n",
      "2021-11-12 02:08:12.548414: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 02:08:13.058850: lr: 0.008639\n",
      "2021-11-12 02:08:13.096392: saving checkpoint...\n",
      "2021-11-12 02:08:13.743213: done, saving took 0.68 seconds\n",
      "2021-11-12 02:08:13.766321: This epoch took 197.130021 s\n",
      "\n",
      "2021-11-12 02:08:13.770214: \n",
      "epoch:  6\n",
      "2021-11-12 02:11:15.921808: train loss : -0.8244\n",
      "2021-11-12 02:11:29.861055: validation loss: -0.8189\n",
      "2021-11-12 02:11:29.865407: Average global foreground Dice: [0.8339]\n",
      "2021-11-12 02:11:29.870139: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 02:11:30.512432: lr: 0.00841\n",
      "2021-11-12 02:11:30.535742: saving checkpoint...\n",
      "2021-11-12 02:11:31.237733: done, saving took 0.72 seconds\n",
      "2021-11-12 02:11:31.269928: This epoch took 197.496221 s\n",
      "\n",
      "2021-11-12 02:11:31.274389: \n",
      "epoch:  7\n",
      "2021-11-12 02:14:33.126802: train loss : -0.8292\n",
      "2021-11-12 02:14:47.093204: validation loss: -0.8357\n",
      "2021-11-12 02:14:47.098547: Average global foreground Dice: [0.8481]\n",
      "2021-11-12 02:14:47.103095: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 02:14:47.612195: lr: 0.008181\n",
      "2021-11-12 02:14:47.636206: saving checkpoint...\n",
      "2021-11-12 02:14:48.274493: done, saving took 0.66 seconds\n",
      "2021-11-12 02:14:48.295354: This epoch took 197.017260 s\n",
      "\n",
      "2021-11-12 02:14:48.298719: \n",
      "epoch:  8\n",
      "2021-11-12 02:17:50.712773: train loss : -0.8338\n",
      "2021-11-12 02:18:04.646142: validation loss: -0.8316\n",
      "2021-11-12 02:18:04.651532: Average global foreground Dice: [0.8456]\n",
      "2021-11-12 02:18:04.655519: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 02:18:05.191046: lr: 0.00795\n",
      "2021-11-12 02:18:05.227557: saving checkpoint...\n",
      "2021-11-12 02:18:05.841690: done, saving took 0.65 seconds\n",
      "2021-11-12 02:18:05.879152: This epoch took 197.576591 s\n",
      "\n",
      "2021-11-12 02:18:05.883609: \n",
      "epoch:  9\n",
      "2021-11-12 02:21:08.361860: train loss : -0.8389\n",
      "2021-11-12 02:21:22.306612: validation loss: -0.8332\n",
      "2021-11-12 02:21:22.311722: Average global foreground Dice: [0.846]\n",
      "2021-11-12 02:21:22.316355: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 02:21:22.811847: lr: 0.007719\n",
      "2021-11-12 02:21:22.847816: saving checkpoint...\n",
      "2021-11-12 02:21:23.500586: done, saving took 0.68 seconds\n",
      "2021-11-12 02:21:23.524174: This epoch took 197.635337 s\n",
      "\n",
      "2021-11-12 02:21:23.528793: \n",
      "epoch:  10\n",
      "2021-11-12 02:24:25.921363: train loss : -0.8419\n",
      "2021-11-12 02:24:39.852543: validation loss: -0.8340\n",
      "2021-11-12 02:24:39.857163: Average global foreground Dice: [0.846]\n",
      "2021-11-12 02:24:39.861192: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 02:24:40.403668: lr: 0.007487\n",
      "2021-11-12 02:24:40.429398: saving checkpoint...\n",
      "2021-11-12 02:24:41.073012: done, saving took 0.66 seconds\n",
      "2021-11-12 02:24:41.106029: This epoch took 197.573256 s\n",
      "\n",
      "2021-11-12 02:24:41.109843: \n",
      "epoch:  11\n",
      "2021-11-12 02:27:43.580647: train loss : -0.8430\n",
      "2021-11-12 02:27:57.515231: validation loss: -0.8333\n",
      "2021-11-12 02:27:57.521038: Average global foreground Dice: [0.8455]\n",
      "2021-11-12 02:27:57.525565: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 02:27:58.085483: lr: 0.007254\n",
      "2021-11-12 02:27:58.108502: saving checkpoint...\n",
      "2021-11-12 02:27:58.714785: done, saving took 0.63 seconds\n",
      "2021-11-12 02:27:58.736567: This epoch took 197.622839 s\n",
      "\n",
      "2021-11-12 02:27:58.740627: \n",
      "epoch:  12\n",
      "2021-11-12 02:31:01.154999: train loss : -0.8477\n",
      "2021-11-12 02:31:15.107642: validation loss: -0.8372\n",
      "2021-11-12 02:31:15.113540: Average global foreground Dice: [0.8501]\n",
      "2021-11-12 02:31:15.118121: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 02:31:15.660421: lr: 0.007021\n",
      "2021-11-12 02:31:15.683772: saving checkpoint...\n",
      "2021-11-12 02:31:16.327382: done, saving took 0.66 seconds\n",
      "2021-11-12 02:31:16.360188: This epoch took 197.614431 s\n",
      "\n",
      "2021-11-12 02:31:16.365091: \n",
      "epoch:  13\n",
      "2021-11-12 02:34:18.737421: train loss : -0.8513\n",
      "2021-11-12 02:34:32.703025: validation loss: -0.8397\n",
      "2021-11-12 02:34:32.708447: Average global foreground Dice: [0.8508]\n",
      "2021-11-12 02:34:32.713522: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 02:34:33.264424: lr: 0.006786\n",
      "2021-11-12 02:34:33.296347: saving checkpoint...\n",
      "2021-11-12 02:34:33.926145: done, saving took 0.66 seconds\n",
      "2021-11-12 02:34:33.960622: This epoch took 197.589377 s\n",
      "\n",
      "2021-11-12 02:34:33.964952: \n",
      "epoch:  14\n",
      "2021-11-12 02:37:36.362837: train loss : -0.8532\n",
      "2021-11-12 02:37:50.307858: validation loss: -0.8357\n",
      "2021-11-12 02:37:50.313507: Average global foreground Dice: [0.8478]\n",
      "2021-11-12 02:37:50.317930: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 02:37:50.837050: lr: 0.006551\n",
      "2021-11-12 02:37:50.859570: saving checkpoint...\n",
      "2021-11-12 02:37:51.460028: done, saving took 0.62 seconds\n",
      "2021-11-12 02:37:51.491245: This epoch took 197.521953 s\n",
      "\n",
      "2021-11-12 02:37:51.496108: \n",
      "epoch:  15\n",
      "2021-11-12 02:40:53.857912: train loss : -0.8545\n",
      "2021-11-12 02:41:07.794454: validation loss: -0.8338\n",
      "2021-11-12 02:41:07.808588: Average global foreground Dice: [0.8447]\n",
      "2021-11-12 02:41:07.814206: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 02:41:08.374056: lr: 0.006314\n",
      "2021-11-12 02:41:08.397980: saving checkpoint...\n",
      "2021-11-12 02:41:09.026949: done, saving took 0.65 seconds\n",
      "2021-11-12 02:41:09.058425: This epoch took 197.557806 s\n",
      "\n",
      "2021-11-12 02:41:09.064140: \n",
      "epoch:  16\n",
      "2021-11-12 02:44:11.608816: train loss : -0.8575\n",
      "2021-11-12 02:44:25.566513: validation loss: -0.8379\n",
      "2021-11-12 02:44:25.571435: Average global foreground Dice: [0.8481]\n",
      "2021-11-12 02:44:25.575884: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 02:44:26.160309: lr: 0.006077\n",
      "2021-11-12 02:44:26.183425: saving checkpoint...\n",
      "2021-11-12 02:44:26.843053: done, saving took 0.68 seconds\n",
      "2021-11-12 02:44:26.875073: This epoch took 197.806865 s\n",
      "\n",
      "2021-11-12 02:44:26.879279: \n",
      "epoch:  17\n",
      "2021-11-12 02:47:29.360348: train loss : -0.8590\n",
      "2021-11-12 02:47:43.281814: validation loss: -0.8429\n",
      "2021-11-12 02:47:43.286838: Average global foreground Dice: [0.8534]\n",
      "2021-11-12 02:47:43.290886: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 02:47:43.845459: lr: 0.005839\n",
      "2021-11-12 02:47:43.869219: saving checkpoint...\n",
      "2021-11-12 02:47:44.481613: done, saving took 0.63 seconds\n",
      "2021-11-12 02:47:44.515222: This epoch took 197.631394 s\n",
      "\n",
      "2021-11-12 02:47:44.519235: \n",
      "epoch:  18\n",
      "2021-11-12 02:50:47.068252: train loss : -0.8607\n",
      "2021-11-12 02:51:01.016247: validation loss: -0.8318\n",
      "2021-11-12 02:51:01.020784: Average global foreground Dice: [0.8447]\n",
      "2021-11-12 02:51:01.024831: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 02:51:01.582367: lr: 0.005599\n",
      "2021-11-12 02:51:01.605238: saving checkpoint...\n",
      "2021-11-12 02:51:02.239115: done, saving took 0.65 seconds\n",
      "2021-11-12 02:51:02.269630: This epoch took 197.746884 s\n",
      "\n",
      "2021-11-12 02:51:02.273836: \n",
      "epoch:  19\n",
      "2021-11-12 02:54:04.848299: train loss : -0.8621\n",
      "2021-11-12 02:54:18.782774: validation loss: -0.8464\n",
      "2021-11-12 02:54:18.788847: Average global foreground Dice: [0.8569]\n",
      "2021-11-12 02:54:18.793067: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 02:54:19.312501: lr: 0.005359\n",
      "2021-11-12 02:54:19.337018: saving checkpoint...\n",
      "2021-11-12 02:54:19.979992: done, saving took 0.66 seconds\n",
      "2021-11-12 02:54:20.003322: This epoch took 197.724777 s\n",
      "\n",
      "2021-11-12 02:54:20.008502: \n",
      "epoch:  20\n",
      "2021-11-12 02:57:22.589407: train loss : -0.8627\n",
      "2021-11-12 02:57:36.547233: validation loss: -0.8395\n",
      "2021-11-12 02:57:36.552774: Average global foreground Dice: [0.85]\n",
      "2021-11-12 02:57:36.557749: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 02:57:37.060743: lr: 0.005117\n",
      "2021-11-12 02:57:37.084004: saving checkpoint...\n",
      "2021-11-12 02:57:37.706354: done, saving took 0.64 seconds\n",
      "2021-11-12 02:57:37.728914: This epoch took 197.715304 s\n",
      "\n",
      "2021-11-12 02:57:37.732963: \n",
      "epoch:  21\n",
      "2021-11-12 03:00:40.310606: train loss : -0.8658\n",
      "2021-11-12 03:00:54.256961: validation loss: -0.8375\n",
      "2021-11-12 03:00:54.262627: Average global foreground Dice: [0.8488]\n",
      "2021-11-12 03:00:54.267172: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 03:00:54.772284: lr: 0.004874\n",
      "2021-11-12 03:00:54.800515: saving checkpoint...\n",
      "2021-11-12 03:00:55.481944: done, saving took 0.70 seconds\n",
      "2021-11-12 03:00:55.512444: This epoch took 197.774928 s\n",
      "\n",
      "2021-11-12 03:00:55.516567: \n",
      "epoch:  22\n",
      "2021-11-12 03:03:58.116115: train loss : -0.8680\n",
      "2021-11-12 03:04:12.064251: validation loss: -0.8462\n",
      "2021-11-12 03:04:12.069692: Average global foreground Dice: [0.8565]\n",
      "2021-11-12 03:04:12.073473: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 03:04:12.606094: lr: 0.00463\n",
      "2021-11-12 03:04:12.629122: saving checkpoint...\n",
      "2021-11-12 03:04:13.263803: done, saving took 0.65 seconds\n",
      "2021-11-12 03:04:13.286300: This epoch took 197.766113 s\n",
      "\n",
      "2021-11-12 03:04:13.290916: \n",
      "epoch:  23\n",
      "2021-11-12 03:07:15.898006: train loss : -0.8675\n",
      "2021-11-12 03:07:29.846837: validation loss: -0.8376\n",
      "2021-11-12 03:07:29.851875: Average global foreground Dice: [0.8487]\n",
      "2021-11-12 03:07:29.856437: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 03:07:30.355397: lr: 0.004384\n",
      "2021-11-12 03:07:30.379579: saving checkpoint...\n",
      "2021-11-12 03:07:31.043219: done, saving took 0.68 seconds\n",
      "2021-11-12 03:07:31.068246: This epoch took 197.773116 s\n",
      "\n",
      "2021-11-12 03:07:31.072541: \n",
      "epoch:  24\n",
      "2021-11-12 03:10:33.710602: train loss : -0.8704\n",
      "2021-11-12 03:10:47.658429: validation loss: -0.8384\n",
      "2021-11-12 03:10:47.665270: Average global foreground Dice: [0.849]\n",
      "2021-11-12 03:10:47.669887: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 03:10:48.220958: lr: 0.004136\n",
      "2021-11-12 03:10:48.244534: saving checkpoint...\n",
      "2021-11-12 03:10:48.920943: done, saving took 0.70 seconds\n",
      "2021-11-12 03:10:48.941841: This epoch took 197.864525 s\n",
      "\n",
      "2021-11-12 03:10:48.945957: \n",
      "epoch:  25\n",
      "2021-11-12 03:13:51.571048: train loss : -0.8717\n",
      "2021-11-12 03:14:05.500900: validation loss: -0.8322\n",
      "2021-11-12 03:14:05.505623: Average global foreground Dice: [0.8456]\n",
      "2021-11-12 03:14:05.510513: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 03:14:06.023130: lr: 0.003887\n",
      "2021-11-12 03:14:06.047094: saving checkpoint...\n",
      "2021-11-12 03:14:06.693882: done, saving took 0.67 seconds\n",
      "2021-11-12 03:14:06.716265: This epoch took 197.766008 s\n",
      "\n",
      "2021-11-12 03:14:06.720814: \n",
      "epoch:  26\n",
      "2021-11-12 03:17:09.363655: train loss : -0.8724\n",
      "2021-11-12 03:17:23.303794: validation loss: -0.8376\n",
      "2021-11-12 03:17:23.309316: Average global foreground Dice: [0.8483]\n",
      "2021-11-12 03:17:23.314057: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 03:17:23.895610: lr: 0.003637\n",
      "2021-11-12 03:17:23.919440: saving checkpoint...\n",
      "2021-11-12 03:17:24.566974: done, saving took 0.67 seconds\n",
      "2021-11-12 03:17:24.591085: This epoch took 197.865787 s\n",
      "\n",
      "2021-11-12 03:17:24.594792: \n",
      "epoch:  27\n",
      "2021-11-12 03:20:27.220057: train loss : -0.8748\n",
      "2021-11-12 03:20:41.168171: validation loss: -0.8424\n",
      "2021-11-12 03:20:41.174119: Average global foreground Dice: [0.8537]\n",
      "2021-11-12 03:20:41.178892: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 03:20:41.775715: lr: 0.003384\n",
      "2021-11-12 03:20:41.798714: saving checkpoint...\n",
      "2021-11-12 03:20:42.463752: done, saving took 0.68 seconds\n",
      "2021-11-12 03:20:42.486953: This epoch took 197.887138 s\n",
      "\n",
      "2021-11-12 03:20:42.492449: \n",
      "epoch:  28\n",
      "2021-11-12 03:23:45.086859: train loss : -0.8763\n",
      "2021-11-12 03:23:59.022908: validation loss: -0.8455\n",
      "2021-11-12 03:23:59.028109: Average global foreground Dice: [0.855]\n",
      "2021-11-12 03:23:59.032974: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 03:23:59.572561: lr: 0.003129\n",
      "2021-11-12 03:23:59.595404: saving checkpoint...\n",
      "2021-11-12 03:24:00.242338: done, saving took 0.67 seconds\n",
      "2021-11-12 03:24:00.266466: This epoch took 197.769532 s\n",
      "\n",
      "2021-11-12 03:24:00.271482: \n",
      "epoch:  29\n",
      "2021-11-12 03:27:02.875903: train loss : -0.8765\n",
      "2021-11-12 03:27:16.830909: validation loss: -0.8383\n",
      "2021-11-12 03:27:16.836355: Average global foreground Dice: [0.8486]\n",
      "2021-11-12 03:27:16.841199: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 03:27:17.390684: lr: 0.002872\n",
      "2021-11-12 03:27:17.413576: saving checkpoint...\n",
      "2021-11-12 03:27:18.049193: done, saving took 0.65 seconds\n",
      "2021-11-12 03:27:18.071718: This epoch took 197.795433 s\n",
      "\n",
      "2021-11-12 03:27:18.076316: \n",
      "epoch:  30\n",
      "2021-11-12 03:30:20.668293: train loss : -0.8787\n",
      "2021-11-12 03:30:34.614294: validation loss: -0.8450\n",
      "2021-11-12 03:30:34.618546: Average global foreground Dice: [0.8545]\n",
      "2021-11-12 03:30:34.624031: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 03:30:35.170409: lr: 0.002612\n",
      "2021-11-12 03:30:35.193289: saving checkpoint...\n",
      "2021-11-12 03:30:35.840458: done, saving took 0.67 seconds\n",
      "2021-11-12 03:30:35.862903: This epoch took 197.782551 s\n",
      "\n",
      "2021-11-12 03:30:35.867431: \n",
      "epoch:  31\n",
      "2021-11-12 03:33:38.456916: train loss : -0.8798\n",
      "2021-11-12 03:33:52.414471: validation loss: -0.8414\n",
      "2021-11-12 03:33:52.420123: Average global foreground Dice: [0.8513]\n",
      "2021-11-12 03:33:52.425315: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 03:33:52.936226: lr: 0.002349\n",
      "2021-11-12 03:33:52.958904: saving checkpoint...\n",
      "2021-11-12 03:33:53.595218: done, saving took 0.66 seconds\n",
      "2021-11-12 03:33:53.616975: This epoch took 197.744542 s\n",
      "\n",
      "2021-11-12 03:33:53.621614: \n",
      "epoch:  32\n",
      "2021-11-12 03:36:56.253359: train loss : -0.8806\n",
      "2021-11-12 03:37:10.197434: validation loss: -0.8417\n",
      "2021-11-12 03:37:10.202487: Average global foreground Dice: [0.8514]\n",
      "2021-11-12 03:37:10.207367: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 03:37:10.788759: lr: 0.002083\n",
      "2021-11-12 03:37:10.811535: saving checkpoint...\n",
      "2021-11-12 03:37:11.506418: done, saving took 0.71 seconds\n",
      "2021-11-12 03:37:11.528404: This epoch took 197.902428 s\n",
      "\n",
      "2021-11-12 03:37:11.534206: \n",
      "epoch:  33\n",
      "2021-11-12 03:40:14.190476: train loss : -0.8821\n",
      "2021-11-12 03:40:28.145291: validation loss: -0.8412\n",
      "2021-11-12 03:40:28.149885: Average global foreground Dice: [0.8521]\n",
      "2021-11-12 03:40:28.154041: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 03:40:28.688060: lr: 0.001813\n",
      "2021-11-12 03:40:28.712039: saving checkpoint...\n",
      "2021-11-12 03:40:29.359051: done, saving took 0.67 seconds\n",
      "2021-11-12 03:40:29.380716: This epoch took 197.841969 s\n",
      "\n",
      "2021-11-12 03:40:29.384576: \n",
      "epoch:  34\n",
      "2021-11-12 03:43:32.031202: train loss : -0.8845\n",
      "2021-11-12 03:43:45.974605: validation loss: -0.8416\n",
      "2021-11-12 03:43:45.980110: Average global foreground Dice: [0.8504]\n",
      "2021-11-12 03:43:45.985271: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 03:43:46.531105: lr: 0.001539\n",
      "2021-11-12 03:43:46.554406: saving checkpoint...\n",
      "2021-11-12 03:43:47.184866: done, saving took 0.65 seconds\n",
      "2021-11-12 03:43:47.206116: This epoch took 197.817204 s\n",
      "\n",
      "2021-11-12 03:43:47.210105: \n",
      "epoch:  35\n",
      "2021-11-12 03:46:49.887440: train loss : -0.8847\n",
      "2021-11-12 03:47:03.836428: validation loss: -0.8383\n",
      "2021-11-12 03:47:03.841811: Average global foreground Dice: [0.8487]\n",
      "2021-11-12 03:47:03.845497: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 03:47:04.374757: lr: 0.001259\n",
      "2021-11-12 03:47:04.406350: saving checkpoint...\n",
      "2021-11-12 03:47:05.057650: done, saving took 0.68 seconds\n",
      "2021-11-12 03:47:05.084332: This epoch took 197.867771 s\n",
      "\n",
      "2021-11-12 03:47:05.088702: \n",
      "epoch:  36\n",
      "2021-11-12 03:50:07.757823: train loss : -0.8863\n",
      "2021-11-12 03:50:21.710804: validation loss: -0.8420\n",
      "2021-11-12 03:50:21.715841: Average global foreground Dice: [0.8497]\n",
      "2021-11-12 03:50:21.720885: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 03:50:22.277478: lr: 0.000972\n",
      "2021-11-12 03:50:22.309467: saving checkpoint...\n",
      "2021-11-12 03:50:22.967771: done, saving took 0.69 seconds\n",
      "2021-11-12 03:50:22.989449: This epoch took 197.895796 s\n",
      "\n",
      "2021-11-12 03:50:22.995950: \n",
      "epoch:  37\n",
      "2021-11-12 03:53:25.655597: train loss : -0.8883\n",
      "2021-11-12 03:53:39.609704: validation loss: -0.8400\n",
      "2021-11-12 03:53:39.614359: Average global foreground Dice: [0.8499]\n",
      "2021-11-12 03:53:39.618275: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 03:53:40.169420: lr: 0.000675\n",
      "2021-11-12 03:53:40.192678: saving checkpoint...\n",
      "2021-11-12 03:53:40.895203: done, saving took 0.72 seconds\n",
      "2021-11-12 03:53:40.920815: This epoch took 197.920304 s\n",
      "\n",
      "2021-11-12 03:53:40.924979: \n",
      "epoch:  38\n",
      "2021-11-12 03:56:43.593208: train loss : -0.8878\n",
      "2021-11-12 03:56:57.534039: validation loss: -0.8443\n",
      "2021-11-12 03:56:57.539392: Average global foreground Dice: [0.8544]\n",
      "2021-11-12 03:56:57.543113: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 03:56:58.078800: lr: 0.000362\n",
      "2021-11-12 03:56:58.101543: saving checkpoint...\n",
      "2021-11-12 03:56:58.834388: done, saving took 0.75 seconds\n",
      "2021-11-12 03:56:58.857043: This epoch took 197.927749 s\n",
      "\n",
      "2021-11-12 03:56:58.861418: \n",
      "epoch:  39\n",
      "2021-11-12 04:00:01.507334: train loss : -0.8884\n",
      "2021-11-12 04:00:15.446880: validation loss: -0.8402\n",
      "2021-11-12 04:00:15.452253: Average global foreground Dice: [0.8494]\n",
      "2021-11-12 04:00:15.456887: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-12 04:00:15.965528: lr: 0.0\n",
      "2021-11-12 04:00:15.990214: saving checkpoint...\n",
      "2021-11-12 04:00:16.621959: done, saving took 0.65 seconds\n",
      "2021-11-12 04:00:16.644133: This epoch took 197.778652 s\n",
      "\n",
      "2021-11-12 04:00:16.667938: saving checkpoint...\n",
      "2021-11-12 04:00:17.233501: done, saving took 0.58 seconds\n",
      "23090558_20120330 (3, 263, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090564_20130312 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090568_20121018 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090569_20120607 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120613 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150908 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090593_20120625 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130103 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090600_20121108 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090603_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090607_20120420 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090609_20120510 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160119 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160510 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141212 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090646_20120718 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-12 04:02:10.198446: finished prediction\n",
      "2021-11-12 04:02:10.203231: evaluation of raw predictions\n",
      "2021-11-12 04:02:11.634141: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.833509072355997\n",
      "after:  0.8257780656305578\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Model 10 (epoch 40)\n",
    "\n",
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_CEGDL 555 0 --cuda_device 0\n",
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_CEGDL 555 1 --cuda_device 0\n",
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_CEGDL 555 2 --cuda_device 0\n",
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_CEGDL 555 3 --cuda_device 0\n",
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_CEGDL 555 4 --cuda_device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = os.path.join(model_dir, 'nnUNet/2d/')\n",
    "# fold_list = ['fold_0', 'fold_1', 'fold_2', 'fold_3', 'fold_4']\n",
    "# fold_list = [fold_0, fold_1, fold_2, fold_3, fold_4]\n",
    "# nnUNetTrainerV2_Loss_CEGDL__nnUNetPlansv2.1\n",
    "\n",
    "fold_all = os.path.join(model_1, 'Task555_PETCT/nnUNetTrainerV2_Loss_CEGDL__nnUNetPlansv2.1/all')\n",
    "fold_0 = os.path.join(model_1, 'Task555_PETCT/nnUNetTrainerV2_Loss_CEGDL__nnUNetPlansv2.1/fold_0')\n",
    "fold_1 = os.path.join(model_1, 'Task555_PETCT/nnUNetTrainerV2_Loss_CEGDL__nnUNetPlansv2.1/fold_1')\n",
    "fold_2 = os.path.join(model_1, 'Task555_PETCT/nnUNetTrainerV2_Loss_CEGDL__nnUNetPlansv2.1/fold_2')\n",
    "fold_3 = os.path.join(model_1, 'Task555_PETCT/nnUNetTrainerV2_Loss_CEGDL__nnUNetPlansv2.1/fold_3')\n",
    "fold_4 = os.path.join(model_1, 'Task555_PETCT/nnUNetTrainerV2_Loss_CEGDL__nnUNetPlansv2.1/fold_4')\n",
    "\n",
    "fold_list = [fold_0, fold_1, fold_2, fold_3, fold_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in fold_list:\n",
    "    if os.path.exists(fold):\n",
    "        shutil.rmtree(fold)\n",
    "        shutil.copytree(fold_all, fold)\n",
    "    else:\n",
    "        shutil.copytree(fold_all, fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! /mnt/utils/setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['utils', 'backup', 'dataset', 'submission', 'temp']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/mnt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23010019_20141.nii.gz',\n",
       " '23010017_20141.nii.gz',\n",
       " '23010018_20141.nii.gz',\n",
       " 'plans.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/mnt/backup/working/nnUNet/nnunet/nnUNet_Prediction_Results/Task555_PETCT/2d/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23090580_20131226.hdf5', '23090618_20161212.hdf5', '23090628_20150204.hdf5', '23090643_20121227.hdf5', '23090644_20131216.hdf5', '23090636_20121018.hdf5', '23090585_20130213.hdf5', '23090572_20130226.hdf5', '23090603_20141212.hdf5', '23090601_20130225.hdf5', '23090569_20120607.hdf5', '23090599_20140701.hdf5', '23090597_20130227.hdf5', '23090627_20160608.hdf5', '23090559_20150812.hdf5', '23090614_20120402.hdf5', '23090557_20130717.hdf5', '23090634_20150409.hdf5', '23090581_20130626.hdf5', '23090626_20160119.hdf5', '23090568_20121018.hdf5', '23090623_20120406.hdf5', '23090615_20140403.hdf5', '23090640_20140711.hdf5', '23090613_20130208.hdf5', '23090641_20160510.hdf5', '23090609_20120510.hdf5', '23090560_20160114.hdf5', '23090563_20151216.hdf5', '23090596_20150112.hdf5', '23090632_20130807.hdf5', '23090598_20130103.hdf5', '23090584_20120523.hdf5', '23090633_20120403.hdf5', '23090607_20120420.hdf5', '23090594_20160706.hdf5', '23090622_20150105.hdf5', '23090583_20160308.hdf5', '23090637_20140401.hdf5', '23090620_20130617.hdf5', '23090645_20141212.hdf5', '23090621_20130409.hdf5', '23090562_20140206.hdf5', '23090582_20150401.hdf5', '23090566_20141114.hdf5', '23090571_20120517.hdf5', '23090642_20130409.hdf5', '23090595_20121015.hdf5', '23090586_20120627.hdf5', '23090604_20140303.hdf5', '23090561_20120330.hdf5', '23090610_20151210.hdf5', '23090639_20150522.hdf5', '23090608_20120718.hdf5', '23090588_20131025.hdf5', '23090578_20120613.hdf5', '23090593_20120625.hdf5', '23090564_20130312.hdf5', '23090631_20130128.hdf5', '23090616_20140331.hdf5', '23090606_20120619.hdf5', '23090638_20131126.hdf5', '23090629_20120830.hdf5', '23090592_20130218.hdf5', '23090625_20160111.hdf5', '23090589_20140219.hdf5', '23090617_20140211.hdf5', '23090590_20121212.hdf5', '23090619_20121210.hdf5', '23090611_20150212.hdf5', '23090612_20121213.hdf5', '23090646_20120718.hdf5', '23090600_20121108.hdf5', '23090579_20141215.hdf5', '23090630_20130213.hdf5', '23090558_20120330.hdf5', '23090591_20140124.hdf5', '23090567_20160819.hdf5', '23090635_20140710.hdf5', '23090587_20150908.hdf5']\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('/mnt/dataset'))\n",
    "print(len(os.listdir('/mnt/dataset')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fold_4',\n",
       " 'fold_0',\n",
       " 'fold_2',\n",
       " 'all',\n",
       " 'fold_1',\n",
       " 'plans.pkl',\n",
       " 'fold_3',\n",
       " 'gt_niftis']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fold_4',\n",
       " 'fold_0',\n",
       " 'fold_2',\n",
       " 'all',\n",
       " 'fold_1',\n",
       " 'plans.pkl',\n",
       " 'fold_3',\n",
       " 'gt_niftis']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename model..\n",
    "# os.rename('/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/all_Task555_PETCT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/backup/temp_submission/models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2_Loss_CEGDL__nnUNetPlansv2.1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "# Copy model..\n",
    "shutil.copytree('/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2_Loss_CEGDL__nnUNetPlansv2.1/', '/mnt/backup/temp_submission/models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2_Loss_CEGDL__nnUNetPlansv2.1')\n",
    "# shutil.copytree('/tf/submission/submitted/21-10-27_13:29:02-models/', '/tf/temp_submission/models')\n",
    "# shutil.copytree('/tf/backup/nnUNet', '/tf/temp_submission/models/module')\n",
    "# shutil.copytree('/tf/backup/temp_submission/', '/tf/temp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/mnt/temp/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['utils', 'backup', 'dataset', 'submission', 'temp']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(os.listdir('/mnt/'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
