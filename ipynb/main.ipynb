{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://ftp.daumkakao.com/pypi/simple\n",
      "Obtaining file:///mnt/backup/nnUNet\n",
      "Requirement already satisfied: torch>=1.6.0a in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (1.9.1+cu111)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (4.62.3)\n",
      "Requirement already satisfied: dicom2nifti in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (2.3.0)\n",
      "Requirement already satisfied: scikit-image>=0.14 in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (0.18.3)\n",
      "Requirement already satisfied: medpy in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (0.4.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (1.7.1)\n",
      "Requirement already satisfied: batchgenerators>=0.23 in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (0.23)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (1.19.5)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (0.0)\n",
      "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (2.1.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (1.3.4)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from nnunet==1.7.0) (2.22.0)\n",
      "Requirement already satisfied: nibabel in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (3.2.1)\n",
      "Requirement already satisfied: tifffile in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (2021.10.12)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6.0a->nnunet==1.7.0) (3.7.4.3)\n",
      "Requirement already satisfied: pydicom>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from dicom2nifti->nnunet==1.7.0) (2.2.2)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (8.3.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (1.1.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (3.4.3)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.9.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.6.3)\n",
      "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.8/dist-packages (from batchgenerators>=0.23->nnunet==1.7.0) (3.0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from batchgenerators>=0.23->nnunet==1.7.0) (1.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from batchgenerators>=0.23->nnunet==1.7.0) (0.18.2)\n",
      "Requirement already satisfied: unittest2 in /usr/local/lib/python3.8/dist-packages (from batchgenerators>=0.23->nnunet==1.7.0) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->nnunet==1.7.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->nnunet==1.7.0) (2021.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.8/dist-packages (from nibabel->nnunet==1.7.0) (21.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14->nnunet==1.7.0) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14->nnunet==1.7.0) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14->nnunet==1.7.0) (2.4.7)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->batchgenerators>=0.23->nnunet==1.7.0) (1.1.0)\n",
      "Requirement already satisfied: traceback2 in /usr/local/lib/python3.8/dist-packages (from unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.4.0)\n",
      "Requirement already satisfied: six>=1.4 in /usr/local/lib/python3.8/dist-packages (from unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.15.0)\n",
      "Requirement already satisfied: argparse in /usr/local/lib/python3.8/dist-packages (from unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.4.0)\n",
      "Requirement already satisfied: linecache2 in /usr/local/lib/python3.8/dist-packages (from traceback2->unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.0.0)\n",
      "Installing collected packages: nnunet\n",
      "  Attempting uninstall: nnunet\n",
      "    Found existing installation: nnunet 1.7.0\n",
      "    Can't uninstall 'nnunet'. No files were found to uninstall.\n",
      "  Running setup.py develop for nnunet\n",
      "Successfully installed nnunet\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def maybe_mkdir_p(directory: str) -> None:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "maic_dir = '/mnt/backup/'\n",
    "base_dir = os.path.join(maic_dir, 'working')\n",
    "input_dir = '/mnt/dataset/'\n",
    "temp_dir = '/mnt/temp/'\n",
    "\n",
    "maybe_mkdir_p(base_dir)\n",
    "maybe_mkdir_p(temp_dir)\n",
    "\n",
    "# ! git clone https://github.com/keemsir/nnUNet.git\n",
    "\n",
    "respository_dir = os.path.join(maic_dir, 'nnUNet')\n",
    "os.chdir(respository_dir)\n",
    "\n",
    "! pip install -e .\n",
    "\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installed\n",
    "import shutil\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "from scipy import special\n",
    "import copy\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "# must install\n",
    "import pydicom\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n! mkdir -p /root/.pip\\n\\n\\n%%writefile /root/.pip/pip.conf\\n[global]\\nindex-url=http://ftp.daumkakao.com/pypi/simple\\ntrusted-host=ftp.daumkakao.com\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "! mkdir -p /root/.pip\n",
    "\n",
    "\n",
    "%%writefile /root/.pip/pip.conf\n",
    "[global]\n",
    "index-url=http://ftp.daumkakao.com/pypi/simple\n",
    "trusted-host=ftp.daumkakao.com\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# zipfile open\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('/tf/backup/nnUNet.zip', 'r') as existing_zip:\n",
    "#     existing_zip.extractall('/tf/temp/')\n",
    "    existing_zip.extractall('/tf/submission/submit_files/')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://ftp.daumkakao.com/pypi/simple\n",
      "Obtaining file:///mnt/backup/nnUNet\n",
      "Requirement already satisfied: torch>=1.6.0a in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (1.9.1+cu111)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (4.62.3)\n",
      "Requirement already satisfied: dicom2nifti in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (2.3.0)\n",
      "Requirement already satisfied: scikit-image>=0.14 in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (0.18.3)\n",
      "Requirement already satisfied: medpy in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (0.4.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (1.7.1)\n",
      "Requirement already satisfied: batchgenerators>=0.23 in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (0.23)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (1.19.5)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (0.0)\n",
      "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (2.1.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (1.3.4)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from nnunet==1.7.0) (2.22.0)\n",
      "Requirement already satisfied: nibabel in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (3.2.1)\n",
      "Requirement already satisfied: tifffile in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (2021.10.12)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6.0a->nnunet==1.7.0) (3.7.4.3)\n",
      "Requirement already satisfied: pydicom>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from dicom2nifti->nnunet==1.7.0) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (3.4.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (1.1.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (8.3.2)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.9.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.6.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from batchgenerators>=0.23->nnunet==1.7.0) (1.0)\n",
      "Requirement already satisfied: unittest2 in /usr/local/lib/python3.8/dist-packages (from batchgenerators>=0.23->nnunet==1.7.0) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.8/dist-packages (from batchgenerators>=0.23->nnunet==1.7.0) (3.0.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from batchgenerators>=0.23->nnunet==1.7.0) (0.18.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->nnunet==1.7.0) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->nnunet==1.7.0) (2.8.2)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.8/dist-packages (from nibabel->nnunet==1.7.0) (21.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14->nnunet==1.7.0) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14->nnunet==1.7.0) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14->nnunet==1.7.0) (1.3.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->batchgenerators>=0.23->nnunet==1.7.0) (1.1.0)\n",
      "Requirement already satisfied: six>=1.4 in /usr/local/lib/python3.8/dist-packages (from unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.15.0)\n",
      "Requirement already satisfied: argparse in /usr/local/lib/python3.8/dist-packages (from unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.4.0)\n",
      "Requirement already satisfied: traceback2 in /usr/local/lib/python3.8/dist-packages (from unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.4.0)\n",
      "Requirement already satisfied: linecache2 in /usr/local/lib/python3.8/dist-packages (from traceback2->unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.0.0)\n",
      "Installing collected packages: nnunet\n",
      "  Attempting uninstall: nnunet\n",
      "    Found existing installation: nnunet 1.7.0\n",
      "    Can't uninstall 'nnunet'. No files were found to uninstall.\n",
      "  Running setup.py develop for nnunet\n",
      "Successfully installed nnunet\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def maybe_mkdir_p(directory: str) -> None:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "maic_dir = '/mnt/backup/'\n",
    "base_dir = os.path.join(maic_dir, 'working')\n",
    "input_dir = '/mnt/dataset/'\n",
    "temp_dir = '/mnt/temp/'\n",
    "\n",
    "maybe_mkdir_p(base_dir)\n",
    "maybe_mkdir_p(temp_dir)\n",
    "\n",
    "# ! git clone https://github.com/keemsir/nnUNet.git\n",
    "\n",
    "respository_dir = os.path.join(maic_dir, 'nnUNet')\n",
    "os.chdir(respository_dir)\n",
    "\n",
    "! pip install -e .\n",
    "\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Completed!\n"
     ]
    }
   ],
   "source": [
    "task_name = 'Task55_PETCT'\n",
    "convert_name = 'Task555_PETCT'\n",
    "\n",
    "main_dir = os.path.join(base_dir, 'nnUNet/nnunet')\n",
    "mainT_dir = os.path.join(temp_dir, 'nnUNet/nnunet')\n",
    "\n",
    "rawbase_dir = os.path.join(mainT_dir, 'nnUNet_raw_data_base/')\n",
    "\n",
    "pp_dir = os.path.join(mainT_dir, 'preprocessed')\n",
    "tasks_dir = os.path.join(mainT_dir, 'Tasks')\n",
    "task_dir = os.path.join(tasks_dir, task_name)\n",
    "\n",
    "model_dir = os.path.join(main_dir, 'nnUNet_trained_models')\n",
    "Prediction_dir = os.path.join(main_dir, 'nnUNet_Prediction_Results')\n",
    "result_dir = os.path.join(Prediction_dir, convert_name)\n",
    "\n",
    "staple_dir = os.path.join(Prediction_dir, 'staple')\n",
    "\n",
    "# 1. Data preprocessing\n",
    "maybe_mkdir_p(tasks_dir)\n",
    "maybe_mkdir_p(temp_dir)\n",
    "\n",
    "# 2. Directory\n",
    "maybe_mkdir_p(main_dir)\n",
    "maybe_mkdir_p(model_dir)\n",
    "maybe_mkdir_p(pp_dir)\n",
    "\n",
    "# 3. Directory\n",
    "maybe_mkdir_p(result_dir)\n",
    "maybe_mkdir_p(staple_dir)\n",
    "\n",
    "\n",
    "#Environment Setting\n",
    "os.environ['nnUNet_raw_data_base'] = rawbase_dir #os.path.join(mainT_dir, 'nnUNet_raw_data_base')\n",
    "os.environ['nnUNet_preprocessed'] = pp_dir #os.path.join(mainT_dir, 'preprocessed')\n",
    "os.environ['RESULTS_FOLDER'] = model_dir #os.path.join(main_dir, 'nnUNet_trained_models')\n",
    "\n",
    "\n",
    "print('Setting Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating \"Task55_PETCT\" Image & Label ..\n",
      "\"Task55_PETCT\" Image & Label Completed !!\n",
      "Image Patient : 80\n"
     ]
    }
   ],
   "source": [
    "def hdf2nifti(hdf_folder: str, save_folder: str):\n",
    "    # hdf_folder : [train_dir, test_dir] hdf5 file path\n",
    "    # save_folder : [imagesTr, imagesTs] Save Folder path\n",
    "    maybe_mkdir_p(os.path.join(save_folder, 'imagesTr'))\n",
    "    maybe_mkdir_p(os.path.join(save_folder, 'labelsTr'))\n",
    "    print('Creating \"{}\" Image & Label ..'.format(os.path.basename(os.path.normpath(save_folder))))\n",
    "    hdf5_files = os.listdir(hdf_folder)\n",
    "\n",
    "\n",
    "    for hdf5_file in hdf5_files:\n",
    "\n",
    "\n",
    "        hdf5_path = os.path.join(hdf_folder, hdf5_file)\n",
    "\n",
    "        # image\n",
    "        f_i = h5py.File(hdf5_path, 'r')\n",
    "        ctarr = np.asarray(f_i['CT'])\n",
    "        petarr = np.asarray(f_i['PET'])\n",
    "        labels = np.asarray(f_i['Aorta'])\n",
    "        f_i.close()\n",
    "\n",
    "        SLICE_SIZE_X, SLICE_SIZE_Y, SLICE_COUNT = ctarr.shape\n",
    "        images = np.empty([SLICE_SIZE_X, SLICE_SIZE_Y, SLICE_COUNT, 0], dtype=np.single)\n",
    "\n",
    "        image_ct = np.expand_dims(ctarr, axis=3)\n",
    "        images = np.append(images, image_ct, axis=3)\n",
    "        image_pet = np.expand_dims(petarr, axis=3)\n",
    "        images = np.append(images, image_pet, axis=3)\n",
    "\n",
    "\n",
    "        hdf5_file_NAME = hdf5_file\n",
    "\n",
    "        niim = nib.Nifti1Image(images, affine=np.eye(4))\n",
    "        nib.save(niim, os.path.join(save_folder, 'imagesTr/{}.nii.gz'.format(hdf5_file[:-8])))\n",
    "\n",
    "        nila = nib.Nifti1Image(labels, affine=np.eye(4))\n",
    "        nib.save(nila, os.path.join(save_folder, 'labelsTr/{}.nii.gz'.format(hdf5_file[:-8])))\n",
    "\n",
    "\n",
    "    print('\"{}\" Image & Label Completed !!'.format(os.path.basename(os.path.normpath(save_folder))))\n",
    "    print('Image Patient : {}'.format(len(os.listdir(input_dir))))\n",
    "\n",
    "hdf2nifti(input_dir, task_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/temp/nnUNet/nnunet/Tasks/Task55_PETCT'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json created!\n"
     ]
    }
   ],
   "source": [
    "def json_mk(save_dir: str):\n",
    "    # Path\n",
    "    imagesTr = os.path.join(save_dir, 'imagesTr')\n",
    "    imagesTs = os.path.join(save_dir, 'imagesTs')\n",
    "    maybe_mkdir_p(imagesTr)\n",
    "    maybe_mkdir_p(imagesTs)\n",
    "\n",
    "    overwrite_json_file = True\n",
    "    json_file_exist = False\n",
    "\n",
    "    if os.path.exists(os.path.join(save_dir, 'dataset.json')):\n",
    "        print('dataset.json already exist!')\n",
    "        json_file_exist = True\n",
    "\n",
    "    if json_file_exist == False or overwrite_json_file:\n",
    "\n",
    "        json_dict = OrderedDict()\n",
    "        json_dict['name'] = \"PETCT\"\n",
    "        json_dict['description'] = \"Medical Image AI Challenge 2021\"\n",
    "        json_dict['tensorImageSize'] = \"4D\"\n",
    "        json_dict['reference'] = \"https://maic.or.kr/competitions/\"\n",
    "        json_dict['licence'] = \"SNUH\"\n",
    "        json_dict['release'] = \"18/10/2021\"\n",
    "\n",
    "        json_dict['modality'] = {\n",
    "            \"0\": \"CT\",\n",
    "            \"1\": \"PET\"\n",
    "        }\n",
    "        json_dict['labels'] = {\n",
    "            \"0\": \"background\",\n",
    "            \"1\": \"Aorta\"\n",
    "        }\n",
    "\n",
    "        train_ids = sorted(os.listdir(imagesTr))\n",
    "        test_ids = sorted(os.listdir(imagesTs))\n",
    "        json_dict['numTraining'] = len(train_ids)\n",
    "        json_dict['numTest'] = len(test_ids)\n",
    "\n",
    "        json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "        json_dict['test'] = [\"./imagesTs/%s\" % i for i in test_ids] #(i[:i.find(\"_0000\")])\n",
    "\n",
    "        with open(os.path.join(save_dir, \"dataset.json\"), 'w') as f:\n",
    "            json.dump(json_dict, f, indent=4, sort_keys=False)\n",
    "\n",
    "        if os.path.exists(os.path.join(save_dir, 'dataset.json')):\n",
    "            if json_file_exist == False:\n",
    "                print('dataset.json created!')\n",
    "            else:\n",
    "                print('dataset.json overwritten!')\n",
    "json_mk(task_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-2. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "23090557_20130\n",
      "23090560_20160\n",
      "23090563_20151\n",
      "23090567_20160\n",
      "23090571_20120\n",
      "23090579_20141\n",
      "23090585_20130\n",
      "23090582_20150\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090558_20120\n",
      "23090572_20130\n",
      "23090564_20130\n",
      "23090583_20160\n",
      "23090561_20120\n",
      "23090580_20131\n",
      "23090568_20121\n",
      "23090586_20120\n",
      "before crop: (2, 263, 128, 128) after crop: (2, 263, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090559_20150\n",
      "23090566_20141\n",
      "23090578_20120\n",
      "23090562_20140\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090587_20150\n",
      "23090584_20120\n",
      "23090581_20130\n",
      "23090569_20120\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090588_20131\n",
      "23090591_20140\n",
      "23090594_20160\n",
      "23090597_20130\n",
      "23090600_20121\n",
      "23090604_20140\n",
      "23090608_20120\n",
      "23090611_20150\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090592_20130\n",
      "23090589_20140\n",
      "23090598_20130\n",
      "23090595_20121\n",
      "23090606_20120\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090601_20130\n",
      "23090612_20121\n",
      "23090609_20120\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090593_20120\n",
      "23090596_20150\n",
      "23090607_20120\n",
      "23090599_20140\n",
      "23090590_20121\n",
      "23090603_20141\n",
      "23090613_20130\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090610_20151\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090614_20120\n",
      "23090617_20140\n",
      "23090620_20130\n",
      "23090623_20120\n",
      "23090627_20160\n",
      "23090630_20130\n",
      "23090633_20120\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090636_20121\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090625_20160\n",
      "23090615_20140\n",
      "23090621_20130\n",
      "23090618_20161\n",
      "23090628_20150\n",
      "23090631_20130\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090634_20150\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090637_20140\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090622_20150\n",
      "23090626_20160\n",
      "23090616_20140\n",
      "23090619_20121\n",
      "23090629_20120\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090635_20140\n",
      "23090632_20130\n",
      "23090638_20131\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090639_20150\n",
      "23090642_20130\n",
      "23090645_20141\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090646_20120\n",
      "23090640_20140\n",
      "23090643_20121\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "23090641_20160\n",
      "23090644_20131\n",
      "before crop: (2, 299, 128, 128) after crop: (2, 299, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 335, 128, 128) after crop: (2, 335, 128, 128) spacing: [1. 1. 1.] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Task555_PETCT\n",
      "number of threads:  (8, 8) \n",
      "\n",
      "not using nonzero mask for normalization\n",
      "Are we using the nonzero mask for normalizaion? OrderedDict([(0, False), (1, False)])\n",
      "the median shape of the dataset is  [299. 128. 128.]\n",
      "the max shape in the dataset is  [335. 128. 128.]\n",
      "the min shape in the dataset is  [263. 128. 128.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [299. 128. 128.]\n",
      "generating configuration for 3d_fullres\n",
      "{0: {'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}}\n",
      "transpose forward [0, 1, 2]\n",
      "transpose backward [0, 1, 2]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /mnt/temp/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_cropped_data/Task555_PETCT\n",
      "output_folder: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after: no resampling necessary\n",
      " {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1523\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090557_20130.npz\n",
      "1 1576\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090571_20120.npz\n",
      "1 2130\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090567_20160.npz\n",
      "1 3800\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090560_20160.npz\n",
      "1 2186\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090579_20141.npz\n",
      "1 2148\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090563_20151.npz\n",
      "1 2179\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090582_20150.npz\n",
      "1 3219\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090585_20130.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 263, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 263, 128, 128)} \n",
      "\n",
      "1 1998\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090558_20120.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2276\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090572_20130.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2259\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090561_20120.npz\n",
      "1 1764\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090564_20130.npz\n",
      "1 1980\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090586_20120.npz\n",
      "1 2405\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090568_20121.npz\n",
      "1 2223\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090583_20160.npz\n",
      "1 1977\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090580_20131.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3121\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090559_20150.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2753\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090578_20120.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2047\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090562_20140.npz\n",
      "1 2088\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090566_20141.npz\n",
      "1 2658\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090587_20150.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2928\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090584_20120.npz\n",
      "1 1188\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090581_20130.npz\n",
      "1 2170\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090569_20120.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2343\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090588_20131.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2175\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090591_20140.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2660\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090597_20130.npz\n",
      "1 3501\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090594_20160.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1603\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090604_20140.npz\n",
      "1 2381\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090600_20121.npz\n",
      "1 2943\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090608_20120.npz\n",
      "1 2569\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090611_20150.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2846\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090592_20130.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2579\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090589_20140.npz\n",
      "1 1630\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090598_20130.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1422\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090595_20121.npz\n",
      "1 2286\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090606_20120.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1385\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090601_20130.npz\n",
      "1 1721\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090612_20121.npz\n",
      "1 1909\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090609_20120.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1803\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090599_20140.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2888\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090593_20120.npz\n",
      "1 2867\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090596_20150.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1770\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090607_20120.npz\n",
      "1 3163\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090590_20121.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2984\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090603_20141.npz\n",
      "1 1447\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090613_20130.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3219\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090610_20151.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3220\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090614_20120.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2589\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090617_20140.npz\n",
      "1 1998\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090620_20130.npz\n",
      "1 2773\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090623_20120.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2354\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090627_20160.npz\n",
      "1 1982\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090630_20130.npz\n",
      "1 2765\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090633_20120.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1903\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090636_20121.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3091\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090615_20140.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1863\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090625_20160.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3187\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090621_20130.npz\n",
      "1 2934\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090618_20161.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2933\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090628_20150.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1586\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090634_20150.npz\n",
      "1 2146\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090631_20130.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1531\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090637_20140.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1799\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090622_20150.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3021\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090616_20140.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 3654\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090626_20160.npz\n",
      "1 1009\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090619_20121.npz\n",
      "1 2319\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090635_20140.npz\n",
      "1 2314\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090629_20120.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2730\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090638_20131.npz\n",
      "1 1693\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090632_20130.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 2119\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090639_20150.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1259\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090642_20130.npz\n",
      "1 1918\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090645_20141.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1909\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090640_20140.npz\n",
      "1 4845\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090643_20121.npz\n",
      "1 2258\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090646_20120.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 1377\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090641_20160.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1635\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_stage0/23090644_20131.npz\n",
      "not using nonzero mask for normalization\n",
      "Are we using the nonzero maks for normalizaion? OrderedDict([(0, False), (1, False)])\n",
      "the median shape of the dataset is  [299. 128. 128.]\n",
      "the max shape in the dataset is  [335. 128. 128.]\n",
      "the min shape in the dataset is  [263. 128. 128.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [299. 128. 128.]\n",
      "[{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /mnt/temp/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_cropped_data/Task555_PETCT\n",
      "output_folder: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "1 1523\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090557_20130.npz\n",
      "normalization done\n",
      "normalization done\n",
      "1 1576\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090571_20120.npz\n",
      "normalization done\n",
      "1 2130\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090567_20160.npz\n",
      "normalization done\n",
      "1 2186\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090579_20141.npz\n",
      "1 3800\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090560_20160.npz\n",
      "1 2148\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090563_20151.npz\n",
      "1 2179\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090582_20150.npz\n",
      "1 3219\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090585_20130.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 263, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 263, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1998\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090558_20120.npz\n",
      "normalization...\n",
      "normalization done\n",
      "1 2276\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090572_20130.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 1764\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090564_20130.npz\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "1 2405\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090568_20121.npz\n",
      "1 2223\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090583_20160.npz\n",
      "1 1977\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090580_20131.npz\n",
      "1 1980\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090586_20120.npz\n",
      "1 2259\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090561_20120.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 3121\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090559_20150.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 2753\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090578_20120.npz\n",
      "1 2088\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090566_20141.npz\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2047\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090562_20140.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after: normalization done\n",
      " {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 2658\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090587_20150.npz\n",
      "normalization done\n",
      "1 2170\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090569_20120.npz\n",
      "normalization done\n",
      "1 2928\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090584_20120.npz\n",
      "1 1188\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090581_20130.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2343\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090588_20131.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 2175\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090591_20140.npz\n",
      "normalization done\n",
      "normalization done\n",
      "1 3501\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090594_20160.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 2660\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090597_20130.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 2381\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090600_20121.npz\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "1 2943\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090608_20120.npz\n",
      "1 1603\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090604_20140.npz\n",
      "1 2569\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090611_20150.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 2846\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090592_20130.npz\n",
      "1 2579\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090589_20140.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 1630\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090598_20130.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1422\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090595_20121.npz\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 2286\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090606_20120.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1385\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090601_20130.npz\n",
      "normalization done\n",
      "normalization done\n",
      "1 1721\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090612_20121.npz\n",
      "1 1909\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090609_20120.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2888\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090593_20120.npz\n",
      "normalization done\n",
      "1 1803\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090599_20140.npz\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 2867\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090596_20150.npz\n",
      "1 3163\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090590_20121.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 1770\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090607_20120.npz\n",
      "normalization done\n",
      "normalization done\n",
      "1 2984\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090603_20141.npz\n",
      "1 1447\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090613_20130.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 3219\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090610_20151.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 3220\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090614_20120.npz\n",
      "1 2589\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090617_20140.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "1 1998\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090620_20130.npz\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2773\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090623_20120.npz\n",
      "normalization done\n",
      "normalization done\n",
      "1 1982\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090630_20130.npz\n",
      "1 2354\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090627_20160.npz\n",
      "1 2765\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090633_20120.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1903\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090636_20121.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 3091\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090615_20140.npz\n",
      "1 2934\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090618_20161.npz\n",
      "normalization done\n",
      "1 1863\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090625_20160.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 3187\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090621_20130.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "1 2146\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090631_20130.npz\n",
      "1 2933\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090628_20150.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 1586\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090634_20150.npz\n",
      "normalization done\n",
      "1 1531\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090637_20140.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization done\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 1799\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090622_20150.npz\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 1009\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090619_20121.npz\n",
      "1 3021\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090616_20140.npz\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "1 3654\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090626_20160.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2319\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090635_20140.npz\n",
      "normalization done\n",
      "normalization done\n",
      "1 1693\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090632_20130.npz\n",
      "1 2314\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090629_20120.npz\n",
      "1 2730\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090638_20131.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "1 2119\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090639_20150.npz\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 1259\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090642_20130.npz\n",
      "1 1918\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090645_20141.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "1 4845\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090643_20121.npz\n",
      "1 2258\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090646_20120.npz\n",
      "1 1909\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090640_20140.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 299, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 299, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1377\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090641_20160.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 335, 128, 128)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 335, 128, 128)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1635\n",
      "saving:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D_stage0/23090644_20131.npz\n"
     ]
    }
   ],
   "source": [
    "os.chdir(mainT_dir)\n",
    "!nnUNet_convert_decathlon_task -i /mnt/temp/nnUNet/nnunet/Tasks/Task55_PETCT -output_task_id 555 # -i : task_dir\n",
    "!nnUNet_plan_and_preprocess -t 555 # --verify_dataset_integrity\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-27 16:15:17.554927: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-27 16:15:46.888453: Unable to plot network architecture:\n",
      "2021-10-27 16:15:46.996411: No module named 'hiddenlayer'\n",
      "2021-10-27 16:15:47.096315: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-27 16:15:47.180416: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-27 16:15:47.433523: \n",
      "\n",
      "2021-10-27 16:15:47.500475: \n",
      "epoch:  0\n",
      "2021-10-27 16:18:59.718543: train loss : -0.2210\n",
      "2021-10-27 16:19:13.865317: validation loss: -0.6623\n",
      "2021-10-27 16:19:13.869488: Average global foreground Dice: [0.6989]\n",
      "2021-10-27 16:19:13.875212: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:19:14.290968: lr: 0.00991\n",
      "2021-10-27 16:19:14.324789: This epoch took 206.756409 s\n",
      "\n",
      "2021-10-27 16:19:14.331478: \n",
      "epoch:  1\n",
      "2021-10-27 16:22:26.081245: train loss : -0.6986\n",
      "2021-10-27 16:22:40.195020: validation loss: -0.7923\n",
      "2021-10-27 16:22:40.199469: Average global foreground Dice: [0.8137]\n",
      "2021-10-27 16:22:40.206626: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:22:40.716233: lr: 0.00982\n",
      "2021-10-27 16:22:40.813947: saving checkpoint...\n",
      "2021-10-27 16:22:41.789972: done, saving took 1.04 seconds\n",
      "2021-10-27 16:22:42.018425: This epoch took 207.678639 s\n",
      "\n",
      "2021-10-27 16:22:42.040115: \n",
      "epoch:  2\n",
      "2021-10-27 16:25:49.402736: train loss : -0.7691\n",
      "2021-10-27 16:26:03.426464: validation loss: -0.8225\n",
      "2021-10-27 16:26:03.430629: Average global foreground Dice: [0.8376]\n",
      "2021-10-27 16:26:03.437733: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:26:03.993473: lr: 0.00973\n",
      "2021-10-27 16:26:04.050973: saving checkpoint...\n",
      "2021-10-27 16:26:05.266915: done, saving took 1.24 seconds\n",
      "2021-10-27 16:26:05.667787: This epoch took 203.621566 s\n",
      "\n",
      "2021-10-27 16:26:05.686312: \n",
      "epoch:  3\n",
      "2021-10-27 16:29:17.119637: train loss : -0.7936\n",
      "2021-10-27 16:29:31.347813: validation loss: -0.8237\n",
      "2021-10-27 16:29:31.352603: Average global foreground Dice: [0.8371]\n",
      "2021-10-27 16:29:31.358892: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:29:31.914852: lr: 0.009639\n",
      "2021-10-27 16:29:31.952582: saving checkpoint...\n",
      "2021-10-27 16:29:33.100416: done, saving took 1.17 seconds\n",
      "2021-10-27 16:29:33.536399: This epoch took 207.844127 s\n",
      "\n",
      "2021-10-27 16:29:33.545092: \n",
      "epoch:  4\n",
      "2021-10-27 16:32:40.637586: train loss : -0.8058\n",
      "2021-10-27 16:32:54.676850: validation loss: -0.8346\n",
      "2021-10-27 16:32:54.681857: Average global foreground Dice: [0.8465]\n",
      "2021-10-27 16:32:54.689617: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:32:55.202167: lr: 0.009549\n",
      "2021-10-27 16:32:55.268535: saving checkpoint...\n",
      "2021-10-27 16:32:56.365358: done, saving took 1.13 seconds\n",
      "2021-10-27 16:32:56.859082: This epoch took 203.307810 s\n",
      "\n",
      "2021-10-27 16:32:56.873139: \n",
      "epoch:  5\n",
      "2021-10-27 16:36:07.219622: train loss : -0.8164\n",
      "2021-10-27 16:36:21.428898: validation loss: -0.8439\n",
      "2021-10-27 16:36:21.432943: Average global foreground Dice: [0.8531]\n",
      "2021-10-27 16:36:21.439554: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:36:21.945920: lr: 0.009458\n",
      "2021-10-27 16:36:22.013656: saving checkpoint...\n",
      "2021-10-27 16:36:23.335724: done, saving took 1.36 seconds\n",
      "2021-10-27 16:36:23.600338: This epoch took 206.720120 s\n",
      "\n",
      "2021-10-27 16:36:23.619381: \n",
      "epoch:  6\n",
      "2021-10-27 16:39:33.962859: train loss : -0.8223\n",
      "2021-10-27 16:39:48.168229: validation loss: -0.8499\n",
      "2021-10-27 16:39:48.172292: Average global foreground Dice: [0.8601]\n",
      "2021-10-27 16:39:48.179092: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:39:48.670321: lr: 0.009368\n",
      "2021-10-27 16:39:48.717124: saving checkpoint...\n",
      "2021-10-27 16:39:49.922694: done, saving took 1.22 seconds\n",
      "2021-10-27 16:39:50.259526: This epoch took 206.633933 s\n",
      "\n",
      "2021-10-27 16:39:50.281845: \n",
      "epoch:  7\n",
      "2021-10-27 16:43:00.683633: train loss : -0.8278\n",
      "2021-10-27 16:43:14.904088: validation loss: -0.8525\n",
      "2021-10-27 16:43:14.908590: Average global foreground Dice: [0.8616]\n",
      "2021-10-27 16:43:14.914384: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:43:15.466205: lr: 0.009277\n",
      "2021-10-27 16:43:15.516546: saving checkpoint...\n",
      "2021-10-27 16:43:16.601164: done, saving took 1.10 seconds\n",
      "2021-10-27 16:43:17.324125: This epoch took 207.035653 s\n",
      "\n",
      "2021-10-27 16:43:17.341800: \n",
      "epoch:  8\n",
      "2021-10-27 16:46:29.139361: train loss : -0.8330\n",
      "2021-10-27 16:46:43.344243: validation loss: -0.8549\n",
      "2021-10-27 16:46:43.348664: Average global foreground Dice: [0.8632]\n",
      "2021-10-27 16:46:43.356322: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:46:43.890189: lr: 0.009186\n",
      "2021-10-27 16:46:43.958172: saving checkpoint...\n",
      "2021-10-27 16:46:45.078849: done, saving took 1.16 seconds\n",
      "2021-10-27 16:46:45.430456: This epoch took 208.082009 s\n",
      "\n",
      "2021-10-27 16:46:45.450783: \n",
      "epoch:  9\n",
      "2021-10-27 16:49:56.594596: train loss : -0.8338\n",
      "2021-10-27 16:50:10.816225: validation loss: -0.8592\n",
      "2021-10-27 16:50:10.820862: Average global foreground Dice: [0.8679]\n",
      "2021-10-27 16:50:10.827181: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:50:11.329562: lr: 0.009095\n",
      "2021-10-27 16:50:11.388503: saving checkpoint...\n",
      "2021-10-27 16:50:12.543743: done, saving took 1.18 seconds\n",
      "2021-10-27 16:50:12.991771: This epoch took 207.534300 s\n",
      "\n",
      "2021-10-27 16:50:13.011533: \n",
      "epoch:  10\n",
      "2021-10-27 16:53:24.052798: train loss : -0.8393\n",
      "2021-10-27 16:53:38.278238: validation loss: -0.8622\n",
      "2021-10-27 16:53:38.282418: Average global foreground Dice: [0.8702]\n",
      "2021-10-27 16:53:38.289221: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:53:38.861925: lr: 0.009004\n",
      "2021-10-27 16:53:38.914918: saving checkpoint...\n",
      "2021-10-27 16:53:40.158682: done, saving took 1.27 seconds\n",
      "2021-10-27 16:53:40.529228: This epoch took 207.510832 s\n",
      "\n",
      "2021-10-27 16:53:40.549043: \n",
      "epoch:  11\n",
      "2021-10-27 16:56:51.992955: train loss : -0.8421\n",
      "2021-10-27 16:57:06.237341: validation loss: -0.8658\n",
      "2021-10-27 16:57:06.241754: Average global foreground Dice: [0.8725]\n",
      "2021-10-27 16:57:06.248301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 16:57:06.745189: lr: 0.008913\n",
      "2021-10-27 16:57:06.802613: saving checkpoint...\n",
      "2021-10-27 16:57:07.909294: done, saving took 1.13 seconds\n",
      "2021-10-27 16:57:08.315907: This epoch took 207.760675 s\n",
      "\n",
      "2021-10-27 16:57:08.334923: \n",
      "epoch:  12\n",
      "2021-10-27 17:00:19.878735: train loss : -0.8436\n",
      "2021-10-27 17:00:34.112004: validation loss: -0.8659\n",
      "2021-10-27 17:00:34.116223: Average global foreground Dice: [0.873]\n",
      "2021-10-27 17:00:34.122811: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:00:34.745908: lr: 0.008822\n",
      "2021-10-27 17:00:34.800883: saving checkpoint...\n",
      "2021-10-27 17:00:35.876860: done, saving took 1.10 seconds\n",
      "2021-10-27 17:00:36.182032: This epoch took 207.840477 s\n",
      "\n",
      "2021-10-27 17:00:36.199789: \n",
      "epoch:  13\n",
      "2021-10-27 17:03:47.900950: train loss : -0.8470\n",
      "2021-10-27 17:04:02.136399: validation loss: -0.8681\n",
      "2021-10-27 17:04:02.140368: Average global foreground Dice: [0.8749]\n",
      "2021-10-27 17:04:02.146461: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:04:02.642723: lr: 0.008731\n",
      "2021-10-27 17:04:02.692363: saving checkpoint...\n",
      "2021-10-27 17:04:03.799992: done, saving took 1.13 seconds\n",
      "2021-10-27 17:04:04.042984: This epoch took 207.836482 s\n",
      "\n",
      "2021-10-27 17:04:04.061878: \n",
      "epoch:  14\n",
      "2021-10-27 17:07:15.883038: train loss : -0.8489\n",
      "2021-10-27 17:07:30.092684: validation loss: -0.8702\n",
      "2021-10-27 17:07:30.096931: Average global foreground Dice: [0.876]\n",
      "2021-10-27 17:07:30.103577: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:07:30.620436: lr: 0.008639\n",
      "2021-10-27 17:07:30.670778: saving checkpoint...\n",
      "2021-10-27 17:07:31.744756: done, saving took 1.09 seconds\n",
      "2021-10-27 17:07:32.188677: This epoch took 208.118920 s\n",
      "\n",
      "2021-10-27 17:07:32.206728: \n",
      "epoch:  15\n",
      "2021-10-27 17:10:43.528100: train loss : -0.8501\n",
      "2021-10-27 17:10:57.746241: validation loss: -0.8714\n",
      "2021-10-27 17:10:57.750674: Average global foreground Dice: [0.8778]\n",
      "2021-10-27 17:10:57.757516: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:10:58.267996: lr: 0.008548\n",
      "2021-10-27 17:10:58.320610: saving checkpoint...\n",
      "2021-10-27 17:10:59.454544: done, saving took 1.16 seconds\n",
      "2021-10-27 17:10:59.751400: This epoch took 207.538210 s\n",
      "\n",
      "2021-10-27 17:10:59.771410: \n",
      "epoch:  16\n",
      "2021-10-27 17:14:12.248561: train loss : -0.8525\n",
      "2021-10-27 17:14:26.456915: validation loss: -0.8768\n",
      "2021-10-27 17:14:26.461422: Average global foreground Dice: [0.8837]\n",
      "2021-10-27 17:14:26.467772: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:14:26.974939: lr: 0.008456\n",
      "2021-10-27 17:14:27.030425: saving checkpoint...\n",
      "2021-10-27 17:14:28.122860: done, saving took 1.11 seconds\n",
      "2021-10-27 17:14:28.513036: This epoch took 208.735487 s\n",
      "\n",
      "2021-10-27 17:14:28.531475: \n",
      "epoch:  17\n",
      "2021-10-27 17:17:41.022295: train loss : -0.8538\n",
      "2021-10-27 17:17:55.225448: validation loss: -0.8756\n",
      "2021-10-27 17:17:55.229394: Average global foreground Dice: [0.8796]\n",
      "2021-10-27 17:17:55.235512: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:17:55.751291: lr: 0.008364\n",
      "2021-10-27 17:17:55.788638: saving checkpoint...\n",
      "2021-10-27 17:17:56.872582: done, saving took 1.10 seconds\n",
      "2021-10-27 17:17:57.135095: This epoch took 208.596153 s\n",
      "\n",
      "2021-10-27 17:17:57.143217: \n",
      "epoch:  18\n",
      "2021-10-27 17:21:09.620421: train loss : -0.8564\n",
      "2021-10-27 17:21:23.855744: validation loss: -0.8798\n",
      "2021-10-27 17:21:23.860033: Average global foreground Dice: [0.886]\n",
      "2021-10-27 17:21:23.866910: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:21:24.378822: lr: 0.008272\n",
      "2021-10-27 17:21:24.416566: saving checkpoint...\n",
      "2021-10-27 17:21:25.514822: done, saving took 1.12 seconds\n",
      "2021-10-27 17:21:26.108468: This epoch took 208.957060 s\n",
      "\n",
      "2021-10-27 17:21:26.116536: \n",
      "epoch:  19\n",
      "2021-10-27 17:24:38.613017: train loss : -0.8581\n",
      "2021-10-27 17:24:52.819587: validation loss: -0.8806\n",
      "2021-10-27 17:24:52.824164: Average global foreground Dice: [0.8861]\n",
      "2021-10-27 17:24:52.831293: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:24:53.333785: lr: 0.008181\n",
      "2021-10-27 17:24:53.374055: saving checkpoint...\n",
      "2021-10-27 17:24:54.463508: done, saving took 1.11 seconds\n",
      "2021-10-27 17:24:54.913401: This epoch took 208.791076 s\n",
      "\n",
      "2021-10-27 17:24:54.923956: \n",
      "epoch:  20\n",
      "2021-10-27 17:28:07.361281: train loss : -0.8594\n",
      "2021-10-27 17:28:21.570464: validation loss: -0.8845\n",
      "2021-10-27 17:28:21.574740: Average global foreground Dice: [0.8893]\n",
      "2021-10-27 17:28:21.582563: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:28:22.124996: lr: 0.008088\n",
      "2021-10-27 17:28:22.162406: saving checkpoint...\n",
      "2021-10-27 17:28:23.244981: done, saving took 1.10 seconds\n",
      "2021-10-27 17:28:23.610828: This epoch took 208.679771 s\n",
      "\n",
      "2021-10-27 17:28:23.618555: \n",
      "epoch:  21\n",
      "2021-10-27 17:31:36.052924: train loss : -0.8613\n",
      "2021-10-27 17:31:50.264493: validation loss: -0.8844\n",
      "2021-10-27 17:31:50.268931: Average global foreground Dice: [0.8881]\n",
      "2021-10-27 17:31:50.275697: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:31:50.883229: lr: 0.007996\n",
      "2021-10-27 17:31:50.921509: saving checkpoint...\n",
      "2021-10-27 17:31:52.003817: done, saving took 1.10 seconds\n",
      "2021-10-27 17:31:52.359109: This epoch took 208.733335 s\n",
      "\n",
      "2021-10-27 17:31:52.367161: \n",
      "epoch:  22\n",
      "2021-10-27 17:35:04.841682: train loss : -0.8618\n",
      "2021-10-27 17:35:19.053703: validation loss: -0.8864\n",
      "2021-10-27 17:35:19.057836: Average global foreground Dice: [0.8905]\n",
      "2021-10-27 17:35:19.063690: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:35:19.579424: lr: 0.007904\n",
      "2021-10-27 17:35:19.620622: saving checkpoint...\n",
      "2021-10-27 17:35:20.759770: done, saving took 1.16 seconds\n",
      "2021-10-27 17:35:21.295731: This epoch took 208.921829 s\n",
      "\n",
      "2021-10-27 17:35:21.304954: \n",
      "epoch:  23\n",
      "2021-10-27 17:38:33.417630: train loss : -0.8627\n",
      "2021-10-27 17:38:47.645205: validation loss: -0.8861\n",
      "2021-10-27 17:38:47.649923: Average global foreground Dice: [0.8907]\n",
      "2021-10-27 17:38:47.656332: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:38:48.159803: lr: 0.007811\n",
      "2021-10-27 17:38:48.196627: saving checkpoint...\n",
      "2021-10-27 17:38:49.289126: done, saving took 1.11 seconds\n",
      "2021-10-27 17:38:49.585298: This epoch took 208.273760 s\n",
      "\n",
      "2021-10-27 17:38:49.593639: \n",
      "epoch:  24\n",
      "2021-10-27 17:42:02.324453: train loss : -0.8633\n",
      "2021-10-27 17:42:16.552246: validation loss: -0.8878\n",
      "2021-10-27 17:42:16.556428: Average global foreground Dice: [0.8919]\n",
      "2021-10-27 17:42:16.563163: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:42:17.062274: lr: 0.007719\n",
      "2021-10-27 17:42:17.111444: saving checkpoint...\n",
      "2021-10-27 17:42:18.252469: done, saving took 1.17 seconds\n",
      "2021-10-27 17:42:18.549101: This epoch took 208.947923 s\n",
      "\n",
      "2021-10-27 17:42:18.558415: \n",
      "epoch:  25\n",
      "2021-10-27 17:45:31.293353: train loss : -0.8646\n",
      "2021-10-27 17:45:45.536252: validation loss: -0.8894\n",
      "2021-10-27 17:45:45.540864: Average global foreground Dice: [0.8924]\n",
      "2021-10-27 17:45:45.548082: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:45:46.073924: lr: 0.007626\n",
      "2021-10-27 17:45:46.112747: saving checkpoint...\n",
      "2021-10-27 17:45:47.201913: done, saving took 1.11 seconds\n",
      "2021-10-27 17:45:47.711458: This epoch took 209.145721 s\n",
      "\n",
      "2021-10-27 17:45:47.719983: \n",
      "epoch:  26\n",
      "2021-10-27 17:49:00.506113: train loss : -0.8654\n",
      "2021-10-27 17:49:14.730387: validation loss: -0.8881\n",
      "2021-10-27 17:49:14.734563: Average global foreground Dice: [0.892]\n",
      "2021-10-27 17:49:14.741678: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:49:15.296919: lr: 0.007533\n",
      "2021-10-27 17:49:15.333424: saving checkpoint...\n",
      "2021-10-27 17:49:16.457399: done, saving took 1.14 seconds\n",
      "2021-10-27 17:49:16.898577: This epoch took 209.171539 s\n",
      "\n",
      "2021-10-27 17:49:16.906759: \n",
      "epoch:  27\n",
      "2021-10-27 17:52:29.759110: train loss : -0.8672\n",
      "2021-10-27 17:52:43.966842: validation loss: -0.8923\n",
      "2021-10-27 17:52:43.971301: Average global foreground Dice: [0.8957]\n",
      "2021-10-27 17:52:43.977158: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:52:44.514082: lr: 0.00744\n",
      "2021-10-27 17:52:44.552968: saving checkpoint...\n",
      "2021-10-27 17:52:45.732203: done, saving took 1.20 seconds\n",
      "2021-10-27 17:52:46.166207: This epoch took 209.253330 s\n",
      "\n",
      "2021-10-27 17:52:46.174451: \n",
      "epoch:  28\n",
      "2021-10-27 17:55:59.100895: train loss : -0.8689\n",
      "2021-10-27 17:56:13.309849: validation loss: -0.8934\n",
      "2021-10-27 17:56:13.314962: Average global foreground Dice: [0.8964]\n",
      "2021-10-27 17:56:13.321711: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:56:13.816742: lr: 0.007347\n",
      "2021-10-27 17:56:13.855166: saving checkpoint...\n",
      "2021-10-27 17:56:14.939538: done, saving took 1.10 seconds\n",
      "2021-10-27 17:56:15.494885: This epoch took 209.313562 s\n",
      "\n",
      "2021-10-27 17:56:15.503253: \n",
      "epoch:  29\n",
      "2021-10-27 17:59:28.381236: train loss : -0.8701\n",
      "2021-10-27 17:59:42.599836: validation loss: -0.8949\n",
      "2021-10-27 17:59:42.604089: Average global foreground Dice: [0.8985]\n",
      "2021-10-27 17:59:42.613005: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 17:59:43.160082: lr: 0.007254\n",
      "2021-10-27 17:59:43.197030: saving checkpoint...\n",
      "2021-10-27 17:59:44.285800: done, saving took 1.11 seconds\n",
      "2021-10-27 17:59:44.504813: This epoch took 208.991896 s\n",
      "\n",
      "2021-10-27 17:59:44.513197: \n",
      "epoch:  30\n",
      "2021-10-27 18:02:57.393340: train loss : -0.8701\n",
      "2021-10-27 18:03:11.602970: validation loss: -0.8945\n",
      "2021-10-27 18:03:11.607172: Average global foreground Dice: [0.8979]\n",
      "2021-10-27 18:03:11.613240: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:03:12.181896: lr: 0.007161\n",
      "2021-10-27 18:03:12.220428: saving checkpoint...\n",
      "2021-10-27 18:03:13.383526: done, saving took 1.18 seconds\n",
      "2021-10-27 18:03:13.879991: This epoch took 209.360189 s\n",
      "\n",
      "2021-10-27 18:03:13.888570: \n",
      "epoch:  31\n",
      "2021-10-27 18:06:26.627889: train loss : -0.8706\n",
      "2021-10-27 18:06:40.843950: validation loss: -0.8942\n",
      "2021-10-27 18:06:40.848250: Average global foreground Dice: [0.8971]\n",
      "2021-10-27 18:06:40.855362: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:06:41.351729: lr: 0.007067\n",
      "2021-10-27 18:06:41.392221: saving checkpoint...\n",
      "2021-10-27 18:06:42.476691: done, saving took 1.10 seconds\n",
      "2021-10-27 18:06:42.946102: This epoch took 209.050401 s\n",
      "\n",
      "2021-10-27 18:06:42.953912: \n",
      "epoch:  32\n",
      "2021-10-27 18:09:55.916393: train loss : -0.8729\n",
      "2021-10-27 18:10:10.132735: validation loss: -0.9004\n",
      "2021-10-27 18:10:10.136760: Average global foreground Dice: [0.9026]\n",
      "2021-10-27 18:10:10.143046: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:10:10.661268: lr: 0.006974\n",
      "2021-10-27 18:10:10.710543: saving checkpoint...\n",
      "2021-10-27 18:10:11.770903: done, saving took 1.08 seconds\n",
      "2021-10-27 18:10:12.288792: This epoch took 209.321669 s\n",
      "\n",
      "2021-10-27 18:10:12.306394: \n",
      "epoch:  33\n",
      "2021-10-27 18:13:25.415457: train loss : -0.8752\n",
      "2021-10-27 18:13:39.631616: validation loss: -0.8955\n",
      "2021-10-27 18:13:39.635985: Average global foreground Dice: [0.8974]\n",
      "2021-10-27 18:13:39.643288: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:13:40.224740: lr: 0.00688\n",
      "2021-10-27 18:13:40.271913: saving checkpoint...\n",
      "2021-10-27 18:13:41.453340: done, saving took 1.20 seconds\n",
      "2021-10-27 18:13:42.022172: This epoch took 209.708516 s\n",
      "\n",
      "2021-10-27 18:13:42.041297: \n",
      "epoch:  34\n",
      "2021-10-27 18:16:55.281148: train loss : -0.8749\n",
      "2021-10-27 18:17:09.510006: validation loss: -0.8993\n",
      "2021-10-27 18:17:09.514738: Average global foreground Dice: [0.9015]\n",
      "2021-10-27 18:17:09.520659: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:17:10.058416: lr: 0.006786\n",
      "2021-10-27 18:17:10.109918: saving checkpoint...\n",
      "2021-10-27 18:17:11.230133: done, saving took 1.14 seconds\n",
      "2021-10-27 18:17:11.738451: This epoch took 209.689980 s\n",
      "\n",
      "2021-10-27 18:17:11.757760: \n",
      "epoch:  35\n",
      "2021-10-27 18:20:25.081292: train loss : -0.8739\n",
      "2021-10-27 18:20:39.327822: validation loss: -0.8997\n",
      "2021-10-27 18:20:39.336111: Average global foreground Dice: [0.9019]\n",
      "2021-10-27 18:20:39.342218: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:20:39.839740: lr: 0.006692\n",
      "2021-10-27 18:20:39.883673: saving checkpoint...\n",
      "2021-10-27 18:20:41.011133: done, saving took 1.15 seconds\n",
      "2021-10-27 18:20:41.537440: This epoch took 209.769815 s\n",
      "\n",
      "2021-10-27 18:20:41.549886: \n",
      "epoch:  36\n",
      "2021-10-27 18:23:54.773245: train loss : -0.8765\n",
      "2021-10-27 18:24:09.003823: validation loss: -0.9023\n",
      "2021-10-27 18:24:09.007932: Average global foreground Dice: [0.9034]\n",
      "2021-10-27 18:24:09.014719: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:24:09.579808: lr: 0.006598\n",
      "2021-10-27 18:24:09.629672: saving checkpoint...\n",
      "2021-10-27 18:24:10.719901: done, saving took 1.11 seconds\n",
      "2021-10-27 18:24:11.162323: This epoch took 209.605477 s\n",
      "\n",
      "2021-10-27 18:24:11.178553: \n",
      "epoch:  37\n",
      "2021-10-27 18:27:24.297173: train loss : -0.8759\n",
      "2021-10-27 18:27:38.516657: validation loss: -0.9004\n",
      "2021-10-27 18:27:38.521299: Average global foreground Dice: [0.9026]\n",
      "2021-10-27 18:27:38.528165: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:27:39.068530: lr: 0.006504\n",
      "2021-10-27 18:27:39.115374: saving checkpoint...\n",
      "2021-10-27 18:27:40.201446: done, saving took 1.10 seconds\n",
      "2021-10-27 18:27:40.477253: This epoch took 209.290530 s\n",
      "\n",
      "2021-10-27 18:27:40.495629: \n",
      "epoch:  38\n",
      "2021-10-27 18:30:53.690677: train loss : -0.8772\n",
      "2021-10-27 18:31:07.903650: validation loss: -0.9033\n",
      "2021-10-27 18:31:07.907789: Average global foreground Dice: [0.9053]\n",
      "2021-10-27 18:31:07.914478: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:31:08.396436: lr: 0.006409\n",
      "2021-10-27 18:31:08.449460: saving checkpoint...\n",
      "2021-10-27 18:31:09.536963: done, saving took 1.11 seconds\n",
      "2021-10-27 18:31:10.005163: This epoch took 209.502626 s\n",
      "\n",
      "2021-10-27 18:31:10.022940: \n",
      "epoch:  39\n",
      "2021-10-27 18:34:23.134222: train loss : -0.8781\n",
      "2021-10-27 18:34:37.347618: validation loss: -0.9046\n",
      "2021-10-27 18:34:37.352507: Average global foreground Dice: [0.9059]\n",
      "2021-10-27 18:34:37.359176: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:34:37.892069: lr: 0.006314\n",
      "2021-10-27 18:34:37.942531: saving checkpoint...\n",
      "2021-10-27 18:34:39.045789: done, saving took 1.12 seconds\n",
      "2021-10-27 18:34:39.452251: This epoch took 209.422542 s\n",
      "\n",
      "2021-10-27 18:34:39.469736: \n",
      "epoch:  40\n",
      "2021-10-27 18:37:53.147609: train loss : -0.8793\n",
      "2021-10-27 18:38:07.369455: validation loss: -0.9037\n",
      "2021-10-27 18:38:07.373936: Average global foreground Dice: [0.904]\n",
      "2021-10-27 18:38:07.381395: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:38:07.874585: lr: 0.00622\n",
      "2021-10-27 18:38:07.923303: saving checkpoint...\n",
      "2021-10-27 18:38:09.006621: done, saving took 1.10 seconds\n",
      "2021-10-27 18:38:09.443952: This epoch took 209.967504 s\n",
      "\n",
      "2021-10-27 18:38:09.463562: \n",
      "epoch:  41\n",
      "2021-10-27 18:41:23.285274: train loss : -0.8806\n",
      "2021-10-27 18:41:37.499027: validation loss: -0.9021\n",
      "2021-10-27 18:41:37.503599: Average global foreground Dice: [0.9036]\n",
      "2021-10-27 18:41:37.509929: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:41:37.991693: lr: 0.006125\n",
      "2021-10-27 18:41:38.039450: saving checkpoint...\n",
      "2021-10-27 18:41:39.121900: done, saving took 1.10 seconds\n",
      "2021-10-27 18:41:39.510254: This epoch took 210.040017 s\n",
      "\n",
      "2021-10-27 18:41:39.527032: \n",
      "epoch:  42\n",
      "2021-10-27 18:44:53.345369: train loss : -0.8806\n",
      "2021-10-27 18:45:07.560451: validation loss: -0.9021\n",
      "2021-10-27 18:45:07.565123: Average global foreground Dice: [0.9035]\n",
      "2021-10-27 18:45:07.571889: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:45:08.117473: lr: 0.00603\n",
      "2021-10-27 18:45:08.172475: saving checkpoint...\n",
      "2021-10-27 18:45:09.286355: done, saving took 1.13 seconds\n",
      "2021-10-27 18:45:09.740690: This epoch took 210.206446 s\n",
      "\n",
      "2021-10-27 18:45:09.758028: \n",
      "epoch:  43\n",
      "2021-10-27 18:48:23.568766: train loss : -0.8824\n",
      "2021-10-27 18:48:37.791871: validation loss: -0.9069\n",
      "2021-10-27 18:48:37.796122: Average global foreground Dice: [0.9077]\n",
      "2021-10-27 18:48:37.802655: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:48:38.306463: lr: 0.005934\n",
      "2021-10-27 18:48:38.352660: saving checkpoint...\n",
      "2021-10-27 18:48:39.468688: done, saving took 1.14 seconds\n",
      "2021-10-27 18:48:39.933730: This epoch took 210.169208 s\n",
      "\n",
      "2021-10-27 18:48:39.952298: \n",
      "epoch:  44\n",
      "2021-10-27 18:51:53.849514: train loss : -0.8812\n",
      "2021-10-27 18:52:08.077659: validation loss: -0.9085\n",
      "2021-10-27 18:52:08.083382: Average global foreground Dice: [0.9103]\n",
      "2021-10-27 18:52:08.089809: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:52:08.584181: lr: 0.005839\n",
      "2021-10-27 18:52:08.630008: saving checkpoint...\n",
      "2021-10-27 18:52:09.726172: done, saving took 1.12 seconds\n",
      "2021-10-27 18:52:10.168128: This epoch took 210.209103 s\n",
      "\n",
      "2021-10-27 18:52:10.186176: \n",
      "epoch:  45\n",
      "2021-10-27 18:55:23.964481: train loss : -0.8824\n",
      "2021-10-27 18:55:38.217515: validation loss: -0.9085\n",
      "2021-10-27 18:55:38.222154: Average global foreground Dice: [0.9092]\n",
      "2021-10-27 18:55:38.229241: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:55:38.724879: lr: 0.005743\n",
      "2021-10-27 18:55:38.772058: saving checkpoint...\n",
      "2021-10-27 18:55:39.930874: done, saving took 1.18 seconds\n",
      "2021-10-27 18:55:40.313049: This epoch took 210.120921 s\n",
      "\n",
      "2021-10-27 18:55:40.334138: \n",
      "epoch:  46\n",
      "2021-10-27 18:58:53.999112: train loss : -0.8837\n",
      "2021-10-27 18:59:08.228720: validation loss: -0.9093\n",
      "2021-10-27 18:59:08.233006: Average global foreground Dice: [0.9103]\n",
      "2021-10-27 18:59:08.240121: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 18:59:08.789995: lr: 0.005647\n",
      "2021-10-27 18:59:08.845074: saving checkpoint...\n",
      "2021-10-27 18:59:09.946259: done, saving took 1.12 seconds\n",
      "2021-10-27 18:59:10.231436: This epoch took 209.890431 s\n",
      "\n",
      "2021-10-27 18:59:10.249202: \n",
      "epoch:  47\n",
      "2021-10-27 19:02:24.073480: train loss : -0.8836\n",
      "2021-10-27 19:02:38.293362: validation loss: -0.9106\n",
      "2021-10-27 19:02:38.297653: Average global foreground Dice: [0.9112]\n",
      "2021-10-27 19:02:38.303978: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:02:38.832428: lr: 0.005551\n",
      "2021-10-27 19:02:38.887215: saving checkpoint...\n",
      "2021-10-27 19:02:40.019033: done, saving took 1.15 seconds\n",
      "2021-10-27 19:02:40.540802: This epoch took 210.284503 s\n",
      "\n",
      "2021-10-27 19:02:40.561311: \n",
      "epoch:  48\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-27 19:05:54.003040: train loss : -0.8830\n",
      "2021-10-27 19:06:08.226439: validation loss: -0.9111\n",
      "2021-10-27 19:06:08.230642: Average global foreground Dice: [0.9116]\n",
      "2021-10-27 19:06:08.237617: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:06:08.816145: lr: 0.005455\n",
      "2021-10-27 19:06:08.868201: saving checkpoint...\n",
      "2021-10-27 19:06:10.074313: done, saving took 1.22 seconds\n",
      "2021-10-27 19:06:10.406582: This epoch took 209.838289 s\n",
      "\n",
      "2021-10-27 19:06:10.425955: \n",
      "epoch:  49\n",
      "2021-10-27 19:09:23.657384: train loss : -0.8843\n",
      "2021-10-27 19:09:37.865330: validation loss: -0.9113\n",
      "2021-10-27 19:09:37.870036: Average global foreground Dice: [0.9119]\n",
      "2021-10-27 19:09:37.876658: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:09:38.405019: lr: 0.005359\n",
      "2021-10-27 19:09:38.435755: saving scheduled checkpoint file...\n",
      "2021-10-27 19:09:38.461917: saving checkpoint...\n",
      "2021-10-27 19:09:39.409618: done, saving took 0.97 seconds\n",
      "2021-10-27 19:09:39.945523: done\n",
      "2021-10-27 19:09:39.986156: saving checkpoint...\n",
      "2021-10-27 19:09:41.103102: done, saving took 1.14 seconds\n",
      "2021-10-27 19:09:41.667199: This epoch took 211.234864 s\n",
      "\n",
      "2021-10-27 19:09:41.684789: \n",
      "epoch:  50\n",
      "2021-10-27 19:12:55.030789: train loss : -0.8847\n",
      "2021-10-27 19:13:09.244159: validation loss: -0.9129\n",
      "2021-10-27 19:13:09.248719: Average global foreground Dice: [0.9137]\n",
      "2021-10-27 19:13:09.255521: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:13:09.795948: lr: 0.005262\n",
      "2021-10-27 19:13:09.838286: saving checkpoint...\n",
      "2021-10-27 19:13:10.957539: done, saving took 1.14 seconds\n",
      "2021-10-27 19:13:11.391642: This epoch took 209.699962 s\n",
      "\n",
      "2021-10-27 19:13:11.405061: \n",
      "epoch:  51\n",
      "2021-10-27 19:16:24.703082: train loss : -0.8858\n",
      "2021-10-27 19:16:38.913828: validation loss: -0.9134\n",
      "2021-10-27 19:16:38.917996: Average global foreground Dice: [0.9134]\n",
      "2021-10-27 19:16:38.924697: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:16:39.467023: lr: 0.005166\n",
      "2021-10-27 19:16:39.517044: saving checkpoint...\n",
      "2021-10-27 19:16:40.584957: done, saving took 1.09 seconds\n",
      "2021-10-27 19:16:41.164922: This epoch took 209.752770 s\n",
      "\n",
      "2021-10-27 19:16:41.184223: \n",
      "epoch:  52\n",
      "2021-10-27 19:19:54.374327: train loss : -0.8857\n",
      "2021-10-27 19:20:08.583690: validation loss: -0.9123\n",
      "2021-10-27 19:20:08.588850: Average global foreground Dice: [0.9131]\n",
      "2021-10-27 19:20:08.596879: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:20:09.112903: lr: 0.005069\n",
      "2021-10-27 19:20:09.163153: saving checkpoint...\n",
      "2021-10-27 19:20:10.252950: done, saving took 1.11 seconds\n",
      "2021-10-27 19:20:10.526856: This epoch took 209.335903 s\n",
      "\n",
      "2021-10-27 19:20:10.546122: \n",
      "epoch:  53\n",
      "2021-10-27 19:23:23.773113: train loss : -0.8871\n",
      "2021-10-27 19:23:37.983027: validation loss: -0.9129\n",
      "2021-10-27 19:23:37.989635: Average global foreground Dice: [0.9134]\n",
      "2021-10-27 19:23:37.996375: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:23:38.484683: lr: 0.004971\n",
      "2021-10-27 19:23:38.535633: saving checkpoint...\n",
      "2021-10-27 19:23:39.625043: done, saving took 1.11 seconds\n",
      "2021-10-27 19:23:39.880332: This epoch took 209.326435 s\n",
      "\n",
      "2021-10-27 19:23:39.900689: \n",
      "epoch:  54\n",
      "2021-10-27 19:26:52.967294: train loss : -0.8879\n",
      "2021-10-27 19:27:07.209468: validation loss: -0.9158\n",
      "2021-10-27 19:27:07.213817: Average global foreground Dice: [0.9156]\n",
      "2021-10-27 19:27:07.222145: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:27:07.749857: lr: 0.004874\n",
      "2021-10-27 19:27:07.795798: saving checkpoint...\n",
      "2021-10-27 19:27:08.926045: done, saving took 1.15 seconds\n",
      "2021-10-27 19:27:09.242221: This epoch took 209.334017 s\n",
      "\n",
      "2021-10-27 19:27:09.260999: \n",
      "epoch:  55\n",
      "2021-10-27 19:30:22.423413: train loss : -0.8886\n",
      "2021-10-27 19:30:36.666178: validation loss: -0.9135\n",
      "2021-10-27 19:30:36.670454: Average global foreground Dice: [0.9141]\n",
      "2021-10-27 19:30:36.677383: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:30:37.207479: lr: 0.004776\n",
      "2021-10-27 19:30:37.255629: saving checkpoint...\n",
      "2021-10-27 19:30:38.345457: done, saving took 1.11 seconds\n",
      "2021-10-27 19:30:38.974070: This epoch took 209.705697 s\n",
      "\n",
      "2021-10-27 19:30:38.993410: \n",
      "epoch:  56\n",
      "2021-10-27 19:33:52.663529: train loss : -0.8894\n",
      "2021-10-27 19:34:06.905928: validation loss: -0.9143\n",
      "2021-10-27 19:34:06.910747: Average global foreground Dice: [0.9148]\n",
      "2021-10-27 19:34:06.917081: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:34:07.404546: lr: 0.004679\n",
      "2021-10-27 19:34:07.450116: saving checkpoint...\n",
      "2021-10-27 19:34:08.587927: done, saving took 1.16 seconds\n",
      "2021-10-27 19:34:09.074216: This epoch took 210.073930 s\n",
      "\n",
      "2021-10-27 19:34:09.094282: \n",
      "epoch:  57\n",
      "2021-10-27 19:37:22.901973: train loss : -0.8886\n",
      "2021-10-27 19:37:37.111795: validation loss: -0.9159\n",
      "2021-10-27 19:37:37.116528: Average global foreground Dice: [0.9165]\n",
      "2021-10-27 19:37:37.124284: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:37:37.714602: lr: 0.004581\n",
      "2021-10-27 19:37:37.765320: saving checkpoint...\n",
      "2021-10-27 19:37:38.875245: done, saving took 1.13 seconds\n",
      "2021-10-27 19:37:39.314889: This epoch took 210.213801 s\n",
      "\n",
      "2021-10-27 19:37:39.334868: \n",
      "epoch:  58\n",
      "2021-10-27 19:40:53.318713: train loss : -0.8898\n",
      "2021-10-27 19:41:07.532108: validation loss: -0.9168\n",
      "2021-10-27 19:41:07.536461: Average global foreground Dice: [0.917]\n",
      "2021-10-27 19:41:07.543389: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:41:08.042904: lr: 0.004482\n",
      "2021-10-27 19:41:08.094285: saving checkpoint...\n",
      "2021-10-27 19:41:09.186874: done, saving took 1.11 seconds\n",
      "2021-10-27 19:41:09.774178: This epoch took 210.432549 s\n",
      "\n",
      "2021-10-27 19:41:09.792928: \n",
      "epoch:  59\n",
      "2021-10-27 19:44:23.489713: train loss : -0.8902\n",
      "2021-10-27 19:44:37.704231: validation loss: -0.9129\n",
      "2021-10-27 19:44:37.709921: Average global foreground Dice: [0.913]\n",
      "2021-10-27 19:44:37.716452: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:44:38.211161: lr: 0.004384\n",
      "2021-10-27 19:44:38.251070: saving checkpoint...\n",
      "2021-10-27 19:44:39.337494: done, saving took 1.11 seconds\n",
      "2021-10-27 19:44:39.749732: This epoch took 209.949464 s\n",
      "\n",
      "2021-10-27 19:44:39.757981: \n",
      "epoch:  60\n",
      "2021-10-27 19:47:53.535278: train loss : -0.8913\n",
      "2021-10-27 19:48:07.759081: validation loss: -0.9164\n",
      "2021-10-27 19:48:07.763155: Average global foreground Dice: [0.9164]\n",
      "2021-10-27 19:48:07.769557: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:48:08.251485: lr: 0.004285\n",
      "2021-10-27 19:48:08.293824: saving checkpoint...\n",
      "2021-10-27 19:48:09.381947: done, saving took 1.11 seconds\n",
      "2021-10-27 19:48:09.852822: This epoch took 210.088605 s\n",
      "\n",
      "2021-10-27 19:48:09.861013: \n",
      "epoch:  61\n",
      "2021-10-27 19:51:23.790404: train loss : -0.8908\n",
      "2021-10-27 19:51:38.014508: validation loss: -0.9183\n",
      "2021-10-27 19:51:38.020443: Average global foreground Dice: [0.9179]\n",
      "2021-10-27 19:51:38.027904: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:51:38.514375: lr: 0.004186\n",
      "2021-10-27 19:51:38.554790: saving checkpoint...\n",
      "2021-10-27 19:51:39.651123: done, saving took 1.12 seconds\n",
      "2021-10-27 19:51:40.104480: This epoch took 210.236465 s\n",
      "\n",
      "2021-10-27 19:51:40.113657: \n",
      "epoch:  62\n",
      "2021-10-27 19:54:54.129905: train loss : -0.8919\n",
      "2021-10-27 19:55:08.347906: validation loss: -0.9191\n",
      "2021-10-27 19:55:08.352703: Average global foreground Dice: [0.9188]\n",
      "2021-10-27 19:55:08.360081: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:55:08.898398: lr: 0.004087\n",
      "2021-10-27 19:55:08.937012: saving checkpoint...\n",
      "2021-10-27 19:55:10.028582: done, saving took 1.11 seconds\n",
      "2021-10-27 19:55:10.322850: This epoch took 210.201872 s\n",
      "\n",
      "2021-10-27 19:55:10.331222: \n",
      "epoch:  63\n",
      "2021-10-27 19:58:24.244332: train loss : -0.8925\n",
      "2021-10-27 19:58:38.476549: validation loss: -0.9175\n",
      "2021-10-27 19:58:38.480878: Average global foreground Dice: [0.917]\n",
      "2021-10-27 19:58:38.488853: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 19:58:39.019267: lr: 0.003987\n",
      "2021-10-27 19:58:39.059770: saving checkpoint...\n",
      "2021-10-27 19:58:40.156377: done, saving took 1.12 seconds\n",
      "2021-10-27 19:58:40.578212: This epoch took 210.239975 s\n",
      "\n",
      "2021-10-27 19:58:40.586604: \n",
      "epoch:  64\n",
      "2021-10-27 20:01:54.344904: train loss : -0.8917\n",
      "2021-10-27 20:02:08.595672: validation loss: -0.9200\n",
      "2021-10-27 20:02:08.602630: Average global foreground Dice: [0.9192]\n",
      "2021-10-27 20:02:08.609382: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:02:09.142107: lr: 0.003887\n",
      "2021-10-27 20:02:09.180128: saving checkpoint...\n",
      "2021-10-27 20:02:10.296857: done, saving took 1.14 seconds\n",
      "2021-10-27 20:02:10.724901: This epoch took 210.131480 s\n",
      "\n",
      "2021-10-27 20:02:10.734387: \n",
      "epoch:  65\n",
      "2021-10-27 20:05:24.081175: train loss : -0.8938\n",
      "2021-10-27 20:05:38.308932: validation loss: -0.9217\n",
      "2021-10-27 20:05:38.313105: Average global foreground Dice: [0.9214]\n",
      "2021-10-27 20:05:38.319721: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:05:38.851503: lr: 0.003787\n",
      "2021-10-27 20:05:38.891527: saving checkpoint...\n",
      "2021-10-27 20:05:40.052271: done, saving took 1.18 seconds\n",
      "2021-10-27 20:05:40.542876: This epoch took 209.801040 s\n",
      "\n",
      "2021-10-27 20:05:40.550988: \n",
      "epoch:  66\n",
      "2021-10-27 20:08:53.911151: train loss : -0.8951\n",
      "2021-10-27 20:09:08.132201: validation loss: -0.9228\n",
      "2021-10-27 20:09:08.136538: Average global foreground Dice: [0.9219]\n",
      "2021-10-27 20:09:08.143013: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:09:08.654717: lr: 0.003687\n",
      "2021-10-27 20:09:08.695593: saving checkpoint...\n",
      "2021-10-27 20:09:09.782169: done, saving took 1.11 seconds\n",
      "2021-10-27 20:09:10.228943: This epoch took 209.671707 s\n",
      "\n",
      "2021-10-27 20:09:10.236654: \n",
      "epoch:  67\n",
      "2021-10-27 20:12:23.696460: train loss : -0.8948\n",
      "2021-10-27 20:12:37.917202: validation loss: -0.9222\n",
      "2021-10-27 20:12:37.922053: Average global foreground Dice: [0.9214]\n",
      "2021-10-27 20:12:37.929561: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:12:38.422100: lr: 0.003586\n",
      "2021-10-27 20:12:38.463353: saving checkpoint...\n",
      "2021-10-27 20:12:39.561992: done, saving took 1.12 seconds\n",
      "2021-10-27 20:12:39.953203: This epoch took 209.709893 s\n",
      "\n",
      "2021-10-27 20:12:39.961633: \n",
      "epoch:  68\n",
      "2021-10-27 20:15:53.221067: train loss : -0.8954\n",
      "2021-10-27 20:16:07.429568: validation loss: -0.9239\n",
      "2021-10-27 20:16:07.433751: Average global foreground Dice: [0.9232]\n",
      "2021-10-27 20:16:07.440206: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:16:07.969167: lr: 0.003485\n",
      "2021-10-27 20:16:08.030812: saving checkpoint...\n",
      "2021-10-27 20:16:09.153811: done, saving took 1.14 seconds\n",
      "2021-10-27 20:16:09.420716: This epoch took 209.452179 s\n",
      "\n",
      "2021-10-27 20:16:09.428357: \n",
      "epoch:  69\n",
      "2021-10-27 20:19:22.376887: train loss : -0.8964\n",
      "2021-10-27 20:19:36.589476: validation loss: -0.9234\n",
      "2021-10-27 20:19:36.593596: Average global foreground Dice: [0.9231]\n",
      "2021-10-27 20:19:36.599974: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:19:37.098011: lr: 0.003384\n",
      "2021-10-27 20:19:37.137971: saving checkpoint...\n",
      "2021-10-27 20:19:38.213141: done, saving took 1.09 seconds\n",
      "2021-10-27 20:19:38.626835: This epoch took 209.191838 s\n",
      "\n",
      "2021-10-27 20:19:38.634830: \n",
      "epoch:  70\n",
      "2021-10-27 20:22:51.480104: train loss : -0.8964\n",
      "2021-10-27 20:23:05.695925: validation loss: -0.9247\n",
      "2021-10-27 20:23:05.700474: Average global foreground Dice: [0.924]\n",
      "2021-10-27 20:23:05.706839: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:23:06.196258: lr: 0.003282\n",
      "2021-10-27 20:23:06.235288: saving checkpoint...\n",
      "2021-10-27 20:23:07.337533: done, saving took 1.12 seconds\n",
      "2021-10-27 20:23:07.988722: This epoch took 209.344851 s\n",
      "\n",
      "2021-10-27 20:23:07.996735: \n",
      "epoch:  71\n",
      "2021-10-27 20:26:20.829101: train loss : -0.8971\n",
      "2021-10-27 20:26:35.038158: validation loss: -0.9260\n",
      "2021-10-27 20:26:35.042964: Average global foreground Dice: [0.9245]\n",
      "2021-10-27 20:26:35.049708: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:26:35.602245: lr: 0.00318\n",
      "2021-10-27 20:26:35.640149: saving checkpoint...\n",
      "2021-10-27 20:26:36.760428: done, saving took 1.14 seconds\n",
      "2021-10-27 20:26:37.079408: This epoch took 209.076185 s\n",
      "\n",
      "2021-10-27 20:26:37.087748: \n",
      "epoch:  72\n",
      "2021-10-27 20:29:50.019905: train loss : -0.8978\n",
      "2021-10-27 20:30:04.241614: validation loss: -0.9260\n",
      "2021-10-27 20:30:04.245916: Average global foreground Dice: [0.9249]\n",
      "2021-10-27 20:30:04.251995: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:30:04.759520: lr: 0.003078\n",
      "2021-10-27 20:30:04.797996: saving checkpoint...\n",
      "2021-10-27 20:30:05.895194: done, saving took 1.12 seconds\n",
      "2021-10-27 20:30:06.314644: This epoch took 209.220294 s\n",
      "\n",
      "2021-10-27 20:30:06.323040: \n",
      "epoch:  73\n",
      "2021-10-27 20:33:19.259122: train loss : -0.8978\n",
      "2021-10-27 20:33:33.481588: validation loss: -0.9254\n",
      "2021-10-27 20:33:33.486125: Average global foreground Dice: [0.9246]\n",
      "2021-10-27 20:33:33.492896: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:33:33.983122: lr: 0.002975\n",
      "2021-10-27 20:33:34.033557: saving checkpoint...\n",
      "2021-10-27 20:33:35.121497: done, saving took 1.11 seconds\n",
      "2021-10-27 20:33:35.527054: This epoch took 209.197583 s\n",
      "\n",
      "2021-10-27 20:33:35.546369: \n",
      "epoch:  74\n",
      "2021-10-27 20:36:48.403444: train loss : -0.8992\n",
      "2021-10-27 20:37:02.639039: validation loss: -0.9262\n",
      "2021-10-27 20:37:02.643097: Average global foreground Dice: [0.9255]\n",
      "2021-10-27 20:37:02.650785: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:37:03.137144: lr: 0.002872\n",
      "2021-10-27 20:37:03.190368: saving checkpoint...\n",
      "2021-10-27 20:37:04.382689: done, saving took 1.21 seconds\n",
      "2021-10-27 20:37:04.805258: This epoch took 209.251645 s\n",
      "\n",
      "2021-10-27 20:37:04.826111: \n",
      "epoch:  75\n",
      "2021-10-27 20:40:17.672020: train loss : -0.8993\n",
      "2021-10-27 20:40:31.915754: validation loss: -0.9271\n",
      "2021-10-27 20:40:31.920605: Average global foreground Dice: [0.9259]\n",
      "2021-10-27 20:40:31.931567: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:40:32.462604: lr: 0.002768\n",
      "2021-10-27 20:40:32.513423: saving checkpoint...\n",
      "2021-10-27 20:40:33.613173: done, saving took 1.12 seconds\n",
      "2021-10-27 20:40:33.950976: This epoch took 209.118092 s\n",
      "\n",
      "2021-10-27 20:40:33.970650: \n",
      "epoch:  76\n",
      "2021-10-27 20:43:46.931294: train loss : -0.9000\n",
      "2021-10-27 20:44:01.159491: validation loss: -0.9276\n",
      "2021-10-27 20:44:01.164469: Average global foreground Dice: [0.9262]\n",
      "2021-10-27 20:44:01.171446: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:44:01.669525: lr: 0.002664\n",
      "2021-10-27 20:44:01.720809: saving checkpoint...\n",
      "2021-10-27 20:44:02.804666: done, saving took 1.10 seconds\n",
      "2021-10-27 20:44:03.205812: This epoch took 209.228037 s\n",
      "\n",
      "2021-10-27 20:44:03.224814: \n",
      "epoch:  77\n",
      "2021-10-27 20:47:16.488878: train loss : -0.8999\n",
      "2021-10-27 20:47:30.698685: validation loss: -0.9290\n",
      "2021-10-27 20:47:30.704420: Average global foreground Dice: [0.9278]\n",
      "2021-10-27 20:47:30.711139: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:47:31.204801: lr: 0.00256\n",
      "2021-10-27 20:47:31.260777: saving checkpoint...\n",
      "2021-10-27 20:47:32.444647: done, saving took 1.21 seconds\n",
      "2021-10-27 20:47:32.858278: This epoch took 209.626297 s\n",
      "\n",
      "2021-10-27 20:47:32.877568: \n",
      "epoch:  78\n",
      "2021-10-27 20:50:46.329304: train loss : -0.9007\n",
      "2021-10-27 20:51:00.547373: validation loss: -0.9268\n",
      "2021-10-27 20:51:00.551728: Average global foreground Dice: [0.9245]\n",
      "2021-10-27 20:51:00.559014: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:51:01.092634: lr: 0.002455\n",
      "2021-10-27 20:51:01.142945: saving checkpoint...\n",
      "2021-10-27 20:51:02.235200: done, saving took 1.11 seconds\n",
      "2021-10-27 20:51:02.497506: This epoch took 209.614185 s\n",
      "\n",
      "2021-10-27 20:51:02.516364: \n",
      "epoch:  79\n",
      "2021-10-27 20:54:15.770254: train loss : -0.9016\n",
      "2021-10-27 20:54:29.979403: validation loss: -0.9310\n",
      "2021-10-27 20:54:29.983731: Average global foreground Dice: [0.9293]\n",
      "2021-10-27 20:54:29.990735: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:54:30.501043: lr: 0.002349\n",
      "2021-10-27 20:54:30.546625: saving checkpoint...\n",
      "2021-10-27 20:54:31.608206: done, saving took 1.08 seconds\n",
      "2021-10-27 20:54:31.828865: This epoch took 209.304489 s\n",
      "\n",
      "2021-10-27 20:54:31.842247: \n",
      "epoch:  80\n",
      "2021-10-27 20:57:45.270379: train loss : -0.9018\n",
      "2021-10-27 20:57:59.485231: validation loss: -0.9299\n",
      "2021-10-27 20:57:59.489508: Average global foreground Dice: [0.9286]\n",
      "2021-10-27 20:57:59.496691: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 20:58:00.053982: lr: 0.002243\n",
      "2021-10-27 20:58:00.106218: saving checkpoint...\n",
      "2021-10-27 20:58:01.207440: done, saving took 1.12 seconds\n",
      "2021-10-27 20:58:01.630846: This epoch took 209.781206 s\n",
      "\n",
      "2021-10-27 20:58:01.649563: \n",
      "epoch:  81\n",
      "2021-10-27 21:01:14.950641: train loss : -0.9026\n",
      "2021-10-27 21:01:29.170892: validation loss: -0.9306\n",
      "2021-10-27 21:01:29.177411: Average global foreground Dice: [0.9297]\n",
      "2021-10-27 21:01:29.184938: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:01:29.674535: lr: 0.002137\n",
      "2021-10-27 21:01:29.721301: saving checkpoint...\n",
      "2021-10-27 21:01:30.841138: done, saving took 1.14 seconds\n",
      "2021-10-27 21:01:31.439124: This epoch took 209.783458 s\n",
      "\n",
      "2021-10-27 21:01:31.459046: \n",
      "epoch:  82\n",
      "2021-10-27 21:04:44.688455: train loss : -0.9037\n",
      "2021-10-27 21:04:58.907620: validation loss: -0.9325\n",
      "2021-10-27 21:04:58.911829: Average global foreground Dice: [0.9309]\n",
      "2021-10-27 21:04:58.918344: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:04:59.428277: lr: 0.00203\n",
      "2021-10-27 21:04:59.477633: saving checkpoint...\n",
      "2021-10-27 21:05:00.543790: done, saving took 1.09 seconds\n",
      "2021-10-27 21:05:00.755704: This epoch took 209.289634 s\n",
      "\n",
      "2021-10-27 21:05:00.771210: \n",
      "epoch:  83\n",
      "2021-10-27 21:08:14.189635: train loss : -0.9040\n",
      "2021-10-27 21:08:28.407394: validation loss: -0.9329\n",
      "2021-10-27 21:08:28.412035: Average global foreground Dice: [0.9318]\n",
      "2021-10-27 21:08:28.417964: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:08:28.974440: lr: 0.001922\n",
      "2021-10-27 21:08:29.025777: saving checkpoint...\n",
      "2021-10-27 21:08:30.124595: done, saving took 1.12 seconds\n",
      "2021-10-27 21:08:30.397497: This epoch took 209.619283 s\n",
      "\n",
      "2021-10-27 21:08:30.416051: \n",
      "epoch:  84\n",
      "2021-10-27 21:11:43.802112: train loss : -0.9038\n",
      "2021-10-27 21:11:58.025545: validation loss: -0.9332\n",
      "2021-10-27 21:11:58.030287: Average global foreground Dice: [0.9316]\n",
      "2021-10-27 21:11:58.036797: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:11:58.556268: lr: 0.001813\n",
      "2021-10-27 21:11:58.605919: saving checkpoint...\n",
      "2021-10-27 21:11:59.706355: done, saving took 1.12 seconds\n",
      "2021-10-27 21:11:59.942307: This epoch took 209.519464 s\n",
      "\n",
      "2021-10-27 21:11:59.960284: \n",
      "epoch:  85\n",
      "2021-10-27 21:15:14.043883: train loss : -0.9048\n",
      "2021-10-27 21:15:28.275241: validation loss: -0.9332\n",
      "2021-10-27 21:15:28.279448: Average global foreground Dice: [0.9313]\n",
      "2021-10-27 21:15:28.286027: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:15:28.846346: lr: 0.001704\n",
      "2021-10-27 21:15:28.900374: saving checkpoint...\n",
      "2021-10-27 21:15:29.995219: done, saving took 1.12 seconds\n",
      "2021-10-27 21:15:30.266608: This epoch took 210.299585 s\n",
      "\n",
      "2021-10-27 21:15:30.284843: \n",
      "epoch:  86\n",
      "2021-10-27 21:18:44.196057: train loss : -0.9053\n",
      "2021-10-27 21:18:58.434228: validation loss: -0.9348\n",
      "2021-10-27 21:18:58.438670: Average global foreground Dice: [0.9329]\n",
      "2021-10-27 21:18:58.445390: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:18:58.927255: lr: 0.001594\n",
      "2021-10-27 21:18:58.974977: saving checkpoint...\n",
      "2021-10-27 21:19:00.066794: done, saving took 1.11 seconds\n",
      "2021-10-27 21:19:00.602233: This epoch took 210.310823 s\n",
      "\n",
      "2021-10-27 21:19:00.620105: \n",
      "epoch:  87\n",
      "2021-10-27 21:22:14.739652: train loss : -0.9056\n",
      "2021-10-27 21:22:28.960334: validation loss: -0.9351\n",
      "2021-10-27 21:22:28.964882: Average global foreground Dice: [0.9324]\n",
      "2021-10-27 21:22:28.971247: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:22:29.451562: lr: 0.001483\n",
      "2021-10-27 21:22:29.499696: saving checkpoint...\n",
      "2021-10-27 21:22:30.604387: done, saving took 1.12 seconds\n",
      "2021-10-27 21:22:30.887698: This epoch took 210.261526 s\n",
      "\n",
      "2021-10-27 21:22:30.905945: \n",
      "epoch:  88\n",
      "2021-10-27 21:25:44.831125: train loss : -0.9052\n",
      "2021-10-27 21:25:59.036747: validation loss: -0.9348\n",
      "2021-10-27 21:25:59.040957: Average global foreground Dice: [0.933]\n",
      "2021-10-27 21:25:59.048035: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:25:59.534214: lr: 0.001372\n",
      "2021-10-27 21:25:59.585217: saving checkpoint...\n",
      "2021-10-27 21:26:00.701123: done, saving took 1.13 seconds\n",
      "2021-10-27 21:26:01.145140: This epoch took 210.232304 s\n",
      "\n",
      "2021-10-27 21:26:01.163864: \n",
      "epoch:  89\n",
      "2021-10-27 21:29:15.229650: train loss : -0.9068\n",
      "2021-10-27 21:29:29.448395: validation loss: -0.9354\n",
      "2021-10-27 21:29:29.454415: Average global foreground Dice: [0.9332]\n",
      "2021-10-27 21:29:29.461432: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:29:29.986075: lr: 0.001259\n",
      "2021-10-27 21:29:30.034969: saving checkpoint...\n",
      "2021-10-27 21:29:31.101214: done, saving took 1.09 seconds\n",
      "2021-10-27 21:29:31.539693: This epoch took 210.369396 s\n",
      "\n",
      "2021-10-27 21:29:31.559355: \n",
      "epoch:  90\n",
      "2021-10-27 21:32:45.692551: train loss : -0.9073\n",
      "2021-10-27 21:32:59.919585: validation loss: -0.9370\n",
      "2021-10-27 21:32:59.923735: Average global foreground Dice: [0.9347]\n",
      "2021-10-27 21:32:59.929613: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:33:00.421001: lr: 0.001145\n",
      "2021-10-27 21:33:00.472834: saving checkpoint...\n",
      "2021-10-27 21:33:01.544254: done, saving took 1.09 seconds\n",
      "2021-10-27 21:33:01.999954: This epoch took 210.433331 s\n",
      "\n",
      "2021-10-27 21:33:02.019347: \n",
      "epoch:  91\n",
      "2021-10-27 21:36:16.209172: train loss : -0.9081\n",
      "2021-10-27 21:36:30.414753: validation loss: -0.9378\n",
      "2021-10-27 21:36:30.418961: Average global foreground Dice: [0.9354]\n",
      "2021-10-27 21:36:30.425363: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:36:30.907677: lr: 0.00103\n",
      "2021-10-27 21:36:30.962582: saving checkpoint...\n",
      "2021-10-27 21:36:32.115925: done, saving took 1.17 seconds\n",
      "2021-10-27 21:36:32.502489: This epoch took 210.476507 s\n",
      "\n",
      "2021-10-27 21:36:32.519588: \n",
      "epoch:  92\n",
      "2021-10-27 21:39:46.734115: train loss : -0.9072\n",
      "2021-10-27 21:40:00.961530: validation loss: -0.9385\n",
      "2021-10-27 21:40:00.965844: Average global foreground Dice: [0.9365]\n",
      "2021-10-27 21:40:00.972866: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:40:01.458180: lr: 0.000913\n",
      "2021-10-27 21:40:01.505439: saving checkpoint...\n",
      "2021-10-27 21:40:02.596578: done, saving took 1.11 seconds\n",
      "2021-10-27 21:40:02.920891: This epoch took 210.394666 s\n",
      "\n",
      "2021-10-27 21:40:02.933887: \n",
      "epoch:  93\n",
      "2021-10-27 21:43:17.256623: train loss : -0.9085\n",
      "2021-10-27 21:43:31.477609: validation loss: -0.9397\n",
      "2021-10-27 21:43:31.482184: Average global foreground Dice: [0.9374]\n",
      "2021-10-27 21:43:31.489246: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:43:31.996620: lr: 0.000795\n",
      "2021-10-27 21:43:32.053448: saving checkpoint...\n",
      "2021-10-27 21:43:33.147370: done, saving took 1.11 seconds\n",
      "2021-10-27 21:43:33.592073: This epoch took 210.651240 s\n",
      "\n",
      "2021-10-27 21:43:33.611052: \n",
      "epoch:  94\n",
      "2021-10-27 21:46:47.689788: train loss : -0.9081\n",
      "2021-10-27 21:47:01.931321: validation loss: -0.9392\n",
      "2021-10-27 21:47:01.935587: Average global foreground Dice: [0.9373]\n",
      "2021-10-27 21:47:01.943267: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:47:02.540334: lr: 0.000675\n",
      "2021-10-27 21:47:02.599293: saving checkpoint...\n",
      "2021-10-27 21:47:03.678540: done, saving took 1.10 seconds\n",
      "2021-10-27 21:47:04.103273: This epoch took 210.485805 s\n",
      "\n",
      "2021-10-27 21:47:04.120881: \n",
      "epoch:  95\n",
      "2021-10-27 21:50:18.211537: train loss : -0.9090\n",
      "2021-10-27 21:50:32.449051: validation loss: -0.9396\n",
      "2021-10-27 21:50:32.455130: Average global foreground Dice: [0.9372]\n",
      "2021-10-27 21:50:32.461590: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:50:32.944235: lr: 0.000552\n",
      "2021-10-27 21:50:33.001392: saving checkpoint...\n",
      "2021-10-27 21:50:34.083019: done, saving took 1.10 seconds\n",
      "2021-10-27 21:50:34.576202: This epoch took 210.448514 s\n",
      "\n",
      "2021-10-27 21:50:34.598963: \n",
      "epoch:  96\n",
      "2021-10-27 21:53:48.723944: train loss : -0.9097\n",
      "2021-10-27 21:54:02.950562: validation loss: -0.9429\n",
      "2021-10-27 21:54:02.954893: Average global foreground Dice: [0.9399]\n",
      "2021-10-27 21:54:02.961798: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:54:03.450382: lr: 0.000426\n",
      "2021-10-27 21:54:03.505901: saving checkpoint...\n",
      "2021-10-27 21:54:04.584997: done, saving took 1.10 seconds\n",
      "2021-10-27 21:54:04.994034: This epoch took 210.388111 s\n",
      "\n",
      "2021-10-27 21:54:05.016133: \n",
      "epoch:  97\n",
      "2021-10-27 21:57:19.159474: train loss : -0.9108\n",
      "2021-10-27 21:57:33.368762: validation loss: -0.9408\n",
      "2021-10-27 21:57:33.373151: Average global foreground Dice: [0.9386]\n",
      "2021-10-27 21:57:33.380163: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 21:57:33.878674: lr: 0.000296\n",
      "2021-10-27 21:57:33.929405: saving checkpoint...\n",
      "2021-10-27 21:57:35.033006: done, saving took 1.12 seconds\n",
      "2021-10-27 21:57:35.443416: This epoch took 210.420974 s\n",
      "\n",
      "2021-10-27 21:57:35.465357: \n",
      "epoch:  98\n",
      "2021-10-27 22:00:49.499074: train loss : -0.9108\n",
      "2021-10-27 22:01:03.703976: validation loss: -0.9417\n",
      "2021-10-27 22:01:03.708362: Average global foreground Dice: [0.9402]\n",
      "2021-10-27 22:01:03.719799: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 22:01:04.252295: lr: 0.000158\n",
      "2021-10-27 22:01:04.299187: saving checkpoint...\n",
      "2021-10-27 22:01:05.427521: done, saving took 1.15 seconds\n",
      "2021-10-27 22:01:05.997954: This epoch took 210.522279 s\n",
      "\n",
      "2021-10-27 22:01:06.016545: \n",
      "epoch:  99\n",
      "2021-10-27 22:04:19.501552: train loss : -0.9108\n",
      "2021-10-27 22:04:33.718564: validation loss: -0.9415\n",
      "2021-10-27 22:04:33.724377: Average global foreground Dice: [0.9394]\n",
      "2021-10-27 22:04:33.736524: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 22:04:34.235325: lr: 0.0\n",
      "2021-10-27 22:04:34.256986: saving scheduled checkpoint file...\n",
      "2021-10-27 22:04:34.286717: saving checkpoint...\n",
      "2021-10-27 22:04:35.404941: done, saving took 1.14 seconds\n",
      "2021-10-27 22:04:36.081759: done\n",
      "2021-10-27 22:04:36.109581: saving checkpoint...\n",
      "2021-10-27 22:04:37.213675: done, saving took 1.12 seconds\n",
      "2021-10-27 22:04:37.762863: This epoch took 211.733864 s\n",
      "\n",
      "2021-10-27 22:04:37.790235: saving checkpoint...\n",
      "2021-10-27 22:04:38.730713: done, saving took 0.96 seconds\n",
      "23090557_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090558_20120 (3, 263, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090559_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090560_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090562_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090563_20151 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090564_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090566_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090567_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090568_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090569_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090571_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090584_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090589_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090590_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090592_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090593_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090596_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090597_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090599_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090600_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090603_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090604_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090607_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090608_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090609_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090614_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090615_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090616_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090617_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090619_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090620_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090621_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090627_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090628_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090629_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090631_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090634_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090635_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090636_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090637_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090640_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090644_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090646_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-27 22:14:07.310181: finished prediction\n",
      "2021-10-27 22:14:07.315912: evaluation of raw predictions\n",
      "2021-10-27 22:14:13.081033: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.9544701828710818\n",
      "after:  0.9544701828710818\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train 2d nnUNetTrainerV2 555 all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-27 05:36:45.754326: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-27 05:37:00.594287: Unable to plot network architecture:\n",
      "2021-10-27 05:37:00.680377: No module named 'hiddenlayer'\n",
      "2021-10-27 05:37:00.764416: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-27 05:37:00.888404: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-27 05:37:01.048429: \n",
      "\n",
      "2021-10-27 05:37:01.132366: \n",
      "epoch:  0\n",
      "2021-10-27 05:42:56.337986: train loss : -0.1084\n",
      "2021-10-27 05:43:19.246696: validation loss: -0.4531\n",
      "2021-10-27 05:43:19.656855: Average global foreground Dice: [0.5549]\n",
      "2021-10-27 05:43:19.735797: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 05:43:20.492887: lr: 0.00991\n",
      "2021-10-27 05:43:20.511991: This epoch took 379.317797 s\n",
      "\n",
      "2021-10-27 05:43:20.519050: \n",
      "epoch:  1\n",
      "2021-10-27 05:48:34.736089: train loss : -0.5763\n",
      "2021-10-27 05:48:57.258855: validation loss: -0.6947\n",
      "2021-10-27 05:48:57.636249: Average global foreground Dice: [0.7405]\n",
      "2021-10-27 05:48:57.653465: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 05:48:58.269662: lr: 0.00982\n",
      "2021-10-27 05:48:58.367762: saving checkpoint...\n",
      "2021-10-27 05:49:00.300601: done, saving took 2.01 seconds\n",
      "2021-10-27 05:49:00.898111: This epoch took 340.372163 s\n",
      "\n",
      "2021-10-27 05:49:00.906590: \n",
      "epoch:  2\n",
      "2021-10-27 05:54:10.472372: train loss : -0.6588\n",
      "2021-10-27 05:54:29.506801: validation loss: -0.7093\n",
      "2021-10-27 05:54:29.512614: Average global foreground Dice: [0.7458]\n",
      "2021-10-27 05:54:29.519367: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 05:54:30.022358: lr: 0.00973\n",
      "2021-10-27 05:54:30.122938: saving checkpoint...\n",
      "2021-10-27 05:54:31.979202: done, saving took 1.94 seconds\n",
      "2021-10-27 05:54:32.377752: This epoch took 331.463497 s\n",
      "\n",
      "2021-10-27 05:54:32.386107: \n",
      "epoch:  3\n",
      "2021-10-27 05:59:41.609478: train loss : -0.6952\n",
      "2021-10-27 06:00:00.365910: validation loss: -0.7450\n",
      "2021-10-27 06:00:00.370566: Average global foreground Dice: [0.785]\n",
      "2021-10-27 06:00:00.377347: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:00:00.912946: lr: 0.009639\n",
      "2021-10-27 06:00:00.998966: saving checkpoint...\n",
      "2021-10-27 06:00:02.739374: done, saving took 1.81 seconds\n",
      "2021-10-27 06:00:03.150345: This epoch took 330.757618 s\n",
      "\n",
      "2021-10-27 06:00:03.158510: \n",
      "epoch:  4\n",
      "2021-10-27 06:05:10.471361: train loss : -0.7361\n",
      "2021-10-27 06:05:29.548562: validation loss: -0.7779\n",
      "2021-10-27 06:05:29.552832: Average global foreground Dice: [0.8133]\n",
      "2021-10-27 06:05:29.559305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:05:30.050826: lr: 0.009549\n",
      "2021-10-27 06:05:30.109914: saving checkpoint...\n",
      "2021-10-27 06:05:31.919902: done, saving took 1.85 seconds\n",
      "2021-10-27 06:05:32.396935: This epoch took 329.231300 s\n",
      "\n",
      "2021-10-27 06:05:32.406394: \n",
      "epoch:  5\n",
      "2021-10-27 06:10:49.058462: train loss : -0.7494\n",
      "2021-10-27 06:11:09.338736: validation loss: -0.7669\n",
      "2021-10-27 06:11:09.342862: Average global foreground Dice: [0.798]\n",
      "2021-10-27 06:11:09.349957: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:11:09.854059: lr: 0.009458\n",
      "2021-10-27 06:11:09.939370: saving checkpoint...\n",
      "2021-10-27 06:11:11.733479: done, saving took 1.85 seconds\n",
      "2021-10-27 06:11:12.519548: This epoch took 340.106175 s\n",
      "\n",
      "2021-10-27 06:11:12.537691: \n",
      "epoch:  6\n",
      "2021-10-27 06:16:21.297568: train loss : -0.7552\n",
      "2021-10-27 06:16:40.766828: validation loss: -0.7856\n",
      "2021-10-27 06:16:40.771118: Average global foreground Dice: [0.8162]\n",
      "2021-10-27 06:16:40.777596: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:16:41.298534: lr: 0.009368\n",
      "2021-10-27 06:16:41.394979: saving checkpoint...\n",
      "2021-10-27 06:16:43.217364: done, saving took 1.89 seconds\n",
      "2021-10-27 06:16:44.065569: This epoch took 331.522061 s\n",
      "\n",
      "2021-10-27 06:16:44.085018: \n",
      "epoch:  7\n",
      "2021-10-27 06:21:59.655666: train loss : -0.7667\n",
      "2021-10-27 06:22:22.121924: validation loss: -0.7889\n",
      "2021-10-27 06:22:22.126039: Average global foreground Dice: [0.8256]\n",
      "2021-10-27 06:22:22.132284: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:22:22.676008: lr: 0.009277\n",
      "2021-10-27 06:22:22.756664: saving checkpoint...\n",
      "2021-10-27 06:22:24.541749: done, saving took 1.85 seconds\n",
      "2021-10-27 06:22:25.235333: This epoch took 341.141758 s\n",
      "\n",
      "2021-10-27 06:22:25.243758: \n",
      "epoch:  8\n",
      "2021-10-27 06:27:38.212064: train loss : -0.7828\n",
      "2021-10-27 06:27:58.232234: validation loss: -0.8125\n",
      "2021-10-27 06:27:58.236296: Average global foreground Dice: [0.8376]\n",
      "2021-10-27 06:27:58.243344: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:27:58.753826: lr: 0.009186\n",
      "2021-10-27 06:27:58.848660: saving checkpoint...\n",
      "2021-10-27 06:28:00.669415: done, saving took 1.88 seconds\n",
      "2021-10-27 06:28:01.266723: This epoch took 336.015583 s\n",
      "\n",
      "2021-10-27 06:28:01.287906: \n",
      "epoch:  9\n",
      "2021-10-27 06:33:18.220029: train loss : -0.7898\n",
      "2021-10-27 06:33:37.289514: validation loss: -0.8148\n",
      "2021-10-27 06:33:37.294728: Average global foreground Dice: [0.8349]\n",
      "2021-10-27 06:33:37.301049: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:33:37.795578: lr: 0.009095\n",
      "2021-10-27 06:33:37.893389: saving checkpoint...\n",
      "2021-10-27 06:33:39.762477: done, saving took 1.93 seconds\n",
      "2021-10-27 06:33:40.367029: This epoch took 339.072011 s\n",
      "\n",
      "2021-10-27 06:33:40.386094: \n",
      "epoch:  10\n",
      "2021-10-27 06:38:53.524237: train loss : -0.7933\n",
      "2021-10-27 06:39:12.187485: validation loss: -0.8239\n",
      "2021-10-27 06:39:12.192142: Average global foreground Dice: [0.845]\n",
      "2021-10-27 06:39:12.199265: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:39:12.685277: lr: 0.009004\n",
      "2021-10-27 06:39:12.730635: saving checkpoint...\n",
      "2021-10-27 06:39:14.423584: done, saving took 1.72 seconds\n",
      "2021-10-27 06:39:14.716424: This epoch took 334.323305 s\n",
      "\n",
      "2021-10-27 06:39:14.724909: \n",
      "epoch:  11\n",
      "2021-10-27 06:44:28.122439: train loss : -0.7944\n",
      "2021-10-27 06:44:46.786031: validation loss: -0.8233\n",
      "2021-10-27 06:44:46.792301: Average global foreground Dice: [0.8461]\n",
      "2021-10-27 06:44:46.799551: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:44:47.286655: lr: 0.008913\n",
      "2021-10-27 06:44:47.343975: saving checkpoint...\n",
      "2021-10-27 06:44:49.186247: done, saving took 1.87 seconds\n",
      "2021-10-27 06:44:50.013637: This epoch took 335.281991 s\n",
      "\n",
      "2021-10-27 06:44:50.024031: \n",
      "epoch:  12\n",
      "2021-10-27 06:50:09.884418: train loss : -0.7952\n",
      "2021-10-27 06:50:32.548254: validation loss: -0.8161\n",
      "2021-10-27 06:50:32.776911: Average global foreground Dice: [0.8336]\n",
      "2021-10-27 06:50:32.892607: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:50:34.265349: lr: 0.008822\n",
      "2021-10-27 06:50:34.790616: saving checkpoint...\n",
      "2021-10-27 06:50:36.791297: done, saving took 2.06 seconds\n",
      "2021-10-27 06:50:37.211121: This epoch took 347.180167 s\n",
      "\n",
      "2021-10-27 06:50:37.221430: \n",
      "epoch:  13\n",
      "2021-10-27 06:55:50.987137: train loss : -0.7990\n",
      "2021-10-27 06:56:09.693555: validation loss: -0.8286\n",
      "2021-10-27 06:56:09.697793: Average global foreground Dice: [0.8489]\n",
      "2021-10-27 06:56:09.703762: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 06:56:10.197740: lr: 0.008731\n",
      "2021-10-27 06:56:10.253930: saving checkpoint...\n",
      "2021-10-27 06:56:12.037356: done, saving took 1.81 seconds\n",
      "2021-10-27 06:56:12.640672: This epoch took 335.412399 s\n",
      "\n",
      "2021-10-27 06:56:12.650077: \n",
      "epoch:  14\n",
      "2021-10-27 07:01:23.809832: train loss : -0.8040\n",
      "2021-10-27 07:01:42.484494: validation loss: -0.8271\n",
      "2021-10-27 07:01:42.488945: Average global foreground Dice: [0.8545]\n",
      "2021-10-27 07:01:42.494767: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:01:43.029150: lr: 0.008639\n",
      "2021-10-27 07:01:43.085283: saving checkpoint...\n",
      "2021-10-27 07:01:44.872595: done, saving took 1.82 seconds\n",
      "2021-10-27 07:01:45.140937: This epoch took 332.483765 s\n",
      "\n",
      "2021-10-27 07:01:45.154666: \n",
      "epoch:  15\n",
      "2021-10-27 07:07:01.236776: train loss : -0.8089\n",
      "2021-10-27 07:07:22.686962: validation loss: -0.8125\n",
      "2021-10-27 07:07:22.691325: Average global foreground Dice: [0.8274]\n",
      "2021-10-27 07:07:22.698020: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:07:23.186690: lr: 0.008548\n",
      "2021-10-27 07:07:23.270579: saving checkpoint...\n",
      "2021-10-27 07:07:25.151231: done, saving took 1.94 seconds\n",
      "2021-10-27 07:07:25.782058: This epoch took 340.619288 s\n",
      "\n",
      "2021-10-27 07:07:25.799818: \n",
      "epoch:  16\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-27 07:12:36.207913: train loss : -0.8148\n",
      "2021-10-27 07:12:54.956311: validation loss: -0.8363\n",
      "2021-10-27 07:12:54.960962: Average global foreground Dice: [0.8549]\n",
      "2021-10-27 07:12:54.967874: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:12:55.478076: lr: 0.008456\n",
      "2021-10-27 07:12:55.581270: saving checkpoint...\n",
      "2021-10-27 07:12:57.413083: done, saving took 1.91 seconds\n",
      "2021-10-27 07:12:57.796482: This epoch took 331.990578 s\n",
      "\n",
      "2021-10-27 07:12:57.816657: \n",
      "epoch:  17\n",
      "2021-10-27 07:18:08.443479: train loss : -0.8171\n",
      "2021-10-27 07:18:28.238153: validation loss: -0.8339\n",
      "2021-10-27 07:18:28.242250: Average global foreground Dice: [0.8505]\n",
      "2021-10-27 07:18:28.249011: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:18:28.752438: lr: 0.008364\n",
      "2021-10-27 07:18:28.821295: saving checkpoint...\n",
      "2021-10-27 07:18:30.647820: done, saving took 1.88 seconds\n",
      "2021-10-27 07:18:31.278517: This epoch took 333.455236 s\n",
      "\n",
      "2021-10-27 07:18:31.286401: \n",
      "epoch:  18\n",
      "2021-10-27 07:23:41.603876: train loss : -0.8192\n",
      "2021-10-27 07:24:01.005017: validation loss: -0.8390\n",
      "2021-10-27 07:24:01.009310: Average global foreground Dice: [0.8573]\n",
      "2021-10-27 07:24:01.016337: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:24:01.503953: lr: 0.008272\n",
      "2021-10-27 07:24:01.581358: saving checkpoint...\n",
      "2021-10-27 07:24:03.380301: done, saving took 1.86 seconds\n",
      "2021-10-27 07:24:03.984866: This epoch took 332.691288 s\n",
      "\n",
      "2021-10-27 07:24:03.993599: \n",
      "epoch:  19\n",
      "2021-10-27 07:29:16.769640: train loss : -0.8223\n",
      "2021-10-27 07:29:37.365802: validation loss: -0.8304\n",
      "2021-10-27 07:29:37.371743: Average global foreground Dice: [0.8503]\n",
      "2021-10-27 07:29:37.378189: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:29:37.884919: lr: 0.008181\n",
      "2021-10-27 07:29:37.963552: saving checkpoint...\n",
      "2021-10-27 07:29:39.794301: done, saving took 1.89 seconds\n",
      "2021-10-27 07:29:40.392755: This epoch took 336.392340 s\n",
      "\n",
      "2021-10-27 07:29:40.400845: \n",
      "epoch:  20\n",
      "2021-10-27 07:34:50.300021: train loss : -0.8227\n",
      "2021-10-27 07:35:11.219905: validation loss: -0.8346\n",
      "2021-10-27 07:35:11.225841: Average global foreground Dice: [0.8485]\n",
      "2021-10-27 07:35:11.233207: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:35:11.753283: lr: 0.008088\n",
      "2021-10-27 07:35:11.845299: saving checkpoint...\n",
      "2021-10-27 07:35:13.685198: done, saving took 1.91 seconds\n",
      "2021-10-27 07:35:14.369558: This epoch took 333.961206 s\n",
      "\n",
      "2021-10-27 07:35:14.379288: \n",
      "epoch:  21\n",
      "2021-10-27 07:40:29.399157: train loss : -0.8257\n",
      "2021-10-27 07:40:51.906086: validation loss: -0.8422\n",
      "2021-10-27 07:40:51.911365: Average global foreground Dice: [0.8582]\n",
      "2021-10-27 07:40:51.918160: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:40:52.475408: lr: 0.007996\n",
      "2021-10-27 07:40:52.566410: saving checkpoint...\n",
      "2021-10-27 07:40:54.436013: done, saving took 1.94 seconds\n",
      "2021-10-27 07:40:55.029176: This epoch took 340.643695 s\n",
      "\n",
      "2021-10-27 07:40:55.037449: \n",
      "epoch:  22\n",
      "2021-10-27 07:46:03.899553: train loss : -0.8265\n",
      "2021-10-27 07:46:22.974674: validation loss: -0.8393\n",
      "2021-10-27 07:46:22.979055: Average global foreground Dice: [0.8573]\n",
      "2021-10-27 07:46:22.985926: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:46:23.473557: lr: 0.007904\n",
      "2021-10-27 07:46:23.524432: saving checkpoint...\n",
      "2021-10-27 07:46:25.340564: done, saving took 1.84 seconds\n",
      "2021-10-27 07:46:25.732403: This epoch took 330.688140 s\n",
      "\n",
      "2021-10-27 07:46:25.741086: \n",
      "epoch:  23\n",
      "2021-10-27 07:51:35.034164: train loss : -0.8239\n",
      "2021-10-27 07:51:54.700251: validation loss: -0.8347\n",
      "2021-10-27 07:51:54.704540: Average global foreground Dice: [0.8517]\n",
      "2021-10-27 07:51:54.710415: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:51:55.197334: lr: 0.007811\n",
      "2021-10-27 07:51:55.247006: saving checkpoint...\n",
      "2021-10-27 07:51:57.061264: done, saving took 1.84 seconds\n",
      "2021-10-27 07:51:57.657955: This epoch took 331.909948 s\n",
      "\n",
      "2021-10-27 07:51:57.665954: \n",
      "epoch:  24\n",
      "2021-10-27 07:57:11.873959: train loss : -0.8198\n",
      "2021-10-27 07:57:32.651845: validation loss: -0.8557\n",
      "2021-10-27 07:57:32.655974: Average global foreground Dice: [0.8665]\n",
      "2021-10-27 07:57:32.661975: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 07:57:33.188350: lr: 0.007719\n",
      "2021-10-27 07:57:33.236439: saving checkpoint...\n",
      "2021-10-27 07:57:35.060813: done, saving took 1.85 seconds\n",
      "2021-10-27 07:57:35.713517: This epoch took 338.040356 s\n",
      "\n",
      "2021-10-27 07:57:35.722692: \n",
      "epoch:  25\n",
      "2021-10-27 08:02:51.361112: train loss : -0.8272\n",
      "2021-10-27 08:03:12.595388: validation loss: -0.8370\n",
      "2021-10-27 08:03:12.636132: Average global foreground Dice: [0.855]\n",
      "2021-10-27 08:03:12.648819: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:03:13.519324: lr: 0.007626\n",
      "2021-10-27 08:03:13.568756: saving checkpoint...\n",
      "2021-10-27 08:03:15.387704: done, saving took 1.85 seconds\n",
      "2021-10-27 08:03:16.048801: This epoch took 340.319428 s\n",
      "\n",
      "2021-10-27 08:03:16.057024: \n",
      "epoch:  26\n",
      "2021-10-27 08:08:28.777412: train loss : -0.8319\n",
      "2021-10-27 08:08:48.083474: validation loss: -0.8459\n",
      "2021-10-27 08:08:48.088450: Average global foreground Dice: [0.8598]\n",
      "2021-10-27 08:08:48.094799: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:08:48.586686: lr: 0.007533\n",
      "2021-10-27 08:08:48.675295: saving checkpoint...\n",
      "2021-10-27 08:08:50.515305: done, saving took 1.90 seconds\n",
      "2021-10-27 08:08:51.017343: This epoch took 334.953342 s\n",
      "\n",
      "2021-10-27 08:08:51.036642: \n",
      "epoch:  27\n",
      "2021-10-27 08:14:08.445664: train loss : -0.8317\n",
      "2021-10-27 08:14:30.127451: validation loss: -0.8412\n",
      "2021-10-27 08:14:30.133045: Average global foreground Dice: [0.8605]\n",
      "2021-10-27 08:14:30.139405: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:14:30.682478: lr: 0.00744\n",
      "2021-10-27 08:14:30.770151: saving checkpoint...\n",
      "2021-10-27 08:14:32.598030: done, saving took 1.89 seconds\n",
      "2021-10-27 08:14:33.208548: This epoch took 342.164896 s\n",
      "\n",
      "2021-10-27 08:14:33.222252: \n",
      "epoch:  28\n",
      "2021-10-27 08:19:46.846218: train loss : -0.8308\n",
      "2021-10-27 08:20:05.534777: validation loss: -0.8448\n",
      "2021-10-27 08:20:05.538927: Average global foreground Dice: [0.8616]\n",
      "2021-10-27 08:20:05.545895: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:20:06.055259: lr: 0.007347\n",
      "2021-10-27 08:20:06.162602: saving checkpoint...\n",
      "2021-10-27 08:20:07.974128: done, saving took 1.89 seconds\n",
      "2021-10-27 08:20:08.652125: This epoch took 335.422223 s\n",
      "\n",
      "2021-10-27 08:20:08.671939: \n",
      "epoch:  29\n",
      "2021-10-27 08:25:21.900605: train loss : -0.8317\n",
      "2021-10-27 08:25:40.830975: validation loss: -0.8436\n",
      "2021-10-27 08:25:40.835417: Average global foreground Dice: [0.862]\n",
      "2021-10-27 08:25:40.842186: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:25:41.339769: lr: 0.007254\n",
      "2021-10-27 08:25:41.447596: saving checkpoint...\n",
      "2021-10-27 08:25:43.250961: done, saving took 1.88 seconds\n",
      "2021-10-27 08:25:43.865656: This epoch took 335.187732 s\n",
      "\n",
      "2021-10-27 08:25:43.883135: \n",
      "epoch:  30\n",
      "2021-10-27 08:30:57.820599: train loss : -0.8309\n",
      "2021-10-27 08:31:16.937678: validation loss: -0.8454\n",
      "2021-10-27 08:31:16.941836: Average global foreground Dice: [0.8598]\n",
      "2021-10-27 08:31:16.948016: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:31:17.462581: lr: 0.007161\n",
      "2021-10-27 08:31:17.566257: saving checkpoint...\n",
      "2021-10-27 08:31:19.405896: done, saving took 1.92 seconds\n",
      "2021-10-27 08:31:20.001666: This epoch took 336.112279 s\n",
      "\n",
      "2021-10-27 08:31:20.021153: \n",
      "epoch:  31\n",
      "2021-10-27 08:36:33.400209: train loss : -0.8264\n",
      "2021-10-27 08:36:54.288383: validation loss: -0.8529\n",
      "2021-10-27 08:36:54.292802: Average global foreground Dice: [0.8649]\n",
      "2021-10-27 08:36:54.299042: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:36:54.818409: lr: 0.007067\n",
      "2021-10-27 08:36:54.926564: saving checkpoint...\n",
      "2021-10-27 08:36:56.754896: done, saving took 1.90 seconds\n",
      "2021-10-27 08:36:57.349473: This epoch took 337.321694 s\n",
      "\n",
      "2021-10-27 08:36:57.367673: \n",
      "epoch:  32\n",
      "2021-10-27 08:42:08.376979: train loss : -0.8315\n",
      "2021-10-27 08:42:27.841266: validation loss: -0.8439\n",
      "2021-10-27 08:42:27.845251: Average global foreground Dice: [0.8597]\n",
      "2021-10-27 08:42:27.851515: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:42:28.368438: lr: 0.006974\n",
      "2021-10-27 08:42:28.471261: saving checkpoint...\n",
      "2021-10-27 08:42:30.290474: done, saving took 1.89 seconds\n",
      "2021-10-27 08:42:30.876517: This epoch took 333.502313 s\n",
      "\n",
      "2021-10-27 08:42:30.894356: \n",
      "epoch:  33\n",
      "2021-10-27 08:47:44.190153: train loss : -0.8308\n",
      "2021-10-27 08:48:03.179371: validation loss: -0.8557\n",
      "2021-10-27 08:48:03.183546: Average global foreground Dice: [0.872]\n",
      "2021-10-27 08:48:03.190126: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:48:03.690746: lr: 0.00688\n",
      "2021-10-27 08:48:03.793864: saving checkpoint...\n",
      "2021-10-27 08:48:05.652019: done, saving took 1.93 seconds\n",
      "2021-10-27 08:48:06.090887: This epoch took 335.189950 s\n",
      "\n",
      "2021-10-27 08:48:06.110717: \n",
      "epoch:  34\n",
      "2021-10-27 08:53:22.723152: train loss : -0.8362\n",
      "2021-10-27 08:53:41.399960: validation loss: -0.8503\n",
      "2021-10-27 08:53:41.405482: Average global foreground Dice: [0.8654]\n",
      "2021-10-27 08:53:41.411476: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:53:41.918862: lr: 0.006786\n",
      "2021-10-27 08:53:42.022581: saving checkpoint...\n",
      "2021-10-27 08:53:43.870504: done, saving took 1.92 seconds\n",
      "2021-10-27 08:53:44.163703: This epoch took 338.046275 s\n",
      "\n",
      "2021-10-27 08:53:44.181862: \n",
      "epoch:  35\n",
      "2021-10-27 08:58:56.906454: train loss : -0.8389\n",
      "2021-10-27 08:59:15.825960: validation loss: -0.8505\n",
      "2021-10-27 08:59:15.830220: Average global foreground Dice: [0.8693]\n",
      "2021-10-27 08:59:15.835989: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 08:59:16.347006: lr: 0.006692\n",
      "2021-10-27 08:59:16.452041: saving checkpoint...\n",
      "2021-10-27 08:59:18.326398: done, saving took 1.95 seconds\n",
      "2021-10-27 08:59:18.814306: This epoch took 334.625644 s\n",
      "\n",
      "2021-10-27 08:59:18.831297: \n",
      "epoch:  36\n",
      "2021-10-27 09:04:34.454200: train loss : -0.8353\n",
      "2021-10-27 09:04:54.948409: validation loss: -0.8458\n",
      "2021-10-27 09:04:54.952317: Average global foreground Dice: [0.8614]\n",
      "2021-10-27 09:04:54.958803: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:04:55.473415: lr: 0.006598\n",
      "2021-10-27 09:04:55.580785: saving checkpoint...\n",
      "2021-10-27 09:04:57.417821: done, saving took 1.91 seconds\n",
      "2021-10-27 09:04:58.008489: This epoch took 339.170347 s\n",
      "\n",
      "2021-10-27 09:04:58.029280: \n",
      "epoch:  37\n",
      "2021-10-27 09:10:18.239484: train loss : -0.8365\n",
      "2021-10-27 09:10:37.874238: validation loss: -0.8493\n",
      "2021-10-27 09:10:37.878478: Average global foreground Dice: [0.8668]\n",
      "2021-10-27 09:10:37.884964: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:10:38.397209: lr: 0.006504\n",
      "2021-10-27 09:10:38.503180: saving checkpoint...\n",
      "2021-10-27 09:10:40.275735: done, saving took 1.85 seconds\n",
      "2021-10-27 09:10:41.039956: This epoch took 343.004281 s\n",
      "\n",
      "2021-10-27 09:10:41.056958: \n",
      "epoch:  38\n",
      "2021-10-27 09:15:54.400546: train loss : -0.8401\n",
      "2021-10-27 09:16:13.758532: validation loss: -0.8556\n",
      "2021-10-27 09:16:13.762788: Average global foreground Dice: [0.8676]\n",
      "2021-10-27 09:16:13.770293: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:16:14.294311: lr: 0.006409\n",
      "2021-10-27 09:16:14.399675: saving checkpoint...\n",
      "2021-10-27 09:16:16.210426: done, saving took 1.89 seconds\n",
      "2021-10-27 09:16:16.863796: This epoch took 335.799948 s\n",
      "\n",
      "2021-10-27 09:16:16.881286: \n",
      "epoch:  39\n",
      "2021-10-27 09:21:35.847135: train loss : -0.8423\n",
      "2021-10-27 09:21:55.515813: validation loss: -0.8486\n",
      "2021-10-27 09:21:55.519841: Average global foreground Dice: [0.8649]\n",
      "2021-10-27 09:21:55.526444: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:21:56.073610: lr: 0.006314\n",
      "2021-10-27 09:21:56.133123: saving checkpoint...\n",
      "2021-10-27 09:21:57.924997: done, saving took 1.82 seconds\n",
      "2021-10-27 09:21:58.515623: This epoch took 341.627457 s\n",
      "\n",
      "2021-10-27 09:21:58.534461: \n",
      "epoch:  40\n",
      "2021-10-27 09:27:16.188045: train loss : -0.8395\n",
      "2021-10-27 09:27:36.453600: validation loss: -0.8526\n",
      "2021-10-27 09:27:36.457867: Average global foreground Dice: [0.8692]\n",
      "2021-10-27 09:27:36.463723: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:27:36.985073: lr: 0.00622\n",
      "2021-10-27 09:27:37.044210: saving checkpoint...\n",
      "2021-10-27 09:27:38.873144: done, saving took 1.86 seconds\n",
      "2021-10-27 09:27:40.101649: This epoch took 341.560426 s\n",
      "\n",
      "2021-10-27 09:27:40.118693: \n",
      "epoch:  41\n",
      "2021-10-27 09:32:55.478247: train loss : -0.8406\n",
      "2021-10-27 09:33:14.376339: validation loss: -0.8554\n",
      "2021-10-27 09:33:14.380378: Average global foreground Dice: [0.8709]\n",
      "2021-10-27 09:33:14.387162: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:33:14.875946: lr: 0.006125\n",
      "2021-10-27 09:33:14.937412: saving checkpoint...\n",
      "2021-10-27 09:33:16.744038: done, saving took 1.84 seconds\n",
      "2021-10-27 09:33:17.836694: This epoch took 337.711675 s\n",
      "\n",
      "2021-10-27 09:33:17.856574: \n",
      "epoch:  42\n",
      "2021-10-27 09:38:33.856787: train loss : -0.8397\n",
      "2021-10-27 09:38:54.555132: validation loss: -0.8461\n",
      "2021-10-27 09:38:54.560517: Average global foreground Dice: [0.8628]\n",
      "2021-10-27 09:38:54.566768: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:38:55.055655: lr: 0.00603\n",
      "2021-10-27 09:38:55.131332: saving checkpoint...\n",
      "2021-10-27 09:38:56.970124: done, saving took 1.89 seconds\n",
      "2021-10-27 09:38:57.802033: This epoch took 339.937121 s\n",
      "\n",
      "2021-10-27 09:38:57.810286: \n",
      "epoch:  43\n",
      "2021-10-27 09:44:16.618143: train loss : -0.8401\n",
      "2021-10-27 09:44:35.681386: validation loss: -0.8586\n",
      "2021-10-27 09:44:35.685620: Average global foreground Dice: [0.8693]\n",
      "2021-10-27 09:44:35.694182: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:44:36.178469: lr: 0.005934\n",
      "2021-10-27 09:44:36.253067: saving checkpoint...\n",
      "2021-10-27 09:44:38.081283: done, saving took 1.88 seconds\n",
      "2021-10-27 09:44:38.935454: This epoch took 341.118671 s\n",
      "\n",
      "2021-10-27 09:44:38.946573: \n",
      "epoch:  44\n",
      "2021-10-27 09:49:59.362663: train loss : -0.8366\n",
      "2021-10-27 09:50:21.833496: validation loss: -0.8642\n",
      "2021-10-27 09:50:22.169322: Average global foreground Dice: [0.8763]\n",
      "2021-10-27 09:50:22.332078: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:50:23.352062: lr: 0.005839\n",
      "2021-10-27 09:50:23.461989: saving checkpoint...\n",
      "2021-10-27 09:50:25.347451: done, saving took 1.94 seconds\n",
      "2021-10-27 09:50:26.399102: This epoch took 347.445382 s\n",
      "\n",
      "2021-10-27 09:50:26.407545: \n",
      "epoch:  45\n",
      "2021-10-27 09:55:42.006908: train loss : -0.8418\n",
      "2021-10-27 09:56:03.371500: validation loss: -0.8586\n",
      "2021-10-27 09:56:03.375653: Average global foreground Dice: [0.8705]\n",
      "2021-10-27 09:56:03.382355: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 09:56:03.886043: lr: 0.005743\n",
      "2021-10-27 09:56:03.937177: saving checkpoint...\n",
      "2021-10-27 09:56:05.828916: done, saving took 1.92 seconds\n",
      "2021-10-27 09:56:06.555861: This epoch took 340.142043 s\n",
      "\n",
      "2021-10-27 09:56:06.563987: \n",
      "epoch:  46\n",
      "2021-10-27 10:01:21.242340: train loss : -0.8410\n",
      "2021-10-27 10:01:40.812607: validation loss: -0.8565\n",
      "2021-10-27 10:01:40.816647: Average global foreground Dice: [0.8711]\n",
      "2021-10-27 10:01:40.823283: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:01:41.343675: lr: 0.005647\n",
      "2021-10-27 10:01:41.431736: saving checkpoint...\n",
      "2021-10-27 10:01:43.243643: done, saving took 1.84 seconds\n",
      "2021-10-27 10:01:44.168144: This epoch took 337.596297 s\n",
      "\n",
      "2021-10-27 10:01:44.176883: \n",
      "epoch:  47\n",
      "2021-10-27 10:06:58.675125: train loss : -0.8426\n",
      "2021-10-27 10:07:17.700844: validation loss: -0.8583\n",
      "2021-10-27 10:07:17.704784: Average global foreground Dice: [0.8715]\n",
      "2021-10-27 10:07:17.711589: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:07:18.211276: lr: 0.005551\n",
      "2021-10-27 10:07:18.260628: saving checkpoint...\n",
      "2021-10-27 10:07:20.046446: done, saving took 1.81 seconds\n",
      "2021-10-27 10:07:20.651901: This epoch took 336.468649 s\n",
      "\n",
      "2021-10-27 10:07:20.670126: \n",
      "epoch:  48\n",
      "2021-10-27 10:12:37.575590: train loss : -0.8417\n",
      "2021-10-27 10:12:57.308330: validation loss: -0.8542\n",
      "2021-10-27 10:12:57.312532: Average global foreground Dice: [0.8678]\n",
      "2021-10-27 10:12:57.318847: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:12:57.814358: lr: 0.005455\n",
      "2021-10-27 10:12:57.886767: saving checkpoint...\n",
      "2021-10-27 10:12:59.704076: done, saving took 1.85 seconds\n",
      "2021-10-27 10:13:01.290091: This epoch took 340.612979 s\n",
      "\n",
      "2021-10-27 10:13:01.298798: \n",
      "epoch:  49\n",
      "2021-10-27 10:18:15.784439: train loss : -0.8392\n",
      "2021-10-27 10:18:35.763544: validation loss: -0.8551\n",
      "2021-10-27 10:18:35.767477: Average global foreground Dice: [0.8723]\n",
      "2021-10-27 10:18:35.774469: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:18:36.274002: lr: 0.005359\n",
      "2021-10-27 10:18:36.296129: saving scheduled checkpoint file...\n",
      "2021-10-27 10:18:36.331500: saving checkpoint...\n",
      "2021-10-27 10:18:37.865548: done, saving took 1.56 seconds\n",
      "2021-10-27 10:18:38.747238: done\n",
      "2021-10-27 10:18:38.784700: saving checkpoint...\n",
      "2021-10-27 10:18:40.571849: done, saving took 1.82 seconds\n",
      "2021-10-27 10:18:41.576798: This epoch took 340.271051 s\n",
      "\n",
      "2021-10-27 10:18:41.585110: \n",
      "epoch:  50\n",
      "2021-10-27 10:23:57.736776: train loss : -0.8435\n",
      "2021-10-27 10:24:16.865106: validation loss: -0.8596\n",
      "2021-10-27 10:24:16.869249: Average global foreground Dice: [0.8737]\n",
      "2021-10-27 10:24:16.875302: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:24:17.362334: lr: 0.005262\n",
      "2021-10-27 10:24:17.410342: saving checkpoint...\n",
      "2021-10-27 10:24:19.192627: done, saving took 1.81 seconds\n",
      "2021-10-27 10:24:19.736643: This epoch took 338.145428 s\n",
      "\n",
      "2021-10-27 10:24:19.744684: \n",
      "epoch:  51\n",
      "2021-10-27 10:29:35.400601: train loss : -0.8451\n",
      "2021-10-27 10:29:56.722901: validation loss: -0.8519\n",
      "2021-10-27 10:29:56.726954: Average global foreground Dice: [0.8666]\n",
      "2021-10-27 10:29:56.733445: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:29:57.220289: lr: 0.005166\n",
      "2021-10-27 10:29:57.272928: saving checkpoint...\n",
      "2021-10-27 10:29:59.094363: done, saving took 1.85 seconds\n",
      "2021-10-27 10:29:59.799447: This epoch took 340.047708 s\n",
      "\n",
      "2021-10-27 10:29:59.807208: \n",
      "epoch:  52\n",
      "2021-10-27 10:35:12.137227: train loss : -0.8394\n",
      "2021-10-27 10:35:32.324435: validation loss: -0.8607\n",
      "2021-10-27 10:35:32.328475: Average global foreground Dice: [0.875]\n",
      "2021-10-27 10:35:32.334682: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:35:32.824584: lr: 0.005069\n",
      "2021-10-27 10:35:32.921238: saving checkpoint...\n",
      "2021-10-27 10:35:34.748378: done, saving took 1.89 seconds\n",
      "2021-10-27 10:35:35.424128: This epoch took 335.610118 s\n",
      "\n",
      "2021-10-27 10:35:35.445065: \n",
      "epoch:  53\n",
      "2021-10-27 10:40:55.006237: train loss : -0.8446\n",
      "2021-10-27 10:41:14.603211: validation loss: -0.8663\n",
      "2021-10-27 10:41:14.607493: Average global foreground Dice: [0.8786]\n",
      "2021-10-27 10:41:14.613998: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:41:15.151183: lr: 0.004971\n",
      "2021-10-27 10:41:15.255430: saving checkpoint...\n",
      "2021-10-27 10:41:17.051549: done, saving took 1.87 seconds\n",
      "2021-10-27 10:41:17.696322: This epoch took 342.244483 s\n",
      "\n",
      "2021-10-27 10:41:17.714064: \n",
      "epoch:  54\n",
      "2021-10-27 10:46:36.708224: train loss : -0.8465\n",
      "2021-10-27 10:46:58.016701: validation loss: -0.8630\n",
      "2021-10-27 10:46:58.020716: Average global foreground Dice: [0.8752]\n",
      "2021-10-27 10:46:58.027166: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:46:58.533263: lr: 0.004874\n",
      "2021-10-27 10:46:58.643459: saving checkpoint...\n",
      "2021-10-27 10:47:00.428953: done, saving took 1.86 seconds\n",
      "2021-10-27 10:47:01.179836: This epoch took 343.458914 s\n",
      "\n",
      "2021-10-27 10:47:01.197492: \n",
      "epoch:  55\n",
      "2021-10-27 10:52:11.688329: train loss : -0.8486\n",
      "2021-10-27 10:52:30.616707: validation loss: -0.8637\n",
      "2021-10-27 10:52:30.620711: Average global foreground Dice: [0.8761]\n",
      "2021-10-27 10:52:30.627906: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:52:31.145968: lr: 0.004776\n",
      "2021-10-27 10:52:31.248901: saving checkpoint...\n",
      "2021-10-27 10:52:33.025600: done, saving took 1.85 seconds\n",
      "2021-10-27 10:52:33.984212: This epoch took 332.780323 s\n",
      "\n",
      "2021-10-27 10:52:34.001855: \n",
      "epoch:  56\n",
      "2021-10-27 10:57:45.084346: train loss : -0.8498\n",
      "2021-10-27 10:58:04.003546: validation loss: -0.8642\n",
      "2021-10-27 10:58:04.007637: Average global foreground Dice: [0.879]\n",
      "2021-10-27 10:58:04.014064: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 10:58:04.537251: lr: 0.004679\n",
      "2021-10-27 10:58:04.646013: saving checkpoint...\n",
      "2021-10-27 10:58:06.455575: done, saving took 1.88 seconds\n",
      "2021-10-27 10:58:07.097543: This epoch took 333.089400 s\n",
      "\n",
      "2021-10-27 10:58:07.113977: \n",
      "epoch:  57\n",
      "2021-10-27 11:03:23.271069: train loss : -0.8520\n",
      "2021-10-27 11:03:43.366331: validation loss: -0.8629\n",
      "2021-10-27 11:03:43.370458: Average global foreground Dice: [0.8747]\n",
      "2021-10-27 11:03:43.376849: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:03:43.900257: lr: 0.004581\n",
      "2021-10-27 11:03:44.002676: saving checkpoint...\n",
      "2021-10-27 11:03:45.889653: done, saving took 1.96 seconds\n",
      "2021-10-27 11:03:46.535783: This epoch took 339.415341 s\n",
      "\n",
      "2021-10-27 11:03:46.555264: \n",
      "epoch:  58\n",
      "2021-10-27 11:08:58.915848: train loss : -0.8456\n",
      "2021-10-27 11:09:18.097389: validation loss: -0.8597\n",
      "2021-10-27 11:09:18.101349: Average global foreground Dice: [0.8738]\n",
      "2021-10-27 11:09:18.108310: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:09:18.616735: lr: 0.004482\n",
      "2021-10-27 11:09:18.721861: saving checkpoint...\n",
      "2021-10-27 11:09:20.569794: done, saving took 1.92 seconds\n",
      "2021-10-27 11:09:21.185719: This epoch took 334.623189 s\n",
      "\n",
      "2021-10-27 11:09:21.203407: \n",
      "epoch:  59\n",
      "2021-10-27 11:14:38.850753: train loss : -0.8394\n",
      "2021-10-27 11:14:59.612266: validation loss: -0.8630\n",
      "2021-10-27 11:14:59.616345: Average global foreground Dice: [0.8748]\n",
      "2021-10-27 11:14:59.623535: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:15:00.133288: lr: 0.004384\n",
      "2021-10-27 11:15:00.231461: saving checkpoint...\n",
      "2021-10-27 11:15:02.043624: done, saving took 1.88 seconds\n",
      "2021-10-27 11:15:02.641912: This epoch took 341.431850 s\n",
      "\n",
      "2021-10-27 11:15:02.662317: \n",
      "epoch:  60\n",
      "2021-10-27 11:20:18.192627: train loss : -0.8507\n",
      "2021-10-27 11:20:37.392681: validation loss: -0.8636\n",
      "2021-10-27 11:20:37.396857: Average global foreground Dice: [0.8753]\n",
      "2021-10-27 11:20:37.402840: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:20:37.914947: lr: 0.004285\n",
      "2021-10-27 11:20:37.996358: saving checkpoint...\n",
      "2021-10-27 11:20:39.801872: done, saving took 1.86 seconds\n",
      "2021-10-27 11:20:40.527262: This epoch took 337.858588 s\n",
      "\n",
      "2021-10-27 11:20:40.546200: \n",
      "epoch:  61\n",
      "2021-10-27 11:25:52.234976: train loss : -0.8538\n",
      "2021-10-27 11:26:11.196808: validation loss: -0.8568\n",
      "2021-10-27 11:26:11.200964: Average global foreground Dice: [0.8709]\n",
      "2021-10-27 11:26:11.206595: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:26:11.723978: lr: 0.004186\n",
      "2021-10-27 11:26:11.753769: This epoch took 331.199540 s\n",
      "\n",
      "2021-10-27 11:26:11.760295: \n",
      "epoch:  62\n",
      "2021-10-27 11:31:27.557966: train loss : -0.8514\n",
      "2021-10-27 11:31:51.042056: validation loss: -0.8612\n",
      "2021-10-27 11:31:51.148701: Average global foreground Dice: [0.8713]\n",
      "2021-10-27 11:31:51.155424: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:31:52.089945: lr: 0.004087\n",
      "2021-10-27 11:31:52.119209: This epoch took 340.352648 s\n",
      "\n",
      "2021-10-27 11:31:52.125203: \n",
      "epoch:  63\n",
      "2021-10-27 11:37:07.011630: train loss : -0.8480\n",
      "2021-10-27 11:37:25.908466: validation loss: -0.8684\n",
      "2021-10-27 11:37:25.913870: Average global foreground Dice: [0.8809]\n",
      "2021-10-27 11:37:25.921167: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:37:26.425206: lr: 0.003987\n",
      "2021-10-27 11:37:26.513384: saving checkpoint...\n",
      "2021-10-27 11:37:28.326210: done, saving took 1.87 seconds\n",
      "2021-10-27 11:37:28.941237: This epoch took 336.810110 s\n",
      "\n",
      "2021-10-27 11:37:28.958987: \n",
      "epoch:  64\n",
      "2021-10-27 11:42:48.670689: train loss : -0.8504\n",
      "2021-10-27 11:43:10.207015: validation loss: -0.8611\n",
      "2021-10-27 11:43:10.211115: Average global foreground Dice: [0.8733]\n",
      "2021-10-27 11:43:10.217436: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:43:10.781179: lr: 0.003887\n",
      "2021-10-27 11:43:10.841158: saving checkpoint...\n",
      "2021-10-27 11:43:12.632288: done, saving took 1.82 seconds\n",
      "2021-10-27 11:43:13.226784: This epoch took 344.261916 s\n",
      "\n",
      "2021-10-27 11:43:13.245499: \n",
      "epoch:  65\n",
      "2021-10-27 11:48:27.202197: train loss : -0.8508\n",
      "2021-10-27 11:48:47.446159: validation loss: -0.8677\n",
      "2021-10-27 11:48:47.450511: Average global foreground Dice: [0.8774]\n",
      "2021-10-27 11:48:47.456847: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:48:47.948381: lr: 0.003787\n",
      "2021-10-27 11:48:48.005176: saving checkpoint...\n",
      "2021-10-27 11:48:49.815933: done, saving took 1.84 seconds\n",
      "2021-10-27 11:48:50.504112: This epoch took 337.251177 s\n",
      "\n",
      "2021-10-27 11:48:50.522283: \n",
      "epoch:  66\n",
      "2021-10-27 11:54:03.555506: train loss : -0.8562\n",
      "2021-10-27 11:54:22.258310: validation loss: -0.8702\n",
      "2021-10-27 11:54:22.262454: Average global foreground Dice: [0.8829]\n",
      "2021-10-27 11:54:22.268714: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 11:54:22.760472: lr: 0.003687\n",
      "2021-10-27 11:54:22.819736: saving checkpoint...\n",
      "2021-10-27 11:54:24.596887: done, saving took 1.81 seconds\n",
      "2021-10-27 11:54:25.232934: This epoch took 334.704103 s\n",
      "\n",
      "2021-10-27 11:54:25.249432: \n",
      "epoch:  67\n",
      "2021-10-27 11:59:42.157796: train loss : -0.8541\n",
      "2021-10-27 12:00:02.854938: validation loss: -0.8631\n",
      "2021-10-27 12:00:02.861270: Average global foreground Dice: [0.8757]\n",
      "2021-10-27 12:00:02.870945: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:00:03.371450: lr: 0.003586\n",
      "2021-10-27 12:00:03.431118: saving checkpoint...\n",
      "2021-10-27 12:00:05.202545: done, saving took 1.80 seconds\n",
      "2021-10-27 12:00:05.837624: This epoch took 340.580344 s\n",
      "\n",
      "2021-10-27 12:00:05.855203: \n",
      "epoch:  68\n",
      "2021-10-27 12:05:24.565482: train loss : -0.8487\n",
      "2021-10-27 12:05:44.529098: validation loss: -0.8683\n",
      "2021-10-27 12:05:44.533028: Average global foreground Dice: [0.8801]\n",
      "2021-10-27 12:05:44.538918: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:05:45.037280: lr: 0.003485\n",
      "2021-10-27 12:05:45.096524: saving checkpoint...\n",
      "2021-10-27 12:05:46.892235: done, saving took 1.82 seconds\n",
      "2021-10-27 12:05:47.523133: This epoch took 341.661388 s\n",
      "\n",
      "2021-10-27 12:05:47.540433: \n",
      "epoch:  69\n",
      "2021-10-27 12:11:03.057410: train loss : -0.8538\n",
      "2021-10-27 12:11:23.696167: validation loss: -0.8691\n",
      "2021-10-27 12:11:23.700324: Average global foreground Dice: [0.8804]\n",
      "2021-10-27 12:11:23.706676: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:11:24.220681: lr: 0.003384\n",
      "2021-10-27 12:11:24.309613: saving checkpoint...\n",
      "2021-10-27 12:11:26.155128: done, saving took 1.91 seconds\n",
      "2021-10-27 12:11:26.897264: This epoch took 339.350504 s\n",
      "\n",
      "2021-10-27 12:11:26.914481: \n",
      "epoch:  70\n",
      "2021-10-27 12:16:43.645449: train loss : -0.8538\n",
      "2021-10-27 12:17:03.670887: validation loss: -0.8704\n",
      "2021-10-27 12:17:03.676153: Average global foreground Dice: [0.8806]\n",
      "2021-10-27 12:17:03.681938: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:17:04.252237: lr: 0.003282\n",
      "2021-10-27 12:17:04.314000: saving checkpoint...\n",
      "2021-10-27 12:17:06.122631: done, saving took 1.84 seconds\n",
      "2021-10-27 12:17:06.763932: This epoch took 339.842589 s\n",
      "\n",
      "2021-10-27 12:17:06.782110: \n",
      "epoch:  71\n",
      "2021-10-27 12:22:22.170742: train loss : -0.8540\n",
      "2021-10-27 12:22:42.626244: validation loss: -0.8631\n",
      "2021-10-27 12:22:42.630238: Average global foreground Dice: [0.8781]\n",
      "2021-10-27 12:22:42.636979: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:22:43.142190: lr: 0.00318\n",
      "2021-10-27 12:22:43.192255: saving checkpoint...\n",
      "2021-10-27 12:22:45.027963: done, saving took 1.86 seconds\n",
      "2021-10-27 12:22:45.679294: This epoch took 338.891024 s\n",
      "\n",
      "2021-10-27 12:22:45.687963: \n",
      "epoch:  72\n",
      "2021-10-27 12:28:01.945551: train loss : -0.8545\n",
      "2021-10-27 12:28:21.584784: validation loss: -0.8683\n",
      "2021-10-27 12:28:21.589278: Average global foreground Dice: [0.8823]\n",
      "2021-10-27 12:28:21.595505: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:28:22.093279: lr: 0.003078\n",
      "2021-10-27 12:28:22.142061: saving checkpoint...\n",
      "2021-10-27 12:28:23.908866: done, saving took 1.80 seconds\n",
      "2021-10-27 12:28:24.510803: This epoch took 338.816025 s\n",
      "\n",
      "2021-10-27 12:28:24.518760: \n",
      "epoch:  73\n",
      "2021-10-27 12:33:37.588612: train loss : -0.8574\n",
      "2021-10-27 12:33:56.867777: validation loss: -0.8723\n",
      "2021-10-27 12:33:56.872149: Average global foreground Dice: [0.8845]\n",
      "2021-10-27 12:33:56.877821: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:33:57.383963: lr: 0.002975\n",
      "2021-10-27 12:33:57.433038: saving checkpoint...\n",
      "2021-10-27 12:33:59.212573: done, saving took 1.81 seconds\n",
      "2021-10-27 12:33:59.743454: This epoch took 335.218347 s\n",
      "\n",
      "2021-10-27 12:33:59.752434: \n",
      "epoch:  74\n",
      "2021-10-27 12:39:11.540598: train loss : -0.8568\n",
      "2021-10-27 12:39:30.190633: validation loss: -0.8713\n",
      "2021-10-27 12:39:30.194885: Average global foreground Dice: [0.8838]\n",
      "2021-10-27 12:39:30.201631: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:39:30.694888: lr: 0.002872\n",
      "2021-10-27 12:39:30.748963: saving checkpoint...\n",
      "2021-10-27 12:39:32.531494: done, saving took 1.81 seconds\n",
      "2021-10-27 12:39:32.757906: This epoch took 332.999312 s\n",
      "\n",
      "2021-10-27 12:39:32.766116: \n",
      "epoch:  75\n",
      "2021-10-27 12:44:45.755841: train loss : -0.8576\n",
      "2021-10-27 12:45:04.724397: validation loss: -0.8686\n",
      "2021-10-27 12:45:04.728333: Average global foreground Dice: [0.8813]\n",
      "2021-10-27 12:45:04.734457: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:45:05.243610: lr: 0.002768\n",
      "2021-10-27 12:45:05.333264: saving checkpoint...\n",
      "2021-10-27 12:45:07.161466: done, saving took 1.89 seconds\n",
      "2021-10-27 12:45:07.546731: This epoch took 334.774636 s\n",
      "\n",
      "2021-10-27 12:45:07.554703: \n",
      "epoch:  76\n",
      "2021-10-27 12:50:23.750068: train loss : -0.8564\n",
      "2021-10-27 12:50:43.216377: validation loss: -0.8755\n",
      "2021-10-27 12:50:43.220494: Average global foreground Dice: [0.8855]\n",
      "2021-10-27 12:50:43.225855: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:50:43.820287: lr: 0.002664\n",
      "2021-10-27 12:50:43.867823: saving checkpoint...\n",
      "2021-10-27 12:50:45.671129: done, saving took 1.83 seconds\n",
      "2021-10-27 12:50:46.267259: This epoch took 338.706201 s\n",
      "\n",
      "2021-10-27 12:50:46.275101: \n",
      "epoch:  77\n",
      "2021-10-27 12:56:01.783557: train loss : -0.8562\n",
      "2021-10-27 12:56:21.501432: validation loss: -0.8742\n",
      "2021-10-27 12:56:21.505505: Average global foreground Dice: [0.8858]\n",
      "2021-10-27 12:56:21.512621: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 12:56:22.016219: lr: 0.00256\n",
      "2021-10-27 12:56:22.068063: saving checkpoint...\n",
      "2021-10-27 12:56:23.869725: done, saving took 1.83 seconds\n",
      "2021-10-27 12:56:24.456137: This epoch took 338.174575 s\n",
      "\n",
      "2021-10-27 12:56:24.464145: \n",
      "epoch:  78\n",
      "2021-10-27 13:01:36.057728: train loss : -0.8594\n",
      "2021-10-27 13:01:57.203727: validation loss: -0.8703\n",
      "2021-10-27 13:01:57.207708: Average global foreground Dice: [0.8795]\n",
      "2021-10-27 13:01:57.213690: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:01:57.734782: lr: 0.002455\n",
      "2021-10-27 13:01:57.757955: This epoch took 333.287396 s\n",
      "\n",
      "2021-10-27 13:01:57.764135: \n",
      "epoch:  79\n",
      "2021-10-27 13:07:08.686100: train loss : -0.8602\n",
      "2021-10-27 13:07:27.360962: validation loss: -0.8764\n",
      "2021-10-27 13:07:27.365032: Average global foreground Dice: [0.8902]\n",
      "2021-10-27 13:07:27.371476: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:07:27.877257: lr: 0.002349\n",
      "2021-10-27 13:07:27.941766: saving checkpoint...\n",
      "2021-10-27 13:07:29.732624: done, saving took 1.82 seconds\n",
      "2021-10-27 13:07:29.999948: This epoch took 332.228988 s\n",
      "\n",
      "2021-10-27 13:07:30.008737: \n",
      "epoch:  80\n",
      "2021-10-27 13:12:43.658887: train loss : -0.8614\n",
      "2021-10-27 13:13:02.349518: validation loss: -0.8735\n",
      "2021-10-27 13:13:02.354912: Average global foreground Dice: [0.8852]\n",
      "2021-10-27 13:13:02.360782: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:13:02.863518: lr: 0.002243\n",
      "2021-10-27 13:13:02.923543: saving checkpoint...\n",
      "2021-10-27 13:13:04.697313: done, saving took 1.80 seconds\n",
      "2021-10-27 13:13:04.970594: This epoch took 334.955056 s\n",
      "\n",
      "2021-10-27 13:13:04.988238: \n",
      "epoch:  81\n",
      "2021-10-27 13:18:16.310612: train loss : -0.8632\n",
      "2021-10-27 13:18:35.361326: validation loss: -0.8632\n",
      "2021-10-27 13:18:35.365278: Average global foreground Dice: [0.875]\n",
      "2021-10-27 13:18:35.371450: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:18:35.865892: lr: 0.002137\n",
      "2021-10-27 13:18:35.900213: This epoch took 330.905383 s\n",
      "\n",
      "2021-10-27 13:18:35.906332: \n",
      "epoch:  82\n",
      "2021-10-27 13:23:54.874989: train loss : -0.8605\n",
      "2021-10-27 13:24:13.583668: validation loss: -0.8740\n",
      "2021-10-27 13:24:13.587970: Average global foreground Dice: [0.8872]\n",
      "2021-10-27 13:24:13.595030: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:24:14.091373: lr: 0.00203\n",
      "2021-10-27 13:24:14.156817: saving checkpoint...\n",
      "2021-10-27 13:24:16.029772: done, saving took 1.91 seconds\n",
      "2021-10-27 13:24:16.624587: This epoch took 340.712164 s\n",
      "\n",
      "2021-10-27 13:24:16.641407: \n",
      "epoch:  83\n",
      "2021-10-27 13:29:30.581821: train loss : -0.8617\n",
      "2021-10-27 13:29:49.317184: validation loss: -0.8743\n",
      "2021-10-27 13:29:49.321404: Average global foreground Dice: [0.8863]\n",
      "2021-10-27 13:29:49.327234: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:29:49.819613: lr: 0.001922\n",
      "2021-10-27 13:29:49.882658: saving checkpoint...\n",
      "2021-10-27 13:29:51.664496: done, saving took 1.81 seconds\n",
      "2021-10-27 13:29:52.297091: This epoch took 335.648651 s\n",
      "\n",
      "2021-10-27 13:29:52.313680: \n",
      "epoch:  84\n",
      "2021-10-27 13:35:08.645694: train loss : -0.8609\n",
      "2021-10-27 13:35:28.996273: validation loss: -0.8756\n",
      "2021-10-27 13:35:29.000255: Average global foreground Dice: [0.8879]\n",
      "2021-10-27 13:35:29.006764: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:35:29.496705: lr: 0.001813\n",
      "2021-10-27 13:35:29.558200: saving checkpoint...\n",
      "2021-10-27 13:35:31.365227: done, saving took 1.84 seconds\n",
      "2021-10-27 13:35:32.068063: This epoch took 339.748055 s\n",
      "\n",
      "2021-10-27 13:35:32.086602: \n",
      "epoch:  85\n",
      "2021-10-27 13:40:44.242605: train loss : -0.8619\n",
      "2021-10-27 13:41:04.068329: validation loss: -0.8791\n",
      "2021-10-27 13:41:04.073794: Average global foreground Dice: [0.8904]\n",
      "2021-10-27 13:41:04.079887: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:41:04.581499: lr: 0.001704\n",
      "2021-10-27 13:41:04.642407: saving checkpoint...\n",
      "2021-10-27 13:41:06.465482: done, saving took 1.85 seconds\n",
      "2021-10-27 13:41:07.080846: This epoch took 334.987244 s\n",
      "\n",
      "2021-10-27 13:41:07.097704: \n",
      "epoch:  86\n",
      "2021-10-27 13:46:19.090565: train loss : -0.8609\n",
      "2021-10-27 13:46:37.827404: validation loss: -0.8751\n",
      "2021-10-27 13:46:37.831453: Average global foreground Dice: [0.8851]\n",
      "2021-10-27 13:46:37.837800: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:46:38.335802: lr: 0.001594\n",
      "2021-10-27 13:46:38.432265: saving checkpoint...\n",
      "2021-10-27 13:46:40.237931: done, saving took 1.86 seconds\n",
      "2021-10-27 13:46:40.852673: This epoch took 333.748409 s\n",
      "\n",
      "2021-10-27 13:46:40.869420: \n",
      "epoch:  87\n",
      "2021-10-27 13:51:58.652572: train loss : -0.8624\n",
      "2021-10-27 13:52:19.985733: validation loss: -0.8732\n",
      "2021-10-27 13:52:20.349074: Average global foreground Dice: [0.8875]\n",
      "2021-10-27 13:52:20.555278: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:52:21.499212: lr: 0.001483\n",
      "2021-10-27 13:52:21.613147: saving checkpoint...\n",
      "2021-10-27 13:52:23.546669: done, saving took 2.01 seconds\n",
      "2021-10-27 13:52:24.192923: This epoch took 343.317061 s\n",
      "\n",
      "2021-10-27 13:52:24.209433: \n",
      "epoch:  88\n",
      "2021-10-27 13:57:41.732277: train loss : -0.8616\n",
      "2021-10-27 13:58:02.602819: validation loss: -0.8777\n",
      "2021-10-27 13:58:02.607138: Average global foreground Dice: [0.8905]\n",
      "2021-10-27 13:58:02.614340: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 13:58:03.140560: lr: 0.001372\n",
      "2021-10-27 13:58:03.245350: saving checkpoint...\n",
      "2021-10-27 13:58:05.124903: done, saving took 1.95 seconds\n",
      "2021-10-27 13:58:05.700750: This epoch took 341.484436 s\n",
      "\n",
      "2021-10-27 13:58:05.718751: \n",
      "epoch:  89\n",
      "2021-10-27 14:03:18.176409: train loss : -0.8620\n",
      "2021-10-27 14:03:37.700831: validation loss: -0.8815\n",
      "2021-10-27 14:03:37.705068: Average global foreground Dice: [0.8919]\n",
      "2021-10-27 14:03:37.711113: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:03:38.225982: lr: 0.001259\n",
      "2021-10-27 14:03:38.336688: saving checkpoint...\n",
      "2021-10-27 14:03:40.164346: done, saving took 1.90 seconds\n",
      "2021-10-27 14:03:41.016505: This epoch took 335.290967 s\n",
      "\n",
      "2021-10-27 14:03:41.035963: \n",
      "epoch:  90\n",
      "2021-10-27 14:08:52.249756: train loss : -0.8653\n",
      "2021-10-27 14:09:13.614411: validation loss: -0.8812\n",
      "2021-10-27 14:09:13.618294: Average global foreground Dice: [0.8897]\n",
      "2021-10-27 14:09:13.624521: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:09:14.133039: lr: 0.001145\n",
      "2021-10-27 14:09:14.254064: saving checkpoint...\n",
      "2021-10-27 14:09:16.093049: done, saving took 1.90 seconds\n",
      "2021-10-27 14:09:16.844113: This epoch took 335.801644 s\n",
      "\n",
      "2021-10-27 14:09:16.862835: \n",
      "epoch:  91\n",
      "2021-10-27 14:14:29.073007: train loss : -0.8642\n",
      "2021-10-27 14:14:47.938326: validation loss: -0.8793\n",
      "2021-10-27 14:14:47.942386: Average global foreground Dice: [0.8922]\n",
      "2021-10-27 14:14:47.976056: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:14:48.481653: lr: 0.00103\n",
      "2021-10-27 14:14:48.583026: saving checkpoint...\n",
      "2021-10-27 14:14:50.443642: done, saving took 1.92 seconds\n",
      "2021-10-27 14:14:51.357242: This epoch took 334.487264 s\n",
      "\n",
      "2021-10-27 14:14:51.378350: \n",
      "epoch:  92\n",
      "2021-10-27 14:20:05.506632: train loss : -0.8660\n",
      "2021-10-27 14:20:26.070569: validation loss: -0.8811\n",
      "2021-10-27 14:20:26.074580: Average global foreground Dice: [0.8938]\n",
      "2021-10-27 14:20:26.081363: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:20:26.583857: lr: 0.000913\n",
      "2021-10-27 14:20:26.673201: saving checkpoint...\n",
      "2021-10-27 14:20:28.515493: done, saving took 1.90 seconds\n",
      "2021-10-27 14:20:29.397102: This epoch took 338.011880 s\n",
      "\n",
      "2021-10-27 14:20:29.415392: \n",
      "epoch:  93\n",
      "2021-10-27 14:25:41.560245: train loss : -0.8649\n",
      "2021-10-27 14:26:01.539243: validation loss: -0.8791\n",
      "2021-10-27 14:26:01.543417: Average global foreground Dice: [0.893]\n",
      "2021-10-27 14:26:01.550516: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:26:02.043810: lr: 0.000795\n",
      "2021-10-27 14:26:02.110137: saving checkpoint...\n",
      "2021-10-27 14:26:03.957816: done, saving took 1.88 seconds\n",
      "2021-10-27 14:26:04.650072: This epoch took 335.227920 s\n",
      "\n",
      "2021-10-27 14:26:04.669096: \n",
      "epoch:  94\n",
      "2021-10-27 14:31:24.676731: train loss : -0.8671\n",
      "2021-10-27 14:31:44.173751: validation loss: -0.8787\n",
      "2021-10-27 14:31:44.177874: Average global foreground Dice: [0.8883]\n",
      "2021-10-27 14:31:44.184414: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:31:44.693813: lr: 0.000675\n",
      "2021-10-27 14:31:44.760379: saving checkpoint...\n",
      "2021-10-27 14:31:46.668366: done, saving took 1.94 seconds\n",
      "2021-10-27 14:31:47.374394: This epoch took 342.698364 s\n",
      "\n",
      "2021-10-27 14:31:47.393735: \n",
      "epoch:  95\n",
      "2021-10-27 14:37:02.372414: train loss : -0.8666\n",
      "2021-10-27 14:37:22.570345: validation loss: -0.8764\n",
      "2021-10-27 14:37:22.577744: Average global foreground Dice: [0.8895]\n",
      "2021-10-27 14:37:22.587365: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:37:23.085510: lr: 0.000552\n",
      "2021-10-27 14:37:23.198147: saving checkpoint...\n",
      "2021-10-27 14:37:25.043677: done, saving took 1.92 seconds\n",
      "2021-10-27 14:37:25.717177: This epoch took 338.316833 s\n",
      "\n",
      "2021-10-27 14:37:25.736930: \n",
      "epoch:  96\n",
      "2021-10-27 14:42:41.746002: train loss : -0.8658\n",
      "2021-10-27 14:43:02.274456: validation loss: -0.8824\n",
      "2021-10-27 14:43:02.278812: Average global foreground Dice: [0.893]\n",
      "2021-10-27 14:43:02.285393: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:43:02.801658: lr: 0.000426\n",
      "2021-10-27 14:43:02.894938: saving checkpoint...\n",
      "2021-10-27 14:43:04.760830: done, saving took 1.94 seconds\n",
      "2021-10-27 14:43:05.407601: This epoch took 339.663821 s\n",
      "\n",
      "2021-10-27 14:43:05.415432: \n",
      "epoch:  97\n",
      "2021-10-27 14:48:27.766203: train loss : -0.8642\n",
      "2021-10-27 14:48:48.991311: validation loss: -0.8798\n",
      "2021-10-27 14:48:49.013809: Average global foreground Dice: [0.8912]\n",
      "2021-10-27 14:48:49.022711: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:48:49.593659: lr: 0.000296\n",
      "2021-10-27 14:48:49.687172: saving checkpoint...\n",
      "2021-10-27 14:48:52.412832: done, saving took 2.78 seconds\n",
      "2021-10-27 14:48:53.080795: This epoch took 347.658721 s\n",
      "\n",
      "2021-10-27 14:48:53.089255: \n",
      "epoch:  98\n",
      "2021-10-27 14:54:06.714407: train loss : -0.8654\n",
      "2021-10-27 14:54:25.596044: validation loss: -0.8822\n",
      "2021-10-27 14:54:25.600147: Average global foreground Dice: [0.8906]\n",
      "2021-10-27 14:54:25.608914: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 14:54:26.114146: lr: 0.000158\n",
      "2021-10-27 14:54:26.200789: saving checkpoint...\n",
      "2021-10-27 14:54:28.042169: done, saving took 1.90 seconds\n",
      "2021-10-27 14:54:28.676009: This epoch took 335.576707 s\n",
      "\n",
      "2021-10-27 14:54:28.685182: \n",
      "epoch:  99\n",
      "2021-10-27 14:59:48.362208: train loss : -0.8679\n",
      "2021-10-27 15:00:08.883269: validation loss: -0.8766\n",
      "2021-10-27 15:00:08.888633: Average global foreground Dice: [0.8892]\n",
      "2021-10-27 15:00:08.897219: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-27 15:00:09.413488: lr: 0.0\n",
      "2021-10-27 15:00:09.457190: saving scheduled checkpoint file...\n",
      "2021-10-27 15:00:09.543148: saving checkpoint...\n",
      "2021-10-27 15:00:11.348438: done, saving took 1.87 seconds\n",
      "2021-10-27 15:00:12.005667: done\n",
      "2021-10-27 15:00:12.042743: saving checkpoint...\n",
      "2021-10-27 15:00:13.834539: done, saving took 1.82 seconds\n",
      "2021-10-27 15:00:14.481227: This epoch took 345.786126 s\n",
      "\n",
      "2021-10-27 15:00:14.518106: saving checkpoint...\n",
      "2021-10-27 15:00:16.030301: done, saving took 1.54 seconds\n",
      "23090557_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090558_20120 (3, 263, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 263, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 7], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090559_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090560_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090562_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090563_20151 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090564_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090566_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090567_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090568_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090569_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090571_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090584_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090589_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090590_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090592_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090593_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090596_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090597_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090599_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090600_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090603_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090604_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090607_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090608_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090609_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090614_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090615_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090616_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090617_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090619_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090620_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090621_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090627_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090628_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090629_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090631_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090634_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090635_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090636_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090637_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090640_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090644_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 335, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 79], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090646_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (2, 299, 128, 128)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 43], [0, 32], [0, 32]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-27 15:17:38.215724: finished prediction\n",
      "2021-10-27 15:17:38.223844: evaluation of raw predictions\n",
      "2021-10-27 15:17:43.813130: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8937433343947685\n",
      "after:  0.8937433343947685\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_Dice.nnUNetTrainerV2_Loss_Dice'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-28 01:31:33.714862: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-28 01:31:45.085984: Unable to plot network architecture:\n",
      "2021-10-28 01:31:45.168310: No module named 'hiddenlayer'\n",
      "2021-10-28 01:31:45.292345: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-28 01:31:45.400444: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-28 01:31:45.554313: \n",
      "\n",
      "2021-10-28 01:31:45.670323: \n",
      "epoch:  0\n",
      "2021-10-28 01:34:53.964792: train loss : -0.0085\n",
      "2021-10-28 01:35:07.892648: validation loss: -0.0199\n",
      "2021-10-28 01:35:07.896813: Average global foreground Dice: [0.0457]\n",
      "2021-10-28 01:35:07.902269: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 01:35:08.316510: lr: 0.00991\n",
      "2021-10-28 01:35:08.345143: This epoch took 202.574508 s\n",
      "\n",
      "2021-10-28 01:35:08.351142: \n",
      "epoch:  1\n",
      "2021-10-28 01:38:20.372456: train loss : -0.3173\n",
      "2021-10-28 01:38:34.339257: validation loss: -0.5889\n",
      "2021-10-28 01:38:34.343286: Average global foreground Dice: [0.7331]\n",
      "2021-10-28 01:38:34.350421: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-28 01:38:34.896802: failed to log:  (<class 'OSError'>, OSError(107, 'Transport endpoint is not connected'), <traceback object at 0x7f0b78b04840>)\n",
      "2021-10-28 01:38:34.896802: failed to log:  (<class 'OSError'>, OSError(107, 'Transport endpoint is not connected'), <traceback object at 0x7f0b78b04840>)\n",
      "2021-10-28 01:38:34.896802: failed to log:  (<class 'OSError'>, OSError(107, 'Transport endpoint is not connected'), <traceback object at 0x7f0b78b04840>)\n",
      "2021-10-28 01:38:34.896802: failed to log:  (<class 'OSError'>, OSError(107, 'Transport endpoint is not connected'), <traceback object at 0x7f0b78b04840>)\n",
      "2021-10-28 01:38:34.896802: failed to log:  (<class 'OSError'>, OSError(107, 'Transport endpoint is not connected'), <traceback object at 0x7f0b78b04840>)\n",
      "2021-10-28 01:38:34.896802: failed to plot:  (<class 'OSError'>, OSError(107, 'Transport endpoint is not connected'), <traceback object at 0x7f0b78b048c0>)\n",
      "2021-10-28 01:38:37.399912: failed to log:  (<class 'OSError'>, OSError(107, 'Transport endpoint is not connected'), <traceback object at 0x7f0a8edf1b40>)\n",
      "2021-10-28 01:38:37.399912: failed to log:  (<class 'OSError'>, OSError(107, 'Transport endpoint is not connected'), <traceback object at 0x7f0a8edf1b40>)\n",
      "2021-10-28 01:38:37.399912: failed to log:  (<class 'OSError'>, OSError(107, 'Transport endpoint is not connected'), <traceback object at 0x7f0a8edf1b40>)\n",
      "2021-10-28 01:38:37.399912: failed to log:  (<class 'OSError'>, OSError(107, 'Transport endpoint is not connected'), <traceback object at 0x7f0a8edf1b40>)\n",
      "2021-10-28 01:38:37.399912: failed to log:  (<class 'OSError'>, OSError(107, 'Transport endpoint is not connected'), <traceback object at 0x7f0a8edf1b40>)\n",
      "2021-10-28 01:38:37.399912: lr: 0.00982\n",
      "2021-10-28 01:38:39.945888: failed to log:  (<class 'OSError'>, OSError(107, 'Transport endpoint is not connected'), <traceback object at 0x7f0b78afb180>)\n",
      "2021-10-28 01:38:39.945888: failed to log:  (<class 'OSError'>, OSError(107, 'Transport endpoint is not connected'), <traceback object at 0x7f0b78afb180>)\n",
      "2021-10-28 01:38:39.945888: failed to log:  (<class 'OSError'>, OSError(107, 'Transport endpoint is not connected'), <traceback object at 0x7f0b78afb180>)\n",
      "2021-10-28 01:38:39.945888: failed to log:  (<class 'OSError'>, OSError(107, 'Transport endpoint is not connected'), <traceback object at 0x7f0b78afb180>)\n",
      "2021-10-28 01:38:39.945888: failed to log:  (<class 'OSError'>, OSError(107, 'Transport endpoint is not connected'), <traceback object at 0x7f0b78afb180>)\n",
      "2021-10-28 01:38:39.945888: saving checkpoint...\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNet_train\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_train')())\n",
      "  File \"/mnt/backup/nnUNet/nnunet/run/run_training.py\", line 179, in main\n",
      "  File \"/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py\", line 440, in run_training\n",
      "  File \"/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainer.py\", line 317, in run_training\n",
      "  File \"/mnt/backup/nnUNet/nnunet/training/network_training/network_trainer.py\", line 484, in run_training\n",
      "  File \"/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py\", line 413, in on_epoch_end\n",
      "  File \"/mnt/backup/nnUNet/nnunet/training/network_training/network_trainer.py\", line 617, in on_epoch_end\n",
      "  File \"/mnt/backup/nnUNet/nnunet/training/network_training/network_trainer.py\", line 577, in manage_patience\n",
      "  File \"/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainer.py\", line 727, in save_checkpoint\n",
      "  File \"/mnt/backup/nnUNet/nnunet/training/network_training/network_trainer.py\", line 287, in save_checkpoint\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 376, in save\n",
      "    with _open_file_like(f, 'wb') as opened_file:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "OSError: [Errno 107] Transport endpoint is not connected: '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2_Loss_Dice__nnUNetPlansv2.1/all/model_best.model'\n",
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/batchgenerators/dataloading/multi_threaded_augmenter.py\", line 92, in results_loop\n",
      "    raise RuntimeError(\"Abort event was set. So someone died and we should end this madness. \\nIMPORTANT: \"\n",
      "RuntimeError: Abort event was set. So someone died and we should end this madness. \n",
      "IMPORTANT: This is not the actual error message! Look further up to see what caused the error. Please also check whether your RAM was full\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/batchgenerators/dataloading/multi_threaded_augmenter.py\", line 92, in results_loop\n",
      "    raise RuntimeError(\"Abort event was set. So someone died and we should end this madness. \\nIMPORTANT: \"\n",
      "RuntimeError: Abort event was set. So someone died and we should end this madness. \n",
      "IMPORTANT: This is not the actual error message! Look further up to see what caused the error. Please also check whether your RAM was full\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_Dice 555 all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNet_train\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_train')())\n",
      "  File \"/mnt/backup/nnUNet/nnunet/run/run_training.py\", line 137, in main\n",
      "    trainer_class = get_default_configuration(network, task, network_trainer, plans_identifier)\n",
      "  File \"/mnt/backup/nnUNet/nnunet/run/default_configuration.py\", line 47, in get_default_configuration\n",
      "    plans = load_pickle(plans_file)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/batchgenerators/utilities/file_and_folder_operations.py\", line 57, in load_pickle\n",
      "    with open(file, mode) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetPlansv2.1_plans_2D.pkl'\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNet_train\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_train')())\n",
      "  File \"/mnt/backup/nnUNet/nnunet/run/run_training.py\", line 137, in main\n",
      "    trainer_class = get_default_configuration(network, task, network_trainer, plans_identifier)\n",
      "  File \"/mnt/backup/nnUNet/nnunet/run/default_configuration.py\", line 47, in get_default_configuration\n",
      "    plans = load_pickle(plans_file)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/batchgenerators/utilities/file_and_folder_operations.py\", line 57, in load_pickle\n",
      "    with open(file, mode) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetPlansv2.1_plans_2D.pkl'\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNet_train\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_train')())\n",
      "  File \"/mnt/backup/nnUNet/nnunet/run/run_training.py\", line 137, in main\n",
      "    trainer_class = get_default_configuration(network, task, network_trainer, plans_identifier)\n",
      "  File \"/mnt/backup/nnUNet/nnunet/run/default_configuration.py\", line 47, in get_default_configuration\n",
      "    plans = load_pickle(plans_file)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/batchgenerators/utilities/file_and_folder_operations.py\", line 57, in load_pickle\n",
      "    with open(file, mode) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetPlansv2.1_plans_2D.pkl'\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNet_train\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_train')())\n",
      "  File \"/mnt/backup/nnUNet/nnunet/run/run_training.py\", line 137, in main\n",
      "    trainer_class = get_default_configuration(network, task, network_trainer, plans_identifier)\n",
      "  File \"/mnt/backup/nnUNet/nnunet/run/default_configuration.py\", line 47, in get_default_configuration\n",
      "    plans = load_pickle(plans_file)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/batchgenerators/utilities/file_and_folder_operations.py\", line 57, in load_pickle\n",
      "    with open(file, mode) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetPlansv2.1_plans_2D.pkl'\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNet_train\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_train')())\n",
      "  File \"/mnt/backup/nnUNet/nnunet/run/run_training.py\", line 137, in main\n",
      "    trainer_class = get_default_configuration(network, task, network_trainer, plans_identifier)\n",
      "  File \"/mnt/backup/nnUNet/nnunet/run/default_configuration.py\", line 47, in get_default_configuration\n",
      "    plans = load_pickle(plans_file)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/batchgenerators/utilities/file_and_folder_operations.py\", line 57, in load_pickle\n",
      "    with open(file, mode) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetPlansv2.1_plans_2D.pkl'\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNet_train\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_train')())\n",
      "  File \"/mnt/backup/nnUNet/nnunet/run/run_training.py\", line 137, in main\n",
      "    trainer_class = get_default_configuration(network, task, network_trainer, plans_identifier)\n",
      "  File \"/mnt/backup/nnUNet/nnunet/run/default_configuration.py\", line 47, in get_default_configuration\n",
      "    plans = load_pickle(plans_file)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/batchgenerators/utilities/file_and_folder_operations.py\", line 57, in load_pickle\n",
      "    with open(file, mode) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetPlansv2.1_plans_3D.pkl'\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'child' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpexpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Vanilla Pexpect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mflush\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command, args, timeout, maxread, searchwindowsize, logfile, cwd, env, ignore_sighup, echo, preexec_fn, encoding, codec_errors, dimensions, use_poll)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreexec_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_poll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_poll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawn\u001b[0;34m(self, command, args, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         self.ptyproc = self._spawnpty(self.args, env=self.env,\n\u001b[0m\u001b[1;32m    304\u001b[0m                                      cwd=self.cwd, **kwargs)\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawnpty\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;34m'''Spawn a pty and return an instance of PtyProcess.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mptyprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPtyProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ptyprocess/ptyprocess.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(cls, argv, cwd, env, echo, preexec_fn, dimensions, pass_fds)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_err_pipe_write\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mexec_err_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_err_pipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_err_pipe_read\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-28293dc1b02a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nnUNet_train 3d_fullres nnUNetTrainerV2 555 0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nnUNet_train 3d_fullres nnUNetTrainerV2 555 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nnUNet_train 3d_fullres nnUNetTrainerV2 555 2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nnUNet_train 3d_fullres nnUNetTrainerV2 555 3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m   2498\u001b[0m         \u001b[0;31m# a non-None value would trigger :func:`sys.displayhook` calls.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2499\u001b[0m         \u001b[0;31m# Instead, we store the exit_code in user_ns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2500\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2502\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msystem_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;31m# (the character is known as ETX for 'End of Text', see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;31m# curses.ascii.ETX).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;31m# Read and print any more output the program might produce on its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;31m# way out.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'child' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Model 1\n",
    "# os.chdir(main_dir)\n",
    "\n",
    "# !nnUNet_train 2d nnUNetTrainerV2 555 0\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 1\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 2\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 3\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 4\n",
    "\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 0\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 1\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 2\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 3\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 4\n",
    "\n",
    "# os.chdir(base_dir)\n",
    "\n",
    "# !nnUNet_predict -i /mnt/temp/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data/Task555_PETCT/imagesTs/ -o /mnt/backup/working/nnUNet/nnunet/nnUNet_Prediction_Results/Task555_PETCT/2d_CEGDL/ -t 577 -tr nnUNetTrainerV2_Loss_CEGDL -m 2d --disable_tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "using model stored in  /mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1\n",
      "This model expects 2 input modalities for each image\n",
      "Found 1 unique case ids, here are some examples: ['23010018_20141226']\n",
      "If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc\n",
      "number of cases: 1\n",
      "number of cases that still need to be predicted: 1\n",
      "emptying cuda cache\n",
      "loading parameters for folds, None\n",
      "folds is None so we will automatically look for output folders (not using 'all'!)\n",
      "found the following folds:  ['/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4']\n",
      "using the following model files:  ['/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4/model_final_checkpoint.model']\n",
      "starting preprocessing generator\n",
      "starting prediction...\n",
      "preprocessing /tf/2d_sample/23010018_20141226.nii.gz\n",
      "using preprocessor PreprocessorFor2D\n",
      "before crop: (2, 284, 200, 200) after crop: (2, 284, 173, 173) spacing: [1. 1. 1.] \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 284, 173, 173)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 284, 173, 173)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "(2, 284, 173, 173)\n",
      "This worker has ended successfully, no errors to report\n",
      "predicting /tf/2d_sample/23010018_20141226.nii.gz\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "inference done. Now waiting for the segmentation export to finish...\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "WARNING! Cannot run postprocessing because the postprocessing file is missing. Make sure to run consolidate_folds in the output folder of the model first!\n",
      "The folder you need to run this in is /mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "using model stored in  /mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1\n",
      "This model expects 2 input modalities for each image\n",
      "Found 1 unique case ids, here are some examples: ['23010018_20141226']\n",
      "If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc\n",
      "number of cases: 1\n",
      "number of cases that still need to be predicted: 1\n",
      "emptying cuda cache\n",
      "loading parameters for folds, None\n",
      "folds is None so we will automatically look for output folders (not using 'all'!)\n",
      "found the following folds:  ['/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4']\n",
      "using the following model files:  ['/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4/model_final_checkpoint.model']\n",
      "starting preprocessing generator\n",
      "starting prediction...\n",
      "preprocessing /tf/3d_sample/23010018_20141226.nii.gz\n",
      "using preprocessor GenericPreprocessor\n",
      "before crop: (2, 284, 200, 200) after crop: (2, 284, 173, 173) spacing: [1. 1. 1.] \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 284, 173, 173)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 284, 173, 173)} \n",
      "\n",
      "(2, 284, 173, 173)\n",
      "This worker has ended successfully, no errors to report\n",
      "predicting /tf/3d_sample/23010018_20141226.nii.gz\n",
      "debug: mirroring False mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: False\n",
      "data shape: (2, 284, 173, 173)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 28], [0, 38, 77], [0, 38, 77]]\n",
      "number of tiles: 18\n",
      "computing Gaussian\n",
      "prediction done\n",
      "debug: mirroring False mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: False\n",
      "data shape: (2, 284, 173, 173)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 28], [0, 38, 77], [0, 38, 77]]\n",
      "number of tiles: 18\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "debug: mirroring False mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: False\n",
      "data shape: (2, 284, 173, 173)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 28], [0, 38, 77], [0, 38, 77]]\n",
      "number of tiles: 18\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "debug: mirroring False mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: False\n",
      "data shape: (2, 284, 173, 173)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 28], [0, 38, 77], [0, 38, 77]]\n",
      "number of tiles: 18\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "debug: mirroring False mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: False\n",
      "data shape: (2, 284, 173, 173)\n",
      "patch size: [256  96  96]\n",
      "steps (x, y, and z): [[0, 28], [0, 38, 77], [0, 38, 77]]\n",
      "number of tiles: 18\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "inference done. Now waiting for the segmentation export to finish...\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "WARNING! Cannot run postprocessing because the postprocessing file is missing. Make sure to run consolidate_folds in the output folder of the model first!\r\n",
      "The folder you need to run this in is /mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1\r\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_predict -i /tf/sample -o /tf/2d_sample/ -t 555 -tr nnUNetTrainerV2 -m 2d --disable_tta\n",
    "!nnUNet_predict -i /tf/sample -o /tf/3d_sample/ -t 555 -tr nnUNetTrainerV2 -m 3d_fullres --disable_tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-10-24 10:41:17.530384: Creating new 5-fold cross-validation split...\n",
      "2021-10-24 10:41:17.552254: Desired fold for training: 0\n",
      "2021-10-24 10:41:17.559065: This split has 40 training and 40 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-24 10:41:26.394751: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-24 10:41:36.594757: Unable to plot network architecture:\n",
      "2021-10-24 10:41:36.725125: No module named 'hiddenlayer'\n",
      "2021-10-24 10:41:36.848667: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-24 10:41:36.976663: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-24 10:41:37.166430: \n",
      "\n",
      "2021-10-24 10:41:37.285095: \n",
      "epoch:  0\n",
      "2021-10-24 10:44:46.063938: train loss : -0.2429\n",
      "2021-10-24 10:44:59.527561: validation loss: -0.6284\n",
      "2021-10-24 10:44:59.533731: Average global foreground Dice: [0.7059]\n",
      "2021-10-24 10:44:59.540667: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 10:44:59.999803: lr: 0.00982\n",
      "2021-10-24 10:45:00.016869: This epoch took 202.654157 s\n",
      "\n",
      "2021-10-24 10:45:00.024058: \n",
      "epoch:  1\n",
      "2021-10-24 10:47:59.006362: train loss : -0.6634\n",
      "2021-10-24 10:48:12.431507: validation loss: -0.7325\n",
      "2021-10-24 10:48:12.435939: Average global foreground Dice: [0.8017]\n",
      "2021-10-24 10:48:12.442757: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 10:48:12.984833: lr: 0.009639\n",
      "2021-10-24 10:48:13.053959: saving checkpoint...\n",
      "2021-10-24 10:48:14.003763: done, saving took 0.99 seconds\n",
      "2021-10-24 10:48:14.528953: This epoch took 194.498498 s\n",
      "\n",
      "2021-10-24 10:48:14.547295: \n",
      "epoch:  2\n",
      "2021-10-24 10:51:12.488868: train loss : -0.7656\n",
      "2021-10-24 10:51:25.910579: validation loss: -0.8046\n",
      "2021-10-24 10:51:25.917163: Average global foreground Dice: [0.8266]\n",
      "2021-10-24 10:51:25.923897: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 10:51:26.569456: lr: 0.009458\n",
      "2021-10-24 10:51:26.619889: saving checkpoint...\n",
      "2021-10-24 10:51:27.712971: done, saving took 1.11 seconds\n",
      "2021-10-24 10:51:28.202699: This epoch took 193.647921 s\n",
      "\n",
      "2021-10-24 10:51:28.219888: \n",
      "epoch:  3\n",
      "2021-10-24 10:54:25.712136: train loss : -0.8008\n",
      "2021-10-24 10:54:39.130751: validation loss: -0.8167\n",
      "2021-10-24 10:54:39.135186: Average global foreground Dice: [0.8344]\n",
      "2021-10-24 10:54:39.141755: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 10:54:39.678124: lr: 0.009277\n",
      "2021-10-24 10:54:39.747457: saving checkpoint...\n",
      "2021-10-24 10:54:40.850347: done, saving took 1.14 seconds\n",
      "2021-10-24 10:54:41.306365: This epoch took 193.080083 s\n",
      "\n",
      "2021-10-24 10:54:41.324924: \n",
      "epoch:  4\n",
      "2021-10-24 10:57:39.687553: train loss : -0.8145\n",
      "2021-10-24 10:57:53.177413: validation loss: -0.8139\n",
      "2021-10-24 10:57:53.183298: Average global foreground Dice: [0.8308]\n",
      "2021-10-24 10:57:53.190133: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 10:57:53.748195: lr: 0.009095\n",
      "2021-10-24 10:57:53.820045: saving checkpoint...\n",
      "2021-10-24 10:57:54.924407: done, saving took 1.14 seconds\n",
      "2021-10-24 10:57:55.685010: This epoch took 194.353788 s\n",
      "\n",
      "2021-10-24 10:57:55.705449: \n",
      "epoch:  5\n",
      "2021-10-24 11:00:54.091327: train loss : -0.8254\n",
      "2021-10-24 11:01:07.588946: validation loss: -0.8076\n",
      "2021-10-24 11:01:07.593099: Average global foreground Dice: [0.8232]\n",
      "2021-10-24 11:01:07.599639: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:01:08.098719: lr: 0.008913\n",
      "2021-10-24 11:01:08.140248: saving checkpoint...\n",
      "2021-10-24 11:01:09.214026: done, saving took 1.09 seconds\n",
      "2021-10-24 11:01:09.669068: This epoch took 193.957631 s\n",
      "\n",
      "2021-10-24 11:01:09.677526: \n",
      "epoch:  6\n",
      "2021-10-24 11:04:08.242592: train loss : -0.8336\n",
      "2021-10-24 11:04:21.757736: validation loss: -0.8228\n",
      "2021-10-24 11:04:21.762376: Average global foreground Dice: [0.8391]\n",
      "2021-10-24 11:04:21.768647: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:04:22.322287: lr: 0.008731\n",
      "2021-10-24 11:04:22.371044: saving checkpoint...\n",
      "2021-10-24 11:04:23.506667: done, saving took 1.16 seconds\n",
      "2021-10-24 11:04:23.952897: This epoch took 194.268546 s\n",
      "\n",
      "2021-10-24 11:04:23.961185: \n",
      "epoch:  7\n",
      "2021-10-24 11:07:22.540674: train loss : -0.8402\n",
      "2021-10-24 11:07:36.059767: validation loss: -0.8231\n",
      "2021-10-24 11:07:36.066867: Average global foreground Dice: [0.8363]\n",
      "2021-10-24 11:07:36.070904: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:07:36.604266: lr: 0.008548\n",
      "2021-10-24 11:07:36.655800: saving checkpoint...\n",
      "2021-10-24 11:07:37.808782: done, saving took 1.18 seconds\n",
      "2021-10-24 11:07:38.501275: This epoch took 194.533338 s\n",
      "\n",
      "2021-10-24 11:07:38.509340: \n",
      "epoch:  8\n",
      "2021-10-24 11:10:37.708094: train loss : -0.8439\n",
      "2021-10-24 11:10:51.211594: validation loss: -0.8208\n",
      "2021-10-24 11:10:51.215853: Average global foreground Dice: [0.8353]\n",
      "2021-10-24 11:10:51.222504: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:10:51.729414: lr: 0.008364\n",
      "2021-10-24 11:10:51.771959: saving checkpoint...\n",
      "2021-10-24 11:10:52.867378: done, saving took 1.11 seconds\n",
      "2021-10-24 11:10:53.350804: This epoch took 194.835327 s\n",
      "\n",
      "2021-10-24 11:10:53.358775: \n",
      "epoch:  9\n",
      "2021-10-24 11:13:52.353994: train loss : -0.8496\n",
      "2021-10-24 11:14:05.840366: validation loss: -0.8242\n",
      "2021-10-24 11:14:05.845122: Average global foreground Dice: [0.8389]\n",
      "2021-10-24 11:14:05.851219: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:14:06.351952: lr: 0.008181\n",
      "2021-10-24 11:14:06.394261: saving checkpoint...\n",
      "2021-10-24 11:14:07.481982: done, saving took 1.11 seconds\n",
      "2021-10-24 11:14:07.948627: This epoch took 194.583042 s\n",
      "\n",
      "2021-10-24 11:14:07.957515: \n",
      "epoch:  10\n",
      "2021-10-24 11:17:06.925238: train loss : -0.8542\n",
      "2021-10-24 11:17:20.434444: validation loss: -0.8180\n",
      "2021-10-24 11:17:20.439053: Average global foreground Dice: [0.8327]\n",
      "2021-10-24 11:17:20.446082: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:17:21.006571: lr: 0.007996\n",
      "2021-10-24 11:17:21.044064: saving checkpoint...\n",
      "2021-10-24 11:17:22.169806: done, saving took 1.14 seconds\n",
      "2021-10-24 11:17:22.623943: This epoch took 194.659315 s\n",
      "\n",
      "2021-10-24 11:17:22.634687: \n",
      "epoch:  11\n",
      "2021-10-24 11:20:21.758855: train loss : -0.8569\n",
      "2021-10-24 11:20:35.273767: validation loss: -0.8192\n",
      "2021-10-24 11:20:35.278338: Average global foreground Dice: [0.8329]\n",
      "2021-10-24 11:20:35.297875: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:20:35.845567: lr: 0.007811\n",
      "2021-10-24 11:20:35.903039: saving checkpoint...\n",
      "2021-10-24 11:20:37.034940: done, saving took 1.17 seconds\n",
      "2021-10-24 11:20:37.488809: This epoch took 194.847810 s\n",
      "\n",
      "2021-10-24 11:20:37.498241: \n",
      "epoch:  12\n",
      "2021-10-24 11:23:36.683834: train loss : -0.8609\n",
      "2021-10-24 11:23:50.209072: validation loss: -0.8266\n",
      "2021-10-24 11:23:50.215249: Average global foreground Dice: [0.8397]\n",
      "2021-10-24 11:23:50.222142: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:23:50.765050: lr: 0.007626\n",
      "2021-10-24 11:23:50.811469: saving checkpoint...\n",
      "2021-10-24 11:23:51.941480: done, saving took 1.15 seconds\n",
      "2021-10-24 11:23:52.410031: This epoch took 194.905041 s\n",
      "\n",
      "2021-10-24 11:23:52.418665: \n",
      "epoch:  13\n",
      "2021-10-24 11:26:51.664809: train loss : -0.8629\n",
      "2021-10-24 11:27:05.144647: validation loss: -0.8240\n",
      "2021-10-24 11:27:05.148889: Average global foreground Dice: [0.8384]\n",
      "2021-10-24 11:27:05.156318: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:27:05.754862: lr: 0.00744\n",
      "2021-10-24 11:27:05.797117: saving checkpoint...\n",
      "2021-10-24 11:27:06.881797: done, saving took 1.10 seconds\n",
      "2021-10-24 11:27:07.349966: This epoch took 194.923394 s\n",
      "\n",
      "2021-10-24 11:27:07.358560: \n",
      "epoch:  14\n",
      "2021-10-24 11:30:06.591059: train loss : -0.8651\n",
      "2021-10-24 11:30:20.088139: validation loss: -0.8308\n",
      "2021-10-24 11:30:20.092532: Average global foreground Dice: [0.844]\n",
      "2021-10-24 11:30:20.099876: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:30:20.617631: lr: 0.007254\n",
      "2021-10-24 11:30:20.660104: saving checkpoint...\n",
      "2021-10-24 11:30:21.736314: done, saving took 1.10 seconds\n",
      "2021-10-24 11:30:22.164234: This epoch took 194.798321 s\n",
      "\n",
      "2021-10-24 11:30:22.173383: \n",
      "epoch:  15\n",
      "2021-10-24 11:33:21.695371: train loss : -0.8670\n",
      "2021-10-24 11:33:35.198244: validation loss: -0.8216\n",
      "2021-10-24 11:33:35.202698: Average global foreground Dice: [0.8349]\n",
      "2021-10-24 11:33:35.208903: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:33:35.750308: lr: 0.007067\n",
      "2021-10-24 11:33:35.789441: saving checkpoint...\n",
      "2021-10-24 11:33:36.859804: done, saving took 1.09 seconds\n",
      "2021-10-24 11:33:37.357631: This epoch took 195.176616 s\n",
      "\n",
      "2021-10-24 11:33:37.366076: \n",
      "epoch:  16\n",
      "2021-10-24 11:36:37.107399: train loss : -0.8693\n",
      "2021-10-24 11:36:50.624498: validation loss: -0.8187\n",
      "2021-10-24 11:36:50.629404: Average global foreground Dice: [0.8302]\n",
      "2021-10-24 11:36:50.635949: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:36:51.202266: lr: 0.00688\n",
      "2021-10-24 11:36:51.246199: saving checkpoint...\n",
      "2021-10-24 11:36:52.402948: done, saving took 1.18 seconds\n",
      "2021-10-24 11:36:52.859659: This epoch took 195.486957 s\n",
      "\n",
      "2021-10-24 11:36:52.867492: \n",
      "epoch:  17\n",
      "2021-10-24 11:39:52.621273: train loss : -0.8720\n",
      "2021-10-24 11:40:06.151651: validation loss: -0.8280\n",
      "2021-10-24 11:40:06.155945: Average global foreground Dice: [0.8398]\n",
      "2021-10-24 11:40:06.163048: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:40:06.674631: lr: 0.006692\n",
      "2021-10-24 11:40:06.712574: saving checkpoint...\n",
      "2021-10-24 11:40:07.841662: done, saving took 1.15 seconds\n",
      "2021-10-24 11:40:08.363688: This epoch took 195.489536 s\n",
      "\n",
      "2021-10-24 11:40:08.372579: \n",
      "epoch:  18\n",
      "2021-10-24 11:43:08.127904: train loss : -0.8735\n",
      "2021-10-24 11:43:21.632085: validation loss: -0.8214\n",
      "2021-10-24 11:43:21.636242: Average global foreground Dice: [0.8347]\n",
      "2021-10-24 11:43:21.643111: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:43:22.189233: lr: 0.006504\n",
      "2021-10-24 11:43:22.253289: saving checkpoint...\n",
      "2021-10-24 11:43:23.413907: done, saving took 1.19 seconds\n",
      "2021-10-24 11:43:23.874923: This epoch took 195.495360 s\n",
      "\n",
      "2021-10-24 11:43:23.894519: \n",
      "epoch:  19\n",
      "2021-10-24 11:46:23.747987: train loss : -0.8759\n",
      "2021-10-24 11:46:37.276960: validation loss: -0.8298\n",
      "2021-10-24 11:46:37.281265: Average global foreground Dice: [0.8423]\n",
      "2021-10-24 11:46:37.287560: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:46:37.801247: lr: 0.006314\n",
      "2021-10-24 11:46:37.855013: saving checkpoint...\n",
      "2021-10-24 11:46:38.976715: done, saving took 1.14 seconds\n",
      "2021-10-24 11:46:39.563599: This epoch took 195.662594 s\n",
      "\n",
      "2021-10-24 11:46:39.581393: \n",
      "epoch:  20\n",
      "2021-10-24 11:49:39.410604: train loss : -0.8768\n",
      "2021-10-24 11:49:52.931951: validation loss: -0.8152\n",
      "2021-10-24 11:49:52.938014: Average global foreground Dice: [0.8269]\n",
      "2021-10-24 11:49:52.944830: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:49:53.488292: lr: 0.006125\n",
      "2021-10-24 11:49:53.539789: saving checkpoint...\n",
      "2021-10-24 11:49:54.599390: done, saving took 1.08 seconds\n",
      "2021-10-24 11:49:55.064709: This epoch took 195.475034 s\n",
      "\n",
      "2021-10-24 11:49:55.084599: \n",
      "epoch:  21\n",
      "2021-10-24 11:52:54.866449: train loss : -0.8774\n",
      "2021-10-24 11:53:08.381022: validation loss: -0.8271\n",
      "2021-10-24 11:53:08.385345: Average global foreground Dice: [0.8396]\n",
      "2021-10-24 11:53:08.393133: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:53:08.938925: lr: 0.005934\n",
      "2021-10-24 11:53:08.988194: saving checkpoint...\n",
      "2021-10-24 11:53:10.095807: done, saving took 1.13 seconds\n",
      "2021-10-24 11:53:10.690241: This epoch took 195.597764 s\n",
      "\n",
      "2021-10-24 11:53:10.708832: \n",
      "epoch:  22\n",
      "2021-10-24 11:56:10.498618: train loss : -0.8797\n",
      "2021-10-24 11:56:24.006025: validation loss: -0.8341\n",
      "2021-10-24 11:56:24.010350: Average global foreground Dice: [0.8458]\n",
      "2021-10-24 11:56:24.017565: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:56:24.589038: lr: 0.005743\n",
      "2021-10-24 11:56:24.650965: saving checkpoint...\n",
      "2021-10-24 11:56:25.732804: done, saving took 1.11 seconds\n",
      "2021-10-24 11:56:26.161520: This epoch took 195.445794 s\n",
      "\n",
      "2021-10-24 11:56:26.179568: \n",
      "epoch:  23\n",
      "2021-10-24 11:59:25.826359: train loss : -0.8812\n",
      "2021-10-24 11:59:39.326884: validation loss: -0.8275\n",
      "2021-10-24 11:59:39.331336: Average global foreground Dice: [0.8427]\n",
      "2021-10-24 11:59:39.337463: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 11:59:39.886425: lr: 0.005551\n",
      "2021-10-24 11:59:39.940508: saving checkpoint...\n",
      "2021-10-24 11:59:41.056011: done, saving took 1.13 seconds\n",
      "2021-10-24 11:59:41.510773: This epoch took 195.324583 s\n",
      "\n",
      "2021-10-24 11:59:41.529165: \n",
      "epoch:  24\n",
      "2021-10-24 12:02:41.631804: train loss : -0.8816\n",
      "2021-10-24 12:02:55.142759: validation loss: -0.8302\n",
      "2021-10-24 12:02:55.147366: Average global foreground Dice: [0.8443]\n",
      "2021-10-24 12:02:55.153354: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:02:55.789290: lr: 0.005359\n",
      "2021-10-24 12:02:55.834933: saving checkpoint...\n",
      "2021-10-24 12:02:56.914081: done, saving took 1.10 seconds\n",
      "2021-10-24 12:02:57.365261: This epoch took 195.828951 s\n",
      "\n",
      "2021-10-24 12:02:57.377926: \n",
      "epoch:  25\n",
      "2021-10-24 12:05:57.404379: train loss : -0.8847\n",
      "2021-10-24 12:06:10.899161: validation loss: -0.8240\n",
      "2021-10-24 12:06:10.904834: Average global foreground Dice: [0.8365]\n",
      "2021-10-24 12:06:10.911530: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:06:11.442488: lr: 0.005166\n",
      "2021-10-24 12:06:11.485333: saving checkpoint...\n",
      "2021-10-24 12:06:12.566167: done, saving took 1.10 seconds\n",
      "2021-10-24 12:06:13.025949: This epoch took 195.640855 s\n",
      "\n",
      "2021-10-24 12:06:13.033815: \n",
      "epoch:  26\n",
      "2021-10-24 12:09:13.116567: train loss : -0.8863\n",
      "2021-10-24 12:09:26.626986: validation loss: -0.8215\n",
      "2021-10-24 12:09:26.633126: Average global foreground Dice: [0.8364]\n",
      "2021-10-24 12:09:26.640738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:09:27.177408: lr: 0.004971\n",
      "2021-10-24 12:09:27.222076: saving checkpoint...\n",
      "2021-10-24 12:09:28.304369: done, saving took 1.10 seconds\n",
      "2021-10-24 12:09:28.770015: This epoch took 195.730068 s\n",
      "\n",
      "2021-10-24 12:09:28.778757: \n",
      "epoch:  27\n",
      "2021-10-24 12:12:28.943443: train loss : -0.8871\n",
      "2021-10-24 12:12:42.463267: validation loss: -0.8298\n",
      "2021-10-24 12:12:42.467986: Average global foreground Dice: [0.8426]\n",
      "2021-10-24 12:12:42.475015: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:12:43.013001: lr: 0.004776\n",
      "2021-10-24 12:12:43.053337: saving checkpoint...\n",
      "2021-10-24 12:12:44.182062: done, saving took 1.15 seconds\n",
      "2021-10-24 12:12:44.641690: This epoch took 195.855899 s\n",
      "\n",
      "2021-10-24 12:12:44.652529: \n",
      "epoch:  28\n",
      "2021-10-24 12:15:44.748107: train loss : -0.8869\n",
      "2021-10-24 12:15:58.266768: validation loss: -0.8290\n",
      "2021-10-24 12:15:58.271503: Average global foreground Dice: [0.8423]\n",
      "2021-10-24 12:15:58.278030: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:15:58.819058: lr: 0.004581\n",
      "2021-10-24 12:15:58.861418: saving checkpoint...\n",
      "2021-10-24 12:15:59.966037: done, saving took 1.12 seconds\n",
      "2021-10-24 12:16:00.469034: This epoch took 195.808477 s\n",
      "\n",
      "2021-10-24 12:16:00.478995: \n",
      "epoch:  29\n",
      "2021-10-24 12:19:00.555289: train loss : -0.8892\n",
      "2021-10-24 12:19:14.073941: validation loss: -0.8201\n",
      "2021-10-24 12:19:14.078376: Average global foreground Dice: [0.8334]\n",
      "2021-10-24 12:19:14.085302: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:19:14.645028: lr: 0.004384\n",
      "2021-10-24 12:19:14.683708: saving checkpoint...\n",
      "2021-10-24 12:19:15.870352: done, saving took 1.21 seconds\n",
      "2021-10-24 12:19:16.410535: This epoch took 195.924583 s\n",
      "\n",
      "2021-10-24 12:19:16.418780: \n",
      "epoch:  30\n",
      "2021-10-24 12:22:16.516326: train loss : -0.8907\n",
      "2021-10-24 12:22:30.033717: validation loss: -0.8262\n",
      "2021-10-24 12:22:30.038184: Average global foreground Dice: [0.8404]\n",
      "2021-10-24 12:22:30.045017: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:22:30.613456: lr: 0.004186\n",
      "2021-10-24 12:22:30.652058: saving checkpoint...\n",
      "2021-10-24 12:22:31.725896: done, saving took 1.09 seconds\n",
      "2021-10-24 12:22:32.191760: This epoch took 195.765626 s\n",
      "\n",
      "2021-10-24 12:22:32.200913: \n",
      "epoch:  31\n",
      "2021-10-24 12:25:32.357908: train loss : -0.8918\n",
      "2021-10-24 12:25:45.890304: validation loss: -0.8293\n",
      "2021-10-24 12:25:45.895193: Average global foreground Dice: [0.8418]\n",
      "2021-10-24 12:25:45.902081: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:25:46.434301: lr: 0.003987\n",
      "2021-10-24 12:25:46.475422: saving checkpoint...\n",
      "2021-10-24 12:25:47.590447: done, saving took 1.13 seconds\n",
      "2021-10-24 12:25:48.100945: This epoch took 195.893266 s\n",
      "\n",
      "2021-10-24 12:25:48.109157: \n",
      "epoch:  32\n",
      "2021-10-24 12:28:48.571952: train loss : -0.8922\n",
      "2021-10-24 12:29:02.091926: validation loss: -0.8188\n",
      "2021-10-24 12:29:02.098297: Average global foreground Dice: [0.8321]\n",
      "2021-10-24 12:29:02.105480: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:29:02.671580: lr: 0.003787\n",
      "2021-10-24 12:29:02.697476: This epoch took 194.581879 s\n",
      "\n",
      "2021-10-24 12:29:02.704314: \n",
      "epoch:  33\n",
      "2021-10-24 12:32:03.244176: train loss : -0.8924\n",
      "2021-10-24 12:32:16.749488: validation loss: -0.8329\n",
      "2021-10-24 12:32:16.754905: Average global foreground Dice: [0.8449]\n",
      "2021-10-24 12:32:16.762637: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:32:17.316799: lr: 0.003586\n",
      "2021-10-24 12:32:17.366597: saving checkpoint...\n",
      "2021-10-24 12:32:18.479241: done, saving took 1.14 seconds\n",
      "2021-10-24 12:32:18.963683: This epoch took 196.252927 s\n",
      "\n",
      "2021-10-24 12:32:18.973291: \n",
      "epoch:  34\n",
      "2021-10-24 12:35:19.368593: train loss : -0.8930\n",
      "2021-10-24 12:35:32.911174: validation loss: -0.8223\n",
      "2021-10-24 12:35:32.915651: Average global foreground Dice: [0.8352]\n",
      "2021-10-24 12:35:32.922389: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:35:33.479438: lr: 0.003384\n",
      "2021-10-24 12:35:33.530026: saving checkpoint...\n",
      "2021-10-24 12:35:34.609591: done, saving took 1.11 seconds\n",
      "2021-10-24 12:35:35.255088: This epoch took 196.274286 s\n",
      "\n",
      "2021-10-24 12:35:35.262630: \n",
      "epoch:  35\n",
      "2021-10-24 12:38:35.626751: train loss : -0.8955\n",
      "2021-10-24 12:38:49.136237: validation loss: -0.8235\n",
      "2021-10-24 12:38:49.140781: Average global foreground Dice: [0.8369]\n",
      "2021-10-24 12:38:49.147872: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:38:49.719172: lr: 0.00318\n",
      "2021-10-24 12:38:49.758122: saving checkpoint...\n",
      "2021-10-24 12:38:50.852067: done, saving took 1.11 seconds\n",
      "2021-10-24 12:38:51.326270: This epoch took 196.056997 s\n",
      "\n",
      "2021-10-24 12:38:51.335242: \n",
      "epoch:  36\n",
      "2021-10-24 12:41:51.847439: train loss : -0.8969\n",
      "2021-10-24 12:42:05.379141: validation loss: -0.8293\n",
      "2021-10-24 12:42:05.383654: Average global foreground Dice: [0.8414]\n",
      "2021-10-24 12:42:05.392025: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:42:05.907405: lr: 0.002975\n",
      "2021-10-24 12:42:05.948387: saving checkpoint...\n",
      "2021-10-24 12:42:07.049860: done, saving took 1.12 seconds\n",
      "2021-10-24 12:42:07.761740: This epoch took 196.417835 s\n",
      "\n",
      "2021-10-24 12:42:07.770682: \n",
      "epoch:  37\n",
      "2021-10-24 12:45:08.273642: train loss : -0.8979\n",
      "2021-10-24 12:45:21.798979: validation loss: -0.8197\n",
      "2021-10-24 12:45:21.803170: Average global foreground Dice: [0.8327]\n",
      "2021-10-24 12:45:21.809987: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:45:22.355364: lr: 0.002768\n",
      "2021-10-24 12:45:22.373688: This epoch took 194.596322 s\n",
      "\n",
      "2021-10-24 12:45:22.380360: \n",
      "epoch:  38\n",
      "2021-10-24 12:48:22.895744: train loss : -0.8989\n",
      "2021-10-24 12:48:36.400154: validation loss: -0.8274\n",
      "2021-10-24 12:48:36.404709: Average global foreground Dice: [0.8409]\n",
      "2021-10-24 12:48:36.411267: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:48:36.970501: lr: 0.00256\n",
      "2021-10-24 12:48:37.006126: saving checkpoint...\n",
      "2021-10-24 12:48:38.134378: done, saving took 1.15 seconds\n",
      "2021-10-24 12:48:38.600187: This epoch took 196.212776 s\n",
      "\n",
      "2021-10-24 12:48:38.608962: \n",
      "epoch:  39\n",
      "2021-10-24 12:51:39.056837: train loss : -0.9001\n",
      "2021-10-24 12:51:52.574257: validation loss: -0.8276\n",
      "2021-10-24 12:51:52.578789: Average global foreground Dice: [0.8383]\n",
      "2021-10-24 12:51:52.585828: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:51:53.135673: lr: 0.002349\n",
      "2021-10-24 12:51:53.177020: saving checkpoint...\n",
      "2021-10-24 12:51:54.294431: done, saving took 1.14 seconds\n",
      "2021-10-24 12:51:54.742460: This epoch took 196.125967 s\n",
      "\n",
      "2021-10-24 12:51:54.752787: \n",
      "epoch:  40\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-24 12:54:55.576948: train loss : -0.9000\n",
      "2021-10-24 12:55:09.113497: validation loss: -0.8312\n",
      "2021-10-24 12:55:09.118048: Average global foreground Dice: [0.8438]\n",
      "2021-10-24 12:55:09.125240: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:55:09.680993: lr: 0.002137\n",
      "2021-10-24 12:55:09.737142: saving checkpoint...\n",
      "2021-10-24 12:55:10.842761: done, saving took 1.13 seconds\n",
      "2021-10-24 12:55:11.323063: This epoch took 196.563090 s\n",
      "\n",
      "2021-10-24 12:55:11.331163: \n",
      "epoch:  41\n",
      "2021-10-24 12:58:11.679102: train loss : -0.9034\n",
      "2021-10-24 12:58:25.209019: validation loss: -0.8249\n",
      "2021-10-24 12:58:25.213950: Average global foreground Dice: [0.8368]\n",
      "2021-10-24 12:58:25.220607: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 12:58:25.832985: lr: 0.001922\n",
      "2021-10-24 12:58:25.853077: This epoch took 194.514632 s\n",
      "\n",
      "2021-10-24 12:58:25.859869: \n",
      "epoch:  42\n",
      "2021-10-24 13:01:26.398830: train loss : -0.9040\n",
      "2021-10-24 13:01:39.926729: validation loss: -0.8256\n",
      "2021-10-24 13:01:39.932673: Average global foreground Dice: [0.8376]\n",
      "2021-10-24 13:01:39.939479: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:01:40.476460: lr: 0.001704\n",
      "2021-10-24 13:01:40.518458: saving checkpoint...\n",
      "2021-10-24 13:01:41.598654: done, saving took 1.10 seconds\n",
      "2021-10-24 13:01:42.118777: This epoch took 196.252033 s\n",
      "\n",
      "2021-10-24 13:01:42.127532: \n",
      "epoch:  43\n",
      "2021-10-24 13:04:42.653624: train loss : -0.9043\n",
      "2021-10-24 13:04:56.168559: validation loss: -0.8272\n",
      "2021-10-24 13:04:56.174624: Average global foreground Dice: [0.839]\n",
      "2021-10-24 13:04:56.181554: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:04:56.692003: lr: 0.001483\n",
      "2021-10-24 13:04:56.731940: saving checkpoint...\n",
      "2021-10-24 13:04:57.835081: done, saving took 1.12 seconds\n",
      "2021-10-24 13:04:58.274525: This epoch took 196.140154 s\n",
      "\n",
      "2021-10-24 13:04:58.282564: \n",
      "epoch:  44\n",
      "2021-10-24 13:07:58.666734: train loss : -0.9050\n",
      "2021-10-24 13:08:12.191715: validation loss: -0.8263\n",
      "2021-10-24 13:08:12.196169: Average global foreground Dice: [0.838]\n",
      "2021-10-24 13:08:12.202738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:08:12.750528: lr: 0.001259\n",
      "2021-10-24 13:08:12.790706: saving checkpoint...\n",
      "2021-10-24 13:08:13.874686: done, saving took 1.10 seconds\n",
      "2021-10-24 13:08:14.543884: This epoch took 196.254589 s\n",
      "\n",
      "2021-10-24 13:08:14.553154: \n",
      "epoch:  45\n",
      "2021-10-24 13:11:15.045040: train loss : -0.9057\n",
      "2021-10-24 13:11:28.590396: validation loss: -0.8240\n",
      "2021-10-24 13:11:28.594665: Average global foreground Dice: [0.8358]\n",
      "2021-10-24 13:11:28.601408: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:11:29.139450: lr: 0.00103\n",
      "2021-10-24 13:11:29.159481: This epoch took 194.599126 s\n",
      "\n",
      "2021-10-24 13:11:29.166360: \n",
      "epoch:  46\n",
      "2021-10-24 13:14:29.744107: train loss : -0.9060\n",
      "2021-10-24 13:14:43.287308: validation loss: -0.8239\n",
      "2021-10-24 13:14:43.291849: Average global foreground Dice: [0.837]\n",
      "2021-10-24 13:14:43.298547: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:14:43.857263: lr: 0.000795\n",
      "2021-10-24 13:14:43.877330: This epoch took 194.703977 s\n",
      "\n",
      "2021-10-24 13:14:43.884272: \n",
      "epoch:  47\n",
      "2021-10-24 13:17:44.425053: train loss : -0.9082\n",
      "2021-10-24 13:17:57.956280: validation loss: -0.8184\n",
      "2021-10-24 13:17:57.961633: Average global foreground Dice: [0.8317]\n",
      "2021-10-24 13:17:57.971985: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:17:58.481414: lr: 0.000552\n",
      "2021-10-24 13:17:58.497418: This epoch took 194.606810 s\n",
      "\n",
      "2021-10-24 13:17:58.507049: \n",
      "epoch:  48\n",
      "2021-10-24 13:20:59.189025: train loss : -0.9077\n",
      "2021-10-24 13:21:12.717654: validation loss: -0.8199\n",
      "2021-10-24 13:21:12.721893: Average global foreground Dice: [0.8328]\n",
      "2021-10-24 13:21:12.730991: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:21:13.295860: lr: 0.000296\n",
      "2021-10-24 13:21:13.317796: This epoch took 194.799896 s\n",
      "\n",
      "2021-10-24 13:21:13.326078: \n",
      "epoch:  49\n",
      "2021-10-24 13:24:14.277965: train loss : -0.9088\n",
      "2021-10-24 13:24:27.796461: validation loss: -0.8240\n",
      "2021-10-24 13:24:27.800963: Average global foreground Dice: [0.8365]\n",
      "2021-10-24 13:24:27.807361: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:24:28.345997: lr: 0.0\n",
      "2021-10-24 13:24:28.366463: saving scheduled checkpoint file...\n",
      "2021-10-24 13:24:28.394214: saving checkpoint...\n",
      "2021-10-24 13:24:29.348693: done, saving took 0.98 seconds\n",
      "2021-10-24 13:24:29.774601: done\n",
      "2021-10-24 13:24:29.783638: This epoch took 196.450797 s\n",
      "\n",
      "2021-10-24 13:24:29.809769: saving checkpoint...\n",
      "2021-10-24 13:24:30.742802: done, saving took 0.95 seconds\n",
      "23090559_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090563_20151 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090567_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090584_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090589_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090590_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090592_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090596_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090599_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090604_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090608_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090614_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090615_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090616_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090617_20140 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090620_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090627_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090628_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090631_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090634_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090635_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090636_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090640_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-24 13:29:26.549421: finished prediction\n",
      "2021-10-24 13:29:26.555833: evaluation of raw predictions\n",
      "2021-10-24 13:29:30.145727: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8308992737772268\n",
      "after:  0.8308746294340972\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-10-24 13:29:47.416392: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-10-24 13:29:47.439077: The split file contains 2 splits.\n",
      "2021-10-24 13:29:47.445198: Desired fold for training: 1\n",
      "2021-10-24 13:29:47.452076: This split has 40 training and 40 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-24 13:29:51.602617: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-24 13:30:02.289120: Unable to plot network architecture:\n",
      "2021-10-24 13:30:02.425066: No module named 'hiddenlayer'\n",
      "2021-10-24 13:30:02.564654: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-24 13:30:02.656566: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-24 13:30:02.756930: \n",
      "\n",
      "2021-10-24 13:30:02.860720: \n",
      "epoch:  0\n",
      "2021-10-24 13:33:20.478953: train loss : -0.3093\n",
      "2021-10-24 13:33:34.243168: validation loss: -0.6849\n",
      "2021-10-24 13:33:34.247638: Average global foreground Dice: [0.7196]\n",
      "2021-10-24 13:33:34.253887: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:33:34.736280: lr: 0.00982\n",
      "2021-10-24 13:33:34.753988: This epoch took 211.801292 s\n",
      "\n",
      "2021-10-24 13:33:34.761931: \n",
      "epoch:  1\n",
      "2021-10-24 13:36:35.155726: train loss : -0.7275\n",
      "2021-10-24 13:36:48.936562: validation loss: -0.7731\n",
      "2021-10-24 13:36:48.941263: Average global foreground Dice: [0.7931]\n",
      "2021-10-24 13:36:48.947916: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:36:49.447848: lr: 0.009639\n",
      "2021-10-24 13:36:49.488218: saving checkpoint...\n",
      "2021-10-24 13:36:50.448651: done, saving took 0.98 seconds\n",
      "2021-10-24 13:36:50.879380: This epoch took 196.111327 s\n",
      "\n",
      "2021-10-24 13:36:50.888358: \n",
      "epoch:  2\n",
      "2021-10-24 13:39:50.845416: train loss : -0.7877\n",
      "2021-10-24 13:40:04.611577: validation loss: -0.7977\n",
      "2021-10-24 13:40:04.615973: Average global foreground Dice: [0.8144]\n",
      "2021-10-24 13:40:04.626283: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:40:05.264827: lr: 0.009458\n",
      "2021-10-24 13:40:05.303283: saving checkpoint...\n",
      "2021-10-24 13:40:06.382324: done, saving took 1.10 seconds\n",
      "2021-10-24 13:40:06.895134: This epoch took 196.000086 s\n",
      "\n",
      "2021-10-24 13:40:06.903036: \n",
      "epoch:  3\n",
      "2021-10-24 13:43:06.965099: train loss : -0.8100\n",
      "2021-10-24 13:43:20.735370: validation loss: -0.7983\n",
      "2021-10-24 13:43:20.739705: Average global foreground Dice: [0.8166]\n",
      "2021-10-24 13:43:20.746173: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:43:21.244801: lr: 0.009277\n",
      "2021-10-24 13:43:21.295605: saving checkpoint...\n",
      "2021-10-24 13:43:22.355316: done, saving took 1.08 seconds\n",
      "2021-10-24 13:43:22.831310: This epoch took 195.921274 s\n",
      "\n",
      "2021-10-24 13:43:22.851567: \n",
      "epoch:  4\n",
      "2021-10-24 13:46:22.923440: train loss : -0.8235\n",
      "2021-10-24 13:46:36.688985: validation loss: -0.8060\n",
      "2021-10-24 13:46:36.695359: Average global foreground Dice: [0.8228]\n",
      "2021-10-24 13:46:36.702399: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:46:37.255460: lr: 0.009095\n",
      "2021-10-24 13:46:37.311130: saving checkpoint...\n",
      "2021-10-24 13:46:38.411627: done, saving took 1.12 seconds\n",
      "2021-10-24 13:46:38.922602: This epoch took 196.064225 s\n",
      "\n",
      "2021-10-24 13:46:38.939681: \n",
      "epoch:  5\n",
      "2021-10-24 13:49:39.047000: train loss : -0.8313\n",
      "2021-10-24 13:49:52.809064: validation loss: -0.8197\n",
      "2021-10-24 13:49:52.813410: Average global foreground Dice: [0.8311]\n",
      "2021-10-24 13:49:52.819435: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:49:53.368926: lr: 0.008913\n",
      "2021-10-24 13:49:53.419334: saving checkpoint...\n",
      "2021-10-24 13:49:54.490732: done, saving took 1.09 seconds\n",
      "2021-10-24 13:49:54.923074: This epoch took 195.976412 s\n",
      "\n",
      "2021-10-24 13:49:54.943800: \n",
      "epoch:  6\n",
      "2021-10-24 13:52:55.007815: train loss : -0.8402\n",
      "2021-10-24 13:53:08.783525: validation loss: -0.8136\n",
      "2021-10-24 13:53:08.787981: Average global foreground Dice: [0.8271]\n",
      "2021-10-24 13:53:08.793867: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:53:09.309471: lr: 0.008731\n",
      "2021-10-24 13:53:09.357110: saving checkpoint...\n",
      "2021-10-24 13:53:10.436089: done, saving took 1.10 seconds\n",
      "2021-10-24 13:53:10.901045: This epoch took 195.951159 s\n",
      "\n",
      "2021-10-24 13:53:10.919713: \n",
      "epoch:  7\n",
      "2021-10-24 13:56:10.969311: train loss : -0.8441\n",
      "2021-10-24 13:56:24.765534: validation loss: -0.8144\n",
      "2021-10-24 13:56:24.770043: Average global foreground Dice: [0.8275]\n",
      "2021-10-24 13:56:24.777278: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:56:25.310712: lr: 0.008548\n",
      "2021-10-24 13:56:25.360400: saving checkpoint...\n",
      "2021-10-24 13:56:26.504049: done, saving took 1.16 seconds\n",
      "2021-10-24 13:56:26.932477: This epoch took 196.005382 s\n",
      "\n",
      "2021-10-24 13:56:26.952926: \n",
      "epoch:  8\n",
      "2021-10-24 13:59:27.542699: train loss : -0.8490\n",
      "2021-10-24 13:59:41.345287: validation loss: -0.8232\n",
      "2021-10-24 13:59:41.350571: Average global foreground Dice: [0.8349]\n",
      "2021-10-24 13:59:41.356848: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 13:59:41.855174: lr: 0.008364\n",
      "2021-10-24 13:59:41.904809: saving checkpoint...\n",
      "2021-10-24 13:59:43.011690: done, saving took 1.13 seconds\n",
      "2021-10-24 13:59:43.480415: This epoch took 196.521197 s\n",
      "\n",
      "2021-10-24 13:59:43.501023: \n",
      "epoch:  9\n",
      "2021-10-24 14:02:44.119778: train loss : -0.8533\n",
      "2021-10-24 14:02:57.911741: validation loss: -0.8178\n",
      "2021-10-24 14:02:57.915898: Average global foreground Dice: [0.8298]\n",
      "2021-10-24 14:02:57.922295: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:02:58.433414: lr: 0.008181\n",
      "2021-10-24 14:02:58.483601: saving checkpoint...\n",
      "2021-10-24 14:02:59.910426: done, saving took 1.45 seconds\n",
      "2021-10-24 14:03:00.126529: This epoch took 196.618574 s\n",
      "\n",
      "2021-10-24 14:03:00.147055: \n",
      "epoch:  10\n",
      "2021-10-24 14:06:00.789150: train loss : -0.8575\n",
      "2021-10-24 14:06:14.600449: validation loss: -0.8188\n",
      "2021-10-24 14:06:14.604778: Average global foreground Dice: [0.8317]\n",
      "2021-10-24 14:06:14.612396: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:06:15.142766: lr: 0.007996\n",
      "2021-10-24 14:06:15.195911: saving checkpoint...\n",
      "2021-10-24 14:06:16.337523: done, saving took 1.16 seconds\n",
      "2021-10-24 14:06:16.748363: This epoch took 196.594434 s\n",
      "\n",
      "2021-10-24 14:06:16.766126: \n",
      "epoch:  11\n",
      "2021-10-24 14:09:17.762249: train loss : -0.8603\n",
      "2021-10-24 14:09:31.568960: validation loss: -0.8212\n",
      "2021-10-24 14:09:31.573224: Average global foreground Dice: [0.8333]\n",
      "2021-10-24 14:09:31.579461: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:09:32.064471: lr: 0.007811\n",
      "2021-10-24 14:09:32.113682: saving checkpoint...\n",
      "2021-10-24 14:09:33.208858: done, saving took 1.11 seconds\n",
      "2021-10-24 14:09:33.621937: This epoch took 196.848973 s\n",
      "\n",
      "2021-10-24 14:09:33.640787: \n",
      "epoch:  12\n",
      "2021-10-24 14:12:34.418630: train loss : -0.8626\n",
      "2021-10-24 14:12:48.227175: validation loss: -0.8125\n",
      "2021-10-24 14:12:48.232064: Average global foreground Dice: [0.826]\n",
      "2021-10-24 14:12:48.238421: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:12:48.736948: lr: 0.007626\n",
      "2021-10-24 14:12:48.790872: saving checkpoint...\n",
      "2021-10-24 14:12:50.092745: done, saving took 1.33 seconds\n",
      "2021-10-24 14:12:50.199325: This epoch took 196.552430 s\n",
      "\n",
      "2021-10-24 14:12:50.217016: \n",
      "epoch:  13\n",
      "2021-10-24 14:15:51.166147: train loss : -0.8650\n",
      "2021-10-24 14:16:04.974886: validation loss: -0.8185\n",
      "2021-10-24 14:16:04.979511: Average global foreground Dice: [0.8318]\n",
      "2021-10-24 14:16:04.986708: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:16:05.587203: lr: 0.00744\n",
      "2021-10-24 14:16:05.639789: saving checkpoint...\n",
      "2021-10-24 14:16:06.767027: done, saving took 1.15 seconds\n",
      "2021-10-24 14:16:07.240066: This epoch took 197.015598 s\n",
      "\n",
      "2021-10-24 14:16:07.260152: \n",
      "epoch:  14\n",
      "2021-10-24 14:19:08.315233: train loss : -0.8688\n",
      "2021-10-24 14:19:22.123161: validation loss: -0.8218\n",
      "2021-10-24 14:19:22.127299: Average global foreground Dice: [0.8315]\n",
      "2021-10-24 14:19:22.134505: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:19:22.644301: lr: 0.007254\n",
      "2021-10-24 14:19:22.696707: saving checkpoint...\n",
      "2021-10-24 14:19:23.809355: done, saving took 1.13 seconds\n",
      "2021-10-24 14:19:24.152200: This epoch took 196.885172 s\n",
      "\n",
      "2021-10-24 14:19:24.172111: \n",
      "epoch:  15\n",
      "2021-10-24 14:22:25.099377: train loss : -0.8707\n",
      "2021-10-24 14:22:38.878529: validation loss: -0.8202\n",
      "2021-10-24 14:22:38.882743: Average global foreground Dice: [0.8329]\n",
      "2021-10-24 14:22:38.889547: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:22:39.432708: lr: 0.007067\n",
      "2021-10-24 14:22:39.483006: saving checkpoint...\n",
      "2021-10-24 14:22:40.575268: done, saving took 1.11 seconds\n",
      "2021-10-24 14:22:41.022128: This epoch took 196.843458 s\n",
      "\n",
      "2021-10-24 14:22:41.039065: \n",
      "epoch:  16\n",
      "2021-10-24 14:25:42.722994: train loss : -0.8712\n",
      "2021-10-24 14:25:56.513341: validation loss: -0.8182\n",
      "2021-10-24 14:25:56.517580: Average global foreground Dice: [0.831]\n",
      "2021-10-24 14:25:56.523071: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:25:57.060405: lr: 0.00688\n",
      "2021-10-24 14:25:57.108605: saving checkpoint...\n",
      "2021-10-24 14:25:58.204958: done, saving took 1.12 seconds\n",
      "2021-10-24 14:25:58.660503: This epoch took 197.614330 s\n",
      "\n",
      "2021-10-24 14:25:58.678979: \n",
      "epoch:  17\n",
      "2021-10-24 14:29:00.047720: train loss : -0.8745\n",
      "2021-10-24 14:29:13.889712: validation loss: -0.8242\n",
      "2021-10-24 14:29:13.894362: Average global foreground Dice: [0.8343]\n",
      "2021-10-24 14:29:13.903271: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:29:14.451412: lr: 0.006692\n",
      "2021-10-24 14:29:14.502840: saving checkpoint...\n",
      "2021-10-24 14:29:15.619940: done, saving took 1.14 seconds\n",
      "2021-10-24 14:29:15.855949: This epoch took 197.167412 s\n",
      "\n",
      "2021-10-24 14:29:15.875077: \n",
      "epoch:  18\n",
      "2021-10-24 14:32:17.390726: train loss : -0.8773\n",
      "2021-10-24 14:32:31.188395: validation loss: -0.8188\n",
      "2021-10-24 14:32:31.192958: Average global foreground Dice: [0.8295]\n",
      "2021-10-24 14:32:31.199289: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:32:31.695045: lr: 0.006504\n",
      "2021-10-24 14:32:31.744686: saving checkpoint...\n",
      "2021-10-24 14:32:32.926815: done, saving took 1.20 seconds\n",
      "2021-10-24 14:32:33.179650: This epoch took 197.297466 s\n",
      "\n",
      "2021-10-24 14:32:33.200074: \n",
      "epoch:  19\n",
      "2021-10-24 14:35:34.785459: train loss : -0.8785\n",
      "2021-10-24 14:35:48.592790: validation loss: -0.8253\n",
      "2021-10-24 14:35:48.597162: Average global foreground Dice: [0.8359]\n",
      "2021-10-24 14:35:48.603696: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:35:49.104351: lr: 0.006314\n",
      "2021-10-24 14:35:49.145687: saving checkpoint...\n",
      "2021-10-24 14:35:50.250195: done, saving took 1.12 seconds\n",
      "2021-10-24 14:35:50.522208: This epoch took 197.315021 s\n",
      "\n",
      "2021-10-24 14:35:50.530648: \n",
      "epoch:  20\n",
      "2021-10-24 14:38:52.262195: train loss : -0.8796\n",
      "2021-10-24 14:39:06.078467: validation loss: -0.8225\n",
      "2021-10-24 14:39:06.082711: Average global foreground Dice: [0.8336]\n",
      "2021-10-24 14:39:06.089103: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:39:06.625906: lr: 0.006125\n",
      "2021-10-24 14:39:06.664541: saving checkpoint...\n",
      "2021-10-24 14:39:07.787275: done, saving took 1.14 seconds\n",
      "2021-10-24 14:39:08.286754: This epoch took 197.749230 s\n",
      "\n",
      "2021-10-24 14:39:08.295883: \n",
      "epoch:  21\n",
      "2021-10-24 14:42:09.910554: train loss : -0.8803\n",
      "2021-10-24 14:42:23.728842: validation loss: -0.8209\n",
      "2021-10-24 14:42:23.733713: Average global foreground Dice: [0.8312]\n",
      "2021-10-24 14:42:23.740746: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:42:24.251086: lr: 0.005934\n",
      "2021-10-24 14:42:24.294313: saving checkpoint...\n",
      "2021-10-24 14:42:25.392356: done, saving took 1.12 seconds\n",
      "2021-10-24 14:42:25.868253: This epoch took 197.564692 s\n",
      "\n",
      "2021-10-24 14:42:25.877178: \n",
      "epoch:  22\n",
      "2021-10-24 14:45:27.591436: train loss : -0.8830\n",
      "2021-10-24 14:45:41.415761: validation loss: -0.8233\n",
      "2021-10-24 14:45:41.421883: Average global foreground Dice: [0.8344]\n",
      "2021-10-24 14:45:41.428388: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:45:41.938165: lr: 0.005743\n",
      "2021-10-24 14:45:41.979968: saving checkpoint...\n",
      "2021-10-24 14:45:43.082557: done, saving took 1.12 seconds\n",
      "2021-10-24 14:45:43.646414: This epoch took 197.762017 s\n",
      "\n",
      "2021-10-24 14:45:43.654883: \n",
      "epoch:  23\n",
      "2021-10-24 14:48:45.496958: train loss : -0.8831\n",
      "2021-10-24 14:48:59.302753: validation loss: -0.8202\n",
      "2021-10-24 14:48:59.307390: Average global foreground Dice: [0.8306]\n",
      "2021-10-24 14:48:59.313595: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:48:59.839273: lr: 0.005551\n",
      "2021-10-24 14:48:59.879687: saving checkpoint...\n",
      "2021-10-24 14:49:00.968297: done, saving took 1.11 seconds\n",
      "2021-10-24 14:49:01.442817: This epoch took 197.780477 s\n",
      "\n",
      "2021-10-24 14:49:01.452352: \n",
      "epoch:  24\n",
      "2021-10-24 14:52:03.840474: train loss : -0.8841\n",
      "2021-10-24 14:52:17.666490: validation loss: -0.8196\n",
      "2021-10-24 14:52:17.671134: Average global foreground Dice: [0.8311]\n",
      "2021-10-24 14:52:17.678287: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:52:18.247311: lr: 0.005359\n",
      "2021-10-24 14:52:18.287887: saving checkpoint...\n",
      "2021-10-24 14:52:19.387598: done, saving took 1.12 seconds\n",
      "2021-10-24 14:52:20.037084: This epoch took 198.578296 s\n",
      "\n",
      "2021-10-24 14:52:20.046385: \n",
      "epoch:  25\n",
      "2021-10-24 14:55:22.408056: train loss : -0.8859\n",
      "2021-10-24 14:55:36.224878: validation loss: -0.8246\n",
      "2021-10-24 14:55:36.229284: Average global foreground Dice: [0.8338]\n",
      "2021-10-24 14:55:36.236154: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:55:36.798869: lr: 0.005166\n",
      "2021-10-24 14:55:36.841222: saving checkpoint...\n",
      "2021-10-24 14:55:37.952287: done, saving took 1.13 seconds\n",
      "2021-10-24 14:55:38.369857: This epoch took 198.315696 s\n",
      "\n",
      "2021-10-24 14:55:38.378203: \n",
      "epoch:  26\n",
      "2021-10-24 14:58:40.622093: train loss : -0.8881\n",
      "2021-10-24 14:58:54.447504: validation loss: -0.8276\n",
      "2021-10-24 14:58:54.452104: Average global foreground Dice: [0.8382]\n",
      "2021-10-24 14:58:54.459153: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 14:58:54.948999: lr: 0.004971\n",
      "2021-10-24 14:58:54.993112: saving checkpoint...\n",
      "2021-10-24 14:58:56.122318: done, saving took 1.15 seconds\n",
      "2021-10-24 14:58:56.567559: This epoch took 198.182318 s\n",
      "\n",
      "2021-10-24 14:58:56.576102: \n",
      "epoch:  27\n",
      "2021-10-24 15:01:58.897054: train loss : -0.8889\n",
      "2021-10-24 15:02:12.708836: validation loss: -0.8201\n",
      "2021-10-24 15:02:12.713595: Average global foreground Dice: [0.8306]\n",
      "2021-10-24 15:02:12.720997: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:02:13.254570: lr: 0.004776\n",
      "2021-10-24 15:02:13.293255: saving checkpoint...\n",
      "2021-10-24 15:02:14.391556: done, saving took 1.12 seconds\n",
      "2021-10-24 15:02:15.173669: This epoch took 198.591621 s\n",
      "\n",
      "2021-10-24 15:02:15.183445: \n",
      "epoch:  28\n",
      "2021-10-24 15:05:17.431828: train loss : -0.8899\n",
      "2021-10-24 15:05:31.257568: validation loss: -0.8245\n",
      "2021-10-24 15:05:31.263896: Average global foreground Dice: [0.8349]\n",
      "2021-10-24 15:05:31.270395: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:05:31.805266: lr: 0.004581\n",
      "2021-10-24 15:05:31.846129: saving checkpoint...\n",
      "2021-10-24 15:05:32.950243: done, saving took 1.12 seconds\n",
      "2021-10-24 15:05:33.502775: This epoch took 198.312057 s\n",
      "\n",
      "2021-10-24 15:05:33.511519: \n",
      "epoch:  29\n",
      "2021-10-24 15:08:35.906508: train loss : -0.8920\n",
      "2021-10-24 15:08:49.725973: validation loss: -0.8185\n",
      "2021-10-24 15:08:49.731056: Average global foreground Dice: [0.8298]\n",
      "2021-10-24 15:08:49.738089: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:08:50.300544: lr: 0.004384\n",
      "2021-10-24 15:08:50.343464: saving checkpoint...\n",
      "2021-10-24 15:08:51.507568: done, saving took 1.18 seconds\n",
      "2021-10-24 15:08:51.943580: This epoch took 198.425317 s\n",
      "\n",
      "2021-10-24 15:08:51.952016: \n",
      "epoch:  30\n",
      "2021-10-24 15:11:54.368151: train loss : -0.8924\n",
      "2021-10-24 15:12:08.194981: validation loss: -0.8186\n",
      "2021-10-24 15:12:08.199623: Average global foreground Dice: [0.8292]\n",
      "2021-10-24 15:12:08.205604: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:12:08.740736: lr: 0.004186\n",
      "2021-10-24 15:12:08.783179: saving checkpoint...\n",
      "2021-10-24 15:12:09.863384: done, saving took 1.10 seconds\n",
      "2021-10-24 15:12:10.153154: This epoch took 198.193837 s\n",
      "\n",
      "2021-10-24 15:12:10.161377: \n",
      "epoch:  31\n",
      "2021-10-24 15:15:12.573116: train loss : -0.8926\n",
      "2021-10-24 15:15:26.402346: validation loss: -0.8191\n",
      "2021-10-24 15:15:26.408420: Average global foreground Dice: [0.8283]\n",
      "2021-10-24 15:15:26.415038: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:15:26.936662: lr: 0.003987\n",
      "2021-10-24 15:15:26.978928: saving checkpoint...\n",
      "2021-10-24 15:15:28.094644: done, saving took 1.13 seconds\n",
      "2021-10-24 15:15:28.568905: This epoch took 198.400805 s\n",
      "\n",
      "2021-10-24 15:15:28.577415: \n",
      "epoch:  32\n",
      "2021-10-24 15:18:31.104983: train loss : -0.8945\n",
      "2021-10-24 15:18:44.952777: validation loss: -0.8218\n",
      "2021-10-24 15:18:44.957221: Average global foreground Dice: [0.8316]\n",
      "2021-10-24 15:18:44.965222: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:18:45.484275: lr: 0.003787\n",
      "2021-10-24 15:18:45.522958: saving checkpoint...\n",
      "2021-10-24 15:18:46.629845: done, saving took 1.13 seconds\n",
      "2021-10-24 15:18:46.928361: This epoch took 198.343654 s\n",
      "\n",
      "2021-10-24 15:18:46.937084: \n",
      "epoch:  33\n",
      "2021-10-24 15:21:49.471540: train loss : -0.8959\n",
      "2021-10-24 15:22:03.292659: validation loss: -0.8244\n",
      "2021-10-24 15:22:03.297091: Average global foreground Dice: [0.8347]\n",
      "2021-10-24 15:22:03.303971: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:22:03.800031: lr: 0.003586\n",
      "2021-10-24 15:22:03.845041: saving checkpoint...\n",
      "2021-10-24 15:22:04.961337: done, saving took 1.14 seconds\n",
      "2021-10-24 15:22:05.305530: This epoch took 198.361514 s\n",
      "\n",
      "2021-10-24 15:22:05.314645: \n",
      "epoch:  34\n",
      "2021-10-24 15:25:07.819792: train loss : -0.8971\n",
      "2021-10-24 15:25:21.638763: validation loss: -0.8214\n",
      "2021-10-24 15:25:21.643069: Average global foreground Dice: [0.8323]\n",
      "2021-10-24 15:25:21.650599: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:25:22.204802: lr: 0.003384\n",
      "2021-10-24 15:25:22.243183: saving checkpoint...\n",
      "2021-10-24 15:25:23.368754: done, saving took 1.14 seconds\n",
      "2021-10-24 15:25:23.719625: This epoch took 198.397324 s\n",
      "\n",
      "2021-10-24 15:25:23.728498: \n",
      "epoch:  35\n",
      "2021-10-24 15:28:26.257487: train loss : -0.8985\n",
      "2021-10-24 15:28:40.095924: validation loss: -0.8254\n",
      "2021-10-24 15:28:40.100186: Average global foreground Dice: [0.8352]\n",
      "2021-10-24 15:28:40.107288: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:28:40.720721: lr: 0.00318\n",
      "2021-10-24 15:28:40.759612: saving checkpoint...\n",
      "2021-10-24 15:28:41.884460: done, saving took 1.14 seconds\n",
      "2021-10-24 15:28:42.124166: This epoch took 198.388572 s\n",
      "\n",
      "2021-10-24 15:28:42.132710: \n",
      "epoch:  36\n",
      "2021-10-24 15:31:44.658720: train loss : -0.8987\n",
      "2021-10-24 15:31:58.476579: validation loss: -0.8223\n",
      "2021-10-24 15:31:58.480747: Average global foreground Dice: [0.8322]\n",
      "2021-10-24 15:31:58.487129: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:31:59.026065: lr: 0.002975\n",
      "2021-10-24 15:31:59.080904: saving checkpoint...\n",
      "2021-10-24 15:32:00.165009: done, saving took 1.10 seconds\n",
      "2021-10-24 15:32:00.612230: This epoch took 198.472549 s\n",
      "\n",
      "2021-10-24 15:32:00.620926: \n",
      "epoch:  37\n",
      "2021-10-24 15:35:03.139813: train loss : -0.9001\n",
      "2021-10-24 15:35:16.987903: validation loss: -0.8220\n",
      "2021-10-24 15:35:16.992487: Average global foreground Dice: [0.8316]\n",
      "2021-10-24 15:35:16.999561: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:35:17.498540: lr: 0.002768\n",
      "2021-10-24 15:35:17.539523: saving checkpoint...\n",
      "2021-10-24 15:35:18.618386: done, saving took 1.10 seconds\n",
      "2021-10-24 15:35:19.058152: This epoch took 198.426982 s\n",
      "\n",
      "2021-10-24 15:35:19.066747: \n",
      "epoch:  38\n",
      "2021-10-24 15:38:21.581141: train loss : -0.9014\n",
      "2021-10-24 15:38:35.413106: validation loss: -0.8217\n",
      "2021-10-24 15:38:35.417685: Average global foreground Dice: [0.8316]\n",
      "2021-10-24 15:38:35.424768: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:38:35.925754: lr: 0.00256\n",
      "2021-10-24 15:38:35.965469: saving checkpoint...\n",
      "2021-10-24 15:38:37.042141: done, saving took 1.10 seconds\n",
      "2021-10-24 15:38:37.490672: This epoch took 198.410596 s\n",
      "\n",
      "2021-10-24 15:38:37.499718: \n",
      "epoch:  39\n",
      "2021-10-24 15:41:40.032419: train loss : -0.9014\n",
      "2021-10-24 15:41:53.873705: validation loss: -0.8228\n",
      "2021-10-24 15:41:53.878748: Average global foreground Dice: [0.8326]\n",
      "2021-10-24 15:41:53.885628: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:41:54.388413: lr: 0.002349\n",
      "2021-10-24 15:41:54.426805: saving checkpoint...\n",
      "2021-10-24 15:41:55.543717: done, saving took 1.14 seconds\n",
      "2021-10-24 15:41:56.085442: This epoch took 198.577537 s\n",
      "\n",
      "2021-10-24 15:41:56.093126: \n",
      "epoch:  40\n",
      "2021-10-24 15:44:58.656851: train loss : -0.9034\n",
      "2021-10-24 15:45:12.486019: validation loss: -0.8207\n",
      "2021-10-24 15:45:12.490833: Average global foreground Dice: [0.8296]\n",
      "2021-10-24 15:45:12.497831: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:45:13.021674: lr: 0.002137\n",
      "2021-10-24 15:45:13.043581: This epoch took 196.943210 s\n",
      "\n",
      "2021-10-24 15:45:13.049759: \n",
      "epoch:  41\n",
      "2021-10-24 15:48:15.631480: train loss : -0.9037\n",
      "2021-10-24 15:48:29.453587: validation loss: -0.8245\n",
      "2021-10-24 15:48:29.457869: Average global foreground Dice: [0.8354]\n",
      "2021-10-24 15:48:29.464570: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:48:29.979172: lr: 0.001922\n",
      "2021-10-24 15:48:30.017819: saving checkpoint...\n",
      "2021-10-24 15:48:31.114498: done, saving took 1.12 seconds\n",
      "2021-10-24 15:48:31.525322: This epoch took 198.469027 s\n",
      "\n",
      "2021-10-24 15:48:31.533783: \n",
      "epoch:  42\n",
      "2021-10-24 15:51:34.105742: train loss : -0.9049\n",
      "2021-10-24 15:51:47.940150: validation loss: -0.8210\n",
      "2021-10-24 15:51:47.944455: Average global foreground Dice: [0.8314]\n",
      "2021-10-24 15:51:47.950786: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:51:48.441867: lr: 0.001704\n",
      "2021-10-24 15:51:48.489631: saving checkpoint...\n",
      "2021-10-24 15:51:49.634890: done, saving took 1.16 seconds\n",
      "2021-10-24 15:51:50.058549: This epoch took 198.517689 s\n",
      "\n",
      "2021-10-24 15:51:50.076082: \n",
      "epoch:  43\n",
      "2021-10-24 15:54:52.643731: train loss : -0.9059\n",
      "2021-10-24 15:55:06.470773: validation loss: -0.8212\n",
      "2021-10-24 15:55:06.474874: Average global foreground Dice: [0.8309]\n",
      "2021-10-24 15:55:06.481726: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:55:07.019156: lr: 0.001483\n",
      "2021-10-24 15:55:07.070592: saving checkpoint...\n",
      "2021-10-24 15:55:08.156786: done, saving took 1.10 seconds\n",
      "2021-10-24 15:55:08.604662: This epoch took 198.521251 s\n",
      "\n",
      "2021-10-24 15:55:08.621973: \n",
      "epoch:  44\n",
      "2021-10-24 15:58:11.211591: train loss : -0.9075\n",
      "2021-10-24 15:58:25.052803: validation loss: -0.8221\n",
      "2021-10-24 15:58:25.057271: Average global foreground Dice: [0.8314]\n",
      "2021-10-24 15:58:25.066427: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 15:58:25.597961: lr: 0.001259\n",
      "2021-10-24 15:58:25.647578: saving checkpoint...\n",
      "2021-10-24 15:58:26.742911: done, saving took 1.11 seconds\n",
      "2021-10-24 15:58:27.189745: This epoch took 198.559943 s\n",
      "\n",
      "2021-10-24 15:58:27.210825: \n",
      "epoch:  45\n",
      "2021-10-24 16:01:29.790074: train loss : -0.9082\n",
      "2021-10-24 16:01:43.621813: validation loss: -0.8185\n",
      "2021-10-24 16:01:43.626059: Average global foreground Dice: [0.8295]\n",
      "2021-10-24 16:01:43.633101: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:01:44.163768: lr: 0.00103\n",
      "2021-10-24 16:01:44.190769: This epoch took 196.972761 s\n",
      "\n",
      "2021-10-24 16:01:44.196869: \n",
      "epoch:  46\n",
      "2021-10-24 16:04:46.772324: train loss : -0.9092\n",
      "2021-10-24 16:05:00.593273: validation loss: -0.8188\n",
      "2021-10-24 16:05:00.598009: Average global foreground Dice: [0.8287]\n",
      "2021-10-24 16:05:00.604993: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:05:01.120240: lr: 0.000795\n",
      "2021-10-24 16:05:01.145230: This epoch took 196.942465 s\n",
      "\n",
      "2021-10-24 16:05:01.151948: \n",
      "epoch:  47\n",
      "2021-10-24 16:08:03.734428: train loss : -0.9085\n",
      "2021-10-24 16:08:17.592523: validation loss: -0.8226\n",
      "2021-10-24 16:08:17.598331: Average global foreground Dice: [0.8308]\n",
      "2021-10-24 16:08:17.605269: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:08:18.137016: lr: 0.000552\n",
      "2021-10-24 16:08:18.171635: This epoch took 197.012337 s\n",
      "\n",
      "2021-10-24 16:08:18.178523: \n",
      "epoch:  48\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-24 16:11:20.760252: train loss : -0.9100\n",
      "2021-10-24 16:11:34.583089: validation loss: -0.8215\n",
      "2021-10-24 16:11:34.587889: Average global foreground Dice: [0.8309]\n",
      "2021-10-24 16:11:34.594177: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:11:35.140652: lr: 0.000296\n",
      "2021-10-24 16:11:35.171732: This epoch took 196.986079 s\n",
      "\n",
      "2021-10-24 16:11:35.178463: \n",
      "epoch:  49\n",
      "2021-10-24 16:14:37.732688: train loss : -0.9108\n",
      "2021-10-24 16:14:51.559486: validation loss: -0.8198\n",
      "2021-10-24 16:14:51.564175: Average global foreground Dice: [0.8293]\n",
      "2021-10-24 16:14:51.570872: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:14:52.137721: lr: 0.0\n",
      "2021-10-24 16:14:52.171845: saving scheduled checkpoint file...\n",
      "2021-10-24 16:14:52.202032: saving checkpoint...\n",
      "2021-10-24 16:14:53.146780: done, saving took 0.97 seconds\n",
      "2021-10-24 16:14:53.660241: done\n",
      "2021-10-24 16:14:53.679339: This epoch took 198.493607 s\n",
      "\n",
      "2021-10-24 16:14:53.704604: saving checkpoint...\n",
      "2021-10-24 16:14:54.632037: done, saving took 0.95 seconds\n",
      "23090557_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090558_20120 (3, 263, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090560_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090562_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090564_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090566_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090568_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090569_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090571_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090593_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090597_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090600_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090603_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090607_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090609_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090619_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090621_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090629_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090637_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090644_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090646_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-24 16:19:49.183383: finished prediction\n",
      "2021-10-24 16:19:49.189948: evaluation of raw predictions\n",
      "2021-10-24 16:19:52.848907: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8183778978503475\n",
      "after:  0.8156732730565895\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-10-24 16:20:11.044228: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-10-24 16:20:11.065658: The split file contains 2 splits.\n",
      "2021-10-24 16:20:11.072833: Desired fold for training: 2\n",
      "2021-10-24 16:20:11.079596: INFO: You requested fold 2 for training but splits contain only 2 folds. I am now creating a random (but seeded) 80:20 split!\n",
      "2021-10-24 16:20:11.087375: This random 80:20 split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-24 16:20:15.245847: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-24 16:20:24.528749: Unable to plot network architecture:\n",
      "2021-10-24 16:20:24.596909: No module named 'hiddenlayer'\n",
      "2021-10-24 16:20:24.740541: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-24 16:20:24.868563: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-24 16:20:24.974388: \n",
      "\n",
      "2021-10-24 16:20:25.094062: \n",
      "epoch:  0\n",
      "2021-10-24 16:23:41.898482: train loss : -0.2389\n",
      "2021-10-24 16:23:55.350923: validation loss: -0.6184\n",
      "2021-10-24 16:23:55.355438: Average global foreground Dice: [0.6963]\n",
      "2021-10-24 16:23:55.362920: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:23:55.827195: lr: 0.00982\n",
      "2021-10-24 16:23:55.849755: This epoch took 210.677068 s\n",
      "\n",
      "2021-10-24 16:23:55.856828: \n",
      "epoch:  1\n",
      "2021-10-24 16:26:55.558709: train loss : -0.6599\n",
      "2021-10-24 16:27:09.050184: validation loss: -0.7338\n",
      "2021-10-24 16:27:09.054962: Average global foreground Dice: [0.8006]\n",
      "2021-10-24 16:27:09.061552: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:27:09.552909: lr: 0.009639\n",
      "2021-10-24 16:27:09.623401: saving checkpoint...\n",
      "2021-10-24 16:27:10.636101: done, saving took 1.05 seconds\n",
      "2021-10-24 16:27:11.179689: This epoch took 195.315481 s\n",
      "\n",
      "2021-10-24 16:27:11.192743: \n",
      "epoch:  2\n",
      "2021-10-24 16:30:10.797293: train loss : -0.7613\n",
      "2021-10-24 16:30:24.287940: validation loss: -0.7959\n",
      "2021-10-24 16:30:24.292886: Average global foreground Dice: [0.8167]\n",
      "2021-10-24 16:30:24.298473: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:30:24.814223: lr: 0.009458\n",
      "2021-10-24 16:30:24.879171: saving checkpoint...\n",
      "2021-10-24 16:30:25.972119: done, saving took 1.13 seconds\n",
      "2021-10-24 16:30:26.419363: This epoch took 195.220027 s\n",
      "\n",
      "2021-10-24 16:30:26.438511: \n",
      "epoch:  3\n",
      "2021-10-24 16:33:25.753616: train loss : -0.7957\n",
      "2021-10-24 16:33:39.260753: validation loss: -0.8106\n",
      "2021-10-24 16:33:39.265273: Average global foreground Dice: [0.8261]\n",
      "2021-10-24 16:33:39.273257: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:33:39.829906: lr: 0.009277\n",
      "2021-10-24 16:33:39.891814: saving checkpoint...\n",
      "2021-10-24 16:33:40.969778: done, saving took 1.11 seconds\n",
      "2021-10-24 16:33:41.432138: This epoch took 194.986816 s\n",
      "\n",
      "2021-10-24 16:33:41.462077: \n",
      "epoch:  4\n",
      "2021-10-24 16:36:40.592069: train loss : -0.8091\n",
      "2021-10-24 16:36:54.085686: validation loss: -0.8224\n",
      "2021-10-24 16:36:54.090173: Average global foreground Dice: [0.8358]\n",
      "2021-10-24 16:36:54.096238: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:36:54.671120: lr: 0.009095\n",
      "2021-10-24 16:36:54.732998: saving checkpoint...\n",
      "2021-10-24 16:36:55.792921: done, saving took 1.09 seconds\n",
      "2021-10-24 16:36:56.279621: This epoch took 194.810510 s\n",
      "\n",
      "2021-10-24 16:36:56.300285: \n",
      "epoch:  5\n",
      "2021-10-24 16:39:55.337314: train loss : -0.8225\n",
      "2021-10-24 16:40:08.829611: validation loss: -0.8253\n",
      "2021-10-24 16:40:08.833927: Average global foreground Dice: [0.8392]\n",
      "2021-10-24 16:40:08.840932: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:40:09.344505: lr: 0.008913\n",
      "2021-10-24 16:40:09.404686: saving checkpoint...\n",
      "2021-10-24 16:40:10.524012: done, saving took 1.15 seconds\n",
      "2021-10-24 16:40:11.017902: This epoch took 194.711008 s\n",
      "\n",
      "2021-10-24 16:40:11.035527: \n",
      "epoch:  6\n",
      "2021-10-24 16:43:10.265429: train loss : -0.8283\n",
      "2021-10-24 16:43:23.749088: validation loss: -0.8307\n",
      "2021-10-24 16:43:23.754769: Average global foreground Dice: [0.8428]\n",
      "2021-10-24 16:43:23.761584: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:43:24.349077: lr: 0.008731\n",
      "2021-10-24 16:43:24.406563: saving checkpoint...\n",
      "2021-10-24 16:43:25.559319: done, saving took 1.18 seconds\n",
      "2021-10-24 16:43:26.030099: This epoch took 194.987828 s\n",
      "\n",
      "2021-10-24 16:43:26.042338: \n",
      "epoch:  7\n",
      "2021-10-24 16:46:25.239428: train loss : -0.8321\n",
      "2021-10-24 16:46:38.738487: validation loss: -0.8272\n",
      "2021-10-24 16:46:38.742905: Average global foreground Dice: [0.8403]\n",
      "2021-10-24 16:46:38.750110: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:46:39.289551: lr: 0.008548\n",
      "2021-10-24 16:46:39.340976: saving checkpoint...\n",
      "2021-10-24 16:46:40.457259: done, saving took 1.15 seconds\n",
      "2021-10-24 16:46:40.958399: This epoch took 194.908051 s\n",
      "\n",
      "2021-10-24 16:46:40.967031: \n",
      "epoch:  8\n",
      "2021-10-24 16:49:40.464757: train loss : -0.8372\n",
      "2021-10-24 16:49:53.969375: validation loss: -0.8231\n",
      "2021-10-24 16:49:53.973957: Average global foreground Dice: [0.8365]\n",
      "2021-10-24 16:49:53.980542: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:49:54.507431: lr: 0.008364\n",
      "2021-10-24 16:49:54.547313: saving checkpoint...\n",
      "2021-10-24 16:49:55.656388: done, saving took 1.13 seconds\n",
      "2021-10-24 16:49:56.095288: This epoch took 195.120805 s\n",
      "\n",
      "2021-10-24 16:49:56.104683: \n",
      "epoch:  9\n",
      "2021-10-24 16:52:55.642510: train loss : -0.8415\n",
      "2021-10-24 16:53:09.154500: validation loss: -0.8298\n",
      "2021-10-24 16:53:09.159187: Average global foreground Dice: [0.8406]\n",
      "2021-10-24 16:53:09.165560: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:53:09.701430: lr: 0.008181\n",
      "2021-10-24 16:53:09.739639: saving checkpoint...\n",
      "2021-10-24 16:53:10.820111: done, saving took 1.10 seconds\n",
      "2021-10-24 16:53:11.290828: This epoch took 195.179713 s\n",
      "\n",
      "2021-10-24 16:53:11.299295: \n",
      "epoch:  10\n",
      "2021-10-24 16:56:10.891892: train loss : -0.8438\n",
      "2021-10-24 16:56:24.410502: validation loss: -0.8272\n",
      "2021-10-24 16:56:24.415142: Average global foreground Dice: [0.8385]\n",
      "2021-10-24 16:56:24.421611: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:56:24.954571: lr: 0.007996\n",
      "2021-10-24 16:56:24.999336: saving checkpoint...\n",
      "2021-10-24 16:56:26.089102: done, saving took 1.11 seconds\n",
      "2021-10-24 16:56:26.524270: This epoch took 195.217305 s\n",
      "\n",
      "2021-10-24 16:56:26.533204: \n",
      "epoch:  11\n",
      "2021-10-24 16:59:26.153882: train loss : -0.8462\n",
      "2021-10-24 16:59:39.675897: validation loss: -0.8244\n",
      "2021-10-24 16:59:39.680318: Average global foreground Dice: [0.8362]\n",
      "2021-10-24 16:59:39.687509: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 16:59:40.199681: lr: 0.007811\n",
      "2021-10-24 16:59:40.237581: saving checkpoint...\n",
      "2021-10-24 16:59:41.350101: done, saving took 1.13 seconds\n",
      "2021-10-24 16:59:41.785038: This epoch took 195.244239 s\n",
      "\n",
      "2021-10-24 16:59:41.793792: \n",
      "epoch:  12\n",
      "2021-10-24 17:02:41.418074: train loss : -0.8515\n",
      "2021-10-24 17:02:54.918193: validation loss: -0.8223\n",
      "2021-10-24 17:02:54.922853: Average global foreground Dice: [0.8338]\n",
      "2021-10-24 17:02:54.929908: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:02:55.490706: lr: 0.007626\n",
      "2021-10-24 17:02:55.557355: saving checkpoint...\n",
      "2021-10-24 17:02:56.655466: done, saving took 1.14 seconds\n",
      "2021-10-24 17:02:57.151786: This epoch took 195.350551 s\n",
      "\n",
      "2021-10-24 17:02:57.160051: \n",
      "epoch:  13\n",
      "2021-10-24 17:05:56.714574: train loss : -0.8527\n",
      "2021-10-24 17:06:10.193537: validation loss: -0.8311\n",
      "2021-10-24 17:06:10.198076: Average global foreground Dice: [0.843]\n",
      "2021-10-24 17:06:10.205443: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:06:10.738383: lr: 0.00744\n",
      "2021-10-24 17:06:10.777604: saving checkpoint...\n",
      "2021-10-24 17:06:11.876755: done, saving took 1.12 seconds\n",
      "2021-10-24 17:06:12.307589: This epoch took 195.140914 s\n",
      "\n",
      "2021-10-24 17:06:12.316059: \n",
      "epoch:  14\n",
      "2021-10-24 17:09:11.888185: train loss : -0.8551\n",
      "2021-10-24 17:09:25.390951: validation loss: -0.8317\n",
      "2021-10-24 17:09:25.395882: Average global foreground Dice: [0.8428]\n",
      "2021-10-24 17:09:25.403181: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:09:25.918406: lr: 0.007254\n",
      "2021-10-24 17:09:25.961221: saving checkpoint...\n",
      "2021-10-24 17:09:27.065701: done, saving took 1.12 seconds\n",
      "2021-10-24 17:09:27.567547: This epoch took 195.244143 s\n",
      "\n",
      "2021-10-24 17:09:27.576889: \n",
      "epoch:  15\n",
      "2021-10-24 17:12:27.100083: train loss : -0.8597\n",
      "2021-10-24 17:12:40.584228: validation loss: -0.8328\n",
      "2021-10-24 17:12:40.589142: Average global foreground Dice: [0.8429]\n",
      "2021-10-24 17:12:40.601152: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:12:41.160880: lr: 0.007067\n",
      "2021-10-24 17:12:41.201529: saving checkpoint...\n",
      "2021-10-24 17:12:42.306479: done, saving took 1.12 seconds\n",
      "2021-10-24 17:12:42.858814: This epoch took 195.275226 s\n",
      "\n",
      "2021-10-24 17:12:42.867675: \n",
      "epoch:  16\n",
      "2021-10-24 17:15:42.690679: train loss : -0.8605\n",
      "2021-10-24 17:15:56.185823: validation loss: -0.8306\n",
      "2021-10-24 17:15:56.190434: Average global foreground Dice: [0.8407]\n",
      "2021-10-24 17:15:56.197742: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:15:56.747689: lr: 0.00688\n",
      "2021-10-24 17:15:56.791020: saving checkpoint...\n",
      "2021-10-24 17:15:57.865984: done, saving took 1.09 seconds\n",
      "2021-10-24 17:15:58.314243: This epoch took 195.439651 s\n",
      "\n",
      "2021-10-24 17:15:58.322372: \n",
      "epoch:  17\n",
      "2021-10-24 17:18:58.182813: train loss : -0.8615\n",
      "2021-10-24 17:19:11.687631: validation loss: -0.8220\n",
      "2021-10-24 17:19:11.692454: Average global foreground Dice: [0.8338]\n",
      "2021-10-24 17:19:11.699386: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:19:12.289241: lr: 0.006692\n",
      "2021-10-24 17:19:12.339317: saving checkpoint...\n",
      "2021-10-24 17:19:13.450827: done, saving took 1.14 seconds\n",
      "2021-10-24 17:19:13.923532: This epoch took 195.594085 s\n",
      "\n",
      "2021-10-24 17:19:13.931799: \n",
      "epoch:  18\n",
      "2021-10-24 17:22:13.922566: train loss : -0.8646\n",
      "2021-10-24 17:22:27.444672: validation loss: -0.8297\n",
      "2021-10-24 17:22:27.449692: Average global foreground Dice: [0.8406]\n",
      "2021-10-24 17:22:27.457294: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:22:28.000073: lr: 0.006504\n",
      "2021-10-24 17:22:28.037791: saving checkpoint...\n",
      "2021-10-24 17:22:29.135133: done, saving took 1.12 seconds\n",
      "2021-10-24 17:22:29.598633: This epoch took 195.659354 s\n",
      "\n",
      "2021-10-24 17:22:29.606790: \n",
      "epoch:  19\n",
      "2021-10-24 17:25:29.553661: train loss : -0.8654\n",
      "2021-10-24 17:25:43.046974: validation loss: -0.8312\n",
      "2021-10-24 17:25:43.052573: Average global foreground Dice: [0.8415]\n",
      "2021-10-24 17:25:43.059647: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:25:43.618699: lr: 0.006314\n",
      "2021-10-24 17:25:43.661427: saving checkpoint...\n",
      "2021-10-24 17:25:44.765550: done, saving took 1.12 seconds\n",
      "2021-10-24 17:25:45.264056: This epoch took 195.650010 s\n",
      "\n",
      "2021-10-24 17:25:45.272446: \n",
      "epoch:  20\n",
      "2021-10-24 17:28:45.211194: train loss : -0.8654\n",
      "2021-10-24 17:28:58.688919: validation loss: -0.8282\n",
      "2021-10-24 17:28:58.693215: Average global foreground Dice: [0.8396]\n",
      "2021-10-24 17:28:58.699513: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:28:59.287506: lr: 0.006125\n",
      "2021-10-24 17:28:59.329283: saving checkpoint...\n",
      "2021-10-24 17:29:00.449567: done, saving took 1.14 seconds\n",
      "2021-10-24 17:29:00.881000: This epoch took 195.601408 s\n",
      "\n",
      "2021-10-24 17:29:00.891104: \n",
      "epoch:  21\n",
      "2021-10-24 17:32:00.811327: train loss : -0.8676\n",
      "2021-10-24 17:32:14.310374: validation loss: -0.8336\n",
      "2021-10-24 17:32:14.314568: Average global foreground Dice: [0.8443]\n",
      "2021-10-24 17:32:14.321455: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:32:14.809780: lr: 0.005934\n",
      "2021-10-24 17:32:14.849575: saving checkpoint...\n",
      "2021-10-24 17:32:15.952789: done, saving took 1.12 seconds\n",
      "2021-10-24 17:32:16.465436: This epoch took 195.567456 s\n",
      "\n",
      "2021-10-24 17:32:16.474289: \n",
      "epoch:  22\n",
      "2021-10-24 17:35:16.436061: train loss : -0.8683\n",
      "2021-10-24 17:35:29.947770: validation loss: -0.8335\n",
      "2021-10-24 17:35:29.952478: Average global foreground Dice: [0.8444]\n",
      "2021-10-24 17:35:29.959309: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:35:30.553303: lr: 0.005743\n",
      "2021-10-24 17:35:30.602040: saving checkpoint...\n",
      "2021-10-24 17:35:31.693426: done, saving took 1.12 seconds\n",
      "2021-10-24 17:35:32.183152: This epoch took 195.701973 s\n",
      "\n",
      "2021-10-24 17:35:32.191714: \n",
      "epoch:  23\n",
      "2021-10-24 17:38:32.193845: train loss : -0.8706\n",
      "2021-10-24 17:38:45.707114: validation loss: -0.8319\n",
      "2021-10-24 17:38:45.712270: Average global foreground Dice: [0.842]\n",
      "2021-10-24 17:38:45.719506: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:38:46.254645: lr: 0.005551\n",
      "2021-10-24 17:38:46.296455: saving checkpoint...\n",
      "2021-10-24 17:38:47.415062: done, saving took 1.14 seconds\n",
      "2021-10-24 17:38:47.859161: This epoch took 195.660492 s\n",
      "\n",
      "2021-10-24 17:38:47.867286: \n",
      "epoch:  24\n",
      "2021-10-24 17:41:48.094194: train loss : -0.8721\n",
      "2021-10-24 17:42:01.589217: validation loss: -0.8364\n",
      "2021-10-24 17:42:01.593582: Average global foreground Dice: [0.8481]\n",
      "2021-10-24 17:42:01.600415: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:42:02.155130: lr: 0.005359\n",
      "2021-10-24 17:42:02.192776: saving checkpoint...\n",
      "2021-10-24 17:42:03.287066: done, saving took 1.11 seconds\n",
      "2021-10-24 17:42:03.720230: This epoch took 195.845917 s\n",
      "\n",
      "2021-10-24 17:42:03.728549: \n",
      "epoch:  25\n",
      "2021-10-24 17:45:04.010607: train loss : -0.8743\n",
      "2021-10-24 17:45:17.519547: validation loss: -0.8378\n",
      "2021-10-24 17:45:17.524621: Average global foreground Dice: [0.8485]\n",
      "2021-10-24 17:45:17.531304: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:45:18.042542: lr: 0.005166\n",
      "2021-10-24 17:45:18.082065: saving checkpoint...\n",
      "2021-10-24 17:45:19.202045: done, saving took 1.14 seconds\n",
      "2021-10-24 17:45:19.677360: This epoch took 195.942227 s\n",
      "\n",
      "2021-10-24 17:45:19.686295: \n",
      "epoch:  26\n",
      "2021-10-24 17:48:19.890135: train loss : -0.8753\n",
      "2021-10-24 17:48:33.381615: validation loss: -0.8311\n",
      "2021-10-24 17:48:33.386569: Average global foreground Dice: [0.8419]\n",
      "2021-10-24 17:48:33.392890: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:48:33.889623: lr: 0.004971\n",
      "2021-10-24 17:48:33.931380: saving checkpoint...\n",
      "2021-10-24 17:48:35.025139: done, saving took 1.11 seconds\n",
      "2021-10-24 17:48:35.500753: This epoch took 195.807418 s\n",
      "\n",
      "2021-10-24 17:48:35.509042: \n",
      "epoch:  27\n",
      "2021-10-24 17:51:35.700157: train loss : -0.8759\n",
      "2021-10-24 17:51:49.201236: validation loss: -0.8385\n",
      "2021-10-24 17:51:49.205524: Average global foreground Dice: [0.8481]\n",
      "2021-10-24 17:51:49.212593: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:51:49.787356: lr: 0.004776\n",
      "2021-10-24 17:51:49.834239: saving checkpoint...\n",
      "2021-10-24 17:51:50.962817: done, saving took 1.15 seconds\n",
      "2021-10-24 17:51:51.441643: This epoch took 195.925964 s\n",
      "\n",
      "2021-10-24 17:51:51.450515: \n",
      "epoch:  28\n",
      "2021-10-24 17:54:51.706387: train loss : -0.8778\n",
      "2021-10-24 17:55:05.205952: validation loss: -0.8318\n",
      "2021-10-24 17:55:05.210474: Average global foreground Dice: [0.8419]\n",
      "2021-10-24 17:55:05.217352: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:55:05.733396: lr: 0.004581\n",
      "2021-10-24 17:55:05.775747: saving checkpoint...\n",
      "2021-10-24 17:55:06.901090: done, saving took 1.14 seconds\n",
      "2021-10-24 17:55:07.365745: This epoch took 195.907126 s\n",
      "\n",
      "2021-10-24 17:55:07.374493: \n",
      "epoch:  29\n",
      "2021-10-24 17:58:07.637203: train loss : -0.8769\n",
      "2021-10-24 17:58:21.124530: validation loss: -0.8306\n",
      "2021-10-24 17:58:21.129675: Average global foreground Dice: [0.8426]\n",
      "2021-10-24 17:58:21.136329: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 17:58:21.664054: lr: 0.004384\n",
      "2021-10-24 17:58:21.704091: saving checkpoint...\n",
      "2021-10-24 17:58:22.784372: done, saving took 1.10 seconds\n",
      "2021-10-24 17:58:23.223920: This epoch took 195.843347 s\n",
      "\n",
      "2021-10-24 17:58:23.232588: \n",
      "epoch:  30\n",
      "2021-10-24 18:01:23.469794: train loss : -0.8791\n",
      "2021-10-24 18:01:36.982090: validation loss: -0.8342\n",
      "2021-10-24 18:01:36.986677: Average global foreground Dice: [0.8449]\n",
      "2021-10-24 18:01:36.994155: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:01:37.533588: lr: 0.004186\n",
      "2021-10-24 18:01:37.594815: saving checkpoint...\n",
      "2021-10-24 18:01:38.703232: done, saving took 1.13 seconds\n",
      "2021-10-24 18:01:39.211961: This epoch took 195.972973 s\n",
      "\n",
      "2021-10-24 18:01:39.233690: \n",
      "epoch:  31\n",
      "2021-10-24 18:04:39.481895: train loss : -0.8816\n",
      "2021-10-24 18:04:52.999821: validation loss: -0.8299\n",
      "2021-10-24 18:04:53.004696: Average global foreground Dice: [0.8412]\n",
      "2021-10-24 18:04:53.013244: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:04:53.513892: lr: 0.003987\n",
      "2021-10-24 18:04:53.558436: saving checkpoint...\n",
      "2021-10-24 18:04:54.653403: done, saving took 1.11 seconds\n",
      "2021-10-24 18:04:55.099867: This epoch took 195.858057 s\n",
      "\n",
      "2021-10-24 18:04:55.112764: \n",
      "epoch:  32\n",
      "2021-10-24 18:07:55.672203: train loss : -0.8801\n",
      "2021-10-24 18:08:09.170772: validation loss: -0.8363\n",
      "2021-10-24 18:08:09.175253: Average global foreground Dice: [0.8444]\n",
      "2021-10-24 18:08:09.181630: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:08:09.782739: lr: 0.003787\n",
      "2021-10-24 18:08:09.839643: saving checkpoint...\n",
      "2021-10-24 18:08:10.964788: done, saving took 1.15 seconds\n",
      "2021-10-24 18:08:11.550846: This epoch took 196.431197 s\n",
      "\n",
      "2021-10-24 18:08:11.568077: \n",
      "epoch:  33\n",
      "2021-10-24 18:11:12.162881: train loss : -0.8817\n",
      "2021-10-24 18:11:25.682047: validation loss: -0.8327\n",
      "2021-10-24 18:11:25.687875: Average global foreground Dice: [0.8439]\n",
      "2021-10-24 18:11:25.695719: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:11:26.220572: lr: 0.003586\n",
      "2021-10-24 18:11:26.269052: saving checkpoint...\n",
      "2021-10-24 18:11:27.420590: done, saving took 1.17 seconds\n",
      "2021-10-24 18:11:27.948349: This epoch took 196.374518 s\n",
      "\n",
      "2021-10-24 18:11:27.963903: \n",
      "epoch:  34\n",
      "2021-10-24 18:14:28.530597: train loss : -0.8843\n",
      "2021-10-24 18:14:42.069953: validation loss: -0.8333\n",
      "2021-10-24 18:14:42.075371: Average global foreground Dice: [0.8429]\n",
      "2021-10-24 18:14:42.084673: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:14:42.645382: lr: 0.003384\n",
      "2021-10-24 18:14:42.692353: saving checkpoint...\n",
      "2021-10-24 18:14:43.727312: done, saving took 1.05 seconds\n",
      "2021-10-24 18:14:44.154091: This epoch took 196.183503 s\n",
      "\n",
      "2021-10-24 18:14:44.169590: \n",
      "epoch:  35\n",
      "2021-10-24 18:17:44.778395: train loss : -0.8851\n",
      "2021-10-24 18:17:58.302064: validation loss: -0.8356\n",
      "2021-10-24 18:17:58.307667: Average global foreground Dice: [0.8465]\n",
      "2021-10-24 18:17:58.314485: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:17:58.815025: lr: 0.00318\n",
      "2021-10-24 18:17:58.873797: saving checkpoint...\n",
      "2021-10-24 18:17:59.922400: done, saving took 1.07 seconds\n",
      "2021-10-24 18:18:00.393982: This epoch took 196.216700 s\n",
      "\n",
      "2021-10-24 18:18:00.415255: \n",
      "epoch:  36\n",
      "2021-10-24 18:21:01.005107: train loss : -0.8862\n",
      "2021-10-24 18:21:14.514577: validation loss: -0.8339\n",
      "2021-10-24 18:21:14.519646: Average global foreground Dice: [0.8435]\n",
      "2021-10-24 18:21:14.527031: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:21:15.094203: lr: 0.002975\n",
      "2021-10-24 18:21:15.154670: saving checkpoint...\n",
      "2021-10-24 18:21:16.210922: done, saving took 1.08 seconds\n",
      "2021-10-24 18:21:16.660651: This epoch took 196.237839 s\n",
      "\n",
      "2021-10-24 18:21:16.679232: \n",
      "epoch:  37\n",
      "2021-10-24 18:24:17.223517: train loss : -0.8870\n",
      "2021-10-24 18:24:30.747156: validation loss: -0.8372\n",
      "2021-10-24 18:24:30.752129: Average global foreground Dice: [0.8467]\n",
      "2021-10-24 18:24:30.759934: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:24:31.328067: lr: 0.002768\n",
      "2021-10-24 18:24:31.388408: saving checkpoint...\n",
      "2021-10-24 18:24:32.498948: done, saving took 1.14 seconds\n",
      "2021-10-24 18:24:32.972363: This epoch took 196.285597 s\n",
      "\n",
      "2021-10-24 18:24:32.993053: \n",
      "epoch:  38\n",
      "2021-10-24 18:27:33.564617: train loss : -0.8880\n",
      "2021-10-24 18:27:47.070179: validation loss: -0.8336\n",
      "2021-10-24 18:27:47.076040: Average global foreground Dice: [0.8436]\n",
      "2021-10-24 18:27:47.083359: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:27:47.603707: lr: 0.00256\n",
      "2021-10-24 18:27:47.654607: saving checkpoint...\n",
      "2021-10-24 18:27:48.764005: done, saving took 1.13 seconds\n",
      "2021-10-24 18:27:49.213881: This epoch took 196.212129 s\n",
      "\n",
      "2021-10-24 18:27:49.231735: \n",
      "epoch:  39\n",
      "2021-10-24 18:30:49.781325: train loss : -0.8884\n",
      "2021-10-24 18:31:03.287900: validation loss: -0.8313\n",
      "2021-10-24 18:31:03.293002: Average global foreground Dice: [0.8398]\n",
      "2021-10-24 18:31:03.301824: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:31:03.807715: lr: 0.002349\n",
      "2021-10-24 18:31:03.843557: This epoch took 194.603903 s\n",
      "\n",
      "2021-10-24 18:31:03.851281: \n",
      "epoch:  40\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-24 18:34:04.857699: train loss : -0.8902\n",
      "2021-10-24 18:34:18.376063: validation loss: -0.8325\n",
      "2021-10-24 18:34:18.381257: Average global foreground Dice: [0.8418]\n",
      "2021-10-24 18:34:18.389126: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:34:18.892980: lr: 0.002137\n",
      "2021-10-24 18:34:18.947917: saving checkpoint...\n",
      "2021-10-24 18:34:20.108385: done, saving took 1.18 seconds\n",
      "2021-10-24 18:34:20.581839: This epoch took 196.722869 s\n",
      "\n",
      "2021-10-24 18:34:20.602900: \n",
      "epoch:  41\n",
      "2021-10-24 18:37:21.111490: train loss : -0.8902\n",
      "2021-10-24 18:37:34.634158: validation loss: -0.8333\n",
      "2021-10-24 18:37:34.639050: Average global foreground Dice: [0.845]\n",
      "2021-10-24 18:37:34.646010: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:37:35.194911: lr: 0.001922\n",
      "2021-10-24 18:37:35.243142: saving checkpoint...\n",
      "2021-10-24 18:37:36.362480: done, saving took 1.14 seconds\n",
      "2021-10-24 18:37:36.914187: This epoch took 196.303683 s\n",
      "\n",
      "2021-10-24 18:37:36.933645: \n",
      "epoch:  42\n",
      "2021-10-24 18:40:37.543367: train loss : -0.8924\n",
      "2021-10-24 18:40:51.047939: validation loss: -0.8334\n",
      "2021-10-24 18:40:51.053080: Average global foreground Dice: [0.8443]\n",
      "2021-10-24 18:40:51.059664: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:40:51.623563: lr: 0.001704\n",
      "2021-10-24 18:40:51.675959: saving checkpoint...\n",
      "2021-10-24 18:40:52.819046: done, saving took 1.16 seconds\n",
      "2021-10-24 18:40:53.305315: This epoch took 196.364106 s\n",
      "\n",
      "2021-10-24 18:40:53.323579: \n",
      "epoch:  43\n",
      "2021-10-24 18:43:53.886818: train loss : -0.8919\n",
      "2021-10-24 18:44:07.389854: validation loss: -0.8325\n",
      "2021-10-24 18:44:07.393995: Average global foreground Dice: [0.8437]\n",
      "2021-10-24 18:44:07.400511: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:44:07.939168: lr: 0.001483\n",
      "2021-10-24 18:44:07.991062: saving checkpoint...\n",
      "2021-10-24 18:44:09.089123: done, saving took 1.12 seconds\n",
      "2021-10-24 18:44:09.795132: This epoch took 196.464301 s\n",
      "\n",
      "2021-10-24 18:44:09.815638: \n",
      "epoch:  44\n",
      "2021-10-24 18:47:10.244709: train loss : -0.8935\n",
      "2021-10-24 18:47:23.766731: validation loss: -0.8332\n",
      "2021-10-24 18:47:23.771177: Average global foreground Dice: [0.8428]\n",
      "2021-10-24 18:47:23.778421: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:47:24.271805: lr: 0.001259\n",
      "2021-10-24 18:47:24.322526: saving checkpoint...\n",
      "2021-10-24 18:47:25.464900: done, saving took 1.16 seconds\n",
      "2021-10-24 18:47:25.895721: This epoch took 196.073371 s\n",
      "\n",
      "2021-10-24 18:47:25.916142: \n",
      "epoch:  45\n",
      "2021-10-24 18:50:26.559340: train loss : -0.8945\n",
      "2021-10-24 18:50:40.058450: validation loss: -0.8353\n",
      "2021-10-24 18:50:40.063176: Average global foreground Dice: [0.8449]\n",
      "2021-10-24 18:50:40.072790: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:50:40.571276: lr: 0.00103\n",
      "2021-10-24 18:50:40.617624: saving checkpoint...\n",
      "2021-10-24 18:50:41.698539: done, saving took 1.10 seconds\n",
      "2021-10-24 18:50:42.174907: This epoch took 196.251664 s\n",
      "\n",
      "2021-10-24 18:50:42.189291: \n",
      "epoch:  46\n",
      "2021-10-24 18:53:42.764614: train loss : -0.8965\n",
      "2021-10-24 18:53:56.283766: validation loss: -0.8328\n",
      "2021-10-24 18:53:56.288130: Average global foreground Dice: [0.8431]\n",
      "2021-10-24 18:53:56.295005: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:53:56.810464: lr: 0.000795\n",
      "2021-10-24 18:53:56.866980: saving checkpoint...\n",
      "2021-10-24 18:53:57.951999: done, saving took 1.10 seconds\n",
      "2021-10-24 18:53:58.519123: This epoch took 196.323459 s\n",
      "\n",
      "2021-10-24 18:53:58.538424: \n",
      "epoch:  47\n",
      "2021-10-24 18:56:59.132831: train loss : -0.8969\n",
      "2021-10-24 18:57:12.651338: validation loss: -0.8366\n",
      "2021-10-24 18:57:12.655716: Average global foreground Dice: [0.8461]\n",
      "2021-10-24 18:57:12.662535: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 18:57:13.256841: lr: 0.000552\n",
      "2021-10-24 18:57:13.309756: saving checkpoint...\n",
      "2021-10-24 18:57:14.400476: done, saving took 1.11 seconds\n",
      "2021-10-24 18:57:14.850260: This epoch took 196.295041 s\n",
      "\n",
      "2021-10-24 18:57:14.868678: \n",
      "epoch:  48\n",
      "2021-10-24 19:00:15.512765: train loss : -0.8970\n",
      "2021-10-24 19:00:28.996361: validation loss: -0.8370\n",
      "2021-10-24 19:00:29.001189: Average global foreground Dice: [0.8466]\n",
      "2021-10-24 19:00:29.013641: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:00:29.559589: lr: 0.000296\n",
      "2021-10-24 19:00:29.622289: saving checkpoint...\n",
      "2021-10-24 19:00:30.737904: done, saving took 1.13 seconds\n",
      "2021-10-24 19:00:31.276778: This epoch took 196.400264 s\n",
      "\n",
      "2021-10-24 19:00:31.295285: \n",
      "epoch:  49\n",
      "2021-10-24 19:03:32.287638: train loss : -0.8991\n",
      "2021-10-24 19:03:45.800519: validation loss: -0.8327\n",
      "2021-10-24 19:03:45.806076: Average global foreground Dice: [0.8423]\n",
      "2021-10-24 19:03:45.815950: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:03:46.375590: lr: 0.0\n",
      "2021-10-24 19:03:46.407490: saving scheduled checkpoint file...\n",
      "2021-10-24 19:03:46.435362: saving checkpoint...\n",
      "2021-10-24 19:03:47.392352: done, saving took 0.98 seconds\n",
      "2021-10-24 19:03:47.838507: done\n",
      "2021-10-24 19:03:47.856525: This epoch took 196.554411 s\n",
      "\n",
      "2021-10-24 19:03:47.882207: saving checkpoint...\n",
      "2021-10-24 19:03:48.857545: done, saving took 0.99 seconds\n",
      "23090559_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090572_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090578_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090582_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090583_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090601_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090618_20161 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090623_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090632_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090638_20131 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090642_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090645_20141 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-24 19:05:47.986095: finished prediction\n",
      "2021-10-24 19:05:47.995601: evaluation of raw predictions\n",
      "2021-10-24 19:05:50.106542: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8359750599923186\n",
      "after:  0.8359750599923186\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-10-24 19:06:03.363327: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-10-24 19:06:03.386248: The split file contains 2 splits.\n",
      "2021-10-24 19:06:03.392496: Desired fold for training: 3\n",
      "2021-10-24 19:06:03.398860: INFO: You requested fold 3 for training but splits contain only 2 folds. I am now creating a random (but seeded) 80:20 split!\n",
      "2021-10-24 19:06:03.405875: This random 80:20 split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-24 19:06:07.560171: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-24 19:06:16.656745: Unable to plot network architecture:\n",
      "2021-10-24 19:06:16.772617: No module named 'hiddenlayer'\n",
      "2021-10-24 19:06:16.880615: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-24 19:06:16.976770: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-24 19:06:17.142101: \n",
      "\n",
      "2021-10-24 19:06:17.325146: \n",
      "epoch:  0\n",
      "2021-10-24 19:09:34.157400: train loss : -0.3071\n",
      "2021-10-24 19:09:47.651990: validation loss: -0.6651\n",
      "2021-10-24 19:09:47.656502: Average global foreground Dice: [0.7336]\n",
      "2021-10-24 19:09:47.663306: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:09:48.130426: lr: 0.00982\n",
      "2021-10-24 19:09:48.152444: This epoch took 210.694984 s\n",
      "\n",
      "2021-10-24 19:09:48.158111: \n",
      "epoch:  1\n",
      "2021-10-24 19:12:46.767506: train loss : -0.6759\n",
      "2021-10-24 19:13:00.258781: validation loss: -0.7464\n",
      "2021-10-24 19:13:00.263005: Average global foreground Dice: [0.8164]\n",
      "2021-10-24 19:13:00.269747: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:13:00.769947: lr: 0.009639\n",
      "2021-10-24 19:13:00.833949: saving checkpoint...\n",
      "2021-10-24 19:13:01.839029: done, saving took 1.05 seconds\n",
      "2021-10-24 19:13:02.315118: This epoch took 194.150783 s\n",
      "\n",
      "2021-10-24 19:13:02.323460: \n",
      "epoch:  2\n",
      "2021-10-24 19:16:00.848135: train loss : -0.7559\n",
      "2021-10-24 19:16:14.334497: validation loss: -0.8117\n",
      "2021-10-24 19:16:14.339264: Average global foreground Dice: [0.8287]\n",
      "2021-10-24 19:16:14.346052: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:16:14.890389: lr: 0.009458\n",
      "2021-10-24 19:16:14.933163: saving checkpoint...\n",
      "2021-10-24 19:16:16.068242: done, saving took 1.15 seconds\n",
      "2021-10-24 19:16:16.532532: This epoch took 194.201877 s\n",
      "\n",
      "2021-10-24 19:16:16.541910: \n",
      "epoch:  3\n",
      "2021-10-24 19:19:14.801013: train loss : -0.7989\n",
      "2021-10-24 19:19:28.291130: validation loss: -0.8214\n",
      "2021-10-24 19:19:28.297066: Average global foreground Dice: [0.8378]\n",
      "2021-10-24 19:19:28.303599: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:19:28.858623: lr: 0.009277\n",
      "2021-10-24 19:19:28.899181: saving checkpoint...\n",
      "2021-10-24 19:19:29.971205: done, saving took 1.09 seconds\n",
      "2021-10-24 19:19:30.515662: This epoch took 193.964619 s\n",
      "\n",
      "2021-10-24 19:19:30.524408: \n",
      "epoch:  4\n",
      "2021-10-24 19:22:28.623270: train loss : -0.8119\n",
      "2021-10-24 19:22:42.113350: validation loss: -0.8321\n",
      "2021-10-24 19:22:42.118301: Average global foreground Dice: [0.8456]\n",
      "2021-10-24 19:22:42.125548: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:22:42.638556: lr: 0.009095\n",
      "2021-10-24 19:22:42.678183: saving checkpoint...\n",
      "2021-10-24 19:22:43.785696: done, saving took 1.13 seconds\n",
      "2021-10-24 19:22:44.231262: This epoch took 193.699395 s\n",
      "\n",
      "2021-10-24 19:22:44.239965: \n",
      "epoch:  5\n",
      "2021-10-24 19:25:42.474105: train loss : -0.8203\n",
      "2021-10-24 19:25:55.972202: validation loss: -0.8295\n",
      "2021-10-24 19:25:55.977381: Average global foreground Dice: [0.8441]\n",
      "2021-10-24 19:25:55.984068: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:25:56.504347: lr: 0.008913\n",
      "2021-10-24 19:25:56.550919: saving checkpoint...\n",
      "2021-10-24 19:25:57.700815: done, saving took 1.17 seconds\n",
      "2021-10-24 19:25:58.226105: This epoch took 193.979300 s\n",
      "\n",
      "2021-10-24 19:25:58.234742: \n",
      "epoch:  6\n",
      "2021-10-24 19:28:56.593500: train loss : -0.8275\n",
      "2021-10-24 19:29:10.106490: validation loss: -0.8378\n",
      "2021-10-24 19:29:10.111096: Average global foreground Dice: [0.8512]\n",
      "2021-10-24 19:29:10.116943: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:29:10.665791: lr: 0.008731\n",
      "2021-10-24 19:29:10.707468: saving checkpoint...\n",
      "2021-10-24 19:29:11.868124: done, saving took 1.18 seconds\n",
      "2021-10-24 19:29:12.347675: This epoch took 194.106697 s\n",
      "\n",
      "2021-10-24 19:29:12.356139: \n",
      "epoch:  7\n",
      "2021-10-24 19:32:10.748062: train loss : -0.8302\n",
      "2021-10-24 19:32:24.236907: validation loss: -0.8373\n",
      "2021-10-24 19:32:24.241793: Average global foreground Dice: [0.8486]\n",
      "2021-10-24 19:32:24.248446: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:32:24.758801: lr: 0.008548\n",
      "2021-10-24 19:32:24.798096: saving checkpoint...\n",
      "2021-10-24 19:32:25.901828: done, saving took 1.12 seconds\n",
      "2021-10-24 19:32:26.393343: This epoch took 194.030946 s\n",
      "\n",
      "2021-10-24 19:32:26.418282: \n",
      "epoch:  8\n",
      "2021-10-24 19:35:25.136766: train loss : -0.8365\n",
      "2021-10-24 19:35:38.650529: validation loss: -0.8388\n",
      "2021-10-24 19:35:38.654994: Average global foreground Dice: [0.8501]\n",
      "2021-10-24 19:35:38.661929: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:35:39.162210: lr: 0.008364\n",
      "2021-10-24 19:35:39.200405: saving checkpoint...\n",
      "2021-10-24 19:35:40.299541: done, saving took 1.12 seconds\n",
      "2021-10-24 19:35:40.754303: This epoch took 194.329144 s\n",
      "\n",
      "2021-10-24 19:35:40.762787: \n",
      "epoch:  9\n",
      "2021-10-24 19:38:39.540963: train loss : -0.8416\n",
      "2021-10-24 19:38:53.046642: validation loss: -0.8376\n",
      "2021-10-24 19:38:53.050921: Average global foreground Dice: [0.8474]\n",
      "2021-10-24 19:38:53.058090: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:38:53.566916: lr: 0.008181\n",
      "2021-10-24 19:38:53.605599: saving checkpoint...\n",
      "2021-10-24 19:38:54.695460: done, saving took 1.11 seconds\n",
      "2021-10-24 19:38:55.172355: This epoch took 194.403607 s\n",
      "\n",
      "2021-10-24 19:38:55.181003: \n",
      "epoch:  10\n",
      "2021-10-24 19:41:53.985646: train loss : -0.8433\n",
      "2021-10-24 19:42:07.486750: validation loss: -0.8353\n",
      "2021-10-24 19:42:07.492036: Average global foreground Dice: [0.8476]\n",
      "2021-10-24 19:42:07.504890: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:42:08.025289: lr: 0.007996\n",
      "2021-10-24 19:42:08.067571: saving checkpoint...\n",
      "2021-10-24 19:42:09.161975: done, saving took 1.12 seconds\n",
      "2021-10-24 19:42:09.627872: This epoch took 194.439423 s\n",
      "\n",
      "2021-10-24 19:42:09.637007: \n",
      "epoch:  11\n",
      "2021-10-24 19:45:08.521969: train loss : -0.8463\n",
      "2021-10-24 19:45:22.027928: validation loss: -0.8472\n",
      "2021-10-24 19:45:22.032926: Average global foreground Dice: [0.8575]\n",
      "2021-10-24 19:45:22.040148: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:45:22.568842: lr: 0.007811\n",
      "2021-10-24 19:45:22.607549: saving checkpoint...\n",
      "2021-10-24 19:45:23.779262: done, saving took 1.19 seconds\n",
      "2021-10-24 19:45:24.263857: This epoch took 194.619936 s\n",
      "\n",
      "2021-10-24 19:45:24.273363: \n",
      "epoch:  12\n",
      "2021-10-24 19:48:23.200451: train loss : -0.8493\n",
      "2021-10-24 19:48:36.712567: validation loss: -0.8423\n",
      "2021-10-24 19:48:36.717820: Average global foreground Dice: [0.8541]\n",
      "2021-10-24 19:48:36.723924: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:48:37.268757: lr: 0.007626\n",
      "2021-10-24 19:48:37.308351: saving checkpoint...\n",
      "2021-10-24 19:48:38.406435: done, saving took 1.12 seconds\n",
      "2021-10-24 19:48:38.921892: This epoch took 194.640483 s\n",
      "\n",
      "2021-10-24 19:48:38.930620: \n",
      "epoch:  13\n",
      "2021-10-24 19:51:37.957740: train loss : -0.8507\n",
      "2021-10-24 19:51:51.475684: validation loss: -0.8380\n",
      "2021-10-24 19:51:51.479932: Average global foreground Dice: [0.8497]\n",
      "2021-10-24 19:51:51.486984: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:51:52.003292: lr: 0.00744\n",
      "2021-10-24 19:51:52.047175: saving checkpoint...\n",
      "2021-10-24 19:51:53.149737: done, saving took 1.12 seconds\n",
      "2021-10-24 19:51:53.574804: This epoch took 194.636885 s\n",
      "\n",
      "2021-10-24 19:51:53.583558: \n",
      "epoch:  14\n",
      "2021-10-24 19:54:52.641249: train loss : -0.8538\n",
      "2021-10-24 19:55:06.145430: validation loss: -0.8306\n",
      "2021-10-24 19:55:06.149841: Average global foreground Dice: [0.8392]\n",
      "2021-10-24 19:55:06.157485: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:55:06.678977: lr: 0.007254\n",
      "2021-10-24 19:55:06.717026: saving checkpoint...\n",
      "2021-10-24 19:55:07.835215: done, saving took 1.14 seconds\n",
      "2021-10-24 19:55:08.391299: This epoch took 194.800567 s\n",
      "\n",
      "2021-10-24 19:55:08.399598: \n",
      "epoch:  15\n",
      "2021-10-24 19:58:07.519516: train loss : -0.8555\n",
      "2021-10-24 19:58:21.037383: validation loss: -0.8448\n",
      "2021-10-24 19:58:21.042086: Average global foreground Dice: [0.8558]\n",
      "2021-10-24 19:58:21.048834: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 19:58:21.554718: lr: 0.007067\n",
      "2021-10-24 19:58:21.595253: saving checkpoint...\n",
      "2021-10-24 19:58:22.726876: done, saving took 1.15 seconds\n",
      "2021-10-24 19:58:23.187196: This epoch took 194.781129 s\n",
      "\n",
      "2021-10-24 19:58:23.195963: \n",
      "epoch:  16\n",
      "2021-10-24 20:01:22.821624: train loss : -0.8586\n",
      "2021-10-24 20:01:36.328006: validation loss: -0.8397\n",
      "2021-10-24 20:01:36.332357: Average global foreground Dice: [0.852]\n",
      "2021-10-24 20:01:36.339876: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:01:36.904104: lr: 0.00688\n",
      "2021-10-24 20:01:36.943414: saving checkpoint...\n",
      "2021-10-24 20:01:38.049835: done, saving took 1.13 seconds\n",
      "2021-10-24 20:01:38.485233: This epoch took 195.282063 s\n",
      "\n",
      "2021-10-24 20:01:38.493772: \n",
      "epoch:  17\n",
      "2021-10-24 20:04:38.083255: train loss : -0.8607\n",
      "2021-10-24 20:04:51.604350: validation loss: -0.8457\n",
      "2021-10-24 20:04:51.608621: Average global foreground Dice: [0.856]\n",
      "2021-10-24 20:04:51.616213: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:04:52.206330: lr: 0.006692\n",
      "2021-10-24 20:04:52.247398: saving checkpoint...\n",
      "2021-10-24 20:04:53.358740: done, saving took 1.13 seconds\n",
      "2021-10-24 20:04:53.893064: This epoch took 195.392284 s\n",
      "\n",
      "2021-10-24 20:04:53.901250: \n",
      "epoch:  18\n",
      "2021-10-24 20:07:53.513623: train loss : -0.8627\n",
      "2021-10-24 20:08:06.993000: validation loss: -0.8446\n",
      "2021-10-24 20:08:06.997364: Average global foreground Dice: [0.8556]\n",
      "2021-10-24 20:08:07.022184: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:08:07.583380: lr: 0.006504\n",
      "2021-10-24 20:08:07.624229: saving checkpoint...\n",
      "2021-10-24 20:08:08.697434: done, saving took 1.09 seconds\n",
      "2021-10-24 20:08:09.140573: This epoch took 195.232635 s\n",
      "\n",
      "2021-10-24 20:08:09.148990: \n",
      "epoch:  19\n",
      "2021-10-24 20:11:08.877974: train loss : -0.8635\n",
      "2021-10-24 20:11:22.393513: validation loss: -0.8412\n",
      "2021-10-24 20:11:22.397781: Average global foreground Dice: [0.8518]\n",
      "2021-10-24 20:11:22.404762: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:11:22.938565: lr: 0.006314\n",
      "2021-10-24 20:11:22.989018: saving checkpoint...\n",
      "2021-10-24 20:11:24.074382: done, saving took 1.10 seconds\n",
      "2021-10-24 20:11:24.538747: This epoch took 195.382639 s\n",
      "\n",
      "2021-10-24 20:11:24.558319: \n",
      "epoch:  20\n",
      "2021-10-24 20:14:24.392318: train loss : -0.8654\n",
      "2021-10-24 20:14:37.898515: validation loss: -0.8391\n",
      "2021-10-24 20:14:37.902966: Average global foreground Dice: [0.8479]\n",
      "2021-10-24 20:14:37.909149: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:14:38.432449: lr: 0.006125\n",
      "2021-10-24 20:14:38.479470: saving checkpoint...\n",
      "2021-10-24 20:14:39.559992: done, saving took 1.10 seconds\n",
      "2021-10-24 20:14:39.987528: This epoch took 195.422009 s\n",
      "\n",
      "2021-10-24 20:14:40.006894: \n",
      "epoch:  21\n",
      "2021-10-24 20:17:39.731362: train loss : -0.8662\n",
      "2021-10-24 20:17:53.243068: validation loss: -0.8430\n",
      "2021-10-24 20:17:53.248284: Average global foreground Dice: [0.8532]\n",
      "2021-10-24 20:17:53.255656: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:17:53.774890: lr: 0.005934\n",
      "2021-10-24 20:17:53.823981: saving checkpoint...\n",
      "2021-10-24 20:17:54.904573: done, saving took 1.10 seconds\n",
      "2021-10-24 20:17:55.436399: This epoch took 195.421902 s\n",
      "\n",
      "2021-10-24 20:17:55.455128: \n",
      "epoch:  22\n",
      "2021-10-24 20:20:55.137953: train loss : -0.8682\n",
      "2021-10-24 20:21:08.647611: validation loss: -0.8424\n",
      "2021-10-24 20:21:08.652105: Average global foreground Dice: [0.8539]\n",
      "2021-10-24 20:21:08.658649: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:21:09.272467: lr: 0.005743\n",
      "2021-10-24 20:21:09.315314: saving checkpoint...\n",
      "2021-10-24 20:21:10.432645: done, saving took 1.14 seconds\n",
      "2021-10-24 20:21:10.978644: This epoch took 195.516651 s\n",
      "\n",
      "2021-10-24 20:21:10.990609: \n",
      "epoch:  23\n",
      "2021-10-24 20:24:10.792255: train loss : -0.8706\n",
      "2021-10-24 20:24:24.295926: validation loss: -0.8463\n",
      "2021-10-24 20:24:24.301042: Average global foreground Dice: [0.8564]\n",
      "2021-10-24 20:24:24.307601: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:24:24.861260: lr: 0.005551\n",
      "2021-10-24 20:24:24.909134: saving checkpoint...\n",
      "2021-10-24 20:24:26.004306: done, saving took 1.11 seconds\n",
      "2021-10-24 20:24:26.466582: This epoch took 195.469139 s\n",
      "\n",
      "2021-10-24 20:24:26.486424: \n",
      "epoch:  24\n",
      "2021-10-24 20:27:26.598994: train loss : -0.8707\n",
      "2021-10-24 20:27:40.109450: validation loss: -0.8438\n",
      "2021-10-24 20:27:40.115873: Average global foreground Dice: [0.8552]\n",
      "2021-10-24 20:27:40.122932: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:27:40.663037: lr: 0.005359\n",
      "2021-10-24 20:27:40.712775: saving checkpoint...\n",
      "2021-10-24 20:27:41.793876: done, saving took 1.10 seconds\n",
      "2021-10-24 20:27:42.231386: This epoch took 195.738579 s\n",
      "\n",
      "2021-10-24 20:27:42.251078: \n",
      "epoch:  25\n",
      "2021-10-24 20:30:42.297537: train loss : -0.8722\n",
      "2021-10-24 20:30:55.781240: validation loss: -0.8458\n",
      "2021-10-24 20:30:55.785505: Average global foreground Dice: [0.8587]\n",
      "2021-10-24 20:30:55.792471: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:30:56.328140: lr: 0.005166\n",
      "2021-10-24 20:30:56.376411: saving checkpoint...\n",
      "2021-10-24 20:30:57.494452: done, saving took 1.14 seconds\n",
      "2021-10-24 20:30:57.936478: This epoch took 195.678261 s\n",
      "\n",
      "2021-10-24 20:30:57.949350: \n",
      "epoch:  26\n",
      "2021-10-24 20:33:58.092050: train loss : -0.8725\n",
      "2021-10-24 20:34:11.600411: validation loss: -0.8463\n",
      "2021-10-24 20:34:11.604885: Average global foreground Dice: [0.8563]\n",
      "2021-10-24 20:34:11.611393: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:34:12.103964: lr: 0.004971\n",
      "2021-10-24 20:34:12.155625: saving checkpoint...\n",
      "2021-10-24 20:34:13.229659: done, saving took 1.09 seconds\n",
      "2021-10-24 20:34:13.725153: This epoch took 195.769376 s\n",
      "\n",
      "2021-10-24 20:34:13.743847: \n",
      "epoch:  27\n",
      "2021-10-24 20:37:13.756466: train loss : -0.8751\n",
      "2021-10-24 20:37:27.280590: validation loss: -0.8443\n",
      "2021-10-24 20:37:27.285224: Average global foreground Dice: [0.8541]\n",
      "2021-10-24 20:37:27.292682: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:37:27.847142: lr: 0.004776\n",
      "2021-10-24 20:37:27.890557: saving checkpoint...\n",
      "2021-10-24 20:37:28.972230: done, saving took 1.10 seconds\n",
      "2021-10-24 20:37:29.414706: This epoch took 195.663735 s\n",
      "\n",
      "2021-10-24 20:37:29.427645: \n",
      "epoch:  28\n",
      "2021-10-24 20:40:29.430617: train loss : -0.8753\n",
      "2021-10-24 20:40:42.962739: validation loss: -0.8472\n",
      "2021-10-24 20:40:42.967549: Average global foreground Dice: [0.8575]\n",
      "2021-10-24 20:40:42.974368: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:40:43.480361: lr: 0.004581\n",
      "2021-10-24 20:40:43.532151: saving checkpoint...\n",
      "2021-10-24 20:40:44.667077: done, saving took 1.16 seconds\n",
      "2021-10-24 20:40:45.094934: This epoch took 195.660518 s\n",
      "\n",
      "2021-10-24 20:40:45.111120: \n",
      "epoch:  29\n",
      "2021-10-24 20:43:45.257913: train loss : -0.8781\n",
      "2021-10-24 20:43:58.758244: validation loss: -0.8403\n",
      "2021-10-24 20:43:58.762536: Average global foreground Dice: [0.8507]\n",
      "2021-10-24 20:43:58.769228: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:43:59.342475: lr: 0.004384\n",
      "2021-10-24 20:43:59.392658: saving checkpoint...\n",
      "2021-10-24 20:44:00.502725: done, saving took 1.13 seconds\n",
      "2021-10-24 20:44:00.941894: This epoch took 195.824826 s\n",
      "\n",
      "2021-10-24 20:44:00.961099: \n",
      "epoch:  30\n",
      "2021-10-24 20:47:01.103423: train loss : -0.8789\n",
      "2021-10-24 20:47:14.609956: validation loss: -0.8456\n",
      "2021-10-24 20:47:14.614327: Average global foreground Dice: [0.8555]\n",
      "2021-10-24 20:47:14.620962: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:47:15.162141: lr: 0.004186\n",
      "2021-10-24 20:47:15.210159: saving checkpoint...\n",
      "2021-10-24 20:47:16.323178: done, saving took 1.13 seconds\n",
      "2021-10-24 20:47:16.817091: This epoch took 195.849412 s\n",
      "\n",
      "2021-10-24 20:47:16.834619: \n",
      "epoch:  31\n",
      "2021-10-24 20:50:16.962036: train loss : -0.8783\n",
      "2021-10-24 20:50:30.482783: validation loss: -0.8401\n",
      "2021-10-24 20:50:30.490282: Average global foreground Dice: [0.8521]\n",
      "2021-10-24 20:50:30.497220: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:50:30.988949: lr: 0.003987\n",
      "2021-10-24 20:50:31.036572: saving checkpoint...\n",
      "2021-10-24 20:50:32.122655: done, saving took 1.10 seconds\n",
      "2021-10-24 20:50:32.578667: This epoch took 195.738247 s\n",
      "\n",
      "2021-10-24 20:50:32.597607: \n",
      "epoch:  32\n",
      "2021-10-24 20:53:32.938265: train loss : -0.8813\n",
      "2021-10-24 20:53:46.457581: validation loss: -0.8402\n",
      "2021-10-24 20:53:46.462327: Average global foreground Dice: [0.851]\n",
      "2021-10-24 20:53:46.468738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:53:47.029584: lr: 0.003787\n",
      "2021-10-24 20:53:47.076813: saving checkpoint...\n",
      "2021-10-24 20:53:48.173058: done, saving took 1.12 seconds\n",
      "2021-10-24 20:53:48.686304: This epoch took 196.081703 s\n",
      "\n",
      "2021-10-24 20:53:48.705587: \n",
      "epoch:  33\n",
      "2021-10-24 20:56:49.157914: train loss : -0.8813\n",
      "2021-10-24 20:57:02.669090: validation loss: -0.8491\n",
      "2021-10-24 20:57:02.673124: Average global foreground Dice: [0.8595]\n",
      "2021-10-24 20:57:02.679794: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 20:57:03.221306: lr: 0.003586\n",
      "2021-10-24 20:57:03.273523: saving checkpoint...\n",
      "2021-10-24 20:57:04.376037: done, saving took 1.12 seconds\n",
      "2021-10-24 20:57:04.957453: This epoch took 196.245773 s\n",
      "\n",
      "2021-10-24 20:57:04.977200: \n",
      "epoch:  34\n",
      "2021-10-24 21:00:05.362079: train loss : -0.8827\n",
      "2021-10-24 21:00:18.879603: validation loss: -0.8415\n",
      "2021-10-24 21:00:18.884384: Average global foreground Dice: [0.8537]\n",
      "2021-10-24 21:00:18.891463: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:00:19.393363: lr: 0.003384\n",
      "2021-10-24 21:00:19.449546: saving checkpoint...\n",
      "2021-10-24 21:00:20.554314: done, saving took 1.12 seconds\n",
      "2021-10-24 21:00:21.027516: This epoch took 196.044086 s\n",
      "\n",
      "2021-10-24 21:00:21.055364: \n",
      "epoch:  35\n",
      "2021-10-24 21:03:21.432864: train loss : -0.8840\n",
      "2021-10-24 21:03:34.944624: validation loss: -0.8466\n",
      "2021-10-24 21:03:34.948809: Average global foreground Dice: [0.856]\n",
      "2021-10-24 21:03:34.955522: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:03:35.493067: lr: 0.00318\n",
      "2021-10-24 21:03:35.545927: saving checkpoint...\n",
      "2021-10-24 21:03:36.644983: done, saving took 1.12 seconds\n",
      "2021-10-24 21:03:37.162036: This epoch took 196.091770 s\n",
      "\n",
      "2021-10-24 21:03:37.182102: \n",
      "epoch:  36\n",
      "2021-10-24 21:06:37.635693: train loss : -0.8847\n",
      "2021-10-24 21:06:51.170818: validation loss: -0.8447\n",
      "2021-10-24 21:06:51.175451: Average global foreground Dice: [0.8552]\n",
      "2021-10-24 21:06:51.182359: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:06:51.753886: lr: 0.002975\n",
      "2021-10-24 21:06:51.802243: saving checkpoint...\n",
      "2021-10-24 21:06:52.900029: done, saving took 1.12 seconds\n",
      "2021-10-24 21:06:53.360753: This epoch took 196.171076 s\n",
      "\n",
      "2021-10-24 21:06:53.380265: \n",
      "epoch:  37\n",
      "2021-10-24 21:09:53.854273: train loss : -0.8872\n",
      "2021-10-24 21:10:07.358170: validation loss: -0.8442\n",
      "2021-10-24 21:10:07.362674: Average global foreground Dice: [0.8545]\n",
      "2021-10-24 21:10:07.369496: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:10:07.937498: lr: 0.002768\n",
      "2021-10-24 21:10:07.991174: saving checkpoint...\n",
      "2021-10-24 21:10:09.112023: done, saving took 1.14 seconds\n",
      "2021-10-24 21:10:09.555897: This epoch took 196.168413 s\n",
      "\n",
      "2021-10-24 21:10:09.573916: \n",
      "epoch:  38\n",
      "2021-10-24 21:13:10.033255: train loss : -0.8884\n",
      "2021-10-24 21:13:23.545261: validation loss: -0.8459\n",
      "2021-10-24 21:13:23.549670: Average global foreground Dice: [0.857]\n",
      "2021-10-24 21:13:23.555330: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:13:24.057527: lr: 0.00256\n",
      "2021-10-24 21:13:24.108918: saving checkpoint...\n",
      "2021-10-24 21:13:25.222131: done, saving took 1.13 seconds\n",
      "2021-10-24 21:13:25.734516: This epoch took 196.153501 s\n",
      "\n",
      "2021-10-24 21:13:25.751969: \n",
      "epoch:  39\n",
      "2021-10-24 21:16:26.220123: train loss : -0.8869\n",
      "2021-10-24 21:16:39.726118: validation loss: -0.8422\n",
      "2021-10-24 21:16:39.730926: Average global foreground Dice: [0.8534]\n",
      "2021-10-24 21:16:39.739423: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:16:40.318105: lr: 0.002349\n",
      "2021-10-24 21:16:40.365588: saving checkpoint...\n",
      "2021-10-24 21:16:41.436803: done, saving took 1.09 seconds\n",
      "2021-10-24 21:16:42.061702: This epoch took 196.303185 s\n",
      "\n",
      "2021-10-24 21:16:42.080043: \n",
      "epoch:  40\n",
      "2021-10-24 21:19:42.865904: train loss : -0.8892\n",
      "2021-10-24 21:19:56.367764: validation loss: -0.8391\n",
      "2021-10-24 21:19:56.372035: Average global foreground Dice: [0.8493]\n",
      "2021-10-24 21:19:56.378818: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:19:56.874765: lr: 0.002137\n",
      "2021-10-24 21:19:56.903404: This epoch took 194.815837 s\n",
      "\n",
      "2021-10-24 21:19:56.909889: \n",
      "epoch:  41\n",
      "2021-10-24 21:22:57.755781: train loss : -0.8903\n",
      "2021-10-24 21:23:11.268363: validation loss: -0.8434\n",
      "2021-10-24 21:23:11.272996: Average global foreground Dice: [0.8542]\n",
      "2021-10-24 21:23:11.279376: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:23:11.813110: lr: 0.001922\n",
      "2021-10-24 21:23:11.832417: This epoch took 194.916174 s\n",
      "\n",
      "2021-10-24 21:23:11.839489: \n",
      "epoch:  42\n",
      "2021-10-24 21:26:12.665371: train loss : -0.8913\n",
      "2021-10-24 21:26:26.173390: validation loss: -0.8411\n",
      "2021-10-24 21:26:26.177794: Average global foreground Dice: [0.8514]\n",
      "2021-10-24 21:26:26.184153: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:26:26.772123: lr: 0.001704\n",
      "2021-10-24 21:26:26.795922: This epoch took 194.949138 s\n",
      "\n",
      "2021-10-24 21:26:26.802881: \n",
      "epoch:  43\n",
      "2021-10-24 21:29:27.646216: train loss : -0.8917\n",
      "2021-10-24 21:29:41.169516: validation loss: -0.8425\n",
      "2021-10-24 21:29:41.173763: Average global foreground Dice: [0.8543]\n",
      "2021-10-24 21:29:41.179682: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:29:41.725157: lr: 0.001483\n",
      "2021-10-24 21:29:41.763471: saving checkpoint...\n",
      "2021-10-24 21:29:42.886478: done, saving took 1.14 seconds\n",
      "2021-10-24 21:29:43.322553: This epoch took 196.512511 s\n",
      "\n",
      "2021-10-24 21:29:43.330790: \n",
      "epoch:  44\n",
      "2021-10-24 21:32:44.127639: train loss : -0.8934\n",
      "2021-10-24 21:32:57.652104: validation loss: -0.8412\n",
      "2021-10-24 21:32:57.656378: Average global foreground Dice: [0.8505]\n",
      "2021-10-24 21:32:57.662894: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:32:58.151142: lr: 0.001259\n",
      "2021-10-24 21:32:58.170524: This epoch took 194.833139 s\n",
      "\n",
      "2021-10-24 21:32:58.177583: \n",
      "epoch:  45\n",
      "2021-10-24 21:35:58.961307: train loss : -0.8946\n",
      "2021-10-24 21:36:12.466415: validation loss: -0.8412\n",
      "2021-10-24 21:36:12.470798: Average global foreground Dice: [0.8508]\n",
      "2021-10-24 21:36:12.478164: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:36:13.037525: lr: 0.00103\n",
      "2021-10-24 21:36:13.061516: This epoch took 194.877023 s\n",
      "\n",
      "2021-10-24 21:36:13.068466: \n",
      "epoch:  46\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-24 21:39:13.623476: train loss : -0.8957\n",
      "2021-10-24 21:39:27.139353: validation loss: -0.8376\n",
      "2021-10-24 21:39:27.143535: Average global foreground Dice: [0.8486]\n",
      "2021-10-24 21:39:27.149673: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:39:27.652062: lr: 0.000795\n",
      "2021-10-24 21:39:27.674906: This epoch took 194.599746 s\n",
      "\n",
      "2021-10-24 21:39:27.681940: \n",
      "epoch:  47\n",
      "2021-10-24 21:42:28.188291: train loss : -0.8952\n",
      "2021-10-24 21:42:41.697711: validation loss: -0.8398\n",
      "2021-10-24 21:42:41.702407: Average global foreground Dice: [0.8507]\n",
      "2021-10-24 21:42:41.708687: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:42:42.242358: lr: 0.000552\n",
      "2021-10-24 21:42:42.264740: This epoch took 194.575569 s\n",
      "\n",
      "2021-10-24 21:42:42.271478: \n",
      "epoch:  48\n",
      "2021-10-24 21:45:42.926270: train loss : -0.8974\n",
      "2021-10-24 21:45:56.441639: validation loss: -0.8438\n",
      "2021-10-24 21:45:56.446295: Average global foreground Dice: [0.8544]\n",
      "2021-10-24 21:45:56.453100: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:45:56.993740: lr: 0.000296\n",
      "2021-10-24 21:45:57.012025: This epoch took 194.708218 s\n",
      "\n",
      "2021-10-24 21:45:57.018618: \n",
      "epoch:  49\n",
      "2021-10-24 21:48:57.635880: train loss : -0.8969\n",
      "2021-10-24 21:49:11.143610: validation loss: -0.8454\n",
      "2021-10-24 21:49:11.148071: Average global foreground Dice: [0.8551]\n",
      "2021-10-24 21:49:11.156070: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:49:11.705513: lr: 0.0\n",
      "2021-10-24 21:49:11.720886: saving scheduled checkpoint file...\n",
      "2021-10-24 21:49:11.750935: saving checkpoint...\n",
      "2021-10-24 21:49:12.715417: done, saving took 0.98 seconds\n",
      "2021-10-24 21:49:13.203496: done\n",
      "2021-10-24 21:49:13.212761: This epoch took 196.186833 s\n",
      "\n",
      "2021-10-24 21:49:13.238732: saving checkpoint...\n",
      "2021-10-24 21:49:14.198663: done, saving took 0.98 seconds\n",
      "23090559_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090561_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090580_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090585_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090591_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090594_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090598_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090610_20151 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090611_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090622_20150 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090630_20130 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090639_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-24 21:51:15.602918: finished prediction\n",
      "2021-10-24 21:51:15.608304: evaluation of raw predictions\n",
      "2021-10-24 21:51:17.710832: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.845940120988292\n",
      "after:  0.8458202553518164\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 202, 'num_pool_per_axis': [5, 5], 'patch_size': array([128, 128]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-10-24 21:51:30.419887: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-10-24 21:51:30.447813: The split file contains 2 splits.\n",
      "2021-10-24 21:51:30.453307: Desired fold for training: 4\n",
      "2021-10-24 21:51:30.459938: INFO: You requested fold 4 for training but splits contain only 2 folds. I am now creating a random (but seeded) 80:20 split!\n",
      "2021-10-24 21:51:30.467949: This random 80:20 split has 64 training and 16 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-24 21:51:34.637051: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-24 21:51:45.825256: Unable to plot network architecture:\n",
      "2021-10-24 21:51:45.936460: No module named 'hiddenlayer'\n",
      "2021-10-24 21:51:46.130623: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-24 21:51:46.184592: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-24 21:51:46.282207: \n",
      "\n",
      "2021-10-24 21:51:46.365255: \n",
      "epoch:  0\n",
      "2021-10-24 21:55:02.196150: train loss : -0.2671\n",
      "2021-10-24 21:55:15.681125: validation loss: -0.6490\n",
      "2021-10-24 21:55:15.689395: Average global foreground Dice: [0.7249]\n",
      "2021-10-24 21:55:15.691819: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:55:16.173418: lr: 0.00982\n",
      "2021-10-24 21:55:16.192772: This epoch took 209.716221 s\n",
      "\n",
      "2021-10-24 21:55:16.198856: \n",
      "epoch:  1\n",
      "2021-10-24 21:58:15.115894: train loss : -0.6793\n",
      "2021-10-24 21:58:28.562808: validation loss: -0.7337\n",
      "2021-10-24 21:58:28.568099: Average global foreground Dice: [0.7982]\n",
      "2021-10-24 21:58:28.575493: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 21:58:29.085123: lr: 0.009639\n",
      "2021-10-24 21:58:29.140976: saving checkpoint...\n",
      "2021-10-24 21:58:30.158081: done, saving took 1.05 seconds\n",
      "2021-10-24 21:58:30.606269: This epoch took 194.401820 s\n",
      "\n",
      "2021-10-24 21:58:30.614437: \n",
      "epoch:  2\n",
      "2021-10-24 22:01:29.092119: train loss : -0.7706\n",
      "2021-10-24 22:01:42.540669: validation loss: -0.8009\n",
      "2021-10-24 22:01:42.545529: Average global foreground Dice: [0.8224]\n",
      "2021-10-24 22:01:42.551485: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:01:43.056829: lr: 0.009458\n",
      "2021-10-24 22:01:43.108621: saving checkpoint...\n",
      "2021-10-24 22:01:44.246897: done, saving took 1.18 seconds\n",
      "2021-10-24 22:01:44.748765: This epoch took 194.128371 s\n",
      "\n",
      "2021-10-24 22:01:44.757569: \n",
      "epoch:  3\n",
      "2021-10-24 22:04:42.973184: train loss : -0.8004\n",
      "2021-10-24 22:04:56.421646: validation loss: -0.8067\n",
      "2021-10-24 22:04:56.426030: Average global foreground Dice: [0.8283]\n",
      "2021-10-24 22:04:56.432904: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:04:56.962026: lr: 0.009277\n",
      "2021-10-24 22:04:57.014067: saving checkpoint...\n",
      "2021-10-24 22:04:58.101743: done, saving took 1.12 seconds\n",
      "2021-10-24 22:04:58.624892: This epoch took 193.861017 s\n",
      "\n",
      "2021-10-24 22:04:58.633550: \n",
      "epoch:  4\n",
      "2021-10-24 22:07:56.796019: train loss : -0.8164\n",
      "2021-10-24 22:08:10.243724: validation loss: -0.8121\n",
      "2021-10-24 22:08:10.248640: Average global foreground Dice: [0.8301]\n",
      "2021-10-24 22:08:10.255281: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:08:10.803059: lr: 0.009095\n",
      "2021-10-24 22:08:10.863198: saving checkpoint...\n",
      "2021-10-24 22:08:11.976206: done, saving took 1.15 seconds\n",
      "2021-10-24 22:08:12.440868: This epoch took 193.800567 s\n",
      "\n",
      "2021-10-24 22:08:12.450736: \n",
      "epoch:  5\n",
      "2021-10-24 22:11:10.599980: train loss : -0.8239\n",
      "2021-10-24 22:11:24.073961: validation loss: -0.8280\n",
      "2021-10-24 22:11:24.080763: Average global foreground Dice: [0.8434]\n",
      "2021-10-24 22:11:24.088047: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:11:24.616607: lr: 0.008913\n",
      "2021-10-24 22:11:24.654405: saving checkpoint...\n",
      "2021-10-24 22:11:25.767296: done, saving took 1.13 seconds\n",
      "2021-10-24 22:11:26.244543: This epoch took 193.786933 s\n",
      "\n",
      "2021-10-24 22:11:26.252941: \n",
      "epoch:  6\n",
      "2021-10-24 22:14:24.557034: train loss : -0.8296\n",
      "2021-10-24 22:14:38.006505: validation loss: -0.8300\n",
      "2021-10-24 22:14:38.011215: Average global foreground Dice: [0.8482]\n",
      "2021-10-24 22:14:38.020338: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:14:38.512670: lr: 0.008731\n",
      "2021-10-24 22:14:38.559405: saving checkpoint...\n",
      "2021-10-24 22:14:39.675581: done, saving took 1.14 seconds\n",
      "2021-10-24 22:14:40.109632: This epoch took 193.851017 s\n",
      "\n",
      "2021-10-24 22:14:40.123190: \n",
      "epoch:  7\n",
      "2021-10-24 22:17:38.404788: train loss : -0.8349\n",
      "2021-10-24 22:17:51.851311: validation loss: -0.8316\n",
      "2021-10-24 22:17:51.855648: Average global foreground Dice: [0.8463]\n",
      "2021-10-24 22:17:51.864465: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:17:52.431226: lr: 0.008548\n",
      "2021-10-24 22:17:52.481606: saving checkpoint...\n",
      "2021-10-24 22:17:53.568366: done, saving took 1.11 seconds\n",
      "2021-10-24 22:17:54.032346: This epoch took 193.903009 s\n",
      "\n",
      "2021-10-24 22:17:54.046900: \n",
      "epoch:  8\n",
      "2021-10-24 22:20:52.674662: train loss : -0.8373\n",
      "2021-10-24 22:21:06.143711: validation loss: -0.8318\n",
      "2021-10-24 22:21:06.148894: Average global foreground Dice: [0.8444]\n",
      "2021-10-24 22:21:06.156223: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:21:06.680258: lr: 0.008364\n",
      "2021-10-24 22:21:06.724456: saving checkpoint...\n",
      "2021-10-24 22:21:07.825227: done, saving took 1.12 seconds\n",
      "2021-10-24 22:21:08.288249: This epoch took 194.234673 s\n",
      "\n",
      "2021-10-24 22:21:08.304551: \n",
      "epoch:  9\n",
      "2021-10-24 22:24:07.001653: train loss : -0.8415\n",
      "2021-10-24 22:24:20.453288: validation loss: -0.8335\n",
      "2021-10-24 22:24:20.458028: Average global foreground Dice: [0.8477]\n",
      "2021-10-24 22:24:20.465118: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:24:21.000405: lr: 0.008181\n",
      "2021-10-24 22:24:21.045321: saving checkpoint...\n",
      "2021-10-24 22:24:22.116463: done, saving took 1.09 seconds\n",
      "2021-10-24 22:24:22.629553: This epoch took 194.317802 s\n",
      "\n",
      "2021-10-24 22:24:22.643672: \n",
      "epoch:  10\n",
      "2021-10-24 22:27:21.434546: train loss : -0.8448\n",
      "2021-10-24 22:27:34.913526: validation loss: -0.8328\n",
      "2021-10-24 22:27:34.918506: Average global foreground Dice: [0.8473]\n",
      "2021-10-24 22:27:34.930262: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:27:35.499487: lr: 0.007996\n",
      "2021-10-24 22:27:35.541872: saving checkpoint...\n",
      "2021-10-24 22:27:36.655800: done, saving took 1.13 seconds\n",
      "2021-10-24 22:27:37.214910: This epoch took 194.564375 s\n",
      "\n",
      "2021-10-24 22:27:37.230280: \n",
      "epoch:  11\n",
      "2021-10-24 22:30:35.860377: train loss : -0.8480\n",
      "2021-10-24 22:30:49.327211: validation loss: -0.8383\n",
      "2021-10-24 22:30:49.331835: Average global foreground Dice: [0.8531]\n",
      "2021-10-24 22:30:49.338742: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:30:49.824818: lr: 0.007811\n",
      "2021-10-24 22:30:49.869525: saving checkpoint...\n",
      "2021-10-24 22:30:50.954245: done, saving took 1.10 seconds\n",
      "2021-10-24 22:30:51.412033: This epoch took 194.173791 s\n",
      "\n",
      "2021-10-24 22:30:51.426468: \n",
      "epoch:  12\n",
      "2021-10-24 22:33:49.967989: train loss : -0.8521\n",
      "2021-10-24 22:34:03.435780: validation loss: -0.8378\n",
      "2021-10-24 22:34:03.440109: Average global foreground Dice: [0.8526]\n",
      "2021-10-24 22:34:03.447101: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:34:03.974695: lr: 0.007626\n",
      "2021-10-24 22:34:04.019155: saving checkpoint...\n",
      "2021-10-24 22:34:05.192853: done, saving took 1.19 seconds\n",
      "2021-10-24 22:34:05.746625: This epoch took 194.313067 s\n",
      "\n",
      "2021-10-24 22:34:05.762133: \n",
      "epoch:  13\n",
      "2021-10-24 22:37:04.483712: train loss : -0.8535\n",
      "2021-10-24 22:37:17.925117: validation loss: -0.8349\n",
      "2021-10-24 22:37:17.929556: Average global foreground Dice: [0.8494]\n",
      "2021-10-24 22:37:17.937068: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:37:18.437821: lr: 0.00744\n",
      "2021-10-24 22:37:18.478862: saving checkpoint...\n",
      "2021-10-24 22:37:19.566130: done, saving took 1.11 seconds\n",
      "2021-10-24 22:37:20.047319: This epoch took 194.277445 s\n",
      "\n",
      "2021-10-24 22:37:20.061718: \n",
      "epoch:  14\n",
      "2021-10-24 22:40:18.898462: train loss : -0.8561\n",
      "2021-10-24 22:40:32.357677: validation loss: -0.8395\n",
      "2021-10-24 22:40:32.362124: Average global foreground Dice: [0.8533]\n",
      "2021-10-24 22:40:32.369827: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:40:32.860515: lr: 0.007254\n",
      "2021-10-24 22:40:32.906566: saving checkpoint...\n",
      "2021-10-24 22:40:33.987832: done, saving took 1.10 seconds\n",
      "2021-10-24 22:40:34.424916: This epoch took 194.356458 s\n",
      "\n",
      "2021-10-24 22:40:34.438391: \n",
      "epoch:  15\n",
      "2021-10-24 22:43:33.218078: train loss : -0.8574\n",
      "2021-10-24 22:43:46.680515: validation loss: -0.8394\n",
      "2021-10-24 22:43:46.685225: Average global foreground Dice: [0.8539]\n",
      "2021-10-24 22:43:46.692225: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:43:47.189428: lr: 0.007067\n",
      "2021-10-24 22:43:47.236903: saving checkpoint...\n",
      "2021-10-24 22:43:48.351099: done, saving took 1.13 seconds\n",
      "2021-10-24 22:43:48.845577: This epoch took 194.400370 s\n",
      "\n",
      "2021-10-24 22:43:48.858832: \n",
      "epoch:  16\n",
      "2021-10-24 22:46:48.190327: train loss : -0.8581\n",
      "2021-10-24 22:47:01.660403: validation loss: -0.8399\n",
      "2021-10-24 22:47:01.664681: Average global foreground Dice: [0.8541]\n",
      "2021-10-24 22:47:01.673325: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:47:02.212524: lr: 0.00688\n",
      "2021-10-24 22:47:02.261553: saving checkpoint...\n",
      "2021-10-24 22:47:03.398769: done, saving took 1.16 seconds\n",
      "2021-10-24 22:47:03.920179: This epoch took 195.054559 s\n",
      "\n",
      "2021-10-24 22:47:03.936529: \n",
      "epoch:  17\n",
      "2021-10-24 22:50:03.382044: train loss : -0.8606\n",
      "2021-10-24 22:50:16.844536: validation loss: -0.8449\n",
      "2021-10-24 22:50:16.848706: Average global foreground Dice: [0.8586]\n",
      "2021-10-24 22:50:16.855397: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:50:17.395066: lr: 0.006692\n",
      "2021-10-24 22:50:17.442607: saving checkpoint...\n",
      "2021-10-24 22:50:18.543522: done, saving took 1.12 seconds\n",
      "2021-10-24 22:50:19.036638: This epoch took 195.092884 s\n",
      "\n",
      "2021-10-24 22:50:19.056811: \n",
      "epoch:  18\n",
      "2021-10-24 22:53:18.463355: train loss : -0.8633\n",
      "2021-10-24 22:53:31.929659: validation loss: -0.8412\n",
      "2021-10-24 22:53:31.934248: Average global foreground Dice: [0.8527]\n",
      "2021-10-24 22:53:31.941103: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:53:32.515566: lr: 0.006504\n",
      "2021-10-24 22:53:32.562876: saving checkpoint...\n",
      "2021-10-24 22:53:33.645752: done, saving took 1.10 seconds\n",
      "2021-10-24 22:53:34.123498: This epoch took 195.060216 s\n",
      "\n",
      "2021-10-24 22:53:34.142477: \n",
      "epoch:  19\n",
      "2021-10-24 22:56:33.569693: train loss : -0.8651\n",
      "2021-10-24 22:56:47.054075: validation loss: -0.8423\n",
      "2021-10-24 22:56:47.058414: Average global foreground Dice: [0.8544]\n",
      "2021-10-24 22:56:47.065161: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 22:56:47.605366: lr: 0.006314\n",
      "2021-10-24 22:56:47.656471: saving checkpoint...\n",
      "2021-10-24 22:56:48.787770: done, saving took 1.15 seconds\n",
      "2021-10-24 22:56:49.204414: This epoch took 195.052046 s\n",
      "\n",
      "2021-10-24 22:56:49.228524: \n",
      "epoch:  20\n",
      "2021-10-24 22:59:48.488714: train loss : -0.8666\n",
      "2021-10-24 23:00:01.956659: validation loss: -0.8435\n",
      "2021-10-24 23:00:01.960999: Average global foreground Dice: [0.856]\n",
      "2021-10-24 23:00:01.969179: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:00:02.531418: lr: 0.006125\n",
      "2021-10-24 23:00:02.582331: saving checkpoint...\n",
      "2021-10-24 23:00:03.711007: done, saving took 1.15 seconds\n",
      "2021-10-24 23:00:04.521357: This epoch took 195.286032 s\n",
      "\n",
      "2021-10-24 23:00:04.535524: \n",
      "epoch:  21\n",
      "2021-10-24 23:03:03.952863: train loss : -0.8678\n",
      "2021-10-24 23:03:17.436359: validation loss: -0.8418\n",
      "2021-10-24 23:03:17.440919: Average global foreground Dice: [0.8547]\n",
      "2021-10-24 23:03:17.447510: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:03:17.939337: lr: 0.005934\n",
      "2021-10-24 23:03:17.987980: saving checkpoint...\n",
      "2021-10-24 23:03:19.104769: done, saving took 1.14 seconds\n",
      "2021-10-24 23:03:19.587239: This epoch took 195.044610 s\n",
      "\n",
      "2021-10-24 23:03:19.606684: \n",
      "epoch:  22\n",
      "2021-10-24 23:06:19.075511: train loss : -0.8687\n",
      "2021-10-24 23:06:32.553458: validation loss: -0.8427\n",
      "2021-10-24 23:06:32.557963: Average global foreground Dice: [0.8544]\n",
      "2021-10-24 23:06:32.564921: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:06:33.057862: lr: 0.005743\n",
      "2021-10-24 23:06:33.108797: saving checkpoint...\n",
      "2021-10-24 23:06:34.212104: done, saving took 1.12 seconds\n",
      "2021-10-24 23:06:34.666928: This epoch took 195.053309 s\n",
      "\n",
      "2021-10-24 23:06:34.685662: \n",
      "epoch:  23\n",
      "2021-10-24 23:09:34.108971: train loss : -0.8698\n",
      "2021-10-24 23:09:47.575773: validation loss: -0.8435\n",
      "2021-10-24 23:09:47.581277: Average global foreground Dice: [0.8534]\n",
      "2021-10-24 23:09:47.586914: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:09:48.138260: lr: 0.005551\n",
      "2021-10-24 23:09:48.189065: saving checkpoint...\n",
      "2021-10-24 23:09:49.285644: done, saving took 1.12 seconds\n",
      "2021-10-24 23:09:49.815325: This epoch took 195.122973 s\n",
      "\n",
      "2021-10-24 23:09:49.835582: \n",
      "epoch:  24\n",
      "2021-10-24 23:12:49.576941: train loss : -0.8721\n",
      "2021-10-24 23:13:03.036395: validation loss: -0.8434\n",
      "2021-10-24 23:13:03.040180: Average global foreground Dice: [0.8549]\n",
      "2021-10-24 23:13:03.047044: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:13:03.549637: lr: 0.005359\n",
      "2021-10-24 23:13:03.589393: saving checkpoint...\n",
      "2021-10-24 23:13:04.693112: done, saving took 1.12 seconds\n",
      "2021-10-24 23:13:05.138122: This epoch took 195.295879 s\n",
      "\n",
      "2021-10-24 23:13:05.150789: \n",
      "epoch:  25\n",
      "2021-10-24 23:16:04.861068: train loss : -0.8741\n",
      "2021-10-24 23:16:18.332420: validation loss: -0.8434\n",
      "2021-10-24 23:16:18.336749: Average global foreground Dice: [0.854]\n",
      "2021-10-24 23:16:18.343350: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:16:18.881341: lr: 0.005166\n",
      "2021-10-24 23:16:18.930132: saving checkpoint...\n",
      "2021-10-24 23:16:20.043763: done, saving took 1.13 seconds\n",
      "2021-10-24 23:16:20.470268: This epoch took 195.312125 s\n",
      "\n",
      "2021-10-24 23:16:20.491317: \n",
      "epoch:  26\n",
      "2021-10-24 23:19:20.124768: train loss : -0.8742\n",
      "2021-10-24 23:19:33.575426: validation loss: -0.8450\n",
      "2021-10-24 23:19:33.579844: Average global foreground Dice: [0.8561]\n",
      "2021-10-24 23:19:33.586967: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:19:34.075721: lr: 0.004971\n",
      "2021-10-24 23:19:34.124824: saving checkpoint...\n",
      "2021-10-24 23:19:35.269660: done, saving took 1.16 seconds\n",
      "2021-10-24 23:19:35.754997: This epoch took 195.256852 s\n",
      "\n",
      "2021-10-24 23:19:35.772998: \n",
      "epoch:  27\n",
      "2021-10-24 23:22:35.542785: train loss : -0.8773\n",
      "2021-10-24 23:22:48.994541: validation loss: -0.8452\n",
      "2021-10-24 23:22:48.999161: Average global foreground Dice: [0.8565]\n",
      "2021-10-24 23:22:49.005623: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:22:49.573690: lr: 0.004776\n",
      "2021-10-24 23:22:49.612652: saving checkpoint...\n",
      "2021-10-24 23:22:50.703521: done, saving took 1.11 seconds\n",
      "2021-10-24 23:22:51.195014: This epoch took 195.415083 s\n",
      "\n",
      "2021-10-24 23:22:51.203552: \n",
      "epoch:  28\n",
      "2021-10-24 23:25:51.081951: train loss : -0.8772\n",
      "2021-10-24 23:26:04.543948: validation loss: -0.8436\n",
      "2021-10-24 23:26:04.548469: Average global foreground Dice: [0.8533]\n",
      "2021-10-24 23:26:04.554763: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:26:05.101505: lr: 0.004581\n",
      "2021-10-24 23:26:05.144191: saving checkpoint...\n",
      "2021-10-24 23:26:06.295110: done, saving took 1.17 seconds\n",
      "2021-10-24 23:26:06.858492: This epoch took 195.648282 s\n",
      "\n",
      "2021-10-24 23:26:06.868235: \n",
      "epoch:  29\n",
      "2021-10-24 23:29:06.589618: train loss : -0.8772\n",
      "2021-10-24 23:29:20.055730: validation loss: -0.8403\n",
      "2021-10-24 23:29:20.061430: Average global foreground Dice: [0.8531]\n",
      "2021-10-24 23:29:20.068162: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:29:20.570872: lr: 0.004384\n",
      "2021-10-24 23:29:20.606152: saving checkpoint...\n",
      "2021-10-24 23:29:21.726361: done, saving took 1.14 seconds\n",
      "2021-10-24 23:29:22.241479: This epoch took 195.366368 s\n",
      "\n",
      "2021-10-24 23:29:22.249694: \n",
      "epoch:  30\n",
      "2021-10-24 23:32:22.174414: train loss : -0.8793\n",
      "2021-10-24 23:32:35.661609: validation loss: -0.8420\n",
      "2021-10-24 23:32:35.665709: Average global foreground Dice: [0.8541]\n",
      "2021-10-24 23:32:35.672548: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:32:36.206122: lr: 0.004186\n",
      "2021-10-24 23:32:36.247699: saving checkpoint...\n",
      "2021-10-24 23:32:37.368197: done, saving took 1.14 seconds\n",
      "2021-10-24 23:32:37.831140: This epoch took 195.574981 s\n",
      "\n",
      "2021-10-24 23:32:37.839144: \n",
      "epoch:  31\n",
      "2021-10-24 23:35:37.588873: train loss : -0.8810\n",
      "2021-10-24 23:35:51.055271: validation loss: -0.8413\n",
      "2021-10-24 23:35:51.059961: Average global foreground Dice: [0.8531]\n",
      "2021-10-24 23:35:51.066322: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:35:51.579397: lr: 0.003987\n",
      "2021-10-24 23:35:51.617986: saving checkpoint...\n",
      "2021-10-24 23:35:52.743800: done, saving took 1.14 seconds\n",
      "2021-10-24 23:35:53.174271: This epoch took 195.328647 s\n",
      "\n",
      "2021-10-24 23:35:53.186482: \n",
      "epoch:  32\n",
      "2021-10-24 23:38:53.137879: train loss : -0.8805\n",
      "2021-10-24 23:39:06.593904: validation loss: -0.8400\n",
      "2021-10-24 23:39:06.599736: Average global foreground Dice: [0.8524]\n",
      "2021-10-24 23:39:06.606137: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:39:07.101360: lr: 0.003787\n",
      "2021-10-24 23:39:07.141276: saving checkpoint...\n",
      "2021-10-24 23:39:08.255003: done, saving took 1.13 seconds\n",
      "2021-10-24 23:39:08.767619: This epoch took 195.574060 s\n",
      "\n",
      "2021-10-24 23:39:08.775942: \n",
      "epoch:  33\n",
      "2021-10-24 23:42:08.738632: train loss : -0.8828\n",
      "2021-10-24 23:42:22.209795: validation loss: -0.8421\n",
      "2021-10-24 23:42:22.214818: Average global foreground Dice: [0.8531]\n",
      "2021-10-24 23:42:22.222176: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:42:22.767568: lr: 0.003586\n",
      "2021-10-24 23:42:22.807226: saving checkpoint...\n",
      "2021-10-24 23:42:23.896072: done, saving took 1.11 seconds\n",
      "2021-10-24 23:42:24.369624: This epoch took 195.586533 s\n",
      "\n",
      "2021-10-24 23:42:24.377780: \n",
      "epoch:  34\n",
      "2021-10-24 23:45:24.384783: train loss : -0.8845\n",
      "2021-10-24 23:45:37.820406: validation loss: -0.8440\n",
      "2021-10-24 23:45:37.825105: Average global foreground Dice: [0.8552]\n",
      "2021-10-24 23:45:37.831628: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:45:38.426276: lr: 0.003384\n",
      "2021-10-24 23:45:38.464577: saving checkpoint...\n",
      "2021-10-24 23:45:39.604822: done, saving took 1.16 seconds\n",
      "2021-10-24 23:45:40.046019: This epoch took 195.661438 s\n",
      "\n",
      "2021-10-24 23:45:40.054121: \n",
      "epoch:  35\n",
      "2021-10-24 23:48:40.091965: train loss : -0.8847\n",
      "2021-10-24 23:48:53.548801: validation loss: -0.8480\n",
      "2021-10-24 23:48:53.552954: Average global foreground Dice: [0.8592]\n",
      "2021-10-24 23:48:53.559439: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:48:54.114409: lr: 0.00318\n",
      "2021-10-24 23:48:54.152989: saving checkpoint...\n",
      "2021-10-24 23:48:55.265372: done, saving took 1.13 seconds\n",
      "2021-10-24 23:48:55.737017: This epoch took 195.676802 s\n",
      "\n",
      "2021-10-24 23:48:55.745822: \n",
      "epoch:  36\n",
      "2021-10-24 23:51:55.681602: train loss : -0.8859\n",
      "2021-10-24 23:52:09.147662: validation loss: -0.8414\n",
      "2021-10-24 23:52:09.151843: Average global foreground Dice: [0.8538]\n",
      "2021-10-24 23:52:09.158115: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:52:09.657582: lr: 0.002975\n",
      "2021-10-24 23:52:09.701147: saving checkpoint...\n",
      "2021-10-24 23:52:10.819004: done, saving took 1.14 seconds\n",
      "2021-10-24 23:52:11.459786: This epoch took 195.706870 s\n",
      "\n",
      "2021-10-24 23:52:11.468647: \n",
      "epoch:  37\n",
      "2021-10-24 23:55:11.432466: train loss : -0.8870\n",
      "2021-10-24 23:55:24.871190: validation loss: -0.8444\n",
      "2021-10-24 23:55:24.875666: Average global foreground Dice: [0.8558]\n",
      "2021-10-24 23:55:24.882903: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:55:25.380063: lr: 0.002768\n",
      "2021-10-24 23:55:25.419537: saving checkpoint...\n",
      "2021-10-24 23:55:26.509398: done, saving took 1.11 seconds\n",
      "2021-10-24 23:55:26.965193: This epoch took 195.489547 s\n",
      "\n",
      "2021-10-24 23:55:26.973555: \n",
      "epoch:  38\n",
      "2021-10-24 23:58:26.953574: train loss : -0.8879\n",
      "2021-10-24 23:58:40.440801: validation loss: -0.8439\n",
      "2021-10-24 23:58:40.445659: Average global foreground Dice: [0.8556]\n",
      "2021-10-24 23:58:40.452028: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-24 23:58:40.991878: lr: 0.00256\n",
      "2021-10-24 23:58:41.030901: saving checkpoint...\n",
      "2021-10-24 23:58:42.120248: done, saving took 1.11 seconds\n",
      "2021-10-24 23:58:42.558003: This epoch took 195.577667 s\n",
      "\n",
      "2021-10-24 23:58:42.567479: \n",
      "epoch:  39\n",
      "2021-10-25 00:01:42.618201: train loss : -0.8884\n",
      "2021-10-25 00:01:56.096727: validation loss: -0.8430\n",
      "2021-10-25 00:01:56.101619: Average global foreground Dice: [0.8544]\n",
      "2021-10-25 00:01:56.109376: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:01:56.672310: lr: 0.002349\n",
      "2021-10-25 00:01:56.712495: saving checkpoint...\n",
      "2021-10-25 00:01:57.820297: done, saving took 1.13 seconds\n",
      "2021-10-25 00:01:58.265532: This epoch took 195.690955 s\n",
      "\n",
      "2021-10-25 00:01:58.273932: \n",
      "epoch:  40\n",
      "/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-10-25 00:04:58.440549: train loss : -0.8910\n",
      "2021-10-25 00:05:11.915466: validation loss: -0.8438\n",
      "2021-10-25 00:05:11.921558: Average global foreground Dice: [0.8557]\n",
      "2021-10-25 00:05:11.931128: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:05:12.489412: lr: 0.002137\n",
      "2021-10-25 00:05:12.532986: saving checkpoint...\n",
      "2021-10-25 00:05:13.659077: done, saving took 1.14 seconds\n",
      "2021-10-25 00:05:14.136315: This epoch took 195.854314 s\n",
      "\n",
      "2021-10-25 00:05:14.145371: \n",
      "epoch:  41\n",
      "2021-10-25 00:08:14.218396: train loss : -0.8906\n",
      "2021-10-25 00:08:27.679959: validation loss: -0.8470\n",
      "2021-10-25 00:08:27.684738: Average global foreground Dice: [0.8588]\n",
      "2021-10-25 00:08:27.693003: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:08:28.180746: lr: 0.001922\n",
      "2021-10-25 00:08:28.220582: saving checkpoint...\n",
      "2021-10-25 00:08:29.364574: done, saving took 1.16 seconds\n",
      "2021-10-25 00:08:29.826011: This epoch took 195.669696 s\n",
      "\n",
      "2021-10-25 00:08:29.835675: \n",
      "epoch:  42\n",
      "2021-10-25 00:11:29.959551: train loss : -0.8919\n",
      "2021-10-25 00:11:43.434301: validation loss: -0.8443\n",
      "2021-10-25 00:11:43.438723: Average global foreground Dice: [0.8569]\n",
      "2021-10-25 00:11:43.446705: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:11:43.983253: lr: 0.001704\n",
      "2021-10-25 00:11:44.034036: saving checkpoint...\n",
      "2021-10-25 00:11:45.147081: done, saving took 1.14 seconds\n",
      "2021-10-25 00:11:45.728830: This epoch took 195.885005 s\n",
      "\n",
      "2021-10-25 00:11:45.737992: \n",
      "epoch:  43\n",
      "2021-10-25 00:14:45.824793: train loss : -0.8923\n",
      "2021-10-25 00:14:59.299669: validation loss: -0.8428\n",
      "2021-10-25 00:14:59.304401: Average global foreground Dice: [0.8537]\n",
      "2021-10-25 00:14:59.317704: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:14:59.849114: lr: 0.001483\n",
      "2021-10-25 00:14:59.899544: saving checkpoint...\n",
      "2021-10-25 00:15:01.023319: done, saving took 1.15 seconds\n",
      "2021-10-25 00:15:01.486564: This epoch took 195.739010 s\n",
      "\n",
      "2021-10-25 00:15:01.497859: \n",
      "epoch:  44\n",
      "2021-10-25 00:18:01.550891: train loss : -0.8944\n",
      "2021-10-25 00:18:15.032896: validation loss: -0.8426\n",
      "2021-10-25 00:18:15.037412: Average global foreground Dice: [0.8547]\n",
      "2021-10-25 00:18:15.057990: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:18:15.616737: lr: 0.001259\n",
      "2021-10-25 00:18:15.656089: saving checkpoint...\n",
      "2021-10-25 00:18:16.743292: done, saving took 1.11 seconds\n",
      "2021-10-25 00:18:17.278919: This epoch took 195.771959 s\n",
      "\n",
      "2021-10-25 00:18:17.287414: \n",
      "epoch:  45\n",
      "2021-10-25 00:21:17.347584: train loss : -0.8944\n",
      "2021-10-25 00:21:30.817395: validation loss: -0.8437\n",
      "2021-10-25 00:21:30.822236: Average global foreground Dice: [0.8548]\n",
      "2021-10-25 00:21:30.829099: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:21:31.320963: lr: 0.00103\n",
      "2021-10-25 00:21:31.359647: saving checkpoint...\n",
      "2021-10-25 00:21:32.455167: done, saving took 1.11 seconds\n",
      "2021-10-25 00:21:32.942211: This epoch took 195.648254 s\n",
      "\n",
      "2021-10-25 00:21:32.952642: \n",
      "epoch:  46\n",
      "2021-10-25 00:24:33.141174: train loss : -0.8960\n",
      "2021-10-25 00:24:46.594903: validation loss: -0.8431\n",
      "2021-10-25 00:24:46.599231: Average global foreground Dice: [0.8563]\n",
      "2021-10-25 00:24:46.607379: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:24:47.144616: lr: 0.000795\n",
      "2021-10-25 00:24:47.183496: saving checkpoint...\n",
      "2021-10-25 00:24:48.293984: done, saving took 1.13 seconds\n",
      "2021-10-25 00:24:48.845616: This epoch took 195.886398 s\n",
      "\n",
      "2021-10-25 00:24:48.853985: \n",
      "epoch:  47\n",
      "2021-10-25 00:27:48.870083: train loss : -0.8976\n",
      "2021-10-25 00:28:02.346172: validation loss: -0.8453\n",
      "2021-10-25 00:28:02.350840: Average global foreground Dice: [0.857]\n",
      "2021-10-25 00:28:02.358055: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:28:02.860328: lr: 0.000552\n",
      "2021-10-25 00:28:02.896674: saving checkpoint...\n",
      "2021-10-25 00:28:03.996668: done, saving took 1.12 seconds\n",
      "2021-10-25 00:28:04.536537: This epoch took 195.675730 s\n",
      "\n",
      "2021-10-25 00:28:04.545433: \n",
      "epoch:  48\n",
      "2021-10-25 00:31:04.446261: train loss : -0.8970\n",
      "2021-10-25 00:31:17.906904: validation loss: -0.8438\n",
      "2021-10-25 00:31:17.911828: Average global foreground Dice: [0.8552]\n",
      "2021-10-25 00:31:17.921145: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:31:18.489462: lr: 0.000296\n",
      "2021-10-25 00:31:18.547734: saving checkpoint...\n",
      "2021-10-25 00:31:19.663722: done, saving took 1.14 seconds\n",
      "2021-10-25 00:31:20.249044: This epoch took 195.696680 s\n",
      "\n",
      "2021-10-25 00:31:20.268377: \n",
      "epoch:  49\n",
      "2021-10-25 00:34:20.082641: train loss : -0.8983\n",
      "2021-10-25 00:34:33.534087: validation loss: -0.8421\n",
      "2021-10-25 00:34:33.538690: Average global foreground Dice: [0.8536]\n",
      "2021-10-25 00:34:33.545929: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:34:34.146600: lr: 0.0\n",
      "2021-10-25 00:34:34.172658: saving scheduled checkpoint file...\n",
      "2021-10-25 00:34:34.197928: saving checkpoint...\n",
      "2021-10-25 00:34:35.172415: done, saving took 0.99 seconds\n",
      "2021-10-25 00:34:35.725542: done\n",
      "2021-10-25 00:34:35.739541: This epoch took 195.463941 s\n",
      "\n",
      "2021-10-25 00:34:35.765414: saving checkpoint...\n",
      "2021-10-25 00:34:36.733920: done, saving took 0.99 seconds\n",
      "23090562_20140 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090567_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090579_20141 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090581_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090586_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090587_20150 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090588_20131 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090595_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090606_20120 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090612_20121 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090613_20130 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090625_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090626_20160 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090633_20120 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090641_20160 (3, 299, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "23090643_20121 (3, 335, 128, 128)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-10-25 00:36:34.012980: finished prediction\n",
      "2021-10-25 00:36:34.020977: evaluation of raw predictions\n",
      "2021-10-25 00:36:36.165757: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8452586547501958\n",
      "after:  0.845594269274395\n",
      "Removing all but the largest foreground region improved results!\n",
      "for_which_classes [1]\n",
      "min_valid_object_sizes None\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[[1]]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Model 2\n",
    "os.chdir(main_dir)\n",
    "\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 0\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 1\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 2\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 3\n",
    "!nnUNet_train 2d nnUNetTrainerV2 555 4\n",
    "\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "using model stored in  /mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1\n",
      "This model expects 2 input modalities for each image\n",
      "Found 3 unique case ids, here are some examples: ['23010017_20141226' '23010018_20141226' '23010017_20141226']\n",
      "If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc\n",
      "number of cases: 3\n",
      "number of cases that still need to be predicted: 3\n",
      "emptying cuda cache\n",
      "loading parameters for folds, None\n",
      "folds is None so we will automatically look for output folders (not using 'all'!)\n",
      "found the following folds:  ['/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4']\n",
      "using the following model files:  ['/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3/model_final_checkpoint.model', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4/model_final_checkpoint.model']\n",
      "starting preprocessing generator\n",
      "starting prediction...\n",
      "preprocessing /tf/2d_fold12345/23010017_20141226.nii.gz\n",
      "using preprocessor PreprocessorFor2D\n",
      "preprocessing /tf/2d_fold12345/23010018_20141226.nii.gz\n",
      "using preprocessor PreprocessorFor2D\n",
      "preprocessing /tf/2d_fold12345/23010019_20141224.nii.gz\n",
      "using preprocessor PreprocessorFor2D\n",
      "before crop: (2, 284, 200, 200) after crop: (2, 284, 173, 173) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (2, 284, 200, 200) after crop: (2, 284, 192, 192) spacing: [1. 1. 1.] \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 284, 173, 173)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 284, 173, 173)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "(2, 284, 173, 173)\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 284, 192, 192)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 284, 192, 192)} \n",
      "\n",
      "normalization...\n",
      "This worker has ended successfully, no errors to report\n",
      "before crop: (2, 326, 200, 200) after crop: (2, 326, 174, 173) spacing: [1. 1. 1.] \n",
      "\n",
      "predicting /tf/2d_fold12345/23010018_20141226.nii.gz\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "normalization done\n",
      "(2, 284, 192, 192)\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (2, 326, 174, 173)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (2, 326, 174, 173)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "(2, 326, 174, 173)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "predicting /tf/2d_fold12345/23010017_20141226.nii.gz\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "This worker has ended successfully, no errors to report\n",
      "predicting /tf/2d_fold12345/23010019_20141224.nii.gz\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "debug: mirroring False mirror_axes (0, 1)\n",
      "This worker has ended successfully, no errors to report\n",
      "inference done. Now waiting for the segmentation export to finish...\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "WARNING! Cannot run postprocessing because the postprocessing file is missing. Make sure to run consolidate_folds in the output folder of the model first!\n",
      "The folder you need to run this in is /mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1\n"
     ]
    }
   ],
   "source": [
    "os.listdir('/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/')\n",
    "!nnUNet_predict -i /tf/sample_input -o /tf/2d_fold12345/ -t 555 -tr nnUNetTrainerV2 -m 2d --disable_tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'CT', 1: 'PET'}\n",
      "use_mask_for_norm OrderedDict([(0, False), (1, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'CT'), (1, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 4, 4], 'patch_size': array([256,  96,  96]), 'median_patient_size_in_voxels': array([299, 128, 128]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2021-10-25 00:36:49.915751: Using splits from existing split file: /mnt/temp/nnUNet/nnunet/preprocessed/Task555_PETCT/splits_final.pkl\n",
      "2021-10-25 00:36:49.937168: The split file contains 2 splits.\n",
      "2021-10-25 00:36:49.943654: Desired fold for training: 0\n",
      "2021-10-25 00:36:49.950582: This split has 40 training and 40 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2021-10-25 00:36:59.084673: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-10-25 00:37:17.056489: Unable to plot network architecture:\n",
      "2021-10-25 00:37:17.184636: No module named 'hiddenlayer'\n",
      "2021-10-25 00:37:17.252661: \n",
      "printing the network instead:\n",
      "\n",
      "2021-10-25 00:37:17.356735: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 1, 1), stride=(2, 1, 1), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-10-25 00:37:17.542167: \n",
      "\n",
      "2021-10-25 00:37:17.644663: \n",
      "epoch:  0\n",
      "2021-10-25 00:42:56.958381: train loss : -0.2380\n",
      "2021-10-25 00:43:19.755966: validation loss: -0.6611\n",
      "2021-10-25 00:43:20.069308: Average global foreground Dice: [0.7133]\n",
      "2021-10-25 00:43:20.184598: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:43:22.686217: lr: 0.00982\n",
      "2021-10-25 00:43:23.084664: This epoch took 365.335917 s\n",
      "\n",
      "2021-10-25 00:43:23.236591: \n",
      "epoch:  1\n",
      "2021-10-25 00:48:26.662487: train loss : -0.6062\n",
      "2021-10-25 00:48:50.169618: validation loss: -0.7207\n",
      "2021-10-25 00:48:50.489095: Average global foreground Dice: [0.7626]\n",
      "2021-10-25 00:48:50.596712: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-10-25 00:48:53.227176: lr: 0.009639\n",
      "2021-10-25 00:48:53.925813: saving checkpoint...\n",
      "2021-10-25 00:48:57.201777: done, saving took 3.62 seconds\n",
      "2021-10-25 00:48:58.055047: This epoch took 334.693393 s\n",
      "\n",
      "2021-10-25 00:48:58.073117: \n",
      "epoch:  2\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNet_train\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_train')())\n",
      "  File \"/mnt/backup/nnUNet/nnunet/run/run_training.py\", line 179, in main\n",
      "    trainer.run_training()\n",
      "  File \"/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py\", line 440, in run_training\n",
      "    ret = super().run_training()\n",
      "  File \"/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainer.py\", line 317, in run_training\n",
      "    super(nnUNetTrainer, self).run_training()\n",
      "  File \"/mnt/backup/nnUNet/nnunet/training/network_training/network_trainer.py\", line 456, in run_training\n",
      "    l = self.run_iteration(self.tr_gen, True)\n",
      "  File \"/mnt/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py\", line 255, in run_iteration\n",
      "    self.amp_grad_scaler.step(self.optimizer)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py\", line 338, in step\n",
      "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py\", line 285, in _maybe_opt_step\n",
      "    retval = optimizer.step(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/sgd.py\", line 110, in step\n",
      "    F.sgd(params_with_grad,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 173, in sgd\n",
      "    buf.mul_(momentum).add_(d_p, alpha=1 - dampening)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'child' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpexpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Vanilla Pexpect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mflush\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command, args, timeout, maxread, searchwindowsize, logfile, cwd, env, ignore_sighup, echo, preexec_fn, encoding, codec_errors, dimensions, use_poll)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreexec_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_poll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_poll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawn\u001b[0;34m(self, command, args, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         self.ptyproc = self._spawnpty(self.args, env=self.env,\n\u001b[0m\u001b[1;32m    304\u001b[0m                                      cwd=self.cwd, **kwargs)\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawnpty\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;34m'''Spawn a pty and return an instance of PtyProcess.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mptyprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPtyProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ptyprocess/ptyprocess.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(cls, argv, cwd, env, echo, preexec_fn, dimensions, pass_fds)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_err_pipe_write\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mexec_err_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_err_pipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_err_pipe_read\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-1f17b42cf7a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nnUNet_train 3d_fullres nnUNetTrainerV2 555 0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nnUNet_train 3d_fullres nnUNetTrainerV2 555 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nnUNet_train 3d_fullres nnUNetTrainerV2 555 2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nnUNet_train 3d_fullres nnUNetTrainerV2 555 3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m   2498\u001b[0m         \u001b[0;31m# a non-None value would trigger :func:`sys.displayhook` calls.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2499\u001b[0m         \u001b[0;31m# Instead, we store the exit_code in user_ns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2500\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2502\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msystem_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;31m# (the character is known as ETX for 'End of Text', see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;31m# curses.ascii.ETX).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;31m# Read and print any more output the program might produce on its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;31m# way out.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'child' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Model 3\n",
    "os.chdir(main_dir)\n",
    "\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 0\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 1\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 2\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 3\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 555 4\n",
    "\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = os.path.join(model_dir, 'nnUNet/2d/')\n",
    "# fold_list = ['fold_0', 'fold_1', 'fold_2', 'fold_3', 'fold_4']\n",
    "# fold_list = [fold_0, fold_1, fold_2, fold_3, fold_4]\n",
    "\n",
    "fold_all = os.path.join(model_1, 'Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/all')\n",
    "fold_0 = os.path.join(model_1, 'Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0')\n",
    "fold_1 = os.path.join(model_1, 'Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1')\n",
    "fold_2 = os.path.join(model_1, 'Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2')\n",
    "fold_3 = os.path.join(model_1, 'Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3')\n",
    "fold_4 = os.path.join(model_1, 'Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4')\n",
    "\n",
    "fold_list = [fold_0, fold_1, fold_2, fold_3, fold_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in fold_list:\n",
    "    if os.path.exists(fold):\n",
    "        shutil.rmtree(fold)\n",
    "        shutil.copytree(fold_all, fold)\n",
    "    else:\n",
    "        shutil.copytree(fold_all, fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! /mnt/utils/setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['utils', 'backup', 'dataset', 'submission', 'temp']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/mnt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23010019_20141.nii.gz',\n",
       " '23010017_20141.nii.gz',\n",
       " '23010018_20141.nii.gz',\n",
       " 'plans.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/mnt/backup/working/nnUNet/nnunet/nnUNet_Prediction_Results/Task555_PETCT/2d/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23090580_20131226.hdf5', '23090618_20161212.hdf5', '23090628_20150204.hdf5', '23090643_20121227.hdf5', '23090644_20131216.hdf5', '23090636_20121018.hdf5', '23090585_20130213.hdf5', '23090572_20130226.hdf5', '23090603_20141212.hdf5', '23090601_20130225.hdf5', '23090569_20120607.hdf5', '23090599_20140701.hdf5', '23090597_20130227.hdf5', '23090627_20160608.hdf5', '23090559_20150812.hdf5', '23090614_20120402.hdf5', '23090557_20130717.hdf5', '23090634_20150409.hdf5', '23090581_20130626.hdf5', '23090626_20160119.hdf5', '23090568_20121018.hdf5', '23090623_20120406.hdf5', '23090615_20140403.hdf5', '23090640_20140711.hdf5', '23090613_20130208.hdf5', '23090641_20160510.hdf5', '23090609_20120510.hdf5', '23090560_20160114.hdf5', '23090563_20151216.hdf5', '23090596_20150112.hdf5', '23090632_20130807.hdf5', '23090598_20130103.hdf5', '23090584_20120523.hdf5', '23090633_20120403.hdf5', '23090607_20120420.hdf5', '23090594_20160706.hdf5', '23090622_20150105.hdf5', '23090583_20160308.hdf5', '23090637_20140401.hdf5', '23090620_20130617.hdf5', '23090645_20141212.hdf5', '23090621_20130409.hdf5', '23090562_20140206.hdf5', '23090582_20150401.hdf5', '23090566_20141114.hdf5', '23090571_20120517.hdf5', '23090642_20130409.hdf5', '23090595_20121015.hdf5', '23090586_20120627.hdf5', '23090604_20140303.hdf5', '23090561_20120330.hdf5', '23090610_20151210.hdf5', '23090639_20150522.hdf5', '23090608_20120718.hdf5', '23090588_20131025.hdf5', '23090578_20120613.hdf5', '23090593_20120625.hdf5', '23090564_20130312.hdf5', '23090631_20130128.hdf5', '23090616_20140331.hdf5', '23090606_20120619.hdf5', '23090638_20131126.hdf5', '23090629_20120830.hdf5', '23090592_20130218.hdf5', '23090625_20160111.hdf5', '23090589_20140219.hdf5', '23090617_20140211.hdf5', '23090590_20121212.hdf5', '23090619_20121210.hdf5', '23090611_20150212.hdf5', '23090612_20121213.hdf5', '23090646_20120718.hdf5', '23090600_20121108.hdf5', '23090579_20141215.hdf5', '23090630_20130213.hdf5', '23090558_20120330.hdf5', '23090591_20140124.hdf5', '23090567_20160819.hdf5', '23090635_20140710.hdf5', '23090587_20150908.hdf5']\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('/mnt/dataset'))\n",
    "print(len(os.listdir('/mnt/dataset')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fold_4',\n",
       " 'fold_0',\n",
       " 'fold_2',\n",
       " 'all',\n",
       " 'fold_1',\n",
       " 'plans.pkl',\n",
       " 'fold_3',\n",
       " 'gt_niftis']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fold_4',\n",
       " 'fold_0',\n",
       " 'fold_2',\n",
       " 'all',\n",
       " 'fold_1',\n",
       " 'plans.pkl',\n",
       " 'fold_3',\n",
       " 'gt_niftis']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/3d_fullres/Task555_PETCT/nnUNetTrainerV2__nnUNetPlansv2.1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename model..\n",
    "# os.rename('/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/Task555_PETCT', '/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/all_Task555_PETCT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/temp/'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "# Copy model..\n",
    "# shutil.copytree('/mnt/backup/working/nnUNet/nnunet/nnUNet_trained_models/nnUNet/2d/', '/mnt/backup/temp_submission/models/nnUNet/2d')\n",
    "# shutil.copytree('/tf/submission/submitted/21-10-27_13:29:02-models/', '/tf/temp_submission/models')\n",
    "# shutil.copytree('/tf/backup/nnUNet', '/tf/temp_submission/models/module')\n",
    "shutil.copytree('/tf/backup/temp_submission/', '/tf/temp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['utils', 'backup', 'dataset', 'submission', 'temp']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/mnt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['utils', 'backup', 'dataset', 'submission', 'temp']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(os.listdir('/mnt/'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
